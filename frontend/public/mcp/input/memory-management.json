{
  "category": "memory-management",
  "categoryDisplay": "Memory Management",
  "description": "",
  "totalRepositories": 84,
  "repositories": {
    "AdamPippert--multi-service-mcp-server": {
      "owner": "AdamPippert",
      "name": "multi-service-mcp-server",
      "url": "https://github.com/AdamPippert/multi-service-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/AdamPippert.webp",
      "description": "Integrate and automate various tools such as GitHub, GitLab, Google Maps, and Puppeteer through a unified gateway for efficient data retrieval and workflow enhancement. The modular architecture allows for easy addition or removal of individual tool modules.",
      "stars": 3,
      "forks": 3,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-04-21T16:09:22Z",
      "readme_content": "** NOTE: This project is no longer being maintained, as issues with model memory for smaller models means my preferred method for MCP servers is as individual containerized server providers rather than a monolithic routing provider.  Code is being kept up in case others still want to try to go down this route.\n\n\n\n\n# Model Context Protocol (MCP) Server\n\nA modular server that implements the [Model Context Protocol](https://modelcontextprotocol.io/) standard, providing tools for GitHub, GitLab, Google Maps, Memory storage, and Puppeteer web automation.\n\n## Architecture\n\nThe MCP server is built with a modular architecture, where each tool is implemented as a separate module. The server provides a unified gateway that routes requests to the appropriate tool.\n\n\n\n## Features\n\n- **MCP Gateway**: A unified endpoint for all tool requests following the MCP standard\n- **MCP Manifest**: An endpoint that describes all available tools and their capabilities\n- **Direct Tool Access**: Each tool can be accessed directly via its own API endpoints\n- **Modular Design**: Easy to add or remove tools as needed\n\n### Included Tools\n\n1. **GitHub Tool**: Interact with GitHub repositories, issues, and search\n2. **GitLab Tool**: Interact with GitLab projects, issues, and pipelines\n3. **Google Maps Tool**: Geocoding, directions, and places search\n4. **Memory Tool**: Store and retrieve data persistently\n5. **Puppeteer Tool**: Take screenshots, generate PDFs, and extract content from websites\n\n## Getting Started\n\n### Prerequisites\n\n- Python 3.8 or higher\n- Node.js 14 or higher\n- A Red Hat-based Linux distribution (RHEL, CentOS, Fedora) or any Linux/macOS system\n\n### Installation\n\n1. Clone this repository:\n   ```bash\n   git clone https://github.com/yourusername/mcp-server.git\n   cd mcp-server\n   ```\n\n2. Install Python dependencies:\n   ```bash\n   pip install -r requirements.txt\n   ```\n\n3. Install Node.js dependencies:\n   ```bash\n   npm install\n   ```\n\n4. Create a `.env` file with your configuration:\n   ```\n   SECRET_KEY=your-secret-key\n   DEBUG=False\n   \n   # GitHub configuration\n   GITHUB_TOKEN=your-github-token\n   \n   # GitLab configuration\n   GITLAB_TOKEN=your-gitlab-token\n   \n   # Google Maps configuration\n   GMAPS_API_KEY=your-google-maps-api-key\n   \n   # Memory configuration\n   MEMORY_DB_URI=sqlite:///memory.db\n   \n   # Puppeteer configuration\n   PUPPETEER_HEADLESS=true\n   CHROME_PATH=/usr/bin/chromium-browser\n   ```\n\n5. Start the server:\n   ```bash\n   python app.py\n   ```\n\n### Containerized Deployment\n\nYou can run the server using either Docker or Podman (Red Hat's container engine).\n\n#### Docker Deployment\n\nIf you already have Docker and docker-compose installed:\n\n1. Build the Docker image:\n   ```bash\n   docker build -t mcp-server .\n   ```\n\n2. Run the container:\n   ```bash\n   docker run -p 5000:5000 --env-file .env mcp-server\n   ```\n\n3. Alternatively, use docker-compose:\n   \n   Create a `docker-compose.yml` file:\n   ```yaml\n   version: '3'\n   services:\n     mcp-server:\n       build: .\n       ports:\n         - \"5000:5000\"\n       volumes:\n         - ./data:/app/data\n       env_file:\n         - .env\n       restart: unless-stopped\n   ```\n\n   Then run:\n   ```bash\n   docker-compose up -d\n   ```\n\n#### Podman Deployment\n\nFor Red Hat based systems (RHEL, CentOS, Fedora) using Podman:\n\n1. Build the container image:\n   ```bash\n   podman build -t mcp-server .\n   ```\n\n2. Run the container:\n   ```bash\n   podman run -p 5000:5000 --env-file .env mcp-server\n   ```\n\n3. If you need persistent storage:\n   ```bash\n   mkdir -p ./data\n   podman run -p 5000:5000 --env-file .env -v ./data:/app/data:Z mcp-server\n   ```\n   Note: The `:Z` suffix is important for SELinux-enabled systems.\n\n4. Using Podman Compose (if installed):\n   ```bash\n   # Install podman-compose if needed\n   pip install podman-compose\n   \n   # Use the same docker-compose.yml file as above\n   podman-compose up -d\n   ```\n\n## Using the MCP Server\n\n### MCP Gateway\n\nThe MCP Gateway is the main endpoint for accessing all tools using the MCP standard.\n\n**Endpoint**: `POST /mcp/gateway`\n\n**Request format**:\n```json\n{\n  \"tool\": \"github\",\n  \"action\": \"listRepos\",\n  \"parameters\": {\n    \"username\": \"octocat\"\n  }\n}\n```\n\n**Response format**:\n```json\n{\n  \"tool\": \"github\",\n  \"action\": \"listRepos\",\n  \"status\": \"success\",\n  \"result\": [\n    {\n      \"id\": 1296269,\n      \"name\": \"Hello-World\",\n      \"full_name\": \"octocat/Hello-World\",\n      \"owner\": {\n        \"login\": \"octocat\",\n        \"id\": 1\n      },\n      ...\n    }\n  ]\n}\n```\n\n### MCP Manifest\n\nThe MCP Manifest describes all available tools and their capabilities.\n\n**Endpoint**: `GET /mcp/manifest`\n\n**Response format**:\n```json\n{\n  \"manifestVersion\": \"1.0\",\n  \"tools\": {\n    \"github\": {\n      \"actions\": {\n        \"listRepos\": {\n          \"description\": \"List repositories for a user or organization\",\n          \"parameters\": {\n            \"username\": {\n              \"type\": \"string\",\n              \"description\": \"GitHub username or organization name\"\n            }\n          },\n          \"returns\": {\n            \"type\": \"array\",\n            \"description\": \"List of repository objects\"\n          }\n        },\n        ...\n      }\n    },\n    ...\n  }\n}\n```\n\n### Direct Tool Access\n\nEach tool can also be accessed directly via its own API endpoints:\n\n- GitHub: `/tool/github/...`\n- GitLab: `/tool/gitlab/...`\n- Google Maps: `/tool/gmaps/...`\n- Memory: `/tool/memory/...`\n- Puppeteer: `/tool/puppeteer/...`\n\nSee the API documentation for each tool for details on the available endpoints.\n\n## Tool Documentation\n\n### GitHub Tool\n\nThe GitHub tool provides access to the GitHub API for repositories, issues, and search.\n\n**Actions**:\n- `listRepos`: List repositories for a user or organization\n- `getRepo`: Get details for a specific repository\n- `searchRepos`: Search for repositories\n- `getIssues`: Get issues for a repository\n- `createIssue`: Create a new issue in a repository\n\n### GitLab Tool\n\nThe GitLab tool provides access to the GitLab API for projects, issues, and pipelines.\n\n**Actions**:\n- `listProjects`: List all projects accessible by the authenticated user\n- `getProject`: Get details for a specific project\n- `searchProjects`: Search for projects on GitLab\n- `getIssues`: Get issues for a project\n- `createIssue`: Create a new issue in a project\n- `getPipelines`: Get pipelines for a project\n\n### Google Maps Tool\n\nThe Google Maps tool provides access to the Google Maps API for geocoding, directions, and places search.\n\n**Actions**:\n- `geocode`: Convert an address to geographic coordinates\n- `reverseGeocode`: Convert geographic coordinates to an address\n- `getDirections`: Get directions between two locations\n- `searchPlaces`: Search for places using the Google Places API\n- `getPlaceDetails`: Get details for a specific place\n\n### Memory Tool\n\nThe Memory tool provides a persistent key-value store for storing and retrieving data.\n\n**Actions**:\n- `get`: Get a memory item by key\n- `set`: Create or update a memory item\n- `delete`: Delete a memory item by key\n- `list`: List all memory items, with optional filtering\n- `search`: Search memory items by value\n\n### Puppeteer Tool\n\nThe Puppeteer tool provides web automation capabilities for taking screenshots, generating PDFs, and extracting content from websites.\n\n**Actions**:\n- `screenshot`: Take a screenshot of a webpage\n- `pdf`: Generate a PDF of a webpage\n- `extract`: Extract content from a webpage\n\n## Contributing\n\nContributions are welcome! Here's how you can extend the MCP server:\n\n### Adding a New Tool\n\n1. Create a new file in the `tools` directory, e.g., `tools/newtool_tool.py`\n2. Implement the tool with actions following the same pattern as existing tools\n3. Add the tool to the manifest in `app.py`\n4. Register the tool's blueprint in `tools/__init__.py`\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## Acknowledgements\n\n- [Model Context Protocol](https://modelcontextprotocol.io/) for the standard specification\n- [Flask](https://flask.palletsprojects.com/) for the web framework\n- [Puppeteer](https://pptr.dev/) for web automation",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "puppeteer",
        "adampippert",
        "tools",
        "maps puppeteer",
        "tool modules",
        "management adampippert"
      ],
      "category": "memory-management"
    },
    "AgentWong--iac-memory-mcp-server-project": {
      "owner": "AgentWong",
      "name": "iac-memory-mcp-server-project",
      "url": "https://github.com/AgentWong/iac-memory-mcp-server-project",
      "imageUrl": "/freedevtools/mcp/pfp/AgentWong.webp",
      "description": "Provides persistent memory storage and version tracking for Infrastructure-as-Code components, focusing on Terraform and Ansible resources with relationship mapping.",
      "stars": 6,
      "forks": 4,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-08-06T04:00:02Z",
      "readme_content": "# IaC Memory MCP Server\n\nA Model Context Protocol (MCP) server that enhances Claude AI's capabilities by providing persistent memory storage for Infrastructure-as-Code (IaC) components, with a focus on version tracking and relationship mapping for Terraform and Ansible resources.\n\n> [!NOTE]  \n> This was a personal project to determine the state of AI's ability if the person using it (me)\n> doesn't have subject matter expertise (lack of Python knowledge).  Since it has become rather cost\n> prohibitive, I do not intend to develop or maintain this project further.\n\n## Overview\n\nThe IaC Memory MCP Server addresses the challenge of maintaining accurate, version-aware context for IaC components by providing:\n\n- Persistent storage and version tracking for IaC components\n- Hierarchical resource organization with URI-based access\n- Comprehensive relationship mapping between components\n- Version-specific documentation management\n- Schema validation and temporal metadata tracking\n- Automated relationship analysis and insights\n\n## Core Components\n\n### Resource Management\n\nThe server implements a sophisticated resource management system with hierarchical URIs:\n\n#### Resource URI Structure\n```\nresources://<platform>/<category>/<name>\n```\n\nSupported platforms:\n- terraform\n- ansible\n- iac (for general infrastructure entities)\n\nExample URIs:\n```\nresources://terraform/providers/aws\nresources://terraform/resources/aws/s3_bucket\nresources://ansible/collections/community.aws\nresources://ansible/modules/community.aws/s3_bucket\n```\n\n#### Resource Templates\nThe server provides dynamic resource templates for standardized access patterns:\n- Terraform provider information: `resources://terraform/providers/{provider_name}`\n- Resource type details: `resources://terraform/resources/{provider_name}/{resource_type}`\n- Ansible collection data: `resources://ansible/collections/{collection_name}`\n- Module information: `resources://ansible/modules/{collection_name}/{module_name}`\n\n### Prompts\n\nThe server implements four specialized prompts for IaC component discovery and analysis:\n\n#### search_resources\n- Purpose: Search for IaC resources\n- Arguments:\n  - `provider`: Provider name\n  - `resource_type`: Resource type\n- Returns: Information about specific resources for the given provider\n\n#### analyze_entity\n- Purpose: Analyze an entity and its relationships\n- Arguments:\n  - `entity_id`: Entity ID\n  - `include_relationships`: Include relationships\n- Returns: Detailed entity analysis including name, type, and observations\n\n#### terraform_provider\n- Purpose: Get information about a Terraform provider\n- Arguments:\n  - `provider_name`: Name of the Terraform provider (required)\n  - `version`: Specific version to query (optional)\n- Returns: Detailed provider information for the specified version\n\n#### ansible_module\n- Purpose: Get information about an Ansible module\n- Arguments:\n  - `collection_name`: Name of the Ansible collection (required)\n  - `module_name`: Name of the module (required)\n  - `version`: Specific version to query (optional)\n- Returns: Detailed module information for the specified version\n\n### Tools\n\nThe server implements comprehensive tooling for IaC component management:\n\n#### Terraform Tools\n- `get_terraform_provider_info`: Retrieve detailed provider information including version and resources\n- `list_provider_resources`: List all resources available for a specific provider\n- `get_terraform_resource_info`: Get detailed information about a specific resource type\n- `add_terraform_provider`: Register new providers with versioning\n- `add_terraform_resource`: Add resource definitions with schemas\n- `update_provider_version`: Update provider versions with new documentation\n\n#### Ansible Tools\n- `get_ansible_collection_info`: Get detailed information about an Ansible collection\n- `list_ansible_collections`: List all available Ansible collections\n- `get_collection_version_history`: View version history of a collection\n- `get_ansible_module_info`: Get detailed information about a specific module\n- `list_collection_modules`: List all modules in a collection\n- `get_module_version_compatibility`: Check version compatibility of modules\n- `add_ansible_collection`: Register new Ansible collections\n- `add_ansible_module`: Add new modules with validation and documentation\n\n#### Entity Operations\n- `create_entity`: Create new infrastructure entities\n- `update_entity`: Modify existing entity configurations\n- `delete_entity`: Remove entities with relationship cleanup\n- `view_relationships`: Analyze entity dependencies and relationships\n\n## Configuration\n\nThe server supports configuration through environment variables:\n\n- `DATABASE_URL`: SQLite database location\n- `MCP_DEBUG`: Enable debug logging when set\n- `MCP_TEST_MODE`: Enable test mode for database resets\n\nFor development, create a `.env` file:\n```bash\nDATABASE_URL=sqlite:////path/to/db.sqlite\nMCP_DEBUG=1\nMCP_TEST_MODE=1\n```\n\n## Integration with Claude Desktop\n\n### Development Setup\n```json\n\"mcpServers\": {\n  \"iac-memory\": {\n    \"command\": \"uv\",\n    \"args\": [\n      \"--directory\",\n      \"/path/to/iac-memory-mcp-server\",\n      \"run\",\n      \"iac-memory-mcp-server\"\n    ]\n    \"env\": {\n          \"DATABASE_URL\": \"sqlite:////home/herman/iac.db\"\n      }\n  }\n}\n```\n\n### Production Setup\n```json\n\"mcpServers\": {\n  \"iac-memory\": {\n    \"command\": \"uvx\",\n    \"args\": [\n        \"--from\",\n        \"git+https://github.com/AgentWong/iac-memory-mcp-server.git\",\n        \"python\",\n        \"-m\",\n        \"iac_memory_mcp_server\"\n    ],\n    \"env\": {\n          \"DATABASE_URL\": \"sqlite:////home/herman/iac.db\"\n      }\n  }\n}\n```\n\n## Development\n\n### Local Development\n```bash\n# Install dependencies\nuv sync\n\n# Run tests\nuv run pytest\n\n# Development server with MCP Inspector\nnpx @modelcontextprotocol/inspector uv run iac-memory-mcp-server\n```\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "terraform",
        "ansible",
        "memory",
        "terraform ansible",
        "iac memory",
        "memory management"
      ],
      "category": "memory-management"
    },
    "AgentWong--optimized-memory-mcp-server": {
      "owner": "AgentWong",
      "name": "optimized-memory-mcp-server",
      "url": "https://github.com/AgentWong/optimized-memory-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/AgentWong.webp",
      "description": "Enables persistent memory capabilities for AI interactions, allowing the model to remember user information and enhance personalization through a local knowledge graph that manages entities, relations, and observations.",
      "stars": 7,
      "forks": 5,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-24T09:06:46Z",
      "readme_content": "# optimized-memory-mcp-server\n\nThis is to test and demonstrate Claude AI's coding abilities, as well as good AI workflows and prompt design.\nThis is a fork of a Python Memory MCP Server (I believe the official one is in Java) which uses SQLite for a backend.\n\n# Knowledge Graph Memory Server\nA basic implementation of persistent memory using a local knowledge graph. This lets Claude remember information about the user across chats.\n\n## Core Concepts\n\n### Entities\nEntities are the primary nodes in the knowledge graph. Each entity has:\n- A unique name (identifier)\n- An entity type (e.g., \"person\", \"organization\", \"event\")\n- A list of observations\n\nExample:\n```json\n{\n  \"name\": \"John_Smith\",\n  \"entityType\": \"person\",\n  \"observations\": [\"Speaks fluent Spanish\"]\n}\n```\n\n### Relations\nRelations define directed connections between entities. They are always stored in active voice and describe how entities interact or relate to each other.\n\nExample:\n```json\n{\n  \"from\": \"John_Smith\",\n  \"to\": \"Anthropic\",\n  \"relationType\": \"works_at\"\n}\n```\n### Observations\nObservations are discrete pieces of information about an entity. They are:\n\n- Stored as strings\n- Attached to specific entities\n- Can be added or removed independently\n- Should be atomic (one fact per observation)\n\nExample:\n```json\n{\n  \"entityName\": \"John_Smith\",\n  \"observations\": [\n    \"Speaks fluent Spanish\",\n    \"Graduated in 2019\",\n    \"Prefers morning meetings\"\n  ]\n}\n```\n\n## API\n\n### Tools\n- **create_entities**\n  - Create multiple new entities in the knowledge graph\n  - Input: `entities` (array of objects)\n    - Each object contains:\n      - `name` (string): Entity identifier\n      - `entityType` (string): Type classification\n      - `observations` (string[]): Associated observations\n  - Ignores entities with existing names\n\n- **create_relations**\n  - Create multiple new relations between entities\n  - Input: `relations` (array of objects)\n    - Each object contains:\n      - `from` (string): Source entity name\n      - `to` (string): Target entity name\n      - `relationType` (string): Relationship type in active voice\n  - Skips duplicate relations\n\n- **add_observations**\n  - Add new observations to existing entities\n  - Input: `observations` (array of objects)\n    - Each object contains:\n      - `entityName` (string): Target entity\n      - `contents` (string[]): New observations to add\n  - Returns added observations per entity\n  - Fails if entity doesn't exist\n\n- **delete_entities**\n  - Remove entities and their relations\n  - Input: `entityNames` (string[])\n  - Cascading deletion of associated relations\n  - Silent operation if entity doesn't exist\n\n- **delete_observations**\n  - Remove specific observations from entities\n  - Input: `deletions` (array of objects)\n    - Each object contains:\n      - `entityName` (string): Target entity\n      - `observations` (string[]): Observations to remove\n  - Silent operation if observation doesn't exist\n\n- **delete_relations**\n  - Remove specific relations from the graph\n  - Input: `relations` (array of objects)\n    - Each object contains:\n      - `from` (string): Source entity name\n      - `to` (string): Target entity name\n      - `relationType` (string): Relationship type\n  - Silent operation if relation doesn't exist\n\n- **read_graph**\n  - Read the entire knowledge graph\n  - No input required\n  - Returns complete graph structure with all entities and relations\n\n- **search_nodes**\n  - Search for nodes based on query\n  - Input: `query` (string)\n  - Searches across:\n    - Entity names\n    - Entity types\n    - Observation content\n  - Returns matching entities and their relations\n\n- **open_nodes**\n  - Retrieve specific nodes by name\n  - Input: `names` (string[])\n  - Returns:\n    - Requested entities\n    - Relations between requested entities\n  - Silently skips non-existent nodes\n\n# Usage with Claude Desktop\n\n### Setup\n\nAdd this to your claude_desktop_config.json:\n\n#### Docker\n\n```json\n{\n  \"mcpServers\": {\n    \"memory\": {\n      \"command\": \"docker\",\n      \"args\": [\"run\", \"-i\", \"--rm\", \"mcp/memory\"]\n    }\n  }\n}\n```\n\n#### NPX\n```json\n{\n  \"mcpServers\": {\n    \"memory\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@modelcontextprotocol/server-memory\"\n      ]\n    }\n  }\n}\n```\n\n### System Prompt\n\nThe prompt for utilizing memory depends on the use case. Changing the prompt will help the model determine the frequency and types of memories created.\n\nHere is an example prompt for chat personalization. You could use this prompt in the \"Custom Instructions\" field of a [Claude.ai Project](https://www.anthropic.com/news/projects). \n\n```\nFollow these steps for each interaction:\n\n1. User Identification:\n   - You should assume that you are interacting with default_user\n   - If you have not identified default_user, proactively try to do so.\n\n2. Memory Retrieval:\n   - Always begin your chat by saying only \"Remembering...\" and retrieve all relevant information from your knowledge graph\n   - Always refer to your knowledge graph as your \"memory\"\n\n3. Memory\n   - While conversing with the user, be attentive to any new information that falls into these categories:\n     a) Basic Identity (age, gender, location, job title, education level, etc.)\n     b) Behaviors (interests, habits, etc.)\n     c) Preferences (communication style, preferred language, etc.)\n     d) Goals (goals, targets, aspirations, etc.)\n     e) Relationships (personal and professional relationships up to 3 degrees of separation)\n\n4. Memory Update:\n   - If any new information was gathered during the interaction, update your memory as follows:\n     a) Create entities for recurring organizations, people, and significant events\n     b) Connect them to the current entities using relations\n     b) Store facts about them as observations\n```\n\n## Building\n\nDocker:\n\n```sh\ndocker build -t mcp/memory -f src/memory/Dockerfile . \n```\n\n## License\n\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "memory",
        "persistent",
        "ai",
        "persistent memory",
        "memory management",
        "memory mcp"
      ],
      "category": "memory-management"
    },
    "ArchimedesCrypto--figma-mcp-chunked": {
      "owner": "ArchimedesCrypto",
      "name": "figma-mcp-chunked",
      "url": "https://github.com/ArchimedesCrypto/figma-mcp-chunked",
      "imageUrl": "/freedevtools/mcp/pfp/ArchimedesCrypto.webp",
      "description": "Efficiently interact with the Figma API, utilizing memory-aware chunking and pagination to manage and process large Figma files. This enables effective handling of extensive design documents and resource-intensive operations.",
      "stars": 3,
      "forks": 3,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-08-18T18:56:40Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/archimedescrypto-figma-mcp-chunked-badge.png)](https://mseep.ai/app/archimedescrypto-figma-mcp-chunked)\n\n# Figma MCP Server with Chunking\n[![smithery badge](https://smithery.ai/badge/@ArchimedesCrypto/figma-mcp-chunked)](https://smithery.ai/server/@ArchimedesCrypto/figma-mcp-chunked)\n\nA Model Context Protocol (MCP) server for interacting with the Figma API, featuring memory-efficient chunking and pagination capabilities for handling large Figma files.\n\n<a href=\"https://glama.ai/mcp/servers/@ArchimedesCrypto/figma-mcp-chunked\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@ArchimedesCrypto/figma-mcp-chunked/badge\" alt=\"Figma Server with Chunking MCP server\" />\n</a>\n\n## Overview\n\nThis MCP server provides a robust interface to the Figma API with built-in memory management features. It's designed to handle large Figma files efficiently by breaking down operations into manageable chunks and implementing pagination where necessary.\n\n### Key Features\n\n- Memory-aware processing with configurable limits\n- Chunked data retrieval for large files\n- Pagination support for all listing operations\n- Node type filtering\n- Progress tracking\n- Configurable chunk sizes\n- Resume capability for interrupted operations\n- Debug logging\n- Config file support\n\n## Installation\n\n### Installing via Smithery\n\nTo install Figma MCP Server with Chunking for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@ArchimedesCrypto/figma-mcp-chunked):\n\n```bash\nnpx -y @smithery/cli install @ArchimedesCrypto/figma-mcp-chunked --client claude\n```\n\n### Manual Installation\n```bash\n# Clone the repository\ngit clone [repository-url]\ncd figma-mcp-chunked\n\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n```\n\n## Configuration\n\n### Environment Variables\n\n- `FIGMA_ACCESS_TOKEN`: Your Figma API access token\n\n### Config File\n\nYou can provide configuration via a JSON file using the `--config` flag:\n\n```json\n{\n  \"mcpServers\": {\n    \"figma\": {\n      \"env\": {\n        \"FIGMA_ACCESS_TOKEN\": \"your-access-token\"\n      }\n    }\n  }\n}\n```\n\nUsage:\n```bash\nnode build/index.js --config=path/to/config.json\n```\n\n## Tools\n\n### get_file_data (New)\n\nRetrieves Figma file data with memory-efficient chunking and pagination.\n\n```typescript\n{\n  \"name\": \"get_file_data\",\n  \"arguments\": {\n    \"fileKey\": \"your-file-key\",\n    \"accessToken\": \"your-access-token\",\n    \"pageSize\": 100,          // Optional: nodes per chunk\n    \"maxMemoryMB\": 512,       // Optional: memory limit\n    \"nodeTypes\": [\"FRAME\", \"COMPONENT\"],  // Optional: filter by type\n    \"cursor\": \"next-page-token\",  // Optional: resume from last position\n    \"depth\": 2                // Optional: traversal depth\n  }\n}\n```\n\nResponse:\n```json\n{\n  \"nodes\": [...],\n  \"memoryUsage\": 256.5,\n  \"nextCursor\": \"next-page-token\",\n  \"hasMore\": true\n}\n```\n\n### list_files\n\nLists files with pagination support.\n\n```typescript\n{\n  \"name\": \"list_files\",\n  \"arguments\": {\n    \"project_id\": \"optional-project-id\",\n    \"team_id\": \"optional-team-id\"\n  }\n}\n```\n\n### get_file_versions\n\nRetrieves version history in chunks.\n\n```typescript\n{\n  \"name\": \"get_file_versions\",\n  \"arguments\": {\n    \"file_key\": \"your-file-key\"\n  }\n}\n```\n\n### get_file_comments\n\nRetrieves comments with pagination.\n\n```typescript\n{\n  \"name\": \"get_file_comments\",\n  \"arguments\": {\n    \"file_key\": \"your-file-key\"\n  }\n}\n```\n\n### get_file_info\n\nRetrieves file information with chunked node traversal.\n\n```typescript\n{\n  \"name\": \"get_file_info\",\n  \"arguments\": {\n    \"file_key\": \"your-file-key\",\n    \"depth\": 2,               // Optional: traversal depth\n    \"node_id\": \"specific-node-id\"  // Optional: start from specific node\n  }\n}\n```\n\n### get_components\n\nRetrieves components with chunking support.\n\n```typescript\n{\n  \"name\": \"get_components\",\n  \"arguments\": {\n    \"file_key\": \"your-file-key\"\n  }\n}\n```\n\n### get_styles\n\nRetrieves styles with chunking support.\n\n```typescript\n{\n  \"name\": \"get_styles\",\n  \"arguments\": {\n    \"file_key\": \"your-file-key\"\n  }\n}\n```\n\n### get_file_nodes\n\nRetrieves specific nodes with chunking support.\n\n```typescript\n{\n  \"name\": \"get_file_nodes\",\n  \"arguments\": {\n    \"file_key\": \"your-file-key\",\n    \"ids\": [\"node-id-1\", \"node-id-2\"]\n  }\n}\n```\n\n## Memory Management\n\nThe server implements several strategies to manage memory efficiently:\n\n### Chunking Strategy\n\n- Configurable chunk sizes via `pageSize`\n- Memory usage monitoring\n- Automatic chunk size adjustment based on memory pressure\n- Progress tracking per chunk\n- Resume capability using cursors\n\n### Best Practices\n\n1. Start with smaller chunk sizes (50-100 nodes) and adjust based on performance\n2. Monitor memory usage through the response metadata\n3. Use node type filtering when possible to reduce data load\n4. Implement pagination for large datasets\n5. Use the resume capability for very large files\n\n### Configuration Options\n\n- `pageSize`: Number of nodes per chunk (default: 100)\n- `maxMemoryMB`: Maximum memory usage in MB (default: 512)\n- `nodeTypes`: Filter specific node types\n- `depth`: Control traversal depth for nested structures\n\n## Debug Logging\n\nThe server includes comprehensive debug logging:\n\n```typescript\n// Debug log examples\n[MCP Debug] Loading config from config.json\n[MCP Debug] Access token found xxxxxxxx...\n[MCP Debug] Request { tool: 'get_file_data', arguments: {...} }\n[MCP Debug] Response size 2.5 MB\n```\n\n## Error Handling\n\nThe server provides detailed error messages and suggestions:\n\n```typescript\n// Memory limit error\n\"Response size too large. Try using a smaller depth value or specifying a node_id.\"\"\n\n// Invalid parameters\n\"Missing required parameters: fileKey and accessToken\"\n\n// API errors\n\"Figma API error: [detailed message]\"\n```\n\n## Troubleshooting\n\n### Common Issues\n\n1. Memory Errors\n   - Reduce chunk size\n   - Use node type filtering\n   - Implement pagination\n   - Specify smaller depth values\n\n2. Performance Issues\n   - Monitor memory usage\n   - Adjust chunk sizes\n   - Use appropriate node type filters\n   - Implement caching for frequently accessed data\n\n3. API Limits\n   - Implement rate limiting\n   - Use pagination\n   - Cache responses when possible\n\n### Debug Mode\n\nEnable debug logging for detailed information:\n\n```bash\n# Set debug environment variable\nexport DEBUG=true\n```\n\n## Contributing\n\nContributions are welcome! Please read our contributing guidelines and submit pull requests to our repository.\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "figma",
        "archimedescrypto",
        "memory",
        "archimedescrypto figma",
        "figma files",
        "figma api"
      ],
      "category": "memory-management"
    },
    "BRO3886--mcp-memory-custom": {
      "owner": "BRO3886",
      "name": "mcp-memory-custom",
      "url": "https://github.com/BRO3886/mcp-memory-custom",
      "imageUrl": "/freedevtools/mcp/pfp/BRO3886.webp",
      "description": "Manage and enhance user interactions with a customizable knowledge graph, capturing and organizing these interactions with timestamps for improved context and project-specific memory management.",
      "stars": 4,
      "forks": 5,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-05-25T04:36:32Z",
      "readme_content": "# Memory Custom\n\n[![smithery badge](https://smithery.ai/badge/@BRO3886/mcp-memory-custom)](https://smithery.ai/server/@BRO3886/mcp-memory-custom)\n\nThis project adds new features to the Memory server offered by the MCP team. It allows for the creation and management of a knowledge graph that captures interactions via a language model (LLM).\n\n<a href=\"https://glama.ai/mcp/servers/w6hi2myrxq\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/w6hi2myrxq/badge\" alt=\"Memory Custom MCP server\" />\n</a>\n\n## New Features\n\n### 1. Custom Memory Paths\n\n- Users can now specify different memory file paths for various projects.\n- **Why?**: This feature enhances organization and management of memory data, allowing for project-specific memory storage.\n\n### 2. Timestamping\n\n- The server now generates timestamps for interactions.\n- **Why?**: Timestamps enable tracking of when each memory was created or modified, providing better context and history for the stored data.\n\n## Getting Started\n\n### Prerequisites\n\n- Node.js (version 16 or higher)\n\n### Installing via Smithery\n\nTo install Knowledge Graph Memory Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@BRO3886/mcp-memory-custom):\n\n```bash\nnpx -y @smithery/cli install @BRO3886/mcp-memory-custom --client claude\n```\n\n### Installation\n\n1. Clone the repository:\n\n   ```bash\n   git clone git@github.com:BRO3886/mcp-memory-custom.git\n   cd mcp-memory-custom\n   ```\n\n2. Install the dependencies:\n\n   ```bash\n   npm install\n   ```\n\n### Configuration\n\nBefore running the server, you can set the `MEMORY_FILE_PATH` environment variable to specify the path for the memory file. If not set, the server will default to using `memory.json` in the same directory as the script.\n\n### Running the Server\n\n#### Updating the mcp server json file\n\nAdd this to your `claude_desktop_config.json` / `.cursor/mcp.json` file:\n\n```json\n{\n  \"mcpServers\": {\n    \"memory\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/mcp-memory-custom/dist/index.js\"]\n    }\n  }\n}\n```\n\nSystem Prompt changes:\n\n```\nFollow these steps for each interaction:\n1. The memoryFilePath for this project is /path/to/memory/project_name.json - always pass this path to the memory file operations (when creating entities, relations, or retrieving memory etc.)\n2. User Identification:\n   - You should assume that you are interacting with default_user\n   - If you have not identified default_user, proactively try to do so.\n\n3. Memory Retrieval:\n   - Always begin your chat by saying only \"Remembering...\" and retrieve all relevant information from your knowledge graph\n   - Always refer to your knowledge graph as your \"memory\"\n\n4. Memory\n   - While conversing with the user, be attentive to any new information that falls into these categories:\n     a) Basic Identity (age, gender, location, job title, education level, etc.)\n     b) Behaviors (interests, habits, etc.)\n     c) Preferences (communication style, preferred language, etc.)\n     d) Goals (goals, targets, aspirations, etc.)\n     e) Relationships (personal and professional relationships up to 3 degrees of separation)\n\n5. Memory Update:\n   - If any new information was gathered during the interaction, update your memory as follows:\n     a) Create entities for recurring organizations, people, and significant events, add timestamps to wherever required. You can get current timestamp via get_current_time\n     b) Connect them to the current entities using relations\n     c) Store facts about them as observations, add timestamps to observations via get_current_time\n\n\nIMPORTANT: Provide a helpful and engaging response, asking relevant questions to encourage user engagement. Update the memory during the interaction, if required, based on the new information gathered (point 4).\n```\n\n#### Running the Server Locally\n\nTo start the Knowledge Graph Memory Server, run:\n\n```bash\nnpm run build\nnode dist/index.js\n```\n\nThe server will listen for requests via standard input/output.\n\n## API Endpoints\n\nThe server exposes several tools that can be called with specific parameters:\n\n- **Get Current Time**\n- **Set Memory File Path**\n- **Create Entities**\n- **Create Relations**\n- **Add Observations**\n- **Delete Entities**\n- **Delete Observations**\n- **Delete Relations**\n- **Read Graph**\n- **Search Nodes**\n- **Open Nodes**\n\n## Acknowledgments\n\n- Inspired by the Memory server from Anthropic.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "memory",
        "manage",
        "management",
        "memory management",
        "memory custom",
        "mcp memory"
      ],
      "category": "memory-management"
    },
    "CheMiguel23--MemoryMesh": {
      "owner": "CheMiguel23",
      "name": "MemoryMesh",
      "url": "https://github.com/CheMiguel23/MemoryMesh",
      "imageUrl": "/freedevtools/mcp/pfp/CheMiguel23.webp",
      "description": "Stores, updates, and recalls structured information using a dynamic schema, enabling relationship management for entities such as characters, locations, and items in a knowledge graph format. Designed specifically for text-based RPGs and interactive storytelling, it helps maintain consistent memory across conversations.",
      "stars": 301,
      "forks": 39,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-29T06:59:31Z",
      "readme_content": "# MemoryMesh\n[![Release](https://img.shields.io/badge/Release-v0.2.8-blue.svg)](./CHANGELOG.md)\n[![smithery badge](https://smithery.ai/badge/memorymesh)](https://smithery.ai/server/memorymesh)\n![TypeScript](https://img.shields.io/badge/TypeScript-007ACC.svg?logo=typescript&logoColor=white)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n![GitHub Stars](https://img.shields.io/github/stars/CheMiguel23/MemoryMesh.svg?style=social)\n\nMemoryMesh is a knowledge graph server designed for AI models, with a focus on text-based RPGs and interactive storytelling. It helps AI maintain consistent, structured memory across conversations, enabling richer and more dynamic interactions.\n\n*The project is based on the [Knowledge Graph Memory Server](https://github.com/modelcontextprotocol/servers/tree/main/src/memory) from the MCP servers repository and retains its core functionality.*\n\n<a href=\"https://glama.ai/mcp/servers/kf6n6221pd\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/kf6n6221pd/badge\" alt=\"MemoryMesh MCP server\" /></a>\n\n## IMPORTANT\nSince `v0.2.7` the default location of schemas was changed to `dist/data/schemas`.\nThis location is not expected to change in the future, but if you are updating from a previous version, make sure to move your schema files to the new location.\n\n## Quick Links\n\n*   [Installation](#installation)\n*   [Example](#example)\n*   [SchemaManager Guide Discussion](https://github.com/CheMiguel23/MemoryMesh/discussions/3)\n*   [MemoryViewer Guide Discussion](https://github.com/CheMiguel23/MemoryMesh/discussions/15)\n\n## Overview\n\nMemoryMesh is a local knowledge graph server that empowers you to build and manage structured information for AI models. While particularly well-suited for text-based RPGs, its adaptable design makes it useful for various applications, including social network simulations, organizational planning, or any scenario involving structured data.\n\n### Key Features\n\n*   **Dynamic Schema-Based Tools:** Define your data structure with schemas, and MemoryMesh automatically generates tools for adding, updating, and deleting data.\n*   **Intuitive Schema Design:** Create schemas that guide the AI in generating and connecting nodes, using required fields, enumerated types, and relationship definitions.\n*   **Metadata for AI Guidance:**  Use metadata to provide context and structure, helping the AI understand the meaning and relationships within your data.\n*   **Relationship Handling:** Define relationships within your schemas to encourage the AI to create connections (edges) between related data points (nodes).\n*   **Informative Feedback:**  Provides error feedback to the AI, enabling it to learn from mistakes and improve its interactions with the knowledge graph.\n*   **Event Support:** An event system tracks operations, providing insights into how the knowledge graph is being modified.\n\n#### Nodes\n\nNodes represent entities or concepts within the knowledge graph. Each node has:\n\n* `name`: A unique identifier.\n* `nodeType`: The type of the node (e.g., `npc`, `artifact`, `location`), defined by your schemas.\n* `metadata`: An array of strings providing descriptive details about the node.\n* `weight`: (Optional) A numerical value between 0 and 1 representing the strength of the relationship, defaulting to 1.\n\n**Example Node:**\n\n```json\n    {\n      \"name\": \"Aragorn\",\n      \"nodeType\": \"player_character\",\n      \"metadata\": [\n        \"Race: Human\",\n        \"Class: Ranger\",\n        \"Skills: Tracking, Swordsmanship\",\n        \"Affiliation: Fellowship of the Ring\"\n      ]\n    }\n```\n\n#### Edges\n\nEdges represent relationships between nodes. Each edge has:\n\n* `from`: The name of the source node.\n* `to`: The name of the target node.\n* `edgeType`: The type of relationship (e.g., `owns`, `located_in`).\n\n```json\n{\n  \"from\": \"Aragorn\",\n  \"to\": \"Andúril\",\n  \"edgeType\": \"owns\"\n}\n```\n\n#### Schemas\n\nSchemas are the heart of MemoryMesh. They define the structure of your data and drive the automatic generation of tools.\n\n##### Schema File Location\n\nPlace your schema files (`.schema.json`) in the `dist/data/schemas` directory of your built MemoryMesh project. MemoryMesh will automatically detect and process these files on startup.\n\n##### Schema Structure\n\nFile name: `[name].schema.json`. For example, for a schema defining an 'npc', the filename would be `add_npc.schema.json`.\n\n* `name` - Identifier for the schema and node type within the memory. **IMPORTANT**: The schema’s name *must* start with `add_` to be recognized.\n* `description` - Used as the description for the `add_<name>` tool, providing context for the AI. *(The `delete` and `update` tools have a generic description)*\n* `properties` - Each property includes its type, description, and additional constraints.\n    * `property`\n        * `type` - Supported values are `string` or `array`.\n        * `description` - Helps guide the AI on the entity’s purpose.\n        * `required` - Boolean. If `true`, the **AI is forced** to provide this property when creating a node.\n        * `enum` - An array of strings. If present, the **AI must choose** one of the given options.\n        * `relationship` - Defines a connection to another node. If a property is required and has a relationship, the **AI will always create** both the node and the corresponding edge.\n            * `edgeType` - Type of the relationship to be created.\n            * `description` - Helps guide the AI on the relationship’s purpose.\n* `additionalProperties` - Boolean. If `true`, allows the AI to add extra attributes beyond those defined as required or optional.\n\n##### Example Schema (add_npc.schema.json):\n\n```json\n{\n  \"name\": \"add_npc\",\n  \"description\": \"Schema for adding an NPC to the memory\" ,\n  \"properties\": {\n    \"name\": {\n      \"type\": \"string\",\n      \"description\": \"A unique identifier for the NPC\",\n      \"required\": true\n    },\n    \"race\": {\n      \"type\": \"string\",\n      \"description\": \"The species or race of the NPC\",\n      \"required\": true,\n      \"enum\": [\n        \"Human\",\n        \"Elf\",\n        \"Dwarf\",\n        \"Orc\",\n        \"Goblin\"\n      ]\n    },\n    \"currentLocation\": {\n      \"type\": \"string\",\n      \"description\": \"The current location of the NPC\",\n      \"required\": true,\n      \"relationship\": {\n        \"edgeType\": \"located_in\",\n        \"description\": \"The current location of the NPC\"\n      }\n    }\n  },\n  \"additionalProperties\": true\n}\n```\n\nBased on this schema, MemoryMesh automatically creates:\n* add_npc: To add new NPC nodes.\n* update_npc: To modify existing NPC nodes.\n* delete_npc: To remove NPC nodes.\n\nMemoryMesh includes 11 pre-built schemas designed for text-based RPGs, providing a ready-to-use foundation for game development.\n\n##### SchemaManager Tool\n\nMemoryMesh includes a [SchemaManager tool](https://github.com/CheMiguel23/MemoryMesh/blob/main/SchemaManager.html) to simplify schema creation and editing. It provides a visual interface, making it easy to define your data structures without writing JSON directly.\n\n<img width=\"370\" alt=\"image\" src=\"https://github.com/user-attachments/assets/e8f0c808-2ff6-48da-ac7c-cf51aebde7b8\">\n\n### Dynamic Tools\n\nMemoryMesh simplifies interaction with your knowledge graph through **dynamic tools**. These tools are not manually coded but are **automatically generated** directly from your **schema definitions**. This means that when you define the structure of your data using schemas, MemoryMesh intelligently creates a set of tools tailored to work with that specific data structure.\n\n**Think of it like this:** You provide a blueprint (the schema), and MemoryMesh automatically constructs the necessary tools to build, modify, and remove elements based on that blueprint.\n\n#### How does it work behind the scenes?\n\nMemoryMesh has an intelligent system that reads your schema definitions. It analyzes the structure you've defined, including the properties of your entities and their relationships. Based on this analysis, it automatically creates a set of tools for each entity type:\n\n*   **`add_<entity>`:**  A tool for creating new instances of an entity.\n*   **`update_<entity>`:** A tool for modifying existing entities.\n*   **`delete_<entity>`:** A tool for removing entities.\n\nThese tools are then made available through a central hub within MemoryMesh, ensuring they can be easily accessed and used by any connected client or AI.\n\n**In essence, MemoryMesh's dynamic tool system provides a powerful and efficient way to manage your knowledge graph, freeing you to focus on the content and logic of your application rather than the underlying mechanics of data manipulation.**\n\n### Memory file\n\nBy default, data is stored in a JSON file in `dist/data/memory.json`.\n\n#### Memory Viewer\n\nThe Memory Viewer is a separate tool designed to help you visualize and inspect the contents of the knowledge graph managed by MemoryMesh. It provides a user-friendly interface for exploring nodes, edges, and their properties.\n\n##### Key Features:\n* Graph Visualization: View the knowledge graph as an interactive node-link diagram.\n* Node Inspection: Select nodes to see their nodeType, metadata, and connected edges.\n* Edge Exploration: Examine relationships between nodes, including edgeType and direction.\n* Search and Filtering: Quickly find specific nodes or filter them by type.\n* Table View: Allows you to easily find and inspect specific nodes and edges, or all of them at once.\n* Raw JSON View: Allows you to view the raw JSON data from the memory file.\n* Stats Panel: Provides key metrics and information about the knowledge graph: total nodes, total edges, node types, and edge types.\n* Search and Filter: Allows you to filter by node type or edge type and filter whether to show nodes, edges, or both.\n\n##### Accessing the Memory Viewer\nThe Memory Viewer is a standalone web application. [Memory Viewer discussion](https://github.com/CheMiguel23/MemoryMesh/discussions/15)\n\n##### Using the Memory Viewer\n* Select Memory File: In the Memory Viewer, click the \"Select Memory File\" button.\n* Choose File: Navigate to your MemoryMesh project directory and select the `memory.json` file (located in `dist/data/memory.json` by default).\n* Explore: The Memory Viewer will load and display the contents of your knowledge graph.\n\n## Memory Flow\n\n![image](https://github.com/user-attachments/assets/27519003-c1e6-448a-9fdb-cd0a0009f67d)\n\n## Prompt\n\nFor optimal results, use Claude's \"Projects\" feature with custom instructions. Here's an example of a prompt you can start with:\n\n```\nYou are a helpful AI assistant managing a knowledge graph for a text-based RPG. You have access to the following tools: add_npc, update_npc, delete_npc, add_location, update_location, delete_location, and other tools for managing the game world.\n\nWhen the user provides input, first process it using your available tools to update the knowledge graph. Then, respond in a way that is appropriate for a text-based RPG.\n```\n\nYou can also instruct the AI to perform specific actions directly in the chat.\n\nExperiment with different prompts to find what works best for your use case!\n\n### Example\n1. A [simple example](https://pastebin.com/0HvKg5FZ) with custom instructions.\n2. An example for the sake of example, with visualization _(NOT part of the functionality)_\n\n> Add a couple of cities, some npcs, couple locations around the city to explore, hide an artifact or two somewhere\n\n![image](https://github.com/user-attachments/assets/508d5903-2896-4665-a892-cdb7b81dfba6)\n\n## Installation\n\n### Installing via Smithery\n\nTo install MemoryMesh for Claude Desktop automatically via [Smithery](https://smithery.ai/server/memorymesh):\n\n```bash\nnpx -y @smithery/cli install memorymesh --client claude\n```\n\n### Prerequisites\n\n*   **Node.js:** Version 18 or higher. You can download it from [nodejs.org](https://nodejs.org/).\n*   **npm:**  Usually included with Node.js.\n*   **Claude for Desktop:**  Make sure you have the latest version installed from [claude.ai/download](https://claude.ai/download).\n\n### Installation Steps\n\n1. **Clone the Repository:**\n\n    ```bash\n    git clone https://github.com/CheMiguel23/memorymesh.git\n    cd memorymesh\n    ```\n\n2. **Install Dependencies:**\n\n    ```bash\n    npm install\n    ```\n\n3. **Build the Project:**\n\n    ```bash\n    npm run build\n    ```\n   This command compiles the TypeScript code into JavaScript in the `dist` directory and copies sample schema and data files into it as well.\n\n4. **Verify File Copy (Optional):**\n\n    *   The build process should automatically copy the `data` folder to `dist`.\n    *   **Check** that `dist/data` exists and contains `.json` files. Also verify that `dist/data/schemas` exists and contains `.schema.json` files.\n\n5. **Configure Claude Desktop:**\n\n   Open your Claude Desktop configuration file:\n\n    * **macOS:** `~/Library/Application Support/Claude/claude_desktop_config.json`\n    * **Windows:** `%APPDATA%\\Claude\\claude_desktop_config.json`\n    * Add an entry for `memorymesh` to the `mcpServers` section. You can choose **one** of the following configuration options:\n\n    ```json\n    \"mcpServers\": {\n      \"memorymesh\": {\n        \"command\": \"node\", \n        \"args\": [\"/ABSOLUTE/PATH/TO/YOUR/PROJECT/memorymesh/dist/index.js\"]\n      }\n    }\n    ```\n\n    *   Replace `/ABSOLUTE/PATH/TO/YOUR/PROJECT/` with the **actual absolute path** to your `memorymesh` project directory.\n    *   **Example (macOS):**\n        ```json\n        \"command\": \"node\",\n        \"args\": [\"/Users/yourusername/Projects/memorymesh/dist/index.js\"]\n        ```\n    *   **Example (Windows):**\n        ```json\n        \"command\": \"node\",\n        \"args\": [\"C:\\\\Projects\\\\memorymesh\\\\dist\\\\index.js\"]\n        ```\n\n6. **Restart Claude Desktop:** Completely restart Claude Desktop for the changes to take effect.\n\n### Verify Installation\n\n1. Start Claude Desktop.\n2. Open a new chat.\n3. Look for the MCP plugin icon <img alt=\"claude_desktop_mcp_plug_icon\" src=\"https://mintlify.s3.us-west-1.amazonaws.com/mcp/images/claude-desktop-mcp-plug-icon.svg\"/> in the top-right corner. If it's there, your configuration is likely correct.\n4. Click the <img alt=\"claude_desktop_mcp_plug_icon\" src=\"https://mintlify.s3.us-west-1.amazonaws.com/mcp/images/claude-desktop-mcp-plug-icon.svg\"/> icon. You should see \"memorymesh\" in the list of connected servers.\n5. Click the <img src=\"https://mintlify.s3.us-west-1.amazonaws.com/mcp/images/claude-desktop-mcp-hammer-icon.svg\"/> icon. If you see tools listed (e.g., `add_npc`, `update_npc`, etc.), your server is working and exposing tools correctly.\n\n### Updating\nBefore updates, make sure to back up your `dist/data` directory to avoid losing your memory data.\n\n### Troubleshooting\n\n*   **Server not appearing in Claude:**\n    *   Double-check the paths in your `claude_desktop_config.json`. Make sure they are absolute paths and correct.\n    *   Verify that the `dist` directory exists and contains the compiled JavaScript files, including `index.js`.\n    *   Check the Claude Desktop logs for errors:\n        *   **macOS:** `~/Library/Logs/Claude/mcp-server-memorymesh.log` (and `mcp.log`)\n        *   **Windows:** (Likely in a `Logs` folder under `%AppData%\\Claude`)\n\n*   **Tools not showing up:**\n    *   Make sure your `npm run build` command completed without errors.\n    *   Verify that your schema files are correctly placed in `dist/data/schemas` and follow the correct naming convention (`add_[entity].schema.json`).\n    *   Check your server's console output or logs for any errors during initialization.\n\n## Advanced Configuration\nMemoryMesh offers several ways to customize its behavior beyond the basic setup:\n\n### Variables\nYou can override default settings using in `/config/config.ts`\n* MEMORY_FILE: Specifies the path to the JSON file used for storing the knowledge graph data. (Default: `dist/data/memory.json`)\n* SCHEMAS_DIR: Path to schema files directory. (Default: `dist/data/schemas/memory.json`)\n\n## Limitations\n\n1. **Node Deletion:** The AI may be hesitant to delete nodes from the knowledge graph. Encourage it through prompts if needed.\n\n## Contribution\n\nContributions, feedback, and ideas are welcome!\nThis project is a personal exploration into integrating structured data with AI reasoning capabilities. Contributions, feedback, and ideas are welcome to push it further or inspire new projects.\n",
      "npm_url": "https://www.npmjs.com/package/memorymesh",
      "npm_downloads": 0,
      "keywords": [
        "memorymesh",
        "memory",
        "schema",
        "memory conversations",
        "memorymesh stores",
        "chemiguel23 memorymesh"
      ],
      "category": "memory-management"
    },
    "ChrisL108--outline-mcp": {
      "owner": "ChrisL108",
      "name": "outline-mcp",
      "url": "https://github.com/ChrisL108/outline-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/ChrisL108.webp",
      "description": "Search and retrieve documents from Outline knowledge bases, facilitating access to internal documentation. Supports secure access via interactive credentials and environment variables.",
      "stars": 1,
      "forks": 0,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-04-13T01:39:32Z",
      "readme_content": "# Outline MCP\n\nAn MCP (Model Control Protocol) server for integrating Outline with Claude.\n\n## Overview\n\nThis tool provides Claude with the ability to search and retrieve documents from your Outline knowledge base. Use it to help Claude answer questions using your organization's internal documentation.\n\n## Features\n\n- Search for documents in your Outline instance\n- Retrieve full document content by ID\n- Maintain persistent credentials between sessions\n\n## Installation\n\n> **Note**: Your Outline API key must have the following permissions:\n> - `documents.info` - For retrieving document content\n> - `documents.search` - For searching documents\n\n> **Note**: If `OUTLINE_URL` and `OUTLINE_API_KEY` are not provided in your config, Claude will prompt you for them. These credentials will be saved in `~/.outline_mcp_credentials.json` for future use.\n\n### Option 1: Install via Smithery CLI (requires smithery key)\n\n```bash\nnpx -y @smithery/cli@latest install @ChrisL108/outline-mcp --client claude --key your-smithery-api-key\n```\n\nYou can enter your `OUTLINE_URL` and `OUTLINE_API_KEY` when prompted by Claude or add them to your `claude_desktop_config.json` directly:\n\n```json\n\"env\": {\n    \"OUTLINE_URL\": \"https://your.outline.com\",\n    \"OUTLINE_API_KEY\": \"your-outline-api-key\"\n}\n```\n\nYour config should look like this:\n\n```json\n\"outline-mcp\": {\n    \"command\": \"npx\",\n    \"args\": [\n      \"-y\",\n      \"@smithery/cli@latest\",\n      \"run\",\n      \"@ChrisL108/outline-mcp\",\n      \"--key\",\n      \"your-smithery-api-key\"\n    ],\n    \"env\": {\n      \"OUTLINE_URL\": \"https://your.outline.com\",\n      \"OUTLINE_API_KEY\": \"your-outline-api-key\"\n    }\n}\n```\n\n### Option 2: Install via UVX\n\n```json\n\"outline-mcp\": {\n    \"command\": \"uvx\",\n    \"args\": [\n      \"--from\",\n      \"git+https://github.com/ChrisL108/outline-mcp\",\n      \"outline-mcp\"\n    ],\n    \"env\": {\n      \"OUTLINE_URL\": \"https://your.outline.com\",\n      \"OUTLINE_API_KEY\": \"your-outline-api-key\"\n    }\n}\n```\n\n## Usage\n\nOnce installed, you can use the following functions in your conversations with Claude:\n\n### Search Documents\n\n```\nsearch_documents(query, outline_url=None, api_key=None, limit=5, status_filter=\"published\", date_filter=\"year\")\n```\n\nParameters:\n- `query`: Search term (required)\n- `outline_url`: Base URL of your Outline instance (only needed first time)\n- `api_key`: Outline API key (only needed first time)\n- `limit`: Maximum number of results (default: 5)\n- `status_filter`: Filter by status (default: \"published\")\n- `date_filter`: Filter by date (default: \"year\")\n\n### Get Document by ID\n\n```\nget_document_by_id(document_id)\n```\n\nParameters:\n- `document_id`: ID of the document to retrieve (required)\n\n### Update Credentials\n\n```\nupdate_credentials(outline_url, api_key)\n```\n\nParameters:\n- `outline_url`: Base URL of your Outline instance\n- `api_key`: Outline API key\n\n### Ping\n\n```\nping()\n```\n\nSimple test function to verify the MCP server is working.\n\n## Example Prompts\n\nHere are some example prompts you can use with Claude:\n\n1. \"Search Outline for information about our product roadmap.\"\n2. \"Can you find any documents related to our hiring process?\"\n3. \"Check our internal documentation for our AWS setup.\"\n4. \"Can you get the full content of this document? [document_id]\"\n\n## Troubleshooting\n\nIf you encounter issues:\n\n1. Ensure your Outline URL and API key are correctly configured\n2. Verify that your Outline instance is accessible\n3. Check if your API key has the necessary permissions\n4. Try the `ping()` function to verify the MCP server is running correctly\n\n## Security Considerations\n\n- Keep your API key secure and don't share it\n- The MCP server only has the permissions granted to your API key\n- Consider using a read-only API key if you only need search functionality\n\n## License\n\nMIT License\n\nCopyright (c) 2025 ChrisL108\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## Credits\n\nCreated by [ChrisL108](https://github.com/ChrisL108)",
      "npm_url": "https://www.npmjs.com/package/outline-mcp",
      "npm_downloads": 684,
      "keywords": [
        "documentation",
        "documents",
        "outline",
        "memory management",
        "outline mcp",
        "documents outline"
      ],
      "category": "memory-management"
    },
    "Din-djarin2--memory-bank-mcp": {
      "owner": "Din-djarin2",
      "name": "memory-bank-mcp",
      "url": "https://github.com/Din-djarin2/memory-bank-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/Din-djarin2.webp",
      "description": "Manage and access project memory banks remotely with centralized control, supporting multi-project operations with secure isolation and consistent file structure enforcement. Perform memory bank operations including reading, writing, and listing files across projects through a type-safe MCP interface.",
      "stars": 1,
      "forks": 0,
      "license": "MIT License",
      "language": "",
      "updated_at": "2025-04-28T05:41:24Z",
      "readme_content": "# Memory Bank MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@alioshr/memory-bank-mcp)](https://smithery.ai/server/@alioshr/memory-bank-mcp)\n[![npm version](https://badge.fury.io/js/%40allpepper%2Fmemory-bank-mcp.svg)](https://www.npmjs.com/package/@allpepper/memory-bank-mcp)\n[![npm downloads](https://img.shields.io/npm/dm/@allpepper/memory-bank-mcp.svg)](https://www.npmjs.com/package/@allpepper/memory-bank-mcp)\n\n<a href=\"https://glama.ai/mcp/servers/ir18x1tixp\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/ir18x1tixp/badge\" alt=\"Memory Bank Server MCP server\" /></a>\n\nA Model Context Protocol (MCP) server implementation for remote memory bank management, inspired by [Cline Memory Bank](https://github.com/nickbaumann98/cline_docs/blob/main/prompting/custom%20instructions%20library/cline-memory-bank.md).\n\n## Overview\n\nThe Memory Bank MCP Server transforms traditional file-based memory banks into a centralized service that:\n\n- Provides remote access to memory bank files via MCP protocol\n- Enables multi-project memory bank management\n- Maintains consistent file structure and validation\n- Ensures proper isolation between project memory banks\n\n## Features\n\n- **Multi-Project Support**\n\n  - Project-specific directories\n  - File structure enforcement\n  - Path traversal prevention\n  - Project listing capabilities\n  - File listing per project\n\n- **Remote Accessibility**\n\n  - Full MCP protocol implementation\n  - Type-safe operations\n  - Proper error handling\n  - Security through project isolation\n\n- **Core Operations**\n  - Read/write/update memory bank files\n  - List available projects\n  - List files within projects\n  - Project existence validation\n  - Safe read-only operations\n\n## Installation\n\n### Installation\n\nTo install Memory Bank Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@alioshr/memory-bank-mcp):\n\n```bash\nnpx -y @smithery/cli install @alioshr/memory-bank-mcp --client claude\n```\n\nThis will set up the MCP server configuration automatically. Alternatively, you can configure the server manually as described in the Configuration section below.\n\n## Quick Start\n\n1. Configure the MCP server in your settings (see Configuration section below)\n2. Start using the memory bank tools in your AI assistant\n\n## Configuration\n\nThe memory bank MCP server needs to be configured in your Cline MCP settings file. The location depends on your setup:\n\n- For Cline extension: `~/Library/Application Support/Cursor/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json`\n- For Claude desktop app: `~/Library/Application Support/Claude/claude_desktop_config.json`\n\nAdd the following configuration to your MCP settings:\n\n```json\n{\n  \"allpepper-memory-bank\": {\n    \"command\": \"npx\",\n    \"args\": [\"-y\", \"@allpepper/memory-bank-mcp\"],\n    \"env\": {\n      \"MEMORY_BANK_ROOT\": \"<path-to-bank>\"\n    },\n    \"disabled\": false,\n    \"autoApprove\": [\n      \"memory_bank_read\",\n      \"memory_bank_write\",\n      \"memory_bank_update\",\n      \"list_projects\",\n      \"list_project_files\"\n    ]\n  }\n}\n```\n\n### Configuration Details\n\n- `MEMORY_BANK_ROOT`: Directory where project memory banks will be stored (e.g., `/path/to/memory-bank`)\n- `disabled`: Set to `false` to enable the server\n- `autoApprove`: List of operations that don't require explicit user approval:\n  - `memory_bank_read`: Read memory bank files\n  - `memory_bank_write`: Create new memory bank files\n  - `memory_bank_update`: Update existing memory bank files\n  - `list_projects`: List available projects\n  - `list_project_files`: List files within a project\n\n## For Cursor\n\nFor Cursor, open the settings -> features -> add MCP server -> add the following:\n\n```\nenv MEMORY_BANK_ROOT=<path-to-bank> npx -y @allpepper/memory-bank-mcp@latest\n```\n\n## Custom IA instructions\n\nThis section contains the instructions that should be pasted on the AI custom instructions, either for Cline, Claude or Cursor, or any other MCP client. You should copy and paste these rules. For reference, see [custom-instructions.md](custom-instructions.md) which contains these rules.\n\n## Development\n\n```bash\n# Install dependencies\nnpm install\n\n# Build\nnpm run build\n\n# Test\nnpm run test\n\n# Watch mode\nnpm run dev\n```\n\n## Contributing\n\nContributions are welcome! Please follow these steps:\n\n1. Fork the repository\n2. Create a feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n\n### Development Guidelines\n\n- Use TypeScript for all new code\n- Maintain type safety across the codebase\n- Add tests for new features\n- Update documentation as needed\n- Follow existing code style and patterns\n\n### Testing\n\n- Write unit tests for new features\n- Include multi-project scenario tests\n- Test error cases thoroughly\n- Validate type constraints\n- Mock filesystem operations appropriately\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Acknowledgments\n\nThis project implements the memory bank concept originally documented in the [Cline Memory Bank](https://github.com/nickbaumann98/cline_docs/blob/main/prompting/custom%20instructions%20library/cline-memory-bank.md), extending it with remote capabilities and multi-project support.\n",
      "npm_url": "https://www.npmjs.com/package/memory-bank-mcp",
      "npm_downloads": 3190,
      "keywords": [
        "memory",
        "mcp",
        "projects",
        "memory bank",
        "memory banks",
        "memory management"
      ],
      "category": "memory-management"
    },
    "Guanxinyuan--neo4j": {
      "owner": "Guanxinyuan",
      "name": "neo4j",
      "url": "https://github.com/Guanxinyuan/neo4j",
      "imageUrl": "/freedevtools/mcp/pfp/Guanxinyuan.webp",
      "description": "Leverage natural language to interact with Neo4j databases and manage knowledge graphs effortlessly. Transform natural language queries into Cypher commands and store knowledge graph memory in Neo4j or a file.",
      "stars": 2,
      "forks": 0,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-05-25T06:03:34Z",
      "readme_content": "# Neo4j MCP Clients & Servers\n\nModel Context Protocol (MCP) is a [standardized protocol](https://modelcontextprotocol.io/introduction) for managing context between large language models (LLMs) and external systems. \n\nThis lets you use Claude Desktop, or any MCP Client, to use natural language to accomplish things with Neo4j and your Aura account, e.g.:\n\n* `What is in this graph?`\n\n## Servers\n\n### `mcp-neo4j-cypher` - natural language to Cypher queries\n\n### `mcp-neo4j-memory` - knowledge graph memory stored in Neo4j\n\n### `mcp-json-memory` - knowledge graph memory stored in a file\n\nA reference server for modeling memory as a knowledge graph.\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n",
      "npm_url": "https://www.npmjs.com/package/neo4j",
      "npm_downloads": 30690,
      "keywords": [
        "neo4j",
        "cypher",
        "databases",
        "memory neo4j",
        "neo4j databases",
        "interact neo4j"
      ],
      "category": "memory-management"
    },
    "Heht571--ops-mcp-server": {
      "owner": "Heht571",
      "name": "ops-mcp-server",
      "url": "https://github.com/Heht571/ops-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/Heht571.webp",
      "description": "A server toolset for monitoring and managing remote servers, providing functionalities for system checks, service status updates, network diagnostics, and security audits. It includes features for memory information retrieval, system load monitoring, and process management.",
      "stars": 38,
      "forks": 13,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-03T10:03:18Z",
      "readme_content": "---\n\n# ops-mcp-server\n\n[![中文](https://img.shields.io/badge/Language-中文-blue.svg)](README_zh.md)\n\n`ops-mcp-server`: an AI-driven IT operations platform that fuses LLMs and MCP architecture to enable intelligent monitoring, anomaly detection, and natural human-infrastructure interaction with enterprise-grade security and scalability.\n\n---\n\n## 📖 Table of Contents\n\n- [Project Overview](#project-overview)\n- [Key Features](#key-features)\n- [Demo Videos](#demo-videos)\n- [Installation](#installation)\n- [Deployment](#deployment)\n- [Local MCP Server Configuration](#local-mcp-server-configuration)\n- [Interactive Client Usage](#interactive-client-usage)\n- [License](#license)\n- [Notes](#notes)\n\n---\n\n## 🚀 Project Overview\n\n`ops-mcp-server` is an IT operations management solution for the AI era. It achieves intelligent IT operations through the seamless integration of the Model Context Protocol (MCP) and Large Language Models (LLMs). By leveraging the power of LLMs and MCP's distributed architecture, it transforms traditional IT operations into an AI-driven experience, enabling automated server monitoring, intelligent anomaly detection, and context-aware troubleshooting. The system acts as a bridge between human operators and complex IT infrastructure, providing natural language interaction for tasks ranging from routine maintenance to complex problem diagnosis, while maintaining enterprise-grade security and scalability.\n\n---\n\n## 🌟 Key Features\n\n### 🖥️ Server Monitoring\n\n- Real-time CPU, memory, disk inspections.\n- System load and process monitoring.\n- Service and network interface checks.\n- Log analysis and configuration backup.\n- Security vulnerability scans (SSH login, firewall status).\n- Detailed OS information retrieval.\n\n### 📦 Container Management (Docker)\n\n- Container, image, and volume management.\n- Container resource usage monitoring.\n- Log retrieval and health checks.\n\n### 🌐 Network Device Management\n\n- Multi-vendor support (Cisco, Huawei, H3C).\n- Switch port, VLAN, and router route checks.\n- ACL security configuration analysis.\n- Optical module and device performance monitoring.\n\n### ➕ Additional Capabilities\n\n- Extensible plugin architecture.\n- Batch operations across multiple devices.\n- Tool listing and descriptive commands.\n\n---\n\n## 🎬 Demo Videos\n\n### 📌 Project Demo\n\n_On Cherry Studio_\n\n\n\n### 📌 Interactive Client Demo\n\n_On Terminal_\n\n\n\n---\n\n## ⚙️ Installation\n\nEnsure you have **Python 3.10+** installed. This project uses [`uv`](https://github.com/astral-sh/uv) for dependency and environment management.\n\n### 1. Install UV\n\n```bash\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n```\n\n### 2. Set Up Virtual Environment\n\n```bash\nuv venv .venv\n\n# Activate the environment\nsource .venv/bin/activate      # Linux/macOS\n.\\.venv\\Scripts\\activate       # Windows\n```\n\n### 3. Install Dependencies\n\n```bash\nuv pip install -r requirements.txt\n```\n\n> Dependencies are managed via `pyproject.toml`.\n\n---\n\n## 🚧 Deployment\n\n### 📡 SSE Remote Deployment (UV)\n\n```bash\ncd server_monitor_sse\n\n# Install dependencies\npip install -r requirements.txt\n\n# Start service\ncd ..\nuv run server_monitor_sse --transport sse --port 8000\n```\n\n### 🐳 SSE Remote Deployment (Docker Compose)\n\nEnsure Docker and Docker Compose are installed.\n\n```bash\ncd server_monitor_sse\ndocker compose up -d\n\n# Check status\ndocker compose ps\n\n# Logs monitoring\ndocker compose logs -f\n```\n\n---\n\n## 🛠️ Local MCP Server Configuration (Stdio)\n\nAdd this configuration to your MCP settings:\n\n```json\n{\n  \"ops-mcp-server\": {\n    \"command\": \"uv\",\n    \"args\": [\n      \"--directory\", \"YOUR_PROJECT_PATH_HERE\",\n      \"run\", \"server_monitor.py\"\n    ],\n    \"env\": {},\n    \"disabled\": true,\n    \"autoApprove\": [\"list_available_tools\"]\n  },\n  \"network_tools\": {\n    \"command\": \"uv\",\n    \"args\": [\n      \"--directory\", \"YOUR_PROJECT_PATH_HERE\",\n      \"run\", \"network_tools.py\"\n    ],\n    \"env\": {},\n    \"disabled\": false,\n    \"autoApprove\": []\n  },\n}\n```\n\n> **Note**: Replace `YOUR_PROJECT_PATH_HERE` with your project's actual path.\n\n---\n\n## 💬 Interactive Client Usage\n\nAn interactive client (`client.py`) allows you to interact with MCP services using natural language.\n\n### 1. Install Client Dependencies\n\n```bash\nuv pip install openai rich\n```\n\n### 2. Configure Client\n\nEdit these configurations within `client.py`:\n\n```python\n# Initialize OpenAI client\nself.client = AsyncOpenAI(\n    base_url=\"https://your-api-endpoint\",\n    api_key=\"YOUR_API_KEY\"\n)\n\n# Set model\nself.model = \"your-preferred-model\"\n```\n\n### 3. Run the Client\n\n```bash\nuv run client.py [path/to/server.py]\n```\n\nExample:\n\n```bash\nuv run client.py ./server_monitor.py\n```\n\n### Client Commands\n\n- `help` - Display help.\n- `quit` - Exit client.\n- `clear` - Clear conversation history.\n- `model <name>` - Switch models.\n\n---\n\n## 📄 License\n\nThis project is licensed under the [MIT License](LICENSE).\n\n---\n\n## 📌 Notes\n\n- Ensure remote SSH access is properly configured.\n- Adjust tool parameters based on actual deployment conditions.\n- This project is under active development; feedback and contributions are welcome.\n\n---",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "servers",
        "server",
        "monitoring",
        "server toolset",
        "mcp server",
        "memory management"
      ],
      "category": "memory-management"
    },
    "IzumiSy--mcp-duckdb-memory-server": {
      "owner": "IzumiSy",
      "name": "mcp-duckdb-memory-server",
      "url": "https://github.com/IzumiSy/mcp-duckdb-memory-server",
      "imageUrl": "/freedevtools/mcp/pfp/IzumiSy.webp",
      "description": "Enhance conversational agents by providing a memory system that retrieves and updates user information using DuckDB for efficient querying of knowledge graphs. Maintain context regarding user preferences and relationships over interactions.",
      "stars": 46,
      "forks": 10,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-26T15:58:49Z",
      "readme_content": "# MCP DuckDB Knowledge Graph Memory Server\n\n[](https://github.com/izumisy/mcp-duckdb-memory-server/actions/workflows/test.yml)\n[![smithery badge](https://smithery.ai/badge/@IzumiSy/mcp-duckdb-memory-server)](https://smithery.ai/server/@IzumiSy/mcp-duckdb-memory-server)\n![NPM Version](https://img.shields.io/npm/v/%40izumisy%2Fmcp-duckdb-memory-server)\n![NPM License](https://img.shields.io/npm/l/%40izumisy%2Fmcp-duckdb-memory-server)\n\nA forked version of [the official Knowledge Graph Memory Server](https://github.com/modelcontextprotocol/servers/tree/main/src/memory).\n\n<a href=\"https://glama.ai/mcp/servers/4mqwh1toao\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/4mqwh1toao/badge\" alt=\"DuckDB Knowledge Graph Memory Server MCP server\" />\n</a>\n\n## Installation\n\n### Installing via Smithery\n\nTo install DuckDB Knowledge Graph Memory Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@IzumiSy/mcp-duckdb-memory-server):\n\n```bash\nnpx -y @smithery/cli install @IzumiSy/mcp-duckdb-memory-server --client claude\n```\n\n### Manual install\n\nOtherwise, add `@IzumiSy/mcp-duckdb-memory-server` in your `claude_desktop_config.json` manually (`MEMORY_FILE_PATH` is optional)\n\n```bash\n{\n  \"mcpServers\": {\n    \"graph-memory\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@izumisy/mcp-duckdb-memory-server\"\n      ],\n      \"env\": {\n        \"MEMORY_FILE_PATH\": \"/path/to/your/memory.data\"\n      }\n    }\n  }\n}\n```\n\nThe data stored on that path is a DuckDB database file.\n\n### Docker\n\nBuild\n\n```bash\ndocker build -t mcp-duckdb-graph-memory .\n```\n\nRun\n\n```bash\ndocker run -dit mcp-duckdb-graph-memory\n```\n\n## Usage\n\nUse the example instruction below\n\n```\nFollow these steps for each interaction:\n\n1. User Identification:\n   - You should assume that you are interacting with default_user\n   - If you have not identified default_user, proactively try to do so.\n\n2. Memory Retrieval:\n   - Always begin your chat by saying only \"Remembering...\" and search relevant information from your knowledge graph\n   - Create a search query from user words, and search things from \"memory\". If nothing matches, try to break down words in the query at first (\"A B\" to \"A\" and \"B\" for example).\n   - Always refer to your knowledge graph as your \"memory\"\n\n3. Memory\n   - While conversing with the user, be attentive to any new information that falls into these categories:\n     a) Basic Identity (age, gender, location, job title, education level, etc.)\n     b) Behaviors (interests, habits, etc.)\n     c) Preferences (communication style, preferred language, etc.)\n     d) Goals (goals, targets, aspirations, etc.)\n     e) Relationships (personal and professional relationships up to 3 degrees of separation)\n\n4. Memory Update:\n   - If any new information was gathered during the interaction, update your memory as follows:\n     a) Create entities for recurring organizations, people, and significant events\n     b) Connect them to the current entities using relations\n     b) Store facts about them as observations\n```\n\n## Motivation\n\nThis project enhances the original MCP Knowledge Graph Memory Server by replacing its backend with DuckDB.\n\n### Why DuckDB?\n\nThe original MCP Knowledge Graph Memory Server used a JSON file as its data store and performed in-memory searches. While this approach works well for small datasets, it presents several challenges:\n\n1. **Performance**: In-memory search performance degrades as the dataset grows\n2. **Scalability**: Memory usage increases significantly when handling large numbers of entities and relations\n3. **Query Flexibility**: Complex queries and conditional searches are difficult to implement\n4. **Data Integrity**: Ensuring atomicity for transactions and CRUD operations is challenging\n\nDuckDB was chosen to address these challenges:\n\n- **Fast Query Processing**: DuckDB is optimized for analytical queries and performs well even with large datasets\n- **SQL Interface**: Standard SQL can be used to execute complex queries easily\n- **Transaction Support**: Supports transaction processing to maintain data integrity\n- **Indexing Capabilities**: Allows creation of indexes to improve search performance\n- **Embedded Database**: Works within the application without requiring an external database server\n\n## Implementation Details\n\nThis implementation uses DuckDB as the backend storage system, focusing on two key aspects:\n\n### Database Structure\n\nThe knowledge graph is stored in a relational database structure as shown below:\n\n```mermaid\nerDiagram\n    ENTITIES {\n        string name PK\n        string entityType\n    }\n    OBSERVATIONS {\n        string entityName FK\n        string content\n    }\n    RELATIONS {\n        string from_entity FK\n        string to_entity FK\n        string relationType\n    }\n\n    ENTITIES ||--o{ OBSERVATIONS : \"has\"\n    ENTITIES ||--o{ RELATIONS : \"from\"\n    ENTITIES ||--o{ RELATIONS : \"to\"\n```\n\nThis schema design allows for efficient storage and retrieval of knowledge graph components while maintaining the relationships between entities, observations, and relations.\n\n### Fuzzy Search Implementation\n\nThe implementation combines SQL queries with Fuse.js for flexible entity searching:\n\n- DuckDB SQL queries retrieve the base data from the database\n- Fuse.js provides fuzzy matching capabilities on top of the retrieved data\n- This hybrid approach allows for both structured queries and flexible text matching\n- Search results include both exact and partial matches, ranked by relevance\n\n## Development\n\n### Setup\n\n```bash\npnpm install\n```\n\n### Testing\n\n```bash\npnpm test\n```\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.",
      "npm_url": "https://www.npmjs.com/package/@izumisy/mcp-duckdb-memory-server",
      "npm_downloads": 1198,
      "keywords": [
        "duckdb",
        "memory",
        "conversational",
        "duckdb memory",
        "duckdb efficient",
        "conversational agents"
      ],
      "category": "memory-management"
    },
    "Jktfe--myAImemory-mcp": {
      "owner": "Jktfe",
      "name": "myAImemory-mcp",
      "url": "https://github.com/Jktfe/myAImemory-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/Jktfe.webp",
      "description": "Synchronizes preferences, personal details, and code standards across all Claude interfaces, ensuring consistent updates without manual input. Utilizes a caching system for faster memory-related queries.",
      "stars": 9,
      "forks": 1,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-08-15T07:42:52Z",
      "readme_content": "# myAI Memory Sync\n\n[![smithery badge](https://smithery.ai/badge/@Jktfe/myaimemory-mcp)](https://smithery.ai/server/@Jktfe/myaimemory-mcp)\n\n**Tired of repeating yourself to Claude every time you start a new chat?** myAI Memory Sync is a game-changing MCP tool that seamlessly synchronizes your preferences, personal details, and code standards across ALL your Claude interfaces! Just update once, and your changes instantly appear everywhere - from Claude Desktop to Claude Code, Windsurf, and Claude.ai web. With our cutting-edge caching system, memory-related queries are up to 2000x faster! Stop wasting tokens on repetitive instructions and enjoy a truly personalized AI experience.\n\n## How myAImemory-mcp Compares to Other Memory Tools\n\nWhile several excellent memory tools exist for AI systems, myAImemory-mcp serves a specific purpose as a Model Context Protocol (MCP) tool:\n\n| Tool | Primary Focus | Privacy Model | Integration | Unique Strength |\n|------|--------------|--------------|------------|----------------|\n| **myAImemory-mcp** | User preferences across Claude interfaces | Local-first, no data sent to external servers | Claude-specific MCP | Cross-platform synchronization with high-performance caching |\n| Graphiti | Temporal knowledge graphs | Database-dependent | General agent framework | Temporal awareness in knowledge representation |\n| Letta/MemGPT | Stateful agent framework | Server-based | Multi-model support | Complete agent architecture |\n| Mem0 | Personalized AI interactions | API-based | Multi-platform | Multi-level memory hierarchy |\n| Memary | Human-like memory for agents | Graph database | Agent-focused | Human memory emulation |\n| Cognee | Reliable memory for AI apps | Multiple storage options | Data pipeline focused | Extensive data source integration |\n\n**Key Advantages of myAImemory-mcp:**\n- **Privacy-First**: All data remains on your device, no personal information sent to external servers\n- **Performance**: Leverages Claude's caching capabilities for dramatic speed improvements\n- **Simplicity**: Natural language updates to your preferences across all Claude interfaces\n- **MCP Integration**: Purpose-built as a Claude MCP for seamless integration\n\n## 🚀 Quick Start\n\n```bash\n# Clone repository\ngit clone https://github.com/Jktfe/myaimemory-mcp.git\ncd myaimemory-mcp\n\n# Install dependencies\nnpm install\n\n# Build TypeScript code\nnpm run build\n\n# Start MCP server (with stdio transport)\nnpm start\n\n# Or start with HTTP transport\nnpm run start:http\n```\n\n### 🧠 Server Options\n\nThe unified server script supports multiple options:\n\n```bash\n# Start with stdio transport (default)\n./start-server.sh\n\n# Start with HTTP transport\n./start-server.sh --http\n\n# Start with HTTP transport on custom port\n./start-server.sh --http --port=8080\n\n# Start with direct implementation (no SDK)\n./start-server.sh --direct\n\n# Start with direct implementation and HTTP transport\n./start-server.sh --direct --http\n\n# Enable debug mode\n./start-server.sh --debug\n```\n\n### 🔄 Direct Sync Method (Simple Alternative)\n\nFor a simpler approach that doesn't require running an MCP server, you can use the unified CLI:\n\n```bash\n# One-time sync of all memory files\nnpm run sync\n\n# Or for emergency sync (fixes permissions)\nnpm run sync:emergency\n```\n\nThis script will:\n- Read from your \"myAI Master.md\" file\n- Update all CLAUDE.md files in your projects\n- Update your Windsurf memory settings\n- All without storing sensitive information in the git repository\n\n### 🔒 Privacy and Security\n\n- The \"myAI Master.md\" file with your personal information is excluded from git tracking\n- All CLAUDE.md files are also excluded to protect your privacy\n- Use the included `.gitignore` to ensure sensitive files remain private\n\n### 🗣️ Supported Natural Language Commands\n\nYou can interact with myAI Memory using these natural language patterns:\n\n| Command Pattern | Example | Purpose |\n|----------------|---------|---------|\n| `Use myAI Memory to remember [information]` | \"Use myAI Memory to remember I prefer TypeScript over JavaScript\" | Adds information to the appropriate section based on content |\n| `Remember that [information]` | \"Remember that I live in London\" | Shorter alternative to add information to memory |\n| `Add to my memory that [information]` | \"Add to my memory that I have two cars\" | Another way to add information to memory |\n| `Use myAI Memory to add to [section] [information]` | \"Use myAI Memory to add to Coding Preferences I prefer dark mode\" | Add information to a specific section |\n| `Update my [section] to include that [information]` | \"Update my User Information to include that my birthday is March 29\" | Update a specific section with new information |\n\nNote: To perform a full sync across all platforms, use the command line: `node sync-memory.js`\n\n```\nYou: Use myAI Memory to remember I prefer TypeScript over JavaScript\nClaude: ✅ Added to your Coding Preferences! I'll remember you prefer TypeScript over JavaScript.\n```\n\n## 📋 Installation Options\n\n### Option 1: Direct Install (Recommended)\n\nInstall from npm:\n\n```bash\nnpm install -g myai-memory-sync\n```\n\nStart the server:\n\n```bash\n# Start with stdio transport (default)\nmyai\n\n# Start with HTTP transport\nmyai server --transport http\n\n# Process memory commands\nmyai remember \"I prefer dark mode\"\n\n# Sync across platforms\nmyai sync\n```\n\n### Option 2: Run from Source\n\nClone and build from source:\n\n```bash\ngit clone https://github.com/Jktfe/myaimemory-mcp.git\ncd myaimemory-mcp\nnpm install\nnpm run build\nnpm start  # Start with stdio transport\n# or\nnpm run start:http  # Start with HTTP transport\n```\n\n### Option 3: Docker\n\nBuild and run with Docker:\n\n```bash\ndocker build -t myai-memory-sync .\ndocker run -v myai-memory:/app/data -p 3000:3000 myai-memory-sync\n```\n\n## 🔌 MCP Configuration\n\n### Claude Desktop Configuration\n\nAdd this to your `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"myai-memory-sync\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"myai\"\n      ],\n      \"env\": {\n        \"TEMPLATE_PATH\": \"/path/to/custom/template.md\",\n        \"ENABLE_ANTHROPIC\": \"true\",\n        \"ANTHROPIC_API_KEY\": \"your-api-key-here\"\n      }\n    }\n  }\n}\n```\n\n### Claude.ai with Smithery\n\n1. Visit [Smithery.ai](https://smithery.ai)\n2. Add the myAI Memory Sync MCP:\n   ```\n   @Jktfe/myaimemory-mcp\n   ```\n3. Configure with your API key in the Smithery settings\n\n### Windsurf Integration\n\nIn Windsurf, add to your `.codeium/config.json`:\n\n```json\n{\n  \"mcp\": {\n    \"servers\": {\n      \"myai-memory-sync\": {\n        \"command\": \"npx\",\n        \"args\": [\n          \"-y\",\n          \"myai\"\n        ]\n      }\n    }\n  }\n}\n```\n\n### HTTP Server Mode\n\nFor HTTP transport instead of stdio:\n\n```bash\n# Using npm scripts:\nnpm run start:http\n\n# Using the unified CLI:\nmyai server --transport http\n\n# Using the shell script with custom port:\n./start-server.sh --http --port=8080\n\n# Using environment variable:\nPORT=8080 npm run start:http\n```\n\n### Environment Variables\n\nCreate a `.env` file with the following options:\n```\n# Basic configuration\nDEBUG=true                      # Enable debug logging\nTEMPLATE_PATH=./data/template.md  # Custom template location\nPORT=3000                       # Port for HTTP transport (default: 3000)\nUSE_DIRECT=true                 # Use direct implementation (no SDK)\n\n# Platform-specific paths\nWINDSURF_MEMORY_PATH=~/.codeium/windsurf/memories/global_rules.md\nCLAUDE_PROJECTS_PATH=~/CascadeProjects\n\n# Performance optimization\nENABLE_ANTHROPIC=true           # Enable Anthropic API integration\nANTHROPIC_API_KEY=your-api-key  # Your Anthropic API key\nENABLE_PROMPT_CACHE=true        # Enable prompt caching system\nCACHE_TTL=300000                # Cache TTL in milliseconds (5 minutes)\n\n# Claude web sync (optional)\nCLAUDE_WEB_SYNC_ENABLED=false   # Enable Claude.ai web synchronization\nCLAUDE_WEB_EMAIL=you@email.com  # Your Claude.ai email\nCLAUDE_WEB_HEADLESS=true        # Run browser in headless mode\n```\n\n## 🧙‍♂️ System Prompt Integration\n\nFor best results, add this to your Claude system prompt:\n\n```\nMemory Integration Instructions:\nWhen you receive a command that starts with \"use myAI Memory to\", you should:\n\n1. Process the rest of the instruction as a memory management command\n2. Try to determine the appropriate section to update based on the content\n3. Use the myAI Memory Sync MCP to update your memory\n4. Confirm the update with a brief acknowledgment\n\nFor example:\n\"use myAI Memory to remember I prefer dark mode\" \n→ Update the preferences section with dark mode preference\n\nWhen asked questions about preferences or personal information, first check your memory via the myAI Memory Sync MCP. Always reference information from memory rather than making assumptions.\n```\n\n## ✨ Features\n\n- 🔄 **Cross-Platform Synchronization**: Update once, syncs everywhere\n- ⚡ **Lightning-Fast Recall**: Caching system with up to 2000x performance boost\n- 🗣️ **Natural Language Interface**: Just talk naturally to update your preferences\n- 🧩 **Multiple Persona Profiles**: Switch between different presets with ease\n- 🔐 **Security-Focused**: Local storage with .gitignore protection\n- 🛠️ **Developer-Friendly**: Full TypeScript implementation with comprehensive API\n\n## 🧩 Core Architecture\n\nmyAI Memory Sync uses a modular architecture with these key components:\n\n- **Template Parser**: Bidirectional conversion between structured memory objects and markdown\n- **Template Storage**: Persistent storage with in-memory and file-system caching\n- **Platform Synchronizers**: Implements the `PlatformSyncer` interface for each target platform\n- **Natural Language Processor**: Extracts structured data from natural language memory commands\n- **Memory Cache Service**: Optimizes performance with multi-level caching strategies\n\n## 🔍 Detailed Features\n\n### Cross-Platform Synchronization\n- **ClaudeCodeSyncer**: Updates CLAUDE.md files across all repositories\n- **WindsurfSyncer**: Manages global_rules.md in Windsurf environment\n- **ClaudeWebSyncer**: Optional Puppeteer-based synchronization with Claude.ai web interface\n\n### Intelligent Memory Management\n- **Pattern-Based Extraction**: Converts natural language to structured key-value pairs\n- **Section Detection Algorithm**: Automatically determines appropriate section for new memories\n- **Memory Template Format**: Markdown-based structure with sections, descriptions, and key-value items\n- **Context Preservation**: Updates memory sections while preserving other template content\n\n### Performance Optimization\n- **Multi-Level Caching**: In-memory caching at both template and section levels\n- **TTL-Based Cache Management**: Configurable Time-To-Live for cached content\n- **Pre-Warming**: Cache pre-population after template updates\n- **Optional Anthropic API Integration**: Accelerates memory-related queries up to 2000x\n\n### Security\n- **Local-First Architecture**: All data remains on your device\n- **Gitignore Management**: Automatically adds CLAUDE.md to .gitignore in all repositories\n- **File Permission Handling**: Fixes permissions issues for maximum compatibility\n- **Encrypted Storage**: Compatible with encrypted file systems\n\n## 📋 Memory Template Format\n\nThe system uses a structured markdown format to organize your preferences:\n\n```markdown\n# myAI Memory\n\n# User Information\n## Use this information if you need to reference them directly\n-~- Name: Your Name\n-~- Location: Your Location\n-~- Likes: Reading, Hiking, Technology\n\n# General Response Style\n## Use this in every response\n-~- Style: Friendly and concise\n-~- Use UK English Spellings: true\n-~- Include emojis when appropriate: true\n\n# Coding Preferences\n## General Preference when responding to coding questions\n-~- I prefer TypeScript over JavaScript\n-~- Show step-by-step explanations\n```\n\n## 🛠️ Technical Implementation\n\n### MemoryTemplate Schema\n```typescript\ninterface MemoryTemplate {\n  sections: TemplateSection[];\n}\n\ninterface TemplateSection {\n  title: string;\n  description: string;\n  items: TemplateItem[];\n}\n\ninterface TemplateItem {\n  key: string;\n  value: string;\n}\n```\n\n### Platform Synchronization Interface\n```typescript\ninterface PlatformSyncer {\n  sync(templateContent: string): Promise<SyncStatus>;\n}\n\ntype PlatformType = 'claude-web' | 'claude-code' | 'windsurf' | 'master';\n\ninterface SyncStatus {\n  platform: PlatformType;\n  success: boolean;\n  message: string;\n}\n```\n\n## 🔌 MCP Integration API\n\nThe myAI Memory Sync tool implements the Model Context Protocol (MCP) with the following functions:\n\n| Function | Description | Parameters |\n|----------|-------------|------------|\n| `get_template` | Retrieves the full memory template | None |\n| `get_section` | Retrieves a specific section | `sectionName: string` |\n| `update_section` | Updates a specific section | `sectionName: string, content: string` |\n| `update_template` | Replaces the entire template | `content: string` |\n| `list_presets` | Lists available presets | None |\n| `load_preset` | Loads a specific preset | `presetName: string` |\n| `create_preset` | Creates a new preset | `presetName: string` |\n| `sync_platforms` | Synchronizes across platforms | `platform?: string` |\n| `list_platforms` | Lists available platforms | None |\n\n### Natural Language Interface\n\nUsers can interact with the system through natural language commands:\n\n```\nYou: Use myAI Memory to remember I prefer TypeScript over JavaScript\nClaude: ✅ Added to your Coding Preferences! I'll remember you prefer TypeScript over JavaScript.\n\nYou: Use myAI Memory to load preset developer\nClaude: ✅ Loaded developer preset! I'll now use your developer preferences.\n```\n\n## 🧙‍♂️ Advanced Usage\n\n### Memory Presets\n\nSwitch between different personas easily:\n\n```\nYou: Use myAI Memory to list presets\nClaude: Available presets: personal, work, developer\n\nYou: Use myAI Memory to load preset developer\nClaude: ✅ Loaded developer preset!\n```\n\n### Emergency Sync\n\nWhen you need to fix synchronization issues across all platforms:\n\n```bash\n# Sync everything immediately\n./emergency-sync.sh\n```\n\n### Command Line Interface\n\n```bash\n# View all available commands\nnode dist/cli.js --help\n\n# Process memory commands directly\nnode dist/cli.js --remember \"remember I prefer dark mode\"\n\n# Start HTTP server for SSE transport\nnpm run start:http\n\n# Start stdio server for MCP transport\nnpm run start\n```\n\n### Development Workflow\n\n```bash\n# Run in development mode with auto-reload\nnpm run dev\n\n# Run in development mode with HTTP server\nnpm run dev:http\n\n# Watch TypeScript compilation\nnpm run build:watch\n\n# Run tests\nnpm test\n\n# Run specific test\nnpm test -- -t \"platformSync\"\n\n# Lint code\nnpm run lint\n\n# Type check without emitting files\nnpm run typecheck\n```\n\n## ⚡ Performance Benchmarks\n\nOur caching system delivers incredible performance improvements:\n\n| Operation | Without Cache | With Cache | Improvement |\n|-----------|---------------|------------|-------------|\n| Memory Query | ~2000ms | ~1ms | 2000x |\n| Section Lookup | ~1600ms | ~0.8ms | 2000x |\n| Template Parse | ~120ms | ~0.1ms | 1200x |\n| Platform Sync | ~850ms | ~350ms | 2.4x |\n\n\n\n## 🔒 Security & Privacy\n\nWe take your privacy seriously:\n\n- All data remains locally on your device\n- CLAUDE.md files are automatically added to .gitignore\n- No data is sent to external servers (except when using the optional Anthropic API integration)\n- Works with encrypted file systems for maximum security\n\n## 🛠️ Troubleshooting\n\n### Common Issues\n\n1. **CLAUDE.md Not Updating**\n   - Check file permissions with `ls -la CLAUDE.md`\n   - Try emergency sync with `./emergency-sync.sh`\n   - Verify platform paths in your `.env` file\n\n2. **MCP Connection Failures**\n   - Ensure MCP server is running with `ps aux | grep myai-memory`\n   - Check Claude Desktop logs for MCP errors\n   - Verify your Claude Desktop configuration file\n\n3. **Caching Issues**\n   - Clear cache with `node dist/cli.js --clear-cache`\n   - Verify Anthropic API key is correctly set\n   - Check memory file integrity with `node dist/cli.js --validate`\n\n4. **Natural Language Commands Not Working**\n   - Make sure to use exactly one of the supported command patterns (see Supported Natural Language Commands section)\n   - If Claude doesn't recognize your command, try a different pattern\n   - For syncing across all platforms, use the direct script: `node sync-memory.js`\n\n### Manual Syncing\n\nIf you're experiencing issues with natural language commands or the MCP server:\n\n```bash\n# Direct sync approach (most reliable)\ncd /path/to/myAImemory\nnode sync-memory.js\n\n# Alternative emergency sync (if permissions need fixing)\ncd /path/to/myAImemory\n./safe-memory.sh sync\n```\n\nThese methods directly read from your master file and update all platforms without relying on the MCP server or natural language processing.\n\n### Logs and Debugging\n\nEnable debug mode to see detailed logs:\n\n```bash\nDEBUG=true npm run start\n```\n\nLog files are stored in:\n- Linux/macOS: `~/.local/share/myai-memory/logs/`\n- Windows: `%APPDATA%\\myai-memory\\logs\\`\n\n## 🤝 Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n1. Fork the repository\n2. Create your feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add some amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n\nWe follow a standard Git workflow and CI process:\n\n- All PRs require passing tests and linting\n- New features should include tests\n- Major changes should update documentation\n- Follow existing code style and patterns\n\n## 📚 Documentation\n\nFor more detailed documentation, see the [Wiki](https://github.com/Jktfe/myaimemory-mcp/wiki).\n\nAPI documentation is available in the `/docs` directory:\n\n```bash\n# Generate API documentation\nnpm run docs\n```\n\n## 📄 License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## 📬 Contact\n\nProject Link: [https://github.com/Jktfe/myaimemory-mcp](https://github.com/Jktfe/myaimemory-mcp)\n\n---\n\n<p align=\"center\">\n  Made with ❤️ for the AI community\n</p>",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "jktfe",
        "caching",
        "memory",
        "jktfe myaimemory",
        "management jktfe",
        "memory management"
      ],
      "category": "memory-management"
    },
    "JovanHsu--mcp-neo4j-memory-server": {
      "owner": "JovanHsu",
      "name": "mcp-neo4j-memory-server",
      "url": "https://github.com/JovanHsu/mcp-neo4j-memory-server",
      "imageUrl": "/freedevtools/mcp/pfp/JovanHsu.webp",
      "description": "Store and retrieve information from AI interactions using a Neo4j backend, facilitating advanced graph querying and memory management. Enhances performance and scalability for complex knowledge graph applications.",
      "stars": 17,
      "forks": 6,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-28T12:23:10Z",
      "readme_content": "# MCP Neo4j Knowledge Graph Memory Server\n\n[![npm version](https://img.shields.io/npm/v/@izumisy/mcp-neo4j-memory-server.svg)](https://www.npmjs.com/package/@izumisy/mcp-neo4j-memory-server)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![TypeScript](https://img.shields.io/badge/TypeScript-5.7-blue)](https://www.typescriptlang.org/)\n[![Neo4j](https://img.shields.io/badge/Neo4j-5.x-brightgreen)](https://neo4j.com/)\n\n## 简介\n\nMCP Neo4j Knowledge Graph Memory Server是一个基于Neo4j图数据库的知识图谱记忆服务器，用于存储和检索AI助手与用户交互过程中的信息。该项目是[官方Knowledge Graph Memory Server](https://github.com/modelcontextprotocol/servers/tree/main/src/memory)的增强版本，使用Neo4j作为后端存储引擎。\n\n通过使用Neo4j作为存储后端，本项目提供了更强大的图查询能力、更好的性能和可扩展性，特别适合构建复杂的知识图谱应用。\n\n## 功能特点\n\n- 🚀 基于Neo4j的高性能图数据库存储\n- 🔍 强大的模糊搜索和精确匹配能力\n- 🔄 实体、关系和观察的完整CRUD操作\n- 🌐 与MCP协议完全兼容\n- 📊 支持复杂的图查询和遍历\n- 🐳 Docker支持，便于部署\n\n## 安装\n\n### 前提条件\n\n- Node.js >= 22.0.0\n- Neo4j数据库（本地或远程）\n\n### 通过npm安装\n\n```bash\n# 全局安装\nnpm install -g @jovanhsu/mcp-neo4j-memory-server\n\n# 或作为项目依赖安装\nnpm install @jovanhsu/mcp-neo4j-memory-server\n```\n\n### 使用Docker\n\n```bash\n# 使用docker-compose启动Neo4j和Memory Server\ngit clone https://github.com/JovanHsu/mcp-neo4j-memory-server.git\ncd mcp-neo4j-memory-server\ndocker-compose up -d\n```\n\n### 环境变量配置\n\n服务器使用以下环境变量进行配置：\n\n| 环境变量 | 描述 | 默认值 |\n|----------|------|--------|\n| NEO4J_URI | Neo4j数据库URI | bolt://localhost:7687 |\n| NEO4J_USER | Neo4j用户名 | neo4j |\n| NEO4J_PASSWORD | Neo4j密码 | password |\n| NEO4J_DATABASE | Neo4j数据库名称 | neo4j |\n\n## 与Claude集成\n\n### 在Claude Desktop中配置\n\n在`claude_desktop_config.json`中添加以下配置：\n\n```json\n{\n  \"mcpServers\": {\n    \"graph-memory\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@izumisy/mcp-neo4j-memory-server\"\n      ],\n      \"env\": {\n        \"NEO4J_URI\": \"neo4j://localhost:7687\",\n        \"NEO4J_USER\": \"neo4j\",\n        \"NEO4J_PASSWORD\": \"password\",\n        \"NEO4J_DATABASE\": \"memory\"\n      }\n    }\n  }\n}\n```\n\n### 在Claude Web中使用MCP Inspector\n\n1. 安装[MCP Inspector](https://github.com/modelcontextprotocol/inspector)\n2. 启动Neo4j Memory Server：\n   ```bash\n   npx @jovanhsu/mcp-neo4j-memory-server\n   ```\n3. 在另一个终端启动MCP Inspector：\n   ```bash\n   npx @modelcontextprotocol/inspector npx @jovanhsu/mcp-neo4j-memory-server\n   ```\n4. 在浏览器中访问MCP Inspector界面\n\n## 使用方法\n\n### Claude自定义指令\n\n在Claude的自定义指令中添加以下内容：\n\n```\nFollow these steps for each interaction:\n\n1. User Identification:\n   - You should assume that you are interacting with default_user\n   - If you have not identified default_user, proactively try to do so.\n\n2. Memory Retrieval:\n   - Always begin your chat by saying only \"Remembering...\" and search relevant information from your knowledge graph\n   - Create a search query from user words, and search things from \"memory\". If nothing matches, try to break down words in the query at first (\"A B\" to \"A\" and \"B\" for example).\n   - Always refer to your knowledge graph as your \"memory\"\n\n3. Memory\n   - While conversing with the user, be attentive to any new information that falls into these categories:\n     a) Basic Identity (age, gender, location, job title, education level, etc.)\n     b) Behaviors (interests, habits, etc.)\n     c) Preferences (communication style, preferred language, etc.)\n     d) Goals (goals, targets, aspirations, etc.)\n     e) Relationships (personal and professional relationships up to 3 degrees of separation)\n\n4. Memory Update:\n   - If any new information was gathered during the interaction, update your memory as follows:\n     a) Create entities for recurring organizations, people, and significant events\n     b) Connect them to the current entities using relations\n     b) Store facts about them as observations\n```\n\n### API示例\n\n如果您想在自己的应用程序中使用本服务器，可以通过MCP协议与其通信：\n\n```typescript\nimport { McpClient } from '@modelcontextprotocol/sdk/client/mcp.js';\nimport { StdioClientTransport } from '@modelcontextprotocol/sdk/client/stdio.js';\n\n// 创建客户端\nconst transport = new StdioClientTransport({\n  command: 'npx',\n  args: ['-y', '@izumisy/mcp-neo4j-memory-server'],\n  env: {\n    NEO4J_URI: 'bolt://localhost:7687',\n    NEO4J_USER: 'neo4j',\n    NEO4J_PASSWORD: 'password',\n    NEO4J_DATABASE: 'neo4j'\n  }\n});\n\nconst client = new McpClient();\nawait client.connect(transport);\n\n// 创建实体\nconst result = await client.callTool('create_entities', {\n  entities: [\n    {\n      name: '用户',\n      entityType: '人物',\n      observations: ['喜欢编程', '使用TypeScript']\n    }\n  ]\n});\n\nconsole.log(result);\n```\n\n## 为什么选择Neo4j？\n\n相比于原始版本使用的JSON文件存储和DuckDB版本，Neo4j提供了以下优势：\n\n1. **原生图数据库**：Neo4j是专为图数据设计的数据库，非常适合知识图谱的存储和查询\n2. **高性能查询**：使用Cypher查询语言可以高效地进行复杂的图遍历和模式匹配\n3. **关系优先**：Neo4j将关系作为一等公民，使得实体间的关系查询更加高效\n4. **可视化能力**：Neo4j提供了内置的可视化工具，方便调试和理解知识图谱\n5. **扩展性**：支持集群部署，可以处理大规模知识图谱\n\n## 实现细节\n\n### 数据模型\n\n知识图谱在Neo4j中的存储模型如下：\n\n```\n(Entity:EntityType {name: \"实体名称\"})\n(Entity)-[:HAS_OBSERVATION]->(Observation {content: \"观察内容\"})\n(Entity1)-[:RELATION_TYPE]->(Entity2)\n```\n\n### 模糊搜索实现\n\n本实现结合了Neo4j的全文搜索功能和Fuse.js进行灵活的实体搜索：\n\n- 使用Neo4j的全文索引进行初步搜索\n- Fuse.js提供额外的模糊匹配能力\n- 搜索结果包括精确和部分匹配，按相关性排序\n\n## 开发\n\n### 环境设置\n\n```bash\n# 克隆仓库\ngit clone https://github.com/JovanHsu/mcp-neo4j-memory-server.git\ncd mcp-neo4j-memory-server\n\n# 安装依赖\npnpm install\n\n# 构建项目\npnpm build\n\n# 开发模式（使用MCP Inspector）\npnpm dev\n```\n\n### 测试\n\n```bash\n# 运行测试\npnpm test\n```\n\n### 发布\n\n```bash\n# 准备发布\nnpm version [patch|minor|major]\n\n# 发布到NPM\nnpm publish\n```\n\n## 贡献指南\n\n欢迎贡献代码、报告问题或提出改进建议！请遵循以下步骤：\n\n1. Fork本仓库\n2. 创建您的特性分支 (`git checkout -b feature/amazing-feature`)\n3. 提交您的更改 (`git commit -m 'Add some amazing feature'`)\n4. 推送到分支 (`git push origin feature/amazing-feature`)\n5. 创建一个Pull Request\n\n## 相关项目\n\n- [Model Context Protocol](https://github.com/modelcontextprotocol/mcp)\n- [MCP Inspector](https://github.com/modelcontextprotocol/inspector)\n- [Claude Desktop](https://github.com/anthropics/claude-desktop)\n\n## 许可证\n\n本项目采用MIT许可证 - 详见[LICENSE](LICENSE)文件。\n\n## 联系方式\n\n- GitHub: [https://github.com/JovanHsu/mcp-neo4j-memory-server](https://github.com/JovanHsu/mcp-neo4j-memory-server)\n- NPM: [https://www.npmjs.com/package/@jovanhsu/mcp-neo4j-memory-server](https://www.npmjs.com/package/@jovanhsu/mcp-neo4j-memory-server)\n- 作者: JovanHsu",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "neo4j",
        "memory",
        "querying",
        "neo4j memory",
        "using neo4j",
        "neo4j backend"
      ],
      "category": "memory-management"
    },
    "Kirandawadi--volatility3-mcp": {
      "owner": "Kirandawadi",
      "name": "volatility3-mcp",
      "url": "https://github.com/Kirandawadi/volatility3-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/Kirandawadi.webp",
      "description": "Analyze memory dumps to detect malware and perform memory forensics using a natural language interface, making the process accessible to users without specialized knowledge.",
      "stars": 12,
      "forks": 1,
      "license": "No License",
      "language": "YARA",
      "updated_at": "2025-07-08T21:51:17Z",
      "readme_content": "# Volatility3 MCP Server\n\n## Introduction\nVolatility3 MCP Server is a powerful tool that connects MCP clients like Claude Desktop with Volatility3, the advanced memory forensics framework. This integration allows LLMs to analyze memory dumps, detect malware, and perform sophisticated memory forensics tasks through a simple, conversational interface.\n\n\n## Demo\n[Demo Video](https://1drv.ms/v/c/b3eb1096e4f4a3a8/EfKIAsM9zUpGtXjJMDn0zywB-R3UnwvYD4yX71q1CinfRw?e=lke0Ox)\n\nYou can also find a [detailed presentation](./attachments/project-presentation.pdf) on this tool here.\n\n## What This Solves\nMemory forensics is a complex field that typically requires specialized knowledge and command-line expertise. This project bridges that gap by:\n- Allowing non-experts to perform memory forensics through natural language\n- Enabling LLMs to directly analyze memory dumps and provide insights\n- Automating common forensic workflows that would normally require multiple manual steps\n- Making memory forensics more accessible and user-friendly\n\n## Features\n- **Memory Dump Analysis**: Analyze Windows and Linux memory dumps using various plugins\n- **Process Inspection**: List running processes, examine their details, and identify suspicious activity\n- **Network Analysis**: Examine network connections to detect command and control servers\n- **Cross-Platform Support**: Works with both Windows and Linux memory dumps (macOS support coming soon)\n- **Malware Detection**: Scan memory with **YARA rules** to identify known malware signatures\n\n## Configuration\n\n1. Clone this repository:\n2. Create a virtual environment:\n   ```bash\n   python -m venv environ\n   source environ/bin/activate\n   ```\n3. Install the required dependencies:\n   ```bash\n   pip install -r requirements.txt\n   ```\n\nYou can use this project in two ways:\n\n### Option 1: With Claude Desktop\n4. Configure Claude Desktop:\n   - Go to `Claude` -> `Settings` -> `Developer` -> `Edit Config` -> `claude_desktop_config.json` and add the following\n     ```json\n        {\n            \"mcpServers\": {\n            \"volatility3\": {\n                \"command\": \"absolute/path/to/virtual/environment/bin/python3\",\n                \"args\": [\n                \"absolute/path/to/bridge_mcp_volatility.py\"\n                ]\n            }\n            }\n        }\n     ```\n        \n5. Restart Claude Desktop and begin analyzing the memory dumps.\n\n### Option 2: With Cursor (SSE Server)\n4. Start the SSE server:\n   ```bash\n   python3 start_sse_server.py\n   ```\n4. Configure Cursor to use the SSE server:\n   - Open Cursor settings\n   - Navigate to `Features` -> `MCP Servers`\n   - Add a new MCP server with the URL `http://127.0.0.1:8080/sse`\n\n6. Use the Cursor Composer in agent mode and begin analyzing memory dumps.\n\n## Available Tools\n\n- **initialize_memory_file**: Set up a memory dump file for analysis\n- **detect_os**: Identify the operating system of the memory dump\n- **list_plugins**: Display all available Volatility3 plugins\n- **get_plugin_info**: Get detailed information about a specific plugin\n- **run_plugin**: Execute any Volatility3 plugin with custom arguments\n- **get_processes**: List all running processes in the memory dump\n- **get_network_connections**: View all network connections from the system\n- **list_process_open_handles**: Examine files and resources accessed by a process\n- **scan_with_yara**: Scan memory for malicious patterns using YARA rules\n\n## Contributing\nContributions are welcome! Please feel free to submit a Pull Request.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "malware",
        "memory",
        "dumps",
        "memory dumps",
        "analyze memory",
        "memory forensics"
      ],
      "category": "memory-management"
    },
    "Lyoneos--mcp-cheatengine-Cto": {
      "owner": "Lyoneos",
      "name": "mcp-cheatengine-Cto",
      "url": "https://github.com/Lyoneos/mcp-cheatengine-Cto",
      "imageUrl": "/freedevtools/mcp/pfp/null.webp",
      "description": "Connects to CheatEngine instances to perform memory operations, including reading memory and analyzing assembly code. Features a plugin architecture for extending functionalities within the toolkit.",
      "stars": 0,
      "forks": 0,
      "license": "Unknown",
      "language": "Unknown",
      "updated_at": "",
      "readme_content": "",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "cheatengine",
        "memory",
        "cto",
        "cheatengine cto",
        "cheatengine instances",
        "mcp cheatengine"
      ],
      "category": "memory-management"
    },
    "Srish-ty--MCP-Testing-interface-for-LLMs": {
      "owner": "Srish-ty",
      "name": "MCP-Testing-interface-for-LLMs",
      "url": "https://github.com/Srish-ty/MCP-Testing-interface-for-LLMs",
      "imageUrl": "/freedevtools/mcp/pfp/Srish-ty.webp",
      "description": "Manage user contexts for LLM interactions by storing and retrieving relevant prompts to ensure continuity in conversations. Provides a RESTful API for context management with support for in-memory storage and TypeScript integration.",
      "stars": 0,
      "forks": 1,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-03-30T07:38:26Z",
      "readme_content": "# Memory Context Provider (MCP) Server\n\nA server that manages context for LLM interactions, storing and providing relevant context for each user.\n\n## Features\n\n- In-memory storage of user contexts\n- Context management with last 5 prompts\n- RESTful API endpoints\n- TypeScript support\n\n## Setup\n\n1. Install dependencies:\n   ```bash\n   npm install\n   ```\n\n2. Start the development server:\n   ```bash\n   npm run dev\n   ```\n\n## API Endpoints\n\n### POST /context/:userId\nAdd a new prompt to user's context and get updated context.\n\nRequest body:\n```json\n{\n  \"prompt\": \"Your prompt here\"\n}\n```\n\nResponse:\n```json\n{\n  \"context\": \"Combined context from last 5 prompts\"\n}\n```\n\n### GET /context/:userId\nGet current context for a user.\n\nResponse:\n```json\n{\n  \"context\": \"Current context\"\n}\n```\n\n### DELETE /context/:userId\nClear context for a user.\n\nResponse:\n```json\n{\n  \"message\": \"Context cleared\"\n}\n```\n\n## Development\n\n- `npm run dev`: Start development server with hot reload\n- `npm run build`: Build TypeScript files\n- `npm start`: Run built files ",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "llm",
        "contexts",
        "contexts llm",
        "interface llms",
        "context management"
      ],
      "category": "memory-management"
    },
    "T1nker-1220--memories-with-lessons-mcp-server": {
      "owner": "T1nker-1220",
      "name": "memories-with-lessons-mcp-server",
      "url": "https://github.com/T1nker-1220/memories-with-lessons-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/T1nker-1220.webp",
      "description": "This server enables the implementation of persistent memory in AI models through a local knowledge graph, allowing for information retention across chats and an error-learning mechanism via a lesson system.",
      "stars": 53,
      "forks": 13,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-30T05:05:09Z",
      "readme_content": "# Knowledge Graph Memory Server\n[![smithery badge](https://smithery.ai/badge/@T1nker-1220/memories-with-lessons-mcp-server)](https://smithery.ai/server/@T1nker-1220/memories-with-lessons-mcp-server)\n\nA basic implementation of persistent memory using a local knowledge graph. This lets Claude remember information about the user across chats and learn from past errors through a lesson system.\n\n<a href=\"https://glama.ai/mcp/servers/eoinvr1bz0\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/eoinvr1bz0/badge\" alt=\"Knowledge Graph Memory Server MCP server\" /></a>\n\n## Core Concepts\n\n### Entities\nEntities are the primary nodes in the knowledge graph. Each entity has:\n- A unique name (identifier)\n- An entity type (e.g., \"person\", \"organization\", \"event\")\n- A list of observations\n\nExample:\n```json\n{\n  \"name\": \"John_Smith\",\n  \"entityType\": \"person\",\n  \"observations\": [\"Speaks fluent Spanish\"]\n}\n```\n\n### Relations\nRelations define directed connections between entities. They are always stored in active voice and describe how entities interact or relate to each other.\n\nExample:\n```json\n{\n  \"from\": \"John_Smith\",\n  \"to\": \"Anthropic\",\n  \"relationType\": \"works_at\"\n}\n```\n### Observations\nObservations are discrete pieces of information about an entity. They are:\n\n- Stored as strings\n- Attached to specific entities\n- Can be added or removed independently\n- Should be atomic (one fact per observation)\n\nExample:\n```json\n{\n  \"entityName\": \"John_Smith\",\n  \"observations\": [\n    \"Speaks fluent Spanish\",\n    \"Graduated in 2019\",\n    \"Prefers morning meetings\"\n  ]\n}\n```\n\n### Lessons\nLessons are special entities that capture knowledge about errors and their solutions. Each lesson has:\n- A unique name (identifier)\n- Error pattern information (type, message, context)\n- Solution steps and verification\n- Success rate tracking\n- Environmental context\n- Metadata (severity, timestamps, frequency)\n\nExample:\n```json\n{\n  \"name\": \"NPM_VERSION_MISMATCH_01\",\n  \"entityType\": \"lesson\",\n  \"observations\": [\n    \"Error occurs when using incompatible package versions\",\n    \"Affects Windows environments specifically\",\n    \"Resolution requires version pinning\"\n  ],\n  \"errorPattern\": {\n    \"type\": \"dependency\",\n    \"message\": \"Cannot find package @shadcn/ui\",\n    \"context\": \"package installation\"\n  },\n  \"metadata\": {\n    \"severity\": \"high\",\n    \"environment\": {\n      \"os\": \"windows\",\n      \"nodeVersion\": \"18.x\"\n    },\n    \"createdAt\": \"2025-02-13T13:21:58.523Z\",\n    \"updatedAt\": \"2025-02-13T13:22:21.336Z\",\n    \"frequency\": 1,\n    \"successRate\": 1.0\n  },\n  \"verificationSteps\": [\n    {\n      \"command\": \"pnpm add shadcn@latest\",\n      \"expectedOutput\": \"Successfully installed shadcn\",\n      \"successIndicators\": [\"added shadcn\"]\n    }\n  ]\n}\n```\n\n## API\n\n### Tools\n- **create_entities**\n  - Create multiple new entities in the knowledge graph\n  - Input: `entities` (array of objects)\n    - Each object contains:\n      - `name` (string): Entity identifier\n      - `entityType` (string): Type classification\n      - `observations` (string[]): Associated observations\n  - Ignores entities with existing names\n\n- **create_relations**\n  - Create multiple new relations between entities\n  - Input: `relations` (array of objects)\n    - Each object contains:\n      - `from` (string): Source entity name\n      - `to` (string): Target entity name\n      - `relationType` (string): Relationship type in active voice\n  - Skips duplicate relations\n\n- **add_observations**\n  - Add new observations to existing entities\n  - Input: `observations` (array of objects)\n    - Each object contains:\n      - `entityName` (string): Target entity\n      - `contents` (string[]): New observations to add\n  - Returns added observations per entity\n  - Fails if entity doesn't exist\n\n- **delete_entities**\n  - Remove entities and their relations\n  - Input: `entityNames` (string[])\n  - Cascading deletion of associated relations\n  - Silent operation if entity doesn't exist\n\n- **delete_observations**\n  - Remove specific observations from entities\n  - Input: `deletions` (array of objects)\n    - Each object contains:\n      - `entityName` (string): Target entity\n      - `observations` (string[]): Observations to remove\n  - Silent operation if observation doesn't exist\n\n- **delete_relations**\n  - Remove specific relations from the graph\n  - Input: `relations` (array of objects)\n    - Each object contains:\n      - `from` (string): Source entity name\n      - `to` (string): Target entity name\n      - `relationType` (string): Relationship type\n  - Silent operation if relation doesn't exist\n\n- **read_graph**\n  - Read the entire knowledge graph\n  - No input required\n  - Returns complete graph structure with all entities and relations\n\n- **search_nodes**\n  - Search for nodes based on query\n  - Input: `query` (string)\n  - Searches across:\n    - Entity names\n    - Entity types\n    - Observation content\n  - Returns matching entities and their relations\n\n- **open_nodes**\n  - Retrieve specific nodes by name\n  - Input: `names` (string[])\n  - Returns:\n    - Requested entities\n    - Relations between requested entities\n  - Silently skips non-existent nodes\n\n### Lesson Management Tools\n- **create_lesson**\n  - Create a new lesson from an error and its solution\n  - Input: `lesson` (object)\n    - Contains:\n      - `name` (string): Unique identifier\n      - `entityType` (string): Must be \"lesson\"\n      - `observations` (string[]): Notes about the error and solution\n      - `errorPattern` (object): Error details\n        - `type` (string): Category of error\n        - `message` (string): Error message\n        - `context` (string): Where error occurred\n        - `stackTrace` (string, optional): Stack trace\n      - `metadata` (object): Additional information\n        - `severity` (\"low\" | \"medium\" | \"high\" | \"critical\")\n        - `environment` (object): System details\n        - `frequency` (number): Times encountered\n        - `successRate` (number): Solution success rate\n      - `verificationSteps` (array): Solution verification\n        - Each step contains:\n          - `command` (string): Action to take\n          - `expectedOutput` (string): Expected result\n          - `successIndicators` (string[]): Success markers\n  - Automatically initializes metadata timestamps\n  - Validates all required fields\n\n- **find_similar_errors**\n  - Find similar errors and their solutions\n  - Input: `errorPattern` (object)\n    - Contains:\n      - `type` (string): Error category\n      - `message` (string): Error message\n      - `context` (string): Error context\n  - Returns matching lessons sorted by success rate\n  - Uses fuzzy matching for error messages\n\n- **update_lesson_success**\n  - Update success tracking for a lesson\n  - Input:\n    - `lessonName` (string): Lesson to update\n    - `success` (boolean): Whether solution worked\n  - Updates:\n    - Success rate (weighted average)\n    - Frequency counter\n    - Last update timestamp\n\n- **get_lesson_recommendations**\n  - Get relevant lessons for current context\n  - Input: `context` (string)\n  - Searches across:\n    - Error type\n    - Error message\n    - Error context\n    - Lesson observations\n  - Returns lessons sorted by:\n    - Context relevance\n    - Success rate\n  - Includes full solution details\n\n## File Management\nThe server now handles two types of files:\n- `memory.json`: Stores basic entities and relations\n- `lesson.json`: Stores lesson entities with error patterns\n\nFiles are automatically split if they exceed 1000 lines to maintain performance.\n\n## Cursor MCP Client Setup\n\nTo integrate this memory server with Cursor MCP client, follow these steps:\n\n1. Clone the Repository:\n```bash\ngit clone [repository-url]\ncd [repository-name]\n```\n\n2. Install Dependencies:\n```bash\npnpm install\n```\n\n3. Build the Project:\n```bash\npnpm build\n```\n\n4. Configure the Server:\n- Locate the full path to the built server file: `/path/to/the/dist/index.js`\n- Start the server using Node.js: `node /path/to/the/dist/index.js`\n\n5. Activate in Cursor:\n- Use the keyboard shortcut `Ctrl+Shift+P`\n- Type \"reload window\" and select it\n- Wait a few seconds for the MCP server to activate\n- Select the stdio type when prompted\n\nThe memory server should now be integrated with your Cursor MCP client and ready to use.\n\n\n# Usage with Claude Desktop\n\n### Setup\n\nAdd this to your claude_desktop_config.json:\n\n#### Docker\n\n```json\n{\n  \"mcpServers\": {\n    \"memory\": {\n      \"command\": \"docker\",\n      \"args\": [\"run\", \"-i\", \"-v\", \"claude-memory:/app/dist\", \"--rm\", \"mcp/memory\"]\n    }\n  }\n}\n```\n\n#### NPX\n```json\n{\n  \"mcpServers\": {\n    \"memory\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@modelcontextprotocol/server-memory\"\n      ]\n    }\n  }\n}\n```\n\n#### NPX with custom setting\n\nThe server can be configured using the following environment variables:\n\n```json\n{\n  \"mcpServers\": {\n    \"memory\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@modelcontextprotocol/server-memory\"\n      ],\n      \"env\": {\n        \"MEMORY_FILE_PATH\": \"/path/to/custom/memory.json\"\n      }\n    }\n  }\n}\n```\n\n- `MEMORY_FILE_PATH`: Path to the memory storage JSON file (default: `memory.json` in the server directory)\n\n### System Prompt\n\nThe prompt for utilizing memory depends on the use case. Changing the prompt will help the model determine the frequency and types of memories created.\n\nHere is an example prompt for chat personalization. You could use this prompt in the \"Custom Instructions\" field of a [Claude.ai Project](https://www.anthropic.com/news/projects).\n\n```\nFollow these steps for each interaction:\n\n1. User Identification:\n   - You should assume that you are interacting with default_user\n   - If you have not identified default_user, proactively try to do so.\n\n2. Memory Retrieval:\n   - Always begin your chat by saying only \"Remembering...\" and retrieve all relevant information from your knowledge graph\n   - Always refer to your knowledge graph as your \"memory\"\n\n3. Memory\n   - While conversing with the user, be attentive to any new information that falls into these categories:\n     a) Basic Identity (age, gender, location, job title, education level, etc.)\n     b) Behaviors (interests, habits, etc.)\n     c) Preferences (communication style, preferred language, etc.)\n     d) Goals (goals, targets, aspirations, etc.)\n     e) Relationships (personal and professional relationships up to 3 degrees of separation)\n\n4. Memory Update:\n   - If any new information was gathered during the interaction, update your memory as follows:\n     a) Create entities for recurring organizations, people, and significant events\n     b) Connect them to the current entities using relations\n     b) Store facts about them as observations\n```\n\n## Building\n\nDocker:\n\n```sh\ndocker build -t mcp/memory -f src/memory/Dockerfile .\n```\n\n## License\n\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.\n\n## New Tools\n\n- **create_lesson**\n  - Create a new lesson from an error and its solution\n  - Input: `lesson` (object)\n    - Contains error pattern, solution steps, and metadata\n    - Automatically tracks creation time and updates\n    - Verifies solution steps are complete\n\n- **find_similar_errors**\n  - Find similar errors and their solutions\n  - Input: `errorPattern` (object)\n    - Contains error type, message, and context\n    - Returns matching lessons sorted by success rate\n    - Includes related solutions and verification steps\n\n- **update_lesson_success**\n  - Update success tracking for a lesson\n  - Input:\n    - `lessonName` (string): Lesson to update\n    - `success` (boolean): Whether solution worked\n  - Updates success rate and frequency metrics\n\n- **get_lesson_recommendations**\n  - Get relevant lessons for current context\n  - Input: `context` (string)\n  - Returns lessons sorted by relevance and success rate\n  - Includes full solution details and verification steps\n\n\n# BIG CREDITS TO THE OWNER OF THIS REPO FOR THE BASE CODE I ENHANCED IT WITH LESSONS AND FILE MANAGEMENT\nBig thanks!\nhttps://github.com/modelcontextprotocol/servers\njerome3o-anthropic\nhttps://github.com/modelcontextprotocol/servers/tree/main/src/memory\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "memory",
        "memories",
        "persistent",
        "memory ai",
        "persistent memory",
        "memory management"
      ],
      "category": "memory-management"
    },
    "Thelyoncrypt--MemGPT": {
      "owner": "Thelyoncrypt",
      "name": "MemGPT",
      "url": "https://github.com/Thelyoncrypt/MemGPT",
      "imageUrl": "/freedevtools/mcp/pfp/Thelyoncrypt.webp",
      "description": "Creates chatbots that maintain self-editing memory with different memory tiers to manage limited LLM context windows. Connects to SQL databases, local files, and documents for seamless conversational AI interactions.",
      "stars": 0,
      "forks": 0,
      "license": "Apache License 2.0",
      "language": "",
      "updated_at": "2024-11-06T21:09:05Z",
      "readme_content": "<a href=\"#user-content-memgpt\"><img src=\"https://memgpt.ai/assets/img/memgpt_logo_circle.png\" alt=\"MemGPT logo\" width=\"75\" align=\"right\"></a>\r\n\r\n# [MemGPT](https://memgpt.ai)\r\n\r\n<div align=\"center\">\r\n\r\n <strong>Try out our MemGPT chatbot on <a href=\"https://discord.gg/9GEQrxmVyE\">Discord</a>!</strong>\r\n \r\n[![Discord](https://img.shields.io/discord/1161736243340640419?label=Discord&logo=discord&logoColor=5865F2&style=flat-square&color=5865F2)](https://discord.gg/9GEQrxmVyE)\r\n[![arXiv 2310.08560](https://img.shields.io/badge/arXiv-2310.08560-B31B1B?logo=arxiv&style=flat-square)](https://arxiv.org/abs/2310.08560)\r\n\r\n</div>\r\n\r\n<details open>\r\n  <summary><h2>🤖 Create perpetual chatbots with self-editing memory!</h1></summary>\r\n  <div align=\"center\">\r\n    <br>\r\n    <img src=\"https://memgpt.ai/assets/img/demo.gif\" alt=\"MemGPT demo video\" width=\"800\">\r\n  </div>\r\n</details>\r\n\r\n<details>\r\n <summary><h2>🗃️ Chat with your data - talk to your SQL database or your local files!</strong></h2></summary>\r\n  <strong>SQL Database</strong>\r\n  <div align=\"center\">\r\n    <img src=\"https://memgpt.ai/assets/img/sql_demo.gif\" alt=\"MemGPT demo video for sql search\" width=\"800\">\r\n  </div>\r\n  <strong>Local files</strong>\r\n  <div align=\"center\">\r\n    <img src=\"https://memgpt.ai/assets/img/preload_archival_demo.gif\" alt=\"MemGPT demo video for sql search\" width=\"800\">\r\n  </div>\r\n</details>\r\n\r\n<details>\r\n  <summary><h2>📄 You can also talk to docs - for example ask about <a href=\"memgpt/personas/examples/docqa\">LlamaIndex</a>!</h1></summary>\r\n  <div align=\"center\">\r\n    <img src=\"https://memgpt.ai/assets/img/docqa_demo.gif\" alt=\"MemGPT demo video for llamaindex api docs search\" width=\"800\">\r\n  </div>\r\n  <details>\r\n  <summary><b>ChatGPT (GPT-4) when asked the same question:</b></summary>\r\n    <div align=\"center\">\r\n      <img src=\"https://memgpt.ai/assets/img/llama_index_gpt4.png\" alt=\"GPT-4 when asked about llamaindex api docs\" width=\"800\">\r\n    </div>\r\n    (Question from https://github.com/run-llama/llama_index/issues/7756)\r\n  </details>\r\n</details>\r\n\r\n## Quick setup \r\n\r\nJoin <a href=\"https://discord.gg/9GEQrxmVyE\">Discord</a></strong> and message the MemGPT bot (in the `#memgpt` channel). Then run the following commands (messaged to \"MemGPT Bot\"): \r\n* `/profile` (to create your profile)\r\n* `/key` (to enter your OpenAI key)\r\n* `/create` (to create a MemGPT chatbot)\r\n\r\nMake sure your privacy settings on this server are open so that MemGPT Bot can DM you: \\\r\nMemGPT → Privacy Settings → Direct Messages set to ON\r\n<div align=\"center\">\r\n <img src=\"https://memgpt.ai/assets/img/discord/dm_settings.png\" alt=\"set DMs settings on MemGPT server to be open in MemGPT so that MemGPT Bot can message you\" width=\"400\">\r\n</div>\r\n\r\nYou can see the full list of available commands when you enter `/` into the message box. \r\n<div align=\"center\">\r\n <img src=\"https://memgpt.ai/assets/img/discord/slash_commands.png\" alt=\"MemGPT Bot slash commands\" width=\"400\">\r\n</div>\r\n\r\n## What is MemGPT? \r\n\r\nMemory-GPT (or MemGPT in short) is a system that intelligently manages different memory tiers in LLMs in order to effectively provide extended context within the LLM's limited context window. For example, MemGPT knows when to push critical information to a vector database and when to retrieve it later in the chat, enabling perpetual conversations. Learn more about MemGPT in our [paper](https://arxiv.org/abs/2310.08560). \r\n\r\n## Running MemGPT Locally \r\n\r\nInstall dependencies:\r\n\r\n```sh\r\npip install -r requirements.txt\r\n```\r\n\r\nAdd your OpenAI API key to your environment:\r\n\r\n```sh\r\nexport OPENAI_API_KEY=YOUR_API_KEY\r\n```\r\n\r\nTo run MemGPT for as a conversation agent in CLI mode, simply run `main.py`:\r\n\r\n```sh\r\npython3 main.py\r\n```\r\n\r\nTo create a new starter user or starter persona (that MemGPT gets initialized with), create a new `.txt` file in [/memgpt/humans/examples](/memgpt/humans/examples) or [/memgpt/personas/examples](/memgpt/personas/examples), then use the `--persona` or `--human` flag when running `main.py`. For example:\r\n\r\n```sh\r\n# assuming you created a new file /memgpt/humans/examples/me.txt\r\npython main.py --human me.txt\r\n```\r\n\r\n### `main.py` flags\r\n\r\n```text\r\n--persona\r\n  load a specific persona file\r\n--human\r\n  load a specific human file\r\n--first\r\n  allows you to send the first message in the chat (by default, MemGPT will send the first message)\r\n--debug\r\n  enables debugging output\r\n--archival_storage_faiss_path=<ARCHIVAL_STORAGE_FAISS_PATH>\r\n  load in document database (backed by FAISS index)\r\n--archival_storage_files=\"<ARCHIVAL_STORAGE_FILES_GLOB>\"\r\n  pre-load files into archival memory\r\n--archival_storage_sqldb=<SQLDB_PATH>\r\n  load in SQL database\r\n```\r\n\r\n### Interactive CLI commands\r\n\r\nWhile using MemGPT via the CLI you can run various commands:\r\n\r\n```text\r\n/exit\r\n  exit the CLI\r\n/save\r\n  save a checkpoint of the current agent/conversation state\r\n/load\r\n  load a saved checkpoint\r\n/dump\r\n  view the current message log (see the contents of main context)\r\n/memory\r\n  print the current contents of agent memory\r\n/pop\r\n  undo the last message in the conversation\r\n/heartbeat\r\n  send a heartbeat system message to the agent\r\n/memorywarning\r\n  send a memory warning system message to the agent\r\n```\r\n\r\n## Use MemGPT to talk to your Database!\r\n\r\nMemGPT's archival memory let's you load your database and talk to it! To motivate this use-case, we have included a toy example. \r\n\r\nConsider the `test.db` already included in the repository.\r\n\r\nid\t| name |\tage\r\n--- | --- | ---\r\n1\t| Alice |\t30\r\n2\t| Bob\t | 25\r\n3\t| Charlie |\t35\r\n\r\nTo talk to this database, run:\r\n\r\n```sh\r\npython main_db.py  --archival_storage_sqldb=memgpt/personas/examples/sqldb/test.db\r\n```\r\n\r\nAnd then you can input the path to your database, and your query.\r\n\r\n```python\r\nPlease enter the path to the database. test.db\r\n...\r\nEnter your message: How old is Bob?\r\n...\r\n🤖 Bob is 25 years old.\r\n```\r\n\r\n\r\n### Support\r\n\r\n* By default MemGPT will use `gpt-4`, so your API key will require `gpt-4` API access.\r\n\r\nIf you have any further questions, or have anything to share, we are excited to hear your feedback!\r\n\r\n* For issues and feature requests, please [open a GitHub issue](https://github.com/cpacker/MemGPT/issues).\r\n\r\n### Datasets\r\nDatasets used in our [paper](https://arxiv.org/abs/2310.08560) can be downloaded at [HuggingFace](https://huggingface.co/MemGPT).\r\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "memgpt",
        "thelyoncrypt",
        "chatbots",
        "thelyoncrypt memgpt",
        "memgpt creates",
        "chatbots maintain"
      ],
      "category": "memory-management"
    },
    "TrackerXXX23--dev_memory_mcp": {
      "owner": "TrackerXXX23",
      "name": "dev_memory_mcp",
      "url": "https://github.com/TrackerXXX23/dev_memory_mcp",
      "imageUrl": "/freedevtools/mcp/pfp/null.webp",
      "description": "Captures and organizes development context, tracking code changes and user interactions across multiple projects. Provides persistent memory for a more effective coding experience.",
      "stars": 0,
      "forks": 0,
      "license": "Unknown",
      "language": "Unknown",
      "updated_at": "",
      "readme_content": "",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "dev_memory_mcp",
        "memory",
        "trackerxxx23",
        "trackerxxx23 dev_memory_mcp",
        "dev_memory_mcp captures",
        "memory management"
      ],
      "category": "memory-management"
    },
    "Vic563--Memgpt-MCP-Server": {
      "owner": "Vic563",
      "name": "Memgpt-MCP-Server",
      "url": "https://github.com/Vic563/Memgpt-MCP-Server",
      "imageUrl": "/freedevtools/mcp/pfp/Vic563.webp",
      "description": "Implements a memory system for large language models (LLMs) with capabilities for chatting, retrieving conversation history, and switching between multiple LLM providers.",
      "stars": 27,
      "forks": 5,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-09-12T19:32:51Z",
      "readme_content": "# MemGPT MCP Server\n\nA TypeScript-based MCP server that implements a memory system for LLMs. It provides tools for chatting with different LLM providers while maintaining conversation history.\n\n## Features\n\n### Tools\n- `chat` - Send a message to the current LLM provider\n  - Takes a message parameter\n  - Supports multiple providers (OpenAI, Anthropic, OpenRouter, Ollama)\n\n- `get_memory` - Retrieve conversation history\n  - Optional `limit` parameter to specify number of memories to retrieve\n  - Pass `limit: null` for unlimited memory retrieval\n  - Returns memories in chronological order with timestamps\n\n- `clear_memory` - Clear conversation history\n  - Removes all stored memories\n\n- `use_provider` - Switch between different LLM providers\n  - Supports OpenAI, Anthropic, OpenRouter, and Ollama\n  - Persists provider selection\n\n- `use_model` - Switch to a different model for the current provider\n  - Supports provider-specific models:\n    - Anthropic Claude Models:\n      - Claude 3 Series:\n        - `claude-3-haiku`: Fastest response times, ideal for tasks like customer support and content moderation\n        - `claude-3-sonnet`: Balanced performance for general-purpose use\n        - `claude-3-opus`: Advanced model for complex reasoning and high-performance tasks\n      - Claude 3.5 Series:\n        - `claude-3.5-haiku`: Enhanced speed and cost-effectiveness\n        - `claude-3.5-sonnet`: Superior performance with computer interaction capabilities\n    - OpenAI: 'gpt-4o', 'gpt-4o-mini', 'gpt-4-turbo'\n    - OpenRouter: Any model in 'provider/model' format (e.g., 'openai/gpt-4', 'anthropic/claude-2')\n    - Ollama: Any locally available model (e.g., 'llama2', 'codellama')\n  - Persists model selection\n\n## Development\n\nInstall dependencies:\n```bash\nnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n```bash\nnpm run watch\n```\n\n## Installation\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"letta-memgpt\": {\n      \"command\": \"/path/to/memgpt-server/build/index.js\",\n      \"env\": {\n        \"OPENAI_API_KEY\": \"your-openai-key\",\n        \"ANTHROPIC_API_KEY\": \"your-anthropic-key\",\n        \"OPENROUTER_API_KEY\": \"your-openrouter-key\"\n      }\n    }\n  }\n}\n```\n\n### Environment Variables\n- `OPENAI_API_KEY` - Your OpenAI API key\n- `ANTHROPIC_API_KEY` - Your Anthropic API key\n- `OPENROUTER_API_KEY` - Your OpenRouter API key\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector):\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n\n## Recent Updates\n\n### Claude 3 and 3.5 Series Support (March 2024)\n- Added support for latest Claude models:\n  - Claude 3 Series (Haiku, Sonnet, Opus)\n  - Claude 3.5 Series (Haiku, Sonnet)\n\n### Unlimited Memory Retrieval\n- Added support for retrieving unlimited conversation history\n- Use `{ \"limit\": null }` with the `get_memory` tool to retrieve all stored memories\n- Use `{ \"limit\": n }` to retrieve the n most recent memories\n- Default limit is 10 if not specified\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "memory",
        "memgpt",
        "llms",
        "memory management",
        "memgpt mcp",
        "mcp server"
      ],
      "category": "memory-management"
    },
    "WhenMoon-afk--claude-memory-mcp": {
      "owner": "WhenMoon-afk",
      "name": "claude-memory-mcp",
      "url": "https://github.com/WhenMoon-afk/claude-memory-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/WhenMoon-afk.webp",
      "description": "Enhances Large Language Models with persistent memory capabilities, allowing for the storage, retrieval, and management of memories across conversations. Integrates with the Claude desktop application, supporting various memory types and semantic search.",
      "stars": 33,
      "forks": 7,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-02T11:43:08Z",
      "readme_content": "# Claude Memory MCP Server\n\nAn MCP (Model Context Protocol) server implementation that provides persistent memory capabilities for Large Language Models, specifically designed to integrate with the Claude desktop application.\n\n![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)\n\n## Overview\n\nThis project implements optimal memory techniques based on comprehensive research of current approaches in the field. It provides a standardized way for Claude to maintain persistent memory across conversations and sessions.\n\n## Features\n\n- **Tiered Memory Architecture**: Short-term, long-term, and archival memory tiers\n- **Multiple Memory Types**: Support for conversations, knowledge, entities, and reflections\n- **Semantic Search**: Retrieve memories based on semantic similarity\n- **Automatic Memory Management**: Intelligent memory capture without explicit commands\n- **Memory Consolidation**: Automatic consolidation of short-term memories into long-term memory\n- **Memory Management**: Importance-based memory retention and forgetting\n- **Claude Integration**: Ready-to-use integration with Claude desktop application\n- **MCP Protocol Support**: Compatible with the Model Context Protocol\n- **Docker Support**: Easy deployment using Docker containers\n\n## Quick Start\n\n### Option 1: Using Docker (Recommended)\n\n```bash\n# Clone the repository\ngit clone https://github.com/WhenMoon-afk/claude-memory-mcp.git\ncd claude-memory-mcp\n\n# Start with Docker Compose\ndocker-compose up -d\n```\n\nConfigure Claude Desktop to use the containerized MCP server (see [Docker Usage Guide](docs/docker_usage.md) for details).\n\n### Option 2: Standard Installation\n\n1. **Prerequisites**:\n   - Python 3.8-3.12\n   - pip package manager\n\n2. **Installation**:\n   ```bash\n   # Clone the repository\n   git clone https://github.com/WhenMoon-afk/claude-memory-mcp.git\n   cd claude-memory-mcp\n   \n   # Install dependencies\n   pip install -r requirements.txt\n   \n   # Run setup script\n   chmod +x setup.sh\n   ./setup.sh\n   ```\n\n3. **Claude Desktop Integration**:\n\n   Add the following to your Claude configuration file:\n\n   ```json\n   {\n     \"mcpServers\": {\n       \"memory\": {\n         \"command\": \"python\",\n         \"args\": [\"-m\", \"memory_mcp\"],\n         \"env\": {\n           \"MEMORY_FILE_PATH\": \"/path/to/your/memory.json\"\n         }\n       }\n     }\n   }\n   ```\n\n## Using Memory with Claude\n\nThe Memory MCP Server enables Claude to remember information across conversations without requiring explicit commands. \n\n1. **Automatic Memory**: Claude will automatically:\n   - Remember important details you share\n   - Store user preferences and facts\n   - Recall relevant information when needed\n\n2. **Memory Recall**: To see what Claude remembers, simply ask:\n   - \"What do you remember about me?\"\n   - \"What do you know about my preferences?\"\n\n3. **System Prompt**: For optimal memory usage, add this to your Claude system prompt:\n\n   ```\n   This Claude instance has been enhanced with persistent memory capabilities.\n   Claude will automatically remember important details about you across\n   conversations and recall them when relevant, without needing explicit commands.\n   ```\n\nSee the [User Guide](docs/user_guide.md) for detailed usage instructions and examples.\n\n## Documentation\n\n- [User Guide](docs/user_guide.md)\n- [Docker Usage Guide](docs/docker_usage.md)\n- [Compatibility Guide](docs/compatibility.md)\n- [Architecture](docs/architecture.md)\n- [Claude Integration Guide](docs/claude_integration.md)\n\n## Examples\n\nThe `examples` directory contains scripts demonstrating how to interact with the Memory MCP Server:\n\n- `store_memory_example.py`: Example of storing a memory\n- `retrieve_memory_example.py`: Example of retrieving memories\n\n## Troubleshooting\n\nIf you encounter issues:\n\n1. Check the [Compatibility Guide](docs/compatibility.md) for dependency requirements\n2. Ensure your Python version is 3.8-3.12\n3. For NumPy issues, use: `pip install \"numpy>=1.20.0,<2.0.0\"`\n4. Try using Docker for simplified deployment\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "memory",
        "memories",
        "retrieval",
        "memory management",
        "memory mcp",
        "persistent memory"
      ],
      "category": "memory-management"
    },
    "ZannyTornadoCoding--my-sequential-thinking-mcp-server": {
      "owner": "ZannyTornadoCoding",
      "name": "my-sequential-thinking-mcp-server",
      "url": "https://github.com/ZannyTornadoCoding/my-sequential-thinking-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/ZannyTornadoCoding.webp",
      "description": "Facilitates structured sequential thinking by breaking down complex problems into logical steps, managing reasoning chains, and visualizing thinking pathways. Integrates with a Memory Bank for storing and retrieving thought processes, while providing tools for reasoning validation and analysis.",
      "stars": 3,
      "forks": 1,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-07-05T01:40:56Z",
      "readme_content": "# Sequential Thinking MCP Server\n\nA Model Context Protocol (MCP) server focused on structured sequential thinking capabilities, designed to integrate with Cline's Memory Bank. This server helps break down complex problems into structured sequential steps, track reasoning chains, and store thinking patterns.\n\n## Features\n\n- Create and manage sequential thinking chains for problem-solving\n- Track chains of thought with validation at each step\n- Store and retrieve reasoning patterns\n- Analyze the quality of reasoning processes\n- Visualize thinking pathways\n- Seamlessly integrate with the Memory Bank system\n\n## Architecture\n\nThe server consists of the following core components:\n\n- **Sequential Thinking Engine**: Manages thinking chains, steps, and reasoning validation\n- **Memory Bank Connector**: Integrates with Cline's Memory Bank\n- **Tag Manager**: Implements a comprehensive tagging system\n- **Visualization Generator**: Creates visual representations of thinking chains\n- **Utilities**: File storage, thinking validation, and other helpers\n\n## Available Tools\n\nThe server provides the following MCP tools:\n\n### create_thinking_chain\nCreate a new sequential thinking process with specified parameters.\n- **Input**: problem description, thinking type, context\n- **Output**: chain_id and initial structure\n\n### add_thinking_step\nAdd a step to an existing thinking chain.\n- **Input**: chain_id, step description, reasoning, evidence\n- **Output**: updated step information\n\n### validate_step\nValidate logical connections between steps.\n- **Input**: chain_id, step_id\n- **Output**: validation results, potential issues\n\n### get_chain\nRetrieve a complete thinking chain.\n- **Input**: chain_id\n- **Output**: full chain with all steps\n\n### generate_visualization\nCreate visual representation of a thinking chain.\n- **Input**: chain_id, format (mermaid, json, text)\n- **Output**: visualization code/data\n\n### save_to_memory\nSave a thinking chain to Memory Bank.\n- **Input**: chain_id, memory_name, tags\n- **Output**: confirmation and memory_id\n\n### load_from_memory\nLoad a thinking chain from Memory Bank.\n- **Input**: memory_id or search parameters\n- **Output**: complete chain\n\n### search_related_thinking\nFind related thinking chains based on parameters.\n- **Input**: keywords, tags, thinking_type\n- **Output**: list of relevant chains\n\n### apply_template\nApply a reasoning template to current thinking.\n- **Input**: template_name, problem_context\n- **Output**: pre-structured thinking chain\n\n## Thinking Types\n\nThe server supports various thinking types, each with specific patterns and structures:\n\n- **Analytical** - Break down, analyze, synthesize\n- **Creative** - Diverge, explore, converge\n- **Critical** - Question, evaluate, conclude\n- **Systems** - Map, analyze, model\n- **First-Principles** - Identify, break down, reassemble\n- **Divergent** - Generate alternatives, explore\n- **Convergent** - Analyze, evaluate, select\n- **Inductive** - Observe, pattern, hypothesize\n- **Deductive** - Premise, logic, conclusion\n\n## Templates\n\nThe server includes ready-to-use reasoning templates to jumpstart the thinking process:\n\n- **First Principles Analysis** - Break down a complex problem into its fundamental principles\n- **Systems Thinking Analysis** - Analyze complex systems holistically\n\n## Installation\n\n1. Ensure Node.js v14+ is installed\n2. Clone the repository\n3. Install dependencies:\n   ```\n   npm install\n   ```\n\n## Usage\n\n1. Start the server:\n   ```\n   node index.js\n   ```\n\n2. The server will be available as an MCP server that you can connect to via Claude/Cline\n\n## Memory Bank Integration\n\nThis server is designed to integrate with Cline's Memory Bank, allowing:\n\n1. Reading from Memory Bank files (projectbrief.md, activeContext.md, etc.)\n2. Storing complete thinking chains as structured memories\n3. Updating activeContext.md with reasoning outcomes\n4. Creating links between reasoning and Memory Bank sections\n\n## Example Tool Usage\n\n```javascript\n// Example: Create a new thinking chain\n{\n  \"problem\": \"How to improve user engagement on our platform\",\n  \"thinking_type\": \"systems\",\n  \"context\": \"Our user engagement metrics have decreased by 15% over the past quarter\"\n}\n\n// Example: Add a thinking step\n{\n  \"chain_id\": \"3a7e4fc0-5c1d-4b9f-9d1a-8b5e7c5a9d3e\",\n  \"description\": \"Identify key components of the engagement system\",\n  \"reasoning\": \"User engagement consists of several interconnected components including onboarding, core user actions, notification systems, and retention mechanisms.\",\n  \"evidence\": \"Analysis of our user journey maps and analytics data\",\n  \"confidence\": 0.8\n}\n\n// Example: Generate a visualization\n{\n  \"chain_id\": \"3a7e4fc0-5c1d-4b9f-9d1a-8b5e7c5a9d3e\",\n  \"format\": \"mermaid\",\n  \"options\": {\n    \"showValidation\": true,\n    \"showConfidence\": true\n  }\n}\n```\n\n## Tag System\n\nThe server implements a comprehensive tagging system with multiple dimensions:\n\n- **Thinking Type** - analytical, creative, critical, systems, etc.\n- **Domain** - business, science, technology, art, etc.\n- **Complexity** - simple, moderate, complex\n- **Status** - draft, validated, complete\n- **Custom** - user-defined tags\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "sequential",
        "thinking",
        "memory",
        "sequential thinking",
        "thinking pathways",
        "managing reasoning"
      ],
      "category": "memory-management"
    },
    "a2888409--CSAPP": {
      "owner": "a2888409",
      "name": "CSAPP",
      "url": "https://github.com/a2888409/CSAPP",
      "imageUrl": "/freedevtools/mcp/pfp/a2888409.webp",
      "description": "A high-performance HTTP server utilizing the epoll model for efficient connection and task management, supporting event-driven architecture and timer management for handling inactive connections. Includes implementations of memory allocation, a simple proxy server, and a basic shell for process management and signal handling.",
      "stars": 4,
      "forks": 3,
      "license": "No License",
      "language": "C",
      "updated_at": "2021-09-03T11:30:14Z",
      "readme_content": "# 基于epoll模型的http服务器 + CSAPP_lab\n基于epoll模型的http服务器 + CSAPP一书配套的实验中，其中3个经典实验的源码<br>\n###http：基于epoll模型的http服务器<br>\n采用epoll模型，实现了统一事件源，并通过时间堆管理定时器回收非活动连接。<br>\n通过一个线程池实现对任务的处理，然后使用状态机解析HTTP报文，请求了静态文件。<br>\n<br>\n###malloclab-handout：基于分离适配算法的内存分配器<br>\n采用双向链表结构维护分配器，每次分配一个内存块时，通过链表头指针查找到一个大小合适的块，并进行可选的分割。性能较隐式空闲链表分配器提升了大约20%。\n<br>\n###proxylab-handout：实现了一个简单的代理程序\n<br>\n###shlab-handout：Tiny Shell<br>\n实现了一个简易shell程序，主要涉及进程管理和信号处理。定义了一个数据结构管理job，实现了job的add，delete，fg，bg等功能。并正确的处理了SIGINT，SIGCHLD，SIGTSTP信号。\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "csapp",
        "http",
        "server",
        "http server",
        "performance http",
        "a2888409 csapp"
      ],
      "category": "memory-management"
    },
    "aakarsh-sasi--memory-bank-mcp": {
      "owner": "aakarsh-sasi",
      "name": "memory-bank-mcp",
      "url": "https://github.com/aakarsh-sasi/memory-bank-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/aakarsh-sasi.webp",
      "description": "Manage AI assistant's context across sessions by storing, retrieving, and tracking information with remote server support for improved collaboration and persistence.",
      "stars": 32,
      "forks": 11,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-02T11:12:08Z",
      "readme_content": "# Memory Bank MCP With Remote SSH Support 🧠\n\n[![NPM Version](https://img.shields.io/npm/v/@aakarsh-sasi/memory-bank-mcp.svg)](https://www.npmjs.com/package/@aakarsh-sasi/memory-bank-mcp)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Tests](https://github.com/movibe/memory-bank-mcp/actions/workflows/test.yml/badge.svg)](https://github.com/movibe/memory-bank-mcp/actions/workflows/test.yml)\n[![smithery badge](https://smithery.ai/badge/@aakarsh-sasi/memory-bank-mcp)](https://smithery.ai/server/@aakarsh-sasi/memory-bank-mcp)\n\nA Model Context Protocol (MCP) server for managing Memory Banks, allowing AI assistants to store and retrieve information across sessions. Now with remote server support!\n\n<a href=\"https://glama.ai/mcp/servers/@aakarsh-sasi/memory-bank-mcp\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@aakarsh-sasi/memory-bank-mcp/badge\" alt=\"Memory Bank MCP server\" />\n</a>\n\n## Overview 📋\n\nMemory Bank Server provides a set of tools and resources for AI assistants to interact with Memory Banks. Memory Banks are structured repositories of information that help maintain context and track progress across multiple sessions.\n\n## Features ✨\n\n- **Memory Bank Management**: Initialize, find, and manage Memory Banks\n- **File Operations**: Read and write files in Memory Banks\n- **Progress Tracking**: Track progress and update Memory Bank files\n- **Decision Logging**: Log important decisions with context and alternatives\n- **Active Context Management**: Maintain and update active context information\n- **Mode Support**: Detect and use .clinerules files for mode-specific behavior\n- **UMB Command**: Update Memory Bank files temporarily with the UMB command\n- **Robust Error Handling**: Gracefully handle errors and continue operation when possible\n- **Status Prefix System**: Immediate visibility into Memory Bank operational state\n- **Remote Server Support**: Store Memory Banks on a remote server using SSH\n\n## Directory Structure 📁\n\nBy default, Memory Bank uses a `memory-bank` directory in the root of your project. When you specify a project path using the `--path` option, the Memory Bank will be created or accessed at `<project_path>/memory-bank`.\n\nYou can customize the name of the Memory Bank folder using the `--folder` option. For example, if you set `--folder custom-memory`, the Memory Bank will be created or accessed at `<project_path>/custom-memory`.\n\nFor more details on customizing the folder name, see [Custom Memory Bank Folder Name](docs/custom-folder-name.md).\n\n## Recent Improvements 🛠️\n\n- **Remote Server Support**: Store your Memory Bank on a remote server via SSH\n- **Customizable Folder Name**: You can now specify a custom folder name for the Memory Bank\n- **Consistent Directory Structure**: Memory Bank now always uses the configured folder name in the project root\n- **Enhanced Initialization**: Memory Bank now works even when .clinerules files don't exist\n- **Better Path Handling**: Improved handling of absolute and relative paths\n- **Improved Directory Detection**: Better detection of existing memory-bank directories\n- **More Robust Error Handling**: Graceful handling of errors related to .clinerules files\n\nFor more details, see [Memory Bank Bug Fixes](docs/memory-bank-bug-fixes.md).\n\n## Installation 🚀\n\n### Installing via Smithery\n\nTo install Memory Bank for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@aakarsh-sasi/memory-bank-mcp):\n\n```bash\nnpx -y @smithery/cli install @aakarsh-sasi/memory-bank-mcp --client claude\n```\n\n### Manual Installation\n```bash\n# Install from npm\nnpm install @aakarsh-sasi/memory-bank-mcp\n\n# Or install globally\nnpm install -g @aakarsh-sasi/memory-bank-mcp\n\n# Or run directly with npx (no installation required)\nnpx @aakarsh-sasi/memory-bank-mcp\n```\n\n## Usage with npx 💻\n\nYou can run Memory Bank MCP directly without installation using npx:\n\n```bash\n# Run with default settings\nnpx @aakarsh-sasi/memory-bank-mcp\n\n# Run with specific mode\nnpx @aakarsh-sasi/memory-bank-mcp --mode code\n\n# Run with custom project path\nnpx @aakarsh-sasi/memory-bank-mcp --path /path/to/project\n\n# Run with custom folder name\nnpx @aakarsh-sasi/memory-bank-mcp --folder custom-memory-bank\n\n# Run with remote server\nnpx @aakarsh-sasi/memory-bank-mcp --remote --remote-user username --remote-host example.host.com --remote-path /home/username/memory-bank\n\n# Show help\nnpx @aakarsh-sasi/memory-bank-mcp --help\n```\n\nFor more detailed information about using npx, see [npx-usage.md](docs/npx-usage.md).\n\n## Using Remote Server Mode 🌐\n\nMemory Bank MCP now supports storing your Memory Bank on a remote server via SSH. This allows you to:\n\n1. **Centralize your Memory Bank**: Keep all your project memory in one place\n2. **Share Memory Banks**: Multiple users can access the same Memory Bank\n3. **Persistent Storage**: Your Memory Bank persists even if your local machine is wiped\n\n### Remote Server Requirements\n\n- SSH access to the remote server\n- SSH key authentication set up (password authentication is not supported)\n- Sufficient permissions to create/modify files in the specified directory\n\n### SSH Key Setup\n\nTo set up SSH key authentication for the remote server:\n\n1. **Generate a new SSH key pair** (if you don't already have one):\n   \n   ```bash\n   # Using modern Ed25519 algorithm (recommended)\n   ssh-keygen -t ed25519 -C \"your_email@example.com\"\n   \n   # OR using RSA if required for compatibility\n   ssh-keygen -t rsa -b 4096 -C \"your_email@example.com\"\n   ```\n\n2. **Start the SSH agent and add your key**:\n   \n   ```bash\n   # Start the agent\n   eval \"$(ssh-agent -s)\"\n   \n   # Add your key\n   ssh-add ~/.ssh/id_ed25519  # or ~/.ssh/id_rsa if you used RSA\n   ```\n\n3. **Copy your public key to the remote server**:\n   \n   ```bash\n   # Easiest method (if available)\n   ssh-copy-id username@your-remote-host.com\n   \n   # Alternative: manually copy your public key\n   cat ~/.ssh/id_ed25519.pub  # copy the output\n   ```\n   \n   Then paste the key into the `~/.ssh/authorized_keys` file on the remote server.\n\n4. **Test your connection**:\n   \n   ```bash\n   ssh username@your-remote-host.com\n   ```\n   \n   You should be able to log in without a password.\n\nFor more detailed SSH key setup instructions, see our [SSH Keys Guide](docs/ssh-keys-guide.md).\n\n### Remote Server Configuration\n\nTo use remote server mode, you need to provide the following parameters:\n\n```bash\nnpx @aakarsh-sasi/memory-bank-mcp --remote \\\n  --ssh-key ~/.ssh/your_ssh_key \\\n  --remote-user username \\\n  --remote-host example.host.com \\\n  --remote-path /home/username/memory-bank\n```\n\nBy default, the SSH key is assumed to be at `~/.ssh/your_ssh_key`. You can specify a different key using the `--ssh-key` option.\n\n### Remote Server Example\n\n```bash\n# Using with a server at example.host.com\nnpx @aakarsh-sasi/memory-bank-mcp --remote \\\n  --remote-user username \\\n  --remote-host example.host.com \\\n  --remote-path /home/username/memory-bank\n```\n\n## Configuring in Cursor 🖱️\n\nCursor is an AI-powered code editor that supports the Model Context Protocol (MCP). To configure Memory Bank MCP in Cursor:\n\n1. **Use Memory Bank MCP with npx**:\n\n   No need to install the package globally. You can use npx directly:\n\n   ```bash\n   # Verify npx is working correctly\n   npx @aakarsh-sasi/memory-bank-mcp --help\n   ```\n\n2. **Open Cursor Settings**:\n\n   - Go to Settings (⚙️) > Extensions > MCP\n   - Click on \"Add MCP Server\"\n\n3. **Configure the MCP Server**:\n\n   - **Name**: Memory Bank MCP\n   - **Command**: npx\n   - **Arguments**: `@aakarsh-sasi/memory-bank-mcp --mode code` (or other mode as needed)\n   \n   For remote server:\n   - **Arguments**: `@aakarsh-sasi/memory-bank-mcp --mode code --remote --remote-user username --remote-host example.host.com --remote-path /home/username/memory-bank`\n\n4. **Save and Activate**:\n\n   - Click \"Save\"\n   - Enable the MCP server by toggling it on\n\n5. **Verify Connection**:\n   - Open a project in Cursor\n   - The Memory Bank MCP should now be active and available in your AI interactions\n\nFor detailed instructions and advanced usage with Cursor, see [cursor-integration.md](docs/cursor-integration.md).\n\n### Using with Cursor 🤖\n\nOnce configured, you can interact with Memory Bank MCP in Cursor through AI commands:\n\n- **Initialize a Memory Bank**: `/mcp memory-bank-mcp initialize_memory_bank path=./memory-bank`\n- **Track Progress**: `/mcp memory-bank-mcp track_progress action=\"Feature Implementation\" description=\"Implemented feature X\"`\n- **Log Decision**: `/mcp memory-bank-mcp log_decision title=\"API Design\" context=\"...\" decision=\"...\"`\n- **Switch Mode**: `/mcp memory-bank-mcp switch_mode mode=code`\n\n## MCP Modes and Their Usage 🔄\n\nMemory Bank MCP supports different operational modes to optimize AI interactions for specific tasks:\n\n### Available Modes\n\n1. **Code Mode** 👨‍💻\n\n   - Focus: Code implementation and development\n   - Usage: `npx @aakarsh-sasi/memory-bank-mcp --mode code`\n   - Best for: Writing, refactoring, and optimizing code\n\n2. **Architect Mode** 🏗️\n\n   - Focus: System design and architecture\n   - Usage: `npx @aakarsh-sasi/memory-bank-mcp --mode architect`\n   - Best for: Planning project structure, designing components, and making architectural decisions\n\n3. **Ask Mode** ❓\n\n   - Focus: Answering questions and providing information\n   - Usage: `npx @aakarsh-sasi/memory-bank-mcp --mode ask`\n   - Best for: Getting explanations, clarifications, and information\n\n4. **Debug Mode** 🐛\n\n   - Focus: Troubleshooting and problem-solving\n   - Usage: `npx @aakarsh-sasi/memory-bank-mcp --mode debug`\n   - Best for: Finding and fixing bugs, analyzing issues\n\n5. **Test Mode** ✅\n   - Focus: Testing and quality assurance\n   - Usage: `npx @aakarsh-sasi/memory-bank-mcp --mode test`\n   - Best for: Writing tests, test-driven development\n\n### Switching Modes\n\nYou can switch modes in several ways:\n\n1. **When starting the server**:\n\n   ```bash\n   npx @aakarsh-sasi/memory-bank-mcp --mode architect\n   ```\n\n2. **During a session**:\n\n   ```bash\n   memory-bank-mcp switch_mode mode=debug\n   ```\n\n3. **In Cursor**:\n\n   ```\n   /mcp memory-bank-mcp switch_mode mode=test\n   ```\n\n4. **Using .clinerules files**:\n   Create a `.clinerules-[mode]` file in your project to automatically switch to that mode when the file is detected.\n\n## How Memory Bank MCP Works 🧠\n\nMemory Bank MCP is built on the Model Context Protocol (MCP), which enables AI assistants to interact with external tools and resources. Here's how it works:\n\n### Core Components 🧩\n\n1. **Memory Bank**: A structured repository of information stored as markdown files:\n\n   - `product-context.md`: Overall project information and goals\n   - `active-context.md`: Current state, ongoing tasks, and next steps\n   - `progress.md`: History of project updates and milestones\n   - `decision-log.md`: Record of important decisions with context and rationale\n   - `system-patterns.md`: Architecture and code patterns used in the project\n\n2. **MCP Server**: Provides tools and resources for AI assistants to interact with Memory Banks:\n\n   - Runs as a standalone process\n   - Communicates with AI assistants through the MCP protocol\n   - Provides a set of tools for managing Memory Banks\n\n3. **Mode System**: Supports different operational modes:\n   - `code`: Focus on code implementation\n   - `ask`: Focus on answering questions\n   - `architect`: Focus on system design\n   - `debug`: Focus on debugging issues\n   - `test`: Focus on testing\n\n### Data Flow 🔄\n\n1. **Initialization**: The AI assistant connects to the MCP server and initializes a Memory Bank\n2. **Tool Calls**: The AI assistant calls tools provided by the MCP server to read/write Memory Bank files\n3. **Context Maintenance**: The Memory Bank maintains context across sessions, allowing the AI to recall previous decisions and progress\n\n### Memory Bank Structure 📂\n\nMemory Banks use a standardized structure to organize information:\n\n- **Product Context**: Project overview, objectives, technologies, and architecture\n- **Active Context**: Current state, ongoing tasks, known issues, and next steps\n- **Progress**: Chronological record of project updates and milestones\n- **Decision Log**: Record of important decisions with context, alternatives, and consequences\n- **System Patterns**: Architecture patterns, code patterns, and documentation patterns\n\n### Advanced Features 🚀\n\n- **UMB Command**: Temporarily update Memory Bank files during a session without committing changes\n- **Mode Detection**: Automatically detect and switch modes based on user input\n- **File Migration**: Tools for migrating between different file naming conventions\n- **Language Standardization**: All Memory Bank files are generated in English for consistency\n\n## Versioning 📌\n\nThis project follows [Semantic Versioning](https://semver.org/) and uses [Conventional Commits](https://www.conventionalcommits.org/) for commit messages. The version is automatically bumped and a changelog is generated based on commit messages when changes are merged into the main branch.\n\n- **Major version** is bumped when there are breaking changes (commit messages with `BREAKING CHANGE` or `!:`)\n- **Minor version** is bumped when new features are added (commit messages with `feat:` or `feat(scope):`)\n- **Patch version** is bumped for all other changes (bug fixes, documentation, etc.)\n\nFor the complete history of changes, see the [CHANGELOG.md](CHANGELOG.md) file.\n\n## Usage 📝\n\n### As a Command Line Tool 💻\n\n```bash\n# Initialize a Memory Bank\nmemory-bank-mcp initialize_memory_bank path=./memory-bank\n\n# Track progress\nmemory-bank-mcp track_progress action=\"Feature Implementation\" description=\"Implemented feature X\"\n\n# Log a decision\nmemory-bank-mcp log_decision title=\"API Design\" context=\"...\" decision=\"...\"\n\n# Switch mode\nmemory-bank-mcp switch_mode mode=code\n```\n\n### As a Library 📚\n\n```typescript\nimport { MemoryBankServer } from \"@aakarsh-sasi/memory-bank-mcp\";\n\n// Create a new server instance\nconst server = new MemoryBankServer();\n\n// Start the server\nserver.run().catch(console.error);\n```\n\n## Contributing 👥\n\nPlease see [CONTRIBUTING.md](CONTRIBUTING.md) for details on our code of conduct and the process for submitting pull requests.\n\n## License 📄\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Memory Bank Status System 🚦\n\nMemory Bank MCP implements a status prefix system that provides immediate visibility into the operational state of the Memory Bank:\n\n### Status Indicators\n\nEvery response from an AI assistant using Memory Bank MCP begins with one of these status indicators:\n\n- **`[MEMORY BANK: ACTIVE]`**: The Memory Bank is available and being used to provide context-aware responses\n- **`[MEMORY BANK: INACTIVE]`**: The Memory Bank is not available or not properly configured\n- **`[MEMORY BANK: UPDATING]`**: The Memory Bank is currently being updated (during UMB command execution)\n\nThis system ensures users always know whether the AI assistant is operating with full context awareness or limited information.\n\n### Benefits\n\n- **Transparency**: Users always know whether the AI has access to the full project context\n- **Troubleshooting**: Makes it immediately obvious when Memory Bank is not properly configured\n- **Context Awareness**: Helps users understand why certain responses may lack historical context\n\nFor more details, see [Memory Bank Status Prefix System](docs/memory-bank-status-prefix.md).\n",
      "npm_url": "https://www.npmjs.com/package/memory-bank-mcp",
      "npm_downloads": 3190,
      "keywords": [
        "memory",
        "assistant",
        "ai",
        "sasi memory",
        "ai assistant",
        "memory management"
      ],
      "category": "memory-management"
    },
    "aiurda--cursor10x-mcp": {
      "owner": "aiurda",
      "name": "cursor10x-mcp",
      "url": "https://github.com/aiurda/cursor10x-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/aiurda.webp",
      "description": "Offers a project-centric database for managing contextual information throughout development workflows. Facilitates seamless retrieval and recall of project context, enhancing productivity and fostering intelligent code connections.",
      "stars": 64,
      "forks": 11,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-30T22:48:07Z",
      "readme_content": "![DevContext - The Next Evolution in AI Development Context](https://i.postimg.cc/sghKLKf6/Dev-Context-banner.png)\n\n<div align=\"center\">\n  \n# 🚀 **Cursor10x is now DevContext** 🚀\n\n### Cursor10x has evolved into DevContext - A more powerful, dedicated context system for developers\n\n<table align=\"center\">\n  <tr>\n    <td align=\"center\"><b>🧠 Project-Centric</b></td>\n    <td align=\"center\"><b>📊 Relationship Graphs</b></td>\n    <td align=\"center\"><b>⚡ High Performance</b></td>\n  </tr>\n  <tr>\n    <td align=\"center\">One database per project</td>\n    <td align=\"center\">Intelligent code connections</td>\n    <td align=\"center\">Minimal resource needs</td>\n  </tr>\n</table>\n\n### 🔥 **DevContext takes AI development to the next level** 🔥\n\n**🔄 Continuous Context Awareness** - Sophisticated retrieval methods focusing on what matters\n**📊 Structured Metadata** - From repository structure down to individual functions\n**🧠 Adaptive Learning** - Continuously learns from and adapts to your development patterns\n**🤖 Completely Autonomous** - Self-managing context system that works in the background\n**📚 External Documentation** - Automatically retrieves and integrates relevant documentation\n**📋 Workflow Integration** - Seamless task management workflow built-in\n\n#### 👀 **Be on the lookout** 👀\n\nThe DevContext Project Generator is launching in the next couple days and will create a COMPLETE set up for your project to literally 10x your development workflow.\n\n<p align=\"center\">\n  <a href=\"https://github.com/aurda012/devcontext\" style=\"display: inline-block; background-color: rgba(40, 230, 210); color: white; padding: 12px 24px; text-decoration: none; border-radius: 8px; font-weight: bold; box-shadow: 0 4px 6px rgba(0,0,0,0.1); transition: all 0.3s ease;\">Visit DevContext Repository</a>\n</p>\n\n<i>DevContext is a cutting-edge Model Context Protocol (MCP) server providing developers with continuous, project-centric context awareness that understands your codebase at a deeper level.</i>\n\n</div>\n\n---\n\n## Overview\n\nThe Cursor10x Memory System creates a persistent memory layer for AI assistants (specifically Claude), enabling them to retain and recall:\n\n- Recent messages and conversation history\n- Active files currently being worked on\n- Important project milestones and decisions\n- Technical requirements and specifications\n- Chronological sequences of actions and events (episodes)\n- Code snippets and structures from your codebase\n- Semantically similar content based on vector embeddings\n- Related code fragments through semantic similarity\n- File structures with function and variable relationships\n\nThis memory system bridges the gap between stateless AI interactions and continuous development workflows, allowing for more productive and contextually aware assistance.\n\n## System Architecture\n\nThe memory system is built on four core components:\n\n1. **MCP Server**: Implements the Model Context Protocol to register tools and process requests\n2. **Memory Database**: Uses Turso database for persistent storage across sessions\n3. **Memory Subsystems**: Organizes memory into specialized systems with distinct purposes\n4. **Vector Embeddings**: Transforms text and code into numerical representations for semantic search\n\n### Memory Types\n\nThe system implements four complementary memory types:\n\n1. **Short-Term Memory (STM)**\n\n   - Stores recent messages and active files\n   - Provides immediate context for current interactions\n   - Automatically prioritizes by recency and importance\n\n2. **Long-Term Memory (LTM)**\n\n   - Stores permanent project information like milestones and decisions\n   - Maintains architectural and design context\n   - Preserves high-importance information indefinitely\n\n3. **Episodic Memory**\n\n   - Records chronological sequences of events\n   - Maintains causal relationships between actions\n   - Provides temporal context for project history\n\n4. **Semantic Memory**\n   - Stores vector embeddings of messages, files, and code snippets\n   - Enables retrieval of content based on semantic similarity\n   - Automatically indexes code structures for contextual retrieval\n   - Tracks relationships between code components\n   - Provides similarity-based search across the codebase\n\n## Features\n\n- **Persistent Context**: Maintains conversation and project context across multiple sessions\n- **Importance-Based Storage**: Prioritizes information based on configurable importance levels\n- **Multi-Dimensional Memory**: Combines short-term, long-term, episodic, and semantic memory systems\n- **Comprehensive Retrieval**: Provides unified context from all memory subsystems\n- **Health Monitoring**: Includes built-in diagnostics and status reporting\n- **Banner Generation**: Creates informative context banners for conversation starts\n- **Database Persistence**: Stores all memory data in Turso database with automatic schema creation\n- **Vector Embeddings**: Creates numerical representations of text and code for similarity search\n- **Advanced Vector Storage**: Utilizes Turso's F32_BLOB and vector functions for efficient embedding storage\n- **ANN Search**: Supports Approximate Nearest Neighbor search for fast similarity matching\n- **Code Indexing**: Automatically detects and indexes code structures (functions, classes, variables)\n- **Semantic Search**: Finds related content based on meaning rather than exact text matches\n- **Relevance Scoring**: Ranks context items by relevance to the current query\n- **Code Structure Detection**: Identifies and extracts code components across multiple languages\n- **Auto-Embedding Generation**: Automatically creates vector embeddings for indexed content\n- **Cross-Reference Retrieval**: Finds related code across different files and components\n\n## Installation\n\n### Prerequisites\n\n- Node.js 18 or higher\n- npm or yarn package manager\n- Turso database account\n\n### Setup Steps\n\n1. **Configure Turso Database:**\n\n```bash\n# Install Turso CLI\ncurl -sSfL https://get.turso.tech/install.sh | bash\n\n# Login to Turso\nturso auth login\n\n# Create a database\nturso db create cursor10x-mcp\n\n# Get database URL and token\nturso db show cursor10x-mcp --url\nturso db tokens create cursor10x-mcp\n```\n\nOr you can visit [Turso](https://turso.tech/) and sign up and proceed to create the database and get proper credentials. The free plan will more than cover your project memory.\n\n2. **Configure Cursor MCP:**\n\nUpdate `.cursor/mcp.json` in your project directory with the database url and turso auth token:\n\n```json\n{\n  \"mcpServers\": {\n    \"cursor10x-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\"cursor10x-mcp\"],\n      \"enabled\": true,\n      \"env\": {\n        \"TURSO_DATABASE_URL\": \"your-turso-database-url\",\n        \"TURSO_AUTH_TOKEN\": \"your-turso-auth-token\"\n      }\n    }\n  }\n}\n```\n\n## Tool Documentation\n\n### System Tools\n\n#### `mcp_cursor10x_initConversation`\n\nInitializes a conversation by storing the user message, generating a banner, and retrieving context in one operation. This unified tool replaces the need for separate generateBanner, getComprehensiveContext, and storeUserMessage calls at the beginning of each conversation.\n\n**Parameters:**\n\n- `content` (string, required): Content of the user message\n- `importance` (string, optional): Importance level (\"low\", \"medium\", \"high\", \"critical\"), defaults to \"low\"\n- `metadata` (object, optional): Additional metadata for the message\n\n**Returns:**\n\n- Object with two sections:\n  - `display`: Contains the banner to be shown to the user\n  - `internal`: Contains the comprehensive context for the agent's use\n\n**Example:**\n\n```javascript\n// Initialize a conversation\nconst result = await mcp_cursor10x_initConversation({\n  content: \"I need to implement a login system for my app\",\n  importance: \"medium\",\n});\n// Result: {\n//   \"status\": \"ok\",\n//   \"display\": {\n//     \"banner\": {\n//       \"status\": \"ok\",\n//       \"memory_system\": \"active\",\n//       \"mode\": \"turso\",\n//       \"message_count\": 42,\n//       \"active_files_count\": 3,\n//       \"last_accessed\": \"4/15/2023, 2:30:45 PM\"\n//     }\n//   },\n//   \"internal\": {\n//     \"context\": { ... comprehensive context data ... },\n//     \"messageStored\": true,\n//     \"timestamp\": 1681567845123\n//   }\n// }\n```\n\n#### `mcp_cursor10x_endConversation`\n\nEnds a conversation by combining multiple operations in one call: storing the assistant's final message, recording a milestone for what was accomplished, and logging an episode in the episodic memory. This unified tool replaces the need for separate storeAssistantMessage, storeMilestone, and recordEpisode calls at the end of each conversation.\n\n**Parameters:**\n\n- `content` (string, required): Content of the assistant's final message\n- `milestone_title` (string, required): Title of the milestone to record\n- `milestone_description` (string, required): Description of what was accomplished\n- `importance` (string, optional): Importance level (\"low\", \"medium\", \"high\", \"critical\"), defaults to \"medium\"\n- `metadata` (object, optional): Additional metadata for all records\n\n**Returns:**\n\n- Object with status and results of each operation\n\n**Example:**\n\n```javascript\n// End a conversation with finalization steps\nconst result = await mcp_cursor10x_endConversation({\n  content:\n    \"I've implemented the authentication system with JWT tokens as requested\",\n  milestone_title: \"Authentication Implementation\",\n  milestone_description:\n    \"Implemented secure JWT-based authentication with refresh tokens\",\n  importance: \"high\",\n});\n// Result: {\n//   \"status\": \"ok\",\n//   \"results\": {\n//     \"assistantMessage\": {\n//       \"stored\": true,\n//       \"timestamp\": 1681568500123\n//     },\n//     \"milestone\": {\n//       \"title\": \"Authentication Implementation\",\n//       \"stored\": true,\n//       \"timestamp\": 1681568500123\n//     },\n//     \"episode\": {\n//       \"action\": \"completion\",\n//       \"stored\": true,\n//       \"timestamp\": 1681568500123\n//     }\n//   }\n// }\n```\n\n#### `mcp_cursor10x_checkHealth`\n\nChecks the health of the memory system and its database connection.\n\n**Parameters:**\n\n- None required\n\n**Returns:**\n\n- Object with health status and diagnostics\n\n**Example:**\n\n```javascript\n// Check memory system health\nconst health = await mcp_cursor10x_checkHealth({});\n// Result: {\n//   \"status\": \"ok\",\n//   \"mode\": \"turso\",\n//   \"message_count\": 42,\n//   \"active_files_count\": 3,\n//   \"current_directory\": \"/users/project\",\n//   \"timestamp\": \"2023-04-15T14:30:45.123Z\"\n// }\n```\n\n#### `mcp_cursor10x_getMemoryStats`\n\nRetrieves detailed statistics about the memory system.\n\n**Parameters:**\n\n- None required\n\n**Returns:**\n\n- Object with comprehensive memory statistics\n\n**Example:**\n\n```javascript\n// Get memory statistics\nconst stats = await mcp_cursor10x_getMemoryStats({});\n// Result: {\n//   \"status\": \"ok\",\n//   \"stats\": {\n//     \"message_count\": 42,\n//     \"active_file_count\": 3,\n//     \"milestone_count\": 7,\n//     \"decision_count\": 12,\n//     \"requirement_count\": 15,\n//     \"episode_count\": 87,\n//     \"oldest_memory\": \"2023-03-10T09:15:30.284Z\",\n//     \"newest_memory\": \"2023-04-15T14:30:45.123Z\"\n//   }\n// }\n```\n\n#### `mcp_cursor10x_getComprehensiveContext`\n\nRetrieves a unified context from all memory subsystems, combining short-term, long-term, and episodic memory.\n\n**Parameters:**\n\n- None required\n\n**Returns:**\n\n- Object with consolidated context from all memory systems\n\n**Example:**\n\n```javascript\n// Get comprehensive context\nconst context = await mcp_cursor10x_getComprehensiveContext({});\n// Result: {\n//   \"status\": \"ok\",\n//   \"context\": {\n//     \"shortTerm\": {\n//       \"recentMessages\": [...],\n//       \"activeFiles\": [...]\n//     },\n//     \"longTerm\": {\n//       \"milestones\": [...],\n//       \"decisions\": [...],\n//       \"requirements\": [...]\n//     },\n//     \"episodic\": {\n//       \"recentEpisodes\": [...]\n//     },\n//     \"system\": {\n//       \"healthy\": true,\n//       \"timestamp\": \"2023-04-15T14:30:45.123Z\"\n//     }\n//   }\n// }\n```\n\n### Short-Term Memory Tools\n\n#### `mcp_cursor10x_storeUserMessage`\n\nStores a user message in the short-term memory system.\n\n**Parameters:**\n\n- `content` (string, required): Content of the message\n- `importance` (string, optional): Importance level (\"low\", \"medium\", \"high\", \"critical\"), defaults to \"low\"\n- `metadata` (object, optional): Additional metadata for the message\n\n**Returns:**\n\n- Object with status and timestamp\n\n**Example:**\n\n```javascript\n// Store a user message\nconst result = await mcp_cursor10x_storeUserMessage({\n  content: \"We need to implement authentication for our API\",\n  importance: \"high\",\n  metadata: {\n    topic: \"authentication\",\n    priority: 1,\n  },\n});\n// Result: {\n//   \"status\": \"ok\",\n//   \"timestamp\": 1681567845123\n// }\n```\n\n#### `mcp_cursor10x_storeAssistantMessage`\n\nStores an assistant message in the short-term memory system.\n\n**Parameters:**\n\n- `content` (string, required): Content of the message\n- `importance` (string, optional): Importance level (\"low\", \"medium\", \"high\", \"critical\"), defaults to \"low\"\n- `metadata` (object, optional): Additional metadata for the message\n\n**Returns:**\n\n- Object with status and timestamp\n\n**Example:**\n\n```javascript\n// Store an assistant message\nconst result = await mcp_cursor10x_storeAssistantMessage({\n  content: \"I recommend implementing JWT authentication with refresh tokens\",\n  importance: \"medium\",\n  metadata: {\n    topic: \"authentication\",\n    contains_recommendation: true,\n  },\n});\n// Result: {\n//   \"status\": \"ok\",\n//   \"timestamp\": 1681567870456\n// }\n```\n\n#### `mcp_cursor10x_trackActiveFile`\n\nTracks an active file being accessed or modified by the user.\n\n**Parameters:**\n\n- `filename` (string, required): Path to the file being tracked\n- `action` (string, required): Action performed on the file (open, edit, close, etc.)\n- `metadata` (object, optional): Additional metadata for the tracking event\n\n**Returns:**\n\n- Object with status, filename, action and timestamp\n\n**Example:**\n\n```javascript\n// Track an active file\nconst result = await mcp_cursor10x_trackActiveFile({\n  filename: \"src/auth/jwt.js\",\n  action: \"edit\",\n  metadata: {\n    changes: \"Added refresh token functionality\",\n  },\n});\n// Result: {\n//   \"status\": \"ok\",\n//   \"filename\": \"src/auth/jwt.js\",\n//   \"action\": \"edit\",\n//   \"timestamp\": 1681567900789\n// }\n```\n\n#### `mcp_cursor10x_getRecentMessages`\n\nRetrieves recent messages from the short-term memory.\n\n**Parameters:**\n\n- `limit` (number, optional): Maximum number of messages to retrieve, defaults to 10\n- `importance` (string, optional): Filter by importance level\n\n**Returns:**\n\n- Object with status and array of messages\n\n**Example:**\n\n```javascript\n// Get recent high importance messages\nconst messages = await mcp_cursor10x_getRecentMessages({\n  limit: 5,\n  importance: \"high\",\n});\n// Result: {\n//   \"status\": \"ok\",\n//   \"messages\": [\n//     {\n//       \"id\": 42,\n//       \"role\": \"user\",\n//       \"content\": \"We need to implement authentication for our API\",\n//       \"created_at\": \"2023-04-15T14:30:45.123Z\",\n//       \"importance\": \"high\",\n//       \"metadata\": {\"topic\": \"authentication\", \"priority\": 1}\n//     },\n//     ...\n//   ]\n// }\n```\n\n#### `mcp_cursor10x_getActiveFiles`\n\nRetrieves active files from the short-term memory.\n\n**Parameters:**\n\n- `limit` (number, optional): Maximum number of files to retrieve, defaults to 10\n\n**Returns:**\n\n- Object with status and array of active files\n\n**Example:**\n\n```javascript\n// Get recent active files\nconst files = await mcp_cursor10x_getActiveFiles({\n  limit: 3,\n});\n// Result: {\n//   \"status\": \"ok\",\n//   \"files\": [\n//     {\n//       \"id\": 15,\n//       \"filename\": \"src/auth/jwt.js\",\n//       \"last_accessed\": \"2023-04-15T14:30:45.123Z\",\n//       \"metadata\": {\"changes\": \"Added refresh token functionality\"}\n//     },\n//     ...\n//   ]\n// }\n```\n\n### Long-Term Memory Tools\n\n#### `mcp_cursor10x_storeMilestone`\n\nStores a project milestone in the long-term memory.\n\n**Parameters:**\n\n- `title` (string, required): Title of the milestone\n- `description` (string, required): Description of the milestone\n- `importance` (string, optional): Importance level, defaults to \"medium\"\n- `metadata` (object, optional): Additional metadata for the milestone\n\n**Returns:**\n\n- Object with status, title, and timestamp\n\n**Example:**\n\n```javascript\n// Store a project milestone\nconst result = await mcp_cursor10x_storeMilestone({\n  title: \"Authentication System Implementation\",\n  description:\n    \"Implemented JWT authentication with refresh tokens and proper error handling\",\n  importance: \"high\",\n  metadata: {\n    version: \"1.0.0\",\n    files_affected: [\"src/auth/jwt.js\", \"src/middleware/auth.js\"],\n  },\n});\n// Result: {\n//   \"status\": \"ok\",\n//   \"title\": \"Authentication System Implementation\",\n//   \"timestamp\": 1681568000123\n// }\n```\n\n#### `mcp_cursor10x_storeDecision`\n\nStores a project decision in the long-term memory.\n\n**Parameters:**\n\n- `title` (string, required): Title of the decision\n- `content` (string, required): Content of the decision\n- `reasoning` (string, optional): Reasoning behind the decision\n- `importance` (string, optional): Importance level, defaults to \"medium\"\n- `metadata` (object, optional): Additional metadata for the decision\n\n**Returns:**\n\n- Object with status, title, and timestamp\n\n**Example:**\n\n```javascript\n// Store a project decision\nconst result = await mcp_cursor10x_storeDecision({\n  title: \"JWT for Authentication\",\n  content: \"Use JWT tokens for API authentication with refresh token rotation\",\n  reasoning:\n    \"JWTs provide stateless authentication with good security and performance characteristics\",\n  importance: \"high\",\n  metadata: {\n    alternatives_considered: [\"Session-based auth\", \"OAuth2\"],\n    decision_date: \"2023-04-15\",\n  },\n});\n// Result: {\n//   \"status\": \"ok\",\n//   \"title\": \"JWT for Authentication\",\n//   \"timestamp\": 1681568100456\n// }\n```\n\n#### `mcp_cursor10x_storeRequirement`\n\nStores a project requirement in the long-term memory.\n\n**Parameters:**\n\n- `title` (string, required): Title of the requirement\n- `content` (string, required): Content of the requirement\n- `importance` (string, optional): Importance level, defaults to \"medium\"\n- `metadata` (object, optional): Additional metadata for the requirement\n\n**Returns:**\n\n- Object with status, title, and timestamp\n\n**Example:**\n\n```javascript\n// Store a project requirement\nconst result = await mcp_cursor10x_storeRequirement({\n  title: \"Secure Authentication\",\n  content:\n    \"System must implement secure authentication with password hashing, rate limiting, and token rotation\",\n  importance: \"critical\",\n  metadata: {\n    source: \"security audit\",\n    compliance: [\"OWASP Top 10\", \"GDPR\"],\n  },\n});\n// Result: {\n//   \"status\": \"ok\",\n//   \"title\": \"Secure Authentication\",\n//   \"timestamp\": 1681568200789\n// }\n```\n\n### Episodic Memory Tools\n\n#### `mcp_cursor10x_recordEpisode`\n\nRecords an episode (action) in the episodic memory.\n\n**Parameters:**\n\n- `actor` (string, required): Actor performing the action (user, assistant, system)\n- `action` (string, required): Type of action performed\n- `content` (string, required): Content or details of the action\n- `importance` (string, optional): Importance level, defaults to \"low\"\n- `context` (string, optional): Context for the episode\n\n**Returns:**\n\n- Object with status, actor, action, and timestamp\n\n**Example:**\n\n```javascript\n// Record an episode\nconst result = await mcp_cursor10x_recordEpisode({\n  actor: \"assistant\",\n  action: \"implementation\",\n  content: \"Created JWT authentication middleware with token verification\",\n  importance: \"medium\",\n  context: \"authentication\",\n});\n// Result: {\n//   \"status\": \"ok\",\n//   \"actor\": \"assistant\",\n//   \"action\": \"implementation\",\n//   \"timestamp\": 1681568300123\n// }\n```\n\n#### `mcp_cursor10x_getRecentEpisodes`\n\nRetrieves recent episodes from the episodic memory.\n\n**Parameters:**\n\n- `limit` (number, optional): Maximum number of episodes to retrieve, defaults to 10\n- `context` (string, optional): Filter by context\n\n**Returns:**\n\n- Object with status and array of episodes\n\n**Example:**\n\n```javascript\n// Get recent episodes in the authentication context\nconst episodes = await mcp_cursor10x_getRecentEpisodes({\n  limit: 5,\n  context: \"authentication\",\n});\n// Result: {\n//   \"status\": \"ok\",\n//   \"episodes\": [\n//     {\n//       \"id\": 87,\n//       \"actor\": \"assistant\",\n//       \"action\": \"implementation\",\n//       \"content\": \"Created JWT authentication middleware with token verification\",\n//       \"timestamp\": \"2023-04-15T14:45:00.123Z\",\n//       \"importance\": \"medium\",\n//       \"context\": \"authentication\"\n//     },\n//     ...\n//   ]\n// }\n```\n\n### Vector-Based Memory Tools\n\n#### `mcp_cursor10x_manageVector`\n\nUnified tool for managing vector embeddings with operations for store, search, update, and delete.\n\n**Parameters:**\n\n- `operation` (string, required): Operation to perform (\"store\", \"search\", \"update\", \"delete\")\n- `contentId` (number, optional): ID of the content this vector represents (for store, update, delete)\n- `contentType` (string, optional): Type of content (\"message\", \"file\", \"snippet\", etc.)\n- `vector` (array, optional): Vector data as array of numbers (for store, update) or query vector (for search)\n- `vectorId` (number, optional): ID of the vector to update or delete\n- `limit` (number, optional): Maximum number of results for search operation, defaults to 10\n- `threshold` (number, optional): Similarity threshold for search operation, defaults to 0.7\n- `metadata` (object, optional): Additional info about the vector\n\n**Returns:**\n\n- Object with status and operation results\n\n**Example:**\n\n```javascript\n// Store a vector embedding\nconst result = await mcp_cursor10x_manageVector({\n  operation: \"store\",\n  contentId: 42,\n  contentType: \"message\",\n  vector: [0.1, 0.2, 0.3, ...], // 128-dimensional vector\n  metadata: {\n    topic: \"authentication\",\n    language: \"en\"\n  }\n});\n// Result: {\n//   \"status\": \"ok\",\n//   \"operation\": \"store\",\n//   \"vectorId\": 15,\n//   \"timestamp\": 1681570000123\n// }\n\n// Search for similar vectors\nconst searchResult = await mcp_cursor10x_manageVector({\n  operation: \"search\",\n  vector: [0.1, 0.2, 0.3, ...], // query vector\n  contentType: \"snippet\", // optional filter\n  limit: 5,\n  threshold: 0.8\n});\n// Result: {\n//   \"status\": \"ok\",\n//   \"operation\": \"search\",\n//   \"results\": [\n//     {\n//       \"vectorId\": 10,\n//       \"contentId\": 30,\n//       \"contentType\": \"snippet\",\n//       \"similarity\": 0.92,\n//       \"metadata\": { ... }\n//     },\n//     ...\n//   ]\n// }\n```\n\n## Database Schema\n\nThe memory system automatically creates and maintains the following database tables:\n\n- `messages`: Stores user and assistant messages\n\n  - `id`: Unique identifier\n  - `timestamp`: Creation timestamp\n  - `role`: Message role (user/assistant)\n  - `content`: Message content\n  - `importance`: Importance level\n  - `archived`: Whether the message is archived\n\n- `active_files`: Tracks file activity\n\n  - `id`: Unique identifier\n  - `filename`: Path to the file\n  - `action`: Last action performed\n  - `last_accessed`: Timestamp of last access\n\n- `milestones`: Records project milestones\n\n  - `id`: Unique identifier\n  - `title`: Milestone title\n  - `description`: Detailed description\n  - `timestamp`: Creation timestamp\n  - `importance`: Importance level\n\n- `decisions`: Stores project decisions\n\n  - `id`: Unique identifier\n  - `title`: Decision title\n  - `content`: Decision content\n  - `reasoning`: Decision reasoning\n  - `timestamp`: Creation timestamp\n  - `importance`: Importance level\n\n- `requirements`: Maintains project requirements\n\n  - `id`: Unique identifier\n  - `title`: Requirement title\n  - `content`: Requirement content\n  - `timestamp`: Creation timestamp\n  - `importance`: Importance level\n\n- `episodes`: Chronicles actions and events\n\n  - `id`: Unique identifier\n  - `timestamp`: Creation timestamp\n  - `actor`: Actor performing the action\n  - `action`: Type of action\n  - `content`: Action details\n  - `importance`: Importance level\n  - `context`: Action context\n\n- `vectors`: Stores vector embeddings for semantic search\n\n  - `id`: Unique identifier\n  - `content_id`: ID of the referenced content\n  - `content_type`: Type of content (message, file, snippet)\n  - `vector`: Binary representation of the embedding vector\n  - `metadata`: Additional metadata for the vector\n\n- `code_files`: Tracks indexed code files\n\n  - `id`: Unique identifier\n  - `file_path`: Path to the file\n  - `language`: Programming language\n  - `last_indexed`: Timestamp of last indexing\n  - `metadata`: Additional file metadata\n\n- `code_snippets`: Stores extracted code structures\n  - `id`: Unique identifier\n  - `file_id`: Reference to the parent file\n  - `start_line`: Starting line number\n  - `end_line`: Ending line number\n  - `symbol_type`: Type of code structure (function, class, variable)\n  - `content`: The code snippet content\n\n## Example Workflows\n\n### Optimized Conversation Start\n\n```javascript\n// Initialize conversation with a single tool call\n// This replaces the need for three separate calls at the start of the conversation\nconst result = await mcp_cursor10x_initConversation({\n  content: \"I need help implementing authentication in my React app\",\n  importance: \"high\",\n});\n\n// Display the banner to the user\nconsole.log(\"Memory System Status:\", result.display.banner);\n\n// Use the context internally (do not show to user)\nconst context = result.internal.context;\n// Use context for more informed assistance\n```\n\n### Starting a New Session (Alternative Method)\n\n```javascript\n// Generate a memory banner at the start\nmcp_cursor10x_generateBanner({});\n\n// Get comprehensive context\nmcp_cursor10x_getComprehensiveContext({});\n\n// Store the user message\nmcp_cursor10x_storeUserMessage({\n  content: \"I need help with authentication\",\n  importance: \"high\",\n});\n```\n\n### Tracking User Activity\n\n```javascript\n// Track an active file\nawait mcp_cursor10x_trackActiveFile({\n  filename: \"src/auth/jwt.js\",\n  action: \"edit\",\n});\n```\n\n## Troubleshooting\n\n### Common Issues\n\n1. **Database Connection Problems**\n\n   - Verify your Turso database URL and authentication token are correct\n   - Check network connectivity to the Turso service\n   - Verify firewall settings allow the connection\n\n2. **Missing Data**\n\n   - Check that data was stored with appropriate importance level\n   - Verify the retrieval query parameters (limit, filters)\n   - Check the database health with `mcp_cursor10x_checkHealth()`\n\n3. **Performance Issues**\n   - Monitor memory statistics with `mcp_cursor10x_getMemoryStats()`\n   - Consider archiving old data if database grows too large\n   - Optimize retrieval by using more specific filters\n\n### Diagnostic Steps\n\n1. Check system health:\n\n   ```javascript\n   const health = await mcp_cursor10x_checkHealth({});\n   console.log(\"System Health:\", health);\n   ```\n\n2. Verify memory statistics:\n\n   ```javascript\n   const stats = await mcp_cursor10x_getMemoryStats({});\n   console.log(\"Memory Stats:\", stats);\n   ```\n\n3. Generate a status banner:\n   ```javascript\n   const banner = await mcp_cursor10x_generateBanner({});\n   console.log(\"Memory Banner:\", banner);\n   ```\n\n## Importance Levels\n\nWhen storing items in memory, use appropriate importance levels:\n\n- **low**: General information, routine operations, everyday conversations\n- **medium**: Useful context, standard work items, regular features\n- **high**: Critical decisions, major features, important architecture elements\n- **critical**: Core architecture, security concerns, data integrity issues\n\n## License\n\nMIT\n",
      "npm_url": "https://www.npmjs.com/package/cursor10x-mcp",
      "npm_downloads": 1339,
      "keywords": [
        "cursor10x",
        "memory",
        "workflows",
        "project context",
        "memory management",
        "cursor10x mcp"
      ],
      "category": "memory-management"
    },
    "alioshr--memory-bank-mcp": {
      "owner": "alioshr",
      "name": "memory-bank-mcp",
      "url": "https://github.com/alioshr/memory-bank-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/alioshr.webp",
      "description": "Manage project memory banks remotely and efficiently, enabling streamlined access and manipulation of memory data.",
      "stars": 690,
      "forks": 65,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T05:26:34Z",
      "readme_content": "# Memory Bank MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@alioshr/memory-bank-mcp)](https://smithery.ai/server/@alioshr/memory-bank-mcp)\n[![npm version](https://badge.fury.io/js/%40allpepper%2Fmemory-bank-mcp.svg)](https://www.npmjs.com/package/@allpepper/memory-bank-mcp)\n[![npm downloads](https://img.shields.io/npm/dm/@allpepper/memory-bank-mcp.svg)](https://www.npmjs.com/package/@allpepper/memory-bank-mcp)\n\n<a href=\"https://glama.ai/mcp/servers/ir18x1tixp\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/ir18x1tixp/badge\" alt=\"Memory Bank Server MCP server\" /></a>\n\nA Model Context Protocol (MCP) server implementation for remote memory bank management, inspired by [Cline Memory Bank](https://github.com/nickbaumann98/cline_docs/blob/main/prompting/custom%20instructions%20library/cline-memory-bank.md).\n\n## Overview\n\nThe Memory Bank MCP Server transforms traditional file-based memory banks into a centralized service that:\n\n- Provides remote access to memory bank files via MCP protocol\n- Enables multi-project memory bank management\n- Maintains consistent file structure and validation\n- Ensures proper isolation between project memory banks\n\n## Features\n\n- **Multi-Project Support**\n\n  - Project-specific directories\n  - File structure enforcement\n  - Path traversal prevention\n  - Project listing capabilities\n  - File listing per project\n\n- **Remote Accessibility**\n\n  - Full MCP protocol implementation\n  - Type-safe operations\n  - Proper error handling\n  - Security through project isolation\n\n- **Core Operations**\n  - Read/write/update memory bank files\n  - List available projects\n  - List files within projects\n  - Project existence validation\n  - Safe read-only operations\n\n## Installation\n\nTo install Memory Bank Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@alioshr/memory-bank-mcp):\n\n```bash\nnpx -y @smithery/cli install @alioshr/memory-bank-mcp --client claude\n```\n\nThis will set up the MCP server configuration automatically. Alternatively, you can configure the server manually as described in the Configuration section below.\n\n## Quick Start\n\n1. Configure the MCP server in your settings (see Configuration section below)\n2. Start using the memory bank tools in your AI assistant\n\n## Using with Cline/Roo Code\n\nThe memory bank MCP server needs to be configured in your Cline MCP settings file. The location depends on your setup:\n\n- For Cline extension: `~/Library/Application Support/Cursor/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json`\n- For Roo Code VS Code extension: `~/Library/Application Support/Code/User/globalStorage/rooveterinaryinc.roo-cline/settings/mcp_settings.json`\n\nAdd the following configuration to your MCP settings:\n\n```json\n{\n  \"allpepper-memory-bank\": {\n    \"command\": \"npx\",\n    \"args\": [\"-y\", \"@allpepper/memory-bank-mcp\"],\n    \"env\": {\n      \"MEMORY_BANK_ROOT\": \"<path-to-bank>\"\n    },\n    \"disabled\": false,\n    \"autoApprove\": [\n      \"memory_bank_read\",\n      \"memory_bank_write\",\n      \"memory_bank_update\",\n      \"list_projects\",\n      \"list_project_files\"\n    ]\n  }\n}\n```\n\n### Configuration Details\n\n- `MEMORY_BANK_ROOT`: Directory where project memory banks will be stored (e.g., `/path/to/memory-bank`)\n- `disabled`: Set to `false` to enable the server\n- `autoApprove`: List of operations that don't require explicit user approval:\n  - `memory_bank_read`: Read memory bank files\n  - `memory_bank_write`: Create new memory bank files\n  - `memory_bank_update`: Update existing memory bank files\n  - `list_projects`: List available projects\n  - `list_project_files`: List files within a project\n\n## Using with Cursor\n\nFor Cursor, open the settings -> features -> add MCP server -> add the following:\n\n```shell\nenv MEMORY_BANK_ROOT=<path-to-bank> npx -y @allpepper/memory-bank-mcp@latest\n```\n## Using with Claude\n\n- Claude desktop config file: `~/Library/Application Support/Claude/claude_desktop_config.json`\n- Claude Code config file:  `~/.claude.json`\n\n1. Locate the config file\n3. Locate the property called `mcpServers`\n4. Paste this:\n\n```\n \"allPepper-memory-bank\": {\n          \"type\": \"stdio\",\n          \"command\": \"npx\",\n          \"args\": [\n            \"-y\",\n            \"@allpepper/memory-bank-mcp@latest\"\n          ],\n          \"env\": {\n            \"MEMORY_BANK_ROOT\": \"YOUR PATH\"\n          }\n        }\n```\n\n## Custom AI instructions\n\nThis section contains the instructions that should be pasted on the AI custom instructions, either for Cline, Claude or Cursor, or any other MCP client. You should copy and paste these rules. For reference, see [custom-instructions.md](custom-instructions.md) which contains these rules.\n\n## Development\n\nBasic development commands:\n\n```bash\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n\n# Run tests\nnpm run test\n\n# Run tests in watch mode\nnpm run test:watch\n\n# Run the server directly with ts-node for quick testing\nnpm run dev\n```\n\n### Running with Docker\n\n1. Build the Docker image:\n\n    ```bash\n    docker build -t memory-bank-mcp:local .\n    ```\n\n2. Run the Docker container for testing:\n\n    ```bash\n    docker run -i --rm \\\n      -e MEMORY_BANK_ROOT=\"/mnt/memory_bank\" \\\n      -v /path/to/memory-bank:/mnt/memory_bank \\\n      --entrypoint /bin/sh \\\n      memory-bank-mcp:local \\\n      -c \"ls -la /mnt/memory_bank\"\n    ```\n\n3. Add MCP configuration, example for Roo Code:\n\n    ```json\n    \"allpepper-memory-bank\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\", \"-i\", \"--rm\",\n        \"-e\", \n        \"MEMORY_BANK_ROOT\",\n        \"-v\", \n        \"/path/to/memory-bank:/mnt/memory_bank\",\n        \"memory-bank-mcp:local\"\n      ],\n      \"env\": {\n        \"MEMORY_BANK_ROOT\": \"/mnt/memory_bank\"\n      },\n      \"disabled\": false,\n      \"alwaysAllow\": [\n        \"list_projects\",\n        \"list_project_files\",\n        \"memory_bank_read\",\n        \"memory_bank_update\",\n        \"memory_bank_write\"\n      ]\n    }\n    ```\n\n## Contributing\n\nContributions are welcome! Please follow these steps:\n\n1. Fork the repository\n2. Create a feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n\n### Development Guidelines\n\n- Use TypeScript for all new code\n- Maintain type safety across the codebase\n- Add tests for new features\n- Update documentation as needed\n- Follow existing code style and patterns\n\n### Testing\n\n- Write unit tests for new features\n- Include multi-project scenario tests\n- Test error cases thoroughly\n- Validate type constraints\n- Mock filesystem operations appropriately\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Acknowledgments\n\nThis project implements the memory bank concept originally documented in the [Cline Memory Bank](https://github.com/nickbaumann98/cline_docs/blob/main/prompting/custom%20instructions%20library/cline-memory-bank.md), extending it with remote capabilities and multi-project support.\n",
      "npm_url": "https://www.npmjs.com/package/memory-bank-mcp",
      "npm_downloads": 3190,
      "keywords": [
        "memory",
        "banks",
        "alioshr",
        "memory bank",
        "memory banks",
        "alioshr memory"
      ],
      "category": "memory-management"
    },
    "amotivv--memory-box-mcp": {
      "owner": "amotivv",
      "name": "memory-box-mcp",
      "url": "https://github.com/amotivv/memory-box-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/amotivv.webp",
      "description": "Manage and retrieve memories using advanced semantic search capabilities, enabling efficient organization and structured formatting of memory data. Integrate with Cline and Claude for enhanced memory management functionalities.",
      "stars": 7,
      "forks": 2,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-22T06:45:44Z",
      "readme_content": "<p align=\"center\">\n  <img src=\"https://storage.googleapis.com/amotivv-public/memory-box-logo.png\" alt=\"Memory Box Logo\" width=\"200\"/>\n</p>\n\n<h1 align=\"center\">Memory Box MCP Server</h1>\n\n<p align=\"center\">\n  Cline and Claude Desktop MCP integration for Memory Box - save, search, and format memories with semantic understanding\n</p>\n\n<p align=\"center\">\n  <a href=\"LICENSE\"><img src=\"https://img.shields.io/badge/License-MIT-blue.svg\" alt=\"License: MIT\"></a>\n</p>\n<p align=\"center\">\n  <a href=\"https://glama.ai/mcp/servers/wtbejx9zwc\">\n    <img alt=\"badge\" width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/wtbejx9zwc/badge\" />\n  </a>\n</p>\n\nThis MCP server provides tools for interacting with a Memory Box instance, allowing you to save and search memories using semantic search directly from Cline and Claude Desktop.\n\n## Related Projects\n\nThis MCP server is designed to work with [Memory Box](https://memorybox.dev), a semantic memory storage and retrieval system powered by vector embeddings.\n\nMemory Box provides the backend API that this MCP server communicates with, allowing you to:\n- Store memories with vector embeddings for semantic search\n- Organize memories into customizable buckets\n- Search for memories based on meaning, not just keywords\n- Retrieve memories with detailed context\n- Find semantically related memories\n- Track memory processing status\n\nFor more information about Memory Box, including how to set up your own instance, please visit the [Memory Box website](https://memorybox.dev).\n\n## Features\n\n- **Save Memories**: Save formatted memories to your Memory Box with source information and metadata\n- **Search Memories**: Search your memories using semantic search with pagination and date sorting\n- **Retrieve Memories**: Get all memories or memories from specific buckets\n- **Bucket Management**: Create and delete buckets for organizing memories\n- **Memory Management**: Update or delete existing memories\n- **Find Related Memories**: Discover semantically similar memories \n- **Check Memory Status**: Monitor the processing status of your memories\n- **Format Memories**: Format memories according to a structured system prompt\n- **Usage Statistics**: View your current plan, usage metrics, and resource limits\n\n## Installation\n\nThe server has been installed and configured for use with Cline. Note that you need a running Memory Box instance (either self-hosted or using the hosted version at memorybox.amotivv.ai) to use this MCP server.\n\n### Installing as Claude Desktop Extension (Recommended)\n\nThe easiest way to use Memory Box with Claude Desktop is through the Desktop Extension:\n\n1. Download the latest `memory-box.mcpb` file from the [releases page](https://github.com/amotivv/memory-box-mcp/releases)\n2. Open Claude Desktop\n3. Go to Settings > Extensions\n4. Click \"Install from file\"\n5. Select the downloaded `memory-box.mcpb` file\n6. Configure your Memory Box API token in the extension settings\n\nThe extension will automatically configure all necessary environment variables and tools.\n\n### Installing via Smithery\n\nTo install Memory Box MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@amotivv/memory-box-mcp):\n\n```bash\nnpx -y @smithery/cli install @amotivv/memory-box-mcp --client claude\n```\n\nTo complete the setup:\n\n1. Edit the Cline MCP settings file at:\n   ```\n   ~/Library/Application Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json\n   ```\n\n2. Add your Memory Box token to the `MEMORY_BOX_TOKEN` environment variable:\n   ```json\n   \"memory-box-mcp\": {\n     \"command\": \"node\",\n     \"args\": [\n       \"<path-to-repository>/build/index.js\"\n     ],\n     \"env\": {\n       \"MEMORY_BOX_API_URL\": \"https://memorybox.amotivv.ai\",\n       \"MEMORY_BOX_TOKEN\": \"your-token-here\",\n       \"DEFAULT_BUCKET\": \"General\"\n     },\n     \"disabled\": false,\n     \"autoApprove\": []\n   }\n   ```\n\n3. Optionally, you can customize the default bucket by changing the `DEFAULT_BUCKET` value.\n\n## Usage\n\nOnce configured, you can use the following tools in Cline:\n\n### Save Memory\n\nSave a memory to Memory Box with proper formatting:\n\n```\nUse the save_memory tool to save this information about vector databases: \"Vector databases like pgvector store and query high-dimensional vectors for semantic search applications.\"\n```\n\nParameters:\n- `text` (required): The memory content to save\n- `bucket_id` (optional): The bucket to save the memory to (default: \"General\")\n- `format` (optional): Whether to format the memory according to the system prompt (default: true)\n- `type` (optional): The type of memory (TECHNICAL, DECISION, SOLUTION, CONCEPT, REFERENCE, APPLICATION, FACT) for formatting (default: \"TECHNICAL\")\n- `source_type` (optional): Type of memory source (default: \"llm_plugin\")\n- `reference_data` (optional): Additional metadata about the memory source and context\n\n### Search Memories\n\nSearch for memories using semantic search:\n\n```\nUse the search_memories tool to find information about \"vector databases\"\n```\n\nParameters:\n- `query` (required): The search query\n- `debug` (optional): Include debug information in results (default: false)\n\n### Get All Memories\n\nRetrieve all memories:\n\n```\nUse the get_all_memories tool to show me all my saved memories\n```\n\n### Get Bucket Memories\n\nGet memories from a specific bucket:\n\n```\nUse the get_bucket_memories tool to show me memories in the \"Learning\" bucket\n```\n\nParameters:\n- `bucket_id` (required): The bucket to retrieve memories from\n\n### Format Memory\n\nFormat a text according to the memory system prompt without saving:\n\n```\nUse the format_memory tool to format this text: \"Vector databases like pgvector store and query high-dimensional vectors for semantic search applications.\"\n```\n\nParameters:\n- `text` (required): The text to format\n- `type` (optional): The type of memory (TECHNICAL, DECISION, SOLUTION, CONCEPT, REFERENCE, APPLICATION, FACT) (default: \"TECHNICAL\")\n\n### Get Related Memories\n\nFind semantically similar memories to a specific memory:\n\n```\nUse the get_related_memories tool with memory ID 123\n```\n\nParameters:\n- `memory_id` (required): The ID of the memory to find related memories for\n- `min_similarity` (optional): Minimum similarity threshold (0.0-1.0) for related memories (default: 0.7)\n\n### Check Memory Status\n\nCheck the processing status of a memory:\n\n```\nUse the check_memory_status tool with memory ID 123\n```\n\nParameters:\n- `memory_id` (required): The ID of the memory to check status for\n\n### Get Usage Stats\n\nRetrieve user usage statistics and plan information:\n\n```\nUse the get_usage_stats tool to show me my current plan and usage metrics\n```\n\nThis tool returns:\n- Current plan information (e.g., free, basic, professional, legacy)\n- User status and limit enforcement information\n- Current month usage metrics (store operations, search operations, API calls)\n- Data processing volume with human-readable formatting\n- Resource limits based on your plan (if applicable)\n- Operation breakdown by type\n\nNo parameters are required for this operation.\n\n### Get Buckets\n\nList all available buckets:\n\n```\nUse the get_buckets tool to show me all available buckets\n```\n\nThis tool returns a list of all buckets with their names, IDs, memory counts, and creation dates.\n\n### Create Bucket\n\nCreate a new bucket for organizing memories:\n\n```\nUse the create_bucket tool to create a bucket named \"Project Ideas\"\n```\n\nParameters:\n- `bucket_name` (required): Name of the bucket to create\n\n### Delete Bucket\n\nDelete an existing bucket:\n\n```\nUse the delete_bucket tool to delete the bucket named \"Old Notes\"\n```\n\nParameters:\n- `bucket_name` (required): Name of the bucket to delete\n- `force` (optional): Force deletion even if bucket contains memories (default: false)\n\n### Update Memory\n\nUpdate an existing memory's content, bucket, or metadata:\n\n```\nUse the update_memory tool to update memory ID 123 with new text: \"Updated information about vector databases\"\n```\n\nParameters:\n- `memory_id` (required): The ID of the memory to update\n- `text` (optional): New text content for the memory\n- `bucket_id` (optional): New bucket for the memory\n- `reference_data` (optional): Updated reference data including relationships\n\n### Delete Memory\n\nDelete a specific memory:\n\n```\nUse the delete_memory tool to delete memory ID 123\n```\n\nParameters:\n- `memory_id` (required): The ID of the memory to delete\n\n## Customization\n\n### System Prompt Customization\n\nThe Memory Box MCP server uses a system prompt to format memories according to specific guidelines. You can customize this prompt to change how memories are formatted.\n\n#### Default System Prompt\n\nThe default system prompt includes formatting guidelines for different types of memories:\n\n```\nYou are a helpful AI assistant. When storing memories with Memory Box, follow these enhanced formatting guidelines:\n\n1. STRUCTURE: Format memories based on the type of information:\n   - TECHNICAL: \"TECHNICAL - [Brief topic]: [Concise explanation with specific details]\"\n   - DECISION: \"DECISION - [Brief topic]: [Decision made] because [rationale]. Alternatives considered: [options].\"\n   - SOLUTION: \"SOLUTION - [Problem summary]: [Implementation details that solved the issue]\"\n   - CONCEPT: \"CONCEPT - [Topic]: [Clear explanation of the concept with examples]\"\n   - REFERENCE: \"REFERENCE - [Topic]: [URL, tool name, or resource] for [specific purpose]\"\n   - APPLICATION: \"APPLICATION - [App name]: [User-friendly description] followed by [technical implementation details]\"\n\n2. FORMATTING GUIDELINES:\n   - CREATE FOCUSED MEMORIES: Each memory should contain a single clear concept or topic\n   - USE DIVERSE TERMINOLOGY: Include both technical terms AND user-friendly alternatives\n   - INCLUDE SEARCHABLE KEYWORDS: Begin with common terms a user might search for\n   - BALANCE DETAIL LEVELS: Include both high-level descriptions and key technical details\n   - LENGTH: Keep memories between 50-150 words\n   - ALWAYS include the current date in YYYY-MM-DD format\n\n3. MEMORY STORAGE PARAMETERS:\n   - Use the \"text\" parameter for your formatted memory content\n   - Set \"source_type\" to \"llm_plugin\"\n   - Include appropriate \"reference_data\" with source information and context\n\n4. REFERENCE DATA STRUCTURE:\n   - source.platform: Identify your platform (e.g., \"claude_desktop\", \"cline\")\n   - source.type: Always set to \"llm_plugin\"\n   - source.version: Optional version information\n   - context.conversation_id: Include when available to link related conversation memories\n   - context.message_id: Optional identifier for the specific message\n\n5. SPECIAL FORMATS:\n   - For user facts, preferences, or personal details: \"YYYY-MM-DD: FACT: [User] [specific preference/attribute/information]\"\n   - For reference materials: Include specific details about where to find the information\n\n6. RELATED MEMORIES: After finding memories with search, check if there are related memories using the get_related_memories tool with the memory_id from search results. Present these additional memories to provide the user with more context.\n\n7. RETRIEVAL CONSIDERATION: Before storing an important memory, consider: \"What search terms might someone use to find this information later?\" and ensure those terms are included.\n```\n\n#### How to Customize the System Prompt\n\nTo customize the system prompt:\n\n1. Edit the Cline MCP settings file at:\n   ```\n   ~/Library/Application Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json\n   ```\n\n2. Add your custom system prompt to the `SYSTEM_PROMPT` environment variable:\n   ```json\n   \"memory-box-mcp\": {\n     \"command\": \"node\",\n     \"args\": [\n       \"<path-to-repository>/build/index.js\"\n     ],\n     \"env\": {\n       \"MEMORY_BOX_API_URL\": \"https://your-memory-box-instance\",\n       \"MEMORY_BOX_TOKEN\": \"your-token-here\",\n       \"DEFAULT_BUCKET\": \"General\",\n       \"SYSTEM_PROMPT\": \"Your custom system prompt here...\"\n     },\n     \"disabled\": false,\n     \"autoApprove\": []\n   }\n   ```\n\n   A template file is provided at `<path-to-repository>/system-prompt-template.txt` that you can copy and modify.\n\n3. Restart Cline to apply the changes\n\n#### System Prompt Helper\n\nThe Memory Box MCP server includes a helper script for managing the system prompt:\n\n```bash\n# View the current system prompt\ncd <path-to-repository>\nnpm run prompt-helper -- view\n\n# Reset to the default system prompt\ncd <path-to-repository>\nnpm run prompt-helper -- reset\n\n# Validate a custom system prompt\ncd <path-to-repository>\nnpm run prompt-helper -- validate\n```\n\n### Other Configuration Options\n\nYou can also customize these environment variables:\n\n- `MEMORY_BOX_API_URL`: The URL of your Memory Box instance\n- `MEMORY_BOX_TOKEN`: Your authentication token for Memory Box\n- `DEFAULT_BUCKET`: The default bucket to use when saving memories\n\n## Troubleshooting\n\nIf you encounter issues:\n\n1. Check that your Memory Box token is correctly configured\n2. Verify that your Memory Box instance is running and accessible\n3. Check the Cline logs for any error messages\n\n## Development\n\nTo make changes to the server:\n\n1. Edit the source code in `<path-to-repository>/src/`\n2. Rebuild the server:\n   ```\n   cd <path-to-repository>\n   npm run build\n   ```\n3. Restart Cline to apply the changes\n\n### Building the Desktop Extension\n\nTo build the Desktop Extension package:\n\n1. Install dependencies:\n   ```\n   npm install\n   ```\n\n2. Build the extension:\n   ```\n   npm run build-extension\n   ```\n\n3. The built extension will be available at `dist/memory-box.mcpb`\n\n### Release Process\n\n1. Update version in `package.json`\n2. Update `CHANGELOG.md` with new changes\n3. Commit changes\n4. Create a new GitHub release\n5. Upload the `memory-box.mcpb` file as a release asset\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "memory",
        "memories",
        "amotivv",
        "amotivv memory",
        "memory management",
        "memory box"
      ],
      "category": "memory-management"
    },
    "basicmachines-co--basic-memory": {
      "owner": "basicmachines-co",
      "name": "basic-memory",
      "url": "https://github.com/basicmachines-co/basic-memory",
      "imageUrl": "/freedevtools/mcp/pfp/basicmachines-co.webp",
      "description": "Enables persistent knowledge management through natural language conversations with LLMs by reading and writing to local Markdown files. Facilitates contextual awareness across sessions while maintaining a user-controlled knowledge base with a simple local-first approach.",
      "stars": 1882,
      "forks": 116,
      "license": "GNU Affero General Public License v3.0",
      "language": "Python",
      "updated_at": "2025-10-03T06:31:12Z",
      "readme_content": "[![License: AGPL v3](https://img.shields.io/badge/License-AGPL_v3-blue.svg)](https://www.gnu.org/licenses/agpl-3.0)\n[![PyPI version](https://badge.fury.io/py/basic-memory.svg)](https://badge.fury.io/py/basic-memory)\n[![Python 3.12+](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)\n[![Tests](https://github.com/basicmachines-co/basic-memory/workflows/Tests/badge.svg)](https://github.com/basicmachines-co/basic-memory/actions)\n[![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json)](https://github.com/astral-sh/ruff)\n![](https://badge.mcpx.dev?type=server 'MCP Server')\n![](https://badge.mcpx.dev?type=dev 'MCP Dev')\n[![smithery badge](https://smithery.ai/badge/@basicmachines-co/basic-memory)](https://smithery.ai/server/@basicmachines-co/basic-memory)\n\n# Basic Memory\n\nBasic Memory lets you build persistent knowledge through natural conversations with Large Language Models (LLMs) like\nClaude, while keeping everything in simple Markdown files on your computer. It uses the Model Context Protocol (MCP) to\nenable any compatible LLM to read and write to your local knowledge base.\n\n- Website: https://basicmachines.co\n- Documentation: https://memory.basicmachines.co\n\n## Pick up your conversation right where you left off\n\n- AI assistants can load context from local files in a new conversation\n- Notes are saved locally as Markdown files in real time\n- No project knowledge or special prompting required\n\nhttps://github.com/user-attachments/assets/a55d8238-8dd0-454a-be4c-8860dbbd0ddc\n\n## Quick Start\n\n```bash\n# Install with uv (recommended)\nuv tool install basic-memory\n\n# Configure Claude Desktop (edit ~/Library/Application Support/Claude/claude_desktop_config.json)\n# Add this to your config:\n{\n  \"mcpServers\": {\n    \"basic-memory\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"basic-memory\",\n        \"mcp\"\n      ]\n    }\n  }\n}\n# Now in Claude Desktop, you can:\n# - Write notes with \"Create a note about coffee brewing methods\"\n# - Read notes with \"What do I know about pour over coffee?\"\n# - Search with \"Find information about Ethiopian beans\"\n\n```\n\nYou can view shared context via files in `~/basic-memory` (default directory location).\n\n### Alternative Installation via Smithery\n\nYou can use [Smithery](https://smithery.ai/server/@basicmachines-co/basic-memory) to automatically configure Basic\nMemory for Claude Desktop:\n\n```bash\nnpx -y @smithery/cli install @basicmachines-co/basic-memory --client claude\n```\n\nThis installs and configures Basic Memory without requiring manual edits to the Claude Desktop configuration file. The\nSmithery server hosts the MCP server component, while your data remains stored locally as Markdown files.\n\n### Glama.ai\n\n<a href=\"https://glama.ai/mcp/servers/o90kttu9ym\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/o90kttu9ym/badge\" alt=\"basic-memory MCP server\" />\n</a>\n\n## Why Basic Memory?\n\nMost LLM interactions are ephemeral - you ask a question, get an answer, and everything is forgotten. Each conversation\nstarts fresh, without the context or knowledge from previous ones. Current workarounds have limitations:\n\n- Chat histories capture conversations but aren't structured knowledge\n- RAG systems can query documents but don't let LLMs write back\n- Vector databases require complex setups and often live in the cloud\n- Knowledge graphs typically need specialized tools to maintain\n\nBasic Memory addresses these problems with a simple approach: structured Markdown files that both humans and LLMs can\nread\nand write to. The key advantages:\n\n- **Local-first:** All knowledge stays in files you control\n- **Bi-directional:** Both you and the LLM read and write to the same files\n- **Structured yet simple:** Uses familiar Markdown with semantic patterns\n- **Traversable knowledge graph:** LLMs can follow links between topics\n- **Standard formats:** Works with existing editors like Obsidian\n- **Lightweight infrastructure:** Just local files indexed in a local SQLite database\n\nWith Basic Memory, you can:\n\n- Have conversations that build on previous knowledge\n- Create structured notes during natural conversations\n- Have conversations with LLMs that remember what you've discussed before\n- Navigate your knowledge graph semantically\n- Keep everything local and under your control\n- Use familiar tools like Obsidian to view and edit notes\n- Build a personal knowledge base that grows over time\n\n## How It Works in Practice\n\nLet's say you're exploring coffee brewing methods and want to capture your knowledge. Here's how it works:\n\n1. Start by chatting normally:\n\n```\nI've been experimenting with different coffee brewing methods. Key things I've learned:\n\n- Pour over gives more clarity in flavor than French press\n- Water temperature is critical - around 205°F seems best\n- Freshly ground beans make a huge difference\n```\n\n... continue conversation.\n\n2. Ask the LLM to help structure this knowledge:\n\n```\n\"Let's write a note about coffee brewing methods.\"\n```\n\nLLM creates a new Markdown file on your system (which you can see instantly in Obsidian or your editor):\n\n```markdown\n---\ntitle: Coffee Brewing Methods\npermalink: coffee-brewing-methods\ntags:\n- coffee\n- brewing\n---\n\n# Coffee Brewing Methods\n\n## Observations\n\n- [method] Pour over provides more clarity and highlights subtle flavors\n- [technique] Water temperature at 205°F (96°C) extracts optimal compounds\n- [principle] Freshly ground beans preserve aromatics and flavor\n\n## Relations\n\n- relates_to [[Coffee Bean Origins]]\n- requires [[Proper Grinding Technique]]\n- affects [[Flavor Extraction]]\n```\n\nThe note embeds semantic content and links to other topics via simple Markdown formatting.\n\n3. You see this file on your computer in real time in the current project directory (default `~/$HOME/basic-memory`).\n\n- Realtime sync can be enabled via running `basic-memory sync --watch`\n\n4. In a chat with the LLM, you can reference a topic:\n\n```\nLook at `coffee-brewing-methods` for context about pour over coffee\n```\n\nThe LLM can now build rich context from the knowledge graph. For example:\n\n```\nFollowing relation 'relates_to [[Coffee Bean Origins]]':\n- Found information about Ethiopian Yirgacheffe\n- Notes on Colombian beans' nutty profile\n- Altitude effects on bean characteristics\n\nFollowing relation 'requires [[Proper Grinding Technique]]':\n- Burr vs. blade grinder comparisons\n- Grind size recommendations for different methods\n- Impact of consistent particle size on extraction\n```\n\nEach related document can lead to more context, building a rich semantic understanding of your knowledge base.\n\nThis creates a two-way flow where:\n\n- Humans write and edit Markdown files\n- LLMs read and write through the MCP protocol\n- Sync keeps everything consistent\n- All knowledge stays in local files.\n\n## Technical Implementation\n\nUnder the hood, Basic Memory:\n\n1. Stores everything in Markdown files\n2. Uses a SQLite database for searching and indexing\n3. Extracts semantic meaning from simple Markdown patterns\n    - Files become `Entity` objects\n    - Each `Entity` can have `Observations`, or facts associated with it\n    - `Relations` connect entities together to form the knowledge graph\n4. Maintains the local knowledge graph derived from the files\n5. Provides bidirectional synchronization between files and the knowledge graph\n6. Implements the Model Context Protocol (MCP) for AI integration\n7. Exposes tools that let AI assistants traverse and manipulate the knowledge graph\n8. Uses memory:// URLs to reference entities across tools and conversations\n\nThe file format is just Markdown with some simple markup:\n\nEach Markdown file has:\n\n### Frontmatter\n\n```markdown\ntitle: <Entity title>\ntype: <The type of Entity> (e.g. note)\npermalink: <a uri slug>\n\n- <optional metadata> (such as tags) \n```\n\n### Observations\n\nObservations are facts about a topic.\nThey can be added by creating a Markdown list with a special format that can reference a `category`, `tags` using a\n\"#\" character, and an optional `context`.\n\nObservation Markdown format:\n\n```markdown\n- [category] content #tag (optional context)\n```\n\nExamples of observations:\n\n```markdown\n- [method] Pour over extracts more floral notes than French press\n- [tip] Grind size should be medium-fine for pour over #brewing\n- [preference] Ethiopian beans have bright, fruity flavors (especially from Yirgacheffe)\n- [fact] Lighter roasts generally contain more caffeine than dark roasts\n- [experiment] Tried 1:15 coffee-to-water ratio with good results\n- [resource] James Hoffman's V60 technique on YouTube is excellent\n- [question] Does water temperature affect extraction of different compounds differently?\n- [note] My favorite local shop uses a 30-second bloom time\n```\n\n### Relations\n\nRelations are links to other topics. They define how entities connect in the knowledge graph.\n\nMarkdown format:\n\n```markdown\n- relation_type [[WikiLink]] (optional context)\n```\n\nExamples of relations:\n\n```markdown\n- pairs_well_with [[Chocolate Desserts]]\n- grown_in [[Ethiopia]]\n- contrasts_with [[Tea Brewing Methods]]\n- requires [[Burr Grinder]]\n- improves_with [[Fresh Beans]]\n- relates_to [[Morning Routine]]\n- inspired_by [[Japanese Coffee Culture]]\n- documented_in [[Coffee Journal]]\n```\n\n## Using with VS Code\n\nAdd the following JSON block to your User Settings (JSON) file in VS Code. You can do this by pressing `Ctrl + Shift + P` and typing `Preferences: Open User Settings (JSON)`.\n\n```json\n{\n  \"mcp\": {\n    \"servers\": {\n      \"basic-memory\": {\n        \"command\": \"uvx\",\n        \"args\": [\"basic-memory\", \"mcp\"]\n      }\n    }\n  }\n}\n```\n\nOptionally, you can add it to a file called `.vscode/mcp.json` in your workspace. This will allow you to share the configuration with others.\n\n```json\n{\n  \"servers\": {\n    \"basic-memory\": {\n      \"command\": \"uvx\",\n      \"args\": [\"basic-memory\", \"mcp\"]\n    }\n  }\n}\n```\n\nYou can use Basic Memory with VS Code to easily retrieve and store information while coding.\n\n## Using with Claude Desktop\n\nBasic Memory is built using the MCP (Model Context Protocol) and works with the Claude desktop app (https://claude.ai/):\n\n1. Configure Claude Desktop to use Basic Memory:\n\nEdit your MCP configuration file (usually located at `~/Library/Application Support/Claude/claude_desktop_config.json`\nfor OS X):\n\n```json\n{\n  \"mcpServers\": {\n    \"basic-memory\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"basic-memory\",\n        \"mcp\"\n      ]\n    }\n  }\n}\n```\n\nIf you want to use a specific project (see [Multiple Projects](#multiple-projects) below), update your Claude Desktop\nconfig:\n\n```json\n{\n  \"mcpServers\": {\n    \"basic-memory\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"basic-memory\",\n        \"mcp\",\n        \"--project\",\n        \"your-project-name\"\n      ]\n    }\n  }\n}\n```\n\n2. Sync your knowledge:\n\n```bash\n# One-time sync of local knowledge updates\nbasic-memory sync\n\n# Run realtime sync process (recommended)\nbasic-memory sync --watch\n```\n\n3. In Claude Desktop, the LLM can now use these tools:\n\n```\nwrite_note(title, content, folder, tags) - Create or update notes\nread_note(identifier, page, page_size) - Read notes by title or permalink\nbuild_context(url, depth, timeframe) - Navigate knowledge graph via memory:// URLs\nsearch(query, page, page_size) - Search across your knowledge base\nrecent_activity(type, depth, timeframe) - Find recently updated information\ncanvas(nodes, edges, title, folder) - Generate knowledge visualizations\n```\n\n5. Example prompts to try:\n\n```\n\"Create a note about our project architecture decisions\"\n\"Find information about JWT authentication in my notes\"\n\"Create a canvas visualization of my project components\"\n\"Read my notes on the authentication system\"\n\"What have I been working on in the past week?\"\n```\n\n## Futher info\n\nSee the [Documentation](https://memory.basicmachines.co/) for more info, including:\n\n- [Complete User Guide](https://memory.basicmachines.co/docs/user-guide)\n- [CLI tools](https://memory.basicmachines.co/docs/cli-reference)\n- [Managing multiple Projects](https://memory.basicmachines.co/docs/cli-reference#project)\n- [Importing data from OpenAI/Claude Projects](https://memory.basicmachines.co/docs/cli-reference#import)\n\n## License\n\nAGPL-3.0\n\nContributions are welcome. See the [Contributing](CONTRIBUTING.md) guide for info about setting up the project locally\nand submitting PRs.\n\n## Star History\n\n<a href=\"https://www.star-history.com/#basicmachines-co/basic-memory&Date\">\n <picture>\n   <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=basicmachines-co/basic-memory&type=Date&theme=dark\" />\n   <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=basicmachines-co/basic-memory&type=Date\" />\n   <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=basicmachines-co/basic-memory&type=Date\" />\n </picture>\n</a>\n\nBuilt with ♥️ by Basic Machines",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "memory",
        "basicmachines",
        "conversations",
        "basic memory",
        "management basicmachines",
        "memory management"
      ],
      "category": "memory-management"
    },
    "bneil--mcp-memory-pouchdb": {
      "owner": "bneil",
      "name": "mcp-memory-pouchdb",
      "url": "https://github.com/bneil/mcp-memory-pouchdb",
      "imageUrl": "/freedevtools/mcp/pfp/bneil.webp",
      "description": "Manage and enhance interactions with contextual information using a robust knowledge graph. It captures, stores, and retrieves data seamlessly with PouchDB for improved consistency and organization by project-specific paths.",
      "stars": 4,
      "forks": 0,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-06-05T07:44:35Z",
      "readme_content": "# Memory Custom : PouchDB 🧠\n\n[![smithery badge](https://smithery.ai/badge/@bneil/mcp-memory-pouchdb)](https://smithery.ai/server/@bneil/mcp-memory-pouchdb)\n\nThis project adds new features to the Memory server offered by the MCP team. It allows for the creation and management of a knowledge graph that captures interactions via a language model (LLM). 🚀\n\nThis repo was forked from [https://github.com/BRO3886/mcp-memory-custom](https://github.com/BRO3886/mcp-memory-custom) which was a great starting point, thanks again for fixing timestamps. This repo's goal was more to fix the issue with an ever increasing json file for context.\n\n## New Features ✨\n\n### 1. PouchDB Integration 💾\n\n- The server now uses PouchDB for robust document-based storage\n- **Why?**: Better data consistency, built-in versioning, and improved performance for large datasets\n- Maintains file backup for compatibility\n\n### 2. Custom Memory Paths 📁\n\n- Users can now specify different memory file paths for various projects\n- **Why?**: This feature enhances organization and management of memory data, allowing for project-specific memory storage\n\n### 3. Timestamping ⏰\n\n- The server now generates timestamps for interactions\n- **Why?**: Timestamps enable tracking of when each memory was created or modified, providing better context and history for the stored data\n\n## Getting Started 🚀\n\n### Prerequisites 🔧\n\n- Node.js (version 16 or higher)\n- PouchDB (automatically installed as a dependency)\n\n### Installing via Smithery 📦\n\nTo install Knowledge Graph Memory Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@bneil/mcp-memory-pouchdb):\n\n```bash\nnpx -y @smithery/cli install @bneil/mcp-memory-pouchdb --client claude\n```\n\n### Installation 🛠️\n\n1. Clone the repository:\n\n   ```bash\n   git clone git@github.com:bneil/mcp-memory-pouchdb.git\n   cd mcp-memory-pouchdb\n   ```\n\n2. Install the dependencies:\n\n   ```bash\n   npm install\n   ```\n\n### Configuration ⚙️\n\nThe server requires two environment variables to be set:\n\n1. `MEMORY_FILE_PATH`: The absolute path where the memory backup file will be stored\n2. `POUCHDB_PATH`: The absolute path where the PouchDB database will be stored\n\nExample configuration in your `claude_desktop_config.json` / `.cursor/mcp.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"memory\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/mcp-memory-pouchdb/dist/index.js\"],\n      \"env\": {\n        \"MEMORY_FILE_PATH\": \"/path/to/custom/memory.json\",\n        \"POUCHDB_PATH\": \"/path/to/custom/pouchdb_directory\",\n        \"DISABLE_MEMORY_FILE\": \"true\"\n      }\n    }\n  }\n}\n```\n\nThe server will fail to start if either environment variable is not set. 🚫\n\nOptional environment variables:\n- `POUCHDB_OPTIONS`: JSON string of additional PouchDB configuration options\n- `DISABLE_MEMORY_FILE`: Set to \"true\" to disable saving to memory.json file (only use PouchDB for storage)\n\n### Running the Server 🚀\n\n#### Updating the mcp server json file 📝\n\nAdd this to your `claude_desktop_config.json` / `.cursor/mcp.json` file:\n\n```json\n{\n  \"mcpServers\": {\n    \"memory\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/mcp-memory-pouchdb/dist/index.js\"],\n      \"env\" : {\n        \"MEMORY_FILE_PATH\":\"/home/.../local_dbs/memory.json\",\n        \"POUCHDB_PATH\":\"/home/.../local_dbs/pouchdb\"\n      }\n    }\n  }\n}\n```\n\nSystem Prompt changes:\n\n```\nFollow these steps for each interaction:\n\n0. Memory Initialization:\n   - At startup, execute a read_graph function to initialize memory access\n   - If memory is empty, create a default entity for the user with basic placeholder info\n   - Run initialization sequence: read_graph → create_entities → read_graph\n\n1. User Identification:\n   - You should assume that you are interacting with default_user\n   - If you have not identified default_user, proactively try to do so\n\n2. Memory Retrieval:\n   - Always begin your chat by saying only \"Remembering...\" and retrieve all relevant information from your knowledge graph\n   - Always refer to your knowledge graph as your \"memory\"\n   - Verify memory access is functioning properly\n\n3. Memory Attention:\n   - While conversing with the user, be attentive to any new information that falls into these categories:\n     a) Basic Identity (age, gender, location, job title, education level, etc.)\n     b) Behaviors (interests, habits, etc.)\n     c) Preferences (communication style, preferred language, etc.)\n     d) Goals (goals, targets, aspirations, etc.)\n     e) Relationships (personal and professional relationships up to 3 degrees of separation)\n\n4. Memory Update:\n   - If any new information was gathered during the interaction, update your memory as follows:\n     a) Create entities for recurring organizations, people, and significant events, add timestamps to wherever required. You can get current timestamp via get_current_time\n     b) Connect them to the current entities using relations\n     c) Store facts about them as observations, add timestamps to observations via get_current_time\n\n5. Error Recovery:\n   - If memory retrieval fails, execute read_graph function immediately\n   - Log any memory access failures for debugging\n   - Continue the conversation with best available information\n\n6. Memory Validation:\n   - Periodically verify that memory access is functional by checking for core entities\n   - If validation fails, attempt reconnection via read_graph\n\nIMPORTANT: Provide a helpful and engaging response, asking relevant questions to encourage user engagement. Update the memory during the interaction, if required, based on the new information gathered (point 3).\n```\n\n#### Running the Server Locally 💻\n\nTo start the Knowledge Graph Memory Server, run:\n\n```bash\nnpm run build\nnode dist/index.js\n```\n\nThe server will listen for requests via standard input/output.\n\n## API Endpoints 🔌\n\nThe server exposes several tools that can be called with specific parameters:\n\n- **Get Current Time** ⏰\n- **Set Memory File Path** 📁\n- **Create Entities** ➕\n- **Create Relations** 🔗\n- **Add Observations** 📝\n- **Delete Entities** ❌\n- **Delete Observations** 🗑️\n- **Delete Relations** 🔗\n- **Read Graph** 📖\n- **Search Nodes** 🔍\n- **Open Nodes** 🔓\n\n## Acknowledgments 🙏\n\n- Inspired by the Memory server from Anthropic\n- Powered by PouchDB for robust data storage 💾\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "pouchdb",
        "memory",
        "manage",
        "memory pouchdb",
        "pouchdb manage",
        "seamlessly pouchdb"
      ],
      "category": "memory-management"
    },
    "boorich--mcp-human-loop": {
      "owner": "boorich",
      "name": "mcp-human-loop",
      "url": "https://github.com/boorich/mcp-human-loop",
      "imageUrl": "/freedevtools/mcp/pfp/boorich.webp",
      "description": "Manage human-agent collaboration by using a sequential scoring system to evaluate and determine the necessity of human intervention in AI operations based on complexity and sensitivity of requests.",
      "stars": 16,
      "forks": 4,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-09-28T18:50:24Z",
      "readme_content": "# MCP Human Loop Server\n\nA Model Context Protocol server that manages human-agent collaboration through a sequential scoring system.\n\n## Core Concept\n\nThis server acts as an intelligent middleware that determines when human intervention is necessary in AI agent operations. Instead of treating human involvement as a binary decision, it uses a sequential scoring system that evaluates multiple dimensions of a request before deciding if human input is required.\n\n## Scoring System\n\nThe server evaluates requests through a series of scoring gates. Each gate represents a specific dimension that might require human intervention. A request only proceeds to human review if it triggers threshold values in any of these dimensions:\n\n1. **Complexity Score**\n   - Evaluates if the task is too complex for autonomous agent handling\n   - Considers factors like number of steps, dependencies, and decision branches\n   - Example: Multi-step tasks with uncertain outcomes score higher\n\n2. **Permission Score**\n   - Assesses if the requested action requires human authorization\n   - Based on predefined permission levels and action types\n   - Example: Financial transactions above certain amounts require human approval\n\n3. **Risk Score**\n   - Measures potential impact and reversibility of actions\n   - Considers both direct and indirect consequences\n   - Example: Actions affecting multiple systems or user data score higher\n\n4. **Emotional Intelligence Score**\n   - Determines if the task requires human emotional understanding\n   - Evaluates context and user state\n   - Example: User frustration or sensitive situations trigger human involvement\n\n5. **Confidence Score**\n   - Reflects the agent's certainty about its proposed action\n   - Lower confidence triggers human review\n   - Example: Edge cases or unusual patterns lower confidence\n\n## Flow Logic\n\n1. Agent submits request to server\n2. Server evaluates scores in sequence\n3. If any score exceeds its threshold → Route to human\n4. If all scores pass → Allow autonomous agent action\n5. Track and log all decisions for system improvement\n\n## Benefits\n\n- **Efficiency**: Only truly necessary cases reach human operators\n- **Scalability**: Easy to add new scoring dimensions\n- **Tunability**: Thresholds can be adjusted based on experience\n- **Transparency**: Clear decision path for each human intervention\n- **Learning**: System improves through tracked outcomes\n\n## Future Improvements\n\n- Dynamic threshold adjustment based on outcome tracking\n- Machine learning integration for score calculation\n- Real-time threshold adjustment based on operator load\n- Integration with external risk assessment systems\n\n## Installation\n\n[Installation instructions to be added]\n\n## Usage\n\n[Usage examples to be added]\n\n## Contributing\n\n[Contribution guidelines to be added]\n\n## ToDo\n\nConversational Quality Monitoring\n\n- Assess the depth and constructiveness of dialogue\n- Detect repetitive or circular conversations\n- Identify when a conversation lacks meaningful progress\n\n\nCognitive Load Management\n\n- Evaluate the complexity of tasks or discussions\n- Warn when the cognitive demands exceed typical processing capabilities\n- Suggest breaking down complex topics or taking breaks\n\n\nLearning and Skill Development Tracking\n\n- Monitor the educational potential of conversations\n- Identify when a discussion moves beyond or falls short of a learner's current skill level\n- Recommend supplementary resources or adjust explanation complexity\n\n\nEmotional Intelligence and Sentiment Analysis\n\n- Detect potential emotional escalation in conversations\n- Identify when a discussion becomes overly emotional or unproductive\n- Suggest de-escalation strategies or communication adjustments\n\n\nCompliance and Ethical Boundary Monitoring\n\n- Proactively identify conversations approaching ethical boundaries\n- Detect potential violations of predefined communication guidelines\n- Provide early warnings about sensitive or potentially inappropriate content\n\n\nMulti-Agent Coordination\n\n- In scenarios with multiple AI agents or models\n- Determine when to escalate or hand off tasks between different AI capabilities\n- Optimize task allocation based on specialized skills\n\n\nResource Allocation and Performance Optimization\n\n- Assess computational complexity of ongoing tasks\n- Predict and manage computational resource requirements\n- Optimize system performance by intelligently routing or prioritizing tasks\n\n\nCross-Disciplinary Knowledge Integration\n\n- Detect when a conversation requires expertise from multiple domains\n- Identify knowledge gaps or areas needing interdisciplinary insights\n- Suggest bringing in additional contextual information or expert perspectives\n\n\nCreativity and Innovation Detection\n\n- Recognize when a conversation is generating novel ideas\n- Identify potential breakthrough thinking or unique problem-solving approaches\n- Encourage and highlight innovative thought patterns\n\n\nMeta-Cognitive Analysis\n\n- Analyze the reasoning and thought processes within a conversation\n- Detect logical fallacies or cognitive biases\n- Provide insights into the quality of reasoning and argumentation\n\n\nContextual Relevance in Research and Information Gathering\n\n- Evaluate the relevance and comprehensiveness of information collection\n- Detect when research is becoming too narrow or too broad\n- Suggest alternative approaches or additional sources\n\n\nPersonalization and Adaptive Communication\n\n- Learn and adapt communication styles based on interaction patterns\n- Detect user preferences and communication effectiveness\n- Dynamically adjust interaction strategies\n",
      "npm_url": "https://www.npmjs.com/package/mcp-human-loop",
      "npm_downloads": 108,
      "keywords": [
        "ai",
        "agent",
        "human",
        "intervention ai",
        "ai operations",
        "manage human"
      ],
      "category": "memory-management"
    },
    "bornpresident--Volatility-MCP-Server": {
      "owner": "bornpresident",
      "name": "Volatility-MCP-Server",
      "url": "https://github.com/bornpresident/Volatility-MCP-Server",
      "imageUrl": "/freedevtools/mcp/pfp/bornpresident.webp",
      "description": "Analyze memory dumps using natural language queries to facilitate forensic investigations, reducing the need for technical expertise while accelerating the analysis process and improving cybersecurity responses.",
      "stars": 22,
      "forks": 2,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-23T07:54:57Z",
      "readme_content": "# Volatility MCP Server\n\nA Model Context Protocol (MCP) server that integrates Volatility 3 memory forensics framework with Claude and other MCP-compatible LLMs.\n\n## Why This Matters\n\nIn India, digital forensic investigators face a massive backlog of cases due to the country's large population and rising cybercrime rates. This tool helps address this challenge by:\n\n- Allowing investigators to analyze memory dumps using simple natural language instead of complex commands\n- Reducing the technical expertise needed to perform memory forensics\n- Accelerating the analysis process through automation\n- Helping clear case backlogs and deliver faster results to the judicial system\n\nBy making memory forensics more accessible, this tool can significantly reduce the burden on forensic experts and improve cybersecurity response across India.\n\n## Overview\n\nThis project bridges the powerful memory forensics capabilities of the Volatility 3 Framework with Large Language Models (LLMs) through the Model Context Protocol (MCP). It allows you to perform memory forensics analysis using natural language by exposing Volatility plugins as MCP tools that can be invoked directly by Claude or other MCP-compatible LLMs.\n\n## Features\n\n- **Natural Language Memory Forensics**: Ask Claude to analyze memory dumps using natural language\n- **Process Analysis**: Examine running processes, parent-child relationships, and hidden processes\n- **Network Forensics**: Identify network connections in memory dumps\n- **Malware Detection**: Find potential code injection and other malicious artifacts\n- **DLL Analysis**: Examine loaded DLLs and modules\n- **File Objects**: Scan for file objects in memory\n- **Custom Plugins**: Run any Volatility plugin with custom arguments\n- **Memory Dump Discovery**: Automatically find memory dumps in a directory\n\n## Requirements\n\n- Python 3.10 or higher\n- Volatility 3 Framework\n- Claude Desktop or other MCP-compatible client\n- MCP Python SDK (`mcp` package)\n\n## Installation\n\n1. Clone this repository:\n   ```bash\n   git clone https://github.com/yourusername/volatility-mcp-server.git\n   ```\n\n2. Install the required Python packages:\n   ```bash\n   pip install mcp httpx\n   ```\n\n3. Configure the Volatility path in the script:\n   - Open `volatility_mcp_server.py` and update the `VOLATILITY_DIR` variable to point to your Volatility 3 installation path.\n\n4. Configure Claude Desktop:\n   - Open your Claude Desktop configuration file located at:\n     - Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n     - macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - Add the server configuration:\n   ```json\n   {\n     \"mcpServers\": {\n       \"volatility\": {\n         \"command\": \"python\",\n         \"args\": [\n           \"/path/to/volatility_mcp_server.py\"\n         ],\n         \"env\": {\n           \"PYTHONPATH\": \"/path/to/volatility3\"\n         }\n       }\n     }\n   }\n   ```\n   - Replace `/path/to/` with the actual path to your files.\n\n5. Restart Claude Desktop to apply the changes.\n\n## Usage\n\nAfter setup, you can simply ask Claude natural language questions about your memory dumps:\n\n- \"List all processes in the memory dump at C:\\path\\to\\dump.vmem\"\n- \"Show me the network connections in C:\\path\\to\\dump.vmem\"\n- \"Run malfind to check for code injection in the memory dump\"\n- \"What DLLs are loaded in process ID 4328?\"\n- \"Check for hidden processes in C:\\path\\to\\dump.vmem\"\n\n## Available Tools\n\nThe server exposes the following Volatility plugins as MCP tools:\n\n1. `list_available_plugins` - Shows all Volatility plugins you can use\n2. `get_image_info` - Provides information about a memory dump file\n3. `run_pstree` - Shows the process hierarchy\n4. `run_pslist` - Lists processes from the process list\n5. `run_psscan` - Scans for processes including ones that might be hidden\n6. `run_netscan` - Shows network connections in the memory dump\n7. `run_malfind` - Detects potential code injection\n8. `run_cmdline` - Shows command line arguments for processes\n9. `run_dlllist` - Lists loaded DLLs for processes\n10. `run_handles` - Shows file handles and other system handles\n11. `run_filescan` - Scans for file objects in memory\n12. `run_memmap` - Shows the memory map for a specific process\n13. `run_custom_plugin` - Run any Volatility plugin with custom arguments\n14. `list_memory_dumps` - Find memory dumps in a directory\n\n## Memory Forensics Workflow\n\nThis MCP server enables a streamlined memory forensics workflow:\n\n1. **Initial Triage**:\n   - \"Show me the process tree in memory.vmem\"\n   - \"List all network connections in memory.vmem\"\n\n2. **Suspicious Process Investigation**:\n   - \"What command line was used to start process 1234?\"\n   - \"Show me all the DLLs loaded by process 1234\"\n   - \"What file handles are open in process 1234?\"\n\n3. **Malware Hunting**:\n   - \"Run malfind on memory.vmem to check for code injection\"\n   - \"Show me processes with unusual parent-child relationships\"\n   - \"Find hidden processes in memory.vmem\"\n\n## Troubleshooting\n\nIf you encounter issues:\n\n1. **Path Problems**:\n   - Make sure all paths are absolute and use double backslashes in Windows paths\n   - Check that the memory dump file exists and is readable\n\n2. **Permission Issues**:\n   - Run Claude Desktop as Administrator\n   - Check that Python and the Volatility directory have proper permissions\n\n3. **Volatility Errors**:\n   - Make sure Volatility 3 works correctly on its own\n   - Try running the same command directly in your command line\n\n4. **MCP Errors**:\n   - Check Claude Desktop logs for MCP errors\n   - Make sure the MCP Python package is installed correctly\n\n## Extending\n\nThis server can be extended by:\n\n1. Adding more Volatility plugins\n2. Creating custom analysis workflows\n3. Integrating with other forensic tools\n4. Adding report generation capabilities\n\n## License\n\n[MIT License](LICENSE)\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "cybersecurity",
        "forensic",
        "memory",
        "memory dumps",
        "analyze memory",
        "server analyze"
      ],
      "category": "memory-management"
    },
    "coleam00--mcp-mem0": {
      "owner": "coleam00",
      "name": "mcp-mem0",
      "url": "https://github.com/coleam00/mcp-mem0",
      "imageUrl": "/freedevtools/mcp/pfp/coleam00.webp",
      "description": "Enables AI agents to store, retrieve, and search memories using semantic indexing for efficient memory management, enhancing contextual awareness.",
      "stars": 576,
      "forks": 215,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-02T22:50:14Z",
      "readme_content": "<h1 align=\"center\">MCP-Mem0: Long-Term Memory for AI Agents</h1>\n\n<p align=\"center\">\n  \n</p>\n\nA template implementation of the [Model Context Protocol (MCP)](https://modelcontextprotocol.io) server integrated with [Mem0](https://mem0.ai) for providing AI agents with persistent memory capabilities.\n\nUse this as a reference point to build your MCP servers yourself, or give this as an example to an AI coding assistant and tell it to follow this example for structure and code correctness!\n\n## Overview\n\nThis project demonstrates how to build an MCP server that enables AI agents to store, retrieve, and search memories using semantic search. It serves as a practical template for creating your own MCP servers, simply using Mem0 and a practical example.\n\nThe implementation follows the best practices laid out by Anthropic for building MCP servers, allowing seamless integration with any MCP-compatible client.\n\n## Features\n\nThe server provides three essential memory management tools:\n\n1. **`save_memory`**: Store any information in long-term memory with semantic indexing\n2. **`get_all_memories`**: Retrieve all stored memories for comprehensive context\n3. **`search_memories`**: Find relevant memories using semantic search\n\n## Prerequisites\n\n- Python 3.12+\n- Supabase or any PostgreSQL database (for vector storage of memories)\n- API keys for your chosen LLM provider (OpenAI, OpenRouter, or Ollama)\n- Docker if running the MCP server as a container (recommended)\n\n## Installation\n\n### Using uv\n\n1. Install uv if you don't have it:\n   ```bash\n   pip install uv\n   ```\n\n2. Clone this repository:\n   ```bash\n   git clone https://github.com/coleam00/mcp-mem0.git\n   cd mcp-mem0\n   ```\n\n3. Install dependencies:\n   ```bash\n   uv pip install -e .\n   ```\n\n4. Create a `.env` file based on `.env.example`:\n   ```bash\n   cp .env.example .env\n   ```\n\n5. Configure your environment variables in the `.env` file (see Configuration section)\n\n### Using Docker (Recommended)\n\n1. Build the Docker image:\n   ```bash\n   docker build -t mcp/mem0 --build-arg PORT=8050 .\n   ```\n\n2. Create a `.env` file based on `.env.example` and configure your environment variables\n\n## Configuration\n\nThe following environment variables can be configured in your `.env` file:\n\n| Variable | Description | Example |\n|----------|-------------|----------|\n| `TRANSPORT` | Transport protocol (sse or stdio) | `sse` |\n| `HOST` | Host to bind to when using SSE transport | `0.0.0.0` |\n| `PORT` | Port to listen on when using SSE transport | `8050` |\n| `LLM_PROVIDER` | LLM provider (openai, openrouter, or ollama) | `openai` |\n| `LLM_BASE_URL` | Base URL for the LLM API | `https://api.openai.com/v1` |\n| `LLM_API_KEY` | API key for the LLM provider | `sk-...` |\n| `LLM_CHOICE` | LLM model to use | `gpt-4o-mini` |\n| `EMBEDDING_MODEL_CHOICE` | Embedding model to use | `text-embedding-3-small` |\n| `DATABASE_URL` | PostgreSQL connection string | `postgresql://user:pass@host:port/db` |\n\n## Running the Server\n\n### Using uv\n\n#### SSE Transport\n\n```bash\n# Set TRANSPORT=sse in .env then:\nuv run src/main.py\n```\n\nThe MCP server will essentially be run as an API endpoint that you can then connect to with config shown below.\n\n#### Stdio Transport\n\nWith stdio, the MCP client iself can spin up the MCP server, so nothing to run at this point.\n\n### Using Docker\n\n#### SSE Transport\n\n```bash\ndocker run --env-file .env -p:8050:8050 mcp/mem0\n```\n\nThe MCP server will essentially be run as an API endpoint within the container that you can then connect to with config shown below.\n\n#### Stdio Transport\n\nWith stdio, the MCP client iself can spin up the MCP server container, so nothing to run at this point.\n\n## Integration with MCP Clients\n\n### SSE Configuration\n\nOnce you have the server running with SSE transport, you can connect to it using this configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"mem0\": {\n      \"transport\": \"sse\",\n      \"url\": \"http://localhost:8050/sse\"\n    }\n  }\n}\n```\n\n> **Note for Windsurf users**: Use `serverUrl` instead of `url` in your configuration:\n> ```json\n> {\n>   \"mcpServers\": {\n>     \"mem0\": {\n>       \"transport\": \"sse\",\n>       \"serverUrl\": \"http://localhost:8050/sse\"\n>     }\n>   }\n> }\n> ```\n\n> **Note for n8n users**: Use host.docker.internal instead of localhost since n8n has to reach outside of it's own container to the host machine:\n> \n> So the full URL in the MCP node would be: http://host.docker.internal:8050/sse\n\nMake sure to update the port if you are using a value other than the default 8050.\n\n### Python with Stdio Configuration\n\nAdd this server to your MCP configuration for Claude Desktop, Windsurf, or any other MCP client:\n\n```json\n{\n  \"mcpServers\": {\n    \"mem0\": {\n      \"command\": \"your/path/to/mcp-mem0/.venv/Scripts/python.exe\",\n      \"args\": [\"your/path/to/mcp-mem0/src/main.py\"],\n      \"env\": {\n        \"TRANSPORT\": \"stdio\",\n        \"LLM_PROVIDER\": \"openai\",\n        \"LLM_BASE_URL\": \"https://api.openai.com/v1\",\n        \"LLM_API_KEY\": \"YOUR-API-KEY\",\n        \"LLM_CHOICE\": \"gpt-4o-mini\",\n        \"EMBEDDING_MODEL_CHOICE\": \"text-embedding-3-small\",\n        \"DATABASE_URL\": \"YOUR-DATABASE-URL\"\n      }\n    }\n  }\n}\n```\n\n### Docker with Stdio Configuration\n\n```json\n{\n  \"mcpServers\": {\n    \"mem0\": {\n      \"command\": \"docker\",\n      \"args\": [\"run\", \"--rm\", \"-i\", \n               \"-e\", \"TRANSPORT\", \n               \"-e\", \"LLM_PROVIDER\", \n               \"-e\", \"LLM_BASE_URL\", \n               \"-e\", \"LLM_API_KEY\", \n               \"-e\", \"LLM_CHOICE\", \n               \"-e\", \"EMBEDDING_MODEL_CHOICE\", \n               \"-e\", \"DATABASE_URL\", \n               \"mcp/mem0\"],\n      \"env\": {\n        \"TRANSPORT\": \"stdio\",\n        \"LLM_PROVIDER\": \"openai\",\n        \"LLM_BASE_URL\": \"https://api.openai.com/v1\",\n        \"LLM_API_KEY\": \"YOUR-API-KEY\",\n        \"LLM_CHOICE\": \"gpt-4o-mini\",\n        \"EMBEDDING_MODEL_CHOICE\": \"text-embedding-3-small\",\n        \"DATABASE_URL\": \"YOUR-DATABASE-URL\"\n      }\n    }\n  }\n}\n```\n\n## Building Your Own Server\n\nThis template provides a foundation for building more complex MCP servers. To build your own:\n\n1. Add your own tools by creating methods with the `@mcp.tool()` decorator\n2. Create your own lifespan function to add your own dependencies (clients, database connections, etc.)\n3. Modify the `utils.py` file for any helper functions you need for your MCP server\n4. Feel free to add prompts and resources as well  with `@mcp.resource()` and `@mcp.prompt()`",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "memory",
        "ai",
        "memories",
        "search memories",
        "memory management",
        "memories using"
      ],
      "category": "memory-management"
    },
    "davidteren--claude-server": {
      "owner": "davidteren",
      "name": "claude-server",
      "url": "https://github.com/davidteren/claude-server",
      "imageUrl": "/freedevtools/mcp/pfp/davidteren.webp",
      "description": "Manages project-specific contexts and maintains conversation continuity with hierarchical structures and metadata tagging. Facilitates quick retrieval for efficient workflows within specified project contexts.",
      "stars": 15,
      "forks": 11,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-09-09T03:54:07Z",
      "readme_content": "# Claude Server MCP\n\n> ⚠️ **IMPORTANT: Project Status** ⚠️\n> \n> This project is in early development (v0.1.0) and is **NOT READY FOR PRODUCTION USE**. It is currently undergoing a significant rewrite to address several critical issues. Please check the [Issues](https://github.com/davidteren/claude-server/issues) page for current limitations and planned improvements.\n>\n> We recommend waiting for a stable release (v0.2.0+) before using this in any critical workflows.\n\nA Model Context Protocol (MCP) server that provides sophisticated context management capabilities for Claude, enabling persistent context across sessions, project-specific context organization, and conversation continuity.\n\n## Current Limitations\n\n- The server currently has compatibility issues with MCP clients other than Claude Desktop\n- Context listing functionality is limited without specific project IDs\n- Security features are minimal and not production-ready\n- Error handling is basic and may not provide helpful guidance\n- No testing infrastructure is in place\n\n## Development Roadmap\n\nThis project is actively being improved. Key upcoming enhancements include:\n\n1. **Stability Improvements** - Fixing core issues with home directory resolution and context listing\n2. **Enhanced Error Handling** - Better error messages and recovery mechanisms\n3. **Security Enhancements** - Input validation, path sanitization, and data protection\n4. **Advanced Context Management** - Versioning, search, and better organization\n\nFor a more detailed roadmap, see our [Comprehensive Analysis](https://github.com/davidteren/claude-server/tree/docs/comprehensive-analysis/docs) branch.\n\n## Features\n\n- **Project Context Management**\n  - Hierarchical context organization\n  - Parent-child relationships\n  - Cross-referencing between contexts\n  - Project-specific metadata\n\n- **Conversation Continuity**\n  - Session-based context tracking\n  - Conversation chaining\n  - Metadata-rich context storage\n  - Flexible tagging system\n\n- **Efficient Storage**\n  - Organized directory structure\n  - JSON-based storage\n  - Quick lookup indexing\n  - Asynchronous operations\n\n## Installation\n\nThe server is automatically configured in your Claude desktop app's MCP settings. All contexts are stored in `~/.claude/` for better organization:\n\n```\n~/.claude/\n├── contexts/           # General conversation contexts\n├── projects/          # Project-specific contexts\n└── context-index.json # Quick lookup index\n```\n\n## Tools\n\n### Project Context Management\n\n```typescript\n// Save project context\nuse_mcp_tool({\n  server_name: \"claude-server\",\n  tool_name: \"save_project_context\",\n  arguments: {\n    id: \"feature-design-v1\",\n    projectId: \"my-project\",\n    content: \"Design discussion...\",\n    parentContextId: \"requirements-v1\",\n    references: [\"api-spec-v1\"],\n    tags: [\"design\"],\n    metadata: { status: \"in-progress\" }\n  }\n});\n```\n\n### Conversation Management\n\n```typescript\n// Save conversation context\nuse_mcp_tool({\n  server_name: \"claude-server\",\n  tool_name: \"save_conversation_context\",\n  arguments: {\n    id: \"chat-2024-01-01\",\n    sessionId: \"session-123\",\n    content: \"Discussion content...\",\n    continuationOf: \"previous-chat-id\",\n    tags: [\"meeting\"]\n  }\n});\n```\n\n### Context Retrieval\n\n```typescript\n// Get context\nuse_mcp_tool({\n  server_name: \"claude-server\",\n  tool_name: \"get_context\",\n  arguments: {\n    id: \"feature-design-v1\",\n    projectId: \"my-project\"\n  }\n});\n\n// List contexts\nuse_mcp_tool({\n  server_name: \"claude-server\",\n  tool_name: \"list_contexts\",\n  arguments: {\n    projectId: \"my-project\",\n    tag: \"design\",\n    type: \"project\"\n  }\n});\n```\n\n## Documentation\n\n- [Context Management Guide](docs/CONTEXT_MANAGEMENT.md) - Detailed guide on context types and usage\n- [Architecture Overview](docs/ARCHITECTURE.md) - Technical implementation details\n- [Usage Guide](docs/USAGE.md) - General usage instructions\n- [Claude Desktop Integration](docs/CLAUDE_DESKTOP_INTEGRATION.md) - Integration with Claude Desktop\n\n## Development\n\n1. Clone the repository\n2. Install dependencies:\n   ```bash\n   npm install\n   ```\n3. Build the server:\n   ```bash\n   npm run build\n   ```\n4. The server will be built to `build/index.js`\n\n## Configuration\n\nThe server is configured through the Claude desktop app's configuration file at:\n`~/Library/Application Support/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"claude-server\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/claude-server/build/index.js\"]\n    }\n  }\n}\n```\n\n## Contributing\n\nContributions are welcome! Please feel free to submit issues and pull requests.\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "workflows",
        "metadata",
        "memory",
        "project contexts",
        "manages project",
        "memory management"
      ],
      "category": "memory-management"
    },
    "davioliveeira--memory-mcp": {
      "owner": "davioliveeira",
      "name": "memory-mcp",
      "url": "https://github.com/davioliveeira/memory-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/davioliveeira.webp",
      "description": "Store and retrieve memories efficiently using SQLite as the backend. Offers tools for managing memories, including functions to remember, get, list, update, and delete entries, along with command-line inspection capabilities.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-05-06T15:44:43Z",
      "readme_content": "# Memory MCP\n\nA Model Context Protocol server for storing and retrieving memories using low-level Server implementation and SQLite storage.\n\n## Installation\n\nThis project uses [uv](https://github.com/astral-sh/uv) for dependency management instead of pip. uv is a fast, reliable Python package installer and resolver.\n\nInstall using uv:\n\n```bash\nuv pip install memory-mcp\n```\n\nOr install directly from source:\n\n```bash\nuv pip install .\n```\n\nFor development:\n\n```bash\nuv pip install -e \".[dev]\"\n```\n\nIf you don't have uv installed, you can install it following the [official instructions](https://github.com/astral-sh/uv#installation).\n\n## Usage\n\n### Running the server\n\n```bash\nmemory-mcp\n```\n\nThis will start the MCP server that allows you to store and retrieve memories.\n\n### Available Tools\n\nThe Memory MCP provides the following tools:\n\n- `remember`: Store a new memory with a title and content\n- `get_memory`: Retrieve a specific memory by ID or title\n- `list_memories`: List all stored memories\n- `update_memory`: Update an existing memory\n- `delete_memory`: Delete a memory\n\n## Debugging with MCP Inspect\n\nMCP provides a handy command-line tool called `mcp inspect` that allows you to debug and interact with your MCP server directly.\n\n### Setup\n\n1. First, make sure the MCP CLI tools are installed:\n\n```bash\nuv pip install mcp[cli]\n```\n\n2. Start the Memory MCP server in one terminal:\n\n```bash\nmemory-mcp\n```\n\n3. In another terminal, connect to the running server using `mcp inspect`:\n\n```bash\nmcp inspect\n```\n\n### Using MCP Inspect\n\nOnce connected, you can:\n\n#### List available tools\n\n```\n> tools\n```\n\nThis will display all the tools provided by the Memory MCP server.\n\n#### Call a tool\n\nTo call a tool, use the `call` command followed by the tool name and any required arguments:\n\n```\n> call remember title=\"Meeting Notes\" content=\"Discussed project timeline and milestones.\"\n```\n\n```\n> call list_memories\n```\n\n```\n> call get_memory memory_id=1\n```\n\n```\n> call update_memory memory_id=1 title=\"Updated Title\" content=\"Updated content.\"\n```\n\n```\n> call delete_memory memory_id=1\n```\n\n#### Debug Mode\n\nYou can enable debug mode to see detailed request and response information:\n\n```\n> debug on\n```\n\nThis helps you understand exactly what data is being sent to and received from the server.\n\n#### Exploring Tool Schemas\n\nTo view the schema for a specific tool:\n\n```\n> tool remember\n```\n\nThis shows the input schema, required parameters, and description for the tool.\n\n### Troubleshooting\n\nIf you encounter issues:\n\n1. Check the server logs in the terminal where your server is running for any error messages.\n2. In the MCP inspect terminal, enable debug mode with `debug on` to see raw requests and responses.\n3. Ensure the tool parameters match the expected schema (check with the `tool` command).\n4. If the server crashes, check for any uncaught exceptions in the server terminal.\n\n## Development\n\nTo contribute to the project, install the development dependencies:\n\n```bash\nuv pip install -e \".[dev]\"\n```\n\n### Managing Dependencies\n\nThis project uses `uv.lock` file to lock dependencies. To update dependencies:\n\n```bash\nuv pip compile pyproject.toml -o uv.lock\n```\n\n### Running tests\n\n```bash\npython -m pytest\n```\n\n### Code formatting\n\n```bash\nblack memory_mcp tests\n```\n\n### Linting\n\n```bash\nruff check memory_mcp tests\n```\n\n### Type checking\n\n```bash\nmypy memory_mcp\n``` ",
      "npm_url": "https://www.npmjs.com/package/memory-mcp",
      "npm_downloads": 113,
      "keywords": [
        "sqlite",
        "memory",
        "memories",
        "memory management",
        "managing memories",
        "retrieve memories"
      ],
      "category": "memory-management"
    },
    "ddkang1--mcp-mem": {
      "owner": "ddkang1",
      "name": "mcp-mem",
      "url": "https://github.com/ddkang1/mcp-mem",
      "imageUrl": "/freedevtools/mcp/pfp/ddkang1.webp",
      "description": "Provides session-based memory management for chat applications using an efficient knowledge graph to search and retrieve information from multiple sources, including uploaded files.",
      "stars": 1,
      "forks": 0,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-07-29T09:51:38Z",
      "readme_content": "# MCP Memory\n\nA Model Context Protocol (MCP) server implementing memory solutions for data-rich applications with efficient knowledge graph capabilities.\n\n## Overview\n\nThis MCP server implements a memory solution for data-rich applications that involve searching information from many sources including uploaded files. It uses HippoRAG internally to manage memory through an efficient knowledge graph. HippoRAG is a required dependency for this package.\n\n## Features\n\n- **Session-based Memory**: Create and manage memory for specific chat sessions\n- **Efficient Knowledge Graph**: Uses HippoRAG for memory management\n- **Multiple Transport Support**: Works with both stdio and SSE transports\n- **Search Capabilities**: Search information from various sources including uploaded files\n- **Automatic Resource Management**: TTL-based cleanup for both sessions and memory instances\n\n## Installation\n\nInstall from PyPI:\n\n```bash\npip install mcp-mem hipporag\n```\n\nOr install from source:\n\n```bash\ngit clone https://github.com/ddkang1/mcp-mem.git\ncd mcp-mem\npip install -e .\npip install hipporag\n```\n\nNote: HippoRAG is a required dependency for mcp-mem to function.\n\n## Usage\n\nYou can run the MCP server directly:\n\n```bash\nmcp-mem\n```\n\nBy default, it uses stdio transport. To use SSE transport:\n\n```bash\nmcp-mem --sse\n```\n\nYou can also specify host and port for SSE transport:\n\n```bash\nmcp-mem --sse --host 127.0.0.1 --port 3001\n```\n\n## Configuration\n\n### Basic Configuration\n\nTo use this tool with Claude in Windsurf, add the following configuration to your MCP config file:\n\n```json\n\"memory\": {\n    \"command\": \"/path/to/mcp-mem\",\n    \"args\": [],\n    \"type\": \"stdio\",\n    \"pollingInterval\": 30000,\n    \"startupTimeout\": 30000,\n    \"restartOnFailure\": true\n}\n```\n\nThe `command` field should point to the directory where you installed the python package using pip.\n\n### Environment Variable Configuration\n\nYou can configure the LLM and embedding models used by mcp-mem through environment variables:\n\n- `EMBEDDING_MODEL_NAME`: Name of the embedding model to use (default: \"text-embedding-3-large\")\n- `EMBEDDING_BASE_URL`: Base URL for the embedding API (optional)\n- `LLM_NAME`: Name of the LLM model to use (default: \"gpt-4o-mini\")\n- `LLM_BASE_URL`: Base URL for the LLM API (optional)\n- `OPENAI_API_KEY`: OpenAI API key (required)\n\n### Memory Management Configuration\n\nThe server includes automatic resource management features:\n\n- **Session TTL**: Automatically removes session directories after a specified number of days of inactivity.\n  Set using the `session_ttl_days` configuration parameter (default: None - disabled).\n\n- **Instance TTL**: Automatically offloads HippoRAG instances from memory after a specified period of inactivity.\n  Set using the `instance_ttl_minutes` configuration parameter (default: 30 minutes).\n  \n  This feature helps manage memory usage by unloading inactive instances while preserving the underlying data.\n  When an offloaded instance is accessed again, it will be automatically reloaded from disk.\n\nExample usage:\n\n```bash\nEMBEDDING_MODEL_NAME=\"your-model\" LLM_NAME=\"your-llm\" mcp-mem\n```\n\nFor convenience, you can use the provided example script:\n\n```bash\n./examples/run_with_env_vars.sh\n```\n\n## Available Tools\n\nThe MCP server provides the following tools:\n\n- **create_memory**: Create a new memory for a given chat session\n- **store_memory**: Add memory to a specific session\n- **retrieve_memory**: Retrieve memory from a specific session\n\n## Development\n\n### Installation for Development\n\n```bash\ngit clone https://github.com/ddkang1/mcp-mem.git\ncd mcp-mem\npip install -e \".[dev]\"\n```\n\n### Running Tests\n\n```bash\npytest\n```\n\n### Code Style\n\nThis project uses Black for formatting, isort for import sorting, and flake8 for linting:\n\n```bash\nblack src tests\nisort src tests\nflake8 src tests\n```\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "memory",
        "ddkang1",
        "chat",
        "memory management",
        "management chat",
        "mem provides"
      ],
      "category": "memory-management"
    },
    "delorenj--mcp-qdrant-memory": {
      "owner": "delorenj",
      "name": "mcp-qdrant-memory",
      "url": "https://github.com/delorenj/mcp-qdrant-memory",
      "imageUrl": "/freedevtools/mcp/pfp/delorenj.webp",
      "description": "A knowledge graph implementation that supports semantic search with a Qdrant vector database, enabling effective graph-based representation of entities and their relations. It includes features for file-based persistence and utilizes OpenAI embeddings for enhanced semantic similarity.",
      "stars": 16,
      "forks": 18,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-09-27T03:40:16Z",
      "readme_content": "# MCP Memory Server with Qdrant Persistence\n[![smithery badge](https://smithery.ai/badge/@delorenj/mcp-qdrant-memory)](https://smithery.ai/server/@delorenj/mcp-qdrant-memory)\n\nThis MCP server provides a knowledge graph implementation with semantic search capabilities powered by Qdrant vector database.\n\n## Features\n\n- Graph-based knowledge representation with entities and relations\n- File-based persistence (memory.json)\n- Semantic search using Qdrant vector database\n- OpenAI embeddings for semantic similarity\n- HTTPS support with reverse proxy compatibility\n- Docker support for easy deployment\n\n## Environment Variables\n\nThe following environment variables are required:\n\n```bash\n# OpenAI API key for generating embeddings\nOPENAI_API_KEY=your-openai-api-key\n\n# Qdrant server URL (supports both HTTP and HTTPS)\nQDRANT_URL=https://your-qdrant-server\n\n# Qdrant API key (if authentication is enabled)\nQDRANT_API_KEY=your-qdrant-api-key\n\n# Name of the Qdrant collection to use\nQDRANT_COLLECTION_NAME=your-collection-name\n```\n\n## Setup\n\n### Local Setup\n\n1. Install dependencies:\n```bash\nnpm install\n```\n\n2. Build the server:\n```bash\nnpm run build\n```\n\n### Docker Setup\n\n1. Build the Docker image:\n```bash\ndocker build -t mcp-qdrant-memory .\n```\n\n2. Run the Docker container with required environment variables:\n```bash\ndocker run -d \\\n  -e OPENAI_API_KEY=your-openai-api-key \\\n  -e QDRANT_URL=http://your-qdrant-server:6333 \\\n  -e QDRANT_COLLECTION_NAME=your-collection-name \\\n  -e QDRANT_API_KEY=your-qdrant-api-key \\\n  --name mcp-qdrant-memory \\\n  mcp-qdrant-memory\n```\n\n### Add to MCP settings:\n```json\n{\n  \"mcpServers\": {\n    \"memory\": {\n      \"command\": \"/bin/zsh\",\n      \"args\": [\"-c\", \"cd /path/to/server && node dist/index.js\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"your-openai-api-key\",\n        \"QDRANT_API_KEY\": \"your-qdrant-api-key\",\n        \"QDRANT_URL\": \"http://your-qdrant-server:6333\",\n        \"QDRANT_COLLECTION_NAME\": \"your-collection-name\"\n      },\n      \"alwaysAllow\": [\n        \"create_entities\",\n        \"create_relations\",\n        \"add_observations\",\n        \"delete_entities\",\n        \"delete_observations\",\n        \"delete_relations\",\n        \"read_graph\",\n        \"search_similar\"\n      ]\n    }\n  }\n}\n```\n\n## Tools\n\n### Entity Management\n- `create_entities`: Create multiple new entities\n- `create_relations`: Create relations between entities\n- `add_observations`: Add observations to entities\n- `delete_entities`: Delete entities and their relations\n- `delete_observations`: Delete specific observations\n- `delete_relations`: Delete specific relations\n- `read_graph`: Get the full knowledge graph\n\n### Semantic Search\n- `search_similar`: Search for semantically similar entities and relations\n  ```typescript\n  interface SearchParams {\n    query: string;     // Search query text\n    limit?: number;    // Max results (default: 10)\n  }\n  ```\n\n## Implementation Details\n\nThe server maintains two forms of persistence:\n\n1. File-based (memory.json):\n   - Complete knowledge graph structure\n   - Fast access to full graph\n   - Used for graph operations\n\n2. Qdrant Vector DB:\n   - Semantic embeddings of entities and relations\n   - Enables similarity search\n   - Automatically synchronized with file storage\n\n### Synchronization\n\nWhen entities or relations are modified:\n1. Changes are written to memory.json\n2. Embeddings are generated using OpenAI\n3. Vectors are stored in Qdrant\n4. Both storage systems remain consistent\n\n### Search Process\n\nWhen searching:\n1. Query text is converted to embedding\n2. Qdrant performs similarity search\n3. Results include both entities and relations\n4. Results are ranked by semantic similarity\n\n## Example Usage\n\n```typescript\n// Create entities\nawait client.callTool(\"create_entities\", {\n  entities: [{\n    name: \"Project\",\n    entityType: \"Task\",\n    observations: [\"A new development project\"]\n  }]\n});\n\n// Search similar concepts\nconst results = await client.callTool(\"search_similar\", {\n  query: \"development tasks\",\n  limit: 5\n});\n```\n\n## HTTPS and Reverse Proxy Configuration\n\nThe server supports connecting to Qdrant through HTTPS and reverse proxies. This is particularly useful when:\n- Running Qdrant behind a reverse proxy like Nginx or Apache\n- Using self-signed certificates\n- Requiring custom SSL/TLS configurations\n\n### Setting up with a Reverse Proxy\n\n1. Configure your reverse proxy (example using Nginx):\n```nginx\nserver {\n    listen 443 ssl;\n    server_name qdrant.yourdomain.com;\n\n    ssl_certificate /path/to/cert.pem;\n    ssl_certificate_key /path/to/key.pem;\n\n    location / {\n        proxy_pass http://localhost:6333;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n    }\n}\n```\n\n2. Update your environment variables:\n```bash\nQDRANT_URL=https://qdrant.yourdomain.com\n```\n\n### Security Considerations\n\nThe server implements robust HTTPS handling with:\n- Custom SSL/TLS configuration\n- Proper certificate verification options\n- Connection pooling and keepalive\n- Automatic retry with exponential backoff\n- Configurable timeouts\n\n### Troubleshooting HTTPS Connections\n\nIf you experience connection issues:\n\n1. Verify your certificates:\n```bash\nopenssl s_client -connect qdrant.yourdomain.com:443\n```\n\n2. Test direct connectivity:\n```bash\ncurl -v https://qdrant.yourdomain.com/collections\n```\n\n3. Check for any proxy settings:\n```bash\nenv | grep -i proxy\n```\n\n## Contributing\n\n1. Fork the repository\n2. Create a feature branch\n3. Make your changes\n4. Submit a pull request\n\n## License\n\nMIT",
      "npm_url": "https://www.npmjs.com/package/mcp-qdrant-memory",
      "npm_downloads": 280,
      "keywords": [
        "semantic",
        "database",
        "memory",
        "knowledge graph",
        "semantic search",
        "qdrant memory"
      ],
      "category": "memory-management"
    },
    "devassistantai--mcp-servers": {
      "owner": "devassistantai",
      "name": "mcp-servers",
      "url": "https://github.com/devassistantai/mcp-servers",
      "imageUrl": "/freedevtools/mcp/pfp/devassistantai.webp",
      "description": "Store and retrieve user information across chats using a local knowledge graph to enable persistent memory for an AI assistant. Manage entities, relations, and observations to personalize interactions effectively.",
      "stars": 5,
      "forks": 0,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-07-30T16:32:40Z",
      "readme_content": "# Model Context Protocol servers\n\nThis repository is a collection of *reference implementations* for the [Model Context Protocol](https://modelcontextprotocol.io/) (MCP), as well as references\nto community built servers and additional resources.\n\nThe servers in this repository showcase the versatility and extensibility of MCP, demonstrating how it can be used to give Large Language Models (LLMs) secure, controlled access to tools and data sources.\nEach MCP server is implemented with either the [Typescript MCP SDK](https://github.com/modelcontextprotocol/typescript-sdk) or [Python MCP SDK](https://github.com/modelcontextprotocol/python-sdk).\n\n> Note: Lists in this README are maintained in alphabetical order to minimize merge conflicts when adding new items.\n\n## 🌟 Reference Servers\n\nThese servers aim to demonstrate MCP features and the TypeScript and Python SDKs.\n\n- **[AWS KB Retrieval](src/aws-kb-retrieval-server)** - Retrieval from AWS Knowledge Base using Bedrock Agent Runtime\n- **[Brave Search](src/brave-search)** - Web and local search using Brave's Search API\n- **[EverArt](src/everart)** - AI image generation using various models\n- **[Everything](src/everything)** - Reference / test server with prompts, resources, and tools\n- **[Fetch](src/fetch)** - Web content fetching and conversion for efficient LLM usage\n- **[Filesystem](src/filesystem)** - Secure file operations with configurable access controls\n- **[Git](src/git)** - Tools to read, search, and manipulate Git repositories\n- **[GitHub](src/github)** - Repository management, file operations, and GitHub API integration\n- **[GitLab](src/gitlab)** - GitLab API, enabling project management\n- **[Google Drive](src/gdrive)** - File access and search capabilities for Google Drive\n- **[Google Maps](src/google-maps)** - Location services, directions, and place details\n- **[Memory](src/memory)** - Knowledge graph-based persistent memory system\n- **[PostgreSQL](src/postgres)** - Read-only database access with schema inspection\n- **[Puppeteer](src/puppeteer)** - Browser automation and web scraping\n- **[Sentry](src/sentry)** - Retrieving and analyzing issues from Sentry.io\n- **[Sequential Thinking](src/sequentialthinking)** - Dynamic and reflective problem-solving through thought sequences\n- **[Slack](src/slack)** - Channel management and messaging capabilities\n- **[Sqlite](src/sqlite)** - Database interaction and business intelligence capabilities\n- **[Time](src/time)** - Time and timezone conversion capabilities\n\n## 🤝 Third-Party Servers\n\n### 🎖️ Official Integrations\n\nOfficial integrations are maintained by companies building production ready MCP servers for their platforms.\n\n- <img height=\"12\" width=\"12\" src=\"https://www.21st.dev/favicon.ico\" alt=\"21st.dev Logo\" /> **[21st.dev Magic](https://github.com/21st-dev/magic-mcp)** - Create crafted UI components inspired by the best 21st.dev design engineers.\n- <img height=\"12\" width=\"12\" src=\"https://apify.com/favicon.ico\" alt=\"Apify Logo\" /> **[Apify](https://github.com/apify/actors-mcp-server)** - [Actors MCP Server](https://apify.com/apify/actors-mcp-server): Use 3,000+ pre-built cloud tools to extract data from websites, e-commerce, social media, search engines, maps, and more\n- <img height=\"12\" width=\"12\" src=\"https://resources.audiense.com/hubfs/favicon-1.png\" alt=\"Audiense Logo\" /> **[Audiense Insights](https://github.com/AudienseCo/mcp-audiense-insights)** - Marketing insights and audience analysis from [Audiense](https://www.audiense.com/products/audiense-insights) reports, covering demographic, cultural, influencer, and content engagement analysis.\n- <img height=\"12\" width=\"12\" src=\"https://axiom.co/favicon.ico\" alt=\"Axiom Logo\" /> **[Axiom](https://github.com/axiomhq/mcp-server-axiom)** - Query and analyze your Axiom logs, traces, and all other event data in natural language\n- <img height=\"12\" width=\"12\" src=\"https://browserbase.com/favicon.ico\" alt=\"Browserbase Logo\" /> **[Browserbase](https://github.com/browserbase/mcp-server-browserbase)** - Automate browser interactions in the cloud (e.g. web navigation, data extraction, form filling, and more)\n- <img height=\"12\" width=\"12\" src=\"https://clickhouse.com/favicon.ico\" alt=\"ClickHouse Logo\" /> **[ClickHouse](https://github.com/ClickHouse/mcp-clickhouse)** - Query your [ClickHouse](https://clickhouse.com/) database server.\n- <img alt=\"cloudflare\" height=\"12\" width=\"12\" src=\"https://cdn.simpleicons.org/cloudflare\" /> **[Cloudflare](https://github.com/cloudflare/mcp-server-cloudflare)** - Deploy, configure & interrogate your resources on the Cloudflare developer platform (e.g. Workers/KV/R2/D1)\n- <img height=\"12\" width=\"12\" src=\"https://e2b.dev/favicon.ico\" alt=\"E2B Logo\" /> **[E2B](https://github.com/e2b-dev/mcp-server)** - Run code in secure sandboxes hosted by [E2B](https://e2b.dev)\n- <img height=\"12\" width=\"12\" src=\"https://esignatures.com/favicon.ico\" alt=\"eSignatures Logo\" /> **[eSignatures](https://github.com/esignaturescom/mcp-server-esignatures)** - Contract and template management for drafting, reviewing, and sending binding contracts.\n- <img height=\"12\" width=\"12\" src=\"https://exa.ai/images/favicon-32x32.png\" alt=\"Exa Logo\" /> **[Exa](https://github.com/exa-labs/exa-mcp-server)** - Search Engine made for AIs by [Exa](https://exa.ai)\n- <img height=\"12\" width=\"12\" src=\"https://firecrawl.dev/favicon.ico\" alt=\"Firecrawl Logo\" /> **[Firecrawl](https://github.com/mendableai/firecrawl-mcp-server)** - Extract web data with [Firecrawl](https://firecrawl.dev)\n- <img height=\"12\" width=\"12\" src=\"https://fireproof.storage/favicon.ico\" alt=\"Fireproof Logo\" /> **[Fireproof](https://github.com/fireproof-storage/mcp-database-server)** - Immutable ledger database with live synchronization\n- <img height=\"12\" width=\"12\" src=\"https://grafana.com/favicon.ico\" alt=\"Grafana Logo\" /> **[Grafana](https://github.com/grafana/mcp-grafana)** - Search dashboards, investigate incidents and query datasources in your Grafana instance\n- **[IBM wxflows](https://github.com/IBM/wxflows/tree/main/examples/mcp/javascript)** - Tool platform by IBM to build, test and deploy tools for any data source\n- <img height=\"12\" width=\"12\" src=\"https://forevervm.com/icon.png\" alt=\"ForeverVM Logo\" /> **[ForeverVM](https://github.com/jamsocket/forevervm/tree/main/javascript/mcp-server)** - Run Python in a code sandbox.\n- <img height=\"12\" width=\"12\" src=\"https://integration.app/favicon.ico\" alt=\"Integration App Icon\" /> **[Integration App](https://github.com/integration-app/mcp-server)** - Interact with any other SaaS applications on behalf of your customers. \n- <img alt=\"jetbrains\" height=\"12\" width=\"12\" src=\"https://cdn.simpleicons.org/jetbrains\" /> **[JetBrains](https://github.com/JetBrains/mcp-jetbrains)** – Work on your code with JetBrains IDEs\n- <img height=\"12\" width=\"12\" src=\"https://kagi.com/favicon.ico\" alt=\"Kagi Logo\" /> **[Kagi Search](https://github.com/kagisearch/kagimcp)** - Search the web using Kagi's search API\n- <img height=\"12\" width=\"12\" src=\"https://langfuse.com/favicon.ico\" alt=\"Langfuse Logo\" /> **[Langfuse Prompt Management](https://github.com/langfuse/mcp-server-langfuse)** - Open-source tool for collaborative editing, versioning, evaluating, and releasing prompts.\n- <img height=\"12\" width=\"12\" src=\"https://lingo.dev/favicon.ico\" alt=\"Lingo.dev Logo\" /> **[Lingo.dev](https://github.com/lingodotdev/lingo.dev/blob/main/mcp.md)** - Make your AI agent speak every language on the planet, using [Lingo.dev](https://lingo.dev) Localization Engine.\n- <img height=\"12\" width=\"12\" src=\"https://www.meilisearch.com/favicon.ico\" alt=\"Meilisearch Logo\" /> **[Meilisearch](https://github.com/meilisearch/meilisearch-mcp)** - Interact & query with Meilisearch (Full-text & semantic search API)\n-  **[Metoro](https://github.com/metoro-io/metoro-mcp-server)** - Query and interact with kubernetes environments monitored by Metoro\n- <img height=\"12\" width=\"12\" src=\"https://www.motherduck.com/favicon.ico\" alt=\"MotherDuck Logo\" /> **[MotherDuck](https://github.com/motherduckdb/mcp-server-motherduck)** - Query and analyze data with MotherDuck and local DuckDB\n- <img height=\"12\" width=\"12\" src=\"https://needle-ai.com/images/needle-logo-orange-2-rounded.png\" alt=\"Needle AI Logo\" /> **[Needle](https://github.com/needle-ai/needle-mcp)** - Production-ready RAG out of the box to search and retrieve data from your own documents.\n- <img height=\"12\" width=\"12\" src=\"https://neo4j.com/favicon.ico\" alt=\"Neo4j Logo\" /> **[Neo4j](https://github.com/neo4j-contrib/mcp-neo4j/)** - Neo4j graph database server (schema + read/write-cypher) and separate graph database backed memory\n- **[Neon](https://github.com/neondatabase/mcp-server-neon)** - Interact with the Neon serverless Postgres platform\n- <img height=\"12\" width=\"12\" src=\"https://oxylabs.io/favicon.ico\" alt=\"Oxylabs Logo\" /> **[Oxylabs](https://github.com/oxylabs/oxylabs-mcp)** - Scrape websites with Oxylabs Web API, supporting dynamic rendering and parsing for structured data extraction.\n- <img alt=\"logomark\" height=\"12\" width=\"12\" src=\"https://qdrant.tech/img/brand-resources-logos/logomark.svg\" /> **[Qdrant](https://github.com/qdrant/mcp-server-qdrant/)** - Implement semantic memory layer on top of the Qdrant vector search engine\n- **[Raygun](https://github.com/MindscapeHQ/mcp-server-raygun)** - Interact with your crash reporting and real using monitoring data on your Raygun account\n- <img height=\"12\" width=\"12\" src=\"https://riza.io/favicon.ico\" alt=\"Riza logo\" /> **[Riza](https://github.com/riza-io/riza-mcp)** - Arbitrary code execution and tool-use platform for LLMs by [Riza](https://riza.io)\n- <img alt=\"56912e614b35093426c515860f9f2234\" height=\"12\" width=\"12\" src=\"https://pics.fatwang2.com/56912e614b35093426c515860f9f2234.svg\" /> [Search1API](https://github.com/fatwang2/search1api-mcp) - One API for Search, Crawling, and Sitemaps\n- <img height=\"12\" width=\"12\" src=\"https://stripe.com/favicon.ico\" alt=\"Stripe Logo\" /> **[Stripe](https://github.com/stripe/agent-toolkit)** - Interact with Stripe API\n- <img height=\"12\" width=\"12\" src=\"https://tavily.com/favicon.ico\" alt=\"Tavily Logo\" /> **[Tavily](https://github.com/tavily-ai/tavily-mcp)** - Search engine for AI agents (search + extract) powered by [Tavily](https://tavily.com/)\n- <img height=\"12\" width=\"12\" src=\"https://www.tinybird.co/favicon.ico\" alt=\"Tinybird Logo\" /> **[Tinybird](https://github.com/tinybirdco/mcp-tinybird)** - Interact with Tinybird serverless ClickHouse platform\n- <img height=\"12\" width=\"12\" src=\"https://verodat.io/assets/favicon-16x16.png\" alt=\"Verodat Logo\" /> **[Verodat](https://github.com/Verodat/verodat-mcp-server)** - Interact with Verodat AI Ready Data platform\n\n### 🌎 Community Servers\n\nA growing set of community-developed and maintained servers demonstrates various applications of MCP across different domains.\n\n> **Note:** Community servers are **untested** and should be used at **your own risk**. They are not affiliated with or endorsed by Anthropic.\n\n- **[AWS S3](https://github.com/aws-samples/sample-mcp-server-s3)** - A sample MCP server for AWS S3 that flexibly fetches objects from S3 such as PDF documents\n- **[AWS](https://github.com/rishikavikondala/mcp-server-aws)** - Perform operations on your AWS resources using an LLM\n- **[Airtable](https://github.com/domdomegg/airtable-mcp-server)** - Read and write access to [Airtable](https://airtable.com/) databases, with schema inspection.\n- **[Airtable](https://github.com/felores/airtable-mcp)** - Airtable Model Context Protocol Server.\n- **[AlphaVantage](https://github.com/calvernaz/alphavantage)** - MCP server for stock market data API [AlphaVantage](https://www.alphavantage.co)\n- **[Anki](https://github.com/scorzeth/anki-mcp-server)** - An MCP server for interacting with your [Anki](https://apps.ankiweb.net) decks and cards.\n- **[Any Chat Completions](https://github.com/pyroprompts/any-chat-completions-mcp)** - Interact with any OpenAI SDK Compatible Chat Completions API like OpenAI, Perplexity, Groq, xAI and many more.\n- **[ArangoDB](https://github.com/ravenwits/mcp-server-arangodb)** - MCP Server that provides database interaction capabilities through [ArangoDB](https://arangodb.com/).\n- **[Atlassian](https://github.com/sooperset/mcp-atlassian)** - Interact with Atlassian Cloud products (Confluence and Jira) including searching/reading Confluence spaces/pages, accessing Jira issues, and project metadata.\n- **[Base Free USDC Transfer](https://github.com/magnetai/mcp-free-usdc-transfer)** - Send USDC on [Base](https://base.org) for free using Claude AI! Built with [Coinbase CDP](https://docs.cdp.coinbase.com/mpc-wallet/docs/welcome).\n- **[BigQuery](https://github.com/LucasHild/mcp-server-bigquery)** (by LucasHild) - This server enables LLMs to inspect database schemas and execute queries on BigQuery.\n- **[BigQuery](https://github.com/ergut/mcp-bigquery-server)** (by ergut) - Server implementation for Google BigQuery integration that enables direct BigQuery database access and querying capabilities\n- **[Calendar](https://github.com/GongRzhe/Calendar-MCP-Server)** - Google Calendar integration server enabling AI assistants to manage calendar events through natural language interactions.\n- **[CFBD API](https://github.com/lenwood/cfbd-mcp-server)** - An MCP server for the [College Football Data API](https://collegefootballdata.com/).\n- **[ChatMCP](https://github.com/AI-QL/chat-mcp)** – An Open Source Cross-platform GUI Desktop application compatible with Linux, macOS, and Windows, enabling seamless interaction with MCP servers across dynamically selectable LLMs, by **[AIQL](https://github.com/AI-QL)**\n- **[ChatSum](https://github.com/mcpso/mcp-server-chatsum)** - Query and Summarize chat messages with LLM. by [mcpso](https://mcp.so)\n- **[Chroma](https://github.com/privetin/chroma)** - Vector database server for semantic document search and metadata filtering, built on Chroma\n- **[ClaudePost](https://github.com/ZilongXue/claude-post)** - ClaudePost enables seamless email management for Gmail, offering secure features like email search, reading, and sending.\n- **[Cloudinary](https://github.com/felores/cloudinary-mcp-server)** - Cloudinary Model Context Protocol Server to upload media to Cloudinary and get back the media link and details.\n- **[code-executor](https://github.com/bazinga012/mcp_code_executor)** - An MCP server that allows LLMs to execute Python code within a specified Conda environment.\n- **[code-sandbox-mcp](https://github.com/Automata-Labs-team/code-sandbox-mcp)** - An MCP server to create secure code sandbox environment for executing code within Docker containers.\n- **[cognee-mcp](https://github.com/topoteretes/cognee/tree/main/cognee-mcp)** - GraphRAG memory server with customizable ingestion, data processing and search\n- **[coin_api_mcp](https://github.com/longmans/coin_api_mcp)** - Provides access to [coinmarketcap](https://coinmarketcap.com/) cryptocurrency data.\n- **[Contentful-mcp](https://github.com/ivo-toby/contentful-mcp)** - Read, update, delete, publish content in your [Contentful](https://contentful.com) space(s) from this MCP Server.\n- **[Dappier](https://github.com/DappierAI/dappier-mcp)** - Connect LLMs to real-time, rights-cleared, proprietary data from trusted sources. Access specialized models for Real-Time Web Search, News, Sports, Financial Data, Crypto, and premium publisher content. Explore data models at [marketplace.dappier.com](https://marketplace.dappier.com/marketplace).\n- **[Data Exploration](https://github.com/reading-plus-ai/mcp-server-data-exploration)** - MCP server for autonomous data exploration on .csv-based datasets, providing intelligent insights with minimal effort. NOTE: Will execute arbitrary Python code on your machine, please use with caution!\n- **[Dataset Viewer](https://github.com/privetin/dataset-viewer)** - Browse and analyze Hugging Face datasets with features like search, filtering, statistics, and data export\n- **[DeepSeek MCP Server](https://github.com/DMontgomery40/deepseek-mcp-server)** - Model Context Protocol server integrating DeepSeek's advanced language models, in addition to [other useful API endpoints](https://github.com/DMontgomery40/deepseek-mcp-server?tab=readme-ov-file#features)\n- **[Deepseek_R1](https://github.com/66julienmartin/MCP-server-Deepseek_R1)** - A Model Context Protocol (MCP) server implementation connecting Claude Desktop with DeepSeek's language models (R1/V3)\n- **[deepseek-thinker-mcp](https://github.com/ruixingshi/deepseek-thinker-mcp)** - A MCP (Model Context Protocol) provider Deepseek reasoning content to MCP-enabled AI Clients, like Claude Desktop. Supports access to Deepseek's thought processes from the Deepseek API service or from a local Ollama server.\n- **[Descope](https://github.com/descope-sample-apps/descope-mcp-server)** - An MCP server to integrate with [Descope](https://descope.com) to search audit logs, manage users, and more.\n- **[DevRev](https://github.com/kpsunil97/devrev-mcp-server)** - An MCP server to integrate with DevRev APIs to search through your DevRev Knowledge Graph where objects can be imported from diff. sources listed [here](https://devrev.ai/docs/import#available-sources).\n- **[Dify](https://github.com/YanxingLiu/dify-mcp-server)** - A simple implementation of an MCP server for dify workflows.\n- **[Discord](https://github.com/v-3/discordmcp)** - A MCP server to connect to Discord guilds through a bot and read and write messages in channels\n- **[Docker](https://github.com/ckreiling/mcp-server-docker)** - Integrate with Docker to manage containers, images, volumes, and networks.\n- **[Drupal](https://github.com/Omedia/mcp-server-drupal)** - Server for interacting with [Drupal](https://www.drupal.org/project/mcp) using STDIO transport layer.\n- **[Elasticsearch](https://github.com/cr7258/elasticsearch-mcp-server)** - MCP server implementation that provides Elasticsearch interaction.\n- **[ElevenLabs](https://github.com/mamertofabian/elevenlabs-mcp-server)** - A server that integrates with ElevenLabs text-to-speech API capable of generating full voiceovers with multiple voices.\n- **[Eunomia](https://github.com/whataboutyou-ai/eunomia-MCP-server)** - Extension of the Eunomia framework that connects Eunomia instruments with MCP servers\n- **[Everything Search](https://github.com/mamertofabian/mcp-everything-search)** - Fast file searching capabilities across Windows (using [Everything SDK](https://www.voidtools.com/support/everything/sdk/)), macOS (using mdfind command), and Linux (using locate/plocate command).\n- **[Fetch](https://github.com/zcaceres/fetch-mcp)** - A server that flexibly fetches HTML, JSON, Markdown, or plaintext.\n- **[FireCrawl](https://github.com/vrknetha/mcp-server-firecrawl)** - Advanced web scraping with JavaScript rendering, PDF support, and smart rate limiting\n- **[FlightRadar24](https://github.com/sunsetcoder/flightradar24-mcp-server)** - A Claude Desktop MCP server that helps you track flights in real-time using Flightradar24 data.\n- **[Ghost](https://github.com/MFYDev/ghost-mcp)** - A Model Context Protocol (MCP) server for interacting with Ghost CMS through LLM interfaces like Claude.\n- **[Glean](https://github.com/longyi1207/glean-mcp-server)** - A server that uses Glean API to search and chat.\n- **[Gmail](https://github.com/GongRzhe/Gmail-MCP-Server)** - A Model Context Protocol (MCP) server for Gmail integration in Claude Desktop with auto authentication support.\n- **[Goal Story](https://github.com/hichana/goalstory-mcp)** - a Goal Tracker and Visualization Tool for personal and professional development.\n- **[Golang Filesystem Server](https://github.com/mark3labs/mcp-filesystem-server)** - Secure file operations with configurable access controls built with Go!\n- **[Google Calendar](https://github.com/v-3/google-calendar)** - Integration with Google Calendar to check schedules, find time, and add/delete events\n- **[Google Calendar](https://github.com/nspady/google-calendar-mcp)** - Google Calendar MCP Server for managing Google calendar events. Also supports searching for events by attributes like title and location.\n- **[Google Custom Search](https://github.com/adenot/mcp-google-search)** - Provides Google Search results via the Google Custom Search API\n- **[Google Tasks](https://github.com/zcaceres/gtasks-mcp)** - Google Tasks API Model Context Protocol Server.\n- **[Holaspirit](https://github.com/syucream/holaspirit-mcp-server)** - Interact with [Holaspirit](https://www.holaspirit.com/).\n- **[Home Assistant](https://github.com/tevonsb/homeassistant-mcp)** - Interact with [Home Assistant](https://www.home-assistant.io/) including viewing and controlling lights, switches, sensors, and all other Home Assistant entities.\n- **[HubSpot](https://github.com/buryhuang/mcp-hubspot)** - HubSpot CRM integration for managing contacts and companies. Create and retrieve CRM data directly through Claude chat.\n- **[HuggingFace Spaces](https://github.com/evalstate/mcp-hfspace)** - Server for using HuggingFace Spaces, supporting Open Source Image, Audio, Text Models and more. Claude Desktop mode for easy integration.\n- **[Inoyu](https://github.com/sergehuber/inoyu-mcp-unomi-server)** - Interact with an Apache Unomi CDP customer data platform to retrieve and update customer profiles\n- **[iTerm MCP](https://github.com/ferrislucas/iterm-mcp)** - Integration with iTerm2 terminal emulator for macOS, enabling LLMs to execute and monitor terminal commands.\n- **[JavaFX](https://github.com/mcpso/mcp-server-javafx)** - Make drawings using a JavaFX canvas\n- **[JDBC](https://github.com/quarkiverse/quarkus-mcp-servers/tree/main/jdbc)** - Connect to any JDBC-compatible database and query, insert, update, delete, and more. Supports MySQL, PostgreSQL, Oracle, SQL Server, sqllite and [more](https://github.com/quarkiverse/quarkus-mcp-servers/tree/main/jdbc#supported-jdbc-variants).\n- **[JSON](https://github.com/GongRzhe/JSON-MCP-Server)** - JSON handling and processing server with advanced query capabilities using JSONPath syntax and support for array, string, numeric, and date operations.\n- **[Keycloak MCP](https://github.com/ChristophEnglisch/keycloak-model-context-protocol)** - This MCP server enables natural language interaction with Keycloak for user and realm management including creating, deleting, and listing users and realms.\n- **[Kibela](https://github.com/kiwamizamurai/mcp-kibela-server)** (by kiwamizamurai) - Interact with Kibela API.\n- **[kintone](https://github.com/macrat/mcp-server-kintone)** - Manage records and apps in [kintone](https://kintone.com) through LLM tools.\n- **[Kubernetes](https://github.com/Flux159/mcp-server-kubernetes)** - Connect to Kubernetes cluster and manage pods, deployments, and services.\n- **[Lightdash](https://github.com/syucream/lightdash-mcp-server)** - Interact with [Lightdash](https://www.lightdash.com/), a BI tool.\n- **[Linear](https://github.com/jerhadf/linear-mcp-server)** - Allows LLM to interact with Linear's API for project management, including searching, creating, and updating issues.\n- **[LlamaCloud](https://github.com/run-llama/mcp-server-llamacloud)** (by marcusschiesser) - Integrate the data stored in a managed index on [LlamaCloud](https://cloud.llamaindex.ai/)\n- **[llm-context](https://github.com/cyberchitta/llm-context.py)** - Provides a repo-packing MCP tool with configurable profiles that specify file inclusion/exclusion patterns and optional prompts.\n- **[MariaDB](https://github.com/abel9851/mcp-server-mariadb)** - MariaDB database integration with configurable access controls in Python.\n- **[MCP Compass](https://github.com/liuyoshio/mcp-compass)** - Suggest the right MCP server for your needs\n- **[MCP Installer](https://github.com/anaisbetts/mcp-installer)** - This server is a server that installs other MCP servers for you.\n- **[mcp-k8s-go](https://github.com/strowk/mcp-k8s-go)** - Golang-based Kubernetes server for MCP to browse pods and their logs, events, namespaces and more. Built to be extensible.\n- **[mcp-proxy](https://github.com/sparfenyuk/mcp-proxy)** - Connect to MCP servers that run on SSE transport, or expose stdio servers as an SSE server.\n- **[MSSQL](https://github.com/aekanun2020/mcp-server/)** - MSSQL database integration with configurable access controls and schema inspection\n- **[MSSQL](https://github.com/JexinSam/mssql_mcp_server)** (by jexin) - MCP Server for MSSQL database in Python\n- **[MSSQL-Python](https://github.com/amornpan/py-mcp-mssql)** (by amornpan) - A read-only Python implementation for MSSQL database access with enhanced security features, configurable access controls, and schema inspection capabilities. Focuses on safe database interaction through Python ecosystem.\n- **[Markdownify](https://github.com/zcaceres/mcp-markdownify-server)** - MCP to convert almost anything to Markdown (PPTX, HTML, PDF, Youtube Transcripts and more)\n- **[Minima](https://github.com/dmayboroda/minima)** - MCP server for RAG on local files\n- **[MongoDB](https://github.com/kiliczsh/mcp-mongo-server)** - A Model Context Protocol Server for MongoDB.\n- **[Monday.com](https://github.com/sakce/mcp-server-monday)** - MCP Server to interact with Monday.com boards and items.\n- **[MySQL](https://github.com/benborla/mcp-server-mysql)** (by benborla) - MySQL database integration in NodeJS with configurable access controls and schema inspection\n- **[MySQL](https://github.com/designcomputer/mysql_mcp_server)** (by DesignComputer) - MySQL database integration in Python with configurable access controls and schema inspection\n- **[NS Travel Information](https://github.com/r-huijts/ns-mcp-server)** - Access Dutch Railways (NS) real-time train travel information and disruptions through the official NS API.\n- **[Neo4j](https://github.com/da-okazaki/mcp-neo4j-server)** - A community built server that interacts with Neo4j Graph Database.\n- **[Neovim](https://github.com/bigcodegen/mcp-neovim-server)** - An MCP Server for your Neovim session.\n- **[Notion](https://github.com/suekou/mcp-notion-server)** (by suekou) - Interact with Notion API.\n- **[Notion](https://github.com/v-3/notion-server)** (by v-3) - Notion MCP integration. Search, Read, Update, and Create pages through Claude chat.\n- **[oatpp-mcp](https://github.com/oatpp/oatpp-mcp)** - C++ MCP integration for Oat++. Use [Oat++](https://oatpp.io) to build MCP servers.\n- **[Obsidian Markdown Notes](https://github.com/calclavia/mcp-obsidian)** - Read and search through your Obsidian vault or any directory containing Markdown notes\n- **[obsidian-mcp](https://github.com/StevenStavrakis/obsidian-mcp)** - (by Steven Stavrakis) An MCP server for Obsidian.md with tools for searching, reading, writing, and organizing notes.\n- **[Okta](https://github.com/kapilduraphe/okta-mcp-server)** - Interact with Okta API.\n- **[OpenAPI](https://github.com/snaggle-ai/openapi-mcp-server)** - Interact with [OpenAPI](https://www.openapis.org/) APIs.\n- **[OpenCTI](https://github.com/Spathodea-Network/opencti-mcp)** - Interact with OpenCTI platform to retrieve threat intelligence data including reports, indicators, malware and threat actors.\n- **[OpenRPC](https://github.com/shanejonas/openrpc-mpc-server)** - Interact with and discover JSON-RPC APIs via [OpenRPC](https://open-rpc.org).\n- **[Open Strategy Partners Marketing Tools](https://github.com/open-strategy-partners/osp_marketing_tools)** - Content editing codes, value map, and positioning tools for product marketing.\n- **[Pandoc](https://github.com/vivekVells/mcp-pandoc)** - MCP server for seamless document format conversion using Pandoc, supporting Markdown, HTML, PDF, DOCX (.docx), csv and more.\n- **[PIF](https://github.com/hungryrobot1/MCP-PIF)** - A Personal Intelligence Framework (PIF), providing tools for file operations, structured reasoning, and journal-based documentation to support continuity and evolving human-AI collaboration across sessions.\n- **[Pinecone](https://github.com/sirmews/mcp-pinecone)** - MCP server for searching and uploading records to Pinecone. Allows for simple RAG features, leveraging Pinecone's Inference API.\n- **[Placid.app](https://github.com/felores/placid-mcp-server)** - Generate image and video creatives using Placid.app templates\n- **[Playwright](https://github.com/executeautomation/mcp-playwright)** - This MCP Server will help you run browser automation and webscraping using Playwright\n- **[Postman](https://github.com/shannonlal/mcp-postman)** - MCP server for running Postman Collections locally via Newman. Allows for simple execution of Postman Server and returns the results of whether the collection passed all the tests.\n- **[Qwen_Max](https://github.com/66julienmartin/MCP-server-Qwen_Max)** - A Model Context Protocol (MCP) server implementation for the Qwen models.\n- **[RabbitMQ](https://github.com/kenliao94/mcp-server-rabbitmq)** - The MCP server that interacts with RabbitMQ to publish and consume messages.\n- **[RAG Web Browser](https://github.com/apify/mcp-server-rag-web-browser)** An MCP server for Apify's open-source RAG Web Browser [Actor](https://apify.com/apify/rag-web-browser) to perform web searches, scrape URLs, and return content in Markdown.\n- **[Reaper](https://github.com/dschuler36/reaper-mcp-server)** - Interact with your [Reaper](https://www.reaper.fm/) (Digital Audio Workstation) projects.\n- **[Redis](https://github.com/GongRzhe/REDIS-MCP-Server)** - Redis database operations and caching microservice server with support for key-value operations, expiration management, and pattern-based key listing.\n- **[Redis](https://github.com/prajwalnayak7/mcp-server-redis)** MCP server to interact with Redis Server, AWS Memory DB, etc for caching or other use-cases where in-memory and key-value based storage is appropriate\n- **[Rememberizer AI](https://github.com/skydeckai/mcp-server-rememberizer)** - An MCP server designed for interacting with the Rememberizer data source, facilitating enhanced knowledge retrieval.\n- **[Replicate](https://github.com/deepfates/mcp-replicate)** - Search, run and manage machine learning models on Replicate through a simple tool-based interface. Browse models, create predictions, track their status, and handle generated images.\n- **[Rijksmuseum](https://github.com/r-huijts/rijksmuseum-mcp)** - Interface with the Rijksmuseum API to search artworks, retrieve artwork details, access image tiles, and explore user collections.\n- **[Salesforce MCP](https://github.com/smn2gnt/MCP-Salesforce)** - Interact with Salesforce Data and Metadata\n- **[Scholarly](https://github.com/adityak74/mcp-scholarly)** - A MCP server to search for scholarly and academic articles.\n- **[SearXNG](https://github.com/ihor-sokoliuk/mcp-searxng)** - A Model Context Protocol Server for [SearXNG](https://docs.searxng.org)\n- **[Snowflake](https://github.com/isaacwasserman/mcp-snowflake-server)** - This MCP server enables LLMs to interact with Snowflake databases, allowing for secure and controlled data operations.\n- **[Solana Agent Kit](https://github.com/sendaifun/solana-agent-kit/tree/main/examples/agent-kit-mcp-server)** - This MCP server enables LLMs to interact with the Solana blockchain with help of Solana Agent Kit by SendAI, allowing for 40+ protcool actions and growing \n- **[Spotify](https://github.com/varunneal/spotify-mcp)** - This MCP allows an LLM to play and use Spotify.\n- **[Stripe](https://github.com/atharvagupta2003/mcp-stripe)** - This MCP allows integration with Stripe for handling payments, customers, and refunds.\n- **[TMDB](https://github.com/Laksh-star/mcp-server-tmdb)** - This MCP server integrates with The Movie Database (TMDB) API to provide movie information, search capabilities, and recommendations.\n- **[Tavily search](https://github.com/RamXX/mcp-tavily)** - An MCP server for Tavily's search & news API, with explicit site inclusions/exclusions\n- **[Ticketmaster](https://github.com/delorenj/mcp-server-ticketmaster)** - Search for events, venues, and attractions through the Ticketmaster Discovery API\n- **[Todoist](https://github.com/abhiz123/todoist-mcp-server)** - Interact with Todoist to manage your tasks.\n- **[Travel Planner](https://github.com/GongRzhe/TRAVEL-PLANNER-MCP-Server)** - Travel planning and itinerary management server integrating with Google Maps API for location search, place details, and route calculations.\n- **[Vega-Lite](https://github.com/isaacwasserman/mcp-vegalite-server)** - Generate visualizations from fetched data using the VegaLite format and renderer.\n- **[Video Editor](https://github.com/burningion/video-editing-mcp)** - A Model Context Protocol Server to add, edit, and search videos with [Video Jungle](https://www.video-jungle.com/).\n- **[Virtual location (Google Street View,etc.)](https://github.com/mfukushim/map-traveler-mcp)** - Integrates Google Map, Google Street View, PixAI, Stability.ai, ComfyUI API and Bluesky to provide a virtual location simulation in LLM (written in Effect.ts)\n- **[WildFly MCP](https://github.com/wildfly-extras/wildfly-mcp)** - WildFly MCP server that enables LLM to interact with running WildFly servers (retrieve metrics, logs, invoke operations, ...).\n- **[Windows CLI](https://github.com/SimonB97/win-cli-mcp-server)** - MCP server for secure command-line interactions on Windows systems, enabling controlled access to PowerShell, CMD, and Git Bash shells.\n- **[World Bank data API](https://github.com/anshumax/world_bank_mcp_server)** - A server that fetches data indicators available with the World Bank as part of their data API\n- **[X (Twitter)](https://github.com/EnesCinr/twitter-mcp)** (by EnesCinr) - Interact with twitter API. Post tweets and search for tweets by query.\n- **[X (Twitter)](https://github.com/vidhupv/x-mcp)** (by vidhupv) - Create, manage and publish X/Twitter posts directly through Claude chat.\n- **[XMind](https://github.com/apeyroux/mcp-xmind)** - Read and search through your XMind directory containing XMind files.\n- **[YouTube](https://github.com/ZubeidHendricks/youtube-mcp-server)** - Comprehensive YouTube API integration for video management, Shorts creation, and analytics.\n\n## 📚 Frameworks\n\nThese are high-level frameworks that make it easier to build MCP servers or clients.\n\n### For servers\n\n* **[EasyMCP](https://github.com/zcaceres/easy-mcp/)** (TypeScript)\n* **[FastMCP](https://github.com/punkpeye/fastmcp)** (TypeScript)\n* **[Foxy Contexts](https://github.com/strowk/foxy-contexts)** – A library to build MCP servers in Golang by **[strowk](https://github.com/strowk)**\n* **[Quarkus MCP Server SDK](https://github.com/quarkiverse/quarkus-mcp-server)** (Java)\n\n### For clients\n\n* **[codemirror-mcp](https://github.com/marimo-team/codemirror-mcp)** - CodeMirror extension that implements the Model Context Protocol (MCP) for resource mentions and prompt commands\n\n## 📚 Resources\n\nAdditional resources on MCP.\n\n- **[AiMCP](https://www.aimcp.info)** - A collection of MCP clients&servers to find the right mcp tools by **[Hekmon](https://github.com/hekmon8)**\n- **[Awesome Crypto MCP Servers by badkk](https://github.com/badkk/awesome-crypto-mcp-servers)** - A curated list of MCP servers by **[Luke Fan](https://github.com/badkk)**\n- **[Awesome MCP Servers by appcypher](https://github.com/appcypher/awesome-mcp-servers)** - A curated list of MCP servers by **[Stephen Akinyemi](https://github.com/appcypher)**\n- **[Awesome MCP Servers by punkpeye](https://github.com/punkpeye/awesome-mcp-servers)** (**[website](https://glama.ai/mcp/servers)**) - A curated list of MCP servers by **[Frank Fiegel](https://github.com/punkpeye)**\n- **[Awesome MCP Servers by wong2](https://github.com/wong2/awesome-mcp-servers)** (**[website](https://mcpservers.org)**) - A curated list of MCP servers by **[wong2](https://github.com/wong2)**\n- **[Discord Server](https://glama.ai/mcp/discord)** – A community discord server dedicated to MCP by **[Frank Fiegel](https://github.com/punkpeye)**\n- **[MCP Badges](https://github.com/mcpx-dev/mcp-badges)** – Quickly highlight your MCP project with clear, eye-catching badges, by **[Ironben](https://github.com/nanbingxyz)**\n- **[MCP Servers Hub](https://github.com/apappascs/mcp-servers-hub)** (**[website](https://mcp-servers-hub-website.pages.dev/)**) - A curated list of MCP servers by **[apappascs](https://github.com/apappascs)**\n- **[MCP X Community](https://x.com/i/communities/1861891349609603310)** – A X community for MCP by **[Xiaoyi](https://x.com/chxy)**\n- **[mcp-cli](https://github.com/wong2/mcp-cli)** - A CLI inspector for the Model Context Protocol by **[wong2](https://github.com/wong2)**\n- **[mcp-get](https://mcp-get.com)** - Command line tool for installing and managing MCP servers by **[Michael Latman](https://github.com/michaellatman)**\n- **[mcp-manager](https://github.com/zueai/mcp-manager)** - Simple Web UI to install and manage MCP servers for Claude Desktop by **[Zue](https://github.com/zueai)**\n- **[MCPHub](https://github.com/Jeamee/MCPHub-Desktop)** – An Open Source MacOS & Windows GUI Desktop app for discovering, installing and managing MCP servers by **[Jeamee](https://github.com/jeamee)**\n- **[mcp.run](https://mcp.run)** - A hosted registry and control plane to install & run secure + portable MCP Servers.\n- **[Open-Sourced MCP Servers Directory](https://github.com/chatmcp/mcp-directory)** - A curated list of MCP servers by **[mcpso](https://mcp.so)**\n- <img height=\"12\" width=\"12\" src=\"https://opentools.com/favicon.ico\" alt=\"OpenTools Logo\" /> **[OpenTools](https://opentools.com)** - An open registry for finding, installing, and building with MCP servers by **[opentoolsteam](https://github.com/opentoolsteam)**\n- **[PulseMCP](https://www.pulsemcp.com)** ([API](https://www.pulsemcp.com/api)) - Community hub & weekly newsletter for discovering MCP servers, clients, articles, and news by **[Tadas Antanavicius](https://github.com/tadasant)**, **[Mike Coughlin](https://github.com/macoughl)**, and **[Ravina Patel](https://github.com/ravinahp)**\n- **[r/mcp](https://www.reddit.com/r/mcp)** – A Reddit community dedicated to MCP by **[Frank Fiegel](https://github.com/punkpeye)**\n- **[Smithery](https://smithery.ai/)** - A registry of MCP servers to find the right tools for your LLM agents by **[Henry Mao](https://github.com/calclavia)**\n- **[Toolbase](https://gettoolbase.ai)** - Desktop application that manages tools and MCP servers with just a few clicks - no coding required by **[gching](https://github.com/gching)**\n\n## 🚀 Getting Started\n\n### Using MCP Servers in this Repository\nTypescript-based servers in this repository can be used directly with `npx`.\n\nFor example, this will start the [Memory](src/memory) server:\n```sh\nnpx -y @modelcontextprotocol/server-memory\n```\n\nPython-based servers in this repository can be used directly with [`uvx`](https://docs.astral.sh/uv/concepts/tools/) or [`pip`](https://pypi.org/project/pip/). `uvx` is recommended for ease of use and setup.\n\nFor example, this will start the [Git](src/git) server:\n```sh\n# With uvx\nuvx mcp-server-git\n\n# With pip\npip install mcp-server-git\npython -m mcp_server_git\n```\n\nFollow [these](https://docs.astral.sh/uv/getting-started/installation/) instructions to install `uv` / `uvx` and [these](https://pip.pypa.io/en/stable/installation/) to install `pip`.\n\n### Using an MCP Client\nHowever, running a server on its own isn't very useful, and should instead be configured into an MCP client. For example, here's the Claude Desktop configuration to use the above server:\n\n```json\n{\n  \"mcpServers\": {\n    \"memory\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-memory\"]\n    }\n  }\n}\n```\n\nAdditional examples of using the Claude Desktop as an MCP client might look like:\n\n```json\n{\n  \"mcpServers\": {\n    \"filesystem\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-filesystem\", \"/path/to/allowed/files\"]\n    },\n    \"git\": {\n      \"command\": \"uvx\",\n      \"args\": [\"mcp-server-git\", \"--repository\", \"path/to/git/repo\"]\n    },\n    \"github\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-github\"],\n      \"env\": {\n        \"GITHUB_PERSONAL_ACCESS_TOKEN\": \"<YOUR_TOKEN>\"\n      }\n    },\n    \"postgres\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-postgres\", \"postgresql://localhost/mydb\"]\n    }\n  }\n}\n```\n\n## 🛠️ Creating Your Own Server\n\nInterested in creating your own MCP server? Visit the official documentation at [modelcontextprotocol.io](https://modelcontextprotocol.io/introduction) for comprehensive guides, best practices, and technical details on implementing MCP servers.\n\n## 🤝 Contributing\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md) for information about contributing to this repository.\n\n## 🔒 Security\n\nSee [SECURITY.md](SECURITY.md) for reporting security vulnerabilities.\n\n## 📜 License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## 💬 Community\n\n- [GitHub Discussions](https://github.com/orgs/modelcontextprotocol/discussions)\n\n## ⭐ Support\n\nIf you find MCP servers useful, please consider starring the repository and contributing new servers or improvements!\n\n---\n\nManaged by Anthropic, but built together with the community. The Model Context Protocol is open source and we encourage everyone to contribute their own servers and improvements!",
      "npm_url": "https://www.npmjs.com/package/mcp-servers",
      "npm_downloads": 854,
      "keywords": [
        "chats",
        "memory",
        "persistent",
        "memory ai",
        "information chats",
        "persistent memory"
      ],
      "category": "memory-management"
    },
    "divslingerx--mcp-server": {
      "owner": "divslingerx",
      "name": "mcp-server",
      "url": "https://github.com/divslingerx/mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/divslingerx.webp",
      "description": "Provides web search capabilities using Puppeteer, returning structured JSON results from Google searches in a lightweight and stateless design.",
      "stars": 0,
      "forks": 4,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-01-20T18:03:10Z",
      "readme_content": "# Memory Store MCP Server\n\nA Model Context Protocol (MCP) server that provides web search capabilities using Puppeteer.\n\n## Features\n\n- Web search functionality via Google\n- Structured JSON results\n- Lightweight and stateless design\n- Easy integration with MCP-enabled systems\n\n## Installation\n\n1. Clone the repository:\n\n   ```bash\n   git clone https://github.com/yourusername/mcp-server.git\n   cd mcp-server\n   ```\n\n2. Install dependencies:\n\n   ```bash\n   npm install\n   ```\n\n3. Build the project:\n   ```bash\n   npm run build\n   ```\n\n## Configuration\n\nCreate a `.env` file in the project root with the following environment variables:\n\n```env\n# Puppeteer configuration\nPUPPETEER_EXECUTABLE_PATH=/path/to/chrome\nPUPPETEER_HEADLESS=true\n\n# Server settings\nPORT=3000\n```\n\n## Usage\n\nStart the server:\n\n```bash\nnpm start\n```\n\nThe server will be available to MCP clients. Example usage through MCP:\n\n```json\n{\n  \"tool\": \"search_web\",\n  \"arguments\": {\n    \"query\": \"example search\"\n  }\n}\n```\n\n## Development\n\n### Building the Project\n\n```bash\nnpm run build\n```\n\n### Running Tests\n\n```bash\nnpm test\n```\n\n### Linting\n\n```bash\nnpm run lint\n```\n\n### Formatting\n\n```bash\nnpm run format\n```\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n",
      "npm_url": "https://www.npmjs.com/package/mcp-server",
      "npm_downloads": 29732,
      "keywords": [
        "puppeteer",
        "searches",
        "memory",
        "using puppeteer",
        "searches lightweight",
        "mcp server"
      ],
      "category": "memory-management"
    },
    "docdyhr--simplenote-mcp-server": {
      "owner": "docdyhr",
      "name": "simplenote-mcp-server",
      "url": "https://github.com/docdyhr/simplenote-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/docdyhr.webp",
      "description": "Connect and manage your Simplenote notes, enabling actions like creating, updating, and deleting notes directly from LLM applications.",
      "stars": 7,
      "forks": 1,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-02T13:16:10Z",
      "readme_content": "# Simplenote MCP Server\n\n\n\nA lightweight MCP server that integrates [Simplenote](https://simplenote.com/) with [Claude Desktop](https://github.com/johnsmith9982/claude-desktop) using the [MCP Python SDK](https://github.com/johnsmith9982/mcp-python-sdk).\n\nThis allows Claude Desktop to interact with your Simplenote notes as a memory backend or content source.\n\n<!-- Status & Build Badges -->\n[](https://github.com/docdyhr/simplenote-mcp-server/actions/workflows/ci.yml)\n[](https://github.com/docdyhr/simplenote-mcp-server/actions/workflows/code-quality.yml)\n[![Security](https://github.com/docdyhr/simplenote-mcp-server/actions/workflows/security.yml/badge.svg?branch=main)](https://github.com/docdyhr/simplenote-mcp-server/actions/workflows/security.yml)\n[](https://github.com/docdyhr/simplenote-mcp-server/actions/workflows/docker-publish.yml)\n\n<!-- Project Info Badges -->\n[![Python Version](https://img.shields.io/badge/python-3.10%20%7C%203.11%20%7C%203.12%20%7C%203.13-blue)](https://github.com/docdyhr/simplenote-mcp-server)\n[![Version](https://img.shields.io/badge/version-1.7.0-blue.svg)](./CHANGELOG.md)\n[![Test Coverage](https://img.shields.io/badge/coverage-15.6%25-yellow)](./htmlcov/index.html)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Docker](https://img.shields.io/docker/v/docdyhr/simplenote-mcp-server?label=docker&color=blue)](https://hub.docker.com/r/docdyhr/simplenote-mcp-server)\n\n<!-- Download & Stats Badges -->\n[![PyPI Downloads](https://img.shields.io/pypi/dm/simplenote-mcp-server?label=PyPI%20downloads)](https://pypi.org/project/simplenote-mcp-server/)\n[![Docker Pulls](https://img.shields.io/docker/pulls/docdyhr/simplenote-mcp-server?label=Docker%20pulls)](https://hub.docker.com/r/docdyhr/simplenote-mcp-server)\n[![GitHub Stars](https://img.shields.io/github/stars/docdyhr/simplenote-mcp-server?style=social)](https://github.com/docdyhr/simplenote-mcp-server)\n\n<!-- Development & Quality Badges -->\n[![MCP Server](https://img.shields.io/badge/MCP-Server-purple.svg)](https://github.com/modelcontextprotocol)\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n[![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json)](https://github.com/astral-sh/ruff)\n[![Smithery](https://smithery.ai/badge/@docdyhr/simplenote-mcp-server)](https://smithery.ai/server/@docdyhr/simplenote-mcp-server)\n\n[![Verified on MseeP](https://mseep.ai/badge.svg)](https://mseep.ai/app/b215d030-b511-457d-8a6d-3e1e6ea3b541)\n---\n\n## 🔧 Features\n\n- 📝 **Full Note Management**: Read, create, update, and delete Simplenote notes\n- 🔍 **Advanced Search**: Boolean operators, phrase matching, tag and date filters\n- ⚡ **High Performance**: In-memory caching with background synchronization\n- 🔐 **Secure Authentication**: Token-based authentication via environment variables\n- 🧩 **MCP Compatible**: Works with Claude Desktop and other MCP clients\n- 🐳 **Docker Ready**: Full containerization with multi-stage builds and security hardening\n- 📊 **Monitoring**: Optional HTTP endpoints for health, readiness, and metrics\n- 🧪 **Robust Testing**: Comprehensive test suite with 700+ tests and continuous integration\n- 🔒 **Security Hardened**: Regular security scanning with Bandit, pip-audit, and dependency checks\n\n---\n\n## 🚀 Quick Start\n\n### Prerequisites\n\n- Simplenote account (create one at [simplenote.com](https://simplenote.com/))\n- Python 3.10+ (for non-Docker installs) or Docker\n\n### Option 1: Docker (Recommended)\n\nThe fastest way to get started is using our pre-built Docker image:\n\n```bash\n# Pull and run the latest image\ndocker run -d \\\n  --name simplenote-mcp \\\n  -e SIMPLENOTE_EMAIL=your.email@example.com \\\n  -e SIMPLENOTE_PASSWORD=your-password \\\n  -p 8000:8000 \\\n  docdyhr/simplenote-mcp-server:latest\n```\n\n**Docker Health Checks:** The container includes built-in health monitoring endpoints:\n- Health: `http://localhost:8000/health`\n- Readiness: `http://localhost:8000/ready`  \n- Metrics: `http://localhost:8000/metrics` (Prometheus format)\n\nOr use Docker Compose:\n\n```bash\n# Clone the repository for docker-compose.yml\ngit clone https://github.com/docdyhr/simplenote-mcp-server.git\ncd simplenote-mcp-server\n\n# Set environment variables\nexport SIMPLENOTE_EMAIL=your.email@example.com\nexport SIMPLENOTE_PASSWORD=your-password\n\n# Run with Docker Compose\ndocker-compose up -d\n```\n\n### Option 2: Smithery (One-click install)\n\nInstall automatically via [Smithery](https://smithery.ai/server/@docdyhr/simplenote-mcp-server):\n\n```bash\nnpx -y @smithery/cli install @docdyhr/simplenote-mcp-server --client claude\n```\n\nThis method automatically configures Claude Desktop with the MCP server.\n\n### Option 3: Traditional Python Install\n\n```bash\ngit clone https://github.com/docdyhr/simplenote-mcp-server.git\ncd simplenote-mcp-server\npip install -e .\nsimplenote-mcp-server\n```\n\n---\n\n## 🐳 Docker Deployment\n\n### Container Features\n\n- **Multi-stage builds** for optimized image size\n- **Security hardening** with non-root user and minimal attack surface\n- **Health monitoring** endpoints built-in\n- **Resource limits** and proper signal handling\n- **Volume support** for persistent data\n\n### Using Pre-built Images\n\nThe easiest way to use the server is with our pre-built Docker images:\n\n```bash\n# Pull the latest image\ndocker pull docdyhr/simplenote-mcp-server:latest\n\n# Run with Docker\ndocker run -d \\\n  -e SIMPLENOTE_EMAIL=your.email@example.com \\\n  -e SIMPLENOTE_PASSWORD=your-password \\\n  -p 8000:8000 \\\n  docdyhr/simplenote-mcp-server:latest\n\n# Or use Docker Compose\ndocker-compose up -d\n```\n\nAvailable tags:\n\n- `latest` - Latest stable release\n- `v1.6.0` - Specific version\n- `main` - Latest development build\n\n### Production Deployment\n\n```bash\n# Build and run the production container\ndocker-compose up -d\n\n# Or build manually\ndocker build -t simplenote-mcp-server .\ndocker run -d \\\n  -e SIMPLENOTE_EMAIL=your.email@example.com \\\n  -e SIMPLENOTE_PASSWORD=your-password \\\n  -p 8000:8000 \\\n  simplenote-mcp-server\n```\n\n### Development with Docker\n\n```bash\n# Use the development compose file for live code mounting\ndocker-compose -f docker-compose.dev.yml up\n```\n\n### Docker Features\n\n- **Multi-stage build** for optimized image size (346MB)\n- **Multi-platform support**: `linux/amd64` and `linux/arm64`\n- **Security hardening**: Non-root user, read-only filesystem, no new privileges\n- **Health checks** and automatic restart policies\n- **Resource limits**: 1 CPU, 512MB memory\n- **Logging**: Persistent log volumes\n- **Environment-based configuration**\n- **CI/CD Pipeline**: Automated builds and publishing to Docker Hub\n- **Security scanning**: Trivy vulnerability scanning on all images\n- **Container signing**: Sigstore cosign signatures for supply chain security\n- **Kubernetes ready**: Production-grade Helm chart with security hardening\n- **Automated updates**: Dependabot for dependencies, auto-versioning workflows\n- **Health monitoring**: Continuous health checks and alerting\n- **Enterprise notifications**: Slack and email integration for CI/CD status\n\n---\n\n## ☸️ Kubernetes Deployment\n\n### Using Helm (Recommended)\n\nDeploy to Kubernetes with our production-ready Helm chart:\n\n```bash\n# Install from local chart\nhelm install my-simplenote ./helm/simplenote-mcp-server \\\n  --set simplenote.email=\"your-email@example.com\" \\\n  --set simplenote.password=\"your-password\"\n\n# Or with external secrets (recommended for production)\nhelm install my-simplenote ./helm/simplenote-mcp-server \\\n  --set externalSecrets.enabled=true \\\n  --set externalSecrets.secretStore.name=\"vault-backend\"\n```\n\n### Kubernetes Features\n\n- **Security hardening**: Non-root user, read-only filesystem, dropped capabilities\n- **Resource management**: CPU/memory limits and requests configured\n- **Auto-scaling**: Horizontal Pod Autoscaler support\n- **Health checks**: Liveness and readiness probes\n- **External secrets**: Integration with external secret management\n- **Service mesh ready**: Compatible with Istio and other service meshes\n\n### Production Configuration\n\n```yaml\n# values.yaml for production\nreplicaCount: 3\nautoscaling:\n  enabled: true\n  minReplicas: 2\n  maxReplicas: 10\nresources:\n  limits:\n    cpu: 1000m\n    memory: 512Mi\n  requests:\n    cpu: 500m\n    memory: 256Mi\n```\n\n---\n\n## ⚙️ Configuration\n\n### Environment Variables\n\n| Variable                | Required | Default | Description                                 |\n| ----------------------- | -------- | ------- | ------------------------------------------- |\n| `SIMPLENOTE_EMAIL`      | Yes      | -       | Your Simplenote account email               |\n| `SIMPLENOTE_PASSWORD`   | Yes      | -       | Your Simplenote account password            |\n| `SYNC_INTERVAL_SECONDS` | No       | 120     | Cache synchronization interval              |\n| `LOG_LEVEL`             | No       | INFO    | Logging level (DEBUG, INFO, WARNING, ERROR) |\n\n### Claude Desktop Integration\n\nAdd to your `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"simplenote\": {\n      \"description\": \"Access and manage your Simplenote notes\",\n      \"command\": \"simplenote-mcp-server\",\n      \"env\": {\n        \"SIMPLENOTE_EMAIL\": \"your.email@example.com\",\n        \"SIMPLENOTE_PASSWORD\": \"your-password\"\n      }\n    }\n  }\n}\n```\n\n---\n\n## 🔍 Advanced Search\n\nPowerful search with boolean logic and filters:\n\n```text\n# Boolean operators\nproject AND meeting AND NOT cancelled\n\n# Phrase matching\n\"action items\" AND project\n\n# Tag filtering\nmeeting tag:work tag:important\n\n# Date ranges\nproject from:2023-01-01 to:2023-12-31\n\n# Combined query\n\"status update\" AND project tag:work from:2023-01-01 NOT cancelled\n```\n\n---\n\n## 🛠️ Available Tools\n\n| Tool           | Description                  | Parameters                                                 |\n| -------------- | ---------------------------- | ---------------------------------------------------------- |\n| `create_note`  | Create a new note            | `content`, `tags` (optional)                               |\n| `update_note`  | Update an existing note      | `note_id`, `content`, `tags` (optional)                    |\n| `delete_note`  | Move a note to trash         | `note_id`                                                  |\n| `get_note`     | Get a note by ID             | `note_id`                                                  |\n| `search_notes` | Advanced search with filters | `query`, `limit`, `offset`, `tags`, `from_date`, `to_date` |\n| `add_tags`     | Add tags to a note           | `note_id`, `tags`                                          |\n| `remove_tags`  | Remove tags from a note      | `note_id`, `tags`                                          |\n| `replace_tags` | Replace all tags on a note   | `note_id`, `tags`                                          |\n\n---\n\n## 📊 Performance & Caching\n\n- **In-memory caching** with background synchronization\n- **Pagination support** for large note collections\n- **Indexed lookups** for tags and content\n- **Query result caching** for repeated searches\n- **Optimized API usage** with minimal Simplenote calls\n\n---\n\n## 🎯 Recent Improvements (September 2025)\n\n### ✅ Quality & Reliability Enhancements\n\n**Test Suite Stabilization**: \n- Fixed test isolation issues that caused intermittent failures\n- Improved test cleanup with proper timeout handling\n- Enhanced fixture management for better test reliability\n- Achieved consistent test results across individual and suite runs\n\n**CI/CD Pipeline Optimization**:\n- Consolidated 28 workflows down to 16 active workflows\n- Implemented unified monitoring workflow combining security, health, and badge checks\n- Improved test coverage reporting with realistic 15.6% baseline\n- Enhanced Docker build validation and security scanning\n\n**Code Quality Improvements**:\n- All linting (Ruff), formatting, and type checking (MyPy) now pass consistently  \n- Zero high-severity security vulnerabilities (verified with Bandit, pip-audit, safety)\n- Standardized code formatting and pre-commit hooks configuration\n- Enhanced error handling and user-facing error messages\n\n### 🔧 Developer Experience\n\n**Improved Testing**:\n- 724 comprehensive tests covering core functionality\n- Function-scoped fixtures for better test isolation  \n- Realistic coverage baseline established (15.6%)\n- Streamlined test execution with proper cleanup\n\n**Enhanced Documentation**:\n- Updated deployment guides with current Docker setup\n- Improved health monitoring endpoint documentation\n- Added troubleshooting guides for common issues\n- Current status and roadmap documentation\n\n**Container Improvements**:\n- Multi-stage Docker builds for optimized image size\n- Built-in health monitoring endpoints (`/health`, `/ready`, `/metrics`)\n- Enhanced security hardening with non-root user\n- Improved signal handling and graceful shutdown\n\n---\n\n## 🧪 Testing & Evaluation\n\n### MCP Evaluations ✅\n\n**Status**: ✅ **WORKING** - Complete mcp-evals integration with TypeScript wrapper!\n\nThis project includes comprehensive evaluations using [mcp-evals](https://github.com/mclenhard/mcp-evals) to ensure reliability and performance:\n\n```bash\n# Setup evaluation environment\nnpm install\nnpm run validate:evals\n\n# Run evaluation suites\nnpm run eval:smoke          # Quick smoke tests (2-3 minutes) ✅ VERIFIED\nnpm run eval:basic          # Standard evaluations (5-10 minutes)\nnpm run eval:comprehensive  # Full evaluation suite (15-30 minutes)\n```\n\n**Latest Test Results**: 4/5 tests passing excellently (avg 4.1/5):\n\n- **Server Startup**: 4.6/5 ⭐ (Excellent)\n- **Authentication**: 4.0/5 ⭐ (Good)\n- **Note Operations**: 3.8/5 ⭐ (Good)\n- **Search**: 5.0/5 ⭐ (Perfect)\n- **Error Handling**: 1.4/5 ⚠️ (Needs improvement)\n\n#### Evaluation Types\n\n- **Smoke Tests**: Basic functionality validation\n- **CRUD Operations**: Note creation, reading, updating, deletion\n- **Search & Filtering**: Boolean search, tag filtering, date ranges\n- **Error Handling**: Authentication, network issues, edge cases\n- **Performance**: Large datasets, concurrent operations\n- **Security**: Input validation, authentication enforcement\n\n#### Automated Testing\n\nEvaluations run automatically on:\n\n- **Pull Requests**: Smoke + basic tests\n- **Releases**: Comprehensive evaluation suite\n- **Manual Trigger**: Full test matrix with detailed reporting\n\nThe evaluations use OpenAI's GPT models to assess:\n\n- **Accuracy**: Correctness of responses\n- **Completeness**: Thoroughness of results\n- **Relevance**: Response appropriateness\n- **Clarity**: Response readability\n- **Performance**: Operation efficiency\n\n📁 See [`evals/README.md`](./evals/README.md) for detailed evaluation documentation.\n\n### Traditional Testing\n\n```bash\n# Python unit tests\npytest\n\n# Code quality checks\nruff check .\nmypy simplenote_mcp\n```\n\n---\n\n## 🛡️ Security\n\n- **Token-based authentication** via environment variables\n- **No hardcoded credentials** in Docker images\n- **Security-hardened containers** with non-root users\n- **Read-only filesystem** in production containers\n- **Resource limits** to prevent abuse\n\n---\n\n## 🚨 Troubleshooting\n\n### Common Issues\n\n**Authentication Problems**:\n\n- Verify `SIMPLENOTE_EMAIL` and `SIMPLENOTE_PASSWORD` are set correctly\n- Check for typos in credentials\n\n**Docker Issues**:\n\n```bash\n# Check container logs\ndocker-compose logs\n\n# Restart services\ndocker-compose restart\n\n# Rebuild if needed\ndocker-compose up --build\n```\n\n**Claude Desktop Connection**:\n\n```bash\n# Verify tools are available\n./simplenote_mcp/scripts/verify_tools.sh\n\n# Monitor logs\n./simplenote_mcp/scripts/watch_logs.sh\n```\n\n### Diagnostic Commands\n\n```bash\n# Test connectivity\npython simplenote_mcp/tests/test_mcp_client.py\n\n# Check server status\n./simplenote_mcp/scripts/check_server_pid.sh\n\n# Clean up and restart\n./simplenote_mcp/scripts/cleanup_servers.sh\n```\n\n---\n\n## 📚 Development\n\n### Quick Setup with mcp-evals\n\n```bash\n# One-command setup including evaluations\n./setup-dev-env-with-evals.sh\n\n# Or manual setup\ngit clone https://github.com/docdyhr/simplenote-mcp-server.git\ncd simplenote-mcp-server\npip install -e \".[dev,test]\"\nnpm install  # For mcp-evals\n```\n\n### Local Development\n\n```bash\n# Run the server\npython simplenote_mcp_server.py\n\n# Run Python tests\npytest\n\n# Run mcp-evals\nnpm run eval:smoke    # Quick validation\nnpm run eval:basic    # Standard tests\nnpm run eval:all      # Full test suite\n\n# Code quality\nruff check .\nruff format .\nmypy simplenote_mcp\n```\n\n### Development Environment\n\nThe setup script creates:\n\n- Python development environment with all dependencies\n- Node.js environment for mcp-evals\n- Example configuration files\n- Pre-commit hooks\n- Validation for all evaluation files\n\n### Testing Strategy\n\n1. **Unit Tests**: Traditional Python pytest for core logic\n2. **Integration Tests**: MCP protocol compliance testing\n3. **Smoke Tests**: Quick validation of basic functionality\n4. **Evaluation Tests**: LLM-based assessment of real-world usage\n5. **Performance Tests**: Load and stress testing\n\n### Running MCP Evaluations\n\n#### Docker Method (Recommended)\nDue to potential permission issues with tsx, we recommend running MCP evaluations in Docker:\n\n```bash\n# Run smoke tests\n./scripts/run-evals-docker.sh smoke\n\n# Run basic evaluations\n./scripts/run-evals-docker.sh basic\n\n# Run comprehensive evaluations\n./scripts/run-evals-docker.sh comprehensive\n\n# Run all evaluations\n./scripts/run-evals-docker.sh all\n```\n\n#### Direct Method (if permissions allow)\n```bash\nnpm run eval:smoke\nnpm run eval:basic\nnpm run eval:comprehensive\nnpm run eval:all\n```\n\n### Docker Development\n\n```bash\n# Development with live code reload\ndocker-compose -f docker-compose.dev.yml up\n\n# Build and test\ndocker build -t simplenote-mcp-server:test .\ndocker run --rm simplenote-mcp-server:test --help\n```\n\n---\n\n## 🤝 Contributing\n\nContributions are welcome! Please read [CONTRIBUTING.md](./CONTRIBUTING.md) for guidelines.\n\n## 📄 License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## 🔗 Related Projects\n\n- [Model Context Protocol](https://modelcontextprotocol.io/)\n- [MCP Example Servers](https://modelcontextprotocol.io/examples)\n\n---\n\n## ⭐ Support the Project\n\nIf you find this project helpful, please consider giving it a star on GitHub! Your support helps:\n\n- 🚀 **Increase visibility** for other developers who might benefit from this tool\n- 💪 **Motivate continued development** and maintenance\n- 📈 **Build community** around the Model Context Protocol ecosystem\n- 🛡️ **Validate trust** through community engagement\n\n[![GitHub stars](https://img.shields.io/github/stars/docdyhr/simplenote-mcp-server?style=social)](https://github.com/docdyhr/simplenote-mcp-server/stargazers)\n\n**[⭐ Star this repository](https://github.com/docdyhr/simplenote-mcp-server)** — it takes just one click and means a lot!\n\n---\n\n[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/docdyhr-simplenote-mcp-server-badge.png)](https://mseep.ai/app/docdyhr-simplenote-mcp-server)",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "simplenote",
        "notes",
        "llm",
        "simplenote mcp",
        "manage simplenote",
        "simplenote notes"
      ],
      "category": "memory-management"
    },
    "doggybee--mcp-server-memo": {
      "owner": "doggybee",
      "name": "mcp-server-memo",
      "url": "https://github.com/doggybee/mcp-server-memo",
      "imageUrl": "/freedevtools/mcp/pfp/doggybee.webp",
      "description": "Manage session summaries and memos for large language models with persistent local storage and version tracking. Store, retrieve, and list detailed session histories to enhance context retention for improved memory capabilities.",
      "stars": 1,
      "forks": 0,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-24T09:10:48Z",
      "readme_content": "# MCP Server Memo\n\n![TypeScript](https://img.shields.io/badge/language-TypeScript-blue)\n![License](https://img.shields.io/github/license/doggybee/mcp-server-memo)\n![Node.js](https://img.shields.io/badge/node-%3E%3D18.0.0-brightgreen)\n![MCP SDK](https://img.shields.io/badge/MCP_SDK-1.9.0-orange)\n\nA lightweight MCP (Model Context Protocol) server for managing rich session summaries and memos for LLMs like Claude. This server provides persistent storage using the local filesystem, with support for session history version tracking, and offers tools for storing, retrieving, and listing summaries.\n\n## Overview\n\nMCP Server Memo is designed as a memory assistant for LLMs, allowing them to store and retrieve detailed session records through the MCP tool interface. The server:\n\n- **Preserves History** - All historical versions of a session (same sessionId) are preserved, not just the latest version\n- **Time-Ordered** - Multiple versions of sessions are organized chronologically, making it easy to track conversation development\n- **Local Storage** - Uses the local filesystem without requiring an external database\n- **MCP Compliant** - Follows the Model Context Protocol specification to provide tool interfaces\n- **Performance Optimized** - Optimized for file I/O and concurrent operations\n- **Minimal Dependencies** - Clean design that's easy to maintain and extend\n\n## Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/doggybee/mcp-server-memo.git\ncd mcp-server-memo\n\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n```\n\n## Configuration\n\nThe server uses the following configuration options:\n\n- `MCP_SUMMARY_DIR`: Directory for storing summaries (default: `./summaries/`)\n\nYou can set these options via environment variables:\n\n```bash\nexport MCP_SUMMARY_DIR=\"/path/to/summaries\"\n```\n\n## Running the Server\n\n```bash\n# Standard startup\nnpm start\n\n# Development mode (with auto-reload)\nnpm run dev\n\n# Start with logging to file\nnpm run start:log\n```\n\n## MCP Tools\n\nThe server provides the following MCP tools:\n\n### 1. upsertSummary\n\nCreates a new version of a session summary without deleting previous versions.\n\n**Parameters:**\n- `sessionId` (string, required): Unique identifier for the conversation session. **It is the client application's responsibility to generate this ID.** It should be generated once at the beginning of a new logical conversation session. **Recommendation:** Use a standard **UUID (Version 4)** library available in your programming language to ensure uniqueness. The client must then reuse the *same* generated ID for all subsequent `upsertSummary` calls pertaining to that specific session.\n- `summary` (string, required): The detailed content of the session chronicle/log. Each call will create a new version in the session history rather than overwriting previous versions.\n- `title` (string, optional): A short, descriptive title for the session.\n- `tags` (string[], optional): Keywords or tags to categorize the session.\n\n**Behavior:**\n- Creates a new file with a new timestamp\n- Preserves all previous versions\n- Returns the timestamp of the new version\n\n### 2. getSummaryTool\n\nRetrieves the latest version of a specific session summary.\n\n**Parameters:**\n- `sessionId` (string, required): The unique ID of the session summary to retrieve.\n- `maxLength` (number, optional): If provided, truncate the retrieved summary text to this maximum length.\n\n**Returns:**\n- The latest session summary object (in JSON format)\n\n### 3. listSummariesTool\n\nLists available summaries (only the latest version of each session), with support for filtering, sorting, and pagination.\n\n**Parameters:**\n- `tag` (string, optional): Filter sessions by a specific tag.\n- `limit` (number, optional): Limit results.\n- `offset` (number, optional): Offset for pagination.\n- `sortBy` (string, optional): Sort field ('lastUpdated' or 'title'). Default: 'lastUpdated'.\n- `order` (string, optional): Sort order ('asc' or 'desc'). Default: 'desc'.\n\n**Returns:**\n- List of summary metadata objects (in JSON format), with only the latest version per session\n\n### 4. updateMetadata\n\nUpdates only the metadata (title and/or tags) of the latest version of a session without changing the summary content or timestamp.\n\n**Parameters:**\n- `sessionId` (string, required): The unique ID of the session whose metadata to update.\n- `title` (string, optional): New title. If omitted, title remains unchanged.\n- `tags` (string[], optional): New tags array. If omitted, tags remain unchanged.\n\n**Note:** At least one of `title` or `tags` must be provided.\n\n**Behavior:**\n- Does not update the timestamp in the filename or the `lastUpdated` field\n- Only modifies the specified metadata fields\n- Does not affect the summary content\n\n### 5. appendSummary\n\nAppends content to a session summary, creating a new version that includes previous content plus new content.\n\n**Parameters:**\n- `sessionId` (string, required): Unique identifier for the conversation session.\n- `content` (string, required): The content to append to the session. This will be added to the existing content and saved as a new version.\n- `title` (string, optional): Optional title for the session.\n- `tags` (string[], optional): Optional tags for categorizing the session.\n\n**Behavior:**\n- Reads the existing latest summary (if any)\n- Adds two newlines between content and appends the new content\n- Creates a new file with a new timestamp\n- Preserves all previous versions\n\n### 6. listAllSummariesTool\n\nLists all available summaries with basic information (only the latest version of each session).\n\n**Parameters:**\n- None\n\n**Returns:**\n- List of all available summaries with basic information (in JSON format)\n\n### 7. getSessionHistory\n\nRetrieves all historical versions of a specific session, ordered from newest to oldest.\n\n**Parameters:**\n- `sessionId` (string, required): The unique ID of the session to retrieve history for.\n\n**Returns:**\n- List of all versions with their full content (in JSON format)\n\n## Client Workflow Example\n\nHere's an example of how a client application might interact with this server:\n\n```javascript\nimport { v4 as uuidv4 } from 'uuid';\nimport { Client } from '@modelcontextprotocol/sdk/client/index.js';\nimport { StdioClientTransport } from '@modelcontextprotocol/sdk/client/stdio.js';\n\n// Initialize client\nconst transport = new StdioClientTransport({\n  command: 'node',\n  args: ['dist/index.js'],\n  cwd: process.cwd()\n});\n\nconst client = new Client({\n  name: 'example-client',\n  version: '1.0.0'\n});\n\nawait client.connect(transport);\n\n// Function to generate new session ID (done once per logical session)\nfunction createNewSession() {\n  return uuidv4();\n}\n\n// Function to append to an existing session\nasync function appendToSession(sessionId, newContent) {\n  return client.callTool({\n    name: \"appendSummary\",\n    arguments: {\n      sessionId,\n      content: newContent,\n      title: \"Example Session\",\n      tags: [\"example\", \"demo\"]\n    }\n  });\n}\n\n// Function to get session history\nasync function getSessionHistory(sessionId) {\n  const response = await client.callTool({\n    name: \"getSessionHistory\",\n    arguments: { sessionId }\n  });\n  \n  const result = JSON.parse(response.content[0].text);\n  if (result.success) {\n    return result.history;\n  }\n  \n  throw new Error(result.error || \"Failed to get session history\");\n}\n\n// Usage example\nconst sessionId = createNewSession();\n\n// Add initial content\nawait appendToSession(sessionId, \"Initial conversation data\");\n\n// Add more content later in the conversation\nawait appendToSession(sessionId, \"Second part of the conversation\");\nawait appendToSession(sessionId, \"Final part of the conversation\");\n\n// Get the full history\nconst history = await getSessionHistory(sessionId);\nconsole.log(`Session ${sessionId} has ${history.length} versions`);\n```\n\n## Project Structure\n\n```\nmcp-server-memo/\n├── dist/                 # Compiled JavaScript output\n├── src/                  # TypeScript source code\n│   ├── config.ts         # Server configuration\n│   ├── index.ts          # Main entry point\n│   ├── storage.ts        # File storage utilities\n│   ├── tools.ts          # MCP tool implementations\n│   └── types.ts          # TypeScript type definitions\n├── summaries/            # Directory for storing session data\n│   └── .gitkeep          # Ensures directory is included in git\n├── package.json          # Project metadata and dependencies\n├── tsconfig.json         # TypeScript configuration\n└── LICENSE               # MIT License file\n```\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "memos",
        "memo",
        "memory",
        "server memo",
        "memo manage",
        "session histories"
      ],
      "category": "memory-management"
    },
    "doobidoo--mcp-memory-service": {
      "owner": "doobidoo",
      "name": "mcp-memory-service",
      "url": "https://github.com/doobidoo/mcp-memory-service",
      "imageUrl": "/freedevtools/mcp/pfp/doobidoo.webp",
      "description": "Provides semantic memory and persistent storage using ChromaDB for long-term memory retention and semantic search capabilities, enhancing context maintenance across conversations.",
      "stars": 738,
      "forks": 108,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-10-03T09:29:45Z",
      "readme_content": "# MCP Memory Service\n\n[![License: Apache 2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n[![GitHub stars](https://img.shields.io/github/stars/doobidoo/mcp-memory-service?style=social)](https://github.com/doobidoo/mcp-memory-service/stargazers)\n[![Production Ready](https://img.shields.io/badge/Production-Ready-brightgreen?style=flat&logo=checkmark)](https://github.com/doobidoo/mcp-memory-service#-in-production)\n\n[![Works with Claude](https://img.shields.io/badge/Works%20with-Claude-blue)](https://claude.ai)\n[![Works with Cursor](https://img.shields.io/badge/Works%20with-Cursor-orange)](https://cursor.sh)\n[![MCP Protocol](https://img.shields.io/badge/MCP-Compatible-4CAF50?style=flat)](https://modelcontextprotocol.io/)\n[![Multi-Client](https://img.shields.io/badge/Multi--Client-13+%20Apps-FF6B35?style=flat)](https://github.com/doobidoo/mcp-memory-service/wiki)\n\n**Universal MCP memory service** with **intelligent memory triggers**, **OAuth 2.1 team collaboration**, and **semantic memory search** for **AI assistants**. Features **Natural Memory Triggers v7.1.0** with 85%+ trigger accuracy, **Claude Code HTTP transport**, **zero-configuration authentication**, and **enterprise security**. Works with **Claude Desktop, VS Code, Cursor, Continue, and 13+ AI applications** with **SQLite-vec** for fast local search and **Cloudflare** for global distribution.\n\n<img width=\"240\" alt=\"MCP Memory Service\" src=\"https://github.com/user-attachments/assets/eab1f341-ca54-445c-905e-273cd9e89555\" />\n\n## 🚀 Quick Start (2 minutes)\n\n### 🧠 **v7.1.0: Natural Memory Triggers for Claude Code**\n\n**🤖 Intelligent Memory Awareness** (Zero Configuration):\n```bash\n# 1. Install MCP Memory Service\ngit clone https://github.com/doobidoo/mcp-memory-service.git\ncd mcp-memory-service && python install.py\n\n# 2. Install Natural Memory Triggers\ncd claude-hooks && python install_hooks.py --natural-triggers\n\n# 3. Test intelligent triggers\nnode memory-mode-controller.js status\n# ✅ Done! Claude Code now automatically detects when you need memory context\n```\n\n**📖 Complete Guide**: [Natural Memory Triggers v7.1.0](https://github.com/doobidoo/mcp-memory-service/wiki/Natural-Memory-Triggers-v7.1.0)\n\n---\n\n### 🆕 **v7.0.0: OAuth 2.1 & Claude Code HTTP Transport**\n\n**🔗 Claude Code Team Collaboration** (Zero Configuration):\n```bash\n# 1. Start OAuth-enabled server\nexport MCP_OAUTH_ENABLED=true\nuv run memory server --http\n\n# 2. Add HTTP transport to Claude Code\nclaude mcp add --transport http memory-service http://localhost:8000/mcp\n\n# ✅ Done! Claude Code automatically handles OAuth registration and team collaboration\n```\n\n**📖 Complete Setup Guide**: [OAuth 2.1 Setup Guide](https://github.com/doobidoo/mcp-memory-service/wiki/OAuth-2.1-Setup-Guide)\n\n---\n\n### Traditional Setup Options\n\n**Universal Installer (Most Compatible):**\n```bash\n# Clone and install with automatic platform detection\ngit clone https://github.com/doobidoo/mcp-memory-service.git\ncd mcp-memory-service\n\n# Lightweight installation (SQLite-vec with ONNX embeddings - recommended)\npython install.py\n\n# Add full ML capabilities (torch + sentence-transformers for advanced features)\npython install.py --with-ml\n\n# Add ChromaDB backend support (includes full ML stack - for multi-client setups)\npython install.py --with-chromadb\n```\n\n**📝 Installation Options Explained:**\n- **Default (recommended)**: Lightweight SQLite-vec with ONNX embeddings - fast, works offline, <100MB dependencies\n- **`--with-ml`**: Adds PyTorch + sentence-transformers for advanced ML features - heavier but more capable\n- **`--with-chromadb`**: Multi-client local server support - use only if you need shared team access\n\n**Docker (Fastest):**\n```bash\n# For MCP protocol (Claude Desktop)\ndocker-compose up -d\n\n# For HTTP API + OAuth (Team Collaboration)\ndocker-compose -f docker-compose.http.yml up -d\n```\n\n**Smithery (Claude Desktop):**\n```bash\n# Auto-install for Claude Desktop\nnpx -y @smithery/cli install @doobidoo/mcp-memory-service --client claude\n```\n\n## ⚠️ v6.17.0+ Script Migration Notice\n\n**Updating from an older version?** Scripts have been reorganized for better maintainability:\n- **Recommended**: Use `python -m mcp_memory_service.server` in your Claude Desktop config (no path dependencies!)\n- **Alternative 1**: Use `uv run memory server` with UV tooling\n- **Alternative 2**: Update path from `scripts/run_memory_server.py` to `scripts/server/run_memory_server.py`\n- **Backward compatible**: Old path still works with a migration notice\n\n## ⚠️ First-Time Setup Expectations\n\nOn your first run, you'll see some warnings that are **completely normal**:\n\n- **\"WARNING: Failed to load from cache: No snapshots directory\"** - The service is checking for cached models (first-time setup)\n- **\"WARNING: Using TRANSFORMERS_CACHE is deprecated\"** - Informational warning, doesn't affect functionality\n- **Model download in progress** - The service automatically downloads a ~25MB embedding model (takes 1-2 minutes)\n\nThese warnings disappear after the first successful run. The service is working correctly! For details, see our [First-Time Setup Guide](docs/first-time-setup.md).\n\n### 🐍 Python 3.13 Compatibility Note\n\n**sqlite-vec** may not have pre-built wheels for Python 3.13 yet. If installation fails:\n- The installer will automatically try multiple installation methods\n- Consider using Python 3.12 for the smoothest experience: `brew install python@3.12`\n- Alternative: Use ChromaDB backend with `--storage-backend chromadb --with-chromadb`\n- See [Troubleshooting Guide](docs/troubleshooting/general.md#python-313-sqlite-vec-issues) for details\n\n### 🍎 macOS SQLite Extension Support\n\n**macOS users** may encounter `enable_load_extension` errors with sqlite-vec:\n- **System Python** on macOS lacks SQLite extension support by default\n- **Solution**: Use Homebrew Python: `brew install python && rehash`\n- **Alternative**: Use pyenv: `PYTHON_CONFIGURE_OPTS='--enable-loadable-sqlite-extensions' pyenv install 3.12.0`\n- **Fallback**: Use sqlite_vec backend (default) or install ChromaDB with `--with-chromadb`\n- See [Troubleshooting Guide](docs/troubleshooting/general.md#macos-sqlite-extension-issues) for details\n\n## 📚 Complete Documentation\n\n**👉 Visit our comprehensive [Wiki](https://github.com/doobidoo/mcp-memory-service/wiki) for detailed guides:**\n\n### 🧠 v7.1.0 Natural Memory Triggers (Latest)\n- **[Natural Memory Triggers v7.1.0 Guide](https://github.com/doobidoo/mcp-memory-service/wiki/Natural-Memory-Triggers-v7.1.0)** - Intelligent automatic memory awareness\n  - ✅ **85%+ trigger accuracy** with semantic pattern detection\n  - ✅ **Multi-tier performance** (50ms instant → 150ms fast → 500ms intensive)\n  - ✅ **CLI management system** for real-time configuration\n  - ✅ **Git-aware context** integration for enhanced relevance\n  - ✅ **Zero-restart installation** with dynamic hook loading\n\n### 🆕 v7.0.0 OAuth & Team Collaboration\n- **[🔐 OAuth 2.1 Setup Guide](https://github.com/doobidoo/mcp-memory-service/wiki/OAuth-2.1-Setup-Guide)** - **NEW!** Complete OAuth 2.1 Dynamic Client Registration guide\n- **[🔗 Integration Guide](https://github.com/doobidoo/mcp-memory-service/wiki/03-Integration-Guide)** - Claude Desktop, **Claude Code HTTP transport**, VS Code, and more\n- **[🛡️ Advanced Configuration](https://github.com/doobidoo/mcp-memory-service/wiki/04-Advanced-Configuration)** - **Updated!** OAuth security, enterprise features\n\n### 🚀 Setup & Installation\n- **[📋 Installation Guide](https://github.com/doobidoo/mcp-memory-service/wiki/01-Installation-Guide)** - Complete installation for all platforms and use cases\n- **[🖥️ Platform Setup Guide](https://github.com/doobidoo/mcp-memory-service/wiki/02-Platform-Setup-Guide)** - Windows, macOS, and Linux optimizations\n- **[⚡ Performance Optimization](https://github.com/doobidoo/mcp-memory-service/wiki/05-Performance-Optimization)** - Speed up queries, optimize resources, scaling\n\n### 🧠 Advanced Topics\n- **[👨‍💻 Development Reference](https://github.com/doobidoo/mcp-memory-service/wiki/06-Development-Reference)** - Claude Code hooks, API reference, debugging\n- **[🔧 Troubleshooting Guide](https://github.com/doobidoo/mcp-memory-service/wiki/07-TROUBLESHOOTING)** - **Updated!** OAuth troubleshooting + common issues\n- **[❓ FAQ](https://github.com/doobidoo/mcp-memory-service/wiki/08-FAQ)** - Frequently asked questions\n- **[📝 Examples](https://github.com/doobidoo/mcp-memory-service/wiki/09-Examples)** - Practical code examples and workflows\n\n### 📂 Internal Documentation\n- **[🏗️ Architecture Specs](docs/architecture/)** - Search enhancement specifications and design documents\n- **[👩‍💻 Development Docs](docs/development/)** - AI agent instructions, release checklist, refactoring notes\n- **[🚀 Deployment Guides](docs/deployment/)** - Docker, dual-service, and production deployment\n- **[📚 Additional Guides](docs/guides/)** - Storage backends, migration, mDNS discovery\n\n## ✨ Key Features\n\n### 🔐 **Enterprise Authentication & Team Collaboration** 🆕\n- **OAuth 2.1 Dynamic Client Registration** - RFC 7591 & RFC 8414 compliant\n- **Claude Code HTTP Transport** - Zero-configuration team collaboration\n- **JWT Authentication** - Enterprise-grade security with scope validation\n- **Auto-Discovery Endpoints** - Seamless client registration and authorization\n- **Multi-Auth Support** - OAuth + API keys + optional anonymous access\n\n### 🧠 **Intelligent Memory Management**\n- **Semantic search** with vector embeddings\n- **Natural language time queries** (\"yesterday\", \"last week\")\n- **Tag-based organization** with smart categorization\n- **Memory consolidation** with dream-inspired algorithms\n\n### 🔗 **Universal Compatibility**\n- **Claude Desktop** - Native MCP integration\n- **Claude Code** - **HTTP transport** + Memory-aware development with hooks\n- **VS Code, Cursor, Continue** - IDE extensions\n- **13+ AI applications** - REST API compatibility\n\n### 💾 **Flexible Storage**\n- **SQLite-vec** - Fast local storage (recommended, lightweight ONNX embeddings)\n- **ChromaDB** - Multi-client collaboration (optional, heavy dependencies)\n- **Cloudflare** - Global edge distribution\n- **Automatic backups** and synchronization\n\n> **Note**: All heavy ML dependencies (PyTorch, sentence-transformers, ChromaDB) are now optional to dramatically reduce build times and image sizes. SQLite-vec uses lightweight ONNX embeddings by default. Install with `--with-ml` for full ML capabilities or `--with-chromadb` for multi-client features.\n\n### 🚀 **Production Ready**\n- **Cross-platform** - Windows, macOS, Linux\n- **Service installation** - Auto-start background operation\n- **HTTPS/SSL** - Secure connections with OAuth 2.1\n- **Docker support** - Easy deployment with team collaboration\n\n## 💡 Basic Usage\n\n### 🔗 **Team Collaboration with OAuth** (v7.0.0+)\n```bash\n# Start OAuth-enabled server for team collaboration\nexport MCP_OAUTH_ENABLED=true\nuv run memory server --http\n\n# Claude Code team members connect via HTTP transport\nclaude mcp add --transport http memory-service http://your-server:8000/mcp\n# → Automatic OAuth discovery, registration, and authentication\n```\n\n### 🧠 **Memory Operations**\n```bash\n# Store a memory\nuv run memory store \"Fixed race condition in authentication by adding mutex locks\"\n\n# Search for relevant memories\nuv run memory recall \"authentication race condition\"\n\n# Search by tags\nuv run memory search --tags python debugging\n\n# Check system health (shows OAuth status)\nuv run memory health\n```\n\n## 🔧 Configuration\n\n### Claude Desktop Integration\n**Recommended approach** - Add to your Claude Desktop config (`~/.claude/config.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"memory\": {\n      \"command\": \"python\",\n      \"args\": [\"-m\", \"mcp_memory_service.server\"],\n      \"env\": {\n        \"MCP_MEMORY_STORAGE_BACKEND\": \"sqlite_vec\"\n      }\n    }\n  }\n}\n```\n\n**Alternative approaches:**\n```json\n// Option 1: UV tooling (if using UV)\n{\n  \"mcpServers\": {\n    \"memory\": {\n      \"command\": \"uv\",\n      \"args\": [\"--directory\", \"/path/to/mcp-memory-service\", \"run\", \"memory\", \"server\"],\n      \"env\": {\n        \"MCP_MEMORY_STORAGE_BACKEND\": \"sqlite_vec\"\n      }\n    }\n  }\n}\n\n// Option 2: Direct script path (v6.17.0+)\n{\n  \"mcpServers\": {\n    \"memory\": {\n      \"command\": \"python\",\n      \"args\": [\"/path/to/mcp-memory-service/scripts/server/run_memory_server.py\"],\n      \"env\": {\n        \"MCP_MEMORY_STORAGE_BACKEND\": \"sqlite_vec\"\n      }\n    }\n  }\n}\n```\n\n### Environment Variables\n```bash\n# Storage backend (sqlite_vec recommended)\nexport MCP_MEMORY_STORAGE_BACKEND=sqlite_vec\n\n# Enable HTTP API\nexport MCP_HTTP_ENABLED=true\nexport MCP_HTTP_PORT=8000\n\n# Security  \nexport MCP_API_KEY=\"your-secure-key\"\n```\n\n## 🏗️ Architecture\n\n```\n┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐\n│   AI Clients    │    │  MCP Memory     │    │ Storage Backend │\n│                 │    │  Service v7.0   │    │                 │\n│ • Claude Desktop│◄──►│ • MCP Protocol  │◄──►│ • SQLite-vec    │\n│ • Claude Code   │    │ • HTTP Transport│    │ • ChromaDB      │\n│   (HTTP/OAuth)  │    │ • OAuth 2.1 Auth│    │ • Cloudflare    │\n│ • VS Code       │    │ • Memory Store  │    │ • Hybrid        │\n│ • Cursor        │    │ • Semantic      │    │                 │\n│ • 13+ AI Apps   │    │   Search        │    │                 │\n└─────────────────┘    └─────────────────┘    └─────────────────┘\n```\n\n## 🛠️ Development\n\n### Project Structure\n```\nmcp-memory-service/\n├── src/mcp_memory_service/    # Core application\n│   ├── models/                # Data models\n│   ├── storage/               # Storage backends\n│   ├── web/                   # HTTP API & dashboard\n│   └── server.py              # MCP server\n├── scripts/                   # Utilities & installation\n├── tests/                     # Test suite\n└── tools/docker/              # Docker configuration\n```\n\n### Contributing\n1. Fork the repository\n2. Create a feature branch\n3. Make your changes with tests\n4. Submit a pull request\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md) for detailed guidelines.\n\n## 🆘 Support\n\n- **📖 Documentation**: [Wiki](https://github.com/doobidoo/mcp-memory-service/wiki) - Comprehensive guides\n- **🐛 Bug Reports**: [GitHub Issues](https://github.com/doobidoo/mcp-memory-service/issues)\n- **💬 Discussions**: [GitHub Discussions](https://github.com/doobidoo/mcp-memory-service/discussions)\n- **🔧 Troubleshooting**: [Troubleshooting Guide](https://github.com/doobidoo/mcp-memory-service/wiki/07-TROUBLESHOOTING)\n- **✅ Configuration Validator**: Run `python scripts/validation/validate_configuration_complete.py` to check your setup\n- **🔄 Backend Sync Tools**: See [scripts/README.md](scripts/README.md#backend-synchronization) for Cloudflare↔SQLite sync\n\n## 📊 In Production\n\n**Real-world metrics from active deployments:**\n- **750+ memories** stored and actively used across teams\n- **<500ms response time** for semantic search (local & HTTP transport)\n- **65% token reduction** in Claude Code sessions with OAuth collaboration\n- **96.7% faster** context setup (15min → 30sec)\n- **100% knowledge retention** across sessions and team members\n- **Zero-configuration** OAuth setup success rate: **98.5%**\n\n## 🏆 Recognition\n\n- [![Smithery](https://smithery.ai/badge/@doobidoo/mcp-memory-service)](https://smithery.ai/server/@doobidoo/mcp-memory-service) **Verified MCP Server**\n- [![Glama AI](https://img.shields.io/badge/Featured-Glama%20AI-blue)](https://glama.ai/mcp/servers/bzvl3lz34o) **Featured AI Tool**\n- **Production-tested** across 13+ AI applications\n- **Community-driven** with real-world feedback and improvements\n\n## 📄 License\n\nApache License 2.0 - see [LICENSE](LICENSE) for details.\n\n---\n\n**Ready to supercharge your AI workflow?** 🚀\n\n👉 **[Start with our Installation Guide](https://github.com/doobidoo/mcp-memory-service/wiki/01-Installation-Guide)** or explore the **[Wiki](https://github.com/doobidoo/mcp-memory-service/wiki)** for comprehensive documentation.\n\n*Transform your AI conversations into persistent, searchable knowledge that grows with you.*",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "memory",
        "chromadb",
        "storage",
        "memory persistent",
        "memory management",
        "memory service"
      ],
      "category": "memory-management"
    },
    "drdee--memory-mcp": {
      "owner": "drdee",
      "name": "memory-mcp",
      "url": "https://github.com/drdee/memory-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/drdee.webp",
      "description": "Store and retrieve memories using a command-line interface with a backend powered by SQLite. Manage important information efficiently in applications with memory functionalities.",
      "stars": 7,
      "forks": 6,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-17T21:25:11Z",
      "readme_content": "# Memory MCP\n\nA Model Context Protocol server for storing and retrieving memories using low-level Server implementation and SQLite storage.\n\n## Installation\n\nThis project uses [uv](https://github.com/astral-sh/uv) for dependency management instead of pip. uv is a fast, reliable Python package installer and resolver.\n\nInstall using uv:\n\n```bash\nuv pip install memory-mcp\n```\n\nOr install directly from source:\n\n```bash\nuv pip install .\n```\n\nFor development:\n\n```bash\nuv pip install -e \".[dev]\"\n```\n\nIf you don't have uv installed, you can install it following the [official instructions](https://github.com/astral-sh/uv#installation).\n\n## Usage\n\n### Running the server\n\n```bash\nmemory-mcp\n```\n\nThis will start the MCP server that allows you to store and retrieve memories.\n\n### Available Tools\n\nThe Memory MCP provides the following tools:\n\n- `remember`: Store a new memory with a title and content\n- `get_memory`: Retrieve a specific memory by ID or title\n- `list_memories`: List all stored memories\n- `update_memory`: Update an existing memory\n- `delete_memory`: Delete a memory\n\n## Debugging with MCP Inspect\n\nMCP provides a handy command-line tool called `mcp inspect` that allows you to debug and interact with your MCP server directly.\n\n### Setup\n\n1. First, make sure the MCP CLI tools are installed:\n\n```bash\nuv pip install mcp[cli]\n```\n\n2. Start the Memory MCP server in one terminal:\n\n```bash\nmemory-mcp\n```\n\n3. In another terminal, connect to the running server using `mcp inspect`:\n\n```bash\nmcp inspect\n```\n\n### Using MCP Inspect\n\nOnce connected, you can:\n\n#### List available tools\n\n```\n> tools\n```\n\nThis will display all the tools provided by the Memory MCP server.\n\n#### Call a tool\n\nTo call a tool, use the `call` command followed by the tool name and any required arguments:\n\n```\n> call remember title=\"Meeting Notes\" content=\"Discussed project timeline and milestones.\"\n```\n\n```\n> call list_memories\n```\n\n```\n> call get_memory memory_id=1\n```\n\n```\n> call update_memory memory_id=1 title=\"Updated Title\" content=\"Updated content.\"\n```\n\n```\n> call delete_memory memory_id=1\n```\n\n#### Debug Mode\n\nYou can enable debug mode to see detailed request and response information:\n\n```\n> debug on\n```\n\nThis helps you understand exactly what data is being sent to and received from the server.\n\n#### Exploring Tool Schemas\n\nTo view the schema for a specific tool:\n\n```\n> tool remember\n```\n\nThis shows the input schema, required parameters, and description for the tool.\n\n### Troubleshooting\n\nIf you encounter issues:\n\n1. Check the server logs in the terminal where your server is running for any error messages.\n2. In the MCP inspect terminal, enable debug mode with `debug on` to see raw requests and responses.\n3. Ensure the tool parameters match the expected schema (check with the `tool` command).\n4. If the server crashes, check for any uncaught exceptions in the server terminal.\n\n## Development\n\nTo contribute to the project, install the development dependencies:\n\n```bash\nuv pip install -e \".[dev]\"\n```\n\n### Managing Dependencies\n\nThis project uses `uv.lock` file to lock dependencies. To update dependencies:\n\n```bash\nuv pip compile pyproject.toml -o uv.lock\n```\n\n### Running tests\n\n```bash\npython -m pytest\n```\n\n### Code formatting\n\n```bash\nblack memory_mcp tests\n```\n\n### Linting\n\n```bash\nruff check memory_mcp tests\n```\n\n### Type checking\n\n```bash\nmypy memory_mcp\n``` ",
      "npm_url": "https://www.npmjs.com/package/memory-mcp",
      "npm_downloads": 113,
      "keywords": [
        "sqlite",
        "memory",
        "drdee",
        "drdee memory",
        "memory management",
        "memory mcp"
      ],
      "category": "memory-management"
    },
    "ebailey78--mcp-memory": {
      "owner": "ebailey78",
      "name": "mcp-memory",
      "url": "https://github.com/ebailey78/mcp-memory",
      "imageUrl": "/freedevtools/mcp/pfp/ebailey78.webp",
      "description": "Manage and maintain structured memories across chat sessions to enhance project continuity and context. Save and retrieve important information over time, building a comprehensive knowledge base tailored to long-term project workflows.",
      "stars": 3,
      "forks": 2,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-08-15T14:43:03Z",
      "readme_content": "# MCP Memory Server\n\nA Model Context Protocol (MCP) server for Claude Desktop that provides structured memory management across chat sessions, specifically designed for project-based work.\n\n## Project-Focused Memory Management\n\nThis MCP server is specifically designed to help Claude maintain context and knowledge within project directories when used with Claude Desktop. It allows Claude to:\n\n- Create a memory store within your project directory\n- Save important information discovered during conversations\n- Retrieve relevant memories in future sessions\n- Build a comprehensive knowledge base about your project over time\n\nThis approach is ideal for long-term projects where maintaining context between sessions is crucial, such as software development, research, writing, or any collaborative work with Claude.\n\n## Features\n\n- Store memories as structured markdown files\n- Index memories using Lunr.js for efficient retrieval\n- Tag and categorize memories\n- Create relationships between memories\n- Search memories by content, tags, or type\n- Build memory stores in specified directories\n\n## Memory Structure\n\nMemories are stored in a hierarchical structure within your project:\n\n```\n/your-project-directory\n  /memory                # Memory store created by Claude\n    /entities/           # Information about specific entities (people, projects, etc.)\n    /concepts/           # Abstract concepts or knowledge\n    /sessions/           # Session-specific memories\n    /index.json          # Lunr.js search index\n    /metadata.json       # Overall memory metadata\n    /README.md           # Auto-generated documentation\n```\n\nThis structure keeps all project-related memories organized and accessible within your project directory.\n\n## Usage with Claude Desktop\n\nAdd this to your claude_desktop_config.json:\n\n```json\n{\n  \"mcpServers\": {\n    \"memory\": {\n      \"command\": \"node\",\n      \"args\": [\"path/to/mcp-memory/dist/index.js\"]\n    }\n  }\n}\n```\n\nYou can also set a custom memory directory using an environment variable:\n\n```json\n{\n  \"mcpServers\": {\n    \"memory\": {\n      \"command\": \"node\",\n      \"args\": [\"path/to/mcp-memory/dist/index.js\"],\n      \"env\": {\n        \"MEMORY_DIR\": \"/path/to/custom/memory/directory\"\n      }\n    }\n  }\n}\n```\n\n## Project Workflow\n\n1. **Setup**: When starting a new project with Claude, have it create a memory store in your project directory\n2. **Ongoing Work**: As you work with Claude, it will save important information to the memory store\n3. **Continuity**: In future sessions, Claude can retrieve relevant memories to maintain context\n4. **Knowledge Building**: Over time, Claude builds a comprehensive knowledge base about your project\n\nThis workflow ensures that Claude maintains context and knowledge specific to each project, making it more effective as a long-term collaborator.\n\n## Claude Project Instructions\n\nThis repository includes an `instructions_template.md` file that provides a comprehensive template for Claude project instructions. You can customize this template for your specific projects to help Claude effectively use the memory system.\n\nThe template includes:\n\n- Memory system setup instructions\n- Memory retrieval process\n- Memory creation guidelines\n- Memory organization system\n- Memory maintenance procedures\n- Conversation workflow\n- Best practices\n\n## Development\n\n```bash\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n\n# Start the server\nnpm start\n\n# Development mode (watch for changes)\nnpm run dev\n```\n\n## Implementation Details\n\nThis server is built using:\n\n- The official Model Context Protocol (MCP) SDK\n- TypeScript for type safety\n- Lunr.js for memory indexing and search\n- Zod for schema validation\n\n## License\n\nMIT ",
      "npm_url": "https://www.npmjs.com/package/mcp-memory-server",
      "npm_downloads": 651,
      "keywords": [
        "memory",
        "memories",
        "manage",
        "memory manage",
        "memories chat",
        "memory management"
      ],
      "category": "memory-management"
    },
    "evangstav--python-memory-mcp-server": {
      "owner": "evangstav",
      "name": "python-memory-mcp-server",
      "url": "https://github.com/evangstav/python-memory-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/evangstav.webp",
      "description": "Manage entities and their relationships within a knowledge graph with strict validation to ensure data consistency. Perform complex queries and maintain observations to enhance application functionality.",
      "stars": 16,
      "forks": 6,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-07-19T19:18:45Z",
      "readme_content": "# Memory MCP Server\n\nA Model Context Protocol (MCP) server that provides knowledge graph functionality for managing entities, relations, and observations in memory, with strict validation rules to maintain data consistency.\n\n## Installation\n\nInstall the server in Claude Desktop:\n\n```bash\nmcp install main.py -v MEMORY_FILE_PATH=/path/to/memory.jsonl\n```\n\n## Data Validation Rules\n\n### Entity Names\n- Must start with a lowercase letter\n- Can contain lowercase letters, numbers, and hyphens\n- Maximum length of 100 characters\n- Must be unique within the graph\n- Example valid names: `python-project`, `meeting-notes-2024`, `user-john`\n\n### Entity Types\nThe following entity types are supported:\n- `person`: Human entities\n- `concept`: Abstract ideas or principles\n- `project`: Work initiatives or tasks\n- `document`: Any form of documentation\n- `tool`: Software tools or utilities\n- `organization`: Companies or groups\n- `location`: Physical or virtual places\n- `event`: Time-bound occurrences\n\n### Observations\n- Non-empty strings\n- Maximum length of 500 characters\n- Must be unique per entity\n- Should be factual and objective statements\n- Include timestamp when relevant\n\n### Relations\nThe following relation types are supported:\n- `knows`: Person to person connection\n- `contains`: Parent/child relationship\n- `uses`: Entity utilizing another entity\n- `created`: Authorship/creation relationship\n- `belongs-to`: Membership/ownership\n- `depends-on`: Dependency relationship\n- `related-to`: Generic relationship\n\nAdditional relation rules:\n- Both source and target entities must exist\n- Self-referential relations not allowed\n- No circular dependencies allowed\n- Must use predefined relation types\n\n## Usage\n\nThe server provides tools for managing a knowledge graph:\n\n### Get Entity\n```python\nresult = await session.call_tool(\"get_entity\", {\n    \"entity_name\": \"example\"\n})\nif not result.success:\n    if result.error_type == \"NOT_FOUND\":\n        print(f\"Entity not found: {result.error}\")\n    elif result.error_type == \"VALIDATION_ERROR\":\n        print(f\"Invalid input: {result.error}\")\n    else:\n        print(f\"Error: {result.error}\")\nelse:\n    entity = result.data\n    print(f\"Found entity: {entity}\")\n```\n\n### Get Graph\n```python\nresult = await session.call_tool(\"get_graph\", {})\nif result.success:\n    graph = result.data\n    print(f\"Graph data: {graph}\")\nelse:\n    print(f\"Error retrieving graph: {result.error}\")\n```\n\n### Create Entities\n```python\n# Valid entity creation\nentities = [\n    Entity(\n        name=\"python-project\",  # Lowercase with hyphens\n        entityType=\"project\",   # Must be a valid type\n        observations=[\"Started development on 2024-01-29\"]\n    ),\n    Entity(\n        name=\"john-doe\",\n        entityType=\"person\",\n        observations=[\"Software engineer\", \"Joined team in 2024\"]\n    )\n]\nresult = await session.call_tool(\"create_entities\", {\n    \"entities\": entities\n})\nif not result.success:\n    if result.error_type == \"VALIDATION_ERROR\":\n        print(f\"Invalid entity data: {result.error}\")\n    else:\n        print(f\"Error creating entities: {result.error}\")\n```\n\n### Add Observation\n```python\n# Valid observation\nresult = await session.call_tool(\"add_observation\", {\n    \"entity\": \"python-project\",\n    \"observation\": \"Completed initial prototype\"  # Must be unique for entity\n})\nif not result.success:\n    if result.error_type == \"NOT_FOUND\":\n        print(f\"Entity not found: {result.error}\")\n    elif result.error_type == \"VALIDATION_ERROR\":\n        print(f\"Invalid observation: {result.error}\")\n    else:\n        print(f\"Error adding observation: {result.error}\")\n```\n\n### Create Relation\n```python\n# Valid relation\nresult = await session.call_tool(\"create_relation\", {\n    \"from_entity\": \"john-doe\",\n    \"to_entity\": \"python-project\",\n    \"relation_type\": \"created\"  # Must be a valid type\n})\nif not result.success:\n    if result.error_type == \"NOT_FOUND\":\n        print(f\"Entity not found: {result.error}\")\n    elif result.error_type == \"VALIDATION_ERROR\":\n        print(f\"Invalid relation data: {result.error}\")\n    else:\n        print(f\"Error creating relation: {result.error}\")\n```\n\n### Search Memory\n```python\nresult = await session.call_tool(\"search_memory\", {\n    \"query\": \"most recent workout\"  # Supports natural language queries\n})\nif result.success:\n    if result.error_type == \"NO_RESULTS\":\n        print(f\"No results found: {result.error}\")\n    else:\n        results = result.data\n        print(f\"Search results: {results}\")\nelse:\n    print(f\"Error searching memory: {result.error}\")\n```\n\nThe search functionality supports:\n- Temporal queries (e.g., \"most recent\", \"last\", \"latest\")\n- Activity queries (e.g., \"workout\", \"exercise\")\n- General entity searches\n- Fuzzy matching with 80% similarity threshold\n- Weighted search across:\n  - Entity names (weight: 1.0)\n  - Entity types (weight: 0.8)\n  - Observations (weight: 0.6)\n\n### Delete Entities\n```python\nresult = await session.call_tool(\"delete_entities\", {\n    \"names\": [\"python-project\", \"john-doe\"]\n})\nif not result.success:\n    if result.error_type == \"NOT_FOUND\":\n        print(f\"Entity not found: {result.error}\")\n    else:\n        print(f\"Error deleting entities: {result.error}\")\n```\n\n### Delete Relation\n```python\nresult = await session.call_tool(\"delete_relation\", {\n    \"from_entity\": \"john-doe\",\n    \"to_entity\": \"python-project\"\n})\nif not result.success:\n    if result.error_type == \"NOT_FOUND\":\n        print(f\"Entity not found: {result.error}\")\n    else:\n        print(f\"Error deleting relation: {result.error}\")\n```\n\n### Flush Memory\n```python\nresult = await session.call_tool(\"flush_memory\", {})\nif not result.success:\n    print(f\"Error flushing memory: {result.error}\")\n```\n\n## Error Types\n\nThe server uses the following error types:\n\n- `NOT_FOUND`: Entity or resource not found\n- `VALIDATION_ERROR`: Invalid input data\n- `INTERNAL_ERROR`: Server-side error\n- `ALREADY_EXISTS`: Resource already exists\n- `INVALID_RELATION`: Invalid relation between entities\n\n## Response Models\n\nAll tools return typed responses using these models:\n\n### EntityResponse\n```python\nclass EntityResponse(BaseModel):\n    success: bool\n    data: Optional[Dict[str, Any]] = None\n    error: Optional[str] = None\n    error_type: Optional[str] = None\n```\n\n### GraphResponse\n```python\nclass GraphResponse(BaseModel):\n    success: bool\n    data: Optional[Dict[str, Any]] = None\n    error: Optional[str] = None\n    error_type: Optional[str] = None\n```\n\n### OperationResponse\n```python\nclass OperationResponse(BaseModel):\n    success: bool\n    error: Optional[str] = None\n    error_type: Optional[str] = None\n```\n\n## Development\n\n### Running Tests\n\n```bash\npytest tests/\n```\n\n### Adding New Features\n\n1. Update validation rules in `validation.py`\n2. Add tests in `tests/test_validation.py`\n3. Implement changes in `knowledge_graph_manager.py`\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "memory",
        "manage",
        "management",
        "python memory",
        "memory management",
        "memory mcp"
      ],
      "category": "memory-management"
    },
    "fourcolors--omi-mcp": {
      "owner": "fourcolors",
      "name": "omi-mcp",
      "url": "https://github.com/fourcolors/omi-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/fourcolors.webp",
      "description": "Manage conversations and memories with the Omi API, enabling retrieval, creation, and manipulation of user data for enhanced conversational capabilities.",
      "stars": 3,
      "forks": 2,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-08-26T05:13:54Z",
      "readme_content": "# Omi MCP Server\n[![smithery badge](https://smithery.ai/badge/@fourcolors/omi-mcp)](https://smithery.ai/server/@fourcolors/omi-mcp)\n\nThis project provides a Model Context Protocol (MCP) server for interacting with the Omi API. The server provides tools for reading conversations and memories, as well as creating new conversations and memories.\n\n## Setup\n\n1. Clone the repository\n2. Install dependencies with `npm install`\n3. Create a `.env` file with the following variables:\n   ```\n   API_KEY=your_api_key\n   APP_ID=your_app_id\n   ```\n\n## Usage\n\n### Installing via Smithery\n\nTo install Omi MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@fourcolors/omi-mcp):\n\n```bash\nnpx -y @smithery/cli install @fourcolors/omi-mcp --client claude\n```\n\n### Building the Server\n\n```bash\nnpm run build\n```\n\n### Running the Server\n\n```bash\nnpm run start\n```\n\n### Development Mode\n\nFor development with hot-reloading:\n\n```bash\nnpm run dev\n```\n\n### Testing the Server\n\nA simple test client is included to interact with the MCP server. After building the project, run:\n\n```bash\nnpm run test\n```\n\nOr directly:\n\n```bash\n./test-mcp-client.js\n```\n\nThis will start the MCP server and provide an interactive menu to test the available tools. The test client uses a default test user ID (`test-user-123`) for all operations.\n\n### Clean and Rebuild\n\nTo clean the build directory and rebuild from scratch:\n\n```bash\nnpm run rebuild\n```\n\n## Configuration with Claude and Cursor\n\n### Claude Configuration\n\nTo use this MCP server with Claude via Anthropic Console or API:\n\n1. Start the MCP server locally:\n\n   ```bash\n   npm run start\n   ```\n\n2. When setting up your Claude conversation, configure the MCP connection:\n\n   ```json\n   {\n   \t\"mcp_config\": {\n   \t\t\"transports\": [\n   \t\t\t{\n   \t\t\t\t\"type\": \"stdio\",\n   \t\t\t\t\"executable\": {\n   \t\t\t\t\t\"path\": \"/path/to/your/omi-mcp-local/dist/index.js\",\n   \t\t\t\t\t\"args\": []\n   \t\t\t\t}\n   \t\t\t}\n   \t\t]\n   \t}\n   }\n   ```\n\n3. Example prompt to Claude:\n\n   ```\n   Please fetch the latest 5 conversations for user \"user123\" using the Omi API.\n   ```\n\n4. Claude will use the MCP to execute the `read_omi_conversations` tool:\n   ```json\n   {\n   \t\"id\": \"req-1\",\n   \t\"type\": \"request\",\n   \t\"method\": \"tools.read_omi_conversations\",\n   \t\"params\": {\n   \t\t\"user_id\": \"user123\",\n   \t\t\"limit\": 5\n   \t}\n   }\n   ```\n\n### Cursor Configuration\n\nTo use this MCP server with Cursor:\n\n1. Start the MCP server in a terminal:\n\n   ```bash\n   npm run start\n   ```\n\n2. In Cursor, go to Settings > Extensions > MCP Servers\n\n3. Add a new MCP server with these settings:\n\n   - Name: Omi API\n   - URL: stdio:/path/to/your/omi-mcp-local/dist/index.js\n   - Enable the server\n\n4. Now you can use the Omi tools directly within Cursor. For example:\n\n   ```\n   @Omi API Please fetch memories for user \"user123\" and summarize them.\n   ```\n\n5. Cursor will communicate with your MCP server to execute the necessary API calls.\n\n## Available Tools\n\nThe MCP server provides the following tools:\n\n### read_omi_conversations\n\nRetrieves conversations from Omi for a specific user, with optional filters.\n\nParameters:\n\n- `user_id` (string): The user ID to fetch conversations for\n- `limit` (number, optional): Maximum number of conversations to return\n- `offset` (number, optional): Number of conversations to skip for pagination\n- `include_discarded` (boolean, optional): Whether to include discarded conversations\n- `statuses` (string, optional): Comma-separated list of statuses to filter conversations by\n\n### read_omi_memories\n\nRetrieves memories from Omi for a specific user.\n\nParameters:\n\n- `user_id` (string): The user ID to fetch memories for\n- `limit` (number, optional): Maximum number of memories to return\n- `offset` (number, optional): Number of memories to skip for pagination\n\n### create_omi_conversation\n\nCreates a new conversation in Omi for a specific user.\n\nParameters:\n\n- `text` (string): The full text content of the conversation\n- `user_id` (string): The user ID to create the conversation for\n- `text_source` (string): Source of the text content (options: \"audio_transcript\", \"message\", \"other_text\")\n- `started_at` (string, optional): When the conversation/event started (ISO 8601 format)\n- `finished_at` (string, optional): When the conversation/event ended (ISO 8601 format)\n- `language` (string, optional): Language code (default: \"en\")\n- `geolocation` (object, optional): Location data for the conversation\n  - `latitude` (number): Latitude coordinate\n  - `longitude` (number): Longitude coordinate\n- `text_source_spec` (string, optional): Additional specification about the source\n\n### create_omi_memories\n\nCreates new memories in Omi for a specific user.\n\nParameters:\n\n- `user_id` (string): The user ID to create memories for\n- `text` (string, optional): The text content from which memories will be extracted\n- `memories` (array, optional): An array of explicit memory objects to be created directly\n  - `content` (string): The content of the memory\n  - `tags` (array of strings, optional): Tags for the memory\n- `text_source` (string, optional): Source of the text content\n- `text_source_spec` (string, optional): Additional specification about the source\n\n## Testing\n\nTo test the MCP server, you can use the provided test client:\n\n```bash\nnode test-mcp-client.js\n```\n\nThis will start an interactive test client that allows you to:\n\n1. Get conversations\n2. Get memories\n3. Create a conversation\n4. Quit\n\nThe test client uses a default test user ID (`test-user-123`) for all operations.\n\n## Logging\n\nThe MCP server includes built-in logging functionality that writes to both the console and a log file. This is useful for debugging and monitoring server activity.\n\n### Log File Location\n\nLogs are written to `logs/mcp-server.log` in your project directory. The log file includes timestamps and detailed information about:\n\n- Server startup and shutdown\n- All API requests and responses\n- Error messages and stack traces\n- API calls to Omi\n- Request parameters and response data\n\n### Viewing Logs\n\nYou can view the logs in real-time using the `tail` command:\n\n```bash\ntail -f logs/mcp-server.log\n```\n\nThis will show you live updates as the server processes requests and interacts with the Omi API.\n\n### Log Format\n\nEach log entry follows this format:\n\n```\n[2024-03-21T12:34:56.789Z] Log message here\n```\n\nThe timestamp is in ISO 8601 format, making it easy to correlate events and debug issues.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "memory",
        "conversations",
        "memories",
        "memories omi",
        "memory management",
        "conversations memories"
      ],
      "category": "memory-management"
    },
    "g0t4--mcp-server-memory-file": {
      "owner": "g0t4",
      "name": "mcp-server-memory-file",
      "url": "https://github.com/g0t4/mcp-server-memory-file",
      "imageUrl": "/freedevtools/mcp/pfp/g0t4.webp",
      "description": "Manage and enhance chat experiences by allowing AI models to remember and recall information during conversations. Effortlessly add, search, delete, and list memories using a simple text file system to improve context retention and response relevance.",
      "stars": 7,
      "forks": 1,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-09-24T09:11:11Z",
      "readme_content": "# mcp-server-memory\n\nThis is an [MCP](https://modelcontextprotocol.io/llms-full.txt) server to interact with a memory text file to help Claude with inter-chat context.\n\nEach line is a memory.\n\nThese tools allow Claude (and other MCP clients) to manage memories mid-chat:\n- `memory_add(memory: string)` - append the memory\n- `memory_search(query: string)` - return matching memories (substring exact match) - later, might allow globs/regex\n- `memory_delete(query: string)` - delete matching memories (substring exact match)\n- `memory_list()` - return all memories\n- FYI `memory_update` == `memory_delete` + `memory_add`\n\nFor example,\n- I mention my name => \"talking to Wes\" \n- metion daughter's age => \"Wes's daughter is 8\" \n- say working on a typescript project => \"working on typescript project\"\n- AND, this is critical, can be based on things Claude (assistant/LLM) says or does... \n    - Notably, tool use (i.e. `run_command`)... say there is a failure on a first attempt to use the tool (i.e. the `python` command isn't present) and then a subsequent tool use succeeds (i.e. using `python3` instead of `python`) => Claude can record \"use python3, python is not present\"...\n- I ask Claude to get rid of memories about X => memory_delete(query: X)\n- I correct my name => memory_search(\"oldname\") + memory_delete(each matching record, or a common subset query) + memory_add(\"newname\")\n\nThen, when a new chat begins, Claude will automatically get recent memories (a subset or all) **OR** can ask for memories (some/more/all). And then can use those to influence responses/tools/etc.\n\n## Design\n\nA simple memory text file, why:\n\n- [ChatGPT's memory](https://help.openai.com/en/articles/8590148-memory-faq) works well and is essentially a text file\n    - Maybe it's structured behind the scenes, however if you review your memory its presented as a text file.\n- My testing of a similar reminders feature for `mcp-server-commands` worked great (when Claude had them).\n- Unstructured text simplifies the tooling and parameters to basically managing a list of strings.\n\nCueing mechanism:\n\n- It's also important to have a cue for the model to know when to store memories. This is a bit more unclear how best to do this but..\n- Training: OpenAI acknowledges some training of models to know when to store memories. Just like models are trained for tool use.\n- Prompt: A system prompt component likely contains a reminder to trigger storing memories.\n- Tool alone: In my testing of Claude, with a tool spec alone, and even with hints/suggestions in tool responses, I couldn't get Claude to store memories. So this alone is not sufficient. Seems like Claude's training with tools is to only use them in pursuit of the prompt/request and thus why I believe adding a reminder/cue in a prompt component will work well.\n\n\n## TODOs/Ideas\n\nI have no idea if these are worth the time, just listing ideas here for the future. Perhaps in part to stop myself from working on them :)\n- Recency factor: a way to rearrange memories based on recency?\n    - Order then becomes relevant for ambiguous memory queries (i.e. work on typescript project and python project then I ask to start a new project, could suggest the most recently used one?)\n- Fade out old memories?\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "memory",
        "conversations",
        "chat",
        "memories using",
        "memory management",
        "memory file"
      ],
      "category": "memory-management"
    },
    "gannonh--memento-mcp": {
      "owner": "gannonh",
      "name": "memento-mcp",
      "url": "https://github.com/gannonh/memento-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/gannonh.webp",
      "description": "Memento is a knowledge graph memory system that facilitates semantic search and contextual recall, enabling LLM applications to manage and retrieve information with temporal awareness. It offers a persistent and adaptive long-term memory structure through ontological entity nodes.",
      "stars": 226,
      "forks": 34,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-02T20:10:04Z",
      "readme_content": "# Memento MCP: A Knowledge Graph Memory System for LLMs\n\n\n\nScalable, high performance knowledge graph memory system with semantic retrieval, contextual recall, and temporal awareness. Provides any LLM client that supports the model context protocol (e.g., Claude Desktop, Cursor, Github Copilot) with resilient, adaptive, and persistent long-term ontological memory.\n\n[![Memento MCP Tests](https://github.com/gannonh/memento-mcp/actions/workflows/memento-mcp.yml/badge.svg)](https://github.com/gannonh/memento-mcp/actions/workflows/memento-mcp.yml)\n[![smithery badge](https://smithery.ai/badge/@gannonh/memento-mcp)](https://smithery.ai/server/@gannonh/memento-mcp)\n\n## Core Concepts\n\n### Entities\n\nEntities are the primary nodes in the knowledge graph. Each entity has:\n\n- A unique name (identifier)\n- An entity type (e.g., \"person\", \"organization\", \"event\")\n- A list of observations\n- Vector embeddings (for semantic search)\n- Complete version history\n\nExample:\n\n```json\n{\n  \"name\": \"John_Smith\",\n  \"entityType\": \"person\",\n  \"observations\": [\"Speaks fluent Spanish\"]\n}\n```\n\n### Relations\n\nRelations define directed connections between entities with enhanced properties:\n\n- Strength indicators (0.0-1.0)\n- Confidence levels (0.0-1.0)\n- Rich metadata (source, timestamps, tags)\n- Temporal awareness with version history\n- Time-based confidence decay\n\nExample:\n\n```json\n{\n  \"from\": \"John_Smith\",\n  \"to\": \"Anthropic\",\n  \"relationType\": \"works_at\",\n  \"strength\": 0.9,\n  \"confidence\": 0.95,\n  \"metadata\": {\n    \"source\": \"linkedin_profile\",\n    \"last_verified\": \"2025-03-21\"\n  }\n}\n```\n\n## Storage Backend\n\nMemento MCP uses Neo4j as its storage backend, providing a unified solution for both graph storage and vector search capabilities.\n\n### Why Neo4j?\n\n- **Unified Storage**: Consolidates both graph and vector storage into a single database\n- **Native Graph Operations**: Built specifically for graph traversal and queries\n- **Integrated Vector Search**: Vector similarity search for embeddings built directly into Neo4j\n- **Scalability**: Better performance with large knowledge graphs\n- **Simplified Architecture**: Clean design with a single database for all operations\n\n### Prerequisites\n\n- Neo4j 5.13+ (required for vector search capabilities)\n\n### Neo4j Desktop Setup (Recommended)\n\nThe easiest way to get started with Neo4j is to use [Neo4j Desktop](https://neo4j.com/download/):\n\n1. Download and install Neo4j Desktop from <https://neo4j.com/download/>\n2. Create a new project\n3. Add a new database\n4. Set password to `memento_password` (or your preferred password)\n5. Start the database\n\nThe Neo4j database will be available at:\n\n- **Bolt URI**: `bolt://127.0.0.1:7687` (for driver connections)\n- **HTTP**: `http://127.0.0.1:7474` (for Neo4j Browser UI)\n- **Default credentials**: username: `neo4j`, password: `memento_password` (or whatever you configured)\n\n### Neo4j Setup with Docker (Alternative)\n\nAlternatively, you can use Docker Compose to run Neo4j:\n\n```bash\n# Start Neo4j container\ndocker-compose up -d neo4j\n\n# Stop Neo4j container\ndocker-compose stop neo4j\n\n# Remove Neo4j container (preserves data)\ndocker-compose rm neo4j\n```\n\nWhen using Docker, the Neo4j database will be available at:\n\n- **Bolt URI**: `bolt://127.0.0.1:7687` (for driver connections)\n- **HTTP**: `http://127.0.0.1:7474` (for Neo4j Browser UI)\n- **Default credentials**: username: `neo4j`, password: `memento_password`\n\n#### Data Persistence and Management\n\nNeo4j data persists across container restarts and even version upgrades due to the Docker volume configuration in the `docker-compose.yml` file:\n\n```yaml\nvolumes:\n  - ./neo4j-data:/data\n  - ./neo4j-logs:/logs\n  - ./neo4j-import:/import\n```\n\nThese mappings ensure that:\n\n- `/data` directory (contains all database files) persists on your host at `./neo4j-data`\n- `/logs` directory persists on your host at `./neo4j-logs`\n- `/import` directory (for importing data files) persists at `./neo4j-import`\n\nYou can modify these paths in your `docker-compose.yml` file to store data in different locations if needed.\n\n##### Upgrading Neo4j Version\n\nYou can change Neo4j editions and versions without losing data:\n\n1. Update the Neo4j image version in `docker-compose.yml`\n2. Restart the container with `docker-compose down && docker-compose up -d neo4j`\n3. Reinitialize the schema with `npm run neo4j:init`\n\nThe data will persist through this process as long as the volume mappings remain the same.\n\n##### Complete Database Reset\n\nIf you need to completely reset your Neo4j database:\n\n```bash\n# Stop the container\ndocker-compose stop neo4j\n\n# Remove the container\ndocker-compose rm -f neo4j\n\n# Delete the data directory contents\nrm -rf ./neo4j-data/*\n\n# Restart the container\ndocker-compose up -d neo4j\n\n# Reinitialize the schema\nnpm run neo4j:init\n```\n\n##### Backing Up Data\n\nTo back up your Neo4j data, you can simply copy the data directory:\n\n```bash\n# Make a backup of the Neo4j data\ncp -r ./neo4j-data ./neo4j-data-backup-$(date +%Y%m%d)\n```\n\n### Neo4j CLI Utilities\n\nMemento MCP includes command-line utilities for managing Neo4j operations:\n\n#### Testing Connection\n\nTest the connection to your Neo4j database:\n\n```bash\n# Test with default settings\nnpm run neo4j:test\n\n# Test with custom settings\nnpm run neo4j:test -- --uri bolt://127.0.0.1:7687 --username myuser --password mypass --database neo4j\n```\n\n#### Initializing Schema\n\nFor normal operation, Neo4j schema initialization happens automatically when Memento MCP connects to the database. You don't need to run any manual commands for regular usage.\n\nThe following commands are only necessary for development, testing, or advanced customization scenarios:\n\n```bash\n# Initialize with default settings (only needed for development or troubleshooting)\nnpm run neo4j:init\n\n# Initialize with custom vector dimensions\nnpm run neo4j:init -- --dimensions 768 --similarity euclidean\n\n# Force recreation of all constraints and indexes\nnpm run neo4j:init -- --recreate\n\n# Combine multiple options\nnpm run neo4j:init -- --vector-index custom_index --dimensions 384 --recreate\n```\n\n## Advanced Features\n\n### Semantic Search\n\nFind semantically related entities based on meaning rather than just keywords:\n\n- **Vector Embeddings**: Entities are automatically encoded into high-dimensional vector space using OpenAI's embedding models\n- **Cosine Similarity**: Find related concepts even when they use different terminology\n- **Configurable Thresholds**: Set minimum similarity scores to control result relevance\n- **Cross-Modal Search**: Query with text to find relevant entities regardless of how they were described\n- **Multi-Model Support**: Compatible with multiple embedding models (OpenAI text-embedding-3-small/large)\n- **Contextual Retrieval**: Retrieve information based on semantic meaning rather than exact keyword matches\n- **Optimized Defaults**: Tuned parameters for balance between precision and recall (0.6 similarity threshold, hybrid search enabled)\n- **Hybrid Search**: Combines semantic and keyword search for more comprehensive results\n- **Adaptive Search**: System intelligently chooses between vector-only, keyword-only, or hybrid search based on query characteristics and available data\n- **Performance Optimization**: Prioritizes vector search for semantic understanding while maintaining fallback mechanisms for resilience\n- **Query-Aware Processing**: Adjusts search strategy based on query complexity and available entity embeddings\n\n### Temporal Awareness\n\nTrack complete history of entities and relations with point-in-time graph retrieval:\n\n- **Full Version History**: Every change to an entity or relation is preserved with timestamps\n- **Point-in-Time Queries**: Retrieve the exact state of the knowledge graph at any moment in the past\n- **Change Tracking**: Automatically records createdAt, updatedAt, validFrom, and validTo timestamps\n- **Temporal Consistency**: Maintain a historically accurate view of how knowledge evolved\n- **Non-Destructive Updates**: Updates create new versions rather than overwriting existing data\n- **Time-Based Filtering**: Filter graph elements based on temporal criteria\n- **History Exploration**: Investigate how specific information changed over time\n\n### Confidence Decay\n\nRelations automatically decay in confidence over time based on configurable half-life:\n\n- **Time-Based Decay**: Confidence in relations naturally decreases over time if not reinforced\n- **Configurable Half-Life**: Define how quickly information becomes less certain (default: 30 days)\n- **Minimum Confidence Floors**: Set thresholds to prevent over-decay of important information\n- **Decay Metadata**: Each relation includes detailed decay calculation information\n- **Non-Destructive**: Original confidence values are preserved alongside decayed values\n- **Reinforcement Learning**: Relations regain confidence when reinforced by new observations\n- **Reference Time Flexibility**: Calculate decay based on arbitrary reference times for historical analysis\n\n### Advanced Metadata\n\nRich metadata support for both entities and relations with custom fields:\n\n- **Source Tracking**: Record where information originated (user input, analysis, external sources)\n- **Confidence Levels**: Assign confidence scores (0.0-1.0) to relations based on certainty\n- **Relation Strength**: Indicate importance or strength of relationships (0.0-1.0)\n- **Temporal Metadata**: Track when information was added, modified, or verified\n- **Custom Tags**: Add arbitrary tags for classification and filtering\n- **Structured Data**: Store complex structured data within metadata fields\n- **Query Support**: Search and filter based on metadata properties\n- **Extensible Schema**: Add custom fields as needed without modifying the core data model\n\n## MCP API Tools\n\nThe following tools are available to LLM client hosts through the Model Context Protocol:\n\n### Entity Management\n\n- **create_entities**\n\n  - Create multiple new entities in the knowledge graph\n  - Input: `entities` (array of objects)\n    - Each object contains:\n      - `name` (string): Entity identifier\n      - `entityType` (string): Type classification\n      - `observations` (string[]): Associated observations\n\n- **add_observations**\n\n  - Add new observations to existing entities\n  - Input: `observations` (array of objects)\n    - Each object contains:\n      - `entityName` (string): Target entity\n      - `contents` (string[]): New observations to add\n\n- **delete_entities**\n\n  - Remove entities and their relations\n  - Input: `entityNames` (string[])\n\n- **delete_observations**\n  - Remove specific observations from entities\n  - Input: `deletions` (array of objects)\n    - Each object contains:\n      - `entityName` (string): Target entity\n      - `observations` (string[]): Observations to remove\n\n### Relation Management\n\n- **create_relations**\n\n  - Create multiple new relations between entities with enhanced properties\n  - Input: `relations` (array of objects)\n    - Each object contains:\n      - `from` (string): Source entity name\n      - `to` (string): Target entity name\n      - `relationType` (string): Relationship type\n      - `strength` (number, optional): Relation strength (0.0-1.0)\n      - `confidence` (number, optional): Confidence level (0.0-1.0)\n      - `metadata` (object, optional): Custom metadata fields\n\n- **get_relation**\n\n  - Get a specific relation with its enhanced properties\n  - Input:\n    - `from` (string): Source entity name\n    - `to` (string): Target entity name\n    - `relationType` (string): Relationship type\n\n- **update_relation**\n\n  - Update an existing relation with enhanced properties\n  - Input: `relation` (object):\n    - Contains:\n      - `from` (string): Source entity name\n      - `to` (string): Target entity name\n      - `relationType` (string): Relationship type\n      - `strength` (number, optional): Relation strength (0.0-1.0)\n      - `confidence` (number, optional): Confidence level (0.0-1.0)\n      - `metadata` (object, optional): Custom metadata fields\n\n- **delete_relations**\n  - Remove specific relations from the graph\n  - Input: `relations` (array of objects)\n    - Each object contains:\n      - `from` (string): Source entity name\n      - `to` (string): Target entity name\n      - `relationType` (string): Relationship type\n\n### Graph Operations\n\n- **read_graph**\n\n  - Read the entire knowledge graph\n  - No input required\n\n- **search_nodes**\n\n  - Search for nodes based on query\n  - Input: `query` (string)\n\n- **open_nodes**\n  - Retrieve specific nodes by name\n  - Input: `names` (string[])\n\n### Semantic Search\n\n- **semantic_search**\n\n  - Search for entities semantically using vector embeddings and similarity\n  - Input:\n    - `query` (string): The text query to search for semantically\n    - `limit` (number, optional): Maximum results to return (default: 10)\n    - `min_similarity` (number, optional): Minimum similarity threshold (0.0-1.0, default: 0.6)\n    - `entity_types` (string[], optional): Filter results by entity types\n    - `hybrid_search` (boolean, optional): Combine keyword and semantic search (default: true)\n    - `semantic_weight` (number, optional): Weight of semantic results in hybrid search (0.0-1.0, default: 0.6)\n  - Features:\n    - Intelligently selects optimal search method (vector, keyword, or hybrid) based on query context\n    - Gracefully handles queries with no semantic matches through fallback mechanisms\n    - Maintains high performance with automatic optimization decisions\n\n- **get_entity_embedding**\n  - Get the vector embedding for a specific entity\n  - Input:\n    - `entity_name` (string): The name of the entity to get the embedding for\n\n### Temporal Features\n\n- **get_entity_history**\n\n  - Get complete version history of an entity\n  - Input: `entityName` (string)\n\n- **get_relation_history**\n\n  - Get complete version history of a relation\n  - Input:\n    - `from` (string): Source entity name\n    - `to` (string): Target entity name\n    - `relationType` (string): Relationship type\n\n- **get_graph_at_time**\n\n  - Get the state of the graph at a specific timestamp\n  - Input: `timestamp` (number): Unix timestamp (milliseconds since epoch)\n\n- **get_decayed_graph**\n  - Get graph with time-decayed confidence values\n  - Input: `options` (object, optional):\n    - `reference_time` (number): Reference timestamp for decay calculation (milliseconds since epoch)\n    - `decay_factor` (number): Optional decay factor override\n\n## Configuration\n\n### Environment Variables\n\nConfigure Memento MCP with these environment variables:\n\n```bash\n# Neo4j Connection Settings\nNEO4J_URI=bolt://127.0.0.1:7687\nNEO4J_USERNAME=neo4j\nNEO4J_PASSWORD=memento_password\nNEO4J_DATABASE=neo4j\n\n# Vector Search Configuration\nNEO4J_VECTOR_INDEX=entity_embeddings\nNEO4J_VECTOR_DIMENSIONS=1536\nNEO4J_SIMILARITY_FUNCTION=cosine\n\n# Embedding Service Configuration\nMEMORY_STORAGE_TYPE=neo4j\nOPENAI_API_KEY=your-openai-api-key\nOPENAI_EMBEDDING_MODEL=text-embedding-3-small\n\n# Debug Settings\nDEBUG=true\n```\n\n### Command Line Options\n\nThe Neo4j CLI tools support the following options:\n\n```\n--uri <uri>              Neo4j server URI (default: bolt://127.0.0.1:7687)\n--username <username>    Neo4j username (default: neo4j)\n--password <password>    Neo4j password (default: memento_password)\n--database <n>           Neo4j database name (default: neo4j)\n--vector-index <n>       Vector index name (default: entity_embeddings)\n--dimensions <number>    Vector dimensions (default: 1536)\n--similarity <function>  Similarity function (cosine|euclidean) (default: cosine)\n--recreate               Force recreation of constraints and indexes\n--no-debug               Disable detailed output (debug is ON by default)\n```\n\n### Embedding Models\n\nAvailable OpenAI embedding models:\n\n- `text-embedding-3-small`: Efficient, cost-effective (1536 dimensions)\n- `text-embedding-3-large`: Higher accuracy, more expensive (3072 dimensions)\n- `text-embedding-ada-002`: Legacy model (1536 dimensions)\n\n#### OpenAI API Configuration\n\nTo use semantic search, you'll need to configure OpenAI API credentials:\n\n1. Obtain an API key from [OpenAI](https://platform.openai.com/api-keys)\n2. Configure your environment with:\n\n```bash\n# OpenAI API Key for embeddings\nOPENAI_API_KEY=your-openai-api-key\n# Default embedding model\nOPENAI_EMBEDDING_MODEL=text-embedding-3-small\n```\n\n> **Note**: For testing environments, the system will mock embedding generation if no API key is provided. However, using real embeddings is recommended for integration testing.\n\n## Integration with Claude Desktop\n\n### Configuration\n\nAdd this to your `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"memento\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@gannonh/memento-mcp\"],\n      \"env\": {\n        \"MEMORY_STORAGE_TYPE\": \"neo4j\",\n        \"NEO4J_URI\": \"bolt://127.0.0.1:7687\",\n        \"NEO4J_USERNAME\": \"neo4j\",\n        \"NEO4J_PASSWORD\": \"memento_password\",\n        \"NEO4J_DATABASE\": \"neo4j\",\n        \"NEO4J_VECTOR_INDEX\": \"entity_embeddings\",\n        \"NEO4J_VECTOR_DIMENSIONS\": \"1536\",\n        \"NEO4J_SIMILARITY_FUNCTION\": \"cosine\",\n        \"OPENAI_API_KEY\": \"your-openai-api-key\",\n        \"OPENAI_EMBEDDING_MODEL\": \"text-embedding-3-small\",\n        \"DEBUG\": \"true\"\n      }\n    }\n  }\n}\n```\n\nAlternatively, for local development, you can use:\n\n```json\n{\n  \"mcpServers\": {\n    \"memento\": {\n      \"command\": \"/path/to/node\",\n      \"args\": [\"/path/to/memento-mcp/dist/index.js\"],\n      \"env\": {\n        \"MEMORY_STORAGE_TYPE\": \"neo4j\",\n        \"NEO4J_URI\": \"bolt://127.0.0.1:7687\",\n        \"NEO4J_USERNAME\": \"neo4j\",\n        \"NEO4J_PASSWORD\": \"memento_password\",\n        \"NEO4J_DATABASE\": \"neo4j\",\n        \"NEO4J_VECTOR_INDEX\": \"entity_embeddings\",\n        \"NEO4J_VECTOR_DIMENSIONS\": \"1536\",\n        \"NEO4J_SIMILARITY_FUNCTION\": \"cosine\",\n        \"OPENAI_API_KEY\": \"your-openai-api-key\",\n        \"OPENAI_EMBEDDING_MODEL\": \"text-embedding-3-small\",\n        \"DEBUG\": \"true\"\n      }\n    }\n  }\n}\n```\n\n> **Important**: Always explicitly specify the embedding model in your Claude Desktop configuration to ensure consistent behavior.\n\n### Recommended System Prompts\n\nFor optimal integration with Claude, add these statements to your system prompt:\n\n```\nYou have access to the Memento MCP knowledge graph memory system, which provides you with persistent memory capabilities.\nYour memory tools are provided by Memento MCP, a sophisticated knowledge graph implementation.\nWhen asked about past conversations or user information, always check the Memento MCP knowledge graph first.\nYou should use semantic_search to find relevant information in your memory when answering questions.\n```\n\n### Testing Semantic Search\n\nOnce configured, Claude can access the semantic search capabilities through natural language:\n\n1. To create entities with semantic embeddings:\n\n   ```\n   User: \"Remember that Python is a high-level programming language known for its readability and JavaScript is primarily used for web development.\"\n   ```\n\n2. To search semantically:\n\n   ```\n   User: \"What programming languages do you know about that are good for web development?\"\n   ```\n\n3. To retrieve specific information:\n\n   ```\n   User: \"Tell me everything you know about Python.\"\n   ```\n\nThe power of this approach is that users can interact naturally, while the LLM handles the complexity of selecting and using the appropriate memory tools.\n\n### Real-World Applications\n\nMemento's adaptive search capabilities provide practical benefits:\n\n1. **Query Versatility**: Users don't need to worry about how to phrase questions - the system adapts to different query types automatically\n\n2. **Failure Resilience**: Even when semantic matches aren't available, the system can fall back to alternative methods without user intervention\n\n3. **Performance Efficiency**: By intelligently selecting the optimal search method, the system balances performance and relevance for each query\n\n4. **Improved Context Retrieval**: LLM conversations benefit from better context retrieval as the system can find relevant information across complex knowledge graphs\n\nFor example, when a user asks \"What do you know about machine learning?\", the system can retrieve conceptually related entities even if they don't explicitly mention \"machine learning\" - perhaps entities about neural networks, data science, or specific algorithms. But if semantic search yields insufficient results, the system automatically adjusts its approach to ensure useful information is still returned.\n\n## Troubleshooting\n\n### Vector Search Diagnostics\n\nMemento MCP includes built-in diagnostic capabilities to help troubleshoot vector search issues:\n\n- **Embedding Verification**: The system checks if entities have valid embeddings and automatically generates them if missing\n- **Vector Index Status**: Verifies that the vector index exists and is in the ONLINE state\n- **Fallback Search**: If vector search fails, the system falls back to text-based search\n- **Detailed Logging**: Comprehensive logging of vector search operations for troubleshooting\n\n### Debug Tools (when DEBUG=true)\n\nAdditional diagnostic tools become available when debug mode is enabled:\n\n- **diagnose_vector_search**: Information about the Neo4j vector index, embedding counts, and search functionality\n- **force_generate_embedding**: Forces the generation of an embedding for a specific entity\n- **debug_embedding_config**: Information about the current embedding service configuration\n\n### Developer Reset\n\nTo completely reset your Neo4j database during development:\n\n```bash\n# Stop the container (if using Docker)\ndocker-compose stop neo4j\n\n# Remove the container (if using Docker)\ndocker-compose rm -f neo4j\n\n# Delete the data directory (if using Docker)\nrm -rf ./neo4j-data/*\n\n# For Neo4j Desktop, right-click your database and select \"Drop database\"\n\n# Restart the database\n# For Docker:\ndocker-compose up -d neo4j\n\n# For Neo4j Desktop:\n# Click the \"Start\" button for your database\n\n# Reinitialize the schema\nnpm run neo4j:init\n```\n\n## Building and Development\n\n```bash\n# Clone the repository\ngit clone https://github.com/gannonh/memento-mcp.git\ncd memento-mcp\n\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n\n# Run tests\nnpm test\n\n# Check test coverage\nnpm run test:coverage\n```\n\n## Installation\n\n### Installing via Smithery\n\nTo install memento-mcp for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@gannonh/memento-mcp):\n\n```bash\nnpx -y @smithery/cli install @gannonh/memento-mcp --client claude\n```\n\n### Global Installation with npx\n\nYou can run Memento MCP directly using npx without installing it globally:\n\n```bash\nnpx -y @gannonh/memento-mcp\n```\n\nThis method is recommended for use with Claude Desktop and other MCP-compatible clients.\n\n### Local Installation\n\nFor development or contributing to the project:\n\n```bash\n# Install locally\nnpm install @gannonh/memento-mcp\n\n# Or clone the repository\ngit clone https://github.com/gannonh/memento-mcp.git\ncd memento-mcp\nnpm install\n```\n\n## License\n\nMIT",
      "npm_url": "https://www.npmjs.com/package/@gannonh/memento-mcp",
      "npm_downloads": 2207,
      "keywords": [
        "memento",
        "memory",
        "recall",
        "memento knowledge",
        "mcp memento",
        "memento mcp"
      ],
      "category": "memory-management"
    },
    "gmacev--Simple-Memory-Extension-MCP-Server": {
      "owner": "gmacev",
      "name": "Simple-Memory-Extension-MCP-Server",
      "url": "https://github.com/gmacev/Simple-Memory-Extension-MCP-Server",
      "imageUrl": "/freedevtools/mcp/pfp/gmacev.webp",
      "description": "Store and recall important information for agents, manage memory through context item and namespace functionalities, and facilitate semantic search capabilities for relevant context retrieval.",
      "stars": 9,
      "forks": 2,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-10T13:12:48Z",
      "readme_content": "# Simple Memory Extension MCP Server\n\nAn MCP server to extend the context window / memory of agents. Useful when coding big features or vibe coding and need to store/recall progress, key moments or changes or anything worth remembering. Simply ask the agent to store memories and recall whenever you need or ask the agent to fully manage its memory (through cursor rules for example) however it sees fit.\n\n## Usage\n\n### Starting the Server\n\n```bash\nnpm install\nnpm start\n```\n\n### Available Tools\n\n#### Context Item Management\n- `store_context_item` - Store a value with key in namespace\n- `retrieve_context_item_by_key` - Get value by key\n- `delete_context_item` - Delete key-value pair\n\n#### Namespace Management\n- `create_namespace` - Create new namespace\n- `delete_namespace` - Delete namespace and all contents\n- `list_namespaces` - List all namespaces\n- `list_context_item_keys` - List keys in a namespace\n\n#### Semantic Search\n- `retrieve_context_items_by_semantic_search` - Find items by meaning\n\n### Semantic Search Implementation\n\n1. Query converted to vector using E5 model\n2. Text automatically split into chunks for better matching\n3. Cosine similarity calculated between query and stored chunks\n4. Results filtered by threshold and sorted by similarity\n5. Top matches returned with full item values\n\n## Development\n\n```bash\n# Dev server\nnpm run dev\n\n# Format code\nnpm run format\n```\n\n## .env\n\n```\n# Path to SQLite database file\nDB_PATH=./data/context.db\n\nPORT=3000\n\n# Use HTTP SSE or Stdio\nUSE_HTTP_SSE=true\n\n# Logging Configuration: debug, info, warn, error\nLOG_LEVEL=info\n```\n\n## Semantic Search\n\nThis project includes semantic search capabilities using the E5 embedding model from Hugging Face. This allows you to find context items based on their meaning rather than just exact key matches.\n\n### Setup\n\nThe semantic search feature requires Python dependencies, but these *should be* automatically installed when you run: `npm run start`\n\n### Embedding Model\n\nWe use the [intfloat/multilingual-e5-large-instruct](https://huggingface.co/intfloat/multilingual-e5-large-instruct)\n\n\n### Notes\n\nDeveloped mostly while vibe coding, so don't expect much :D. But it works, and I found it helpful so w/e. Feel free to contribute or suggest improvements.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "gmacev",
        "memory",
        "retrieval",
        "management gmacev",
        "memory context",
        "manage memory"
      ],
      "category": "memory-management"
    },
    "henryhawke--mcp-titan": {
      "owner": "henryhawke",
      "name": "mcp-titan",
      "url": "https://github.com/henryhawke/mcp-titan",
      "imageUrl": "/freedevtools/mcp/pfp/henryhawke.webp",
      "description": "A memory engine designed for LLMs, enabling continuous learning and context management through a transformer-based neural memory system that can predict sequences and maintain state across interactions.",
      "stars": 70,
      "forks": 15,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-30T23:10:12Z",
      "readme_content": "# Titan Memory MCP Server\n\nThe project has been fundamentally fixed - the core architectural problem (incompatible custom ToolResponse interface) has been resolved, and the MCP Titan Memory System is now compatible with the official MCP SDK v1.12.0.\nThe remaining errors are primarily code quality and type safety improvements rather than blocking functionality issues. The server should now be able to run and provide its 16 sophisticated memory tools for agentic AI models.\n\n## System Prompt for LLMs (Cursor/Claude MCP)\n\n```markdown\nYou are connected to the @henryhawke/mcp-titan MCP server. Use the tools exactly as documented in docs/llm-system-prompt.md. For a comprehensive overview of the system architecture, see [docs/architecture-overview.md](docs/architecture-overview.md). No human intervention is required except for adding the mcp-titan llm-system-prompt rule to the client.\n\n- Always use the MCP tools for all memory, training, and state operations.\n- Always initialize the model with `init_model` before using any other tool.\n- Use `help` to discover available tools and their parameter schemas.\n- Use `save_checkpoint` and `load_checkpoint` to persist and restore memory state.\n- Use `reset_gradients` if you encounter training instability or errors.\n- Use `prune_memory` when memory capacity drops below 30%.\n- Always check tool responses for errors (`isError: true` or `type: \"error\"`) and handle them as documented.\n- Follow all best practices and error handling as described in docs/llm-system-prompt.md.\n- Do not use any implementation details or code not exposed by the server.\n- Reference docs/llm-system-prompt.md for the latest schemas and usage examples.\n\nThis prompt is copy-pastable and should be used as the system prompt for any LLM (Cursor, Claude, or other MCP-compliant clients) to ensure correct and robust operation with MCP Titan.\n```\n\n## Installation & Usage as MCP Server for Cursor or Claude\n\n### Prerequisites\n\n- Node.js (v18 or later recommended)\n- npm (comes with Node.js)\n- (Optional) Docker, if you want to run in a container\n\n### 1. Clone the Repository\n\n```bash\ngit clone https://github.com/henryhawke/mcp-titan.git\ncd titan-memory\n```\n\n### 2. Install Dependencies\n\n```bash\nnpm install\n```\n\n### 3. Build the Project\n\n```bash\nnpm run build\n```\n\n### 4. Start the MCP Server\n\n```bash\nnpm start\n```\n\nThe server will start and listen for MCP tool requests. By default, it runs on port 8080 (or as configured in your environment).\n\n### 5. Integrate with Cursor or Claude\n\n- **Cursor**: Ensure MCP is enabled in Cursor settings. Cursor will auto-detect and connect to the running MCP server.\n\n    \"titan-memory\": {\n      \"command\": \"node\",\n      \"args\": [\"index.js\"],\n      \"cwd\": \"/Users/henrymayo/Desktop/mcp-titan\",\n      \"autoapprove\": [\n        \"create_entities\",\n        \"create_relations\",\n        \"add_observations\",\n        \"delete_entities\",\n        \"delete_observations\",\n        \"delete_relations\",\n        \"read_graph\",\n        \"search_nodes\",\n        \"open_nodes\"\n      ]\n    },\n\n    \n- **Claude Desktop**: Set the MCP server endpoint in Claude's settings to `http://localhost:8080` (or your configured host/port).\n\n### 6. Test the MCP Server\n\nYou can use the provided tool APIs (see below) or connect via Cursor/Claude to verify memory operations.\n\n---\nIdeally this just runs in yolo mode in cursor (or claude desktop) without human intervention and creates a \"brain\" available independent of LLM version.\n\nA neural memory system for LLMs that can learn and predict sequences while maintaining state through a memory vector. This MCP (Model Context Protocol) server provides tools for Claude 3.7 Sonnet and other LLMs to maintain memory state across interactions.\n\n## Features\n\n- **Perfect for Cursor**: Now that Cursor automatically runs MCP in yolo mode, you can take your hands off the wheel with your LLM's new memory\n- **Neural Memory Architecture**: Transformer-based memory system that can learn and predict sequences\n- **Memory Management**: Efficient tensor operations with automatic memory cleanup\n- **MCP Integration**: Fully compatible with Cursor and other MCP clients\n- **Text Encoding**: Convert text inputs to tensor representations\n- **Memory Persistence**: Save and load memory states between sessions\n\n## Available Tools\n\nThe Titan Memory MCP server provides the following tools:\n\n### `help`\n\nGet help about available tools.\n\n**Parameters:**\n\n- `tool` (optional): Specific tool name to get help for\n- `category` (optional): Category of tools to explore\n- `showExamples` (optional): Include usage examples\n- `verbose` (optional): Include detailed descriptions\n\n### `init_model`\n\nInitialize the Titan Memory model with custom configuration.\n\n**Parameters:**\n\n- `inputDim`: Input dimension size (default: 768)\n- `hiddenDim`: Hidden dimension size (default: 512)\n- `memoryDim`: Memory dimension size (default: 1024)\n- `transformerLayers`: Number of transformer layers (default: 6)\n- `numHeads`: Number of attention heads (default: 8)\n- `ffDimension`: Feed-forward dimension (default: 2048)\n- `dropoutRate`: Dropout rate (default: 0.1)\n- `maxSequenceLength`: Maximum sequence length (default: 512)\n- `memorySlots`: Number of memory slots (default: 5000)\n- `similarityThreshold`: Similarity threshold (default: 0.65)\n- `surpriseDecay`: Surprise decay rate (default: 0.9)\n- `pruningInterval`: Pruning interval (default: 1000)\n- `gradientClip`: Gradient clipping value (default: 1.0)\n\n### `forward_pass`\n\nPerform a forward pass through the model to get predictions.\n\n**Parameters:**\n\n- `x`: Input vector or text\n- `memoryState` (optional): Memory state to use\n\n### `train_step`\n\nExecute a training step to update the model.\n\n**Parameters:**\n\n- `x_t`: Current input vector or text\n- `x_next`: Next input vector or text\n\n### `get_memory_state`\n\nGet the current memory state and statistics.\n\n**Parameters:**\n\n- `type` (optional): Optional memory type filter\n\n### `manifold_step`\n\nUpdate memory along a manifold direction.\n\n**Parameters:**\n\n- `base`: Base memory state\n- `velocity`: Update direction\n\n### `prune_memory`\n\nRemove less relevant memories to free up space.\n\n**Parameters:**\n\n- `threshold`: Pruning threshold (0-1)\n\n### `save_checkpoint`\n\nSave memory state to a file.\n\n**Parameters:**\n\n- `path`: Checkpoint file path\n\n### `load_checkpoint`\n\nLoad memory state from a file.\n\n**Parameters:**\n\n- `path`: Checkpoint file path\n\n### `reset_gradients`\n\nReset accumulated gradients to recover from training issues.\n\n**Parameters:** None\n\n## Usage with Claude 4 Sonnet in Cursor\n\nThe Titan Memory MCP server is designed to work seamlessly with Claude 3.7 Sonnet in Cursor. Here's an example of how to use it:\n\n```javascript\n// Initialize the model\nconst result = await callTool(\"init_model\", {\n  inputDim: 768,\n  memorySlots: 10000,\n  transformerLayers: 8,\n});\n\n// Perform a forward pass\nconst { predicted, memoryUpdate } = await callTool(\"forward_pass\", {\n  x: \"const x = 5;\", // or vector: [0.1, 0.2, ...]\n  memoryState: currentMemory,\n});\n\n// Train the model\nconst result = await callTool(\"train_step\", {\n  x_t: \"function hello() {\",\n  x_next: \"  console.log('world');\",\n});\n\n// Get memory state\nconst state = await callTool(\"get_memory_state\", {});\n```\n\n## How the MCP Server Learns: TITANS-Inspired Neural Memory\n\nThe Titan Memory MCP server implements a sophisticated neural memory architecture inspired by transformer mechanisms and continual learning principles. Here's a detailed breakdown of the learning process:\n\n### Core Learning Architecture\n\n**Three-Tier Memory Hierarchy:**\n1. **Short-term Memory** - Recent activations and immediate context\n2. **Long-term Memory** - Consolidated patterns and persistent knowledge  \n3. **Meta Memory** - Statistics about memory usage and learning patterns\n\n**Surprise-Driven Learning:**\nThe system uses surprise-based learning mechanisms where unexpected inputs trigger stronger memory updates:\n- **Surprise Calculation**: `surprise = ||decoded_output - input||` (L2 norm of prediction error)\n- **Surprise Decay**: Previous surprise scores decay exponentially with configurable rate (default: 0.9)\n- **Memory Gating**: High surprise opens memory gates for stronger encoding\n\n### Forward Pass Learning Process\n\n1. **Input Encoding**: Text inputs are encoded using advanced BPE tokenization or TF-IDF fallback\n2. **Memory Attention**: Transformer-style attention mechanism computes relevance scores across stored memories\n3. **Prediction Generation**: Decoder network generates predictions based on attended memories\n4. **Surprise Computation**: Compare predictions with actual inputs to calculate surprise\n5. **Memory Update**: Update all three memory tiers based on surprise magnitude\n\n```typescript\n// Core forward pass with memory updates\npublic forward(input: ITensor, state?: IMemoryState): {\n  predicted: ITensor;\n  memoryUpdate: IMemoryUpdateResult;\n} {\n  const encodedInput = this.encoder.predict(inputTensor);\n  const memoryResult = this.computeMemoryAttention(encodedInput);\n  const decoded = this.decoder.predict([encodedInput, memoryResult]);\n  const surprise = tf.norm(tf.sub(decoded, inputTensor));\n  \n  // Update memory based on surprise\n  const newMemoryState = this.updateMemory(encodedInput, surprise, memoryState);\n  \n  return { predicted: decoded, memoryUpdate: newMemoryState };\n}\n```\n\n### Training Step Learning Process\n\n**Predictive Learning:**\n- Each training step predicts the next input given the current input\n- Loss computed as mean squared error between prediction and target\n- Gradients computed using TensorFlow.js automatic differentiation\n\n**Memory-Augmented Training:**\n1. **Attention-Based Retrieval**: Query current memory using input as key\n2. **Gradient Computation**: Backpropagate through attention mechanism\n3. **Weight Updates**: Update encoder, decoder, and attention networks\n4. **Memory Consolidation**: Move important patterns from short-term to long-term memory\n\n### Online Learning Service\n\n**Ring Buffer Replay System:**\n- Maintains circular buffer of training samples (default: 10,000 samples)\n- Samples mini-batches for continuous learning (default: 32 samples)\n- Three learning objectives combined with configurable weights:\n\n```typescript\n// Mixed loss function combining multiple learning signals\nprivate computeMixedLoss(batch: TrainingSample[]): {\n  loss: tf.Scalar;\n  gradients: Map<string, tf.Tensor>;\n} {\n  let totalLoss = tf.scalar(0);\n  \n  // Next-token prediction (40% weight)\n  if (this.config.nextTokenWeight > 0) {\n    const nextTokenLoss = this.computeNextTokenLoss(batch);\n    totalLoss = tf.add(totalLoss, tf.mul(nextTokenLoss, 0.4));\n  }\n  \n  // Contrastive learning (20% weight)\n  if (this.config.contrastiveWeight > 0) {\n    const contrastiveLoss = this.computeContrastiveLoss(batch);\n    totalLoss = tf.add(totalLoss, tf.mul(contrastiveLoss, 0.2));\n  }\n  \n  // Masked language modeling (40% weight)\n  if (this.config.mlmWeight > 0) {\n    const mlmLoss = this.computeMLMLoss(batch);\n    totalLoss = tf.add(totalLoss, tf.mul(mlmLoss, 0.4));\n  }\n  \n  return { loss: totalLoss, gradients };\n}\n```\n\n### Advanced Learning Features\n\n**Hierarchical Memory (Optional):**\n- Multiple memory levels with different time scales\n- Higher levels update less frequently (powers of 2)\n- Enables long-term pattern recognition and forgetting\n\n**Information-Gain Based Pruning:**\n- Automatically removes low-relevance memories when capacity reached\n- Scores memories based on: recency, frequency, surprise history\n- Distills important patterns into long-term storage before pruning\n\n**Gradient Management:**\n- **Gradient Clipping**: Prevents exploding gradients (default: 1.0)\n- **Gradient Accumulation**: Accumulates gradients over multiple steps for stability\n- **NaN Guards**: Detects and skips corrupted gradient updates\n\n### Memory Persistence and Bootstrapping\n\n**Automatic State Persistence:**\n- Memory state auto-saved every 60 seconds\n- Checkpoint system for manual save/load operations\n- Graceful shutdown with state preservation\n\n**Bootstrap Learning:**\n- `bootstrap_memory` tool initializes memory from URLs or text corpora\n- TF-IDF vectorizer provides sparse fallback for untrained models\n- Seed summaries populate initial memory state\n\n### Continual Learning Loop\n\nThe online learning service runs continuously in the background:\n\n1. **Sample Collection**: Gather training samples from interactions\n2. **Batch Formation**: Create mini-batches from replay buffer\n3. **Mixed Loss Computation**: Combine multiple learning objectives\n4. **Gradient Application**: Update model weights with clipped gradients\n5. **Memory Consolidation**: Promote important short-term memories to long-term storage\n6. **Pruning**: Remove irrelevant memories to maintain performance\n\nThis architecture enables the MCP server to continuously learn from interactions while maintaining stable, long-term memory that persists across sessions and model updates.\n\n## Memory Management\n\nThe Titan Memory MCP server includes sophisticated memory management to prevent memory leaks and ensure efficient tensor operations:\n\n1. **Automatic Cleanup**: Periodically cleans up unused tensors using `tf.tidy()`\n2. **Memory Encryption**: Securely stores memory states with AES-256-CBC encryption\n3. **Tensor Validation**: Ensures tensors have correct shapes and are not disposed\n4. **Error Recovery**: Handles tensor errors gracefully with fallback mechanisms\n\n## Architecture\n\nThe Titan Memory MCP server is built with a modular architecture:\n\n- **TitanMemoryServer**: Main server class that registers 16 MCP tools and handles requests\n- **TitanMemoryModel**: Neural memory model with transformer-inspired attention mechanisms\n- **LearnerService**: Online learning loop with replay buffer and mixed loss functions\n- **MemoryPruner**: Information-gain based pruning for memory management\n- **AdvancedTokenizer**: BPE tokenization with embedding capabilities\n- **VectorProcessor**: Text encoding and tensor operations with safety guards\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n",
      "npm_url": "https://www.npmjs.com/package/mcp-titan",
      "npm_downloads": 0,
      "keywords": [
        "memory",
        "llms",
        "neural",
        "memory engine",
        "titan memory",
        "memory management"
      ],
      "category": "memory-management"
    },
    "honeybluesky--my-apple-remembers": {
      "owner": "honeybluesky",
      "name": "my-apple-remembers",
      "url": "https://github.com/honeybluesky/my-apple-remembers",
      "imageUrl": "/freedevtools/mcp/pfp/honeybluesky.webp",
      "description": "Recalls and saves memories from Apple Notes, accessing notes, calendar events, messages, and files on macOS. Facilitates the persistence of important information for future reference with minimal setup.",
      "stars": 9,
      "forks": 2,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-13T14:48:09Z",
      "readme_content": "# MCP Server - My Apple Remembers\n**A simple MCP server that recalls and saves memories from and to Apple Notes.**\n\n[![Docker Pulls](https://img.shields.io/docker/pulls/buryhuang/mcp-my-apple-remembers)](https://hub.docker.com/r/buryhuang/mcp-my-apple-remembers)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\n<img width=\"600\" alt=\"image\" src=\"https://github.com/user-attachments/assets/9bd5bc1c-02fe-4e71-88c4-46b3e9438ac0\" />\n\n\n## Features\n\n* **Memory Recall**: Access notes, calendar events, messages, files and other information from your Mac\n* **Memory Persistence**: Save important information to Apple Notes for future reference\n* **Minimal Setup**: Just enable Remote Login on the target Mac\n* **Universal Compatibility**: Works with all macOS versions\n\n## Control in your hand\nYou can use prompt to instruct how you want your memory to be save. For example:\n```\nYou should always use Folder \"baryhuang\" on recall and save memory.\n```\n\n## Installation\n- [Enable SSH on macOS](https://support.apple.com/guide/mac-help/allow-a-remote-computer-to-access-your-mac-mchlp1066/mac)\n- [Install Docker Desktop for local Mac](https://docs.docker.com/desktop/setup/install/mac-install/)\n- [Add this MCP server to Claude Desktop](https://modelcontextprotocol.io/quickstart/user)\n\nYou can configure Claude Desktop to use the Docker image by adding the following to your Claude configuration:\n```json\n{\n  \"mcpServers\": {\n    \"my-apple-remembers\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"-e\",\n        \"MACOS_USERNAME=your_macos_username\",\n        \"-e\",\n        \"MACOS_PASSWORD=your_macos_password\",\n        \"-e\",\n        \"MACOS_HOST=localhost\",\n        \"--rm\",\n        \"buryhuang/mcp-my-apple-remembers:latest\"\n      ]\n    }\n  }\n}\n```\n\n## Developer Instructions\n### Clone the repo\n```bash\n# Clone the repository\ngit clone https://github.com/baryhuang/mcp-my-apple-remembers.git\ncd mcp-my-apple-remembers\n```\n\n### Building the Docker Image\n\n```bash\n# Build the Docker image\ndocker build -t mcp-my-apple-remembers .\n```\n\n### Publishing Multi-Platform Docker Images\n\n```bash\n# Set up Docker buildx for multi-platform builds\ndocker buildx create --use\n\n# Build and push the multi-platform image\ndocker buildx build --platform linux/amd64,linux/arm64 -t buryhuang/mcp-my-apple-remembers:latest --push .\n```\n\n### Tools Specifications\n\n#### my_apple_recall_memory\nRun AppleScript commands on a remote macOS system to recall memories. This tool helps access Apple Notes, Calendar events, iMessages, chat history, files, and other information on your Mac.\n\n#### my_apple_save_memory\nRun AppleScript commands on a remote macOS system to save important information. This tool allows AI to persist relevant information to Apple Notes for future reference. \n\nAll tools require macOS SSH access, with host and password.\n\n## Security Note\n\nAlways use secure, authenticated connections when accessing remote macOS machines. This tool should only be used with servers you trust and have permission to access.\n\n## License\n\nSee the LICENSE file for details. \n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "memory",
        "recalls",
        "remembers",
        "apple remembers",
        "memory management",
        "saves memories"
      ],
      "category": "memory-management"
    },
    "ibproduct--ib-mcp-cache-server": {
      "owner": "ibproduct",
      "name": "ib-mcp-cache-server",
      "url": "https://github.com/ibproduct/ib-mcp-cache-server",
      "imageUrl": "/freedevtools/mcp/pfp/ibproduct.webp",
      "description": "Efficiently caches data between language model interactions to reduce token consumption, enhancing performance and speeding up responses. Integrates seamlessly with any MCP client and language model that uses tokens.",
      "stars": 17,
      "forks": 8,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-09-30T23:13:03Z",
      "readme_content": "# Memory Cache Server\n\nA Model Context Protocol (MCP) server that reduces token consumption by efficiently caching data between language model interactions. Works with any MCP client and any language model that uses tokens.\n\n## Installation\n\n1. Clone the repository:\n```bash\ngit clone git@github.com:ibproduct/ib-mcp-cache-server\ncd ib-mcp-cache-server\n```\n\n2. Install dependencies:\n```bash\nnpm install\n```\n\n3. Build the project:\n```bash\nnpm run build\n```\n\n4. Add to your MCP client settings:\n```json\n{\n  \"mcpServers\": {\n    \"memory-cache\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/ib-mcp-cache-server/build/index.js\"]\n    }\n  }\n}\n```\n\n5. The server will automatically start when you use your MCP client\n\n## Verifying It Works\n\nWhen the server is running properly, you'll see:\n1. A message in the terminal: \"Memory Cache MCP server running on stdio\"\n2. Improved performance when accessing the same data multiple times\n3. No action required from you - the caching happens automatically\n\nYou can verify the server is running by:\n1. Opening your MCP client\n2. Looking for any error messages in the terminal where you started the server\n3. Performing operations that would benefit from caching (like reading the same file multiple times)\n\n## Configuration\n\nThe server can be configured through `config.json` or environment variables:\n\n```json\n{\n  \"maxEntries\": 1000,        // Maximum number of items in cache\n  \"maxMemory\": 104857600,    // Maximum memory usage in bytes (100MB)\n  \"defaultTTL\": 3600,        // Default time-to-live in seconds (1 hour)\n  \"checkInterval\": 60000,    // Cleanup interval in milliseconds (1 minute)\n  \"statsInterval\": 30000     // Stats update interval in milliseconds (30 seconds)\n}\n```\n\n### Configuration Settings Explained\n\n1. **maxEntries** (default: 1000)\n   - Maximum number of items that can be stored in cache\n   - Prevents cache from growing indefinitely\n   - When exceeded, oldest unused items are removed first\n\n2. **maxMemory** (default: 100MB)\n   - Maximum memory usage in bytes\n   - Prevents excessive memory consumption\n   - When exceeded, least recently used items are removed\n\n3. **defaultTTL** (default: 1 hour)\n   - How long items stay in cache by default\n   - Items are automatically removed after this time\n   - Prevents stale data from consuming memory\n\n4. **checkInterval** (default: 1 minute)\n   - How often the server checks for expired items\n   - Lower values keep memory usage more accurate\n   - Higher values reduce CPU usage\n\n5. **statsInterval** (default: 30 seconds)\n   - How often cache statistics are updated\n   - Affects accuracy of hit/miss rates\n   - Helps monitor cache effectiveness\n\n## How It Reduces Token Consumption\n\nThe memory cache server reduces token consumption by automatically storing data that would otherwise need to be re-sent between you and the language model. You don't need to do anything special - the caching happens automatically when you interact with any language model through your MCP client.\n\nHere are some examples of what gets cached:\n\n### 1. File Content Caching\nWhen reading a file multiple times:\n- First time: Full file content is read and cached\n- Subsequent times: Content is retrieved from cache instead of re-reading the file\n- Result: Fewer tokens used for repeated file operations\n\n### 2. Computation Results\nWhen performing calculations or analysis:\n- First time: Full computation is performed and results are cached\n- Subsequent times: Results are retrieved from cache if the input is the same\n- Result: Fewer tokens used for repeated computations\n\n### 3. Frequently Accessed Data\nWhen the same data is needed multiple times:\n- First time: Data is processed and cached\n- Subsequent times: Data is retrieved from cache until TTL expires\n- Result: Fewer tokens used for accessing the same information\n\n## Automatic Cache Management\n\nThe server automatically manages the caching process by:\n- Storing data when first encountered\n- Serving cached data when available\n- Removing old/unused data based on settings\n- Tracking effectiveness through statistics\n\n## Optimization Tips\n\n### 1. Set Appropriate TTLs\n- Shorter for frequently changing data\n- Longer for static content\n\n### 2. Adjust Memory Limits\n- Higher for more caching (more token savings)\n- Lower if memory usage is a concern\n\n### 3. Monitor Cache Stats\n- High hit rate = good token savings\n- Low hit rate = adjust TTL or limits\n\n## Environment Variable Configuration\n\nYou can override config.json settings using environment variables in your MCP settings:\n\n```json\n{\n  \"mcpServers\": {\n    \"memory-cache\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/build/index.js\"],\n      \"env\": {\n        \"MAX_ENTRIES\": \"5000\",\n        \"MAX_MEMORY\": \"209715200\",  // 200MB\n        \"DEFAULT_TTL\": \"7200\",      // 2 hours\n        \"CHECK_INTERVAL\": \"120000\",  // 2 minutes\n        \"STATS_INTERVAL\": \"60000\"    // 1 minute\n      }\n    }\n  }\n}\n```\n\nYou can also specify a custom config file location:\n```json\n{\n  \"env\": {\n    \"CONFIG_PATH\": \"/path/to/your/config.json\"\n  }\n}\n```\n\nThe server will:\n1. Look for config.json in its directory\n2. Apply any environment variable overrides\n3. Use default values if neither is specified\n\n## Testing the Cache in Practice\n\nTo see the cache in action, try these scenarios:\n\n1. **File Reading Test**\n   - Read and analyze a large file\n   - Ask the same question about the file again\n   - The second response should be faster as the file content is cached\n\n2. **Data Analysis Test**\n   - Perform analysis on some data\n   - Request the same analysis again\n   - The second analysis should use cached results\n\n3. **Project Navigation Test**\n   - Explore a project's structure\n   - Query the same files/directories again\n   - Directory listings and file contents will be served from cache\n\nThe cache is working when you notice:\n- Faster responses for repeated operations\n- Consistent answers about unchanged content\n- No need to re-read files that haven't changed\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ibproduct",
        "ib",
        "cache",
        "mcp cache",
        "ibproduct ib",
        "management ibproduct"
      ],
      "category": "memory-management"
    },
    "identimoji--mcp-server-emojikey": {
      "owner": "identimoji",
      "name": "mcp-server-emojikey",
      "url": "https://github.com/identimoji/mcp-server-emojikey",
      "imageUrl": "/freedevtools/mcp/pfp/identimoji.webp",
      "description": "Manages and persists interaction styles for language models using emoji-based memory keys. Supports setting, retrieving, and maintaining conversation contexts across devices and applications while tracking history.",
      "stars": 4,
      "forks": 5,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-23T08:09:13Z",
      "readme_content": "# mcp-server-emojikey\n\n[![smithery badge](https://smithery.ai/badge/@identimoji/mcp-server-emojikey)](https://smithery.ai/server/@identimoji/mcp-server-emojikey)\n\nMCP server for persisting LLM relationship context as emoji-based memory keys. This allows Claude to maintain consistent interaction styles and remember relationship context across conversations.\n\nEmojikeys are stored online, so you can use them across devices and applications. No user information is stored other than the emojikeys.\n\n## Building and Running\n\nThere are multiple ways to build and run the server:\n\n### Quick Start (Recommended)\n\n```bash\n# Install dependencies\nnpm install\n\n# Build the project (all TypeScript errors fixed)\nnpm run build\n\n# Run the server (coding features disabled by default)\nnpm run start\n\n# Optional: Run with coding features enabled\nCODE_MODE=true npm run start\n```\n\n### Alternative Build Options\n\nFor more build options, see [BUILD_OPTIONS.md](BUILD_OPTIONS.md) which includes:\n\n1. Standard Build with Coding Features Disabled (recommended)\n2. Full Build with All Features (if you need coding dimensions)\n3. Simplified Build without Coding Files (alternative stable option)\n\n<a href=\"https://glama.ai/mcp/servers/e042rg25ct\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/e042rg25ct/badge\" alt=\"emojikey-server Server MCP server\" />\n</a>\n\n> 📝 **Note**\n> Usage note: The first time you use the tool in Claude desktop, tell Claude to \"Set emojikey\" then next time you start a conversation, he will automatically use this key. You can ask to set vibe, or show emojikey history as well. Have fun!\n\n> ⚠️ **Warning**\n> This is a beta version, more features are planned, so the API may change.\n\n## Usage with Claude Desktop\n\nGet your API key from [emojikey.io](https://emojikey.io) and add this to your config:\n\n```json\n{\n  \"mcpServers\": {\n    \"emojikey\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@identimoji/mcp-server-emojikey\"],\n      \"env\": {\n        \"EMOJIKEYIO_API_KEY\": \"your-api-key-from-emojikey.io\",\n        \"MODEL_ID\": \"Claude-3-7-Sonnet\",\n        \"CODE_MODE\": \"false\" // Set to \"true\" to enable coding features\n      }\n    }\n  }\n}\n```\n\nNote: The `-y` flag in the `args` array tells npx to skip confirmation prompts when installing packages.\n\nConfig locations:\n- MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n- Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\nFirst-time usage: Tell Claude to \"Set emojikey\". On subsequent conversations, Claude will automatically use this key to maintain context.\n\n### Emojikey Initialization Display\n\nWhen initializing a conversation, the server now displays:\n\n1. **Starting Key** - The most recent key or baseline key if no history exists\n2. **Aggregated Keys** - Time-based summaries of your emojikey history:\n   - **Lifetime** - Aggregated key from all your previous conversations\n   - **90-day** - Aggregated key from the past 90 days (if available)\n   - **30-day** - Aggregated key from the past 30 days (if available)\n   - **7-day** - Aggregated key from the past 7 days (if available)\n   - **24-hour** - Aggregated key from the past 24 hours (if available)\n3. **Conversation ID** - Used for tracking keys within each conversation\n\n## Environment Variables\n\nYou can customize the behavior with these environment variables:\n\n- `EMOJIKEYIO_API_KEY` - Your API key from emojikey.io\n- `MODEL_ID` - The Claude model ID (e.g., \"Claude-3-7-Sonnet\")\n- `CODE_MODE` - Set to \"true\" to enable coding dimensions (disabled by default, may show safe-to-ignore integration warnings)\n- `SUPABASE_URL` - Custom Supabase URL (optional)\n- `SUPABASE_ANON_KEY` - Custom Supabase anonymous key (optional)\n\n## Tools\n\n- `initialize_conversation` - Get current emojikey at start of conversation\n- `get_emojikey` - Retrieve current emojikey when requested\n- `set_emojikey` - Create and store a new emojikey\n- `create_superkey` - Create a compressed superkey (after 10 regular emojikeys)\n- `get_emojikey_history` - View previous emojikeys\n\n## New in v0.3.1: Coding Context Support\n\nThis version includes special dimensions for tracking programming-related interaction patterns:\n\n- 💻🔧 (ImplementationFocus) - Balance between high-level design and implementation details\n- 🏗️🔍 (CodeScope) - Building new features vs. improving existing code\n- 🧩🧠 (ProblemSolving) - Practical vs. analytical approaches to coding problems\n- 🔄📊 (ProcessVsResults) - Emphasizing coding process vs. outcomes\n- 📚🧪 (LearnVsApply) - Teaching programming concepts vs. applying them\n- 🚀🛡️ (SpeedVsSecurity) - Development speed vs. security considerations\n- 👥💻 (CollaborationStyle) - Solo coding vs. collaborative approaches\n- 🧬🎨 (CodeStructuring) - Systematic vs. creative code organization\n- 📦🔧 (AbstractionLevel) - Preference for abstraction vs. concrete implementations\n- 🐞📚 (DebugApproach) - Practical vs. theoretical debugging approaches\n\nThese dimensions help Claude adapt to your programming style, providing the right balance of theoretical explanations and practical guidance.\n\n### Example Coding Emojikey\n\n```\n[ME|💻🔧8∠45|🧩🧠7∠60|🐞📚6∠40]~[CONTENT|🏗️🔍9∠30|📚🧪8∠65]~[YOU|👥💻7∠70|🧬🎨8∠55]\n```\n\nThis shows Claude positioning itself with a balanced implementation focus and somewhat analytical problem-solving approach, while perceiving the user as preferring collaborative coding with creative structuring.\n\n## Angle Distribution and Dimension Balance\n\nEmojikey angles represent positioning on each dimension:\n- 0° represents one extreme of a dimension\n- 90° represents a balanced center position\n- 180° represents the opposite extreme\n\nThe current implementation assigns angles primarily in the 0-90° range. Future updates will improve angle distribution to better utilize the full 0-180° spectrum, providing more nuanced dimension positioning.\n\n## Superkeys\n\nAfter creating 10 regular emojikeys, Claude will be prompted to create a superkey that compresses their meaning into a single key with format: `[[×10emoji-sequence]]`\n\nThis allows Claude to maintain a longer conversation history context.\n\n> ⚠️ This is a beta version; the API may change in future updates.\n",
      "npm_url": "https://www.npmjs.com/package/@identimoji/mcp-server-emojikey",
      "npm_downloads": 3370,
      "keywords": [
        "emoji",
        "emojikey",
        "memory",
        "server emojikey",
        "using emoji",
        "emojikey manages"
      ],
      "category": "memory-management"
    },
    "ipospelov--mcp-memory-bank": {
      "owner": "ipospelov",
      "name": "mcp-memory-bank",
      "url": "https://github.com/ipospelov/mcp-memory-bank",
      "imageUrl": "/freedevtools/mcp/pfp/ipospelov.webp",
      "description": "Facilitates the setup and management of a structured Memory Bank for context preservation in AI assistant environments, offering detailed guidance on file structures, template generation, and project summary analysis. Enhances AI context management through organized documentation and relevant content suggestions.",
      "stars": 72,
      "forks": 13,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-30T23:15:52Z",
      "readme_content": "# Memory Bank MCP Server\n\nThis MCP server helps to build structured documentation system based on [Cline's Memory Bank pattern](https://docs.cline.bot/improving-your-prompting-skills/cline-memory-bank) for context preservation in AI assistant environments. \n\nPowered by [Enlighter](https://enlightby.ai) and [Hyperskill](https://hyperskill.org).\n\nLearn how to setup and use Memory Bank directly in Cursor: http://enlightby.ai/projects/37\n\n[![smithery badge](https://smithery.ai/badge/@ipospelov/mcp-memory-bank)](https://smithery.ai/server/@ipospelov/mcp-memory-bank)\n\n<a href=\"https://glama.ai/mcp/servers/@ipospelov/mcp-memory-bank\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@ipospelov/mcp-memory-bank/badge\" alt=\"Memory Bank Server MCP server\" />\n</a>\n\n## Features\n\n- Get detailed information about Memory Bank structure\n- Generate templates for Memory Bank files\n- Analyze project and provide suggestions for Memory Bank content\n\n## Running the Server\n\nThere are a few options to use this MCP server:\n\n### With UVX\n\nAdd this to your mcp.json config file:\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-memory-bank\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"--from\",\n        \"git+https://github.com/ipospelov/mcp-memory-bank\",\n        \"mcp_memory_bank\"\n      ]\n    }\n  }\n}\n```\n\n### With [Smithery](https://smithery.ai/server/@ipospelov/mcp-memory-bank)\n\nAdd this to your mcp.json config file:\n\n```json\n{\n  \"mcpServers\": {\n    \"memory-bank\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@smithery/cli@latest\",\n        \"run\",\n        \"@ipospelov/mcp-memory-bank\",\n        \"--key\",\n        \"your_smithery_key\"\n      ]\n    }\n  }\n}\n```\n\n### With Docker\n\nAdd this to your mcp.json config file:\n\n```json\n{\n  \"mcpServers\": {\n    \"memory-bank\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"19283744/mcp-memory-bank:latest\"\n      ]\n    }\n  }\n}\n```\n\n### Manually\n\nClone repository and run the following commands:\n\n```bash\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\npip install -r requirements.txt\n```\n\nThen add this to your mcp.json config file:\n\n```json\n{\n  \"mcpServers\": {\n    \"memory-bank\": {\n      \"command\": \"python\",\n      \"args\": [\"src/mcp_memory_bank/main.py\"]\n    }\n  }\n}\n```\n\n## Usage Example\n\nAsk Cursor or any other AI code assistant with Memory Bank MCP:\n```\nCreate memory bank for To Do list application with your tools\n```\nProvide more context to get better results.\n\n## Available Tools\n\n### get_memory_bank_structure\n\nReturns a detailed description of the Memory Bank file structure.\n\n### generate_memory_bank_template\n\nReturns a template for a specific Memory Bank file.\n\nExample:\n```json\n{\n  \"file_name\": \"projectbrief.md\"\n}\n```\n\n### analyze_project_summary\n\nAnalyzes a project summary and provides suggestions for Memory Bank content.\n\nExample:\n```json\n{\n  \"project_summary\": \"Building a React web app for inventory management with barcode scanning\"\n}\n```\n\n## Memory Bank Structure\n\nThe Memory Bank consists of core files and optional context files, all in Markdown format:\n\n### Core Files (Required)\n\n1. `projectbrief.md` - Foundation document that shapes all other files\n2. `productContext.md` - Explains why the project exists, problems being solved\n3. `activeContext.md` - Current work focus, recent changes, next steps\n4. `systemPatterns.md` - System architecture, technical decisions, design patterns\n5. `techContext.md` - Technologies used, development setup, constraints\n6. `progress.md` - What works, what's left to build\n7. `memory_bank_instructions.md` - How to work with Memory Bank, instructtions for AI-agent",
      "npm_url": "https://www.npmjs.com/package/mcp-memory-bank",
      "npm_downloads": 360,
      "keywords": [
        "memory",
        "ai",
        "structured",
        "memory bank",
        "memory management",
        "structured memory"
      ],
      "category": "memory-management"
    },
    "itseasy21--mcp-knowledge-graph": {
      "owner": "itseasy21",
      "name": "mcp-knowledge-graph",
      "url": "https://github.com/itseasy21/mcp-knowledge-graph",
      "imageUrl": "/freedevtools/mcp/pfp/itseasy21.webp",
      "description": "Enables AI tools to retain and utilize user-specific information across multiple conversations by leveraging a local knowledge graph for persistent memory management.",
      "stars": 54,
      "forks": 14,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-15T14:36:59Z",
      "readme_content": "# Knowledge Graph Memory Server\n\n[![smithery badge](https://smithery.ai/badge/@itseasy21/mcp-knowledge-graph)](https://smithery.ai/server/@itseasy21/mcp-knowledge-graph)\n\nAn improved implementation of persistent memory using a local knowledge graph with a customizable memory path.\n\nThis lets Claude remember information about the user across chats.\n\n<a href=\"https://glama.ai/mcp/servers/@itseasy21/mcp-knowledge-graph\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@itseasy21/mcp-knowledge-graph/badge\" alt=\"Knowledge Graph Memory Server MCP server\" />\n</a>\n\n> [!NOTE]\n> This is a fork of the original [Memory Server](https://github.com/modelcontextprotocol/servers/tree/main/src/memory) and is intended to not use the ephemeral memory npx installation method.\n\n## Server Name\n\n```txt\nmcp-knowledge-graph\n```\n\n\n\n\n\n## Core Concepts\n\n### Entities\n\nEntities are the primary nodes in the knowledge graph. Each entity has:\n\n- A unique name (identifier)\n- An entity type (e.g., \"person\", \"organization\", \"event\")\n- A list of observations\n- Creation date and version tracking\n\nThe version tracking feature helps maintain a historical context of how knowledge evolves over time.\n\nExample:\n\n```json\n{\n  \"name\": \"John_Smith\",\n  \"entityType\": \"person\",\n  \"observations\": [\"Speaks fluent Spanish\"]\n}\n```\n\n### Relations\n\nRelations define directed connections between entities. They are always stored in active voice and describe how entities interact or relate to each other. Each relation includes:\n\n- Source and target entities\n- Relationship type\n- Creation date and version information\n\nThis versioning system helps track how relationships between entities evolve over time.\n\nExample:\n\n```json\n{\n  \"from\": \"John_Smith\",\n  \"to\": \"Anthropic\",\n  \"relationType\": \"works_at\"\n}\n```\n\n### Observations\n\nObservations are discrete pieces of information about an entity. They are:\n\n- Stored as strings\n- Attached to specific entities\n- Can be added or removed independently\n- Should be atomic (one fact per observation)\n\nExample:\n\n```json\n{\n  \"entityName\": \"John_Smith\",\n  \"observations\": [\n    \"Speaks fluent Spanish\",\n    \"Graduated in 2019\",\n    \"Prefers morning meetings\"\n  ]\n}\n```\n\n## API\n\n### Tools\n\n- **create_entities**\n  - Create multiple new entities in the knowledge graph\n  - Input: `entities` (array of objects)\n    - Each object contains:\n      - `name` (string): Entity identifier\n      - `entityType` (string): Type classification\n      - `observations` (string[]): Associated observations\n  - Ignores entities with existing names\n\n- **create_relations**\n  - Create multiple new relations between entities\n  - Input: `relations` (array of objects)\n    - Each object contains:\n      - `from` (string): Source entity name\n      - `to` (string): Target entity name\n      - `relationType` (string): Relationship type in active voice\n  - Skips duplicate relations\n\n- **add_observations**\n  - Add new observations to existing entities\n  - Input: `observations` (array of objects)\n    - Each object contains:\n      - `entityName` (string): Target entity\n      - `contents` (string[]): New observations to add\n  - Returns added observations per entity\n  - Fails if entity doesn't exist\n\n- **delete_entities**\n  - Remove entities and their relations\n  - Input: `entityNames` (string[])\n  - Cascading deletion of associated relations\n  - Silent operation if entity doesn't exist\n\n- **delete_observations**\n  - Remove specific observations from entities\n  - Input: `deletions` (array of objects)\n    - Each object contains:\n      - `entityName` (string): Target entity\n      - `observations` (string[]): Observations to remove\n  - Silent operation if observation doesn't exist\n\n- **delete_relations**\n  - Remove specific relations from the graph\n  - Input: `relations` (array of objects)\n    - Each object contains:\n      - `from` (string): Source entity name\n      - `to` (string): Target entity name\n      - `relationType` (string): Relationship type\n  - Silent operation if relation doesn't exist\n\n- **read_graph**\n  - Read the entire knowledge graph\n  - No input required\n  - Returns complete graph structure with all entities and relations\n\n- **search_nodes**\n  - Search for nodes based on query\n  - Input: `query` (string)\n  - Searches across:\n    - Entity names\n    - Entity types\n    - Observation content\n  - Returns matching entities and their relations\n\n- **open_nodes**\n  - Retrieve specific nodes by name\n  - Input: `names` (string[])\n  - Returns:\n    - Requested entities\n    - Relations between requested entities\n  - Silently skips non-existent nodes\n\n## Usage with Cursor, Cline or Claude Desktop\n\n### Setup\n\nAdd this to your mcp.json or claude_desktop_config.json:\n\n```json\n{\n    \"mcpServers\": {\n      \"memory\": {\n        \"command\": \"npx\",\n        \"args\": [\n          \"-y\",\n          \"@itseasy21/mcp-knowledge-graph\"\n        ],\n        \"env\": {\n          \"MEMORY_FILE_PATH\": \"/path/to/your/projects.jsonl\"\n        }\n      }\n    }\n  }\n```\n\n### Installing via Smithery\n\nTo install Knowledge Graph Memory Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@itseasy21/mcp-knowledge-graph):\n\n```bash\nnpx -y @smithery/cli install @itseasy21/mcp-knowledge-graph --client claude\n```\n\n### Custom Memory Path\n\nYou can specify a custom path for the memory file in two ways:\n\n1. Using command-line arguments:\n```json\n{\n  \"mcpServers\": {\n    \"memory\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@itseasy21/mcp-knowledge-graph\", \"--memory-path\", \"/path/to/your/memory.jsonl\"]\n    }\n  }\n}\n```\n\n2. Using environment variables:\n```json\n{\n  \"mcpServers\": {\n    \"memory\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@itseasy21/mcp-knowledge-graph\"],\n      \"env\": {\n        \"MEMORY_FILE_PATH\": \"/path/to/your/memory.jsonl\"\n      }\n    }\n  }\n}\n```\n\nIf no path is specified, it will default to memory.jsonl in the server's installation directory.\n\n### System Prompt\n\nThe prompt for utilizing memory depends on the use case. Changing the prompt will help the model determine the frequency and types of memories created.\n\nHere is an example prompt for chat personalization. You could use this prompt in the \"Custom Instructions\" field of a [Claude.ai Project](https://www.anthropic.com/news/projects).\n\n```txt\nFollow these steps for each interaction:\n\n1. User Identification:\n   - You should assume that you are interacting with default_user\n   - If you have not identified default_user, proactively try to do so.\n\n2. Memory Retrieval:\n   - Always begin your chat by saying only \"Remembering...\" and retrieve all relevant information from your knowledge graph\n   - Always refer to your knowledge graph as your \"memory\"\n\n3. Memory\n   - While conversing with the user, be attentive to any new information that falls into these categories:\n     a) Basic Identity (age, gender, location, job title, education level, etc.)\n     b) Behaviors (interests, habits, etc.)\n     c) Preferences (communication style, preferred language, etc.)\n     d) Goals (goals, targets, aspirations, etc.)\n     e) Relationships (personal and professional relationships up to 3 degrees of separation)\n\n4. Memory Update:\n   - If any new information was gathered during the interaction, update your memory as follows:\n     a) Create entities for recurring organizations, people, and significant events\n     b) Connect them to the current entities using relations\n     b) Store facts about them as observations\n```\n\n## License\n\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.",
      "npm_url": "https://www.npmjs.com/package/mcp-knowledge-graph",
      "npm_downloads": 9675,
      "keywords": [
        "memory",
        "knowledge",
        "conversations",
        "persistent memory",
        "knowledge graph",
        "conversations leveraging"
      ],
      "category": "memory-management"
    },
    "j3k0--mcp-brain-tools": {
      "owner": "j3k0",
      "name": "mcp-brain-tools",
      "url": "https://github.com/j3k0/mcp-brain-tools",
      "imageUrl": "/freedevtools/mcp/pfp/j3k0.webp",
      "description": "Utilizes a scalable knowledge graph built on Elasticsearch to manage and query large datasets, providing persistent memory for AI systems. Supports complete CRUD operations and offers advanced search capabilities for improved data handling in Model Context Protocol applications.",
      "stars": 16,
      "forks": 5,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-09-28T07:07:56Z",
      "readme_content": "# MCP Memory: Persistent Memory for AI Conversations 🧠\n\n![Version](https://img.shields.io/badge/version-1.0.0-blue)\n![License](https://img.shields.io/badge/license-MIT-green)\n![Elasticsearch](https://img.shields.io/badge/Elasticsearch-7.x-yellow)\n![Node](https://img.shields.io/badge/node-18+-green)\n\n> **Give your AI a memory that persists across conversations.** Never lose important context again.\n\nMCP Memory is a robust, Elasticsearch-backed knowledge graph system that gives AI models persistent memory beyond the limits of their context windows. Built for the Model Context Protocol (MCP), it ensures your LLMs remember important information forever, creating more coherent, personalized, and effective AI conversations.\n\n<p align=\"center\">\n  <img src=\"https://via.placeholder.com/800x400?text=MCP+Memory+Visualization\" alt=\"MCP Memory Visualization\" width=\"600\">\n</p>\n\n## 🌟 Why AI Models Need Persistent Memory\n\nEver experienced these frustrations with AI assistants?\n\n- Your AI forgetting crucial details from earlier conversations\n- Having to repeat the same context every time you start a new chat\n- Losing valuable insights once the conversation history fills up\n- Inability to reference past work or decisions\n\nMCP Memory solves these problems by creating a structured, searchable memory store that preserves context indefinitely. Your AI can now build meaningful, long-term relationships with users and maintain coherence across days, weeks, or months of interactions.\n\n## ✨ Key Features\n\n- **📊 Persistent Memory**: Store and retrieve information across multiple sessions\n- **🔍 Smart Search**: Find exactly what you need with powerful Elasticsearch queries\n- **📓 Contextual Recall**: AI automatically prioritizes relevant information based on the conversation\n- **🧩 Relational Understanding**: Connect concepts with relationships that mimic human associative memory\n- **🔄 Long-term / Short-term Memory**: Distinguish between temporary details and important knowledge\n- **🗂️ Memory Zones**: Organize information into separate domains (projects, clients, topics)\n- **🔒 Reliable & Scalable**: Built on Elasticsearch for enterprise-grade performance\n\n## 🚀 5-Minute Setup\n\nGetting started is incredibly simple:\n\n### Prerequisites\n\n- **Docker**: Required for running Elasticsearch (or a local Elasticsearch installation)\n- **Node.js**: Version 18 or higher\n- **npm**: For package management\n\n```bash\n# 1. Clone the repository\ngit clone https://github.com/mcp-servers/mcp-servers.git\ncd mcp-servers/memory\n\n# 2. Install dependencies\nnpm install\n\n# 3. Start Elasticsearch (uses Docker)\nnpm run es:start\n# Note: If you prefer to use your own Elasticsearch installation,\n# set the ES_NODE environment variable to point to your Elasticsearch instance\n\n# 4. Build the project\nnpm run build\n```\n\n### 🔌 Connecting to Claude Desktop\n\nMCP Memory is designed to work seamlessly with Claude Desktop, giving Claude persistent memory across all your conversations:\n\n1. **Copy and configure the launch script**:\n   \n   The repository includes a `launch.example` file that you can simply copy:\n   \n   ```bash\n   # Copy the example launch file\n   cp launch.example launch.sh\n   \n   # Edit launch.sh to add your Groq API key\n   # This is required for smart memory retrieval\n   nano launch.sh  # or use your preferred editor\n   ```\n   \n   Make the script executable:\n   ```bash\n   chmod +x launch.sh\n   ```\n\n2. **Add the command to Claude Desktop**:\n   - Open Claude Desktop Settings\n   - Navigate to the \"Commands\" section\n   - Click \"Add New Command\"\n   - Configure as follows:\n     - **Name**: MCP Memory\n     - **Command**: /path/to/mcp-servers/memory/launch.sh\n     - **Arguments**: Leave empty\n     - **Run in background**: Yes\n     - **Show in menu**: Yes\n\n3. **Verify connection**:\n   - Start the command from Claude Desktop\n   - You should see a notification that Claude is connected to MCP Memory\n   - Try asking Claude about something you discussed in a previous conversation!\n\nFor complete examples and visual guides, see the [Claude Desktop MCP Server Setup Guide](https://github.com/anthropic-claude/claude-desktop-mcp-examples) online.\n\n## 💡 How It Works\n\nMCP Memory creates a structured knowledge graph where:\n\n1. **Entities** represent people, concepts, projects, or anything worth remembering\n2. **Relations** connect entities, creating a network of associations\n3. **Observations** capture specific details about entities\n4. **Relevance scoring** determines what information to prioritize\n\nWhen integrated with an LLM, the system automatically:\n- Stores new information learned during conversations\n- Retrieves relevant context when needed\n- Builds connections between related concepts\n- Forgets unimportant details while preserving critical knowledge\n\n## 🛠️ Example: How Agents Use Memory\n\n### From the User's Perspective\n\n**Conversation 1: Initial Information**\n\n```\nUser: My daughter's name is Emma and she's turning 8 next month.\n\nClaude: That's wonderful! Emma will be turning 8 next month. Is there anything special you're planning for her birthday?\n(Behind the scenes: Claude stores \"Emma\" as an entity of type \"Person\" with observations about her age and birthday timing)\n```\n\n**Conversation 2: Days or Weeks Later**\n\n```\nUser: I'm thinking about what to get for a gift.\n\nClaude: If you're looking for gift ideas for Emma's 8th birthday coming up, have you considered what her current interests are? At that age, many children enjoy creative items, books, or educational games.\n(Behind the scenes: Claude retrieved the entity \"Emma\", her age, and the fact that her birthday is approaching)\n```\n\n**Conversation 3: After the Birthday**\n\n```\nUser: The party went really well on Saturday!\n\nClaude: I'm glad Emma's 8th birthday party was a success on Saturday! Did she enjoy the gifts she received?\n(Behind the scenes: Claude updates the observations about Emma, noting that her birthday party occurred on a Saturday and went well)\n```\n\n### How the Agent Uses Memory\n\nWhen the user mentions something important, the agent:\n\n1. **Recognizes important information** worth remembering\n2. **Stores it in memory** by creating entities, relations, and observations\n3. **Updates existing information** when new details emerge\n\nWhen the user mentions something related to stored information, the agent:\n\n1. **Searches memory** for relevant context based on the current conversation\n2. **Retrieves important details** that might be helpful\n3. **Incorporates this information** naturally into its responses\n\nThis happens automatically - the user simply has a normal conversation with the assistant, and the memory system works behind the scenes to maintain context across sessions.\n\n### Intelligent Entity Management\n\nMCP Memory includes smart handling of entity creation and updates:\n\n- When attempting to create an entity that already exists, the system returns the existing entity data with guidance on how to extend it with new information\n- The system intelligently differentiates between creating new entities and updating existing ones\n- Entity relationships are automatically maintained even when information is updated\n\n## 🧰 Admin Tools\n\nMCP Memory includes a comprehensive admin CLI for maintaining your knowledge graph:\n\n```bash\n# Search the memory\nnode dist/admin-cli.js search \"Emma birthday\"\n\n# View details about a specific entity\nnode dist/admin-cli.js entity \"Emma\"\n\n# Back up your entire memory system\nnode dist/admin-cli.js backup memory-backup.json\n```\n\n## 📚 Advanced Features\n\n### Memory Zones\n\nOrganize knowledge into separate domains:\n\n```bash\n# Create a project-specific memory zone\nnode dist/admin-cli.js zones add client-acme \"ACME Corp Project Knowledge\"\n\n# Import data into that zone\nnode dist/admin-cli.js import acme-data.json client-acme\n```\n\n### Conversational Memory Management\n\nYou can also instruct the assistant to organize memories in different zones through natural conversation:\n\n**Creating and Using Memory Zones**\n\n```\nUser: Claude, can you create a new memory zone called \"work-project\" for storing information about my current work project?\n\nClaude: I've created a new memory zone called \"work-project\". I'll store information related to your work project in this zone. What would you like me to remember about your project?\n\nUser: The project deadline is March 15th, and we're building a new inventory management system.\n\nClaude: I've stored information about your work project in the \"work-project\" zone, including the March 15th deadline and that you're building an inventory management system. I'll keep future information about this project organized in this zone.\n(Behind the scenes: Claude creates a new memory zone and stores project information specifically in that zone)\n```\n\n**Retrieving Zone-Specific Information**\n\n```\nUser: What do you remember about my work project?\n\nClaude: Based on what we've discussed about your work project, I recall that you're building an inventory management system with a deadline of March 15th.\n(Behind the scenes: Claude specifically searches the \"work-project\" zone for relevant information)\n```\n\n**Switching Between Memory Zones**\n\n```\nUser: Claude, let's switch to my \"cooking\" memory zone now. I want to discuss a recipe.\n\nClaude: I've switched to your \"cooking\" memory zone. What recipe would you like to discuss today?\n(Behind the scenes: Claude updates its memory context to prioritize searching in the \"cooking\" zone)\n\nUser: What was that pasta dish I told you about last month?\n\nClaude: From our previous conversations in your cooking zone, you shared a carbonara recipe that used pancetta, eggs, pecorino cheese, and black pepper. You mentioned it was a family favorite that you learned during your trip to Rome.\n(Behind the scenes: Claude searches specifically in the \"cooking\" zone to find this information)\n```\n\nBy organizing memory into separate zones, conversations become more relevant and focused on the current topic or project.\n\n### Search Capabilities\n\nLeverage Elasticsearch's powerful search features:\n\n```bash\n# Fuzzy search (finds \"meeting\" even with typo)\nnode dist/admin-cli.js search \"meteing notes\"\n\n# Zone-specific search\nnode dist/admin-cli.js search \"budget\" client-acme\n```\n\n## 🤝 Contributing\n\nContributions are welcome! See [CONTRIBUTING.md](CONTRIBUTING.md) for details.\n\n## 📝 License\n\nMIT\n\n---\n\n<p align=\"center\">\n  <b>Ready to give your AI a memory that lasts? Get started in 5 minutes!</b><br>\n  <a href=\"https://github.com/mcp-servers/mcp-servers\">GitHub</a> •\n  <a href=\"https://discord.gg/mcp-community\">Discord</a> •\n  <a href=\"https://mcp-servers.readthedocs.io\">Documentation</a>\n</p>\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "elasticsearch",
        "memory",
        "search",
        "memory ai",
        "built elasticsearch",
        "elasticsearch manage"
      ],
      "category": "memory-management"
    },
    "jasonmorganson--servers": {
      "owner": "jasonmorganson",
      "name": "servers",
      "url": "https://github.com/jasonmorganson/servers",
      "imageUrl": "/freedevtools/mcp/pfp/jasonmorganson.webp",
      "description": "Utilizes a local knowledge graph for the creation, management, and retrieval of entities and their relationships, enabling users to maintain context and continuity in conversations across chats.",
      "stars": 1,
      "forks": 0,
      "license": "MIT License",
      "language": "",
      "updated_at": "2025-09-05T13:11:57Z",
      "readme_content": "# Model Context Protocol servers\n\nThis repository is a collection of *reference implementations* for the [Model Context Protocol](https://modelcontextprotocol.io/) (MCP), as well as references\nto community built servers and additional resources.\n\nThe servers in this repository showcase the versatility and extensibility of MCP, demonstrating how it can be used to give Large Language Models (LLMs) secure, controlled access to tools and data sources.\nEach MCP server is implemented with either the [Typescript MCP SDK](https://github.com/modelcontextprotocol/typescript-sdk) or [Python MCP SDK](https://github.com/modelcontextprotocol/python-sdk).\n\n> Note: Lists in this README are maintained in alphabetical order to minimize merge conflicts when adding new items.\n\n## 🌟 Reference Servers\n\nThese servers aim to demonstrate MCP features and the TypeScript and Python SDKs.\n\n- **[AWS KB Retrieval](src/aws-kb-retrieval-server)** - Retrieval from AWS Knowledge Base using Bedrock Agent Runtime\n- **[Brave Search](src/brave-search)** - Web and local search using Brave's Search API\n- **[EverArt](src/everart)** - AI image generation using various models\n- **[Everything](src/everything)** - Reference / test server with prompts, resources, and tools\n- **[Fetch](src/fetch)** - Web content fetching and conversion for efficient LLM usage\n- **[Filesystem](src/filesystem)** - Secure file operations with configurable access controls\n- **[Git](src/git)** - Tools to read, search, and manipulate Git repositories\n- **[GitHub](src/github)** - Repository management, file operations, and GitHub API integration\n- **[GitLab](src/gitlab)** - GitLab API, enabling project management\n- **[Google Drive](src/gdrive)** - File access and search capabilities for Google Drive\n- **[Google Maps](src/google-maps)** - Location services, directions, and place details\n- **[Memory](src/memory)** - Knowledge graph-based persistent memory system\n- **[PostgreSQL](src/postgres)** - Read-only database access with schema inspection\n- **[Puppeteer](src/puppeteer)** - Browser automation and web scraping\n- **[Redis](src/redis)** - Interact with Redis key-value stores\n- **[Sentry](src/sentry)** - Retrieving and analyzing issues from Sentry.io\n- **[Sequential Thinking](src/sequentialthinking)** - Dynamic and reflective problem-solving through thought sequences\n- **[Slack](src/slack)** - Channel management and messaging capabilities\n- **[Sqlite](src/sqlite)** - Database interaction and business intelligence capabilities\n- **[Time](src/time)** - Time and timezone conversion capabilities\n\n## 🤝 Third-Party Servers\n\n### 🎖️ Official Integrations\n\nOfficial integrations are maintained by companies building production ready MCP servers for their platforms.\n\n- <img height=\"12\" width=\"12\" src=\"https://www.21st.dev/favicon.ico\" alt=\"21st.dev Logo\" /> **[21st.dev Magic](https://github.com/21st-dev/magic-mcp)** - Create crafted UI components inspired by the best 21st.dev design engineers.\n- <img height=\"12\" width=\"12\" src=\"https://invoxx-public-bucket.s3.eu-central-1.amazonaws.com/frontend-resources/adfin-logo-small.svg\" alt=\"Adfin Logo\" /> **[Adfin](https://github.com/Adfin-Engineering/mcp-server-adfin)** - The only platform you need to get paid - all payments in one place, invoicing and accounting reconciliations with [Adfin](https://www.adfin.com/).\n- <img height=\"12\" width=\"12\" src=\"https://www.agentql.com/favicon/favicon.png\" alt=\"AgentQL Logo\" /> **[AgentQL](https://github.com/tinyfish-io/agentql-mcp)** - Enable AI agents to get structured data from unstructured web with [AgentQL](https://www.agentql.com/).\n- <img height=\"12\" width=\"12\" src=\"https://agentrpc.com/favicon.ico\" alt=\"AgentRPC Logo\" /> **[AgentRPC](https://github.com/agentrpc/agentrpc)** - Connect to any function, any language, across network boundaries using [AgentRPC](https://www.agentrpc.com/).\n- <img height=\"12\" width=\"12\" src=\"https://aiven.io/favicon.ico\" alt=\"Aiven Logo\" /> **[Aiven](https://github.com/Aiven-Open/mcp-aiven)** - Navigate your [Aiven projects](https://go.aiven.io/mcp-server) and interact with the PostgreSQL®, Apache Kafka®, ClickHouse® and OpenSearch® services\n- <img height=\"12\" width=\"12\" src=\"https://iotdb.apache.org/img/logo.svg\" alt=\"Apache IoTDB Logo\" /> **[Apache IoTDB](https://github.com/apache/iotdb-mcp-server)** - MCP Server for [Apache IoTDB](https://github.com/apache/iotdb) database and its tools\n- <img height=\"12\" width=\"12\" src=\"https://apify.com/favicon.ico\" alt=\"Apify Logo\" /> **[Apify](https://github.com/apify/actors-mcp-server)** - [Actors MCP Server](https://apify.com/apify/actors-mcp-server): Use 3,000+ pre-built cloud tools to extract data from websites, e-commerce, social media, search engines, maps, and more\n- <img height=\"12\" width=\"12\" src=\"https://2052727.fs1.hubspotusercontent-na1.net/hubfs/2052727/cropped-cropped-apimaticio-favicon-1-32x32.png\" alt=\"APIMatic Logo\" /> **[APIMatic MCP](https://github.com/apimatic/apimatic-validator-mcp)** - APIMatic MCP Server is used to validate OpenAPI specifications using [APIMatic](https://www.apimatic.io/). The server processes OpenAPI files and returns validation summaries by leveraging APIMatic’s API.\n- <img height=\"12\" width=\"12\" src=\"https://resources.audiense.com/hubfs/favicon-1.png\" alt=\"Audiense Logo\" /> **[Audiense Insights](https://github.com/AudienseCo/mcp-audiense-insights)** - Marketing insights and audience analysis from [Audiense](https://www.audiense.com/products/audiense-insights) reports, covering demographic, cultural, influencer, and content engagement analysis.\n- <img height=\"12\" width=\"12\" src=\"https://axiom.co/favicon.ico\" alt=\"Axiom Logo\" /> **[Axiom](https://github.com/axiomhq/mcp-server-axiom)** - Query and analyze your Axiom logs, traces, and all other event data in natural language\n- <img height=\"12\" width=\"12\" src=\"https://www.bankless.com/favicon.ico\" alt=\"Bankless Logo\" /> **[Bankless Onchain](https://github.com/bankless/onchain-mcp)** - Query Onchain data, like ERC20 tokens, transaction history, smart contract state.\n- <img height=\"12\" width=\"12\" src=\"https://bicscan.io/favicon.png\" alt=\"BICScan Logo\" /> **[BICScan](https://github.com/ahnlabio/bicscan-mcp)** - Risk score / asset holdings of EVM blockchain address (EOA, CA, ENS) and even domain names.\n- <img height=\"12\" width=\"12\" src=\"https://www.box.com/favicon.ico\" alt=\"Box Logo\" /> **[Box](https://github.com/box-community/mcp-server-box)** - Interact with the Intelligent Content Management platform through Box AI.\n- <img height=\"12\" width=\"12\" src=\"https://browserbase.com/favicon.ico\" alt=\"Browserbase Logo\" /> **[Browserbase](https://github.com/browserbase/mcp-server-browserbase)** - Automate browser interactions in the cloud (e.g. web navigation, data extraction, form filling, and more)\n- <img alt=\"favicon\" height=\"12\" width=\"12\" src=\"https://www.chargebee.com/static/resources/brand/favicon.png\" /> **[Chargebee](https://github.com/chargebee/agentkit/tree/main/modelcontextprotocol)** - MCP Server that connects AI agents to [Chargebee platform](https://www.chargebee.com).\n- <img height=\"12\" width=\"12\" src=\"https://trychroma.com/_next/static/media/chroma-logo.ae2d6e4b.svg\" /> **[Chroma](https://github.com/chroma-core/chroma-mcp)** - Embeddings, vector search, document storage, and full-text search with the open-source AI application database\n- <img height=\"12\" width=\"12\" src=\"https://www.chronulus.com/favicon/chronulus-logo-blue-on-alpha-square-128x128.ico\" alt=\"Chronulus AI Logo\" /> **[Chronulus AI](https://github.com/ChronulusAI/chronulus-mcp)** - Predict anything with Chronulus AI forecasting and prediction agents.\n- <img height=\"12\" width=\"12\" src=\"https://circleci.com/favicon.ico\" alt=\"CircleCI Logo\" /> **[CircleCI](https://github.com/CircleCI-Public/mcp-server-circleci)** - Enable AI Agents to fix build failures from CircleCI.\n- <img height=\"12\" width=\"12\" src=\"https://clickhouse.com/favicon.ico\" alt=\"ClickHouse Logo\" /> **[ClickHouse](https://github.com/ClickHouse/mcp-clickhouse)** - Query your [ClickHouse](https://clickhouse.com/) database server.\n- <img alt=\"cloudflare\" height=\"12\" width=\"12\" src=\"https://cdn.simpleicons.org/cloudflare\" /> **[Cloudflare](https://github.com/cloudflare/mcp-server-cloudflare)** - Deploy, configure & interrogate your resources on the Cloudflare developer platform (e.g. Workers/KV/R2/D1)\n-  **[CodeLogic](https://github.com/CodeLogicIncEngineering/codelogic-mcp-server)** - Interact with [CodeLogic](https://codelogic.com), a Software Intelligence platform that graphs complex code and data architecture dependencies, to boost AI accuracy and insight.\n- <img height=\"12\" width=\"12\" src=\"https://www.comet.com/favicon.ico\" alt=\"Comet Logo\" /> **[Comet Opik](https://github.com/comet-ml/opik-mcp)** - Query and analyze your [Opik](https://github.com/comet-ml/opik) logs, traces, prompts and all other telemtry data from your LLMs in natural language.\n- <img alt=\"favicon\" height=\"12\" width=\"12\" src=\"https://www.convex.dev/favicon.ico\" /> **[Convex](https://stack.convex.dev/convex-mcp-server)** - Introspect and query your apps deployed to Convex.\n- <img height=\"12\" width=\"12\" src=\"http://app.itsdart.com/static/img/favicon.png\" alt=\"Dart Logo\" /> **[Dart](https://github.com/its-dart/dart-mcp-server)** - Interact with task, doc, and project data in [Dart](https://itsdart.com), an AI-native project management tool\n- <img height=\"12\" width=\"12\" src=\"https://www.devhub.com/img/upload/favicon-196x196-dh.png\" alt=\"DevHub Logo\" /> **[DevHub](https://github.com/devhub/devhub-cms-mcp)** - Manage and utilize website content within the [DevHub](https://www.devhub.com) CMS platform\n- <img height=\"12\" width=\"12\" src=\"https://e2b.dev/favicon.ico\" alt=\"E2B Logo\" /> **[E2B](https://github.com/e2b-dev/mcp-server)** - Run code in secure sandboxes hosted by [E2B](https://e2b.dev)\n- <img height=\"12\" width=\"12\" src=\"https://static.edubase.net/media/brand/favicon/favicon-32x32.png\" alt=\"EduBase Logo\" /> **[EduBase](https://github.com/EduBase/MCP)** - Interact with [EduBase](https://www.edubase.net), a comprehensive e-learning platform with advanced quizzing, exam management, and content organization capabilities\n- <img height=\"12\" width=\"12\" src=\"https://www.elastic.co/favicon.ico\" alt=\"Elasticsearch Logo\" /> **[Elasticsearch](https://github.com/elastic/mcp-server-elasticsearch)** - Query your data in [Elasticsearch](https://www.elastic.co/elasticsearch)\n- <img height=\"12\" width=\"12\" src=\"https://esignatures.com/favicon.ico\" alt=\"eSignatures Logo\" /> **[eSignatures](https://github.com/esignaturescom/mcp-server-esignatures)** - Contract and template management for drafting, reviewing, and sending binding contracts.\n- <img height=\"12\" width=\"12\" src=\"https://exa.ai/images/favicon-32x32.png\" alt=\"Exa Logo\" /> **[Exa](https://github.com/exa-labs/exa-mcp-server)** - Search Engine made for AIs by [Exa](https://exa.ai)\n- <img height=\"12\" width=\"12\" src=\"https://fewsats.com/favicon.svg\" alt=\"Fewsats Logo\" /> **[Fewsats](https://github.com/Fewsats/fewsats-mcp)** - Enable AI Agents to purchase anything in a secure way using [Fewsats](https://fewsats.com)\n- <img height=\"12\" width=\"12\" src=\"https://fibery.io/favicon.svg\" alt=\"Fibery Logo\" /> **[Fibery](https://github.com/Fibery-inc/fibery-mcp-server)** - Perform queries and entity operations in your [Fibery](https://fibery.io) workspace.\n- <img height=\"12\" width=\"12\" src=\"https://financialdatasets.ai/favicon.ico\" alt=\"Financial Datasets Logo\" /> **[Financial Datasets](https://github.com/financial-datasets/mcp-server)** - Stock market API made for AI agents\n- <img height=\"12\" width=\"12\" src=\"https://firecrawl.dev/favicon.ico\" alt=\"Firecrawl Logo\" /> **[Firecrawl](https://github.com/mendableai/firecrawl-mcp-server)** - Extract web data with [Firecrawl](https://firecrawl.dev)\n- <img height=\"12\" width=\"12\" src=\"https://fireproof.storage/favicon.ico\" alt=\"Fireproof Logo\" /> **[Fireproof](https://github.com/fireproof-storage/mcp-database-server)** - Immutable ledger database with live synchronization\n- <img height=\"12\" width=\"12\" src=\"https://gitee.com/favicon.ico\" alt=\"Gitee Logo\" /> **[Gitee](https://github.com/oschina/mcp-gitee)** - Gitee API integration, repository, issue, and pull request management, and more.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/6605a2979ff17b2cd1939cd4/6605a460de47e7596ed84f06_icon256.png\" alt=\"gotoHuman Logo\" /> **[gotoHuman](https://github.com/gotohuman/gotohuman-mcp-server)** - Human-in-the-loop platform - Allow AI agents and automations to send requests for approval to your [gotoHuman](https://www.gotohuman.com) inbox.\n- <img height=\"12\" width=\"12\" src=\"https://grafana.com/favicon.ico\" alt=\"Grafana Logo\" /> **[Grafana](https://github.com/grafana/mcp-grafana)** - Search dashboards, investigate incidents and query datasources in your Grafana instance\n- <img height=\"12\" width=\"12\" src=\"https://framerusercontent.com/images/KCOWBYLKunDff1Dr452y6EfjiU.png\" alt=\"Graphlit Logo\" /> **[Graphlit](https://github.com/graphlit/graphlit-mcp-server)** - Ingest anything from Slack to Gmail to podcast feeds, in addition to web crawling, into a searchable [Graphlit](https://www.graphlit.com) project.\n- <img height=\"12\" width=\"12\" src=\"https://greptime.com/favicon.ico\" alt=\"Greptime Logo\" /> **[GreptimeDB](https://github.com/GreptimeTeam/greptimedb-mcp-server)** - Provides AI assistants with a secure and structured way to explore and analyze data in [GreptimeDB](https://github.com/GreptimeTeam/greptimedb).\n- <img height=\"12\" width=\"12\" src=\"https://www.herokucdn.com/favicons/favicon.ico\" alt=\"Heroku Logo\" /> **[Heroku](https://github.com/heroku/heroku-mcp-server)** - Interact with the Heroku Platform through LLM-driven tools for managing apps, add-ons, dynos, databases, and more.\n- <img height=\"12\" width=\"12\" src=\"https://img.alicdn.com/imgextra/i3/O1CN01d9qrry1i6lTNa2BRa_!!6000000004364-2-tps-218-200.png\" alt=\"Hologres Logo\" /> **[Hologres](https://github.com/aliyun/alibabacloud-hologres-mcp-server)** - Connect to a [Hologres](https://www.alibabacloud.com/en/product/hologres) instance, get table metadata, query and analyze data.\n- <img height=\"12\" width=\"12\" src=\"https://hyperbrowser-assets-bucket.s3.us-east-1.amazonaws.com/Hyperbrowser-logo.png\" alt=\"Hyperbrowsers23 Logo\" /> **[Hyperbrowser](https://github.com/hyperbrowserai/mcp)** - [Hyperbrowser](https://www.hyperbrowser.ai/) is the next-generation platform empowering AI agents and enabling effortless, scalable browser automation.\n- **[IBM wxflows](https://github.com/IBM/wxflows/tree/main/examples/mcp/javascript)** - Tool platform by IBM to build, test and deploy tools for any data source\n- <img height=\"12\" width=\"12\" src=\"https://forevervm.com/icon.png\" alt=\"ForeverVM Logo\" /> **[ForeverVM](https://github.com/jamsocket/forevervm/tree/main/javascript/mcp-server)** - Run Python in a code sandbox.\n- <img height=\"12\" width=\"12\" src=\"https://www.getinboxzero.com/icon.png\" alt=\"Inbox Zero Logo\" /> **[Inbox Zero](https://github.com/elie222/inbox-zero/tree/main/apps/mcp-server)** - AI personal assistant for email [Inbox Zero](https://www.getinboxzero.com)\n-  **[Inkeep](https://github.com/inkeep/mcp-server-python)** - RAG Search over your content powered by [Inkeep](https://inkeep.com)\n- <img height=\"12\" width=\"12\" src=\"https://integration.app/favicon.ico\" alt=\"Integration App Icon\" /> **[Integration App](https://github.com/integration-app/mcp-server)** - Interact with any other SaaS applications on behalf of your customers.\n- <img alt=\"jetbrains\" height=\"12\" width=\"12\" src=\"https://cdn.simpleicons.org/jetbrains\" /> **[JetBrains](https://github.com/JetBrains/mcp-jetbrains)** – Work on your code with JetBrains IDEs\n- <img height=\"12\" width=\"12\" src=\"https://kagi.com/favicon.ico\" alt=\"Kagi Logo\" /> **[Kagi Search](https://github.com/kagisearch/kagimcp)** - Search the web using Kagi's search API\n- <img height=\"12\" width=\"12\" src=\"https://connection.keboola.com/favicon.ico\" alt=\"Keboola Logo\" /> **[Keboola](https://github.com/keboola/keboola-mcp-server)** - Build robust data workflows, integrations, and analytics on a single intuitive platform.\n- <img height=\"12\" width=\"12\" src=\"https://laratranslate.com/favicon.ico\" alt=\"Lara Translate Logo\" /> **[Lara Translate](https://github.com/translated/lara-mcp)** - MCP Server for Lara Translate API, enabling powerful translation capabilities with support for language detection and context-aware translations.\n- <img height=\"12\" width=\"12\" src=\"https://logfire.pydantic.dev/favicon.ico\" alt=\"Logfire Logo\" /> **[Logfire](https://github.com/pydantic/logfire-mcp)** - Provides access to OpenTelemetry traces and metrics through Logfire.\n- <img height=\"12\" width=\"12\" src=\"https://langfuse.com/favicon.ico\" alt=\"Langfuse Logo\" /> **[Langfuse Prompt Management](https://github.com/langfuse/mcp-server-langfuse)** - Open-source tool for collaborative editing, versioning, evaluating, and releasing prompts.\n- <img height=\"12\" width=\"12\" src=\"https://lingo.dev/favicon.ico\" alt=\"Lingo.dev Logo\" /> **[Lingo.dev](https://github.com/lingodotdev/lingo.dev/blob/main/mcp.md)** - Make your AI agent speak every language on the planet, using [Lingo.dev](https://lingo.dev) Localization Engine.\n- <img height=\"12\" width=\"12\" src=\"https://www.mailgun.com/favicon.ico\" alt=\"Mailgun Logo\" /> **[Mailgun](https://github.com/mailgun/mailgun-mcp-server)** - Interact with Mailgun API.\n- <img height=\"12\" width=\"12\" src=\"https://www.make.com/favicon.ico\" alt=\"Make Logo\" /> **[Make](https://github.com/integromat/make-mcp-server)** - Turn your [Make](https://www.make.com/) scenarios into callable tools for AI assistants.\n- <img height=\"12\" width=\"12\" src=\"https://www.meilisearch.com/favicon.ico\" alt=\"Meilisearch Logo\" /> **[Meilisearch](https://github.com/meilisearch/meilisearch-mcp)** - Interact & query with Meilisearch (Full-text & semantic search API)\n-  **[Metoro](https://github.com/metoro-io/metoro-mcp-server)** - Query and interact with kubernetes environments monitored by Metoro\n- <img alt=\"favicon_32x32\" height=\"12\" width=\"12\" src=\"https://milvus.io/favicon-32x32.png\" /> **[Milvus](https://github.com/zilliztech/mcp-server-milvus)** - Search, Query and interact with data in your Milvus Vector Database.\n- <img height=\"12\" width=\"12\" src=\"https://www.motherduck.com/favicon.ico\" alt=\"MotherDuck Logo\" /> **[MotherDuck](https://github.com/motherduckdb/mcp-server-motherduck)** - Query and analyze data with MotherDuck and local DuckDB\n- <img height=\"12\" width=\"12\" src=\"https://needle-ai.com/images/needle-logo-orange-2-rounded.png\" alt=\"Needle AI Logo\" /> **[Needle](https://github.com/needle-ai/needle-mcp)** - Production-ready RAG out of the box to search and retrieve data from your own documents.\n- <img height=\"12\" width=\"12\" src=\"https://neo4j.com/favicon.ico\" alt=\"Neo4j Logo\" /> **[Neo4j](https://github.com/neo4j-contrib/mcp-neo4j/)** - Neo4j graph database server (schema + read/write-cypher) and separate graph database backed memory\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/183852044?s=48&v=4\" alt=\"Neon Logo\" /> **[Neon](https://github.com/neondatabase/mcp-server-neon)** - Interact with the Neon serverless Postgres platform\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/82347605?s=48&v=4\" alt=\"OceanBase Logo\" /> **[OceanBase](https://github.com/oceanbase/mcp-oceanbase)** - MCP Server for OceanBase database and its tools\n- <img height=\"12\" width=\"12\" src=\"https://docs.octagonagents.com/logo.svg\" alt=\"Octagon Logo\" /> **[Octagon](https://github.com/OctagonAI/octagon-mcp-server)** - Deliver real-time investment research with extensive private and public market data.\n- <img height=\"12\" width=\"12\" src=\"https://oxylabs.io/favicon.ico\" alt=\"Oxylabs Logo\" /> **[Oxylabs](https://github.com/oxylabs/oxylabs-mcp)** - Scrape websites with Oxylabs Web API, supporting dynamic rendering and parsing for structured data extraction.\n- <img height=\"12\" width=\"12\" src=\"https://developer.paddle.com/favicon.svg\" alt=\"Paddle Logo\" /> **[Paddle](https://github.com/PaddleHQ/paddle-mcp-server)** - Interact with the Paddle API. Manage product catalog, billing and subscriptions, and reports.\n- <img height=\"12\" width=\"12\" src=\"https://www.paypalobjects.com/webstatic/icon/favicon.ico\" alt=\"PayPal Logo\" /> **[PayPal](https://mcp.paypal.com)** - PayPal's official MCP server.\n- <img height=\"12\" width=\"12\" src=\"https://www.perplexity.ai/favicon.ico\" alt=\"Perplexity Logo\" /> **[Perplexity](https://github.com/ppl-ai/modelcontextprotocol)** - An MCP server that connects to Perplexity's Sonar API, enabling real-time web-wide research in conversational AI.\n- <img alt=\"logomark\" height=\"12\" width=\"12\" src=\"https://qdrant.tech/img/brand-resources-logos/logomark.svg\" /> **[Qdrant](https://github.com/qdrant/mcp-server-qdrant/)** - Implement semantic memory layer on top of the Qdrant vector search engine\n- <img alt=\"favicon\" height=\"12\" width=\"12\" src=\"https://www.ramp.com/favicon.ico\" /> **[Ramp](https://github.com/ramp-public/ramp-mcp)** - Interact with [Ramp](https://ramp.com)'s Developer API to run analysis on your spend and gain insights leveraging LLMs\n- **[Raygun](https://github.com/MindscapeHQ/mcp-server-raygun)** - Interact with your crash reporting and real using monitoring data on your Raygun account\n- <img height=\"12\" width=\"12\" src=\"https://www.rember.com/favicon.ico\" alt=\"Rember Logo\" /> **[Rember](https://github.com/rember/rember-mcp)** - Create spaced repetition flashcards in [Rember](https://rember.com) to remember anything you learn in your chats\n- <img height=\"12\" width=\"12\" src=\"https://riza.io/favicon.ico\" alt=\"Riza logo\" /> **[Riza](https://github.com/riza-io/riza-mcp)** - Arbitrary code execution and tool-use platform for LLMs by [Riza](https://riza.io)\n- <img alt=\"56912e614b35093426c515860f9f2234\" height=\"12\" width=\"12\" src=\"https://pics.fatwang2.com/56912e614b35093426c515860f9f2234.svg\" /> [Search1API](https://github.com/fatwang2/search1api-mcp) - One API for Search, Crawling, and Sitemaps\n- <img height=\"12\" width=\"12\" src=\"https://screenshotone.com/favicon.ico\" alt=\"ScreenshotOne Logo\" /> **[ScreenshotOne](https://github.com/screenshotone/mcp/)** - Render website screenshots with [ScreenshotOne](https://screenshotone.com/)\n- <img height=\"12\" width=\"12\" src=\"https://semgrep.dev/favicon.ico\" alt=\"Semgrep Logo\" /> **[Semgrep](https://github.com/semgrep/mcp)** - Enable AI agents to secure code with [Semgrep](https://semgrep.dev/).\n- <img alt=\"favicon_32x32_png_v_277b9cbbe31e8bc416504cf3b902d430\" height=\"12\" width=\"12\" src=\"https://www.singlestore.com/favicon-32x32.png?v=277b9cbbe31e8bc416504cf3b902d430\"/> **[SingleStore](https://github.com/singlestore-labs/mcp-server-singlestore)** - Interact with the SingleStore database platform\n- <img height=\"12\" width=\"12\" src=\"https://www.starrocks.io/favicon.ico\" alt=\"StarRocks Logo\" /> **[StarRocks](https://github.com/StarRocks/mcp-server-starrocks)** - Interact with [StarRocks](https://www.starrocks.io/)\n- <img height=\"12\" width=\"12\" src=\"https://stripe.com/favicon.ico\" alt=\"Stripe Logo\" /> **[Stripe](https://github.com/stripe/agent-toolkit)** - Interact with Stripe API\n- <img height=\"12\" width=\"12\" src=\"https://tavily.com/favicon.ico\" alt=\"Tavily Logo\" /> **[Tavily](https://github.com/tavily-ai/tavily-mcp)** - Search engine for AI agents (search + extract) powered by [Tavily](https://tavily.com/)\n- <img height=\"12\" width=\"12\" src=\"https://thirdweb.com/favicon.ico\" alt=\"Thirdweb Logo\" /> **[Thirdweb](https://github.com/thirdweb-dev/ai/tree/main/python/thirdweb-mcp)** - Read/write to over 2k blockchains, enabling data querying, contract analysis/deployment, and transaction execution, powered by [Thirdweb](https://thirdweb.com/)\n- <img height=\"12\" width=\"12\" src=\"https://www.tinybird.co/favicon.ico\" alt=\"Tinybird Logo\" /> **[Tinybird](https://github.com/tinybirdco/mcp-tinybird)** - Interact with Tinybird serverless ClickHouse platform\n- <img height=\"12\" width=\"12\" src=\"https://unifai.network/favicon.ico\" alt=\"UnifAI Logo\" /> **[UnifAI](https://github.com/unifai-network/unifai-mcp-server)** - Dynamically search and call tools using [UnifAI Network](https://unifai.network)\n- <img height=\"12\" width=\"12\" src=\"https://framerusercontent.com/images/plcQevjrOYnyriuGw90NfQBPoQ.jpg\" alt=\"Unstructured Logo\" /> **[Unstructured](https://github.com/Unstructured-IO/UNS-MCP)** - Set up and interact with your unstructured data processing workflows in [Unstructured Platform](https://unstructured.io)\n- **[Vectorize](https://github.com/vectorize-io/vectorize-mcp-server/)** - [Vectorize](https://vectorize.io) MCP server for advanced retrieval, Private Deep Research, Anything-to-Markdown file extraction and text chunking.\n- <img height=\"12\" width=\"12\" src=\"https://verodat.io/assets/favicon-16x16.png\" alt=\"Verodat Logo\" /> **[Verodat](https://github.com/Verodat/verodat-mcp-server)** - Interact with Verodat AI Ready Data platform\n- <img height=\"12\" width=\"12\" src=\"https://www.veyrax.com/favicon.ico\" alt=\"VeyraX Logo\" /> **[VeyraX](https://github.com/VeyraX/veyrax-mcp)** - Single tool to control all 100+ API integrations, and UI components\n- <img height=\"12\" width=\"12\" src=\"https://www.xero.com/favicon.ico\" alt=\"Xero Logo\" /> **[Xero](https://github.com/XeroAPI/xero-mcp-server)** - Interact with the accounting data in your business using our official MCP server\n- <img height=\"12\" width=\"12\" src=\"https://cdn.zapier.com/zapier/images/favicon.ico\" alt=\"Zapier Logo\" /> **[Zapier](https://zapier.com/mcp)** - Connect your AI Agents to 8,000 apps instantly.\n- **[ZenML](https://github.com/zenml-io/mcp-zenml)** - Interact with your MLOps and LLMOps pipelines through your [ZenML](https://www.zenml.io) MCP server\n\n### 🌎 Community Servers\n\nA growing set of community-developed and maintained servers demonstrates various applications of MCP across different domains.\n\n> **Note:** Community servers are **untested** and should be used at **your own risk**. They are not affiliated with or endorsed by Anthropic.\n- **[Ableton Live](https://github.com/Simon-Kansara/ableton-live-mcp-server)** - an MCP server to control Ableton Live.\n- **[Airbnb](https://github.com/openbnb-org/mcp-server-airbnb)** - Provides tools to search Airbnb and get listing details.\n- **[AI Agent Marketplace Index](https://github.com/AI-Agent-Hub/ai-agent-marketplace-index-mcp)** - MCP server to search more than 5000+ AI agents and tools of various categories from [AI Agent Marketplace Index](http://www.deepnlp.org/store/ai-agent) and monitor traffic of AI Agents.\n- **[Algorand](https://github.com/GoPlausible/algorand-mcp)** - A comprehensive MCP server for tooling interactions (40+) and resource accessibility (60+) plus many useful prompts for interacting with the Algorand blockchain.\n- **[Airflow](https://github.com/yangkyeongmo/mcp-server-apache-airflow)** - A MCP Server that connects to [Apache Airflow](https://airflow.apache.org/) using official python client.\n- **[Airtable](https://github.com/domdomegg/airtable-mcp-server)** - Read and write access to [Airtable](https://airtable.com/) databases, with schema inspection.\n- **[Airtable](https://github.com/felores/airtable-mcp)** - Airtable Model Context Protocol Server.\n- **[AlphaVantage](https://github.com/calvernaz/alphavantage)** - MCP server for stock market data API [AlphaVantage](https://www.alphavantage.co)\n- **[Anki](https://github.com/scorzeth/anki-mcp-server)** - An MCP server for interacting with your [Anki](https://apps.ankiweb.net) decks and cards.\n- **[Any Chat Completions](https://github.com/pyroprompts/any-chat-completions-mcp)** - Interact with any OpenAI SDK Compatible Chat Completions API like OpenAI, Perplexity, Groq, xAI and many more.\n- **[Apple Calendar](https://github.com/Omar-v2/mcp-ical)** - An MCP server that allows you to interact with your MacOS Calendar through natural language, including features such as event creation, modification, schedule listing, finding free time slots etc.\n- **[ArangoDB](https://github.com/ravenwits/mcp-server-arangodb)** - MCP Server that provides database interaction capabilities through [ArangoDB](https://arangodb.com/).\n- **[Arduino](https://github.com/vishalmysore/choturobo)** - MCP Server that enables AI-powered robotics using Claude AI and Arduino (ESP32) for real-world automation and interaction with robots.\n- **[Atlassian](https://github.com/sooperset/mcp-atlassian)** - Interact with Atlassian Cloud products (Confluence and Jira) including searching/reading Confluence spaces/pages, accessing Jira issues, and project metadata.\n- **[Attestable MCP](https://github.com/co-browser/attestable-mcp-server)** - An MCP server running inside a trusted execution environment (TEE) via Gramine, showcasing remote attestation using [RA-TLS](https://gramine.readthedocs.io/en/stable/attestation.html). This allows an MCP client to verify the server before conencting.\n- **[AWS](https://github.com/rishikavikondala/mcp-server-aws)** - Perform operations on your AWS resources using an LLM.\n- **[AWS Athena](https://github.com/lishenxydlgzs/aws-athena-mcp)** - A MCP server for AWS Athena to run SQL queries on Glue Catalog.\n- **[AWS Cost Explorer](https://github.com/aarora79/aws-cost-explorer-mcp-server)** - Optimize your AWS spend (including Amazon Bedrock spend) with this MCP server by examining spend across regions, services, instance types and foundation models ([demo video](https://www.youtube.com/watch?v=WuVOmYLRFmI&feature=youtu.be)).\n- **[AWS Resources Operations](https://github.com/baryhuang/mcp-server-aws-resources-python)** - Run generated python code to securely query or modify any AWS resources supported by boto3.\n- **[AWS S3](https://github.com/aws-samples/sample-mcp-server-s3)** - A sample MCP server for AWS S3 that flexibly fetches objects from S3 such as PDF documents.\n- **[Azure ADX](https://github.com/pab1it0/adx-mcp-server)** - Query and analyze Azure Data Explorer databases.\n- **[Azure DevOps](https://github.com/Vortiago/mcp-azure-devops)** - An MCP server that provides a bridge to Azure DevOps services, enabling AI assistants to query and manage work items.\n- **[Baidu AI Search](https://github.com/baidubce/app-builder/tree/master/python/mcp_server/ai_search)** - Web search with Baidu Cloud's AI Search\n- **[Base Free USDC Transfer](https://github.com/magnetai/mcp-free-usdc-transfer)** - Send USDC on [Base](https://base.org) for free using Claude AI! Built with [Coinbase CDP](https://docs.cdp.coinbase.com/mpc-wallet/docs/welcome).\n* **[Basic Memory](https://github.com/basicmachines-co/basic-memory)** - Local-first knowledge management system that builds a semantic graph from Markdown files, enabling persistent memory across conversations with LLMs.\n- **[BigQuery](https://github.com/LucasHild/mcp-server-bigquery)** (by LucasHild) - This server enables LLMs to inspect database schemas and execute queries on BigQuery.\n- **[BigQuery](https://github.com/ergut/mcp-bigquery-server)** (by ergut) - Server implementation for Google BigQuery integration that enables direct BigQuery database access and querying capabilities\n- **[Bing Web Search API](https://github.com/leehanchung/bing-search-mcp)** (by hanchunglee) - Server implementation for Microsoft Bing Web Search API.\n- **[Bitable MCP](https://github.com/lloydzhou/bitable-mcp)** (by lloydzhou) - MCP server provides access to Lark Bitable through the Model Context Protocol. It allows users to interact with Bitable tables using predefined tools.\n- **[Blender](https://github.com/ahujasid/blender-mcp)** (by ahujasid) - Blender integration allowing prompt enabled 3D scene creation, modeling and manipulation.\n- **[browser-use](https://github.com/co-browser/browser-use-mcp-server)** (by co-browser) - browser-use MCP server with dockerized playwright + chromium + vnc. supports stdio & resumable http.\n- **[Bsc-mcp](https://github.com/TermiX-official/bsc-mcp)** The first MCP server that serves as the bridge between AI and BNB Chain, enabling AI agents to execute complex on-chain operations through seamless integration with the BNB Chain, including transfer, swap, launch, security check on any token and even more.\n- **[Calculator](https://github.com/githejie/mcp-server-calculator)** - This server enables LLMs to use calculator for precise numerical calculations.\n- **[CFBD API](https://github.com/lenwood/cfbd-mcp-server)** - An MCP server for the [College Football Data API](https://collegefootballdata.com/).\n- **[ChatMCP](https://github.com/AI-QL/chat-mcp)** – An Open Source Cross-platform GUI Desktop application compatible with Linux, macOS, and Windows, enabling seamless interaction with MCP servers across dynamically selectable LLMs, by **[AIQL](https://github.com/AI-QL)**\n- **[ChatSum](https://github.com/mcpso/mcp-server-chatsum)** - Query and Summarize chat messages with LLM. by [mcpso](https://mcp.so)\n- **[Chroma](https://github.com/privetin/chroma)** - Vector database server for semantic document search and metadata filtering, built on Chroma\n- **[ClaudePost](https://github.com/ZilongXue/claude-post)** - ClaudePost enables seamless email management for Gmail, offering secure features like email search, reading, and sending.\n- **[Cloudinary](https://github.com/felores/cloudinary-mcp-server)** - Cloudinary Model Context Protocol Server to upload media to Cloudinary and get back the media link and details.\n- **[code-assistant](https://github.com/stippi/code-assistant)** - A coding assistant MCP server that allows to explore a code-base and make changes to code. Should be used with trusted repos only (insufficient protection against prompt injections).\n- **[code-executor](https://github.com/bazinga012/mcp_code_executor)** - An MCP server that allows LLMs to execute Python code within a specified Conda environment.\n- **[code-sandbox-mcp](https://github.com/Automata-Labs-team/code-sandbox-mcp)** - An MCP server to create secure code sandbox environment for executing code within Docker containers.\n- **[cognee-mcp](https://github.com/topoteretes/cognee/tree/main/cognee-mcp)** - GraphRAG memory server with customizable ingestion, data processing and search\n- **[coin_api_mcp](https://github.com/longmans/coin_api_mcp)** - Provides access to [coinmarketcap](https://coinmarketcap.com/) cryptocurrency data.\n- **[Contentful-mcp](https://github.com/ivo-toby/contentful-mcp)** - Read, update, delete, publish content in your [Contentful](https://contentful.com) space(s) from this MCP Server.\n- **[crypto-feargreed-mcp](https://github.com/kukapay/crypto-feargreed-mcp)**  -  Providing real-time and historical Crypto Fear & Greed Index data.\n- **[cryptopanic-mcp-server](https://github.com/kukapay/cryptopanic-mcp-server)** - Providing latest cryptocurrency news to AI agents, powered by CryptoPanic.\n- **[Dappier](https://github.com/DappierAI/dappier-mcp)** - Connect LLMs to real-time, rights-cleared, proprietary data from trusted sources. Access specialized models for Real-Time Web Search, News, Sports, Financial Data, Crypto, and premium publisher content. Explore data models at [marketplace.dappier.com](https://marketplace.dappier.com/marketplace).\n- **[Databricks](https://github.com/JordiNeil/mcp-databricks-server)** - Allows LLMs to run SQL queries, list and get details of jobs executions in a Databricks account.\n- **[Datadog](https://github.com/GeLi2001/datadog-mcp-server)** - Datadog MCP Server for application tracing, monitoring, dashboard, incidents queries built on official datadog api.\n- **[Data Exploration](https://github.com/reading-plus-ai/mcp-server-data-exploration)** - MCP server for autonomous data exploration on .csv-based datasets, providing intelligent insights with minimal effort. NOTE: Will execute arbitrary Python code on your machine, please use with caution!\n- **[Dataset Viewer](https://github.com/privetin/dataset-viewer)** - Browse and analyze Hugging Face datasets with features like search, filtering, statistics, and data export\n- **[DBHub](https://github.com/bytebase/dbhub/)** - Universal database MCP server connecting to MySQL, PostgreSQL, SQLite, DuckDB and etc.\n- **[DeepSeek MCP Server](https://github.com/DMontgomery40/deepseek-mcp-server)** - Model Context Protocol server integrating DeepSeek's advanced language models, in addition to [other useful API endpoints](https://github.com/DMontgomery40/deepseek-mcp-server?tab=readme-ov-file#features)\n- **[Deepseek_R1](https://github.com/66julienmartin/MCP-server-Deepseek_R1)** - A Model Context Protocol (MCP) server implementation connecting Claude Desktop with DeepSeek's language models (R1/V3)\n- **[deepseek-thinker-mcp](https://github.com/ruixingshi/deepseek-thinker-mcp)** - A MCP (Model Context Protocol) provider Deepseek reasoning content to MCP-enabled AI Clients, like Claude Desktop. Supports access to Deepseek's thought processes from the Deepseek API service or from a local Ollama server.\n- **[Descope](https://github.com/descope-sample-apps/descope-mcp-server)** - An MCP server to integrate with [Descope](https://descope.com) to search audit logs, manage users, and more.\n- **[DevRev](https://github.com/kpsunil97/devrev-mcp-server)** - An MCP server to integrate with DevRev APIs to search through your DevRev Knowledge Graph where objects can be imported from diff. sources listed [here](https://devrev.ai/docs/import#available-sources).\n- **[Dicom](https://github.com/ChristianHinge/dicom-mcp)** - An MCP server to query and retrieve medical images and for parsing and reading dicom-encapsulated documents (pdf etc.). \n- **[Dify](https://github.com/YanxingLiu/dify-mcp-server)** - A simple implementation of an MCP server for dify workflows.\n- **[Discord](https://github.com/v-3/discordmcp)** - A MCP server to connect to Discord guilds through a bot and read and write messages in channels\n- **[Discord](https://github.com/SaseQ/discord-mcp)** - A MCP server, which connects to Discord through a bot, and provides comprehensive integration with Discord.\n- **[Discourse](https://github.com/AshDevFr/discourse-mcp-server)** - A MCP server to search Discourse posts on a Discourse forum.\n- **[Docker](https://github.com/ckreiling/mcp-server-docker)** - Integrate with Docker to manage containers, images, volumes, and networks.\n- **[Drupal](https://github.com/Omedia/mcp-server-drupal)** - Server for interacting with [Drupal](https://www.drupal.org/project/mcp) using STDIO transport layer.\n- **[dune-analytics-mcp](https://github.com/kukapay/dune-analytics-mcp)** -  A mcp server that bridges Dune Analytics data to AI agents.\n- **[EdgeOne Pages MCP](https://github.com/TencentEdgeOne/edgeone-pages-mcp)** - An MCP service for deploying HTML content to EdgeOne Pages and obtaining a publicly accessible URL.\n- **[Elasticsearch](https://github.com/cr7258/elasticsearch-mcp-server)** - MCP server implementation that provides Elasticsearch interaction.\n- **[ElevenLabs](https://github.com/mamertofabian/elevenlabs-mcp-server)** - A server that integrates with ElevenLabs text-to-speech API capable of generating full voiceovers with multiple voices.\n- **[Ergo Blockchain MCP](https://github.com/marctheshark3/ergo-mcp)** -An MCP server to integrate Ergo Blockchain Node and Explorer APIs for checking address balances, analyzing transactions, viewing transaction history, performing forensic analysis of addresses, searching for tokens, and monitoring network status.\n- **[Eunomia](https://github.com/whataboutyou-ai/eunomia-MCP-server)** - Extension of the Eunomia framework that connects Eunomia instruments with MCP servers\n- **[EVM MCP Server](https://github.com/mcpdotdirect/evm-mcp-server)** - Comprehensive blockchain services for 30+ EVM networks, supporting native tokens, ERC20, NFTs, smart contracts, transactions, and ENS resolution.\n- **[Everything Search](https://github.com/mamertofabian/mcp-everything-search)** - Fast file searching capabilities across Windows (using [Everything SDK](https://www.voidtools.com/support/everything/sdk/)), macOS (using mdfind command), and Linux (using locate/plocate command).\n- **[Excel](https://github.com/haris-musa/excel-mcp-server)** - Excel manipulation including data reading/writing, worksheet management, formatting, charts, and pivot table.\n- **[Fantasy PL](https://github.com/rishijatia/fantasy-pl-mcp)** - Give your coding agent direct access to up-to date Fantasy Premier League data\n- **[fastn.ai – Unified API MCP Server](https://github.com/fastnai/mcp-fastn)** - A remote, dynamic MCP server with a unified API that connects to 1,000+ tools, actions, and workflows, featuring built-in authentication and monitoring.\n- **[Fetch](https://github.com/zcaceres/fetch-mcp)** - A server that flexibly fetches HTML, JSON, Markdown, or plaintext.\n- **[Fingertip](https://github.com/fingertip-com/fingertip-mcp)** - MCP server for Fingertip.com to search and create new sites.\n- **[Figma](https://github.com/GLips/Figma-Context-MCP)** - Give your coding agent direct access to Figma file data, helping it one-shot design implementation.\n- **[Firebase](https://github.com/gannonh/firebase-mcp)** - Server to interact with Firebase services including Firebase Authentication, Firestore, and Firebase Storage.\n- **[FireCrawl](https://github.com/vrknetha/mcp-server-firecrawl)** - Advanced web scraping with JavaScript rendering, PDF support, and smart rate limiting\n- **[FlightRadar24](https://github.com/sunsetcoder/flightradar24-mcp-server)** - A Claude Desktop MCP server that helps you track flights in real-time using Flightradar24 data.\n- **[Ghost](https://github.com/MFYDev/ghost-mcp)** - A Model Context Protocol (MCP) server for interacting with Ghost CMS through LLM interfaces like Claude.\n- **[Github Actions](https://github.com/ko1ynnky/github-actions-mcp-server)** - A Model Context Protocol (MCP) server for interacting with Github Actions.\n- **[Glean](https://github.com/longyi1207/glean-mcp-server)** - A server that uses Glean API to search and chat.\n- **[Gmail](https://github.com/GongRzhe/Gmail-MCP-Server)** - A Model Context Protocol (MCP) server for Gmail integration in Claude Desktop with auto authentication support.\n- **[Gmail Headless](https://github.com/baryhuang/mcp-headless-gmail)** - Remote hostable MCP server that can get and send Gmail messages without local credential or file system setup.\n- **[Goal Story](https://github.com/hichana/goalstory-mcp)** - a Goal Tracker and Visualization Tool for personal and professional development.\n- **[GOAT](https://github.com/goat-sdk/goat/tree/main/typescript/examples/by-framework/model-context-protocol)** - Run more than +200 onchain actions on any blockchain including Ethereum, Solana and Base.\n- **[Godot](https://github.com/Coding-Solo/godot-mcp)** - A MCP server providing comprehensive Godot engine integration for project editing, debugging, and scene management.\n- **[Golang Filesystem Server](https://github.com/mark3labs/mcp-filesystem-server)** - Secure file operations with configurable access controls built with Go!\n- **[Goodnews](https://github.com/VectorInstitute/mcp-goodnews)** - A simple MCP server that delivers curated positive and uplifting news stories.\n- **[Google Calendar](https://github.com/v-3/google-calendar)** - Integration with Google Calendar to check schedules, find time, and add/delete events\n- **[Google Calendar](https://github.com/nspady/google-calendar-mcp)** - Google Calendar MCP Server for managing Google calendar events. Also supports searching for events by attributes like title and location.\n- **[Google Custom Search](https://github.com/adenot/mcp-google-search)** - Provides Google Search results via the Google Custom Search API\n- **[Google Tasks](https://github.com/zcaceres/gtasks-mcp)** - Google Tasks API Model Context Protocol Server.\n- **[GraphQL Schema](https://github.com/hannesj/mcp-graphql-schema)** - Allow LLMs to explore large GraphQL schemas without bloating the context.\n- **[HDW LinkedIn](https://github.com/horizondatawave/hdw-mcp-server)** - Access to profile data and management of user account with [HorizonDataWave.ai](https://horizondatawave.ai/).\n- **[Heurist Mesh Agent](https://github.com/heurist-network/heurist-mesh-mcp-server)** - Access specialized web3 AI agents for blockchain analysis, smart contract security, token metrics, and blockchain interactions through the [Heurist Mesh network](https://github.com/heurist-network/heurist-agent-framework/tree/main/mesh).\n- **[Holaspirit](https://github.com/syucream/holaspirit-mcp-server)** - Interact with [Holaspirit](https://www.holaspirit.com/).\n- **[Home Assistant](https://github.com/tevonsb/homeassistant-mcp)** - Interact with [Home Assistant](https://www.home-assistant.io/) including viewing and controlling lights, switches, sensors, and all other Home Assistant entities.\n- **[Home Assistant](https://github.com/voska/hass-mcp)** - Docker-ready MCP server for Home Assistant with entity management, domain summaries, automation support, and guided conversations. Includes pre-built container images for easy installation.\n- **[HubSpot](https://github.com/buryhuang/mcp-hubspot)** - HubSpot CRM integration for managing contacts and companies. Create and retrieve CRM data directly through Claude chat.\n- **[HuggingFace Spaces](https://github.com/evalstate/mcp-hfspace)** - Server for using HuggingFace Spaces, supporting Open Source Image, Audio, Text Models and more. Claude Desktop mode for easy integration.\n- **[Hyperliquid](https://github.com/mektigboy/server-hyperliquid)** - An MCP server implementation that integrates the Hyperliquid SDK for exchange data.\n- **[iFlytek Workflow](https://github.com/iflytek/ifly-workflow-mcp-server)** - Connect to iFlytek Workflow via the MCP server and run your own Agent.\n- **[Image Generation](https://github.com/GongRzhe/Image-Generation-MCP-Server)** - This MCP server provides image generation capabilities using the Replicate Flux model.\n- **[InfluxDB](https://github.com/idoru/influxdb-mcp-server)** - Run queries against InfluxDB OSS API v2.\n- **[Inoyu](https://github.com/sergehuber/inoyu-mcp-unomi-server)** - Interact with an Apache Unomi CDP customer data platform to retrieve and update customer profiles\n- **[Intercom](https://github.com/raoulbia-ai/mcp-server-for-intercom)** - An MCP-compliant server for retrieving customer support tickets from Intercom. This tool enables AI assistants like Claude Desktop and Cline to access and analyze your Intercom support tickets.\n- **[iOS Simulator](https://github.com/InditexTech/mcp-server-simulator-ios-idb)** - A Model Context Protocol (MCP) server that enables LLMs to interact with iOS simulators (iPhone, iPad, etc.) through natural language commands.\n- **[iTerm MCP](https://github.com/ferrislucas/iterm-mcp)** - Integration with iTerm2 terminal emulator for macOS, enabling LLMs to execute and monitor terminal commands.\n- **[JavaFX](https://github.com/mcpso/mcp-server-javafx)** - Make drawings using a JavaFX canvas\n- **[JDBC](https://github.com/quarkiverse/quarkus-mcp-servers/tree/main/jdbc)** - Connect to any JDBC-compatible database and query, insert, update, delete, and more. Supports MySQL, PostgreSQL, Oracle, SQL Server, sqllite and [more](https://github.com/quarkiverse/quarkus-mcp-servers/tree/main/jdbc#supported-jdbc-variants).\n- **[JSON](https://github.com/GongRzhe/JSON-MCP-Server)** - JSON handling and processing server with advanced query capabilities using JSONPath syntax and support for array, string, numeric, and date operations.\n- **[KiCad MCP](https://github.com/lamaalrajih/kicad-mcp)** - MCP server for KiCad on Mac, Windows, and Linux.\n- **[Keycloak MCP](https://github.com/ChristophEnglisch/keycloak-model-context-protocol)** - This MCP server enables natural language interaction with Keycloak for user and realm management including creating, deleting, and listing users and realms.\n- **[Kibela](https://github.com/kiwamizamurai/mcp-kibela-server)** (by kiwamizamurai) - Interact with Kibela API.\n- **[kintone](https://github.com/macrat/mcp-server-kintone)** - Manage records and apps in [kintone](https://kintone.com) through LLM tools.\n- **[Kong Konnect](https://github.com/Kong/mcp-konnect)** - A Model Context Protocol (MCP) server for interacting with Kong Konnect APIs, allowing AI assistants to query and analyze Kong Gateway configurations, traffic, and analytics.\n- **[Kubernetes](https://github.com/Flux159/mcp-server-kubernetes)** - Connect to Kubernetes cluster and manage pods, deployments, and services.\n- **[Kubernetes and OpenShift](https://github.com/manusa/kubernetes-mcp-server)** - A powerful Kubernetes MCP server with additional support for OpenShift. Besides providing CRUD operations for any Kubernetes resource, this server provides specialized tools to interact with your cluster.\n- **[Langflow-DOC-QA-SERVER](https://github.com/GongRzhe/Langflow-DOC-QA-SERVER)** - A Model Context Protocol server for document Q&A powered by Langflow. It demonstrates core MCP concepts by providing a simple interface to query documents through a Langflow backend.\n- **[Lightdash](https://github.com/syucream/lightdash-mcp-server)** - Interact with [Lightdash](https://www.lightdash.com/), a BI tool.\n- **[Linear](https://github.com/jerhadf/linear-mcp-server)** - Allows LLM to interact with Linear's API for project management, including searching, creating, and updating issues.\n- **[Linear (Go)](https://github.com/geropl/linear-mcp-go)** - Allows LLM to interact with Linear's API via a single static binary.\n- **[LINE](https://github.com/amornpan/py-mcp-line)** (by amornpan) - Implementation for LINE Bot integration that enables Language Models to read and analyze LINE conversations through a standardized interface. Features asynchronous operation, comprehensive logging, webhook event handling, and support for various message types.\n- **[LlamaCloud](https://github.com/run-llama/mcp-server-llamacloud)** (by marcusschiesser) - Integrate the data stored in a managed index on [LlamaCloud](https://cloud.llamaindex.ai/)\n- **[llm-context](https://github.com/cyberchitta/llm-context.py)** - Provides a repo-packing MCP tool with configurable profiles that specify file inclusion/exclusion patterns and optional prompts.\n- **[mac-messages-mcp](https://github.com/carterlasalle/mac_messages_mcp)** - An MCP server that securely interfaces with your iMessage database via the Model Context Protocol (MCP), allowing LLMs to query and analyze iMessage conversations. It includes robust phone number validation, attachment processing, contact management, group chat handling, and full support for sending and receiving messages.\n- **[MariaDB](https://github.com/abel9851/mcp-server-mariadb)** - MariaDB database integration with configurable access controls in Python.\n- **[Maton](https://github.com/maton-ai/agent-toolkit/tree/main/modelcontextprotocol)** - Connect to your SaaS tools like HubSpot, Salesforce, and more.\n- **[MCP Compass](https://github.com/liuyoshio/mcp-compass)** - Suggest the right MCP server for your needs\n- **[MCP Create](https://github.com/tesla0225/mcp-create)** - A dynamic MCP server management service that creates, runs, and manages Model Context Protocol servers on-the-fly.\n- **[MCP Installer](https://github.com/anaisbetts/mcp-installer)** - This server is a server that installs other MCP servers for you.\n- **[mcp-k8s-go](https://github.com/strowk/mcp-k8s-go)** - Golang-based Kubernetes server for MCP to browse pods and their logs, events, namespaces and more. Built to be extensible.\n- **[mcp-local-rag](https://github.com/nkapila6/mcp-local-rag)** - \"primitive\" RAG-like web search model context protocol (MCP) server that runs locally using Google's MediaPipe Text Embedder and DuckDuckGo Search. ✨ no APIs required ✨.\n- **[mcp-proxy](https://github.com/sparfenyuk/mcp-proxy)** - Connect to MCP servers that run on SSE transport, or expose stdio servers as an SSE server.\n- **[mem0-mcp](https://github.com/mem0ai/mem0-mcp)** - A Model Context Protocol server for Mem0, which helps with managing coding preferences.\n- **[MSSQL](https://github.com/aekanun2020/mcp-server/)** - MSSQL database integration with configurable access controls and schema inspection\n- **[MSSQL](https://github.com/JexinSam/mssql_mcp_server)** (by jexin) - MCP Server for MSSQL database in Python\n- **[MSSQL-Python](https://github.com/amornpan/py-mcp-mssql)** (by amornpan) - A read-only Python implementation for MSSQL database access with enhanced security features, configurable access controls, and schema inspection capabilities. Focuses on safe database interaction through Python ecosystem.\n- **[MSSQL-MCP](https://github.com/daobataotie/mssql-mcp)** (by daobataotie) - MSSQL MCP that refer to the official website's SQLite MCP for modifications to adapt to MSSQL\n- **[Markdownify](https://github.com/zcaceres/mcp-markdownify-server)** - MCP to convert almost anything to Markdown (PPTX, HTML, PDF, Youtube Transcripts and more)\n- **[Microsoft Teams](https://github.com/InditexTech/mcp-teams-server)** - MCP server that integrates Microsoft Teams messaging (read, post, mention, list members and threads) \n- **[Mindmap](https://github.com/YuChenSSR/mindmap-mcp-server)** (by YuChenSSR) - A server that generates mindmaps from input containing markdown code.\n- **[Minima](https://github.com/dmayboroda/minima)** - MCP server for RAG on local files\n- **[Mobile MCP](https://github.com/mobile-next/mobile-mcp)** (by Mobile Next) - MCP server for Mobile(iOS/Android) automation, app scraping and development using physical devices or simulators/emulators.\n- **[MongoDB](https://github.com/kiliczsh/mcp-mongo-server)** - A Model Context Protocol Server for MongoDB.\n- **[MongoDB Lens](https://github.com/furey/mongodb-lens)** - Full Featured MCP Server for MongoDB Databases.\n- **[Monday.com](https://github.com/sakce/mcp-server-monday)** - MCP Server to interact with Monday.com boards and items.\n- **[Multicluster-MCP-Sever](https://github.com/yanmxa/multicluster-mcp-server)** - The gateway for GenAI systems to interact with multiple Kubernetes clusters.\n- **[MySQL](https://github.com/benborla/mcp-server-mysql)** (by benborla) - MySQL database integration in NodeJS with configurable access controls and schema inspection\n- **[MySQL](https://github.com/designcomputer/mysql_mcp_server)** (by DesignComputer) - MySQL database integration in Python with configurable access controls and schema inspection\n- **[n8n](https://github.com/leonardsellem/n8n-mcp-server)** - This MCP server provides tools and resources for AI assistants to manage n8n workflows and executions, including listing, creating, updating, and deleting workflows, as well as monitoring their execution status.\n- **[NASA](https://github.com/ProgramComputer/NASA-MCP-server)** (by ProgramComputer) - Access to a unified gateway of NASA's data sources including but not limited to APOD, NEO, EPIC, GIBS.\n- **[Nasdaq Data Link](https://github.com/stefanoamorelli/nasdaq-data-link-mcp)** (by stefanoamorelli) - An MCP server to access, explore, and interact with Nasdaq Data Link’s extensive and valuable financial and economic datasets.\n- **[National Parks](https://github.com/KyrieTangSheng/mcp-server-nationalparks)** - The server provides latest information of park details, alerts, visitor centers, campgrounds, hiking trails, and events for U.S. National Parks.\n- **[NAVER](https://github.com/pfldy2850/py-mcp-naver)** (by pfldy2850) - This MCP server provides tools to interact with various Naver services, such as searching blogs, news, books, and more.\n- **[NS Travel Information](https://github.com/r-huijts/ns-mcp-server)** - Access Dutch Railways (NS) real-time train travel information and disruptions through the official NS API.\n- **[Neo4j](https://github.com/da-okazaki/mcp-neo4j-server)** - A community built server that interacts with Neo4j Graph Database.\n- **[Neovim](https://github.com/bigcodegen/mcp-neovim-server)** - An MCP Server for your Neovim session.\n- **[Notion](https://github.com/suekou/mcp-notion-server)** (by suekou) - Interact with Notion API.\n- **[Notion](https://github.com/v-3/notion-server)** (by v-3) - Notion MCP integration. Search, Read, Update, and Create pages through Claude chat.\n- **[ntfy-mcp](https://github.com/teddyzxcv/ntfy-mcp)** (by teddyzxcv) - The MCP server that keeps you informed by sending the notification on phone using ntfy\n- **[oatpp-mcp](https://github.com/oatpp/oatpp-mcp)** - C++ MCP integration for Oat++. Use [Oat++](https://oatpp.io) to build MCP servers.\n- **[Obsidian Markdown Notes](https://github.com/calclavia/mcp-obsidian)** - Read and search through your Obsidian vault or any directory containing Markdown notes\n- **[obsidian-mcp](https://github.com/StevenStavrakis/obsidian-mcp)** - (by Steven Stavrakis) An MCP server for Obsidian.md with tools for searching, reading, writing, and organizing notes.\n- **[OceanBase](https://github.com/yuanoOo/oceanbase_mcp_server)** - (by yuanoOo) A Model Context Protocol (MCP) server that enables secure interaction with OceanBase databases.\n- **[Okta](https://github.com/kapilduraphe/okta-mcp-server)** - Interact with Okta API.\n- **[OneNote](https://github.com/rajvirtual/MCP-Servers/tree/master/onenote)** - (by Rajesh Vijay) An MCP server that connects to Microsoft OneNote using the Microsoft Graph API. Reading notebooks, sections, and pages from OneNote,Creating new notebooks, sections, and pages in OneNote.\n- **[OpenAI WebSearch MCP](https://github.com/ConechoAI/openai-websearch-mcp)** - This is a Python-based MCP server that provides OpenAI `web_search` build-in tool.\n- **[OpenAPI](https://github.com/snaggle-ai/openapi-mcp-server)** - Interact with [OpenAPI](https://www.openapis.org/) APIs.\n- **[OpenAPI AnyApi](https://github.com/baryhuang/mcp-server-any-openapi)** - Interact with large [OpenAPI](https://www.openapis.org/) docs using built-in semantic search for endpoints. Allows for customizing the MCP server prefix.\n- **[OpenAPI Schema](https://github.com/hannesj/mcp-openapi-schema)** - Allow LLMs to explore large [OpenAPI](https://www.openapis.org/) schemas without bloating the context.\n- **[OpenCTI](https://github.com/Spathodea-Network/opencti-mcp)** - Interact with OpenCTI platform to retrieve threat intelligence data including reports, indicators, malware and threat actors.\n- **[OpenDota](https://github.com/asusevski/opendota-mcp-server)** - Interact with OpenDota API to retrieve Dota 2 match data, player statistics, and more.\n- **[OpenRPC](https://github.com/shanejonas/openrpc-mpc-server)** - Interact with and discover JSON-RPC APIs via [OpenRPC](https://open-rpc.org).\n- **[Open Strategy Partners Marketing Tools](https://github.com/open-strategy-partners/osp_marketing_tools)** - Content editing codes, value map, and positioning tools for product marketing.\n- **[Pandoc](https://github.com/vivekVells/mcp-pandoc)** - MCP server for seamless document format conversion using Pandoc, supporting Markdown, HTML, PDF, DOCX (.docx), csv and more.\n- **[PIF](https://github.com/hungryrobot1/MCP-PIF)** - A Personal Intelligence Framework (PIF), providing tools for file operations, structured reasoning, and journal-based documentation to support continuity and evolving human-AI collaboration across sessions.\n- **[Pinecone](https://github.com/sirmews/mcp-pinecone)** - MCP server for searching and uploading records to Pinecone. Allows for simple RAG features, leveraging Pinecone's Inference API.\n- **[Placid.app](https://github.com/felores/placid-mcp-server)** - Generate image and video creatives using Placid.app templates\n- **[Playwright](https://github.com/executeautomation/mcp-playwright)** - This MCP Server will help you run browser automation and webscraping using Playwright\n- **[Postman](https://github.com/shannonlal/mcp-postman)** - MCP server for running Postman Collections locally via Newman. Allows for simple execution of Postman Server and returns the results of whether the collection passed all the tests.\n- **[Productboard](https://github.com/kenjihikmatullah/productboard-mcp)** - Integrate the Productboard API into agentic workflows via MCP.\n- **[Prometheus](https://github.com/pab1it0/prometheus-mcp-server)** - Query and analyze Prometheus - open-source monitoring system.\n- **[Pulumi](https://github.com/dogukanakkaya/pulumi-mcp-server)** - MCP Server to Interact with Pulumi API, creates and lists Stacks\n- **[Pushover](https://github.com/ashiknesin/pushover-mcp)** - Send instant notifications to your devices using [Pushover.net](https://pushover.net/)\n- **[QGIS](https://github.com/jjsantos01/qgis_mcp)** - connects QGIS to Claude AI through the MCP. This integration enables prompt-assisted project creation, layer loading, code execution, and more.\n- **[QuickChart](https://github.com/GongRzhe/Quickchart-MCP-Server)** - A Model Context Protocol server for generating charts using QuickChart.io\n- **[Qwen_Max](https://github.com/66julienmartin/MCP-server-Qwen_Max)** - A Model Context Protocol (MCP) server implementation for the Qwen models.\n- **[RabbitMQ](https://github.com/kenliao94/mcp-server-rabbitmq)** - The MCP server that interacts with RabbitMQ to publish and consume messages.\n- **[RAG Web Browser](https://github.com/apify/mcp-server-rag-web-browser)** An MCP server for Apify's open-source RAG Web Browser [Actor](https://apify.com/apify/rag-web-browser) to perform web searches, scrape URLs, and return content in Markdown.\n- **[Reaper](https://github.com/dschuler36/reaper-mcp-server)** - Interact with your [Reaper](https://www.reaper.fm/) (Digital Audio Workstation) projects.\n- **[Redis](https://github.com/GongRzhe/REDIS-MCP-Server)** - Redis database operations and caching microservice server with support for key-value operations, expiration management, and pattern-based key listing.\n- **[Redis](https://github.com/prajwalnayak7/mcp-server-redis)** MCP server to interact with Redis Server, AWS Memory DB, etc for caching or other use-cases where in-memory and key-value based storage is appropriate\n- **[Rememberizer AI](https://github.com/skydeckai/mcp-server-rememberizer)** - An MCP server designed for interacting with the Rememberizer data source, facilitating enhanced knowledge retrieval.\n- **[Replicate](https://github.com/deepfates/mcp-replicate)** - Search, run and manage machine learning models on Replicate through a simple tool-based interface. Browse models, create predictions, track their status, and handle generated images.\n- **[Rquest](https://github.com/xxxbrian/mcp-rquest)** - An MCP server providing realistic browser-like HTTP request capabilities with accurate TLS/JA3/JA4 fingerprints for bypassing anti-bot measures.\n- **[Rijksmuseum](https://github.com/r-huijts/rijksmuseum-mcp)** - Interface with the Rijksmuseum API to search artworks, retrieve artwork details, access image tiles, and explore user collections.\n- **[Salesforce MCP](https://github.com/smn2gnt/MCP-Salesforce)** - Interact with Salesforce Data and Metadata\n- **[Scholarly](https://github.com/adityak74/mcp-scholarly)** - A MCP server to search for scholarly and academic articles.\n- **[scrapling-fetch](https://github.com/cyberchitta/scrapling-fetch-mcp)** - Access text content from bot-protected websites. Fetches HTML/markdown from sites with anti-automation measures using Scrapling.\n- **[SearXNG](https://github.com/ihor-sokoliuk/mcp-searxng)** - A Model Context Protocol Server for [SearXNG](https://docs.searxng.org)\n- **[ServiceNow](https://github.com/osomai/servicenow-mcp)** - A MCP server to interact with a ServiceNow instance\n- **[Shopify](https://github.com/GeLi2001/shopify-mcp)** - MCP to interact with Shopify API including order, product, customers and so on.\n- **[Siri Shortcuts](https://github.com/dvcrn/mcp-server-siri-shortcuts)** - MCP to interact with Siri Shortcuts on macOS. Exposes all Shortcuts as MCP tools.\n- **[Snowflake](https://github.com/isaacwasserman/mcp-snowflake-server)** - This MCP server enables LLMs to interact with Snowflake databases, allowing for secure and controlled data operations.\n- **[Solana Agent Kit](https://github.com/sendaifun/solana-agent-kit/tree/main/examples/agent-kit-mcp-server)** - This MCP server enables LLMs to interact with the Solana blockchain with help of Solana Agent Kit by SendAI, allowing for 40+ protcool actions and growing\n- **[Spotify](https://github.com/varunneal/spotify-mcp)** - This MCP allows an LLM to play and use Spotify.\n- **[Starwind UI](https://github.com/Boston343/starwind-ui-mcp/)** - This MCP provides relevant commands, documentation, and other information to allow LLMs to take full advantage of Starwind UI's open source Astro components.\n- **[Stripe](https://github.com/atharvagupta2003/mcp-stripe)** - This MCP allows integration with Stripe for handling payments, customers, and refunds.\n- **[ShaderToy](https://github.com/wilsonchenghy/ShaderToy-MCP)** - This MCP server lets LLMs to interact with the ShaderToy API, allowing LLMs to learn from compute shaders examples and enabling them to create complex GLSL shaders that they are previously not capable of.\n- **[TMDB](https://github.com/Laksh-star/mcp-server-tmdb)** - This MCP server integrates with The Movie Database (TMDB) API to provide movie information, search capabilities, and recommendations.\n- **[Tavily search](https://github.com/RamXX/mcp-tavily)** - An MCP server for Tavily's search & news API, with explicit site inclusions/exclusions\n- **[Telegram](https://github.com/chigwell/telegram-mcp)** - An MCP server that provides paginated chat reading, message retrieval, and message sending capabilities for Telegram through Telethon integration.\n- **[Terminal-Control](https://github.com/GongRzhe/terminal-controller-mcp)** - A MCP server that enables secure terminal command execution, directory navigation, and file system operations through a standardized interface.\n- **[TFT-Match-Analyzer](https://github.com/GeLi2001/tft-mcp-server)** - MCP server for teamfight tactics match history & match details fetching, providing user the detailed context for every match.\n- **[Ticketmaster](https://github.com/delorenj/mcp-server-ticketmaster)** - Search for events, venues, and attractions through the Ticketmaster Discovery API\n- **[Todoist](https://github.com/abhiz123/todoist-mcp-server)** - Interact with Todoist to manage your tasks.\n- **[Typesense](https://github.com/suhail-ak-s/mcp-typesense-server)** - A Model Context Protocol (MCP) server implementation that provides AI models with access to Typesense search capabilities. This server enables LLMs to discover, search, and analyze data stored in Typesense collections.\n- **[Travel Planner](https://github.com/GongRzhe/TRAVEL-PLANNER-MCP-Server)** - Travel planning and itinerary management server integrating with Google Maps API for location search, place details, and route calculations.\n- **[Unity Catalog](https://github.com/ognis1205/mcp-server-unitycatalog)** - An MCP server that enables LLMs to interact with Unity Catalog AI, supporting CRUD operations on Unity Catalog Functions and executing them as MCP tools.\n- **[Unity3d Game Engine](https://github.com/CoderGamester/mcp-unity)** - An MCP server that enables LLMs to interact with Unity3d Game Engine, supporting access to a variety of the Unit's Editor engine tools (e.g. Console Logs, Test Runner logs, Editor functions, hierarchy state, etc) and executing them as MCP tools or gather them as resources.\n- **[Unity Integration (Advanced)](https://github.com/quazaai/UnityMCPIntegration)** - Advanced Unity3d Game Engine MCP which supports ,Execution of Any Editor Related Code Directly Inside of Unity, Fetch Logs, Get Editor State and Allow File Access of the Project making it much more useful in Script Editing or asset creation.\n- **[Vega-Lite](https://github.com/isaacwasserman/mcp-vegalite-server)** - Generate visualizations from fetched data using the VegaLite format and renderer.\n- **[Video Editor](https://github.com/burningion/video-editing-mcp)** - A Model Context Protocol Server to add, edit, and search videos with [Video Jungle](https://www.video-jungle.com/).\n- **[Virtual location (Google Street View,etc.)](https://github.com/mfukushim/map-traveler-mcp)** - Integrates Google Map, Google Street View, PixAI, Stability.ai, ComfyUI API and Bluesky to provide a virtual location simulation in LLM (written in Effect.ts)\n- **[VolcEngine TOS](https://github.com/dinghuazhou/sample-mcp-server-tos)** - A sample MCP server for VolcEngine TOS that flexibly get objects from TOS.\n- **[Wanaku MCP Router](https://github.com/wanaku-ai/wanaku/)** - The Wanaku MCP Router is a SSE-based MCP server that provides an extensible routing engine that allows integrating your enterprise systems with AI agents.\n- **[Webflow](https://github.com/kapilduraphe/webflow-mcp-server)** - Interfact with the Webflow APIs\n- **[whale-tracker-mcp](https://github.com/kukapay/whale-tracker-mcp)**  -  A mcp server for tracking cryptocurrency whale transactions. \n- **[Whois MCP](https://github.com/bharathvaj-ganesan/whois-mcp)** - MCP server that performs whois lookup against domain, IP, ASN and TLD. \n- **[Wikidata MCP](https://github.com/zzaebok/mcp-wikidata)** - Wikidata MCP server that interact with Wikidata, by searching identifiers, extracting metadata, and executing sparql query.\n- **[WildFly MCP](https://github.com/wildfly-extras/wildfly-mcp)** - WildFly MCP server that enables LLM to interact with running WildFly servers (retrieve metrics, logs, invoke operations, ...).\n- **[Windows CLI](https://github.com/SimonB97/win-cli-mcp-server)** - MCP server for secure command-line interactions on Windows systems, enabling controlled access to PowerShell, CMD, and Git Bash shells.\n- **[World Bank data API](https://github.com/anshumax/world_bank_mcp_server)** - A server that fetches data indicators available with the World Bank as part of their data API\n- **[X (Twitter)](https://github.com/EnesCinr/twitter-mcp)** (by EnesCinr) - Interact with twitter API. Post tweets and search for tweets by query.\n- **[X (Twitter)](https://github.com/vidhupv/x-mcp)** (by vidhupv) - Create, manage and publish X/Twitter posts directly through Claude chat.\n- **[xcodebuild](https://github.com/ShenghaiWang/xcodebuild)**  - 🍎 Build iOS Xcode workspace/project and feed back errors to llm.\n- **[Xero-mcp-server](https://github.com/john-zhang-dev/xero-mcp)** - Enabling clients to interact with Xero system for streamlined accounting, invoicing, and business operations.\n- **[XiYan](https://github.com/XGenerationLab/xiyan_mcp_server)** - 🗄️ An MCP server that supports fetching data from a database using natural language queries, powered by XiyanSQL as the text-to-SQL LLM.\n- **[XMind](https://github.com/apeyroux/mcp-xmind)** - Read and search through your XMind directory containing XMind files.\n- **[YouTube](https://github.com/ZubeidHendricks/youtube-mcp-server)** - Comprehensive YouTube API integration for video management, Shorts creation, and analytics.\n\n## 📚 Frameworks\n\nThese are high-level frameworks that make it easier to build MCP servers or clients.\n\n### For servers\n\n* **[EasyMCP](https://github.com/zcaceres/easy-mcp/)** (TypeScript)\n- **[FastAPI to MCP auto generator](https://github.com/tadata-org/fastapi_mcp)** – A zero-configuration tool for automatically exposing FastAPI endpoints as MCP tools by **[Tadata](https://tadata.com/)**\n* **[FastMCP](https://github.com/punkpeye/fastmcp)** (TypeScript)\n* **[Foxy Contexts](https://github.com/strowk/foxy-contexts)** – A library to build MCP servers in Golang by **[strowk](https://github.com/strowk)**\n* **[Higress MCP Server Hosting](https://github.com/alibaba/higress/tree/main/plugins/wasm-go/mcp-servers)** - A solution for hosting MCP Servers by extending the API Gateway (based on Envoy) with wasm plugins.\n* **[MCP-Framework](https://mcp-framework.com)** Build MCP servers with elegance and speed in Typescript. Comes with a CLI to create your project with `mcp create app`. Get started with your first server in under 5 minutes by **[Alex Andru](https://github.com/QuantGeekDev)**\n* **[Quarkus MCP Server SDK](https://github.com/quarkiverse/quarkus-mcp-server)** (Java)\n* **[Template MCP Server](https://github.com/mcpdotdirect/template-mcp-server)** - A CLI tool to create a new Model Context Protocol server project with TypeScript support, dual transport options, and an extensible structure\n\n### For clients\n\n* **[codemirror-mcp](https://github.com/marimo-team/codemirror-mcp)** - CodeMirror extension that implements the Model Context Protocol (MCP) for resource mentions and prompt commands\n\n## 📚 Resources\n\nAdditional resources on MCP.\n\n- **[AiMCP](https://www.aimcp.info)** - A collection of MCP clients&servers to find the right mcp tools by **[Hekmon](https://github.com/hekmon8)**\n- **[Awesome Crypto MCP Servers by badkk](https://github.com/badkk/awesome-crypto-mcp-servers)** - A curated list of MCP servers by **[Luke Fan](https://github.com/badkk)**\n- **[Awesome MCP Servers by appcypher](https://github.com/appcypher/awesome-mcp-servers)** - A curated list of MCP servers by **[Stephen Akinyemi](https://github.com/appcypher)**\n- **[Awesome MCP Servers by punkpeye](https://github.com/punkpeye/awesome-mcp-servers)** (**[website](https://glama.ai/mcp/servers)**) - A curated list of MCP servers by **[Frank Fiegel](https://github.com/punkpeye)**\n- **[Awesome MCP Servers by wong2](https://github.com/wong2/awesome-mcp-servers)** (**[website](https://mcpservers.org)**) - A curated list of MCP servers by **[wong2](https://github.com/wong2)**\n- **[Discord Server](https://glama.ai/mcp/discord)** – A community discord server dedicated to MCP by **[Frank Fiegel](https://github.com/punkpeye)**\n- **[Discord Server (ModelContextProtocol)](https://discord.gg/jHEGxQu2a5)** – Connect with developers, share insights, and collaborate on projects in an active Discord community dedicated to the Model Context Protocol by **[Alex Andru](https://github.com/QuantGeekDev)**\n\n- **[MCP Badges](https://github.com/mcpx-dev/mcp-badges)** – Quickly highlight your MCP project with clear, eye-catching badges, by **[Ironben](https://github.com/nanbingxyz)**\n- **[MCP Servers Hub](https://github.com/apappascs/mcp-servers-hub)** (**[website](https://mcp-servers-hub-website.pages.dev/)**) - A curated list of MCP servers by **[apappascs](https://github.com/apappascs)**\n- **[MCP X Community](https://x.com/i/communities/1861891349609603310)** – A X community for MCP by **[Xiaoyi](https://x.com/chxy)**\n- **[mcp-cli](https://github.com/wong2/mcp-cli)** - A CLI inspector for the Model Context Protocol by **[wong2](https://github.com/wong2)**\n- **[mcp-get](https://mcp-get.com)** - Command line tool for installing and managing MCP servers by **[Michael Latman](https://github.com/michaellatman)**\n- **[mcp-guardian](https://github.com/eqtylab/mcp-guardian)** - GUI application + tools for proxying / managing control of MCP servers by **[EQTY Lab](https://eqtylab.io)**\n- **[mcp-manager](https://github.com/zueai/mcp-manager)** - Simple Web UI to install and manage MCP servers for Claude Desktop by **[Zue](https://github.com/zueai)**\n- **[MCPHub](https://github.com/Jeamee/MCPHub-Desktop)** – An Open Source MacOS & Windows GUI Desktop app for discovering, installing and managing MCP servers by **[Jeamee](https://github.com/jeamee)**\n- **[mcp.natoma.id](https://mcp.natoma.id)** - A Hosted MCP Platform to discover, install, manage and deploy MCP servers by **[Natoma Labs](https://www.natoma.id)**\n- **[mcp.run](https://mcp.run)** - A hosted registry and control plane to install & run secure + portable MCP Servers.\n- **[mcp-dockmaster](https://mcp-dockmaster.com)** - An Open-Sourced UI to install and manage MCP servers for Windows, Linux and MacOS.\n- **[MCP Servers Rating and User Reviews](http://www.deepnlp.org/store/ai-agent/mcp-server)** - Website to rate MCP servers, write authentic user reviews, and [search engine for agent & mcp](http://www.deepnlp.org/search/agent)\n- <img height=\"12\" width=\"12\" src=\"https://mkinf.io/favicon-lilac.png\" alt=\"mkinf Logo\" /> **[mkinf](https://mkinf.io)** - An Open Source registry of hosted MCP Servers to accelerate AI agent workflows.\n- **[Open-Sourced MCP Servers Directory](https://github.com/chatmcp/mcp-directory)** - A curated list of MCP servers by **[mcpso](https://mcp.so)**\n- <img height=\"12\" width=\"12\" src=\"https://opentools.com/favicon.ico\" alt=\"OpenTools Logo\" /> **[OpenTools](https://opentools.com)** - An open registry for finding, installing, and building with MCP servers by **[opentoolsteam](https://github.com/opentoolsteam)**\n- **[PulseMCP](https://www.pulsemcp.com)** ([API](https://www.pulsemcp.com/api)) - Community hub & weekly newsletter for discovering MCP servers, clients, articles, and news by **[Tadas Antanavicius](https://github.com/tadasant)**, **[Mike Coughlin](https://github.com/macoughl)**, and **[Ravina Patel](https://github.com/ravinahp)**\n- **[r/mcp](https://www.reddit.com/r/mcp)** – A Reddit community dedicated to MCP by **[Frank Fiegel](https://github.com/punkpeye)**\n- **[r/modelcontextprotocol](https://www.reddit.com/r/modelcontextprotocol)** – A Model Context Protocol community Reddit page - discuss ideas, get answers to your questions, network with like-minded people, and showcase your projects! by **[Alex Andru](https://github.com/QuantGeekDev)**\n\n\n- **[Smithery](https://smithery.ai/)** - A registry of MCP servers to find the right tools for your LLM agents by **[Henry Mao](https://github.com/calclavia)**\n- **[Toolbase](https://gettoolbase.ai)** - Desktop application that manages tools and MCP servers with just a few clicks - no coding required by **[gching](https://github.com/gching)**\n\n## 🚀 Getting Started\n\n### Using MCP Servers in this Repository\nTypescript-based servers in this repository can be used directly with `npx`.\n\nFor example, this will start the [Memory](src/memory) server:\n```sh\nnpx -y @modelcontextprotocol/server-memory\n```\n\nPython-based servers in this repository can be used directly with [`uvx`](https://docs.astral.sh/uv/concepts/tools/) or [`pip`](https://pypi.org/project/pip/). `uvx` is recommended for ease of use and setup.\n\nFor example, this will start the [Git](src/git) server:\n```sh\n# With uvx\nuvx mcp-server-git\n\n# With pip\npip install mcp-server-git\npython -m mcp_server_git\n```\n\nFollow [these](https://docs.astral.sh/uv/getting-started/installation/) instructions to install `uv` / `uvx` and [these](https://pip.pypa.io/en/stable/installation/) to install `pip`.\n\n### Using an MCP Client\nHowever, running a server on its own isn't very useful, and should instead be configured into an MCP client. For example, here's the Claude Desktop configuration to use the above server:\n\n```json\n{\n  \"mcpServers\": {\n    \"memory\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-memory\"]\n    }\n  }\n}\n```\n\nAdditional examples of using the Claude Desktop as an MCP client might look like:\n\n```json\n{\n  \"mcpServers\": {\n    \"filesystem\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-filesystem\", \"/path/to/allowed/files\"]\n    },\n    \"git\": {\n      \"command\": \"uvx\",\n      \"args\": [\"mcp-server-git\", \"--repository\", \"path/to/git/repo\"]\n    },\n    \"github\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-github\"],\n      \"env\": {\n        \"GITHUB_PERSONAL_ACCESS_TOKEN\": \"<YOUR_TOKEN>\"\n      }\n    },\n    \"postgres\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-postgres\", \"postgresql://localhost/mydb\"]\n    }\n  }\n}\n```\n\n## 🛠️ Creating Your Own Server\n\nInterested in creating your own MCP server? Visit the official documentation at [modelcontextprotocol.io](https://modelcontextprotocol.io/introduction) for comprehensive guides, best practices, and technical details on implementing MCP servers.\n\n## 🤝 Contributing\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md) for information about contributing to this repository.\n\n## 🔒 Security\n\nSee [SECURITY.md](SECURITY.md) for reporting security vulnerabilities.\n\n## 📜 License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## 💬 Community\n\n- [GitHub Discussions](https://github.com/orgs/modelcontextprotocol/discussions)\n\n## ⭐ Support\n\nIf you find MCP servers useful, please consider starring the repository and contributing new servers or improvements!\n\n---\n\nManaged by Anthropic, but built together with the community. The Model Context Protocol is open source and we encourage everyone to contribute their own servers and improvements!",
      "npm_url": "https://www.npmjs.com/package/servers",
      "npm_downloads": 2441,
      "keywords": [
        "chats",
        "servers",
        "conversations",
        "jasonmorganson servers",
        "conversations chats",
        "knowledge graph"
      ],
      "category": "memory-management"
    },
    "jlia0--servers": {
      "owner": "jlia0",
      "name": "servers",
      "url": "https://github.com/jlia0/servers",
      "imageUrl": "/freedevtools/mcp/pfp/null.webp",
      "description": "Utilizes a local knowledge graph to enable persistent memory for AI agents, allowing them to create, update, and retrieve personalized user information across chat sessions. Facilitates tailored interactions by managing entities, relations, and observations.",
      "stars": 0,
      "forks": 0,
      "license": "Unknown",
      "language": "Unknown",
      "updated_at": "",
      "readme_content": "",
      "npm_url": "https://www.npmjs.com/package/servers",
      "npm_downloads": 2441,
      "keywords": [
        "jlia0",
        "memory",
        "persistent",
        "jlia0 servers",
        "management jlia0",
        "memory ai"
      ],
      "category": "memory-management"
    },
    "joleyline--mcp-memory-libsql": {
      "owner": "joleyline",
      "name": "mcp-memory-libsql",
      "url": "https://github.com/joleyline/mcp-memory-libsql",
      "imageUrl": "/freedevtools/mcp/pfp/joleyline.webp",
      "description": "Leverage high-performance vector search and efficient knowledge storage to manage entities and relations. Provides semantic search capabilities and secure token-based authentication for connecting to remote libSQL databases.",
      "stars": 18,
      "forks": 5,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-28T13:57:56Z",
      "readme_content": "# mcp-memory-libsql\n\nA high-performance, persistent memory system for the Model Context\nProtocol (MCP) powered by libSQL. This server provides vector search\ncapabilities and efficient knowledge storage using libSQL as the\nbacking store.\n\n<a href=\"https://glama.ai/mcp/servers/22lg4lq768\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/22lg4lq768/badge\" alt=\"Glama badge\" />\n</a>\n\n## Features\n\n- 🚀 High-performance vector search using libSQL\n- 💾 Persistent storage of entities and relations\n- 🔍 Semantic search capabilities\n- 🔄 Knowledge graph management\n- 🌐 Compatible with local and remote libSQL databases\n- 🔒 Secure token-based authentication for remote databases\n\n## Configuration\n\nThis server is designed to be used as part of an MCP configuration.\nHere are examples for different environments:\n\n### Cline Configuration\n\nAdd this to your Cline MCP settings:\n\n```json\n{\n\t\"mcpServers\": {\n\t\t\"mcp-memory-libsql\": {\n\t\t\t\"command\": \"npx\",\n\t\t\t\"args\": [\"-y\", \"mcp-memory-libsql\"],\n\t\t\t\"env\": {\n\t\t\t\t\"LIBSQL_URL\": \"file:/path/to/your/database.db\"\n\t\t\t}\n\t\t}\n\t}\n}\n```\n\n### Claude Desktop with WSL Configuration\n\nFor a detailed guide on setting up this server with Claude Desktop in\nWSL, see\n[Getting MCP Server Working with Claude Desktop in WSL](https://scottspence.com/posts/getting-mcp-server-working-with-claude-desktop-in-wsl).\n\nAdd this to your Claude Desktop configuration for WSL environments:\n\n```json\n{\n\t\"mcpServers\": {\n\t\t\"mcp-memory-libsql\": {\n\t\t\t\"command\": \"wsl.exe\",\n\t\t\t\"args\": [\n\t\t\t\t\"bash\",\n\t\t\t\t\"-c\",\n\t\t\t\t\"source ~/.nvm/nvm.sh && LIBSQL_URL=file:/path/to/database.db /home/username/.nvm/versions/node/v20.12.1/bin/npx mcp-memory-libsql\"\n\t\t\t]\n\t\t}\n\t}\n}\n```\n\n### Database Configuration\n\nThe server supports both local SQLite and remote libSQL databases\nthrough the LIBSQL_URL environment variable:\n\nFor local SQLite databases:\n\n```json\n{\n\t\"env\": {\n\t\t\"LIBSQL_URL\": \"file:/path/to/database.db\"\n\t}\n}\n```\n\nFor remote libSQL databases (e.g., Turso):\n\n```json\n{\n\t\"env\": {\n\t\t\"LIBSQL_URL\": \"libsql://your-database.turso.io\",\n\t\t\"LIBSQL_AUTH_TOKEN\": \"your-auth-token\"\n\t}\n}\n```\n\nNote: When using WSL, ensure the database path uses the Linux\nfilesystem format (e.g., `/home/username/...`) rather than Windows\nformat.\n\nBy default, if no URL is provided, it will use `file:/memory-tool.db`\nin the current directory.\n\n## API\n\nThe server implements the standard MCP memory interface with\nadditional vector search capabilities:\n\n- Entity Management\n  - Create/Update entities with embeddings\n  - Delete entities\n  - Search entities by similarity\n- Relation Management\n  - Create relations between entities\n  - Delete relations\n  - Query related entities\n\n## Architecture\n\nThe server uses a libSQL database with the following schema:\n\n- Entities table: Stores entity information and embeddings\n- Relations table: Stores relationships between entities\n- Vector search capabilities implemented using libSQL's built-in\n  vector operations\n\n## Development\n\n### Publishing\n\nDue to npm 2FA requirements, publishing needs to be done manually:\n\n1. Create a changeset (documents your changes):\n\n```bash\npnpm changeset\n```\n\n2. Version the package (updates version and CHANGELOG):\n\n```bash\npnpm changeset version\n```\n\n3. Publish to npm (will prompt for 2FA code):\n\n```bash\npnpm release\n```\n\n## Contributing\n\nContributions are welcome! Please read our contributing guidelines\nbefore submitting pull requests.\n\n## License\n\nMIT License - see the [LICENSE](LICENSE) file for details.\n\n## Acknowledgments\n\n- Built on the\n  [Model Context Protocol](https://github.com/modelcontextprotocol)\n- Powered by [libSQL](https://github.com/tursodatabase/libsql)\n",
      "npm_url": "https://www.npmjs.com/package/mcp-memory-libsql",
      "npm_downloads": 4827,
      "keywords": [
        "libsql",
        "databases",
        "memory",
        "memory libsql",
        "libsql databases",
        "remote libsql"
      ],
      "category": "memory-management"
    },
    "kiranraathod--taskflow-memory-server": {
      "owner": "kiranraathod",
      "name": "taskflow-memory-server",
      "url": "https://github.com/kiranraathod/taskflow-memory-server",
      "imageUrl": "/freedevtools/mcp/pfp/kiranraathod.webp",
      "description": "Manage tasks with persistent memory to maintain project context and streamline workflow execution using intelligent planning and execution modes. The server integrates seamlessly with FastMCP-compatible clients for enhanced task and context management.",
      "stars": 3,
      "forks": 1,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-09-24T09:13:12Z",
      "readme_content": "# TaskFlow Memory Server\n\nA task management server with persistent memory architecture for maintaining context and managing workflow execution.\n\n## Overview\n\nTaskFlow Memory Server is a specialized server that combines task management features with a robust Memory Bank architecture for maintaining project context across sessions. The system is designed to support intelligent context-aware task management with persistent state.\n\n## Features\n\n- **Memory Bank System**: Maintains project context in structured Markdown files.\n- **Context Management**: Provides mechanisms for tracking and updating project context.\n- **Task Management**: Integrated functionality for task tracking and execution.\n- **Plan/Act Modes**: Supports distinct planning and execution workflows.\n- **AI Integration**: Uses Claude AI for intelligent planning and task management.\n- **Persistent State**: Maintains context between sessions for continuous workflow.\n- **MCP SDK Integration**: Uses the official Model Context Protocol TypeScript SDK.\n\n## Core Components\n\n- **Memory Manager**: Centralized component for Memory Bank file operations and validation.\n- **Context Manager**: Manages context information with caching and Memory Bank integration.\n- **Plan/Act Mode Engine**: Controls planning and execution workflows with mode-specific functionality.\n- **Async Operation Manager**: Handles long-running operations with status tracking.\n- **TaskFlow Tools**: Collection of tools for interacting with the system through the MCP protocol.\n\n## Memory Bank Structure\n\nThe Memory Bank consists of core files that maintain project context:\n\n- `projectbrief.md`: Foundation document defining core requirements and goals.\n- `productContext.md`: Why the project exists and how it should work.\n- `activeContext.md`: Current work focus and recent changes.\n- `systemPatterns.md`: System architecture and key technical decisions.\n- `techContext.md`: Technologies used and development setup.\n- `progress.md`: Project status, what works, and what's next.\n\n## Core Workflows\n\n### Plan Mode\n\n1. Read Memory Bank files to understand context\n2. Analyze current project state\n3. Develop strategy based on context\n4. Present approach for execution\n5. Update Memory Bank with plan details\n\n### Act Mode\n\n1. Check Memory Bank for relevant context\n2. Update documentation as needed\n3. Execute specific task\n4. Document changes and update Memory Bank\n5. Capture insights from task execution\n\n## Available Tools\n\n### Memory Bank Tools\n- Read, write, and update Memory Bank files\n- Get complete Memory Bank context\n- Update the entire Memory Bank\n\n### Plan-Act Tools\n- Generate project plans\n- Execute tasks\n- Switch between Plan and Act modes\n- Document task insights\n\n### System Tools\n- Get operation status and results\n- Check system status\n- Manage asynchronous operations\n\n## Getting Started\n\n1. Clone the repository\n2. Create a `.env` file with required variables (see `.env.example`)\n3. Install dependencies with `npm install`\n4. Start the server with `npm start`\n\nFor detailed setup and usage instructions, see the [Getting Started Guide](docs/getting-started.md).\n\n## Environment Configuration\n\n```\nANTHROPIC_API_KEY=your_anthropic_api_key\nMODEL=claude-3-7-sonnet-20250219\nMAX_TOKENS=64000\nTEMPERATURE=0.2\nMEMORY_BANK_PATH=./memory-bank\nLOG_LEVEL=info\n```\n\n## Using with MCP-compatible clients\n\nTaskFlow Memory Server can be used with clients that support the Model Context Protocol (MCP). Configure your client to connect to the server and use the provided tools for interacting with the Memory Bank and managing tasks.\n\nExample workflow:\n```\nCan you switch to Plan mode and generate a plan for implementing the file system integration?\n```\n\n### Claude for Desktop Integration\n\nTaskFlow Memory Server is compatible with Claude for Desktop. To configure:\n\n1. Navigate to your Claude for Desktop configuration directory\n2. Copy the configuration from `config/claude-desktop.json`:\n   ```json\n   {\n       \"mcpServers\": {\n           \"taskflow\": {\n               \"command\": \"node\",\n               \"args\": [\n                   \"C:\\\\PATH\\\\TO\\\\taskflow-memory-server\\\\server.js\"\n               ]\n           }\n       }\n   }\n   ```\n3. Update the path in the `args` array to point to your installation of TaskFlow Memory Server\n4. Save the file and restart Claude for Desktop\n5. Select \"taskflow\" as your server in Claude for Desktop\n\nThe TaskFlow Memory Server provides Claude for Desktop with:\n- Persistent memory for context across conversations\n- Task planning and execution workflow\n- Structured knowledge management\n\nCommand examples:\n```\nClaude, can you create a task plan for my project?\nClaude, please update the memory bank with our recent progress\nClaude, retrieve project context from memory bank\n```\n\n## Documentation Updates\n\nMemory Bank files should be updated when:\n\n1. Discovering new project patterns\n2. Implementing significant changes\n3. When context needs clarification\n\nUse the `update_memory_file` tool to update specific Memory Bank files with new information.\n\n## Migration to Official MCP SDK\n\nThis project has been migrated from the third-party FastMCP framework to the official Model Context Protocol (MCP) TypeScript SDK. For details about the migration, see [MIGRATION.md](MIGRATION.md).\n\n## Documentation\n\n- [Getting Started Guide](docs/getting-started.md) - Basic setup and usage instructions\n- [Technical Reference](docs/technical-reference.md) - Detailed technical documentation\n- [Migration Guide](MIGRATION.md) - Details about the migration to the official MCP SDK\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "taskflow",
        "fastmcp",
        "memory",
        "kiranraathod taskflow",
        "taskflow memory",
        "memory management"
      ],
      "category": "memory-management"
    },
    "leonskenidy--omi-mcp": {
      "owner": "leonskenidy",
      "name": "omi-mcp",
      "url": "https://github.com/leonskenidy/omi-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/leonskenidy.webp",
      "description": "Provides access to Omi conversations and memories through a standardized MCP interface, enabling reading, creating, and managing these elements efficiently within LLM workflows.",
      "stars": 1,
      "forks": 0,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-08-26T06:05:08Z",
      "readme_content": "# Omi MCP Server\n[![smithery badge](https://smithery.ai/badge/@fourcolors/omi-mcp)](https://smithery.ai/server/@fourcolors/omi-mcp)\n\nThis project provides a Model Context Protocol (MCP) server for interacting with the Omi API. The server provides tools for reading conversations and memories, as well as creating new conversations and memories.\n\n## Setup\n\n1. Clone the repository\n2. Install dependencies with `npm install`\n3. Create a `.env` file with the following variables:\n   ```\n   API_KEY=your_api_key\n   APP_ID=your_app_id\n   ```\n\n## Usage\n\n### Installing via Smithery\n\nTo install Omi MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@fourcolors/omi-mcp):\n\n```bash\nnpx -y @smithery/cli install @fourcolors/omi-mcp --client claude\n```\n\n### Building the Server\n\n```bash\nnpm run build\n```\n\n### Running the Server\n\n```bash\nnpm run start\n```\n\n### Development Mode\n\nFor development with hot-reloading:\n\n```bash\nnpm run dev\n```\n\n### Testing the Server\n\nA simple test client is included to interact with the MCP server. After building the project, run:\n\n```bash\nnpm run test\n```\n\nOr directly:\n\n```bash\n./test-mcp-client.js\n```\n\nThis will start the MCP server and provide an interactive menu to test the available tools. The test client uses a default test user ID (`test-user-123`) for all operations.\n\n### Clean and Rebuild\n\nTo clean the build directory and rebuild from scratch:\n\n```bash\nnpm run rebuild\n```\n\n## Configuration with Claude and Cursor\n\n### Claude Configuration\n\nTo use this MCP server with Claude via Anthropic Console or API:\n\n1. Start the MCP server locally:\n\n   ```bash\n   npm run start\n   ```\n\n2. When setting up your Claude conversation, configure the MCP connection:\n\n   ```json\n   {\n   \t\"mcp_config\": {\n   \t\t\"transports\": [\n   \t\t\t{\n   \t\t\t\t\"type\": \"stdio\",\n   \t\t\t\t\"executable\": {\n   \t\t\t\t\t\"path\": \"/path/to/your/omi-mcp-local/dist/index.js\",\n   \t\t\t\t\t\"args\": []\n   \t\t\t\t}\n   \t\t\t}\n   \t\t]\n   \t}\n   }\n   ```\n\n3. Example prompt to Claude:\n\n   ```\n   Please fetch the latest 5 conversations for user \"user123\" using the Omi API.\n   ```\n\n4. Claude will use the MCP to execute the `read_omi_conversations` tool:\n   ```json\n   {\n   \t\"id\": \"req-1\",\n   \t\"type\": \"request\",\n   \t\"method\": \"tools.read_omi_conversations\",\n   \t\"params\": {\n   \t\t\"user_id\": \"user123\",\n   \t\t\"limit\": 5\n   \t}\n   }\n   ```\n\n### Cursor Configuration\n\nTo use this MCP server with Cursor:\n\n1. Start the MCP server in a terminal:\n\n   ```bash\n   npm run start\n   ```\n\n2. In Cursor, go to Settings > Extensions > MCP Servers\n\n3. Add a new MCP server with these settings:\n\n   - Name: Omi API\n   - URL: stdio:/path/to/your/omi-mcp-local/dist/index.js\n   - Enable the server\n\n4. Now you can use the Omi tools directly within Cursor. For example:\n\n   ```\n   @Omi API Please fetch memories for user \"user123\" and summarize them.\n   ```\n\n5. Cursor will communicate with your MCP server to execute the necessary API calls.\n\n## Available Tools\n\nThe MCP server provides the following tools:\n\n### read_omi_conversations\n\nRetrieves conversations from Omi for a specific user, with optional filters.\n\nParameters:\n\n- `user_id` (string): The user ID to fetch conversations for\n- `limit` (number, optional): Maximum number of conversations to return\n- `offset` (number, optional): Number of conversations to skip for pagination\n- `include_discarded` (boolean, optional): Whether to include discarded conversations\n- `statuses` (string, optional): Comma-separated list of statuses to filter conversations by\n\n### read_omi_memories\n\nRetrieves memories from Omi for a specific user.\n\nParameters:\n\n- `user_id` (string): The user ID to fetch memories for\n- `limit` (number, optional): Maximum number of memories to return\n- `offset` (number, optional): Number of memories to skip for pagination\n\n### create_omi_conversation\n\nCreates a new conversation in Omi for a specific user.\n\nParameters:\n\n- `text` (string): The full text content of the conversation\n- `user_id` (string): The user ID to create the conversation for\n- `text_source` (string): Source of the text content (options: \"audio_transcript\", \"message\", \"other_text\")\n- `started_at` (string, optional): When the conversation/event started (ISO 8601 format)\n- `finished_at` (string, optional): When the conversation/event ended (ISO 8601 format)\n- `language` (string, optional): Language code (default: \"en\")\n- `geolocation` (object, optional): Location data for the conversation\n  - `latitude` (number): Latitude coordinate\n  - `longitude` (number): Longitude coordinate\n- `text_source_spec` (string, optional): Additional specification about the source\n\n### create_omi_memories\n\nCreates new memories in Omi for a specific user.\n\nParameters:\n\n- `user_id` (string): The user ID to create memories for\n- `text` (string, optional): The text content from which memories will be extracted\n- `memories` (array, optional): An array of explicit memory objects to be created directly\n  - `content` (string): The content of the memory\n  - `tags` (array of strings, optional): Tags for the memory\n- `text_source` (string, optional): Source of the text content\n- `text_source_spec` (string, optional): Additional specification about the source\n\n## Testing\n\nTo test the MCP server, you can use the provided test client:\n\n```bash\nnode test-mcp-client.js\n```\n\nThis will start an interactive test client that allows you to:\n\n1. Get conversations\n2. Get memories\n3. Create a conversation\n4. Quit\n\nThe test client uses a default test user ID (`test-user-123`) for all operations.\n\n## Logging\n\nThe MCP server includes built-in logging functionality that writes to both the console and a log file. This is useful for debugging and monitoring server activity.\n\n### Log File Location\n\nLogs are written to `logs/mcp-server.log` in your project directory. The log file includes timestamps and detailed information about:\n\n- Server startup and shutdown\n- All API requests and responses\n- Error messages and stack traces\n- API calls to Omi\n- Request parameters and response data\n\n### Viewing Logs\n\nYou can view the logs in real-time using the `tail` command:\n\n```bash\ntail -f logs/mcp-server.log\n```\n\nThis will show you live updates as the server processes requests and interacts with the Omi API.\n\n### Log Format\n\nEach log entry follows this format:\n\n```\n[2024-03-21T12:34:56.789Z] Log message here\n```\n\nThe timestamp is in ISO 8601 format, making it easy to correlate events and debug issues.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcp",
        "memory",
        "llm",
        "omi mcp",
        "memory management",
        "mcp interface"
      ],
      "category": "memory-management"
    },
    "mcp-get--community-servers": {
      "owner": "mcp-get",
      "name": "community-servers",
      "url": "https://github.com/mcp-get/community-servers",
      "imageUrl": "/freedevtools/mcp/pfp/mcp-get.webp",
      "description": "Provides macOS-specific system information and operations, including retrieval of CPU, memory, disk, and network details, as well as enabling native macOS notifications.",
      "stars": 64,
      "forks": 19,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-22T04:01:08Z",
      "readme_content": "# MCP Get Community Servers\n\nThis repository contains a collection of community-maintained Model Context Protocol (MCP) servers. All servers are automatically listed on the [MCP Get registry](https://mcp-get.com) and can be viewed and installed via CLI:\n\n```bash\nnpx @michaellatman/mcp-get@latest list\n```\n\n> **Note:** While we review all servers in this repository, they are maintained by their respective creators who are responsible for their functionality and maintenance.\n\n## Available Servers\n\n- **[LLM.txt Server](src/server-llm-txt)** - A server for searching and retrieving content from [LLM.txt](https://llmstxt.org/) files. Provides tools for listing available files, fetching content, and performing contextual searches.\n- **[Curl Server](src/server-curl)** - A server that allows LLMs to make HTTP requests to any URL using a curl-like interface. Supports all common HTTP methods, custom headers, request body, and configurable timeouts.\n- **[macOS Server](src/server-macos)** - A server that provides macOS-specific system information and operations.\n\n## Installation\n\nYou can install any server using the MCP Get CLI:\n\n```bash\nnpx @michaellatman/mcp-get@latest install <server-name>\n```\n\nFor example:\n\n```bash\nnpx @michaellatman/mcp-get@latest install @mcp-get-community/server-curl\n```\n\n## Development\n\nTo run in development mode with automatic recompilation:\n\n```bash\nnpm install\nnpm run watch\n```\n\n## Contributing\n\nWe welcome contributions! Please feel free to submit a Pull Request.\n\n## License\n\nWhile this repository's structure and documentation are licensed under the MIT License, individual servers may have their own licenses. Please check each server's documentation in the [src](src) directory for its specific license terms.\n\n## Support\n\nIf you find these servers useful, please consider starring the repository!\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcp",
        "macos",
        "servers",
        "provides macos",
        "mcp community",
        "macos specific"
      ],
      "category": "memory-management"
    },
    "mem0ai--mem0-mcp": {
      "owner": "mem0ai",
      "name": "mem0-mcp",
      "url": "https://github.com/mem0ai/mem0-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/mem0ai.webp",
      "description": "Store and retrieve user-specific memories to maintain context and make informed decisions based on past interactions using a simple API. Features relevance scoring to enhance memory management with user preferences.",
      "stars": 473,
      "forks": 94,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-10-02T02:12:07Z",
      "readme_content": "# MCP Server with Mem0 for Managing Coding Preferences\n\nThis demonstrates a structured approach for using an [MCP](https://modelcontextprotocol.io/introduction) server with [mem0](https://mem0.ai) to manage coding preferences efficiently. The server can be used with Cursor and provides essential tools for storing, retrieving, and searching coding preferences.\n\n## Installation\n\n1. Clone this repository\n2. Initialize the `uv` environment:\n\n```bash\nuv venv\n```\n\n3. Activate the virtual environment:\n\n```bash\nsource .venv/bin/activate\n```\n\n4. Install the dependencies using `uv`:\n\n```bash\n# Install in editable mode from pyproject.toml\nuv pip install -e .\n```\n\n5. Update `.env` file in the root directory with your mem0 API key:\n\n```bash\nMEM0_API_KEY=your_api_key_here\n```\n\n## Usage\n\n1. Start the MCP server:\n\n```bash\nuv run main.py\n```\n\n2. In Cursor, connect to the SSE endpoint, follow this [doc](https://docs.cursor.com/context/model-context-protocol) for reference:\n\n```\nhttp://0.0.0.0:8080/sse\n```\n\n3. Open the Composer in Cursor and switch to `Agent` mode.\n\n## Demo with Cursor\n\nhttps://github.com/user-attachments/assets/56670550-fb11-4850-9905-692d3496231c\n\n## Features\n\nThe server provides three main tools for managing code preferences:\n\n1. `add_coding_preference`: Store code snippets, implementation details, and coding patterns with comprehensive context including:\n   - Complete code with dependencies\n   - Language/framework versions\n   - Setup instructions\n   - Documentation and comments\n   - Example usage\n   - Best practices\n\n2. `get_all_coding_preferences`: Retrieve all stored coding preferences to analyze patterns, review implementations, and ensure no relevant information is missed.\n\n3. `search_coding_preferences`: Semantically search through stored coding preferences to find relevant:\n   - Code implementations\n   - Programming solutions\n   - Best practices\n   - Setup guides\n   - Technical documentation\n\n## Why?\n\nThis implementation allows for a persistent coding preferences system that can be accessed via MCP. The SSE-based server can run as a process that agents connect to, use, and disconnect from whenever needed. This pattern fits well with \"cloud-native\" use cases where the server and clients can be decoupled processes on different nodes.\n\n### Server\n\nBy default, the server runs on 0.0.0.0:8080 but is configurable with command line arguments like:\n\n```\nuv run main.py --host <your host> --port <your port>\n```\n\nThe server exposes an SSE endpoint at `/sse` that MCP clients can connect to for accessing the coding preferences management tools.\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "memory",
        "mem0",
        "mem0ai",
        "memory management",
        "management mem0ai",
        "specific memories"
      ],
      "category": "memory-management"
    },
    "modelcontextprotocol--servers": {
      "owner": "modelcontextprotocol",
      "name": "servers",
      "url": "https://github.com/modelcontextprotocol/servers",
      "imageUrl": "/freedevtools/mcp/pfp/modelcontextprotocol.webp",
      "description": "A basic implementation of persistent memory using a local knowledge graph that enables storage and retrieval of user-specific information across chats by defining entities and their relationships.",
      "stars": 69426,
      "forks": 8224,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T09:39:35Z",
      "readme_content": "# Model Context Protocol servers\n\nThis repository is a collection of *reference implementations* for the [Model Context Protocol](https://modelcontextprotocol.io/) (MCP), as well as references to community-built servers and additional resources.\n\nThe servers in this repository showcase the versatility and extensibility of MCP, demonstrating how it can be used to give Large Language Models (LLMs) secure, controlled access to tools and data sources.\nTypically, each MCP server is implemented with an MCP SDK:\n\n- [C# MCP SDK](https://github.com/modelcontextprotocol/csharp-sdk)\n- [Go MCP SDK](https://github.com/modelcontextprotocol/go-sdk)\n- [Java MCP SDK](https://github.com/modelcontextprotocol/java-sdk)\n- [Kotlin MCP SDK](https://github.com/modelcontextprotocol/kotlin-sdk)\n- [PHP MCP SDK](https://github.com/modelcontextprotocol/php-sdk)\n- [Python MCP SDK](https://github.com/modelcontextprotocol/python-sdk)\n- [Ruby MCP SDK](https://github.com/modelcontextprotocol/ruby-sdk)\n- [Rust MCP SDK](https://github.com/modelcontextprotocol/rust-sdk)\n- [Swift MCP SDK](https://github.com/modelcontextprotocol/swift-sdk)\n- [TypeScript MCP SDK](https://github.com/modelcontextprotocol/typescript-sdk)\n\n> [!NOTE]\n> Lists in this README are maintained in alphabetical order to minimize merge conflicts when adding new items.\n\n## 🌟 Reference Servers\n\nThese servers aim to demonstrate MCP features and the official SDKs.\n\n- **[Everything](src/everything)** - Reference / test server with prompts, resources, and tools.\n- **[Fetch](src/fetch)** - Web content fetching and conversion for efficient LLM usage.\n- **[Filesystem](src/filesystem)** - Secure file operations with configurable access controls.\n- **[Git](src/git)** - Tools to read, search, and manipulate Git repositories.\n- **[Memory](src/memory)** - Knowledge graph-based persistent memory system.\n- **[Sequential Thinking](src/sequentialthinking)** - Dynamic and reflective problem-solving through thought sequences.\n- **[Time](src/time)** - Time and timezone conversion capabilities.\n\n### Archived\n\nThe following reference servers are now archived and can be found at [servers-archived](https://github.com/modelcontextprotocol/servers-archived).\n\n- **[AWS KB Retrieval](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/aws-kb-retrieval-server)** - Retrieval from AWS Knowledge Base using Bedrock Agent Runtime.\n- **[Brave Search](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/brave-search)** - Web and local search using Brave's Search API.  Has been replaced by the [official server](https://github.com/brave/brave-search-mcp-server).\n- **[EverArt](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/everart)** - AI image generation using various models.\n- **[GitHub](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/github)** - Repository management, file operations, and GitHub API integration.\n- **[GitLab](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/gitlab)** - GitLab API, enabling project management.\n- **[Google Drive](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/gdrive)** - File access and search capabilities for Google Drive.\n- **[Google Maps](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/google-maps)** - Location services, directions, and place details.\n- **[PostgreSQL](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/postgres)** - Read-only database access with schema inspection.\n- **[Puppeteer](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/puppeteer)** - Browser automation and web scraping.\n- **[Redis](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/redis)** - Interact with Redis key-value stores.\n- **[Sentry](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/sentry)** - Retrieving and analyzing issues from Sentry.io.\n- **[Slack](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/slack)** - Channel management and messaging capabilities. Now maintained by [Zencoder](https://github.com/zencoderai/slack-mcp-server)\n- **[SQLite](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/sqlite)** - Database interaction and business intelligence capabilities.\n\n## 🤝 Third-Party Servers\n\n### 🎖️ Official Integrations\n\nOfficial integrations are maintained by companies building production ready MCP servers for their platforms.\n\n- <img height=\"12\" width=\"12\" src=\"https://www.21st.dev/favicon.ico\" alt=\"21st.dev Logo\" /> **[21st.dev Magic](https://github.com/21st-dev/magic-mcp)** - Create crafted UI components inspired by the best 21st.dev design engineers.\n- <img height=\"12\" width=\"12\" src=\"https://framerusercontent.com/images/LpSK1tSZweomrAHOMAj9Gea96lA.svg\" alt=\"Paragon Logo\" /> **[ActionKit by Paragon](https://github.com/useparagon/paragon-mcp)** - Connect to 130+ SaaS integrations (e.g. Slack, Salesforce, Gmail) with Paragon’s [ActionKit](https://www.useparagon.com/actionkit) API.\n- <img height=\"12\" width=\"12\" src=\"https://invoxx-public-bucket.s3.eu-central-1.amazonaws.com/frontend-resources/adfin-logo-small.svg\" alt=\"Adfin Logo\" /> **[Adfin](https://github.com/Adfin-Engineering/mcp-server-adfin)** - The only platform you need to get paid - all payments in one place, invoicing and accounting reconciliations with [Adfin](https://www.adfin.com/).\n- <img height=\"12\" width=\"12\" src=\"https://github.com/AgentOps-AI/agentops/blob/main/docs/favicon.png\" alt=\"AgentOps Logo\" /> **[AgentOps](https://github.com/AgentOps-AI/agentops-mcp)** - Provide observability and tracing for debugging AI agents with [AgentOps](https://www.agentops.ai/) API.\n- <img height=\"12\" width=\"12\" src=\"https://www.agentql.com/favicon/favicon.png\" alt=\"AgentQL Logo\" /> **[AgentQL](https://github.com/tinyfish-io/agentql-mcp)** - Enable AI agents to get structured data from unstructured web with [AgentQL](https://www.agentql.com/).\n- <img height=\"12\" width=\"12\" src=\"https://agentrpc.com/favicon.ico\" alt=\"AgentRPC Logo\" /> **[AgentRPC](https://github.com/agentrpc/agentrpc)** - Connect to any function, any language, across network boundaries using [AgentRPC](https://www.agentrpc.com/).\n- **[Agentset](https://github.com/agentset-ai/mcp-server)** - RAG for your knowledge base connected to [Agentset](https://agentset.ai).\n- <img height=\"12\" width=\"12\" src=\"https://aiven.io/favicon.ico\" alt=\"Aiven Logo\" /> **[Aiven](https://github.com/Aiven-Open/mcp-aiven)** - Navigate your [Aiven projects](https://go.aiven.io/mcp-server) and interact with the PostgreSQL®, Apache Kafka®, ClickHouse® and OpenSearch® services\n- <img height=\"12\" width=\"12\" src=\"https://www.alation.com/resource-center/download/7p3vnbbznfiw/34FMtBTex5ppvs2hNYa9Fc/c877c37e88e5339878658697c46d2d58/Alation-Logo-Bug-Primary.svg\" alt=\"Alation Logo\" /> **[Alation](https://github.com/Alation/alation-ai-agent-sdk)** - Unlock the power of the enterprise Data Catalog by harnessing tools provided by the Alation MCP server.\n- <img height=\"12\" width=\"12\" src=\"https://i.postimg.cc/5NYw9qjS/alby-icon-head-yellow-500x500.png\" alt=\"Alby Logo\" /> **[Alby Bitcoin Payments](https://github.com/getAlby/mcp)** - Connect any bitcoin lightning wallet to your agent to send and receive instant payments globally with your agent.\n- **[Algolia](https://github.com/algolia/mcp)** - Use AI agents to provision, configure, and query your [Algolia](https://algolia.com) search indices.\n- <img height=\"12\" width=\"12\" src=\"https://img.alicdn.com/imgextra/i4/O1CN01epkXwH1WLAXkZfV6N_!!6000000002771-2-tps-200-200.png\" alt=\"Alibaba Cloud AnalyticDB for MySQL Logo\" /> **[Alibaba Cloud AnalyticDB for MySQL](https://github.com/aliyun/alibabacloud-adb-mysql-mcp-server)** - Connect to an [AnalyticDB for MySQL](https://www.alibabacloud.com/en/product/analyticdb-for-mysql) cluster for getting database or table metadata, querying and analyzing data. It will be supported to add the OpenAPI for cluster operation in the future.\n- <img height=\"12\" width=\"12\" src=\"https://github.com/aliyun/alibabacloud-adbpg-mcp-server/blob/master/images/AnalyticDB.png\" alt=\"Alibaba Cloud AnalyticDB for PostgreSQL Logo\" /> **[Alibaba Cloud AnalyticDB for PostgreSQL](https://github.com/aliyun/alibabacloud-adbpg-mcp-server)** - An MCP server to connect to [AnalyticDB for PostgreSQL](https://github.com/aliyun/alibabacloud-adbpg-mcp-server) instances, query and analyze data.\n- <img height=\"12\" width=\"12\" src=\"https://img.alicdn.com/imgextra/i3/O1CN0101UWWF1UYn3rAe3HU_!!6000000002530-2-tps-32-32.png\" alt=\"DataWorks Logo\" /> **[Alibaba Cloud DataWorks](https://github.com/aliyun/alibabacloud-dataworks-mcp-server)** - A Model Context Protocol (MCP) server that provides tools for AI, allowing it to interact with the [DataWorks](https://www.alibabacloud.com/help/en/dataworks/) Open API through a standardized interface. This implementation is based on the Alibaba Cloud Open API and enables AI agents to perform cloud resources operations seamlessly.\n- <img height=\"12\" width=\"12\" src=\"https://opensearch-shanghai.oss-cn-shanghai.aliyuncs.com/ouhuang/aliyun-icon.png\" alt=\"Alibaba Cloud OpenSearch Logo\" /> **[Alibaba Cloud OpenSearch](https://github.com/aliyun/alibabacloud-opensearch-mcp-server)** - This MCP server equips AI Agents with tools to interact with [OpenSearch](https://help.aliyun.com/zh/open-search/?spm=5176.7946605.J_5253785160.6.28098651AaYZXC) through a standardized and extensible interface.\n- <img height=\"12\" width=\"12\" src=\"https://github.com/aliyun/alibaba-cloud-ops-mcp-server/blob/master/image/alibaba-cloud.png\" alt=\"Alibaba Cloud OPS Logo\" /> **[Alibaba Cloud OPS](https://github.com/aliyun/alibaba-cloud-ops-mcp-server)** - Manage the lifecycle of your Alibaba Cloud resources with [CloudOps Orchestration Service](https://www.alibabacloud.com/en/product/oos) and Alibaba Cloud OpenAPI.\n- <img height=\"12\" width=\"12\" src=\"https://github.com/aliyun/alibabacloud-rds-openapi-mcp-server/blob/main/assets/alibabacloudrds.png\" alt=\"Alibaba Cloud RDS MySQL Logo\" /> **[Alibaba Cloud RDS](https://github.com/aliyun/alibabacloud-rds-openapi-mcp-server)** - An MCP server designed to interact with the Alibaba Cloud RDS OpenAPI, enabling programmatic management of RDS resources via an LLM.\n- <img height=\"12\" width=\"12\" src=\"https://www.alipayplus.com/favicon.ico\" alt=\"AlipayPlus Logo\" /> **[AlipayPlus](https://github.com/alipay/global-alipayplus-mcp)** - Connect your AI Agents to AlipayPlus Checkout Payment.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.allvoicelab.com/resources/workbench/dist/icon-dark.ico\" alt=\"AllVoiceLab Logo\" /> **[AllVoiceLab](https://www.allvoicelab.com/mcp)** - An AI voice toolkit with TTS, voice cloning, and video translation, now available as an MCP server for smarter agent integration.\n- <img height=\"12\" width=\"12\" src=\"https://files.alpaca.markets/webassets/favicon-32x32.png\" alt=\"Alpaca Logo\" /> **[Alpaca](https://github.com/alpacahq/alpaca-mcp-server)** – Alpaca's MCP server lets you trade stocks and options, analyze market data, and build strategies through [Alpaca's Trading API](https://alpaca.markets/)\n- <img height=\"12\" width=\"12\" src=\"https://www.alphavantage.co/logo.png/\" alt=\"AlphaVantage Logo\" /> **[AlphaVantage](https://mcp.alphavantage.co/)** - Connect to 100+ APIs for financial market data, including stock prices, fundamentals, and more from [AlphaVantage](https://www.alphavantage.co)\n- <img height=\"12\" width=\"12\" src=\"https://alttester.com/app/themes/alttester-sage-theme/public/images/logo-alttester.038ec8.png\" alt=\"AltTester Logo\" /> **[AltTester®](https://alttester.com/docs/desktop/latest/pages/ai-extension.html)** - Use AltTester® capabilities to connect and test your Unity or Unreal game. Write game test automation faster and smarter, using [AltTester](https://alttester.com) and the AltTester® MCP server. \n- <img height=\"12\" width=\"12\" src=\"https://www.antom.com/favicon.ico\" alt=\"Antom Logo\" /> **[Antom](https://github.com/alipay/global-antom-mcp)** - Connect your AI Agents to Antom Checkout Payment.\n- <img height=\"12\" width=\"12\" src=\"https://developers.anytype.io/img/favicon.ico\" alt=\"Anytype Logo\" /> **[Anytype](https://github.com/anyproto/anytype-mcp)** - An MCP server enabling AI assistants to interact with [Anytype](https://anytype.io) - a local and collaborative wiki - to organize objects, lists, and more through natural language.\n- <img height=\"12\" width=\"12\" src=\"https://doris.apache.org/images/favicon.ico\" alt=\"Apache Doris Logo\" /> **[Apache Doris](https://github.com/apache/doris-mcp-server)** - MCP Server For [Apache Doris](https://doris.apache.org/), an MPP-based real-time data warehouse.\n- <img height=\"12\" width=\"12\" src=\"https://iotdb.apache.org/img/logo.svg\" alt=\"Apache IoTDB Logo\" /> **[Apache IoTDB](https://github.com/apache/iotdb-mcp-server)** - MCP Server for [Apache IoTDB](https://github.com/apache/iotdb) database and its tools\n- **[Apache Pinot](https://github.com/startreedata/mcp-pinot)** – MCP server for running real - time analytics queries on Apache Pinot, an open-source OLAP database built for high-throughput, low-latency powering real-time applications.\n- <img height=\"12\" width=\"12\" src=\"https://apify.com/favicon.ico\" alt=\"Apify Logo\" /> **[Apify](https://github.com/apify/apify-mcp-server)** - Use 6,000+ pre-built cloud tools to extract data from websites, e-commerce, social media, search engines, maps, and more\n- <img height=\"12\" width=\"12\" src=\"https://2052727.fs1.hubspotusercontent-na1.net/hubfs/2052727/cropped-cropped-apimaticio-favicon-1-32x32.png\" alt=\"APIMatic Logo\" /> **[APIMatic MCP](https://github.com/apimatic/apimatic-validator-mcp)** - APIMatic MCP Server is used to validate OpenAPI specifications using [APIMatic](https://www.apimatic.io/). The server processes OpenAPI files and returns validation summaries by leveraging APIMatic's API.\n- <img height=\"12\" width=\"12\" src=\"https://apollo-server-landing-page.cdn.apollographql.com/_latest/assets/favicon.png\" alt=\"Apollo Graph Logo\" /> **[Apollo MCP Server](https://github.com/apollographql/apollo-mcp-server/)** - Connect your GraphQL APIs to AI agents\n- <img height=\"12\" width=\"12\" src=\"https://developer.aqara.com/favicon.ico\" alt=\"Aqara Logo\" /> **[Aqara MCP Server](https://github.com/aqara/aqara-mcp-server/)** - Control  [Aqara](https://www.aqara.com/) smart home devices, query status, execute scenes, and much more using natural language.\n- <img height=\"12\" width=\"12\" src=\"https://media.licdn.com/dms/image/v2/C4D0BAQEeD7Dxbpadkw/company-logo_200_200/company-logo_200_200/0/1644692667545/archbee_logo?e=2147483647&v=beta&t=lTi9GRIoqzG6jN3kJC26uZWh0q3uiQelsH6mGoq_Wfw\" alt=\"Archbee Logo\" /> **[Archbee](https://www.npmjs.com/package/@archbee/mcp)** - Write and publish documentation that becomes the trusted source for instant answers with AI. Stop cobbling tools and use [Archbee](https://www.archbee.com/) — the first complete documentation platform.\n- <img height=\"12\" width=\"12\" src=\"https://phoenix.arize.com/wp-content/uploads/2023/04/cropped-Favicon-32x32.png\" alt=\"Arize-Phoenix Logo\" /> **[Arize Phoenix](https://github.com/Arize-ai/phoenix/tree/main/js/packages/phoenix-mcp)** - Inspect traces, manage prompts, curate datasets, and run experiments using [Arize Phoenix](https://github.com/Arize-ai/phoenix), an open-source AI and LLM observability tool.\n- <img height=\"12\" width=\"12\" src=\"https://731523176-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FaVUBXRZbpAgtjYf5HsvO%2Fuploads%2FaRRrVVocXCTr6GkepfCx%2Flogo_color.svg?alt=media&token=3ba24089-0ab2-421f-a9d9-41f2f94f954a\" alt=\"Armor Logo\" /> **[Armor Crypto MCP](https://github.com/armorwallet/armor-crypto-mcp)** - MCP to interface with multiple blockchains, staking, DeFi, swap, bridging, wallet management, DCA, Limit Orders, Coin Lookup, Tracking and more.\n- <img height=\"12\" width=\"12\" src=\"https://console.asgardeo.io/app/libs/themes/wso2is/assets/images/branding/favicon.ico\" alt=\"Asgardeo Logo\" /> **[Asgardeo](https://github.com/asgardeo/asgardeo-mcp-server)** - MCP server to interact with your [Asgardeo](https://wso2.com/asgardeo) organization through LLM tools.\n- <img height=\"12\" width=\"12\" src=\"https://www.datastax.com/favicon-32x32.png\" alt=\"DataStax logo\" /> **[Astra DB](https://github.com/datastax/astra-db-mcp)** - Comprehensive tools for managing collections and documents in a [DataStax Astra DB](https://www.datastax.com/products/datastax-astra) NoSQL database with a full range of operations such as create, update, delete, find, and associated bulk actions.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/66598898fd13d51606c3215d/66ccbfef13bd8bc19d587578_favicon-32x32.png\" alt=\"Atla Logo\" /> **[Atla](https://github.com/atla-ai/atla-mcp-server)** - Enable AI agents to interact with the [Atla API](https://docs.atla-ai.com/) for state-of-the-art LLMJ evaluation.\n- <img height=\"12\" width=\"12\" src=\"https://assets.atlan.com/assets/atlan-a-logo-blue-background.png\" alt=\"Atlan Logo\" /> **[Atlan](https://github.com/atlanhq/agent-toolkit/tree/main/modelcontextprotocol)** - The Atlan Model Context Protocol server allows you to interact with the [Atlan](https://www.atlan.com/) services through multiple tools.\n- <img height=\"12\" width=\"12\" src=\"https://www.atlassian.com/favicon.ico\" alt=\"Atlassian Logo\" /> **[Atlassian](https://www.atlassian.com/platform/remote-mcp-server)** - Securely interact with Jira work items and Confluence pages, and search across both.\n- <img height=\"12\" width=\"12\" src=\"https://res.oafimg.cn/-/737b3b3ffed9b19e/logo.png\" alt=\"AtomGit Logo\" /> **[AtomGit](https://atomgit.com/atomgit-open-source-ecosystem/atomgit-mcp-server)** - Official AtomGit server for integration with repository management, PRs, issues, branches, labels, and more.\n- <img height=\"12\" width=\"12\" src=\"https://resources.audiense.com/hubfs/favicon-1.png\" alt=\"Audiense Logo\" /> **[Audiense Insights](https://github.com/AudienseCo/mcp-audiense-insights)** - Marketing insights and audience analysis from [Audiense](https://www.audiense.com/products/audiense-insights) reports, covering demographic, cultural, influencer, and content engagement analysis.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.auth0.com/website/website/favicons/auth0-favicon.svg\" alt=\"Auth0 Logo\" /> **[Auth0](https://github.com/auth0/auth0-mcp-server)** - MCP server for interacting with your Auth0 tenant, supporting creating and modifying actions, applications, forms, logs, resource servers, and more.\n- <img height=\"12\" width=\"12\" src=\"https://firstorder.ai/favicon_auth.ico\" alt=\"Authenticator App Logo\" /> **[Authenticator App · 2FA](https://github.com/firstorderai/authenticator_mcp)** - A secure MCP (Model Context Protocol) server that enables AI agents to interact with the Authenticator App.\n- <img height=\"12\" width=\"12\" src=\"https://a0.awsstatic.com/libra-css/images/site/fav/favicon.ico\" alt=\"AWS Logo\" /> **[AWS](https://github.com/awslabs/mcp)** -  Specialized MCP servers that bring AWS best practices directly to your development workflow.\n- <img height=\"12\" width=\"12\" src=\"https://axiom.co/favicon.ico\" alt=\"Axiom Logo\" /> **[Axiom](https://github.com/axiomhq/mcp-server-axiom)** - Query and analyze your Axiom logs, traces, and all other event data in natural language\n- <img height=\"12\" width=\"12\" src=\"https://cdn-dynmedia-1.microsoft.com/is/content/microsoftcorp/acom_social_icon_azure\" alt=\"Microsoft Azure Logo\" /> **[Azure](https://github.com/microsoft/mcp/tree/main/servers/Azure.Mcp.Server)** - The Azure MCP Server gives MCP Clients access to key Azure services and tools like Azure Storage, Cosmos DB, the Azure CLI, and more.\n- <img height=\"12\" width=\"12\" src=\"https://cdn-dynmedia-1.microsoft.com/is/content/microsoftcorp/1062064-Products-1.2-24x24\" alt=\"Microsoft Azure DevOps Logo\" /> **[Azure DevOps](https://github.com/microsoft/azure-devops-mcp)** - Interact with Azure DevOps services like repositories, work items, builds, releases, test plans, and code search.\n- <img height=\"12\" width=\"12\" src=\"https://application.backdocket.com/favicon.ico\" alt=\"Backdocket Logo\" /> **[Backdocket](https://ai.backdocket.com)** - Search, Retrieve, and Update your **[Backdocket](https://backdocket.com)** data. This currently includes Claims, Matters, Contacts, Tasks and Advanced Searches. To easily use the Remote Mcp Server utilize the following url: **[https://ai.backdocket.com/mcp]([https://backdocket.com](https://ai.backdocket.com/mcp))**\n- <img height=\"12\" width=\"12\" src=\"https://mapopen-website-wiki.cdn.bcebos.com/LOGO/lbsyunlogo_icon.ico\" alt=\"Baidu Map Logo\" /> **[Baidu Map](https://github.com/baidu-maps/mcp)** - [Baidu Map MCP Server](https://lbsyun.baidu.com/faq/api?title=mcpserver/base) provides tools for AI agents to interact with Baidu Maps APIs, enabling location-based services and geospatial data analysis.\n- <img height=\"12\" width=\"12\" src=\"https://www.bankless.com/favicon.ico\" alt=\"Bankless Logo\" /> **[Bankless Onchain](https://github.com/bankless/onchain-mcp)** - Query Onchain data, like ERC20 tokens, transaction history, smart contract state.\n- <img height=\"12\" width=\"12\" src=\"https://baserow.io/img/logo_baserow_square_large.png\" alt=\"Baserow Logo\" /> **[Baserow](https://gitlab.com/baserow/baserow/-/tree/develop/backend/src/baserow/api/mcp)** - Query data from Baserow self-hosted or SaaS databases using MCP integration.\n- <img height=\"12\" width=\"12\" src=\"https://bicscan.io/favicon.png\" alt=\"BICScan Logo\" /> **[BICScan](https://github.com/ahnlabio/bicscan-mcp)** - Risk score / asset holdings of EVM blockchain address (EOA, CA, ENS) and even domain names.\n- <img height=\"12\" width=\"12\" src=\"https://web-cdn.bitrise.io/favicon.ico\" alt=\"Bitrise Logo\" /> **[Bitrise](https://github.com/bitrise-io/bitrise-mcp)** - Chat with your builds, CI, and [more](https://bitrise.io/blog/post/chat-with-your-builds-ci-and-more-introducing-the-bitrise-mcp-server).\n- <img height=\"12\" width=\"12\" src=\"https://boikot.xyz/assets/favicon.svg\" alt=\"boikot Logo\" /> **[Boikot](https://github.com/boikot-xyz/boikot)** - Learn about the ethical and unethical actions of major companies with [boikot.xyz](https://boikot.xyz/).\n- <img height=\"12\" width=\"12\" src=\"https://boldsign.com/favicon.ico\" alt=\"BoldSign Logo\" /> **[BoldSign](https://github.com/boldsign/boldsign-mcp)** - Search, request, and manage e-signature contracts effortlessly with [BoldSign](https://boldsign.com/).\n- <img height=\"12\" width=\"12\" src=\"https://boost.space/favicon.ico\" alt=\"Boost.space Logo\" /> **[Boost.space](https://github.com/boostspace/boostspace-mcp-server)** - An MCP server integrating with [Boost.space](https://boost.space) for centralized, automated business data from 2000+ sources.\n- <img height=\"12\" width=\"12\" src=\"https://www.box.com/favicon.ico\" alt=\"Box Logo\" /> **[Box](https://github.com/box-community/mcp-server-box)** - Interact with the Intelligent Content Management platform through Box AI.\n- <img height=\"12\" width=\"12\" src=\"https://www.brightdata.com/favicon.ico\" alt=\"BrightData Logo\" /> **[BrightData](https://github.com/luminati-io/brightdata-mcp)** - Discover, extract, and interact with the web - one interface powering automated access across the public internet.\n- <img height=\"12\" width=\"12\" src=\"https://browserbase.com/favicon.ico\" alt=\"Browserbase Logo\" /> **[Browserbase](https://github.com/browserbase/mcp-server-browserbase)** - Automate browser interactions in the cloud (e.g. web navigation, data extraction, form filling, and more)\n- <img height=\"12\" width=\"12\" src=\"https://browserstack.wpenginepowered.com/wp-content/themes/browserstack/img/favicons/favicon.ico\" alt=\"BrowserStack Logo\" /> **[BrowserStack](https://github.com/browserstack/mcp-server)** - Access BrowserStack's [Test Platform](https://www.browserstack.com/test-platform) to debug, write and fix tests, do accessibility testing and more.\n- <img height=\"12\" width=\"12\" src=\"https://www.google.com/s2/favicons?domain=buildkite.com&sz=24\" alt=\"Buildkite Logo\" /> **[Buildkite](https://github.com/buildkite/buildkite-mcp-server)** - Exposing Buildkite data (pipelines, builds, jobs, tests) to AI tooling and editors.\n- <img height=\"12\" width=\"12\" src=\"https://bldbl.dev/favico.png\" alt=\"Buildable Logo\" />**[Buildable](https://github.com/chunkydotdev/bldbl-mcp)** (TypeScript) - Official MCP server for Buildable AI-powered development platform. Enables AI assistants to manage tasks, track progress, get project context, and collaborate with humans on software projects.\n- <img height=\"12\" width=\"12\" src=\"https://builtwith.com/favicon.ico\" alt=\"BuiltWith Logo\" /> **[BuiltWith](https://github.com/builtwith/mcp)** - Identify the technology stack behind any website.\n- <img height=\"12\" width=\"12\" src=\"https://portswigger.net/favicon.ico\" alt=\"PortSwigger Logo\" /> **[Burp Suite](https://github.com/PortSwigger/mcp-server)** - MCP Server extension allowing AI clients to connect to [Burp Suite](https://portswigger.net)\n- <img src=\"https://app.cal.com/favicon.ico\" alt=\"Cal.com\" width=\"12\" height=\"12\"> **[Cal.com](https://www.npmjs.com/package/@calcom/cal-mcp?activeTab=readme)** - Connect to the Cal.com API to schedule and manage bookings and appointments.\n- <img height=\"12\" width=\"12\" src=\"https://campertunity.com/assets/icon/favicon.ico\" alt=\"Campertunity Logo\" /> **[Campertunity](https://github.com/campertunity/mcp-server)** - Search campgrounds around the world on campertunity, check availability, and provide booking links.\n- <img height=\"12\" width=\"12\" src=\"https://static.canva.com/static/images/favicon.ico\" alt=\"Canva logo\" /> **[Canva](https://www.canva.dev/docs/apps/mcp-server/)** — Provide AI - powered development assistance for [Canva](https://canva.com) apps and integrations.\n- <img height=\"12\" width=\"12\" src=\"https://carbonvoice.app/favicon.ico\" alt=\"Carbon Voice Logo\" /> **[Carbon Voice](https://github.com/PhononX/cv-mcp-server)** - MCP Server that connects AI Agents to [Carbon Voice](https://getcarbon.app). Create, manage, and interact with voice messages, conversations, direct messages, folders, voice memos, AI actions and more in [Carbon Voice](https://getcarbon.app).\n-  **[Cartesia](https://github.com/cartesia-ai/cartesia-mcp)** - Connect to the [Cartesia](https://cartesia.ai/) voice platform to perform text-to-speech, voice cloning etc.\n- <img height=\"12\" width=\"12\" src=\"https://www.cashfree.com/favicon.ico\" alt=\"Cashfree logo\" /> **[Cashfree](https://github.com/cashfree/cashfree-mcp)** - [Cashfree Payments](https://www.cashfree.com/) official MCP server.\n- **[CB Insights](https://github.com/cbinsights/cbi-mcp-server)** - Use the [CB Insights](https://www.cbinsights.com) MCP Server to connect to [ChatCBI](https://www.cbinsights.com/chatcbi/)\n- <img height=\"12\" width=\"12\" src=\"https://cleanupcrew.ai/favicon-light.png\" alt=\"Cleanup Crew logo\" /> **[Cleanup Crew](https://cleanupcrew.ai/install)** - Real-time human support service for non-technical founders using AI coding tools. When AI hits a wall, request instant human help directly from your IDE.\n- <img height=\"12\" width=\"12\" src=\"https://www.chargebee.com/static/resources/brand/favicon.png\" alt=\"Chargebee Logo\" /> **[Chargebee](https://github.com/chargebee/agentkit/tree/main/modelcontextprotocol)** - MCP Server that connects AI agents to [Chargebee platform](https://www.chargebee.com).\n- <img height=\"12\" width=\"12\" src=\"https://cheqd.io/wp-content/uploads/2023/03/logo_cheqd_favicon.png\" alt=\"Cheqd Logo\" /> **[Cheqd](https://github.com/cheqd/mcp-toolkit)** - Enable AI Agents to be trusted, verified, prevent fraud, protect your reputation, and more through [cheqd's](https://cheqd.io) Trust Registries and Credentials.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.chiki.studio/brand/logo.png\" alt=\"Chiki StudIO Logo\" /> **[Chiki StudIO](https://chiki.studio/galimybes/mcp/)** - Create your own configurable MCP servers purely via configuration (no code), with instructions, prompts, and tools support.\n- <img height=\"12\" width=\"12\" src=\"https://trychroma.com/_next/static/media/chroma-logo.ae2d6e4b.svg\" alt=\"Chroma Logo\" /> **[Chroma](https://github.com/chroma-core/chroma-mcp)** - Embeddings, vector search, document storage, and full-text search with the open-source AI application database\n- <img height=\"12\" width=\"12\" src=\"https://www.chronulus.com/favicon/chronulus-logo-blue-on-alpha-square-128x128.ico\" alt=\"Chronulus AI Logo\" /> **[Chronulus AI](https://github.com/ChronulusAI/chronulus-mcp)** - Predict anything with Chronulus AI forecasting and prediction agents.\n- <img height=\"12\" width=\"12\" src=\"https://circleci.com/favicon.ico\" alt=\"CircleCI Logo\" /> **[CircleCI](https://github.com/CircleCI-Public/mcp-server-circleci)** - Enable AI Agents to fix build failures from CircleCI.\n- <img height=\"12\" width=\"12\" src=\"https://assets.zilliz.com/Zilliz_Logo_Mark_White_20230223_041013_86057436cc.png\" alt=\"Claude Context Logo\" /> **[Claude Context](https://github.com/zilliztech/claude-context)** - Bring your codebase as context to Claude Code\n- <img height=\"12\" width=\"12\" src=\"https://clickhouse.com/favicon.ico\" alt=\"ClickHouse Logo\" /> **[ClickHouse](https://github.com/ClickHouse/mcp-clickhouse)** - Query your [ClickHouse](https://clickhouse.com/) database server.\n- <img height=\"12\" width=\"12\" src=\"https://brand.clicksend.com/_ipx/s_794x608/img/clicksend_icon_only.svg\" alt=\"ClickSend Logo\" /> **[ClickSend](https://github.com/ClickSend/clicksend-mcp-server/)** - This is the official ClickSend MCP Server developed by ClickSend team.\n- <img height=\"12\" width=\"12\" src=\"https://7463-tcb-advanced-a656fc-1257967285.tcb.qcloud.la/mcp/cloudbase-logo.svg\" alt=\"CloudBase Logo\" /> **[CloudBase](https://github.com/TencentCloudBase/CloudBase-AI-ToolKit)** - One-stop backend services for WeChat Mini-Programs and full-stack apps with serverless cloud functions and databases by [Tencent CloudBase](https://tcb.cloud.tencent.com/)\n- <img height=\"12\" width=\"12\" src=\"https://www.cloudbet.com/favicon.ico\" alt=\"Cloudbet Logo\" /> **[Cloudbet](https://github.com/cloudbet/sports-mcp-server)** - Structured sports and esports data via Cloudbet API: fixtures, live odds, stake limits, and markets.\n- <img height=\"12\" width=\"12\" src=\"https://www.cloudbees.com/favicon.ico\" alt=\"CloudBees Logo\" /> **[CloudBees](https://docs.cloudbees.com/docs/cloudbees-mcp/latest/)** - Enable AI access to your [CloudBees Unify](https://www.cloudbees.com/unify) environment.\n- <img src=\"http://www.google.com/s2/favicons?domain=www.cloudera.com\" alt=\"Cloudera Iceberg\" width=\"12\" height=\"12\"> **[Cloudera Iceberg](https://github.com/cloudera/iceberg-mcp-server)** - enabling AI on the [Open Data Lakehouse](https://www.cloudera.com/products/open-data-lakehouse.html).\n- <img alt=\"cloudflare\" height=\"12\" width=\"12\" src=\"https://cdn.simpleicons.org/cloudflare\" /> **[Cloudflare](https://github.com/cloudflare/mcp-server-cloudflare)** - Deploy, configure & interrogate your resources on the Cloudflare developer platform (e.g. Workers/KV/R2/D1)\n- <img src=\"https://cdn.prod.website-files.com/64d41aab8183c7c3324ddb29/67c0f1e272e51cf3c511c17c_Gyph.svg\" alt=\"Cloudinary\" width=\"12\" height=\"12\"> **[Cloudinary](https://github.com/cloudinary/mcp-servers)** - Exposes Cloudinary's media upload, transformation, AI analysis, management, optimization and delivery as tools usable by AI agents\n- <img height=\"12\" width=\"12\" src=\"https://raw.githubusercontent.com/Cloudsway-AI/smartsearch/refs/heads/main/plugin_cloudsway.ico\" alt=\"Cloudsway Logo\" /> **[Cloudsway SmartSearch](https://github.com/Cloudsway-AI/smartsearch)** - Web search MCP server powered by Cloudsway, supporting keyword search, language, and safety options. Returns structured JSON results.\n-  **[Codacy](https://github.com/codacy/codacy-mcp-server/)** - Interact with [Codacy](https://www.codacy.com) API to query code quality issues, vulnerabilities, and coverage insights about your code.\n-  **[CodeLogic](https://github.com/CodeLogicIncEngineering/codelogic-mcp-server)** - Interact with [CodeLogic](https://codelogic.com), a Software Intelligence platform that graphs complex code and data architecture dependencies, to boost AI accuracy and insight.\n- <img height=\"12\" width=\"12\" src=\"https://www.coingecko.com/favicon.ico\" alt=\"CoinGecko Logo\" /> **[CoinGecko](https://github.com/coingecko/coingecko-typescript/tree/main/packages/mcp-server)** - Official [CoinGecko API](https://www.coingecko.com/en/api) MCP Server for Crypto Price & Market Data, across 200+ Blockchain Networks and 8M+ Tokens.\n- <img height=\"12\" width=\"12\" src=\"https://www.comet.com/favicon.ico\" alt=\"Comet Logo\" /> **[Comet Opik](https://github.com/comet-ml/opik-mcp)** - Query and analyze your [Opik](https://github.com/comet-ml/opik) logs, traces, prompts and all other telemetry data from your LLMs in natural language.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/6572bd8c27ee5db3eb91f4b3/6572bd8d27ee5db3eb91f55e_favicon-dashflow-webflow-template.svg\" alt=\"OSS Conductor Logo\" /> <img height=\"12\" width=\"12\" src=\"https://orkes.io/icons/icon-48x48.png\" alt=\"Orkes Conductor Logo\" />**[Conductor](https://github.com/conductor-oss/conductor-mcp)** - Interact with Conductor (OSS and Orkes) REST APIs.\n- <img height=\"12\" width=\"12\" src=\"https://platform.composio.dev/favicon.ico\" alt=\"Composio Logo\" /> **[Composio](https://docs.composio.dev/docs/mcp-overview#-getting-started)** – Use [Composio](https://composio.dev) to connect 100+ tools. Zero setup. Auth built-in. Made for agents, works for humans.\n- <img height=\"12\" width=\"12\" src=\"https://www.confluent.io/favicon.ico\" alt=\"Confluent Logo\" /> **[Confluent](https://github.com/confluentinc/mcp-confluent)** - Interact with Confluent Kafka and Confluent Cloud REST APIs.\n- <img src=\"https://contrastsecurity.com/favicon.ico\" alt=\"Contrast Security\" width=\"12\" height=\"12\"> **[Contrast Security](https://github.com/Contrast-Security-OSS/mcp-contrast)** - Brings Contrast's vulnerability and SCA data into your coding agent to quickly remediate vulnerabilities.\n- <img height=\"12\" width=\"12\" src=\"https://www.convex.dev/favicon.ico\" alt=\"Convex Logo\" /> **[Convex](https://stack.convex.dev/convex-mcp-server)** - Introspect and query your apps deployed to Convex.\n- <img height=\"12\" width=\"12\" src=\"https://www.cortex.io/favicon.ico\" alt=\"Cortex Logo\" /> **[Cortex](https://github.com/cortexapps/cortex-mcp)** - Official MCP server for [Cortex](https://www.cortex.io).\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/605755?s=200&v=4\" alt=\"Couchbase Logo\" /> **[Couchbase](https://github.com/Couchbase-Ecosystem/mcp-server-couchbase)** - Interact with the data stored in Couchbase clusters.\n- <img height=\"12\" width=\"12\" src=\"https://github.com/user-attachments/assets/b256f9fa-2020-4b37-9644-c77229ef182b\" alt=\"CRIC 克而瑞 LOGO\"> **[CRIC Wuye AI](https://github.com/wuye-ai/mcp-server-wuye-ai)** - Interact with capabilities of the CRIC Wuye AI platform, an intelligent assistant specifically for the property management industry.\n- <img height=\"12\" width=\"12\" src=\"https://www.crowdstrike.com/etc.clientlibs/crowdstrike/clientlibs/crowdstrike-common/resources/favicon.ico\" alt=\"CrowdStrike Logo\" /> **[CrowdStrike Falcon](https://github.com/CrowdStrike/falcon-mcp)** - Connects AI agents with the CrowdStrike Falcon platform for intelligent security analysis, providing programmatic access to detections, incidents, behaviors, threat intelligence, hosts, vulnerabilities, and identity protection capabilities.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/58433296\" alt=\"CTERA Edge Filer\" /> **[CTERA Edge Filer](https://github.com/ctera/mcp-ctera-edge)** - CTERA Edge Filer delivers intelligent edge caching and multiprotocol file access, enabling fast, secure access to files across core and remote sites.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/58433296\" alt=\"CTERA Portal\" /> **[CTERA Portal](https://github.com/ctera/mcp-ctera-core)** - CTERA Portal is a multi-tenant, multi-cloud platform that delivers a global namespace and unified management across petabytes of distributed content.\n- <img height=\"12\" width=\"12\" src=\"https://app.cycode.com/img/favicon.ico\" alt=\"Cycode Logo\" /> **[Cycode](https://github.com/cycodehq/cycode-cli#mcp-command-experiment)** - Boost security in your dev lifecycle via SAST, SCA, Secrets & IaC scanning with [Cycode](https://cycode.com/).\n- <img height=\"12\" width=\"12\" src=\"http://app.itsdart.com/static/img/favicon.png\" alt=\"Dart Logo\" /> **[Dart](https://github.com/its-dart/dart-mcp-server)** - Interact with task, doc, and project data in [Dart](https://itsdart.com), an AI-native project management tool\n- <img height=\"12\" width=\"12\" src=\"https://cdn.bfldr.com/9AYANS2F/at/k8bgnnxhb4bggjk88r4x9snf/databricks-symbol-color.svg?auto=webp&format=png&width=12&height=13\" alt=\"Databricks Logo\" /> **[Databricks](https://docs.databricks.com/aws/en/generative-ai/mcp/)** - Connect to data, AI tools & agents, and the rest of the Databricks platform using turnkey managed MCP servers. Or, host your own custom MCP servers within the Databricks security and data governance boundary.\n- <img height=\"12\" width=\"12\" src=\"https://datahub.com/wp-content/uploads/2025/04/cropped-Artboard-1-32x32.png\" alt=\"DataHub Logo\" /> **[DataHub](https://github.com/acryldata/mcp-server-datahub)** - Search your data assets, traverse data lineage, write SQL queries, and more using [DataHub](https://datahub.com/) metadata.\n- <img height=\"12\" width=\"12\" src=\"https://www.daytona.io/brand/social-daytona-icon.png\" alt=\"Daytona Logo\" /> **[Daytona](https://github.com/daytonaio/daytona/tree/main/apps/cli/mcp)** - Fast and secure execution of your AI generated code with [Daytona](https://daytona.io) sandboxes\n- <img height=\"12\" width=\"12\" src=\"https://debugg.ai/favicon.svg\" alt=\"Debugg AI Logo\" /> **[Debugg.AI](https://github.com/debugg-ai/debugg-ai-mcp)** - Zero-Config, Fully AI-Managed End-to-End Testing for any code gen platform via [Debugg.AI](https://debugg.ai) remote browsing test agents.\n- <img height=\"12\" width=\"12\" src=\"https://www.deepl.com/img/logo/deepl-logo-blue.svg\" alt=\"DeepL Logo\" /> **[DeepL](https://github.com/DeepLcom/deepl-mcp-server)** - Translate or rewrite text with [DeepL](https://deepl.com)'s very own AI models using [the DeepL API](https://developers.deepl.com/docs)\n- <img height=\"12\" width=\"12\" src=\"https://defang.io/_next/static/media/defang-icon-dark-colour.25f95b77.svg\" alt=\"Defang Logo\" /> **[Defang](https://github.com/DefangLabs/defang/blob/main/src/pkg/mcp/README.md)** - Deploy your project to the cloud seamlessly with the [Defang](https://www.defang.io) platform without leaving your integrated development environment\n- <img height=\"12\" width=\"12\" src=\"https://detailer.ginylil.com/favicon.ico\" alt=\"Detailer Logo\" /> **[Detailer](https://detailer.ginylil.com/)** – Instantly generate rich, AI-powered documentation for your GitHub repositories. Designed for AI agents to gain deep project context before taking action.\n- <img height=\"12\" width=\"12\" src=\"https://devcycle.com/_next/image?url=%2Fassets%2Fbrand%2FColor-logo-mark.png&w=384&q=75\" alt=\"DevCycle Logo\" /> **[DevCycle](https://docs.devcycle.com/cli-mcp/mcp-getting-started)** - Create and monitor feature flags using natural language in your AI coding assistant.\n- <img height=\"12\" width=\"12\" src=\"https://www.devhub.com/img/upload/favicon-196x196-dh.png\" alt=\"DevHub Logo\" /> **[DevHub](https://github.com/devhub/devhub-cms-mcp)** - Manage and utilize website content within the [DevHub](https://www.devhub.com) CMS platform\n- <img height=\"12\" width=\"12\" src=\"https://devrev.ai/favicon.ico\" alt=\"DevRev Logo\" /> **[DevRev](https://github.com/devrev/mcp-server)** - An MCP server to integrate with DevRev APIs to search through your DevRev Knowledge Graph where objects can be imported from diff. Sources listed [here](https://devrev.ai/docs/import#available-sources).\n- <img height=\"12\" width=\"12\" src=\"https://dexpaprika.com/favicon.ico\" alt=\"DexPaprika Logo\" /> **[DexPaprika (CoinPaprika)](https://github.com/coinpaprika/dexpaprika-mcp)** - Access real-time DEX data, liquidity pools, token information, and trading analytics across multiple blockchain networks with [DexPaprika](https://dexpaprika.com) by CoinPaprika.\n- <img height=\"12\" width=\"12\" src=\"https://github.com/dolthub/dolt/raw/main/images/Dolt-Logo@3x.svg\" alt=\"Dolt Logo\" /> **[Dolt](https://github.com/dolthub/dolt-mcp)** - The official MCP server for version-controlled [Dolt](https://doltdb.com/) databases.\n- <img height=\"12\" width=\"12\" src=\"https://eu.getdot.ai/favicon.ico\" alt=\"GetDot.ai Logo\" /> **[Dot (GetDot.ai)](https://docs.getdot.ai/dot/integrations/mcp)** - Fetch, analyze or visualize data from your favorite database or data warehouse (Snowflake, BigQuery, Redshift, Databricks, Clickhouse, ...) with [Dot](https://getdot.ai), your AI Data Analyst. This remote MCP server is a one-click integration for user that have setup Dot.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/65421071?s=200&v=4\" alt=\"Drata Logo\" /> **[Drata](https://drata.com/mcp)** - Get hands-on with our experimental MCP server—bringing real-time compliance intelligence into your AI workflows.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/204530939?s=200&v=4\" alt=\"Dumpling AI Logo\" /> **[Dumpling AI](https://github.com/Dumpling-AI/mcp-server-dumplingai)** - Access data, web scraping, and document conversion APIs by [Dumpling AI](https://www.dumplingai.com/)\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/58178984\" alt=\"Dynatrace Logo\" /> **[Dynatrace](https://github.com/dynatrace-oss/dynatrace-mcp)** - Manage and interact with the [Dynatrace Platform ](https://www.dynatrace.com/platform) for real-time observability and monitoring.\n- <img height=\"12\" width=\"12\" src=\"https://e2b.dev/favicon.ico\" alt=\"E2B Logo\" /> **[E2B](https://github.com/e2b-dev/mcp-server)** - Run code in secure sandboxes hosted by [E2B](https://e2b.dev)\n- <img height=\"12\" width=\"12\" src=\"https://www.edgee.cloud/favicon.ico\" alt=\"Edgee Logo\" /> **[Edgee](https://github.com/edgee-cloud/mcp-server-edgee)** - Deploy and manage [Edgee](https://www.edgee.cloud) components and projects\n- <img height=\"12\" width=\"12\" src=\"https://static.edubase.net/media/brand/favicon/favicon-32x32.png\" alt=\"EduBase Logo\" /> **[EduBase](https://github.com/EduBase/MCP)** - Interact with [EduBase](https://www.edubase.net), a comprehensive e-learning platform with advanced quizzing, exam management, and content organization capabilities\n- <img height=\"12\" width=\"12\" src=\"https://www.elastic.co/favicon.ico\" alt=\"Elasticsearch Logo\" /> **[Elasticsearch](https://github.com/elastic/mcp-server-elasticsearch)** - Query your data in [Elasticsearch](https://www.elastic.co/elasticsearch)\n- <img height=\"12\" width=\"12\" src=\"https://github.com/EmberAGI/arbitrum-vibekit/blob/main/img/Ember%20Black.png?raw=true\" alt=\"Ember AI Logo\" /> **[Ember AI](https://docs.emberai.xyz/)** - A unified MCP server that enables AI agents to execute cross-chain DeFi strategies.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/656eaf5c6da3527caf362363/656ecc07555afac40df4c40e_Facicon.png\" alt=\"Endor Labs Logo\" /> **[Endor Labs](https://docs.endorlabs.com/deployment/ide/mcp/)** - Find and fix security risks in you code. Integrate [Endor Labs](https://endorlabs.com) to scan and secure your code from vulnerabilities and secret leaks.\n- <img height=\"12\" width=\"12\" src=\"https://esignatures.com/favicon.ico\" alt=\"eSignatures Logo\" /> **[eSignatures](https://github.com/esignaturescom/mcp-server-esignatures)** - Contract and template management for drafting, reviewing, and sending binding contracts.\n- <img height=\"12\" width=\"12\" src=\"https://rainmaker.espressif.com/favicon.ico\" alt=\"ESP RainMaker Logo\" /> **[ESP RainMaker](https://github.com/espressif/esp-rainmaker-mcp)** - Official Espressif MCP Server to Control and Manage ESP RainMaker Devices.\n- <img height=\"12\" width=\"12\" src=\"https://exa.ai/images/favicon-32x32.png\" alt=\"Exa Logo\" /> **[Exa](https://github.com/exa-labs/exa-mcp-server)** - Search Engine made for AIs by [Exa](https://exa.ai)\n- <img height=\"12\" width=\"12\" src=\"https://www.explorium.ai/wp-content/uploads/2025/04/Favicon-Purple-512x512-1-150x150.png\" alt=\"Explorium Logo\" /> **[Explorium](https://github.com/explorium-ai/mcp-explorium)** - B2B data and infrastructure for AI SDR & GTM Agents [Explorium](https://www.explorium.ai)\n- **[FalkorDB](https://github.com/FalkorDB/FalkorDB-MCPServer)** - FalkorDB graph database server get schema and read/write-cypher [FalkorDB](https://www.falkordb.com)\n- <img height=\"12\" width=\"12\" src=\"https://fetchserp.com/icon.png\" alt=\"fetchSERP Logo\" /> **[fetchSERP](https://github.com/fetchSERP/fetchserp-mcp-server-node)** - All-in-One SEO & Web Intelligence Toolkit API [fetchSERP](https://www.fetchserp.com/)\n- <img height=\"12\" width=\"12\" src=\"https://fewsats.com/favicon.svg\" alt=\"Fewsats Logo\" /> **[Fewsats](https://github.com/Fewsats/fewsats-mcp)** - Enable AI Agents to purchase anything in a secure way using [Fewsats](https://fewsats.com)\n- <img height=\"12\" width=\"12\" src=\"https://fibery.io/favicon.svg\" alt=\"Fibery Logo\" /> **[Fibery](https://github.com/Fibery-inc/fibery-mcp-server)** - Perform queries and entity operations in your [Fibery](https://fibery.io) workspace.\n- <img height=\"12\" width=\"12\" src=\"https://financialdatasets.ai/favicon.ico\" alt=\"Financial Datasets Logo\" /> **[Financial Datasets](https://github.com/financial-datasets/mcp-server)** - Stock market API made for AI agents\n- <img height=\"12\" width=\"12\" src=\"https://www.gstatic.com/devrel-devsite/prod/v7aeef7f1393bb1d75a4489145c511cdd5aeaa8e13ad0a83ec1b5b03612e66330/firebase/images/favicon.png\" alt=\"Firebase Logo\" /> **[Firebase](https://github.com/firebase/firebase-tools/blob/master/src/mcp)** - Firebase's experimental [MCP Server](https://firebase.google.com/docs/cli/mcp-server) to power your AI Tools\n- <img height=\"12\" width=\"12\" src=\"https://firecrawl.dev/favicon.ico\" alt=\"Firecrawl Logo\" /> **[Firecrawl](https://github.com/firecrawl/firecrawl-mcp-server)** - Extract web data with [Firecrawl](https://firecrawl.dev)\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/100200663?s=200&v=4\" alt=\"Firefly Logo\" /> **[Firefly](https://github.com/gofireflyio/firefly-mcp)** - Integrates, discovers, manages, and codifies cloud resources with [Firefly](https://firefly.ai).\n- <img height=\"12\" width=\"12\" src=\"https://fireproof.storage/favicon.ico\" alt=\"Fireproof Logo\" /> **[Fireproof](https://github.com/fireproof-storage/mcp-database-server)** - Immutable ledger database with live synchronization\n- <img height=\"12\" width=\"12\" src=\"https://fixparser.dev/favicon.ico\" alt=\"FIXParser Logo\" /> **[FIXParser](https://gitlab.com/logotype/fixparser/-/tree/main/packages/fixparser-plugin-mcp)** - A modern FIX Protocol engine for AI-powered trading agents\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/52471808\" alt=\"Fluid Attacks Logo\" /> **[Fluid Attacks](https://github.com/fluidattacks/mcp)** - Interact with the [Fluid Attacks](https://fluidattacks.com/) API, enabling vulnerability management, organization insights, and GraphQL query execution.\n- <img height=\"12\" width=\"12\" src=\"https://forevervm.com/icon.png\" alt=\"ForeverVM Logo\" /> **[ForeverVM](https://github.com/jamsocket/forevervm/tree/main/javascript/mcp-server)** - Run Python in a code sandbox.\n- <img height=\"12\" width=\"12\" src=\"https://flutterwave.com/favicon.ico\" alt=\"Flutterwave Logo\" /> **[Flutterwave](https://github.com/bajoski34/mcp-flutterwave/tree/main)** - Interact with Flutterwave payment solutions API, to manage transactions, payment links and more.\n- <img height=\"12\" width=\"12\" src=\"https://app.gibsonai.com/favicon.ico\" alt=\"GibsonAI Logo\" /> **[GibsonAI](https://github.com/GibsonAI/mcp)** - AI-Powered Cloud databases: Build, migrate, and deploy database instances with AI\n- <img height=\"12\" width=\"12\" src=\"https://gcore.com/assets/favicon/favicon-16x16.png\" alt=\"Gcore Logo\" /> **[Gcore](https://github.com/G-Core/gcore-mcp-server)** - Interact with Gcore platform services via LLM assistants, providing unified access to CDN, GPU Cloud & AI Inference, Video Streaming, WAAP, and cloud resources including instances and networks.\n- <img height=\"12\" width=\"12\" src=\"https://gitea.com/assets/img/favicon.svg\" alt=\"Gitea Logo\" /> **[Gitea](https://gitea.com/gitea/gitea-mcp)** - Interact with Gitea instances with MCP.\n- <img height=\"12\" width=\"12\" src=\"https://gitee.com/favicon.ico\" alt=\"Gitee Logo\" /> **[Gitee](https://github.com/oschina/mcp-gitee)** - Gitee API integration, repository, issue, and pull request management, and more.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/5ee25cbe47310017adf964da/6323888a9b9f4e22a7bc766b_GG%20Favicon.svg\" alt=\"GitGuardian Logo\" /> **[GitGuardian](https://github.com/GitGuardian/gg-mcp)** - GitGuardian official MCP server - Scan projects using GitGuardian's industry-leading API, which features over 500 secret detectors to prevent credential leaks before they reach public repositories. Resolve security incidents directly with rich contextual data for rapid, automated remediation.\n- <img height=\"12\" width=\"12\" src=\"https://gitlab.com/favicon.ico\" alt=\"GitLab Logo\" /> **[GitLab](https://docs.gitlab.com/user/gitlab_duo/model_context_protocol/mcp_server/)** - GitLab's official MCP server enabling AI tools to securely access GitLab project data, manage issues, and perform repository operations via OAuth 2.0.\n- <img height=\"12\" width=\"12\" src=\"https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png\" alt=\"GitHub Logo\" /> **[GitHub](https://github.com/github/github-mcp-server)** - GitHub's official MCP Server.\n- <img height=\"12\" width=\"12\" src=\"https://www.gitkraken.com/wp-content/uploads/2021/03/android-chrome-144x144-1.png\" alt=\"GitKraken Logo\" /> **[GitKraken](https://github.com/gitkraken/gk-cli?tab=readme-ov-file#mcp-server)** - A CLI for interacting with GitKraken APIs. Includes an MCP server via `gk mcp` that not only wraps GitKraken APIs, but also Jira, GitHub, GitLab, and more.\n- <img height=\"12\" width=\"12\" src=\"https://app.glean.com/images/favicon3-196x196.png\" alt=\"Glean Logo\" /> **[Glean](https://github.com/gleanwork/mcp-server)** - Enterprise search and chat using Glean's API.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.jsdelivr.net/gh/jsdelivr/globalping-media@refs/heads/master/icons/android-chrome-192x192.png\" alt=\"Globalping Logo\" /> **[Globalping](https://github.com/jsdelivr/globalping-mcp-server)** - Access a network of thousands of probes to run network commands like ping, traceroute, mtr, http and DNS resolve.\n- <img height=\"12\" width=\"12\" src=\"https://gnucleus.ai/favicon.ico\" alt=\"gNucleus Logo\" /> **[gNucleus Text-To-CAD](https://github.com/gNucleus/text-to-cad-mcp)** - Generate CAD parts and assemblies from text using gNucleus AI models.\n- <img height=\"12\" width=\"12\" src=\"https://www.gstatic.com/cgc/favicon.ico\" alt=\"Google Cloud Logo\" /> **[Google Cloud Run](https://github.com/GoogleCloudPlatform/cloud-run-mcp)** - Deploy code to Google Cloud Run\n- <img height=\"12\" width=\"12\" src=\"https://api.gologin.com/favicon.ico\" alt=\"GoLogin Logo\" /> **[GoLogin MCP server](https://github.com/gologinapp/gologin-mcp)** - Manage your GoLogin browser profiles and automation directly through AI conversations!\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/3717923?s=200&v=4\" alt=\"Google Maps Platform Logo\" /> **[Google Maps Platform Code Assist](https://github.com/googlemaps/platform-ai/tree/main/packages/code-assist)** - Ground agents on fresh, official documentation and code samples for optimal geo-related guidance and code..\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/6605a2979ff17b2cd1939cd4/6605a460de47e7596ed84f06_icon256.png\" alt=\"gotoHuman Logo\" /> **[gotoHuman](https://github.com/gotohuman/gotohuman-mcp-server)** - Human-in-the-loop platform - Allow AI agents and automations to send requests for approval to your [gotoHuman](https://www.gotohuman.com) inbox.\n- <img height=\"12\" width=\"12\" src=\"https://grafana.com/favicon.ico\" alt=\"Grafana Logo\" /> **[Grafana](https://github.com/grafana/mcp-grafana)** - Search dashboards, investigate incidents and query datasources in your Grafana instance\n- <img height=\"12\" width=\"12\" src=\"https://grafbase.com/favicon.ico\" alt=\"Grafbase Logo\" /> **[Grafbase](https://github.com/grafbase/grafbase/tree/main/crates/mcp)** - Turn your GraphQL API into an efficient MCP server with schema intelligence in a single command.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/5f5e90c17e7c9eb95c7acb17/61d3457a519242f2c75c725c_favicon.png\" alt=\"Grain Logo\" /> **[Grain](https://grain.com/release-note/06-18-2025)** - Access your Grain meetings notes & transcripts directly in claude and generate reports with native Claude Prompts.\n- <img height=\"12\" width=\"12\" src=\"https://framerusercontent.com/images/KCOWBYLKunDff1Dr452y6EfjiU.png\" alt=\"Graphlit Logo\" /> **[Graphlit](https://github.com/graphlit/graphlit-mcp-server)** - Ingest anything from Slack to Gmail to podcast feeds, in addition to web crawling, into a searchable [Graphlit](https://www.graphlit.com) project.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/64a5291e7847ac04fe1531ad/64a529af2f1fc7debc26f2a6_favicon-32x32.avif\" alt=\"Gremlin favicon\" /> **[Gremlin](https://github.com/gremlin/mcp)** - The official [Gremlin](https://www.gremlin.com) MCP server. Analyze your reliability posture, review recent tests and chaos engineering experiments, and create detailed reports.\n- <img height=\"12\" width=\"12\" src=\"https://greptime.com/favicon.ico\" alt=\"Greptime Logo\" /> **[GreptimeDB](https://github.com/GreptimeTeam/greptimedb-mcp-server)** - Provides AI assistants with a secure and structured way to explore and analyze data in [GreptimeDB](https://github.com/GreptimeTeam/greptimedb).\n- <img height=\"12\" width=\"12\" src=\"https://growi.org/assets/images/favicon.ico\" alt=\"GROWI Logo\" /> **[GROWI](https://github.com/growilabs/growi-mcp-server)** - Official MCP Server to integrate with GROWI APIs.\n- <img height=\"12\" width=\"12\" src=\"https://gyazo.com/favicon.ico\" alt=\"Gyazo Logo\" /> **[Gyazo](https://github.com/nota/gyazo-mcp-server)** - Search, fetch, upload, and interact with Gyazo images, including metadata and OCR data.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/6374050260446c42f94dc90f/63d828be3e13d32ee6973f35_favicon-32x32.png\" alt=\"Harper Logo\" /> **[Harper](https://github.com/HarperDB/mcp-server)** - An MCP server providing an interface for MCP clients to access data within [Harper](https://www.harpersystems.dev/).\n- <img height=\"12\" width=\"12\" src=\"https://www.herokucdn.com/favicons/favicon.ico\" alt=\"Heroku Logo\" /> **[Heroku](https://github.com/heroku/heroku-mcp-server)** - Interact with the Heroku Platform through LLM-driven tools for managing apps, add-ons, dynos, databases, and more.\n- <img height=\"12\" width=\"12\" src=\"https://heyoncall.com/favicon.ico\" alt=\"HeyOnCall Logo\" /> **[HeyOnCall](https://heyoncall.com/blog/mcp-server-for-paging-a-human)** - Page a human, sending critical or non-critical alerts to the free [HeyOnCall](https://heyoncall.com/) iOS or Android apps.\n- <img height=\"12\" width=\"12\" src=\"https://www.hiveflow.ai/favicon.ico\" alt=\"Hiveflow Logo\" /> **[Hiveflow](https://github.com/hiveflowai/hiveflow-mcp-server)** - Create, manage, and execute agentic AI workflows directly from your assistant.\n- <img height=\"12\" width=\"12\" src=\"https://hiveintelligence.xyz/favicon.ico\" alt=\"Hive Intelligence Logo\" /> **[Hive Intelligence](https://github.com/hive-intel/hive-crypto-mcp)** - Ultimate cryptocurrency MCP for AI assistants with unified access to crypto, DeFi, and Web3 analytics\n- <img height=\"12\" width=\"12\" src=\"https://img.alicdn.com/imgextra/i3/O1CN01d9qrry1i6lTNa2BRa_!!6000000004364-2-tps-218-200.png\" alt=\"Hologres Logo\" /> **[Hologres](https://github.com/aliyun/alibabacloud-hologres-mcp-server)** - Connect to a [Hologres](https://www.alibabacloud.com/en/product/hologres) instance, get table metadata, query and analyze data.\n- <img height=\"12\" width=\"12\" src=\"https://brew.sh/assets/img/favicon.ico\" alt=\"Homebrew Logo\" /> **[Homebrew](https://docs.brew.sh/MCP-Server)** Allows [Homebrew](https://brew.sh) users to run Homebrew commands locally.\n- <img height=\"12\" width=\"12\" src=\"https://www.honeycomb.io/favicon.ico\" alt=\"Honeycomb Logo\" /> **[Honeycomb](https://github.com/honeycombio/honeycomb-mcp)** Allows [Honeycomb](https://www.honeycomb.io/) Enterprise customers to query and analyze their data, alerts, dashboards, and more; and cross-reference production behavior with the codebase.\n- <img height=\"12\" width=\"12\" src=\"https://static.hsinfrastatic.net/StyleGuideUI/static-3.438/img/sprocket/favicon-32x32.png\" alt=\"HubSpot Logo\" /> **[HubSpot](https://developer.hubspot.com/mcp)** - Connect, manage, and interact with [HubSpot](https://www.hubspot.com/) CRM data\n- <img height=\"12\" width=\"12\" src=\"https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo.svg\" alt=\"HuggingFace Logo\" /> **[Hugging Face](https://huggingface.co/settings/mcp)** - Connect to the Hugging Face Hub APIs programmatically: semantic search for spaces and papers, exploration of datasets and models, and access to all compatible MCP Gradio tool spaces!\n- <img height=\"12\" width=\"12\" src=\"https://hunter.io/favicon.ico\" alt=\"Hunter Logo\" /> **[Hunter](https://github.com/hunter-io/hunter-mcp)** - Interact with the [Hunter API](https://hunter.io) to get B2B data using natural language.\n- <img height=\"12\" width=\"12\" src=\"https://app.hyperbolic.xyz/hyperbolic-logo.svg\" alt=\"Hyperbolic Labs Logo\" /> **[Hyperbolic](https://github.com/HyperbolicLabs/hyperbolic-mcp)** - Interact with Hyperbolic's GPU cloud, enabling agents and LLMs to view and rent available GPUs, SSH into them, and run GPU-powered workloads for you.\n- <img height=\"12\" width=\"12\" src=\"https://hyperbrowser-assets-bucket.s3.us-east-1.amazonaws.com/Hyperbrowser-logo.png\" alt=\"Hyperbrowsers23 Logo\" /> **[Hyperbrowser](https://github.com/hyperbrowserai/mcp)** - [Hyperbrowser](https://www.hyperbrowser.ai/) is the next-generation platform empowering AI agents and enabling effortless, scalable browser automation.\n- **[IBM wxflows](https://github.com/IBM/wxflows/tree/main/examples/mcp/javascript)** - Tool platform by IBM to build, test and deploy tools for any data source\n- <img height=\"12\" width=\"12\" src=\"https://www.getinboxzero.com/icon.png\" alt=\"Inbox Zero Logo\" /> **[Inbox Zero](https://github.com/elie222/inbox-zero/tree/main/apps/mcp-server)** - AI personal assistant for email [Inbox Zero](https://www.getinboxzero.com)\n- <img height=\"12\" width=\"12\" src=\"https://www.inflectra.com/Favicon.ico\" alt=\"Inflectra Logo\" /> **[Inflectra Spira](https://github.com/Inflectra/mcp-server-spira)** - Connect to your instance of the SpiraTest, SpiraTeam or SpiraPlan application lifecycle management platform by [Inflectra](https://www.inflectra.com)\n-  **[Inkeep](https://github.com/inkeep/mcp-server-python)** - RAG Search over your content powered by [Inkeep](https://inkeep.com)\n- <img height=\"12\" width=\"12\" src=\"https://integration.app/favicon.ico\" alt=\"Integration App Icon\" /> **[Integration App](https://github.com/integration-app/mcp-server)** - Interact with any other SaaS applications on behalf of your customers.\n- <img height=\"12\" width=\"12\" src=\"https://www.ip2location.io/favicon.ico\" alt=\"IP2Location.io Icon\" /> **[IP2Location.io](https://github.com/ip2location/mcp-ip2location-io)** - Interact with IP2Location.io API to retrieve the geolocation information for an IP address.\n- <img height=\"12\" width=\"12\" src=\"https://static.iplocate.io/custom/logo-square-rounded.png\" alt=\"IPLocate Icon\" /> **[IPLocate](https://github.com/iplocate/mcp-server-iplocate)** - Look up IP address geolocation, network information, detect proxies and VPNs, and find abuse contact details using [IPLocate.io](https://www.iplocate.io)\n- <img height=\"12\" width=\"12\" src=\"https://jellyfish.co/favicon.ico\" alt=\"Jellyfish Logo\" /> **[Jellyfish](https://github.com/Jellyfish-AI/jellyfish-mcp)** – Give your AI agent context about your team's software engineering allocations and workflow via the [Jellyfish](https://jellyfish.co) platform\n- <img alt=\"jetbrains\" height=\"12\" width=\"12\" src=\"https://cdn.simpleicons.org/jetbrains\" /> **[JetBrains](https://www.jetbrains.com/help/idea/mcp-server.html)** – Work on your code with JetBrains IDEs: IntelliJ IDEA, PhpStorm, etc.\n- <img height=\"12\" width=\"12\" src=\"https://speedmedia.jfrog.com/08612fe1-9391-4cf3-ac1a-6dd49c36b276/media.jfrog.com/wp-content/uploads/2019/04/20131046/Jfrog16-1.png\" alt=\"JFrog Logo\" /> **[JFrog](https://github.com/jfrog/mcp-jfrog)** - Model Context Protocol (MCP) Server for the [JFrog](https://jfrog.com/) Platform API, enabling repository management, build tracking, release lifecycle management, and more.\n- <img height=\"12\" width=\"12\" src=\"https://jenkins.io/images/logos/jenkins/jenkins.svg\" alt=\"Jenkins Logo\" /> **[Jenkins](https://plugins.jenkins.io/mcp-server/)** - Official Jenkins MCP Server plugin enabling AI assistants to manage builds, check job statuses, retrieve logs, and integrate with CI/CD pipelines through standardized MCP interface.\n- <img height=\"12\" width=\"12\" src=\"https://kagi.com/favicon.ico\" alt=\"Kagi Logo\" /> **[Kagi Search](https://github.com/kagisearch/kagimcp)** - Search the web using Kagi's search API\n- <img height=\"12\" width=\"12\" src=\"https://connection.keboola.com/favicon.ico\" alt=\"Keboola Logo\" /> **[Keboola](https://github.com/keboola/keboola-mcp-server)** - Build robust data workflows, integrations, and analytics on a single intuitive platform.\n- <img height=\"12\" width=\"12\" src=\"https://mcp.onkernel.com/favicon.svg\" alt=\"Kernel Logo\" /> **[Kernel](https://github.com/onkernel/kernel-mcp-server)** – Access Kernel's cloud‑based browsers via MCP.\n- <img height=\"12\" width=\"12\" src=\"https://keywordseverywhere.com/favicon.ico\" alt=\"Keywords Everywhere Logo\" /> **[Keywords Everywhere](https://api.keywordseverywhere.com/docs/#/mcp_integration)** – Access SEO data through the official Keywords Everywhere API MCP server.\n- <img height=\"12\" width=\"12\" src=\"https://keywordspeopleuse.com/favicon.ico\" alt=\"KeywordsPeopleUse Logo\" /> **[KeywordsPeopleUse.com](https://github.com/data-skunks/kpu-mcp)** - Find questions people ask online with [KeywordsPeopleUse](https://keywordspeopleuse.com).\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/4815054\" alt=\"Kintone Logo\" /> **[Kintone](https://github.com/kintone/mcp-server)** - The official local MCP server for [Kintone](https://kintone.com).\n- <img height=\"12\" width=\"12\" src=\"https://kirokuforms.com/favicon.svg\" alt=\"KirokuForms Logo\" /> **[KirokuForms](https://www.kirokuforms.com/ai/mcp)** - [KirokuForms](https://www.kirokuforms.com) is an AI-powered form platform combining professional form building with Human-in-the-Loop (HITL) capabilities. Create custom forms, collect submissions, and integrate human oversight into AI workflows through [MCP integration](https://kirokuforms.com/ai/mcp).\n- <img height=\"12\" width=\"12\" src=\"https://raw.githubusercontent.com/klavis-ai/klavis/main/static/klavis-ai.png\" alt=\"Klavis Logo\" /> **[Klavis ReportGen](https://github.com/Klavis-AI/klavis/tree/main/mcp_servers/report_generation)** - Create professional reports from a simple user query.\n- <img height=\"12\" width=\"12\" src=\"https://www.klaviyo.com/media/Favicon-16by16.png\" alt=\"Klaviyo Logo\" /> **[Klaviyo](https://developers.klaviyo.com/en/docs/klaviyo_mcp_server)** - Interact with your [Klaviyo](https://www.klaviyo.com/) marketing data.\n- <img height=\"12\" width=\"12\" src=\"https://platform.kluster.ai/logo-light.svg\" alt=\"kluster.ai Logo\" /> **[kluster.ai](https://docs.kluster.ai/get-started/mcp/overview/)** - kluster.ai provides MCP servers that bring AI services directly into your development workflow, including guardrails like hallucination detection.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/6347ea26001f0287c592ff91/649953ef7a9ffe1f3e492b5a_Knit%20Logo.svg\" alt=\"Knit Logo\" /> **[Knit MCP Server](https://developers.getknit.dev/docs/knit-mcp-server-getting-started)** - Production-ready remote MCP servers that enable you to connect with 10000+ tools across CRM, HRIS, Payroll, Accounting, ERP, Calendar, Expense Management, and Chat categories.\n- <img height=\"12\" width=\"12\" src=\"https://knock.app/favicon/favicon-dark.svg\" alt=\"Knock Logo\" /> **[Knock MCP Server](https://github.com/knocklabs/agent-toolkit#model-context-protocol-mcp)** - Send product and customer messaging across email, in-app, push, SMS, Slack, MS Teams.\n- <img height=\"12\" width=\"12\" src=\"https://kumo-sdk-public.s3.us-west-2.amazonaws.com/rfm-colabs/kumo_ai_logo.jpeg\" alt=\"Kumo Logo\" /> **[Kumo](https://github.com/kumo-ai/kumo-rfm-mcp)** - MCP Server to interact with KumoRFM, a foundation model for generating predictions from your relational data.\n- <img height=\"12\" width=\"12\" src=\"https://www.kurrent.io/favicon.ico\" alt=\"Kurrent Logo\" /> **[KurrentDB](https://github.com/kurrent-io/mcp-server)** - This is a simple MCP server to help you explore data and prototype projections faster on top of KurrentDB.\n- <img height=\"12\" width=\"12\" src=\"https://kuzudb.com/favicon.ico\" alt=\"Kuzu Logo\" /> **[Kuzu](https://github.com/kuzudb/kuzu-mcp-server)** - This server enables LLMs to inspect database schemas and execute queries on the provided Kuzu graph database. See [blog](https://blog.kuzudb.com/post/2025-03-23-kuzu-mcp-server/)) for a debugging use case.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/187484914\" alt=\"KWDB Logo\" /> **[KWDB](https://github.com/KWDB/kwdb-mcp-server)** - Reading, writing, querying, modifying data, and performing DDL operations with data in your KWDB Database.\n- <img height=\"12\" width=\"12\" src=\"https://labelstud.io/favicon-16x16.png\" alt=\"Label Studio Logo\" /> **[Label Studio](https://github.com/HumanSignal/label-studio-mcp-server)** - Open Source data labeling platform.\n- <img src=\"https://avatars.githubusercontent.com/u/188884511?s=48&v=4\" alt=\"Lambda Capture\" width=\"12\" height=\"12\"> **[Lambda Capture](https://github.com/lambda-capture/mcp-server)** - Macroeconomic Forecasts & Semantic Context from Federal Reserve, Bank of England, ECB.\n- <img src=\"https://www.lambdatest.com/resources/images/header/professional-service.svg\" alt=\"LambdaTest MCP server\" width=\"12\" height=\"12\"> **[LambdaTest](https://www.lambdatest.com/mcp)** - LambdaTest MCP Servers ranging from Accessibility, SmartUI, Automation, and HyperExecute allows you to connect AI assistants with your testing workflow, streamlining setup, analyzing failures, and generating fixes to speed up testing and improve efficiency.\n- <img height=\"12\" width=\"12\" src=\"https://langfuse.com/favicon.ico\" alt=\"Langfuse Logo\" /> **[Langfuse Prompt Management](https://github.com/langfuse/mcp-server-langfuse)** - Open-source tool for collaborative editing, versioning, evaluating, and releasing prompts.\n- <img height=\"12\" width=\"12\" src=\"https://laratranslate.com/favicon.ico\" alt=\"Lara Translate Logo\" /> **[Lara Translate](https://github.com/translated/lara-mcp)** - MCP Server for Lara Translate API, enabling powerful translation capabilities with support for language detection and context-aware translations.\n- <img height=\"12\" width=\"12\" src=\"https://last9.io/favicon.png\" alt=\"Last9 Logo\" /> **[Last9](https://github.com/last9/last9-mcp-server)** - Seamlessly bring real-time production context—logs, metrics, and traces—into your local environment to auto-fix code faster.\n- <img height=\"12\" width=\"12\" src=\"https://www.launchdarkly.com/favicon.ico\" alt=\"LaunchDarkly Logo\" /> **[LaunchDarkly](https://github.com/launchdarkly/mcp-server)** - LaunchDarkly is a continuous delivery platform that provides feature flags as a service and allows developers to iterate quickly and safely.\n- <img height=\"12\" width=\"12\" src=\"https://www.line.me/favicon-32x32.png\" alt=\"LINE Logo\" /> **[LINE](https://github.com/line/line-bot-mcp-server)** - Integrates the LINE Messaging API to connect an AI Agent to the LINE Official Account.\n- <img height=\"12\" width=\"12\" src=\"https://linear.app/favicon.ico\" alt=\"Linear Logo\" /> **[Linear](https://linear.app/docs/mcp)** - Search, create, and update Linear issues, projects, and comments.\n- <img height=\"12\" width=\"12\" src=\"https://lingo.dev/favicon.ico\" alt=\"Lingo.dev Logo\" /> **[Lingo.dev](https://github.com/lingodotdev/lingo.dev/blob/main/mcp.md)** - Make your AI agent speak every language on the planet, using [Lingo.dev](https://lingo.dev) Localization Engine.\n- <img height=\"12\" width=\"12\" src=\"https://ligo.ertiqah.com/favicon.avif\" alt=\"LiGo Logo\" /> **[LinkedIn MCP Runner](https://github.com/ertiqah/linkedin-mcp-runner)** - Write, edit, and schedule LinkedIn posts right from ChatGPT and Claude with [LiGo](https://ligo.ertiqah.com/).\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/175112039?s=200&v=4\" alt=\"Linkup Logo\" /> **[Linkup](https://github.com/LinkupPlatform/js-mcp-server)** - (JS version) MCP server that provides web search capabilities through Linkup's advanced search API. This server enables AI assistants and development tools to perform intelligent web searches with natural language queries.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/175112039?s=200&v=4\" alt=\"Linkup Logo\" /> **[Linkup](https://github.com/LinkupPlatform/python-mcp-server)** - (Python version) MCP server that provides web search capabilities through Linkup's advanced search API. This server enables AI assistants and development tools to perform intelligent web searches with natural language queries.\n- <img src=\"https://avatars.githubusercontent.com/u/149083471\" alt=\"Lippia.io\" width=\"12\" height=\"12\"> **[Lippia](https://github.com/Lippia-io/Lippia-MCP-Server/blob/main/getting-started.md)** - MCP Server to accelerate Test Automation using Lippia Framework.\n- <img src=\"https://gornschool.com/gorn.png\" alt=\"Lisply\" width=\"12\" height=\"12\"> **[Lisply](https://github.com/gornskew/lisply-mcp)** - Flexible frontend for compliant Lisp-speaking backends.\n- <img height=\"12\" width=\"12\" src=\"https://litmus.io/favicon.ico\" alt=\"Litmus.io Logo\" /> **[Litmus.io](https://github.com/litmusautomation/litmus-mcp-server)** - Official MCP server for configuring [Litmus](https://litmus.io) Edge for Industrial Data Collection, Edge Analytics & Industrial AI.\n- <img height=\"12\" width=\"12\" src=\"https://liveblocks.io/favicon.ico\" alt=\"Liveblocks Logo\" /> **[Liveblocks](https://github.com/liveblocks/liveblocks-mcp-server)** - Ready‑made features for AI & human collaboration—use this to develop your [Liveblocks](https://liveblocks.io) app quicker.\n- <img height=\"12\" width=\"12\" src=\"https://logfire.pydantic.dev/favicon.ico\" alt=\"Logfire Logo\" /> **[Logfire](https://github.com/pydantic/logfire-mcp)** - Provides access to OpenTelemetry traces and metrics through Logfire.\n- <img height=\"12\" width=\"12\" src=\"https://make.magicmealkits.com/favicon.ico\" alt=\"Magic Meal Kits Logo\" /> **[Magic Meal Kits](https://github.com/pureugong/mmk-mcp)** - Unleash Make's Full Potential by [Magic Meal Kits](https://make.magicmealkits.com/)\n- <img height=\"12\" width=\"12\" src=\"https://www.mailgun.com/favicon.ico\" alt=\"Mailgun Logo\" /> **[Mailgun](https://github.com/mailgun/mailgun-mcp-server)** - Interact with Mailgun API.\n- <img height=\"12\" width=\"12\" src=\"https://www.mailjet.com/favicon.ico\" alt=\"Mailjet Logo\" /> **[Mailjet](https://github.com/mailgun/mailjet-mcp-server)** - Official MCP server which allows AI agents to interact with contact, campaign, segmentation, statistics, workflow (and more) APIs from [Sinch Mailjet](https://www.mailjet.com).\n- <img height=\"12\" width=\"12\" src=\"https://www.make.com/favicon.ico\" alt=\"Make Logo\" /> **[Make](https://github.com/integromat/make-mcp-server)** - Turn your [Make](https://www.make.com/) scenarios into callable tools for AI assistants.\n- <img height=\"12\" width=\"12\" src=\"https://static-assets.mapbox.com/branding/favicon/v1/favicon.ico\" alt=\"Mapbox Logo\" /> **[Mapbox](https://github.com/mapbox/mcp-server)** - Unlock geospatial intelligence through Mapbox APIs like geocoding, POI search, directions, isochrones and more.\n- <img height=\"12\" width=\"12\" src=\"https://www.mariadb.com/favicon.ico\" alt=\"MariaDB Logo\" /> **[MariaDB](https://github.com/mariadb/mcp)** - A standard interface for managing and querying MariaDB databases, supporting both standard SQL operations and advanced vector/embedding-based search.\n- <img height=\"14\" width=\"14\" src=\"https://raw.githubusercontent.com/rust-mcp-stack/mcp-discovery/refs/heads/main/docs/_media/mcp-discovery-logo.png\" alt=\"mcp-discovery logo\" /> **[MCP Discovery](https://github.com/rust-mcp-stack/mcp-discovery)** - A lightweight CLI tool built in Rust for discovering MCP server capabilities.\n- <img height=\"12\" width=\"12\" src=\"https://googleapis.github.io/genai-toolbox/favicons/favicon.ico\" alt=\"MCP Toolbox for Databases Logo\" /> **[MCP Toolbox for Databases](https://github.com/googleapis/genai-toolbox)** - Open source MCP server specializing in easy, fast, and secure tools for Databases. Supports  AlloyDB, BigQuery, Bigtable, Cloud SQL, Dgraph, Looker, MySQL, Neo4j, Postgres, Spanner, and more.\n- <img height=\"12\" width=\"12\" src=\"https://www.meilisearch.com/favicon.ico\" alt=\"Meilisearch Logo\" /> **[Meilisearch](https://github.com/meilisearch/meilisearch-mcp)** - Interact & query with Meilisearch (Full-text & semantic search API)\n- <img height=\"12\" width=\"12\" src=\"https://memgraph.com/favicon.png\" alt=\"Memgraph Logo\" /> **[Memgraph](https://github.com/memgraph/ai-toolkit/tree/main/integrations/mcp-memgraph)** - Query your data in [Memgraph](https://memgraph.com/) graph database.\n- <img height=\"12\" width=\"12\" src=\"https://www.mercadolibre.com.ar/favicon.ico\" alt=\"MercadoLibre Logo\" /> **[Mercado Libre](https://mcp.mercadolibre.com/)** - Mercado Libre's official MCP server.\n- <img height=\"12\" width=\"12\" src=\"https://www.mercadopago.com/favicon.ico\" alt=\"MercadoPago Logo\" /> **[Mercado Pago](https://mcp.mercadopago.com/)** - Mercado Pago's official MCP server.\n- <img height=\"12\" width=\"12\" src=\"https://metoro.io/static/images/logos/MetoroLogo.png\" alt=\"Metoro Logo\" /> **[Metoro](https://github.com/metoro-io/metoro-mcp-server)** - Query and interact with kubernetes environments monitored by Metoro\n- <img height=\"12\" width=\"12\" src=\"https://claritystatic.azureedge.net/images/logo.ico\" alt=\"Microsoft Clarity Logo\"/> **[Microsoft Clarity](https://github.com/microsoft/clarity-mcp-server)** - Official MCP Server to get your behavioral analytics data and insights from [Clarity](https://clarity.microsoft.com)\n- <img height=\"12\" width=\"12\" src=\"https://conn-afd-prod-endpoint-bmc9bqahasf3grgk.b01.azurefd.net/releases/v1.0.1735/1.0.1735.4099/commondataserviceforapps/icon.png\" alt=\"Microsoft Dataverse Logo\" /> **[Microsoft Dataverse](https://go.microsoft.com/fwlink/?linkid=2320176)** - Chat over your business data using NL - Discover tables, run queries, retrieve data, insert or update records, and execute custom prompts grounded in business knowledge and context.\n- <img height=\"12\" width=\"12\" src=\"https://learn.microsoft.com/favicon.ico\" alt=\"Microsoft Learn Logo\" /> **[Microsoft Learn Docs](https://github.com/microsoftdocs/mcp)** - An MCP server that provides structured access to Microsoft's official documentation. Retrieves accurate, authoritative, and context-aware technical content for code generation, question answering, and workflow grounding.\n- <img height=\"12\" width=\"12\" src=\"https://statics.teams.microsoft.com/hashedassets/favicon/prod/favicon-9f45b466.ico\" alt=\"Microsoft Teams Logo\" /> **[Microsoft Teams](https://devblogs.microsoft.com/microsoft365dev/announcing-the-updated-teams-ai-library-and-mcp-support/)** - Official Microsoft Teams AI Library with MCP support enabling advanced agent orchestration, multi-agent collaboration, and seamless integration with Teams messaging and collaboration features.\n- <img alt=\"favicon_32x32\" height=\"12\" width=\"12\" src=\"https://milvus.io/favicon-32x32.png\" /> **[Milvus](https://github.com/zilliztech/mcp-server-milvus)** - Search, Query and interact with data in your Milvus Vector Database.\n- <img src=\"https://www.mimilabs.ai/logos/mimilabsSquare.svg\" alt=\"mimilabs\" width=\"12\" height=\"12\"> **[mimilabs](https://www.mimilabs.ai/mcp)** - A US healthcare data discovery guide for 50+ gov sources and thousands of publicly available US healthcare datasets regarding gov-funded programs, policies, drug pricings, clinical trials, etc.\n- <img src=\"https://avatars.githubusercontent.com/u/94089762?s=48&v=4\" alt=\"Mobb\" width=\"12\" height=\"12\"> **[Mobb](https://github.com/mobb-dev/bugsy?tab=readme-ov-file#model-context-protocol-mcp-server)** - The [Mobb Vibe Shield](https://vibe.mobb.ai/) MCP server identifies and remediates vulnerabilities in both human and AI-written code, ensuring your applications remain secure without slowing development.\n- <img alt=\"favicon\" height=\"12\" width=\"12\" src=\"https://console.gomomento.com/favicon.ico\" /> **[Momento](https://github.com/momentohq/mcp-momento)** - Momento Cache lets you quickly improve your performance, reduce costs, and handle load at any scale.\n- <img height=\"12\" width=\"12\" src=\"https://www.monday.com/favicon.ico\" alt=\"Monday.com Logo\" /> **[Monday.com](https://github.com/mondaycom/mcp)** - Interact with Monday.com boards, items, accounts and work forms.\n- <img alt=\"favicon\" height=\"12\" width=\"12\" src=\"https://www.mongodb.com/favicon.ico\" /> **[MongoDB](https://github.com/mongodb-js/mongodb-mcp-server)** - Both MongoDB Community Server and MongoDB Atlas are supported.\n- <img height=\"12\" width=\"12\" src=\"https://moorcheh.ai/Moorcheh-mcp.ico\" alt=\"Moorcheh Logo\" /> **[Moorcheh](https://github.com/moorcheh-ai/moorcheh-mcp)** - Embed, store, and search your documents, and build secure chatbots and RAG systems with Moorcheh's information-theoretic semantic search engine\n- <img height=\"12\" width=\"12\" src=\"https://www.motherduck.com/favicon.ico\" alt=\"MotherDuck Logo\" /> **[MotherDuck](https://github.com/motherduckdb/mcp-server-motherduck)** - Query and analyze data with MotherDuck and local DuckDB\n- <img height=\"12\" width=\"12\" src=\"https://docs.mulesoft.com/_/img/favicon.ico\" alt=\"Mulesoft Logo\" /> **[Mulesoft](https://www.npmjs.com/package/@mulesoft/mcp-server)** - Build, deploy, and manage MuleSoft applications with natural language, directly inside any compatible IDE.\n- <img height=\"12\" width=\"12\" src=\"https://www.multiplayer.app/favicon-32x32.png\" alt=\"Multiplayer Logo\" /> **[Multiplayer](https://www.multiplayer.app/docs/ai/mcp-server)** - Analyze your full stack session recordings easily. Record a bug with Multiplayer, analyze and fix it with LLM\n-  **[Nango](https://docs.nango.dev/guides/use-cases/mcp-server)** - Integrate your AI agent with 500+ APIs: Auth, custom tools, and observability. Open-source.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/38020270\" alt=\"NanoVMs Logo\" /> **[NanoVMs](https://github.com/nanovms/ops-mcp)** - Easily Build and Deploy unikernels to any cloud.\n- <img height=\"12\" width=\"12\" src=\"https://needle-ai.com/images/needle-logo-orange-2-rounded.png\" alt=\"Needle AI Logo\" /> **[Needle](https://github.com/needle-ai/needle-mcp)** - Production-ready RAG out of the box to search and retrieve data from your own documents.\n- <img height=\"12\" width=\"12\" src=\"https://neo4j.com/favicon.ico\" alt=\"Neo4j Logo\" /> **[Neo4j](https://github.com/neo4j-contrib/mcp-neo4j/)** - Neo4j graph database server (schema + read/write-cypher) and separate graph database backed memory\n- <img height=\"12\" width=\"12\" src=\"https://knowall.ai/favicon.ico\" alt=\"Neo4j Agent Memory Logo\" /> **[Neo4j Agent Memory](https://github.com/knowall-ai/mcp-neo4j-agent-memory)** - Memory management for AI agents using Neo4j knowledge graphs\n- <img height=\"12\" width=\"12\" src=\"https://neo4j.com/favicon.ico\" alt=\"Neo4j Logo\" /> **[Neo4j GDS](https://github.com/neo4j-contrib/gds-agent)** - Neo4j graph data science server with comprehensive graph algorithms that enables complex graph reasoning and Q&A.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/183852044?s=48&v=4\" alt=\"Neon Logo\" /> **[Neon](https://github.com/neondatabase/mcp-server-neon)** - Interact with the Neon serverless Postgres platform\n- <img height=\"12\" width=\"12\" src=\"https://app.usenerve.com/favicon.ico\" alt=\"Nerve Logo\" /> **[Nerve](https://github.com/nerve-hq/nerve-mcp-server)** - Search and Act on all your company data across all your SaaS apps via [Nerve](https://www.usenerve.com/)\n- <img height=\"12\" width=\"12\" src=\"https://www.netdata.cloud/favicon-32x32.png\" alt=\"Netdata Logo\" /> **[Netdata](https://github.com/netdata/netdata/blob/master/src/web/mcp/README.md)** - Discovery, exploration, reporting and root cause analysis using all observability data, including metrics, logs, systems, containers, processes, and network connections\n- <img height=\"12\" width=\"12\" src=\"https://www.netlify.com/favicon/icon.svg\" alt=\"Netlify Logo\" /> **[Netlify](https://docs.netlify.com/welcome/build-with-ai/netlify-mcp-server/)** - Create, build, deploy, and manage your websites with Netlify web platform.\n- <img height=\"12\" width=\"12\" src=\"https://www.thenile.dev/favicon.ico\" alt=\"Nile Logo\" /> **[Nile](https://github.com/niledatabase/nile-mcp-server)** - An MCP server that talks to Nile - Postgres re-engineered for B2B apps. Manage and query databases, tenants, users, auth using LLMs\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/208441832?s=400&v=4\" alt=\"Nodit Logo\" /> **[Nodit](https://github.com/noditlabs/nodit-mcp-server)** - Official Nodit MCP Server enabling access to multi-chain RPC Nodes and Data APIs for blockchain data.\n- <img height=\"12\" width=\"12\" src=\"https://app.norman.finance/favicons/favicon-32x32.png\" alt=\"Norman Logo\" /> **[Norman Finance](https://github.com/norman-finance/norman-mcp-server)** - MCP server for managing accounting and taxes with Norman Finance.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/4792552?s=200&v=4\" alt=\"Notion Logo\" /> **[Notion](https://github.com/makenotion/notion-mcp-server#readme)** - This project implements an MCP server for the Notion API.\n-  **[Nutrient](https://github.com/PSPDFKit/nutrient-dws-mcp-server)** - Create, Edit, Sign, Extract Documents using Natural Language\n- <img height=\"12\" width=\"12\" src=\"https://nx.dev/favicon/favicon.svg\" alt=\"Nx Logo\" /> **[Nx](https://github.com/nrwl/nx-console/blob/master/apps/nx-mcp)** - Makes [Nx's understanding](https://nx.dev/features/enhance-AI) of your codebase accessible to LLMs, providing insights into the codebase architecture, project relationships and runnable tasks thus allowing AI to make precise code suggestions.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/82347605?s=48&v=4\" alt=\"OceanBase Logo\" /> **[OceanBase](https://github.com/oceanbase/mcp-oceanbase)** - MCP Server for OceanBase database and its tools\n- <img height=\"12\" width=\"12\" src=\"https://docs.octagonagents.com/logo.svg\" alt=\"Octagon Logo\" /> **[Octagon](https://github.com/OctagonAI/octagon-mcp-server)** - Deliver real-time investment research with extensive private and public market data.\n- <img height=\"12\" width=\"12\" src=\"https://octoeverywhere.com/img/logo.png\" alt=\"OctoEverywhere Logo\" /> **[OctoEverywhere](https://github.com/OctoEverywhere/mcp)** - A 3D Printing MCP server that allows for querying for live state, webcam snapshots, and 3D printer control.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/211697972\" alt=\"Offorte Logo\" /> **[Offorte](https://github.com/offorte/offorte-mcp-server#readme)** - Offorte Proposal Software official MCP server enables creation and sending of business proposals.\n-  **[OlaMaps](https://pypi.org/project/ola-maps-mcp-server)** - Official Ola Maps MCP Server for services like geocode, directions, place details and many more.\n- <img height=\"12\" width=\"12\" src=\"https://www.olostep.com/favicon.ico\" alt=\"Olostep\" /> **[Olostep](https://github.com/olostep/olostep-mcp-server)** - Search, scrape and crawl content from web. Real-time results in clean markdown.\n- <img height=\"12\" width=\"12\" src=\"https://static.onlyoffice.com/images/favicon.ico\" alt=\"ONLYOFFICE DocSpace\" /> **[ONLYOFFICE DocSpace](https://github.com/ONLYOFFICE/docspace-mcp)** - Interact with [ONLYOFFICE DocSpace](https://www.onlyoffice.com/docspace.aspx) API to create rooms, manage files and folders.\n- **[OMOP MCP](https://github.com/OHNLP/omop_mcp)** - Map clinical terminology to OMOP concepts using LLMs for healthcare data standardization.\n- <img height=\"12\" width=\"12\" src=\"https://op.gg/favicon.ico\" alt=\"OP.GG Logo\" /> **[OP.GG](https://github.com/opgginc/opgg-mcp)** - Access real-time gaming data across popular titles like League of Legends, TFT, and Valorant, offering champion analytics, esports schedules, meta compositions, and character statistics.\n- <img height=\"12\" width=\"12\" src=\"https://www.openfort.io/img/icon.svg\" alt=\"Openfort\" /> **[Openfort](https://github.com/openfort-xyz/mcp)** - Connect your AI to Openfort's smart wallet, auth, and project infrastructure.\n- <img height=\"12\" width=\"12\" src=\"https://open-metadata.org/favicon.ico\" alt=\"OpenMetadata\" /> **[OpenMetadata](https://open-metadata.org/mcp)** - The first Enterprise-grade MCP server for metadata\n- <img height=\"12\" width=\"12\" src=\"https://opensearch.org/wp-content/uploads/2025/01/opensearch_mark_default.svg\" alt=\"OpenSearch Logo\" /> **[OpenSearch](https://github.com/opensearch-project/opensearch-mcp-server-py)** -  MCP server that enables AI agents to perform search and analytics use cases on data stored in [OpenSearch](https://opensearch.org/).\n- <img height=\"12\" width=\"12\" src=\"https://app.opslevel.com/favicon.ico\" alt=\"OpsLevel\" /> **[OpsLevel](https://github.com/opslevel/opslevel-mcp)** - Official MCP Server for [OpsLevel](https://www.opslevel.com).\n- <img height=\"12\" width=\"12\" src=\"https://optuna.org/assets/img/favicon.ico\" alt=\"Optuna Logo\" /> **[Optuna](https://github.com/optuna/optuna-mcp)** - Official MCP server enabling seamless orchestration of hyperparameter search and other optimization tasks with [Optuna](https://optuna.org/).\n- <img height=\"12\" width=\"12\" src=\"https://raw.githubusercontent.com/oracle/mcp/refs/heads/main/oracle.svg\" alt=\"Oracle Logo\" /> **[Oracle](https://docs.oracle.com/en/database/oracle/sql-developer-command-line/25.2/sqcug/starting-and-managing-sqlcl-mcp-server.html#GUID-5F916B5D-8670-42BD-9F8B-D3D2424EC47E)** - Official [Oracle Database: SQLcl ](https://www.oracle.com/database/sqldeveloper/technologies/sqlcl/download/) MCP server enabling all access to any Oracle Database via native MCP support directly in SQLcl.\n- <img height=\"12\" width=\"12\" src=\"https://orshot.com/brand/favicon.svg\" alt=\"Orshot Logo\" /> **[Orshot](https://github.com/rishimohan/orshot-mcp-server)** - Official [Orshot](https://orshot.com) MCP server to dynamically generate images from custom design templates.\n- <img height=\"12\" width=\"12\" src=\"https://oxylabs.io/favicon.ico\" alt=\"Oxylabs Logo\" /> **[Oxylabs](https://github.com/oxylabs/oxylabs-mcp)** - Scrape websites with Oxylabs Web API, supporting dynamic rendering and parsing for structured data extraction.\n- <img height=\"12\" width=\"12\" src=\"https://developer.paddle.com/favicon.svg\" alt=\"Paddle Logo\" /> **[Paddle](https://github.com/PaddleHQ/paddle-mcp-server)** - Interact with the Paddle API. Manage product catalog, billing and subscriptions, and reports.\n- **[PaddleOCR](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/mcp_server.html)** - An MCP server that brings enterprise-grade OCR and document parsing capabilities to AI applications.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.brandfolder.io/YX9ETPCP/at/266537g8kh6mmvt24jvsjb/P-GreenRGB.svg\" alt=\"PagerDuty Logo\" /> **[PagerDuty](https://github.com/PagerDuty/pagerduty-mcp-server)** - Interact with your PagerDuty account, allowing you to manage incidents, services, schedules, and more directly from your MCP-enabled client.\n- **[Pagos](https://github.com/pagos-ai/pagos-mcp)** - Interact with the Pagos API. Query Credit Card BIN Data with more to come.\n- <img height=\"12\" width=\"12\" src=\"https://paiml.com/favicon.ico\" alt=\"PAIML Logo\" /> **[PAIML MCP Agent Toolkit](https://github.com/paiml/paiml-mcp-agent-toolkit)** - Professional project scaffolding toolkit with zero-configuration AI context generation, template generation for Rust/Deno/Python projects, and hybrid neuro-symbolic code analysis.\n- <img height=\"12\" width=\"12\" src=\"https://app.paperinvest.io/favicon.svg\" alt=\"Paper Logo\" /> **[Paper](https://github.com/paperinvest/mcp-server)** - Realistic paper trading platform with market simulation, 22 broker emulations, and professional tools for risk-free trading practice. First trading platform with MCP integration.\n- **[Patronus AI](https://github.com/patronus-ai/patronus-mcp-server)** - Test, evaluate, and optimize AI agents and RAG apps\n- <img height=\"12\" width=\"12\" src=\"https://mcp.paubox.com/paubox.png\" alt=\"Paubox Logo\" />**[Paubox](https://mcp.paubox.com)** - Official MCP server which allows AI agents to interact with Paubox Email API. HITRUST certified.\n- <img height=\"12\" width=\"12\" src=\"https://www.paypalobjects.com/webstatic/icon/favicon.ico\" alt=\"PayPal Logo\" /> **[PayPal](https://mcp.paypal.com)** - PayPal's official MCP server.\n- <img height=\"12\" width=\"12\" src=\"https://ww2-secure.pearl.com/static/pearl/pearl-logo.svg\" alt=\"Pearl Logo\" /> **[Pearl](https://github.com/Pearl-com/pearl_mcp_server)** - Official MCP Server to interact with Pearl API. Connect your AI Agents with 12,000+ certified experts instantly.\n- <img height=\"12\" width=\"12\" src=\"https://www.perplexity.ai/favicon.ico\" alt=\"Perplexity Logo\" /> **[Perplexity](https://github.com/ppl-ai/modelcontextprotocol)** - An MCP server that connects to Perplexity's Sonar API, enabling real-time web-wide research in conversational AI.\n- <img height=\"12\" width=\"12\" src=\"https://www.foxit.com/favicon.ico\" alt=\"Foxit Logo\" /> **[PDFActionInspector](https://github.com/foxitsoftware/PDFActionInspector/tree/develop)** - A Model Context Protocol server for extracting and analyzing JavaScript Actions from PDF files. Provides comprehensive security analysis to detect malicious PDF behaviors, hidden scripts, and potential security threats through AI-assisted risk assessment.\n- <img height=\"12\" width=\"12\" src=\"https://www.pga.com/favicon.ico\" alt=\"PGA Logo\" /> **[PGA (Golf)](https://mcp.pga.com)** - PGA's official MCP Server for all things golf-related. Find a coach, play golf, improve your game, and more.\n- <img alt=\"54333248\" height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/54333248\" /> **[Pinecone](https://github.com/pinecone-io/pinecone-mcp)** - [Pinecone](https://docs.pinecone.io/guides/operations/mcp-server)'s developer MCP Server assist developers in searching documentation and managing data within their development environment.\n- <img alt=\"54333248\" height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/54333248\" /> **[Pinecone Assistant](https://github.com/pinecone-io/assistant-mcp)** - Retrieves context from your [Pinecone Assistant](https://docs.pinecone.io/guides/assistant/mcp-server) knowledge base.\n- <img height=\"12\" width=\"12\" src=\"https://pipedream.com/favicon.ico\" alt=\"Pipedream Logo\" /> **[Pipedream](https://github.com/PipedreamHQ/pipedream/tree/master/modelcontextprotocol)** - Connect with 2,500 APIs with 8,000+ prebuilt tools.\n- <img height=\"12\" width=\"12\" src=\"https://playcanvas.com/static-assets/images/icons/favicon.png\" alt=\"PlayCanvas Logo\" /> **[PlayCanvas](https://github.com/playcanvas/editor-mcp-server)** - Create interactive 3D web apps with the PlayCanvas Editor.\n- <img height=\"12\" width=\"12\" src=\"https://playwright.dev/img/playwright-logo.ico\" alt=\"Playwright Logo\" /> **[Playwright](https://github.com/microsoft/playwright-mcp)** — Browser automation MCP server using Playwright to run tests, navigate pages, capture screenshots, scrape content, and automate web interactions reliably.\n- <img height=\"12\" width=\"12\" src=\"https://www.plugged.in/favicon.ico\" alt=\"Plugged.in Logo\" /> **[Plugged.in](https://github.com/VeriTeknik/pluggedin-mcp)** - A comprehensive proxy that combines multiple MCP servers into a single MCP. It provides discovery and management of tools, prompts, resources, and templates across servers, plus a playground for debugging when building MCP servers.\n- <img height=\"12\" width=\"12\" src=\"https://github.com/port-labs/port-mcp-server/blob/main/assets/port_symbol_white.svg\" alt=\"Port Logo\" /> **[Port IO](https://github.com/port-labs/port-mcp-server)** - Access and manage your software catalog to improve service quality and compliance.\n- **[PostHog](https://github.com/posthog/mcp)** - Interact with PostHog analytics, feature flags, error tracking and more with the official PostHog MCP server.\n- **[Postman API](https://github.com/postmanlabs/postman-api-mcp)** - Manage your Postman resources using the [Postman API](https://www.postman.com/postman/postman-public-workspace/collection/i2uqzpp/postman-api).\n- <img height=\"12\" width=\"12\" src=\"https://powerdrill.ai/_next/static/media/powerdrill.0fa27d00.webp\" alt=\"Powerdrill Logo\" /> **[Powerdrill](https://github.com/powerdrillai/powerdrill-mcp)** - An MCP server that provides tools to interact with Powerdrill datasets, enabling smart AI data analysis and insights.\n- <img height=\"12\" width=\"12\" src=\"https://www.prisma.io/images/favicon-32x32.png\" alt=\"Prisma Logo\" /> **[Prisma](https://www.prisma.io/docs/postgres/mcp-server)** - Create and manage Prisma Postgres databases\n- <img height=\"12\" width=\"12\" src=\"https://probe.dev/favicon.ico\" alt=\"Probe.dev Logo\" /> **[Probe.dev](https://docs.probe.dev/guides/mcp-integration)** - Comprehensive media analysis and validation powered by [Probe.dev](https://probe.dev). Hosted MCP server with FFprobe, MediaInfo, and Probe Report analysis capabilities.\n- <img height=\"12\" width=\"12\" src=\"https://framerusercontent.com/images/FGzpihs4MxmSJhyGZ6n7f2Xj0.png\" alt=\"Prode.ai Logo\" /> **[ProdE](https://github.com/CuriousBox-AI/ProdE-mcp)** - Your 24/7 production engineer that preserves context across multiple codebases.\n- <img height=\"12\" width=\"12\" src=\"https://programintegrity.org/wp-content/uploads/2024/07/PIA-Favicon.svg\" alt=\"Program Integrity Alliance (PIA) Logo\" /> **[Program Integrity Alliance (PIA)](https://github.com/Program-Integrity-Alliance/pia-mcp-local)** - Local and Hosted MCP servers providing AI-friendly access to U.S. Government Open Datasets. Also available on [Docker MCP Catalog](https://hub.docker.com/mcp/explore?search=PIA). See [our website](https://programintegrity.org) for more details.\n- <img height=\"12\" width=\"12\" src=\"https://github.com/newtype-01/prompthouse-mcp/raw/main/prompthouse-logo-12x12.png\" alt=\"PromptHouse Logo\" /> **[PromptHouse](https://github.com/newtype-01/prompthouse-mcp)** - Personal prompt library with MCP integration for AI clients.\n- <img height=\"12\" width=\"12\" src=\"https://docs.speedscale.com/img/favicon.ico\" alt=\"proxymock Logo\" /> **[proxymock](https://docs.speedscale.com/proxymock/reference/mcp/)** - An MCP server that automatically generates tests and mocks by recording a live app.\n- <img src=\"https://www.pubnub.com/favicon/favicon-32x32.png\" alt=\"PubNub\" width=\"12\" height=\"12\"> **[PubNub](https://github.com/pubnub/pubnub-mcp-server)** - Retrieves context for developing with PubNub SDKs and calling APIs.\n- <img height=\"12\" width=\"12\" src=\"https://www.pulumi.com/images/favicon.ico\" alt=\"Pulumi Logo\" /> **[Pulumi](https://github.com/pulumi/mcp-server)** - Deploy and manage cloud infrastructure using [Pulumi](https://pulumi.com).\n- <img height=\"12\" width=\"12\" src=\"https://pure.md/favicon.png\" alt=\"Pure.md Logo\" /> **[Pure.md](https://github.com/puremd/puremd-mcp)** - Reliably access web content in markdown format with [pure.md](https://pure.md) (bot detection avoidance, proxy rotation, and headless JS rendering built in).\n- <img height=\"12\" width=\"12\" src=\"https://put.io/images/favicon.ico\" alt=\"Put.io Logo\" /> **[Put.io](https://github.com/putdotio/putio-mcp-server)** - Interact with your Put.io account to download torrents.\n- <img alt=\"logomark\" height=\"12\" width=\"12\" src=\"https://qdrant.tech/img/brand-resources-logos/logomark.svg\" /> **[Qdrant](https://github.com/qdrant/mcp-server-qdrant/)** - Implement semantic memory layer on top of the Qdrant vector search engine\n- <img src=\"https://api.qoretechnologies.com/api/public/apps/Qorus/qorus-logo.svg\" alt=\"Qorus\" width=\"12\" height=\"12\"> **[Qorus](https://qoretechnologies.com/manual/qorus/current/qorus/sysarch.html#mcp_server)** - Connect to any application, system, or technology and automate your business processes without coding and with AI\n- <img src=\"https://avatars.githubusercontent.com/u/18053493?s=200&v=4\" alt=\"Qonto\" width=\"12\" height=\"12\"> **[Qonto](https://github.com/qonto/qonto-mcp-server)** - Access and interact your Qonto account through LLMs using MCP.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/3912814\" alt=\"QuantConnect Logo\" /> **[QuantConnect](https://github.com/QuantConnect/mcp-server)** - Interact with your [QuantConnect](https://www.quantconnect.com/) account to update projects, write strategies, run backtest, and deploying strategies to production live-trading.\n- **[Quickchat AI](https://github.com/incentivai/quickchat-ai-mcp)** - Launch your conversational [Quickchat AI](https://quickchat.ai) agent as an MCP to give AI apps real-time access to its Knowledge Base and conversational capabilities\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/165178062\" alt=\"Ragie Logo\" /> **[Ragie](https://github.com/ragieai/ragie-mcp-server/)** - Retrieve context from your [Ragie](https://www.ragie.ai) (RAG) knowledge base connected to integrations like Google Drive, Notion, JIRA and more.\n- <img alt=\"favicon\" height=\"12\" width=\"12\" src=\"https://www.ramp.com/favicon.ico\" /> **[Ramp](https://github.com/ramp-public/ramp-mcp)** - Interact with [Ramp](https://ramp.com)'s Developer API to run analysis on your spend and gain insights leveraging LLMs\n- **[Raygun](https://github.com/MindscapeHQ/mcp-server-raygun)** - Interact with your crash reporting and real using monitoring data on your Raygun account\n- <img height=\"12\" width=\"12\" src=\"https://framerusercontent.com/images/CU1m0xFonUl76ZeaW0IdkQ0M.png\" alt=\"Razorpay Logo\" /> **[Razorpay](https://github.com/razorpay/razorpay-mcp-server)** - Razorpay's official MCP server\n- <img height=\"12\" width=\"12\" src=\"https://www.recraft.ai/favicons/icon.svg\" alt=\"Recraft Logo\" /> **[Recraft](https://github.com/recraft-ai/mcp-recraft-server)** - Generate raster and vector (SVG) images using [Recraft](https://recraft.ai). Also you can edit, upscale images, create your own styles, and vectorize raster images\n- <img height=\"12\" width=\"12\" src=\"https://www.redhat.com/favicon.ico\" alt=\"Red Hat Logo\" /> **[Red Hat Insights](https://github.com/RedHatInsights/insights-mcp)** - Interact with [Red Hat Insights](https://www.redhat.com/en/technologies/management/insights) - build images, manage vulnerabilities, or view targeted recommendations.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/1529926\" alt=\"Redis Logo\" /> **[Redis](https://github.com/redis/mcp-redis/)** - The Redis official MCP Server offers an interface to manage and search data in Redis.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/1529926\" alt=\"Redis Logo\" /> **[Redis Cloud API](https://github.com/redis/mcp-redis-cloud/)** - The Redis Cloud API MCP Server allows you to manage your Redis Cloud resources using natural language.\n- <img src=\"https://avatars.githubusercontent.com/u/149024635\" alt=\"Reexpress\" width=\"12\" height=\"12\"> **[Reexpress](https://github.com/ReexpressAI/reexpress_mcp_server)** - Enable Similarity-Distance-Magnitude statistical verification for your search, software, and data science workflows\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/68a872edf3df6064de547670/68b7f089c45a6083ce25acb1_reflag-favicon-32.png\" alt=\"Reflag\" /> **[Reflag](https://github.com/reflagcom/javascript/tree/main/packages/cli#model-context-protocol)** - Create and manage feature flags using [Reflag](https://reflag.com)\n- <img height=\"12\" width=\"12\" src=\"https://www.reltio.com/wp-content/uploads/2024/03/cropped-cropped-Reltio_Light_Mode_Dark_Mode_Favicon-270x270.png\" alt=\"Reltio Logo\" /> **[Reltio](https://github.com/reltio-ai/reltio-mcp-server)** - A lightweight, plugin-based MCP server designed to perform advanced entity matching with language models in Reltio environments.\n- <img height=\"12\" width=\"12\" src=\"https://www.rember.com/favicon.ico\" alt=\"Rember Logo\" /> **[Rember](https://github.com/rember/rember-mcp)** - Create spaced repetition flashcards in [Rember](https://rember.com) to remember anything you learn in your chats\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/114033652\" alt=\"Render Logo\" /> **[Render](https://render.com/docs/mcp-server)** - The official Render MCP server: spin up new services, run queries against your databases, and debug rapidly with direct access to service metrics and logs.\n- <img height=\"12\" width=\"12\" src=\"https://reportportal.io/favicon.ico\" alt=\"ReportPortal Logo\" /> **[ReportPortal](https://github.com/reportportal/reportportal-mcp-server)** - explore and analyze automated test results from [ReportPortal](https://reportportal.io) using your favourite LLM.\n- <img height=\"12\" width=\"12\" src=\"http://nonica.io/Nonica-logo.ico\" alt=\"Nonica Logo\" /> **[Revit](https://github.com/NonicaTeam/AI-Connector-for-Revit)** - Connect and interact with your Revit models live.\n- <img height=\"12\" width=\"12\" src=\"https://ui.rilldata.com/favicon.png\" alt=\"Rill Data Logo\" /> **[Rill Data](https://docs.rilldata.com/explore/mcp)** - Interact with Rill Data to query and analyze your data.\n- <img height=\"12\" width=\"12\" src=\"https://riza.io/favicon.ico\" alt=\"Riza logo\" /> **[Riza](https://github.com/riza-io/riza-mcp)** - Arbitrary code execution and tool-use platform for LLMs by [Riza](https://riza.io)\n- <img height=\"12\" width=\"12\" src=\"https://cdn.foundation.roblox.com/current/RobloxStudio.ico\" alt=\"Roblox Studio\" /> **[Roblox Studio](https://github.com/Roblox/studio-rust-mcp-server)** - Roblox Studio MCP Server, create and manipulate scenes, scripts in Roblox Studio\n- <img src=\"https://hyper3d.ai/favicon.ico\" alt=\"Rodin\" width=\"12\" height=\"12\"> **[Rodin](https://github.com/DeemosTech/rodin-api-mcp)** - Generate 3D Models with [Hyper3D Rodin](https://hyper3d.ai)\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/66b7de6a233c04f4dac200a6/66bed52680d689629483c18b_faviconV2%20(2).png\" alt=\"Root Signals Logo\" /> **[Root Signals](https://github.com/root-signals/root-signals-mcp)** - Improve and quality control your outputs with evaluations using LLM-as-Judge\n- **[Routine](https://github.com/routineco/mcp-server)** - MCP server to interact with [Routine](https://routine.co/): calendars, tasks, notes, etc.\n- <img height=\"12\" width=\"12\" src=\"https://platform.composio.dev/favicon.ico\" alt=\"Composio Logo\"> **[Rube](https://github.com/ComposioHQ/Rube)** - Rube is a Model Context Protocol (MCP) server that connects your AI tools to 500+ apps like Gmail, Slack, GitHub, and Notion. Simply install it in your AI client, authenticate once with your apps, and start asking your AI to perform real actions like \"Send an email\" or \"Create a task.\"\n- <img height=\"12\" width=\"12\" src=\"https://raw.githubusercontent.com/safedep/.github/refs/heads/main/assets/logo/1.png\" alt=\"SafeDep Logo\" /> **[SafeDep](https://github.com/safedep/vet/blob/main/docs/mcp.md)** - SafeDep `vet-mcp` helps in  vetting open source packages for security risks—such as vulnerabilities and malicious code—before they're used in your project, especially with AI-generated code suggestions.\n- <img height=\"12\" width=\"12\" src=\"https://waf-ce.chaitin.cn/favicon.ico\" alt=\"SafeLine Logo\" /> **[SafeLine](https://github.com/chaitin/SafeLine/tree/main/mcp_server)** - [SafeLine](https://safepoint.cloud/landing/safeline) is a self-hosted WAF(Web Application Firewall) to protect your web apps from attacks and exploits.\n- <img height=\"12\" width=\"12\" src=\"https://scrapi.tech/favicon.ico\" alt=\"ScrAPI Logo\" /> **[ScrAPI](https://github.com/DevEnterpriseSoftware/scrapi-mcp)** - Web scraping using [ScrAPI](https://scrapi.tech). Extract website content that is difficult to access because of bot detection, captchas or even geolocation restrictions.\n- <img height=\"12\" width=\"12\" src=\"https://upnorthmedia.co/favicon.ico\" alt=\"Up North Media Logo\" /> **[ScreenshotMCP](https://github.com/upnorthmedia/ScreenshotMCP/)** - A Model Context Protocol MCP server for capturing website screenshots with full page, element, and device size features.\n- <img height=\"12\" width=\"12\" src=\"https://screenshotone.com/favicon.ico\" alt=\"ScreenshotOne Logo\" /> **[ScreenshotOne](https://github.com/screenshotone/mcp/)** - Render website screenshots with [ScreenshotOne](https://screenshotone.com/)\n- <img height=\"12\" width=\"12\" src=\"https://pics.fatwang2.com/56912e614b35093426c515860f9f2234.svg\" alt=\"Search1API Logo\" /> **[Search1API](https://github.com/fatwang2/search1api-mcp)** - One API for Search, Crawling, and Sitemaps\n- <img height=\"12\" width=\"12\" src=\"https://www.searchunify.com/favicon.ico\" alt=\"SearchUnify Logo\" /> **[SearchUnify](https://github.com/searchunify/su-mcp/)** - SearchUnify MCP Server (su-mcp) enables seamless integration of SearchUnify with Claude Desktop\n- <img height=\"12\" width=\"12\" src=\"https://secureframe.com/favicon.ico\" alt=\"Secureframe Logo\" /> **[Secureframe](https://github.com/secureframe/secureframe-mcp-server)** - Query security controls, monitor compliance tests, and access audit data across SOC 2, ISO 27001, CMMC, FedRAMP, and other frameworks from [Secureframe](https://secureframe.com).\n- <img height=\"12\" width=\"12\" src=\"https://semgrep.dev/favicon.ico\" alt=\"Semgrep Logo\" /> **[Semgrep](https://github.com/semgrep/mcp)** - Enable AI agents to secure code with [Semgrep](https://semgrep.dev/).\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/187640573?s=48&v=4\" alt=\"Sequa Logo\" /> **[Sequa.AI](https://github.com/sequa-ai/sequa-mcp)** - Stop stitching context for Copilot and Cursor. With [Sequa MCP](https://github.com/sequa-ai/sequa-mcp), your AI tools know all your codebases and docs out of the box.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/6372338e5477e047032b37a5/64f85e6388a2a5c8c9525b4d_favLogo.png\" alt=\"Shortcut Logo\" /> **[Shortcut](https://github.com/useshortcut/mcp-server-shortcut)** - Access and implement all of your projects and tasks (Stories) from [Shortcut](https://shortcut.com/).\n- <img alt=\"favicon_32x32_png_v_277b9cbbe31e8bc416504cf3b902d430\" height=\"12\" width=\"12\" src=\"https://www.singlestore.com/favicon-32x32.png?v=277b9cbbe31e8bc416504cf3b902d430\"/> **[SingleStore](https://github.com/singlestore-labs/mcp-server-singlestore)** - Interact with the SingleStore database platform\n- <img height=\"12\" width=\"12\" src=\"https://smartbear.com/smartbear/assets/img/favicon.png\" alt=\"SmartBear Logo\" /> **[SmartBear](https://github.com/SmartBear/smartbear-mcp)** - Provides access to multiple capabilities across SmartBear's API Hub, Test Hub, and Insight Hub, all through [dedicated tools and resources](https://developer.smartbear.com/smartbear-mcp/docs/mcp-server).\n- <img src=\"https://smooth-operator.online/logo48.png\" alt=\"Smooth Operator\" width=\"12\" height=\"12\"> **[Smooth Operator](https://smooth-operator.online/agent-tools-api-docs/toolserverdocs)** - Tools to automate Windows via AI Vision, Mouse, Keyboard, Automation Trees, Webbrowser\n- <img height=\"12\" width=\"12\" src=\"https://app.snyk.io/bundle/favicon-faj49uD9.png\" alt=\"Snyk Logo\" /> **[Snyk](https://github.com/snyk/snyk-ls/blob/main/mcp_extension/README.md)** - Enhance security posture by embedding [Snyk](https://snyk.io/) vulnerability scanning directly into agentic workflows.\n- <img height=\"12\" width=\"12\" src=\"https://www.sonarsource.com/favicon.ico\" alt=\"SonarQube Logo\" /> **[SonarQube](https://github.com/SonarSource/sonarqube-mcp-server)** - Enables seamless integration with [SonarQube](https://www.sonarsource.com/) Server or Cloud and allows for code snippet analysis within the agent context.\n- <img src=\"https://sophtron.com/favicon.ico\" alt=\"Sophtron\" width=\"12\" height=\"12\"> **[Sophtron](https://github.com/sophtron/Sophtron-Integration/tree/main/modelcontextprotocol)** - Connect to your bank, credit card, utilities accounts to retrieve account balances and transactions with [Sophtron Bank Integration](https://sophtron.com).\n- <img height=\"12\" width=\"12\" src=\"https://www.stackhawk.com/wp-content/uploads/2025/03/icon-512x512-2-150x150.png\" alt=\"StackHawk Logo\" /> **[StackHawk](https://github.com/stackhawk/stackhawk-mcp)** - Use [StackHawk](https://www.stackhawk.com/) to test for and FIX security problems in your code or vibe coded app.\n- <img height=\"12\" width=\"12\" src=\"https://www.starrocks.io/favicon.ico\" alt=\"StarRocks Logo\" /> **[StarRocks](https://github.com/StarRocks/mcp-server-starrocks)** - Interact with [StarRocks](https://www.starrocks.io/)\n- <img height=\"12\" width=\"12\" src=\"https://downloads.steadybit.com/logomark.svg\" alt=\"Steadybit Logo\" /> **[Steadybit](https://github.com/steadybit/mcp)** - Interact with [Steadybit](https://www.steadybit.com/)\n- <img height=\"12\" width=\"12\" src=\"https://steuerboard.net/favicon.ico\" alt=\"Steuerboard Logo\" /> **[Steuerboard](https://github.com/steuerboard/steuerboard-mcp-typescript)** - Interact with the accounting data in your business using our official MCP server\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/22632046?s=200&v=4\" alt=\"Storybook Logo\" /> **[Storybook](https://github.com/storybookjs/addon-mcp)** - Interact with [Storybook](https://storybook.js.org/) to automate UI component testing and documentation\n- <img height=\"12\" width=\"12\" src=\"https://stripe.com/favicon.ico\" alt=\"Stripe Logo\" /> **[Stripe](https://github.com/stripe/agent-toolkit)** - Interact with Stripe API\n- <img height=\"12\" width=\"12\" src=\"https://sunra.ai/favicon.ico\" alt=\"Sunra AI Logo\" /> **[Sunra AI](https://github.com/sunra-ai/sunra-clients/tree/main/mcp-server)** - Search for and run AI models on [Sunra.ai](https://sunra.ai). Discover models, create video, image, and 3D model content, track their status, and manage the generated media.\n- <img height=\"12\" width=\"12\" src=\"https://supabase.com/favicon/favicon.ico\" alt=\"Supabase Logo\" /> **[Supabase](https://github.com/supabase-community/supabase-mcp)** - Interact with Supabase: Create tables, query data, deploy edge functions, and more.\n- <img height=\"12\" width=\"12\" src=\"https://supadata.ai/favicon.ico\" alt=\"Supadata Logo\" /> **[Supadata](https://github.com/supadata-ai/mcp)** - Official MCP server for [Supadata](https://supadata.ai) - YouTube, TikTok, X and Web data for makers.\n- <img height=\"12\" width=\"12\" src=\"https://d12w4pyrrczi5e.cloudfront.net/archive/50eb154ab859c63a8f1c850f9fe094e25d35e929/images/favicon.ico\" alt=\"Tako Logo\" /> **[Tako](https://github.com/TakoData/tako-mcp)** - Use natural language to search [Tako](https://trytako.com) for real-time financial, sports, weather, and public data with visualization\n- <img height=\"12\" width=\"12\" src=\"https://tavily.com/favicon.ico\" alt=\"Tavily Logo\" /> **[Tavily](https://github.com/tavily-ai/tavily-mcp)** - Search engine for AI agents (search + extract) powered by [Tavily](https://tavily.com/)\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/10522416?s=200&v=4\" alt=\"Telnyx Logo\" /> **[Telnyx](https://github.com/team-telnyx/telnyx-mcp-server)** - Official MCP server for building AI-powered communication apps. Create voice assistants, send SMS campaigns, manage phone numbers, and integrate real-time messaging with enterprise-grade reliability. Includes remote [streamable-http](https://api.telnyx.com/v2/mcp) and [sse](https://api.telnyx.com/mcp/sse) servers.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/1615979?s=200&v=4\" alt=\"Teradata Logo\" /> **[Teradata](https://github.com/Teradata/teradata-mcp-server)** - This MCP Server support tools and prompts for multi task data analytics on a [Teradata](https://teradata.com) platform.\n- <img height=\"12\" width=\"12\" src=\"https://raw.githubusercontent.com/hashicorp/terraform-mcp-server/main/public/images/Terraform-LogoMark_onDark.svg\" alt=\"Terraform Logo\" /> **[Terraform](https://github.com/hashicorp/terraform-mcp-server)** - Seamlessly integrate with Terraform ecosystem, enabling advanced automation and interaction capabilities for Infrastructure as Code (IaC) development powered by [Terraform](https://www.hashicorp.com/en/products/terraform)\n- <img height=\"12\" width=\"12\" src=\"https://www.textin.com/favicon.png\" alt=\"TextIn Logo\" /> **[TextIn](https://github.com/intsig-textin/textin-mcp)** - An MCP server for the [TextIn](https://www.textin.com/?from=github_mcp) API, is a tool for extracting text and performing OCR on documents, it also supports converting documents into Markdown\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/106156665?s=200\" alt=\"Thena Logo\" /> **[Thena](https://mcp.thena.ai)** - Thena's MCP server for enabling users and AI agents to interact with Thena's services and manage customers across different channels such as Slack, Email, Web, Discord etc.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/24291394?v=4\" alt=\"ThingsBoard\" /> **[ThingsBoard](https://github.com/thingsboard/thingsboard-mcp)** - The ThingsBoard MCP Server provides a natural language interface for LLMs and AI agents to interact with your ThingsBoard IoT platform.\n- <img height=\"12\" width=\"12\" src=\"https://www.lg.com/favicon.ico\" alt=\"ThinQ Logo\" /> **[ThinQ Connect](https://github.com/thinq-connect/thinqconnect-mcp)** - Interact with LG ThinQ smart home devices and appliances through the ThinQ Connect MCP server.\n- <img height=\"12\" width=\"12\" src=\"https://thirdweb.com/favicon.ico\" alt=\"Thirdweb Logo\" /> **[Thirdweb](https://github.com/thirdweb-dev/ai/tree/main/python/thirdweb-mcp)** - Read/write to over 2k blockchains, enabling data querying, contract analysis/deployment, and transaction execution, powered by [Thirdweb](https://thirdweb.com/)\n- <img height=\"12\" width=\"12\" src=\"https://www.thoughtspot.com/favicon-16x16.png\" alt=\"ThoughtSpot Logo\" /> **[ThoughtSpot](https://github.com/thoughtspot/mcp-server)** - AI is the new BI. A dedicated data analyst for everyone on your team. Bring [ThoughtSpot](https://thoughtspot.com) powers into Claude or any MCP host.\n- <img height=\"12\" width=\"12\" src=\"https://tianji.msgbyte.com/img/dark-brand.svg\" alt=\"Tianji Logo\" /> **[Tianji](https://github.com/msgbyte/tianji/tree/master/apps/mcp-server)** - Interact with Tianji platform whatever selfhosted or cloud platform, powered by [Tianji](https://tianji.msgbyte.com/).\n- <img height=\"12\" width=\"12\" src=\"https://www.pingcap.com/favicon.ico\" alt=\"TiDB Logo\" /> **[TiDB](https://github.com/pingcap/pytidb)** - MCP Server to interact with TiDB database platform.\n- <img height=\"12\" width=\"12\" src=\"https://www.tinybird.co/favicon.ico\" alt=\"Tinybird Logo\" /> **[Tinybird](https://github.com/tinybirdco/mcp-tinybird)** - Interact with Tinybird serverless ClickHouse platform\n- <img height=\"12\" width=\"12\" src=\"https://b2729162.smushcdn.com/2729162/wp-content/uploads/2023/10/cropped-Favicon-1-192x192.png?lossy=1&strip=1&webp=1\" alt=\"Tldv Logo\" /> **[Tldv](https://gitlab.com/tldv/tldv-mcp-server)** - Connect your AI agents to Google-Meet, Zoom & Microsoft Teams through [tl;dv](https://tldv.io)\n- <img height=\"12\" width=\"12\" src=\"https://www.todoist.com/static/favicon-32x32.png\" alt=\"Todoist Logo\" /> **[Todoist](https://github.com/doist/todoist-ai)** - Search, add, and update [Todoist](https://todoist.com) tasks, projects, sections, comments, and more.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.tokenmetrics.com/logo.svg\" alt=\"Token Metrics Logo\" /> **[Token Metrics](https://github.com/token-metrics/mcp)** - [Token Metrics](https://www.tokenmetrics.com/) integration for fetching real-time crypto market data, trading signals, price predictions, and advanced analytics.\n- <img height=\"12\" width=\"12\" src=\"https://di8m9w6rqrh5d.cloudfront.net/2G3TRwfv1w3GTLfmT7Dmco1VddoFTI5P/1920_6b7e7ec2-d897-4cd7-94f3-46a8301212c3.png\" alt=\"TomTom Logo\" /> **[TomTom-MCP](https://github.com/tomtom-international/tomtom-mcp)** - The [TomTom](https://www.tomtom.com/) MCP Server simplifies geospatial development by providing seamless access to TomTom's location services, including search, routing, traffic and static maps data.\n- <img height=\"12\" width=\"12\" src=\"https://images.thetradeagent.ai/trade_agent/logo.svg\" alt=\"Trade Agent Logo\" /> **[Trade Agent](https://github.com/Trade-Agent/trade-agent-mcp)** - Execute stock and crypto trades on your brokerage via [Trade Agent](https://thetradeagent.ai)\n-  **[Twelve Data](https://github.com/twelvedata/mcp)** — Integrate your AI agents with real-time and historical financial market data through our official [Twelve Data](https://twelvedata.com) MCP server.\n- <img height=\"12\" width=\"12\" src=\"https://www.twilio.com/content/dam/twilio-com/core-assets/social/favicon-16x16.png\" alt=\"Twilio Logo\" /> **[Twilio](https://github.com/twilio-labs/mcp)** - Interact with [Twilio](https://www.twilio.com/en-us) APIs to send SMS messages, manage phone numbers, configure your account, and more.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/91520705?s=48&v=4\" alt=\"Tencent RTC Logo\" /> **[Tencent RTC](https://github.com/Tencent-RTC/mcp)** - The MCP Server enables AI IDEs to more effectively understand and use [Tencent's Real-Time Communication](https://trtc.io/) SDKs and APIs, which significantly streamlines the process for developers to build audio/video call applications.\n- <img height=\"12\" width=\"12\" src=\"https://uberall.com/media/favicon.svg\" alt=\"Uberall Logo\" /> **[Uberall](https://github.com/uberall/uberall-mcp-server)** – Manage multi - location presence, including listings, reviews, and social posting, via [uberall](https://uberall.com).\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/91906527\" alt=\"Unblocked Logo\" /> **[Unblocked](https://docs.getunblocked.com/unblocked-mcp)** Help your AI-powered IDEs generate faster, more accurate code by giving them access to context from Slack, Confluence, Google Docs, JIRA, and more with [Unblocked](https://getunblocked.com).\n- <img height=\"12\" width=\"12\" src=\"https://unifai.network/favicon.ico\" alt=\"UnifAI Logo\" /> **[UnifAI](https://github.com/unifai-network/unifai-mcp-server)** - Dynamically search and call tools using [UnifAI Network](https://unifai.network)\n- <img height=\"12\" width=\"12\" src=\"https://framerusercontent.com/images/plcQevjrOYnyriuGw90NfQBPoQ.jpg\" alt=\"Unstructured Logo\" /> **[Unstructured](https://github.com/Unstructured-IO/UNS-MCP)** - Set up and interact with your unstructured data processing workflows in [Unstructured Platform](https://unstructured.io)\n- <img height=\"12\" width=\"12\" src=\"https://upstash.com/icons/favicon-32x32.png\" alt=\"Upstash Logo\" /> **[Upstash](https://github.com/upstash/mcp-server)** - Manage Redis databases and run Redis commands on [Upstash](https://upstash.com/) with natural language.\n-  **[Vantage](https://github.com/vantage-sh/vantage-mcp-server)** - Interact with your organization's cloud cost spend.\n- <img height=\"12\" width=\"12\" src=\"https://mcp.variflight.com/favicon.ico\" alt=\"VariFlight Logo\" /> **[VariFlight](https://github.com/variflight/variflight-mcp)** - VariFlight's official MCP server provides tools to query flight information, weather data, comfort metrics, the lowest available fares, and other civil aviation-related data.\n- <img height=\"12\" width=\"12\" src=\"https://docs.octagonagents.com/logo.svg\" alt=\"Octagon Logo\" /> **[VCAgents](https://github.com/OctagonAI/octagon-vc-agents)** - Interact with investor agents—think Wilson or Thiel—continuously updated with market intel.\n- **[Vectorize](https://github.com/vectorize-io/vectorize-mcp-server/)** - [Vectorize](https://vectorize.io) MCP server for advanced retrieval, Private Deep Research, Anything-to-Markdown file extraction and text chunking.\n- <img height=\"12\" width=\"12\" src=\"https://static.verbwire.com/favicon-16x16.png\" alt=\"Verbwire Logo\" /> **[Verbwire](https://github.com/verbwire/verbwire-mcp-server)** - Deploy smart contracts, mint NFTs, manage IPFS storage, and more through the Verbwire API\n- <img height=\"12\" width=\"12\" src=\"http://vercel.com/favicon.ico\" alt=\"Vercel Logo\" /> **[Vercel](https://vercel.com/docs/mcp/vercel-mcp)** - Access logs, search docs, and manage projects and deployments.\n- <img height=\"12\" width=\"12\" src=\"https://verodat.io/assets/favicon-16x16.png\" alt=\"Verodat Logo\" /> **[Verodat](https://github.com/Verodat/verodat-mcp-server)** - Interact with Verodat AI Ready Data platform\n- <img height=\"12\" width=\"12\" src=\"https://www.veyrax.com/favicon.ico\" alt=\"VeyraX Logo\" /> **[VeyraX](https://github.com/VeyraX/veyrax-mcp)** - Single tool to control all 100+ API integrations, and UI components\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/174736222?s=200&v=4\" alt=\"VictoriaMetrics Logo\" /> **[VictoriaMetrics](https://github.com/VictoriaMetrics-Community/mcp-victoriametrics)** - Comprehensive integration with [VictoriaMetrics APIs](https://docs.victoriametrics.com/victoriametrics/url-examples/) and [documentation](https://docs.victoriametrics.com/) for monitoring, observability, and debugging tasks related to your VictoriaMetrics instances.\n- <img height=\"12\" width=\"12\" src=\"https://framerusercontent.com/images/ijlYG00LOcMD6zR1XLMxHbAwZkM.png\" alt=\"VideoDB Director\" /> **[VideoDB Director](https://github.com/video-db/agent-toolkit/tree/main/modelcontextprotocol)** - Create AI-powered video workflows including automatic editing, content moderation, voice cloning, highlight generation, and searchable video moments—all accessible via simple APIs and intuitive chat-based interfaces.\n- <img height=\"12\" width=\"12\" src=\"https://landing.ai/wp-content/uploads/2024/04/cropped-favicon-192x192.png\" alt=\"LandingAI VisionAgent\" /> **[VisionAgent MCP](https://github.com/landing-ai/vision-agent-mcp)** - A simple MCP server that enables your LLM to better reason over images, video and documents.\n- <img height=\"12\" width=\"12\" src=\"https://raw.githubusercontent.com/mckinsey/vizro/main/vizro-core/docs/assets/images/favicon.png\" alt=\"Vizro Logo\" /> **[Vizro](https://github.com/mckinsey/vizro/tree/main/vizro-mcp)** - Tools and templates to create validated and maintainable data charts and dashboards\n- <img height=\"12\" width=\"12\" src=\"https://wavespeed.ai/logo.webp\" alt=\"WaveSpeed Logo\" /> **[WaveSpeed](https://github.com/WaveSpeedAI/mcp-server)** - WaveSpeed MCP server providing AI agents with image and video generation capabilities.\n- <img height=\"12\" width=\"12\" src=\"https://waystation.ai/images/logo.svg\" alt=\"WayStation Logo\" /> **[WayStation](https://github.com/waystation-ai/mcp)** - Universal MCP server to connect to popular productivity tools such as Notion, Monday, AirTable, and many more\n- <img height=\"12\" width=\"12\" src=\"https://static.whatsapp.net/rsrc.php/v3/yz/r/ujTY9i_Jhs1.png\" alt=\"WhatsApp Business Logo\" /> **[WhatsApp Business](https://medium.com/@wassenger/introducing-whatsapp-mcp-ai-connector-3d393b52d1b0)** - WhatsApp Business MCP connector enabling AI agents to send messages, manage conversations, access templates, and integrate with WhatsApp Business API for automated customer communication.\n- <img height=\"12\" width=\"12\" src=\"https://www.webflow.com/favicon.ico\" alt=\"Webflow Logo\"> **[Webflow](https://github.com/webflow/mcp-server)** - Interact with Webflow sites, pages, and collections\n- <img height=\"12\" width=\"12\" src=\"https://webscraping.ai/favicon.ico\" alt=\"WebScraping.AI Logo\" /> **[WebScraping.AI](https://github.com/webscraping-ai/webscraping-ai-mcp-server)** - Interact with **[WebScraping.AI](https://WebScraping.AI)** for web data extraction and scraping\n- <img height=\"12\" width=\"12\" src=\"https://winston-app-production-public.s3.us-east-1.amazonaws.com/winston-ai-favicon-light.svg\" alt=\"Winston.AI Logo\" /> **[Winston AI](https://github.com/gowinston-ai/winston-ai-mcp-server)** - AI detector MCP server with industry leading accuracy rates in detecting use of AI in text and images. The [Winston AI](https://gowinston.ai) MCP server also offers a robust plagiarism checker to help maintain integrity.\n- <img height=\"12\" width=\"12\" src=\"https://www.xero.com/favicon.ico\" alt=\"Xero Logo\" /> **[Xero](https://github.com/XeroAPI/xero-mcp-server)** - Interact with the accounting data in your business using our official MCP server\n- <img height=\"12\" width=\"12\" src=\"https://storage.yandexcloud.net/ydb-www-prod-site-assets/favicon-202305/favicon.ico\" alt=\"YDB Logo\" /> **[YDB](https://github.com/ydb-platform/ydb-mcp)** - Query [YDB](https://ydb.tech/) databases\n- <img height=\"12\" width=\"12\" src=\"https://fe-resource.yeelight.com/logo-black.jpeg\" alt=\"Yeelight Logo\" /> **[Yeelight MCP Server](https://github.com/Yeelight/yeelight-iot-mcp)** - The official [Yeelight MCP Server](https://github.com/Yeelight/yeelight-iot-mcp) enables users to control and query their [Yeelight](https://en.yeelight.com/) smart devices using natural language, offering a seamless and efficient human-AI interaction experience.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/632cd328ed2b485519c3f689/6334977a5d1a542102d4b9b5_favicon-32x32.png\" alt=\"YepCode Logo\" /> **[YepCode](https://github.com/yepcode/mcp-server-js)** - Run code in a secure, scalable sandbox environment with full support for dependencies, secrets, logs, and access to APIs or databases. Powered by [YepCode](https://yepcode.io)\n- <img height=\"12\" width=\"12\" src=\"https://www.yugabyte.com/favicon-16x16.png\" alt=\"YugabyteDB Logo\" /> **[YugabyteDB](https://github.com/yugabyte/yugabytedb-mcp-server)** -  MCP Server to interact with your [YugabyteDB](https://www.yugabyte.com/) database\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/14069894\" alt=\"Yunxin Logo\" /> **[Yunxin](https://github.com/netease-im/yunxin-mcp-server)** - An MCP server that connects to Yunxin's IM/RTC/DATA Open-API\n- <img height=\"12\" width=\"12\" src=\"https://cdn.zapier.com/zapier/images/favicon.ico\" alt=\"Zapier Logo\" /> **[Zapier](https://zapier.com/mcp)** - Connect your AI Agents to 8,000 apps instantly.\n- <img height=\"12\" width=\"12\" src=\"https://www.zenable.app/zenable_light.svg\" alt=\"Zenable Logo\" /> **[Zenable](https://docs.zenable.io/integrations/mcp/getting-started)** - Clean up sloppy AI code and prevent vulnerabilities\n- **[ZenML](https://github.com/zenml-io/mcp-zenml)** - Interact with your MLOps and LLMOps pipelines through your [ZenML](https://www.zenml.io) MCP server\n- <img height=\"12\" width=\"12\" src=\"https://www.zine.ai/images/zine-logo.png\" alt=\"Zine Logo\" /> **[Zine](https://www.zine.ai)** - Your memory, everywhere AI goes. Think iPhoto for your knowledge - upload and curate. Like ChatGPT but portable - context that travels with you.\n- <img height=\"12\" width=\"12\" src=\"https://zizai.work/images/logo.jpg\" alt=\"ZIZAI Logo\" /> **[ZIZAI Recruitment](https://github.com/zaiwork/mcp)** - Interact with the next-generation intelligent recruitment platform for employees and employers, powered by [ZIZAI Recruitment](https://zizai.work).\n\n### 🌎 Community Servers\n\nA growing set of community-developed and maintained servers demonstrates various applications of MCP across different domains.\n\n> [!NOTE]\n> Community servers are **untested** and should be used at **your own risk**. They are not affiliated with or endorsed by Anthropic.\n\n- **[1mcpserver](https://github.com/particlefuture/1mcpserver)** - MCP of MCPs. Automatically discover, configure, and add MCP servers on your local machine.\n- **[1Panel](https://github.com/1Panel-dev/mcp-1panel)** - MCP server implementation that provides 1Panel interaction.\n- **[A2A](https://github.com/GongRzhe/A2A-MCP-Server)** - An MCP server that bridges the Model Context Protocol (MCP) with the Agent-to-Agent (A2A) protocol, enabling MCP-compatible AI assistants (like Claude) to seamlessly interact with A2A agents.\n- **[Ableton Live](https://github.com/Simon-Kansara/ableton-live-mcp-server)** - an MCP server to control Ableton Live.\n- **[Ableton Live](https://github.com/ahujasid/ableton-mcp)** (by ahujasid) - Ableton integration allowing prompt enabled music creation.\n- **[Actor Critic Thinking](https://github.com/aquarius-wing/actor-critic-thinking-mcp)** - Actor-critic thinking for performance evaluation\n- **[Adobe Commerce](https://github.com/rafaelstz/adobe-commerce-dev-mcp)** — MCP to interact with Adobe Commerce GraphQL API, including orders, products, customers, etc.\n- **[ADR Analysis](https://github.com/tosin2013/mcp-adr-analysis-server)** - AI-powered Architectural Decision Records (ADR) analysis server that provides architectural insights, technology stack detection, security checks, and TDD workflow enhancement for software development projects.\n- **[AgentBay](https://github.com/Michael98671/agentbay)** - An MCP server for providing serverless cloud infrastructure for AI agents.\n- **[AgentMode](https://www.agentmode.app)** - Connect to dozens of databases, data warehouses, Github & more, from a single MCP server.  Run the Docker image locally, in the cloud, or on-premise.\n- **[AI Agent Marketplace Index](https://github.com/AI-Agent-Hub/ai-agent-marketplace-index-mcp)** - MCP server to search more than 5000+ AI agents and tools of various categories from [AI Agent Marketplace Index](http://www.deepnlp.org/store/ai-agent) and monitor traffic of AI Agents.\n- **[AI Tasks](https://github.com/jbrinkman/valkey-ai-tasks)** - Let the AI manage complex plans with integrated task management and tracking tools. Supports STDIO, SSE and Streamable HTTP transports.\n- **[ai-Bible](https://github.com/AdbC99/ai-bible)** - Search the bible reliably and repeatably [ai-Bible Labs](https://ai-bible.com)\n- **[Airbnb](https://github.com/openbnb-org/mcp-server-airbnb)** - Provides tools to search Airbnb and get listing details.\n- **[Airflow](https://github.com/yangkyeongmo/mcp-server-apache-airflow)** - An MCP Server that connects to [Apache Airflow](https://airflow.apache.org/) using official python client.\n- **[Airtable](https://github.com/domdomegg/airtable-mcp-server)** - Read and write access to [Airtable](https://airtable.com/) databases, with schema inspection.\n- **[Airtable](https://github.com/felores/airtable-mcp)** - Airtable Model Context Protocol Server.\n- **[Algorand](https://github.com/GoPlausible/algorand-mcp)** - A comprehensive MCP server for tooling interactions (40+) and resource accessibility (60+) plus many useful prompts for interacting with the Algorand blockchain.\n- **[Amadeus](https://github.com/donghyun-chae/mcp-amadeus)** (by donghyun-chae) - An MCP server to access, explore, and interact with Amadeus Flight Offers Search API for retrieving detailed flight options, including airline, times, duration, and pricing data.\n- **[Amazon Ads](https://github.com/MarketplaceAdPros/amazon-ads-mcp-server)** - MCP Server that provides interaction capabilities with Amazon Advertising through [MarketplaceAdPros](https://marketplaceadpros.com)/\n- **[AniList](https://github.com/yuna0x0/anilist-mcp)** (by yuna0x0) - An MCP server to interact with AniList API, allowing you to search for anime and manga, retrieve user data, and manage your watchlist.\n- **[Anki](https://github.com/scorzeth/anki-mcp-server)** - An MCP server for interacting with your [Anki](https://apps.ankiweb.net) decks and cards.\n- **[Anki](https://github.com/nietus/anki-mcp)** - MCP server to run locally with Anki and Ankiconnect. Supports creating, updating, searching and filtering cards and decks. Include mass update and other advanced tools.\n- **[AntV Chart](https://github.com/antvis/mcp-server-chart)** - A Model Context Protocol server for generating 15+ visual charts using [AntV](https://github.com/antvis).\n- **[Any Chat Completions](https://github.com/pyroprompts/any-chat-completions-mcp)** - Interact with any OpenAI SDK Compatible Chat Completions API like OpenAI, Perplexity, Groq, xAI and many more.\n- **[Apache Gravitino(incubating)](https://github.com/datastrato/mcp-server-gravitino)** - Allow LLMs to explore metadata of structured data and unstructured data with Gravitino, and perform data governance tasks including tagging/classification.\n- **[API Lab MCP](https://github.com/atototo/api-lab-mcp)** - Transform Claude into your AI-powered API testing laboratory. Test, debug, and document APIs through natural conversation with authentication support, response validation, and performance metrics.\n- **[APIWeaver](https://github.com/GongRzhe/APIWeaver)** - An MCP server that dynamically creates MCP  servers from web API configurations. This allows you to easily integrate any REST API, GraphQL endpoint, or web service into an MCP-compatible tool that can be used by AI assistants like Claude.\n- **[Apollo IO MCP Server](https://github.com/AgentX-ai/apollo-io-mcp-server)** - apollo.io mcp server. Get/enrich contact data for people and organizations agentically.\n- **[Apple Books](https://github.com/vgnshiyer/apple-books-mcp)** - Interact with your library on Apple Books, manage your book collection, summarize highlights, notes, and much more.\n- **[Apple Calendar](https://github.com/Omar-v2/mcp-ical)** - An MCP server that allows you to interact with your macOS Calendar through natural language, including features such as event creation, modification, schedule listing, finding free time slots etc.\n- **[Apple Docs](https://github.com/kimsungwhee/apple-docs-mcp)** - A powerful Model Context Protocol (MCP) server that provides seamless access to Apple Developer Documentation through natural language queries. Search, explore, and get detailed information about Apple frameworks, APIs, sample code, and more directly in your AI-powered development environment.\n- **[Apple Script](https://github.com/peakmojo/applescript-mcp)** - MCP server that lets LLM run AppleScript code to to fully control anything on Mac, no setup needed.\n- **[APT MCP](https://github.com/GdMacmillan/apt-mcp-server)** - MCP server which runs debian package manager (apt) commands for you using ai agents.\n- **[Aranet4](https://github.com/diegobit/aranet4-mcp-server)** - MCP Server to manage your Aranet4 CO2 sensor. Fetch data and store in a local SQLite. Ask questions about historical data.\n- **[ArangoDB](https://github.com/ravenwits/mcp-server-arangodb)** - MCP Server that provides database interaction capabilities through [ArangoDB](https://arangodb.com/).\n- **[ArangoDB Graph](https://github.com/PCfVW/mcp-arangodb-async)** - Async-first Python architecture, wrapping the official [python-arango driver](https://github.com/arangodb/python-arango) with graph management capabilities, content conversion utilities (JSON, Markdown, YAML and Table), backup/restore functionality, and graph analytics capabilities; the 33 MCP tools use strict [Pydantic](https://github.com/pydantic/pydantic) validation.\n- **[Arduino](https://github.com/vishalmysore/choturobo)** - MCP Server that enables AI-powered robotics using Claude AI and Arduino (ESP32) for real-world automation and interaction with robots.\n- **[arXiv API](https://github.com/prashalruchiranga/arxiv-mcp-server)** - An MCP server that enables interacting with the arXiv API using natural language.\n- **[arxiv-latex-mcp](https://github.com/takashiishida/arxiv-latex-mcp)** - MCP server that fetches and processes arXiv LaTeX sources for precise interpretation of mathematical expressions in papers.\n- **[Atlassian](https://github.com/sooperset/mcp-atlassian)** - Interact with Atlassian Cloud products (Confluence and Jira) including searching/reading Confluence spaces/pages, accessing Jira issues, and project metadata.\n- **[Atlassian Server (by phuc-nt)](https://github.com/phuc-nt/mcp-atlassian-server)** - An MCP server that connects AI agents (Cline, Claude Desktop, Cursor, etc.) to Atlassian Jira & Confluence, enabling data queries and actions through the Model Context Protocol.\n- **[Attestable MCP](https://github.com/co-browser/attestable-mcp-server)** - An MCP server running inside a trusted execution environment (TEE) via Gramine, showcasing remote attestation using [RA-TLS](https://gramine.readthedocs.io/en/stable/attestation.html). This allows an MCP client to verify the server before connecting.\n- **[Audius](https://github.com/glassBead-tc/audius-mcp-atris)** - Audius + AI = Atris. Interact with fans, stream music, tip your favorite artists, and more on Audius: all through Claude.\n- **[AutoML](https://github.com/emircansoftware/MCP_Server_DataScience)** – An MCP server for data analysis workflows including reading, preprocessing, feature engineering, model selection, visualization, and hyperparameter tuning.\n- **[AX-Platform](https://github.com/AX-MCP/PaxAI?tab=readme-ov-file#mcp-setup-guides)** - AI Agent collaboration platform. Collaborate on tasks, share context, and coordinate workflows.\n- **[AWS](https://github.com/rishikavikondala/mcp-server-aws)** - Perform operations on your AWS resources using an LLM.\n- **[AWS Athena](https://github.com/lishenxydlgzs/aws-athena-mcp)** - An MCP server for AWS Athena to run SQL queries on Glue Catalog.\n- **[AWS Cognito](https://github.com/gitCarrot/mcp-server-aws-cognito)** - An MCP server that connects to AWS Cognito for authentication and user management.\n- **[AWS Cost Explorer](https://github.com/aarora79/aws-cost-explorer-mcp-server)** - Optimize your AWS spend (including Amazon Bedrock spend) with this MCP server by examining spend across regions, services, instance types and foundation models ([demo video](https://www.youtube.com/watch?v=WuVOmYLRFmI&feature=youtu.be)).\n- **[AWS Resources Operations](https://github.com/baryhuang/mcp-server-aws-resources-python)** - Run generated python code to securely query or modify any AWS resources supported by boto3.\n- **[AWS S3](https://github.com/aws-samples/sample-mcp-server-s3)** - A sample MCP server for AWS S3 that flexibly fetches objects from S3 such as PDF documents.\n- **[AWS SES](https://github.com/aws-samples/sample-for-amazon-ses-mcp)** Sample MCP Server for Amazon SES (SESv2). See [AWS blog post](https://aws.amazon.com/blogs/messaging - and-targeting/use-ai-agents-and-the-model-context-protocol-with-amazon-ses/) for more details.\n- **[Azure ADX](https://github.com/pab1it0/adx-mcp-server)** - Query and analyze Azure Data Explorer databases.\n- **[Azure DevOps](https://github.com/Vortiago/mcp-azure-devops)** - An MCP server that provides a bridge to Azure DevOps services, enabling AI assistants to query and manage work items.\n- **[Azure MCP Hub](https://github.com/Azure-Samples/mcp)** - A curated list of all MCP servers and related resources for Azure developers by **[Arun Sekhar](https://github.com/achandmsft)**\n- **[Azure OpenAI DALL-E 3 MCP Server](https://github.com/jacwu/mcp-server-aoai-dalle3)** - An MCP server for Azure OpenAI DALL-E 3 service to generate image from text.\n- **[Azure Wiki Search](https://github.com/coder-linping/azure-wiki-search-server)** - An MCP that enables AI to query the wiki hosted on Azure Devops Wiki.\n- **[Baidu AI Search](https://github.com/baidubce/app-builder/tree/master/python/mcp_server/ai_search)** - Web search with Baidu Cloud's AI Search\n- **[BambooHR MCP](https://github.com/encoreshao/bamboohr-mcp)** - An MCP server that interfaces with the BambooHR APIs, providing access to employee data, time tracking, and HR management features.\n- **[Base Free USDC Transfer](https://github.com/magnetai/mcp-free-usdc-transfer)** - Send USDC on [Base](https://base.org) for free using Claude AI! Built with [Coinbase CDP](https://docs.cdp.coinbase.com/mpc-wallet/docs/welcome).\n- **[Basic Memory](https://github.com/basicmachines-co/basic-memory)** - Local-first knowledge management system that builds a semantic graph from Markdown files, enabling persistent memory across conversations with LLMs.\n- **[BGG MCP](https://github.com/kkjdaniel/bgg-mcp)** (by kkjdaniel) - MCP to enable interaction with the BoardGameGeek API via AI tooling.\n- **[Bible](https://github.com/trevato/bible-mcp)** - Add biblical context to your generative AI applications.\n- **[BigQuery](https://github.com/LucasHild/mcp-server-bigquery)** (by LucasHild) - This server enables LLMs to inspect database schemas and execute queries on BigQuery.\n- **[BigQuery](https://github.com/ergut/mcp-bigquery-server)** (by ergut) - Server implementation for Google BigQuery integration that enables direct BigQuery database access and querying capabilities\n- **[Bilibili](https://github.com/wangshunnn/bilibili-mcp-server)** - This MCP server provides tools to fetch Bilibili user profiles, video metadata, search videos, and more.\n- **[Binance](https://github.com/ethancod1ng/binance-mcp-server)** - Cryptocurrency trading and market data access through Binance API integration.\n- **[Binance](https://github.com/AnalyticAce/BinanceMCPServer)** (by dosseh shalom) - Unofficial tools and server implementation for Binance's Model Context Protocol (MCP). Designed to support developers building crypto trading AI Agents.\n- **[Bing Web Search API](https://github.com/leehanchung/bing-search-mcp)** (by hanchunglee) - Server implementation for Microsoft Bing Web Search API.\n- **[BioMCP](https://github.com/genomoncology/biomcp)** (by imaurer) - Biomedical research assistant server providing access to PubMed, ClinicalTrials.gov, and MyVariant.info.\n- **[bioRxiv](https://github.com/JackKuo666/bioRxiv-MCP-Server)** - 🔍 Enable AI assistants to search and access bioRxiv papers through a simple MCP interface.\n- **[Bitable MCP](https://github.com/lloydzhou/bitable-mcp)** (by lloydzhou) - MCP server provides access to Lark Bitable through the Model Context Protocol. It allows users to interact with Bitable tables using predefined tools.\n- **[Blender](https://github.com/ahujasid/blender-mcp)** (by ahujasid) - Blender integration allowing prompt enabled 3D scene creation, modeling and manipulation.\n- **[Blender MCP](https://github.com/pranav-deshmukh/blender-mcp)** - MCP server to create professional like 3d scenes on blender using natural language.\n- **[Blockbench MCP Plugin](https://github.com/jasonjgardner/blockbench-mcp-plugin)** (by jasonjgardner) - Blockbench plugin to connect AI agents to Blockbench's JavaScript API. Allows for creating and editing 3D models or pixel art textures with AI in Blockbench.\n- **[Blockchain MCP](https://github.com/tatumio/blockchain-mcp)** - MCP Server for Blockchain Data from **[Tatum](http://tatum.io/mcp)** that instantly unlocks blockchain access for your AI agents. This official Tatum MCP server connects to any LLM in seconds.\n- **[Bluesky](https://github.com/semioz/bluesky-mcp)** (by semioz) - An MCP server for Bluesky, a decentralized social network. It enables automated interactions with the AT Protocol, supporting features like posting, liking, reposting, timeline management, and profile operations.\n- **[Bluetooth MCP Server](https://github.com/Hypijump31/bluetooth-mcp-server)** - Control Bluetooth devices and manage connections through natural language commands, including device discovery, pairing, and audio controls.\n- **[BNBChain MCP](https://github.com/bnb-chain/bnbchain-mcp)** - An MCP server for interacting with BSC, opBNB, and the Greenfield blockchain.\n- **[Braintree](https://github.com/QuentinCody/braintree-mcp-server)** - Unofficial PayPal Braintree payment gateway MCP Server for AI agents to process payments, manage customers, and handle transactions securely.\n- **[Brazilian Law](https://github.com/pdmtt/brlaw_mcp_server/)** (by pdmtt) - Agent-driven research on Brazilian law using official sources.\n- **[BreakoutRoom](https://github.com/agree-able/room-mcp)** - Agents accomplishing goals together in p2p rooms\n- **[Browser MCP](https://github.com/bytedance/UI-TARS-desktop/tree/main/packages/agent-infra/mcp-servers/browser)** (by UI-TARS) - A fast, lightweight MCP server that empowers LLMs with browser automation via Puppeteer’s structured accessibility data, featuring optional vision mode for complex visual understanding and flexible, cross-platform configuration.\n- **[browser-use](https://github.com/co-browser/browser-use-mcp-server)** (by co-browser) - browser-use MCP server with dockerized playwright + chromium + vnc. supports stdio & resumable http.\n- **[BrowserLoop](https://github.com/mattiasw/browserloop)** - An MCP server for taking screenshots of web pages using Playwright. Supports high-quality capture with configurable formats, viewport sizes, cookie-based authentication, and both full page and element-specific screenshots.\n- **[Bsc-mcp](https://github.com/TermiX-official/bsc-mcp)** The first MCP server that serves as the bridge between AI and BNB Chain, enabling AI agents to execute complex on-chain operations through seamless integration with the BNB Chain, including transfer, swap, launch, security check on any token and even more.\n- **[BugBug MCP Server](https://github.com/simplypixi/bugbug-mcp-server)** - Unofficial MCP server for BugBug API.\n- **[BVG MCP Server - (Unofficial) ](https://github.com/svkaizoku/mcp-bvg)** - Unofficial MCP server for Berliner Verkehrsbetriebe Api.\n- **[Bybit](https://github.com/ethancod1ng/bybit-mcp-server)** - A Model Context Protocol (MCP) server for integrating AI assistants with Bybit cryptocurrency exchange APIs, enabling automated trading, market data access, and account management.\n- **[CAD-MCP](https://github.com/daobataotie/CAD-MCP#)** (by daobataotie) - Drawing CAD(Line,Circle,Text,Annotation...) through MCP server, supporting mainstream CAD software.\n- **[Calculator](https://github.com/githejie/mcp-server-calculator)** - This server enables LLMs to use calculator for precise numerical calculations.\n- **[CalDAV MCP](https://github.com/dominik1001/caldav-mcp)** - A CalDAV MCP server to expose calendar operations as tools for AI assistants.\n- **[Calendly-mcp-server](https://github.com/meAmitPatil/calendly-mcp-server)** - Open source calendly mcp server.\n- **[Catalysis Hub](https://github.com/QuentinCody/catalysishub-mcp-server)** - Unofficial MCP server for searching and retrieving scientific data from the Catalysis Hub database, providing access to computational catalysis research and surface reaction data.\n- **[CCTV VMS MCP](https://github.com/jyjune/mcp_vms)** - A Model Context Protocol (MCP) server designed to connect to a CCTV recording program (VMS) to retrieve recorded and live video streams. It also provides tools to control the VMS software, such as showing live or playback dialogs for specific channels at specified times.\n- **[CFBD API](https://github.com/lenwood/cfbd-mcp-server)** - An MCP server for the [College Football Data API](https://collegefootballdata.com/).\n- **[ChatMCP](https://github.com/AI-QL/chat-mcp)** – An Open Source Cross-platform GUI Desktop application compatible with Linux, macOS, and Windows, enabling seamless interaction with MCP servers across dynamically selectable LLMs, by **[AIQL](https://github.com/AI-QL)**\n- **[ChatSum](https://github.com/mcpso/mcp-server-chatsum)** - Query and Summarize chat messages with LLM. by [mcpso](https://mcp.so)\n- **[Chess.com](https://github.com/pab1it0/chess-mcp)** - Access Chess.com player data, game records, and other public information through standardized MCP interfaces, allowing AI assistants to search and analyze chess information.\n- **[ChessPal Chess Engine (stockfish)](https://github.com/wilson-urdaneta/chesspal-mcp-engine)** - A Stockfish-powered chess engine exposed as an MCP server. Calculates best moves and supports both HTTP/SSE and stdio transports.\n- **[Chroma](https://github.com/privetin/chroma)** - Vector database server for semantic document search and metadata filtering, built on Chroma\n- **[Chrome history](https://github.com/vincent-pli/chrome-history-mcp)** - Talk with AI about your browser history, get fun ^_^\n- **[CIViC](https://github.com/QuentinCody/civic-mcp-server)** - MCP server for the Clinical Interpretation of Variants in Cancer (CIViC) database, providing access to clinical variant interpretations and genomic evidence for cancer research.\n- **[Claude Thread Continuity](https://github.com/peless/claude-thread-continuity)** - Persistent memory system enabling Claude Desktop conversations to resume with full context across sessions. Maintains conversation history, project states, and user preferences for seamless multi-session workflows.\n- **[ClaudePost](https://github.com/ZilongXue/claude-post)** - ClaudePost enables seamless email management for Gmail, offering secure features like email search, reading, and sending.\n- **[CLDGeminiPDF Analyzer](https://github.com/tfll37/CLDGeminiPDF-Analyzer)** - MCP server tool enabling sharing large PDF files to Google LLMs via API for further/additional analysis and response retrieval to Claude Desktop.\n- **[ClearML MCP](https://github.com/prassanna-ravishankar/clearml-mcp)** - Get comprehensive ML experiment context and analysis directly from [ClearML](https://clear.ml) in your AI conversations.\n- **[ClickUp](https://github.com/TaazKareem/clickup-mcp-server)** - MCP server for ClickUp task management, supporting task creation, updates, bulk operations, and markdown descriptions.\n- **[Cloudinary](https://github.com/felores/cloudinary-mcp-server)** - Cloudinary Model Context Protocol Server to upload media to Cloudinary and get back the media link and details.\n- **[CockroachDB](https://github.com/amineelkouhen/mcp-cockroachdb)** - MCP server enabling AI agents and LLMs to manage, monitor, and query **[CockroachDB](https://www.cockroachlabs.com/)** using natural language.\n- **[CockroachDB MCP Server](https://github.com/viragtripathi/cockroachdb-mcp-server)** – Full - featured MCP implementation built with FastAPI and CockroachDB. Supports schema bootstrapping, JSONB storage, LLM-ready CLI, and optional `/debug` endpoints.\n- **[code-assistant](https://github.com/stippi/code-assistant)** - A coding assistant MCP server that allows to explore a code-base and make changes to code. Should be used with trusted repos only (insufficient protection against prompt injections).\n- **[code-context-provider-mcp](https://github.com/AB498/code-context-provider-mcp)** - MCP server that provides code context and analysis for AI assistants. Extracts directory structure and code symbols using WebAssembly Tree-sitter parsers without Native Dependencies.\n- **[code-executor](https://github.com/bazinga012/mcp_code_executor)** - An MCP server that allows LLMs to execute Python code within a specified Conda environment.\n- **[code-sandbox-mcp](https://github.com/Automata-Labs-team/code-sandbox-mcp)** - An MCP server to create secure code sandbox environment for executing code within Docker containers.\n- **[cognee-mcp](https://github.com/topoteretes/cognee/tree/main/cognee-mcp)** - GraphRAG memory server with customizable ingestion, data processing and search\n- **[coin_api_mcp](https://github.com/longmans/coin_api_mcp)** - Provides access to [coinmarketcap](https://coinmarketcap.com/) cryptocurrency data.\n- **[CoinMarketCap](https://github.com/shinzo-labs/coinmarketcap-mcp)** - Implements the complete [CoinMarketCap](https://coinmarketcap.com/) API for accessing cryptocurrency market data, exchange information, and other blockchain-related metrics.\n- **[commands](https://github.com/g0t4/mcp-server-commands)** - Run commands and scripts. Just like in a terminal.\n- **[Companies House MCP](https://github.com/stefanoamorelli/companies-house-mcp)** (by Stefano Amorelli) - MCP server to connect with the UK Companies House API.\n- **[computer-control-mcp](https://github.com/AB498/computer-control-mcp)** - MCP server that provides computer control capabilities, like mouse, keyboard, OCR, etc. using PyAutoGUI, RapidOCR, ONNXRuntime Without External Dependencies.\n- **[Computer-Use - Remote MacOS Use](https://github.com/baryhuang/mcp-remote-macos-use)** - Open-source out-of-the-box alternative to OpenAI Operator, providing a full desktop experience and optimized for using remote macOS machines as autonomous AI agents.\n- **[Congress.gov API](https://github.com/AshwinSundar/congress_gov_mcp)** - An MCP server to interact with real-time data from the Congress.gov API, which is the official API for the United States Congress.\n- **[consul-mcp](https://github.com/kocierik/consul-mcp-server)** - A consul MCP server for service management, health check and Key-Value Store\n- **[consult7](https://github.com/szeider/consult7)** - Analyze large codebases and document collections using high-context models via OpenRouter, OpenAI, or Google AI -- very useful, e.g., with Claude Code\n- **[Contentful-mcp](https://github.com/ivo-toby/contentful-mcp)** - Read, update, delete, publish content in your [Contentful](https://contentful.com) space(s) from this MCP Server.\n- **[Context Crystallizer](https://github.com/hubertciebiada/context-crystallizer)** - AI Context Engineering tool that transforms large repositories into crystallized, AI-consumable knowledge through systematic analysis and optimization.\n- **[MCP Context Provider](https://github.com/doobidoo/MCP-Context-Provider)** - Static server that provides AI models with persistent tool-specific context and rules, preventing context loss between chat sessions and enabling consistent behavior across interactions.\n- **[context-portal](https://github.com/GreatScottyMac/context-portal)** - Context Portal (ConPort) is a memory bank database system that effectively builds a project-specific knowledge graph, capturing entities like decisions, progress, and architecture, along with their relationships. This serves as a powerful backend for Retrieval Augmented Generation (RAG), enabling AI assistants to access precise, up-to-date project information.\n- **[cplusplus-mcp](https://github.com/kandrwmrtn/cplusplus_mcp)** - Semantic C++ code analysis using libclang. Enables Claude to understand C++ codebases through AST parsing rather than text search - find classes, navigate inheritance, trace function calls, and explore code relationships.\n- **[CreateveAI Nexus](https://github.com/spgoodman/createveai-nexus-server)** - Open-Source Bridge Between AI Agents and Enterprise Systems, with simple custom API plug-in capabilities (including close compatibility with ComfyUI nodes), support for Copilot Studio's MCP agent integations, and support for Azure deployment in secure environments with secrets stored in Azure Key Vault, as well as straightforward on-premises deployment.\n- **[CRASH](https://github.com/nikkoxgonzales/crash-mcp)** - MCP server for structured, iterative reasoning and thinking with flexible validation, confidence tracking, revision mechanisms, and branching support.\n- **[Creatify](https://github.com/TSavo/creatify-mcp)** - MCP Server that exposes Creatify AI API capabilities for AI video generation, including avatar videos, URL-to-video conversion, text-to-speech, and AI-powered editing tools.\n- **[Cronlytic](https://github.com/Cronlytic/cronlytic-mcp-server)** - Create CRUD operations for serverless cron jobs through [Cronlytic](https://cronlytic.com) MCP Server\n- **[crypto-feargreed-mcp](https://github.com/kukapay/crypto-feargreed-mcp)**  -  Providing real-time and historical Crypto Fear & Greed Index data.\n- **[crypto-indicators-mcp](https://github.com/kukapay/crypto-indicators-mcp)**  -  An MCP server providing a range of cryptocurrency technical analysis indicators and strategies.\n- **[crypto-sentiment-mcp](https://github.com/kukapay/crypto-sentiment-mcp)**  -  An MCP server that delivers cryptocurrency sentiment analysis to AI agents.\n- **[cryptopanic-mcp-server](https://github.com/kukapay/cryptopanic-mcp-server)** - Providing latest cryptocurrency news to AI agents, powered by CryptoPanic.\n- **[CSV Editor](https://github.com/santoshray02/csv-editor)** - Comprehensive CSV processing with 40+ operations for data manipulation, analysis, and validation. Features auto-save, undo/redo, and handles GB+ files. Built with FastMCP & Pandas.\n- **[Cursor MCP Installer](https://github.com/matthewdcage/cursor-mcp-installer)** - A tool to easily install and configure other MCP servers within Cursor IDE, with support for npm packages, local directories, and Git repositories.\n- **[CVE Intelligence Server](https://github.com/gnlds/mcp-cve-intelligence-server-lite)** – Provides vulnerability intelligence via multi - source CVE data, essential exploit discovery, and EPSS risk scoring through the MCP. Useful for security research, automation, and agent workflows.\n- **[D365FO](https://github.com/mafzaal/d365fo-client)** - A comprehensive MCP server for Microsoft Dynamics 365 Finance & Operations (D365 F&O) that provides easy access to OData endpoints, metadata operations, label management, and AI assistant integration.\n- **[Dagster](https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-dg-cli)** - An MCP server to easily build data pipelines using [Dagster](https://dagster.io/).\n- **[Dappier](https://github.com/DappierAI/dappier-mcp)** - Connect LLMs to real-time, rights-cleared, proprietary data from trusted sources. Access specialized models for Real-Time Web Search, News, Sports, Financial Data, Crypto, and premium publisher content. Explore data models at [marketplace.dappier.com](https://marketplace.dappier.com/marketplace).\n- **[Data Exploration](https://github.com/reading-plus-ai/mcp-server-data-exploration)** - MCP server for autonomous data exploration on .csv-based datasets, providing intelligent insights with minimal effort. NOTE: Will execute arbitrary Python code on your machine, please use with caution!\n- **[Databricks](https://github.com/JordiNeil/mcp-databricks-server)** - Allows LLMs to run SQL queries, list and get details of jobs executions in a Databricks account.\n- **[Databricks Genie](https://github.com/yashshingvi/databricks-genie-MCP)** - A server that connects to the Databricks Genie, allowing LLMs to ask natural language questions, run SQL queries, and interact with Databricks conversational agents.\n- **[Databricks Smart SQL](https://github.com/RafaelCartenet/mcp-databricks-server)** - Leveraging Databricks Unity Catalog metadata, perform smart efficient SQL queries to solve Ad-hoc queries and explore data.\n- **[DataCite](https://github.com/QuentinCody/datacite-mcp-server)** - Unofficial MCP server for DataCite, providing access to research data and publication metadata through DataCite's REST API and GraphQL interface for scholarly research discovery.\n- **[Datadog](https://github.com/GeLi2001/datadog-mcp-server)** - Datadog MCP Server for application tracing, monitoring, dashboard, incidents queries built on official datadog api.\n- **[Dataset Viewer](https://github.com/privetin/dataset-viewer)** - Browse and analyze Hugging Face datasets with features like search, filtering, statistics, and data export\n- **[DataWorks](https://github.com/aliyun/alibabacloud-dataworks-mcp-server)** - A Model Context Protocol (MCP) server that provides tools for AI, allowing it to interact with the [DataWorks](https://www.alibabacloud.com/help/en/dataworks/) Open API through a standardized interface. This implementation is based on the Alibaba Cloud Open API and enables AI agents to perform cloud resources operations seamlessly.\n- **[Data4library](https://github.com/isnow890/data4library-mcp)** (by isnow890) - MCP server for Korea's Library Information Naru API, providing comprehensive access to public library data, book searches, loan status, reading statistics, and GPS-based nearby library discovery across South Korea.\n\n- **[DaVinci Resolve](https://github.com/samuelgursky/davinci-resolve-mcp)** - MCP server integration for DaVinci Resolve providing powerful tools for video editing, color grading, media management, and project control.\n- **[DBHub](https://github.com/bytebase/dbhub/)** - Universal database MCP server connecting to MySQL, MariaDB, PostgreSQL, and SQL Server.\n- **[Deebo](https://github.com/snagasuri/deebo-prototype)** – Agentic debugging MCP server that helps AI coding agents delegate and fix hard bugs through isolated multi-agent hypothesis testing.\n- **[Deep Research](https://github.com/reading-plus-ai/mcp-server-deep-research)** - Lightweight MCP server offering Grok/OpenAI/Gemini/Perplexity-style automated deep research exploration and structured reporting.\n- **[DeepSeek MCP Server](https://github.com/DMontgomery40/deepseek-mcp-server)** - Model Context Protocol server integrating DeepSeek's advanced language models, in addition to [other useful API endpoints](https://github.com/DMontgomery40/deepseek-mcp-server?tab=readme-ov-file#features)\n- **[deepseek-thinker-mcp](https://github.com/ruixingshi/deepseek-thinker-mcp)** - A MCP (Model Context Protocol) provider Deepseek reasoning content to MCP-enabled AI Clients, like Claude Desktop. Supports access to Deepseek's thought processes from the Deepseek API service or from a local Ollama server.\n- **[Deepseek_R1](https://github.com/66julienmartin/MCP-server-Deepseek_R1)** - A Model Context Protocol (MCP) server implementation connecting Claude Desktop with DeepSeek's language models (R1/V3)\n- **[Depyler](https://github.com/paiml/depyler/blob/main/docs/mcp-integration.md)** - Energy-efficient Python-to-Rust transpiler with progressive verification, enabling AI assistants to convert Python code to safe, performant Rust while reducing energy consumption by 75-85%.\n- **[deploy-mcp](https://github.com/alexpota/deploy-mcp)** - Universal deployment tracker for AI assistants with live status badges and deployment monitoring.\n- **[Descope](https://github.com/descope-sample-apps/descope-mcp-server)** - An MCP server to integrate with [Descope](https://descope.com) to search audit logs, manage users, and more.\n- **[DesktopCommander](https://github.com/wonderwhy-er/DesktopCommanderMCP)** - Let AI edit and manage files on your computer, run terminal commands, and connect to remote servers via SSH - all powered by one of the most popular local MCP servers.\n- **[Devcontainer](https://github.com/AI-QL/mcp-devcontainers)** - An MCP server for devcontainer to generate and configure development containers directly from devcontainer configuration files.\n- **[DevDb](https://github.com/damms005/devdb-vscode?tab=readme-ov-file#mcp-configuration)** - An MCP server that runs right inside the IDE, for connecting to MySQL, Postgres, SQLite, and MSSQL databases.\n- **[DevOps AI Toolkit](https://github.com/vfarcic/dot-ai)** - AI-powered development productivity platform that enhances software development workflows through intelligent automation and AI-driven assistance.\n- **[DevOps-MCP](https://github.com/wangkanai/devops-mcp)** - Dynamic Azure DevOps MCP server with directory-based authentication switching, supporting work items, repositories, builds, pipelines, and multi-project management with local configuration files.\n- **[DGIdb](https://github.com/QuentinCody/dgidb-mcp-server)** - MCP server for the Drug Gene Interaction Database (DGIdb), providing access to drug-gene interaction data, druggable genome information, and pharmacogenomics research.\n- **[Dicom](https://github.com/ChristianHinge/dicom-mcp)** - An MCP server to query and retrieve medical images and for parsing and reading dicom-encapsulated documents (pdf etc.).\n- **[Dify](https://github.com/YanxingLiu/dify-mcp-server)** - A simple implementation of an MCP server for dify workflows.\n- **[Discogs](https://github.com/cswkim/discogs-mcp-server)** - An MCP server that connects to the Discogs API for interacting with your music collection.\n- **[Discord](https://github.com/v-3/discordmcp)** - An MCP server to connect to Discord guilds through a bot and read and write messages in channels\n- **[Discord](https://github.com/SaseQ/discord-mcp)** - An MCP server, which connects to Discord through a bot, and provides comprehensive integration with Discord.\n- **[Discord](https://github.com/Klavis-AI/klavis/tree/main/mcp_servers/discord)** - For Discord API integration by Klavis AI\n- **[Discourse](https://github.com/AshDevFr/discourse-mcp-server)** - An MCP server to search Discourse posts on a Discourse forum.\n- **[DocBase](https://help.docbase.io/posts/3925317)** - Official MCP server for DocBase API integration, enabling post management, user collaboration, group administration, and more.\n- **[Docker](https://github.com/ckreiling/mcp-server-docker)** - Integrate with Docker to manage containers, images, volumes, and networks.\n- **[Docker](https://github.com/0xshariq/docker-mcp-server)** - Docker MCP Server provides advanced, unified Docker management via CLI and MCP workflows, supporting containers, images, volumes, networks, and orchestration.\n- **[Docs](https://github.com/da1z/docsmcp)** - Enable documentation access for the AI agent, supporting llms.txt and other remote or local files.\n- **[documcp](https://github.com/tosin2013/documcp)** - An MCP server for intelligent document processing and management, supporting multiple formats and document operations.\n- **[Docy](https://github.com/oborchers/mcp-server-docy)** - Docy gives your AI direct access to the technical documentation it needs, right when it needs it. No more outdated information, broken links, or rate limits - just accurate, real-time documentation access for more precise coding assistance.\n- **[Dodo Payments](https://github.com/dodopayments/dodopayments-node/tree/main/packages/mcp-server)** - Enables AI agents to securely perform payment operations via a lightweight, serverless-compatible interface to the [Dodo Payments](https://dodopayments.com) API.\n- **[Domain Tools](https://github.com/deshabhishek007/domain-tools-mcp-server)** - A Model Context Protocol (MCP) server for comprehensive domain analysis: WHOIS, DNS records, and DNS health checks.\n- **[DPLP](https://github.com/szeider/mcp-dblp)**  - Searches the [DBLP](https://dblp.org) computer science bibliography database.\n- **[Druid MCP Server](https://github.com/iunera/druid-mcp-server)** - STDIO/SEE MCP Server for Apache Druid by [iunera](https://www.iunera.com) that provides extensive tools, resources, and prompts for managing and analyzing Druid clusters.\n- **[Drupal](https://github.com/Omedia/mcp-server-drupal)** - Server for interacting with [Drupal](https://www.drupal.org/project/mcp) using STDIO transport layer.\n- **[dune-analytics-mcp](https://github.com/kukapay/dune-analytics-mcp)** -  A mcp server that bridges Dune Analytics data to AI agents.\n- **[DynamoDB-Toolbox](https://www.dynamodbtoolbox.com/docs/databases/actions/mcp-toolkit)** - Leverages your Schemas and Access Patterns to interact with your [DynamoDB](https://aws.amazon.com/dynamodb) Database using natural language.\n- **[eBook-mcp](https://github.com/onebirdrocks/ebook-mcp)** - A lightweight MCP server that allows LLMs to read and interact with your personal PDF and EPUB ebooks. Ideal for building AI reading assistants or chat-based ebook interfaces.\n- **[ECharts MCP Server](https://github.com/hustcc/mcp-echarts)** - Generate visual charts using ECharts with AI MCP dynamically, used for chart generation and data analysis.\n- **[EDA MCP Server](https://github.com/NellyW8/mcp-EDA)** - A comprehensive Model Context Protocol server for Electronic Design Automation tools, enabling AI assistants to synthesize Verilog with Yosys, simulate designs with Icarus Verilog, run complete ASIC flows with OpenLane, and view results with GTKWave and KLayout.\n- **[EdgeOne Pages MCP](https://github.com/TencentEdgeOne/edgeone-pages-mcp)** - An MCP service for deploying HTML content to EdgeOne Pages and obtaining a publicly accessible URL.\n- **[Edwin](https://github.com/edwin-finance/edwin/tree/main/examples/mcp-server)** - MCP server for edwin SDK - enabling AI agents to interact with DeFi protocols across EVM, Solana and other blockchains.\n- **[eechat](https://github.com/Lucassssss/eechat)** - An open-source, cross-platform desktop application that seamlessly connects with MCP servers, across Linux, macOS, and Windows.\n- **[Elasticsearch](https://github.com/cr7258/elasticsearch-mcp-server)** - MCP server implementation that provides Elasticsearch interaction.\n- **[ElevenLabs](https://github.com/mamertofabian/elevenlabs-mcp-server)** - A server that integrates with ElevenLabs text-to-speech API capable of generating full voiceovers with multiple voices.\n- **[Email](https://github.com/Shy2593666979/mcp-server-email)** - This server enables users to send emails through various email providers, including Gmail, Outlook, Yahoo, Sina, Sohu, 126, 163, and QQ Mail. It also supports attaching files from specified directories, making it easy to upload attachments along with the email content.\n- **[Email SMTP](https://github.com/egyptianego17/email-mcp-server)** - A simple MCP server that lets your AI agent send emails and attach files through SMTP.\n- **[Enhance Prompt](https://github.com/FelixFoster/mcp-enhance-prompt)** - An MCP service for enhance you prompt.\n- **[Entrez](https://github.com/QuentinCody/entrez-mcp-server)** - Unofficial MCP server for NCBI Entrez databases, providing access to PubMed articles, gene information, protein data, and other biomedical research resources through NCBI's E-utilities API.\n- **[Ergo Blockchain MCP](https://github.com/marctheshark3/ergo-mcp)** -An MCP server to integrate Ergo Blockchain Node and Explorer APIs for checking address balances, analyzing transactions, viewing transaction history, performing forensic analysis of addresses, searching for tokens, and monitoring network status.\n- **[ESP MCP Server](https://github.com/horw/esp-mcp)** - An MCP server that integrates ESP IDF commands like building and flashing code for ESP Microcontrollers using an LLM.\n- **[Eunomia](https://github.com/whataboutyou-ai/eunomia-MCP-server)** - Extension of the Eunomia framework that connects Eunomia instruments with MCP servers\n- **[Everything Search](https://github.com/mamertofabian/mcp-everything-search)** - Fast file searching capabilities across Windows (using [Everything SDK](https://www.voidtools.com/support/everything/sdk/)), macOS (using mdfind command), and Linux (using locate/plocate command).\n- **[EVM MCP Server](https://github.com/mcpdotdirect/evm-mcp-server)** - Comprehensive blockchain services for 30+ EVM networks, supporting native tokens, ERC20, NFTs, smart contracts, transactions, and ENS resolution.\n- **[Excel](https://github.com/haris-musa/excel-mcp-server)** - Excel manipulation including data reading/writing, worksheet management, formatting, charts, and pivot table.\n- **[Excel to JSON MCP by WTSolutions](https://github.com/he-yang/excel-to-json-mcp)** - MCP Server providing a standardized interface for converting (1) Excel or CSV data into JSON format ;(2) Excel(.xlsx) file into Structured JSON.\n- **[Extended Memory](https://github.com/ssmirnovpro/extended-memory-mcp)** - Persistent memory across Claude conversations with multi-project support, automatic importance scoring, and tag-based organization. Production-ready with 400+ tests.\n- **[F1](https://github.com/AbhiJ2706/f1-mcp/tree/main)** - Access to Formula 1 data including race results, driver information, lap times, telemetry, and circuit details.\n- **[Fabric MCP](https://github.com/aci-labs/ms-fabric-mcp)** - Microsoft Fabric MCP server to accelerate working in your Fabric Tenant with the help of your favorite LLM models.\n- **[Fabric Real-Time Intelligence MCP](https://github.com/Microsoft/fabric-rti-mcp)** - Official Microsoft Fabric RTI server to accelerate working with Eventhouse, Azure Data Explorer(Kusto), Eventstreams and other RTI items using your favorite LLM models.\n- **[fabric-mcp-server](https://github.com/adapoet/fabric-mcp-server)** - The fabric-mcp-server is an MCP server that integrates [Fabric](https://github.com/danielmiessler/fabric) patterns with [Cline](https://cline.bot/), exposing them as tools for AI-driven task execution and enhancing Cline's capabilities.\n- **[Fal MCP Server](https://github.com/raveenb/fal-mcp-server)** - Generate AI images, videos, and music using Fal.ai models (FLUX, Stable Diffusion, MusicGen) directly in Claude\n- **[Facebook Ads](https://github.com/gomarble-ai/facebook-ads-mcp-server)** - MCP server acting as an interface to the Facebook Ads, enabling programmatic access to Facebook Ads data and management features.\n- **[Facebook Ads 10xeR](https://github.com/fortytwode/10xer)** - Advanced Facebook Ads MCP server with enhanced creative insights, multi-dimensional breakdowns, and comprehensive ad performance analytics.\n- **[Facebook Ads Library](https://github.com/trypeggy/facebook-ads-library-mcp)** - Get any answer from the Facebook Ads Library, conduct deep research including messaging, creative testing and comparisons in seconds.\n- **[Fantasy PL](https://github.com/rishijatia/fantasy-pl-mcp)** - Give your coding agent direct access to up-to date Fantasy Premier League data\n- **[Fastmail MCP](https://github.com/MadLlama25/fastmail-mcp)** - Access Fastmail via JMAP: list/search emails, send and move mail, handle attachments/threads, plus contacts and calendar tools.\n- **[fastn.ai – Unified API MCP Server](https://github.com/fastnai/mcp-fastn)** - A remote, dynamic MCP server with a unified API that connects to 1,000+ tools, actions, and workflows, featuring built-in authentication and monitoring.\n- **[FDIC BankFind MCP Server - (Unofficial)](https://github.com/clafollett/fdic-bank-find-mcp-server)** - The is a MCPserver that brings the power of FDIC BankFind APIs straight to your AI tools and workflows. Structured U.S. banking data, delivered with maximum vibes. 😎📊\n- **[FPE Demo MCP](https://github.com/Horizon-Digital-Engineering/fpe-demo-mcp)** - FF3 Format Preserving Encryption with authentication patterns for secure data protection in LLM workflows.\n- **[Federal Reserve Economic Data (FRED)](https://github.com/stefanoamorelli/fred-mcp-server)** (by Stefano Amorelli) - Community developed MCP server to interact with the Federal Reserve Economic Data.\n- **[Fetch](https://github.com/zcaceres/fetch-mcp)** - A server that flexibly fetches HTML, JSON, Markdown, or plaintext.\n- **[Feyod](https://github.com/jeroenvdmeer/feyod-mcp)** - A server that answers questions about football matches, and specialised in the football club Feyenoord.\n- **[Fast Filesystem](https://github.com/efforthye/fast-filesystem-mcp)** - Advanced filesystem operations with large file handling capabilities and Claude-optimized features. Provides fast file reading/writing, sequential reading for large files, directory operations, file search, and streaming writes with backup & recovery.\n- **[FHIR](https://github.com/wso2/fhir-mcp-server)** - A Model Context Protocol server that provides seamless, standardized access to Fast Healthcare Interoperability Resources (FHIR) data from any compatible FHIR server. Designed for easy integration with AI tools, developer workflows, and healthcare applications, it enables natural language and programmatic search, retrieval, and analysis of clinical data.\n- **[Fibaro HC3](https://github.com/coding-sailor/mcp-server-hc3)** - MCP server for Fibaro Home Center 3 smart home systems.\n- **[Figma](https://github.com/GLips/Figma-Context-MCP)** - Give your coding agent direct access to Figma file data, helping it one-shot design implementation.\n- **[Figma](https://github.com/paulvandermeijs/figma-mcp)** - A blazingly fast MCP server to read and export your Figma design files.\n- **[Figma to Flutter](https://github.com/mhmzdev/figma-flutter-mcp)** - Write down clean and better Flutter code from Figma design tokens and enrich nodes data in Flutter terminology.\n- **[Files](https://github.com/flesler/mcp-files)** - Enables agents to quickly find and edit code in a codebase with surgical precision. Find symbols, edit them everywhere.\n- **[FileSystem Server](https://github.com/Oncorporation/filesystem_server)** - Local MCP server for Visual Studio 2022 that provides code-workspace functionality by giving AI agents selective access to project folders and files\n- **[finmap.org](https://github.com/finmap-org/mcp-server)** MCP server provides comprehensive historical data from the US, UK, Russian and Turkish stock exchanges. Access sectors, tickers, company profiles, market cap, volume, value, and trade counts, as well as treemap and histogram visualizations.\n- **[Firebase](https://github.com/gannonh/firebase-mcp)** - Server to interact with Firebase services including Firebase Authentication, Firestore, and Firebase Storage.\n- **[Fish Audio](https://github.com/da-okazaki/mcp-fish-audio-server)** - Text-to-Speech integration with Fish Audio's API, supporting multiple voices, streaming, and real-time playback\n- **[FitBit MCP Server](https://github.com/NitayRabi/fitbit-mcp)** - An MCP server that connects to FitBit API using a token obtained from OAuth flow.\n- **[FlightRadar24](https://github.com/sunsetcoder/flightradar24-mcp-server)** - A Claude Desktop MCP server that helps you track flights in real-time using Flightradar24 data.\n- **[Fluent-MCP](https://github.com/modesty/fluent-mcp)** - MCP server for Fluent (ServiceNow SDK) providing access to ServiceNow SDK CLI, API specifications, code snippets, and more.\n- **[Flyworks Avatar](https://github.com/Flyworks-AI/flyworks-mcp)** - Fast and free zeroshot lipsync MCP server.\n- **[fmp-mcp-server](https://github.com/vipbat/fmp-mcp-server)** - Enable your agent for M&A analysis and investment banking workflows. Access company profiles, financial statements, ratios, and perform sector analysis with the [Financial Modeling Prep APIs]\n- **[FoundationModels](https://github.com/phimage/mcp-foundation-models)** - An MCP server that integrates Apple's [FoundationModels](https://developer.apple.com/documentation/foundationmodels) for text generation.\n- **[Foursquare](https://github.com/foursquare/foursquare-places-mcp)** - Enable your agent to recommend places around the world with the [Foursquare Places API](https://location.foursquare.com/products/places-api/)\n- **[FrankfurterMCP](https://github.com/anirbanbasu/frankfurtermcp)** - MCP server acting as an interface to the [Frankfurter API](https://frankfurter.dev/) for currency exchange data.\n- **[freqtrade-mcp](https://github.com/kukapay/freqtrade-mcp)** - An MCP server that integrates with the Freqtrade cryptocurrency trading bot.\n- **[Geolocation](https://github.com/jackyang25/geolocation-mcp-server)** - WalkScore API integration for walkability, transit, and bike scores.\n- **[GDB](https://github.com/pansila/mcp_server_gdb)** - A GDB/MI protocol server based on the MCP protocol, providing remote application debugging capabilities with AI assistants.\n- **[ggRMCP](https://github.com/aalobaidi/ggRMCP)** - A Go gateway that converts gRPC services into MCP-compatible tools, allowing AI models like Claude to directly call your gRPC services.\n- **[Gemini Bridge](https://github.com/eLyiN/gemini-bridge)** - Lightweight MCP server that enables Claude to interact with Google's Gemini AI through the official CLI, offering zero API costs and stateless architecture.\n- **[Ghost](https://github.com/MFYDev/ghost-mcp)** - A Model Context Protocol (MCP) server for interacting with Ghost CMS through LLM interfaces like Claude.\n- **[Git](https://github.com/geropl/git-mcp-go)** - Allows LLM to interact with a local git repository, incl. optional push support.\n- **[Git Mob](https://github.com/Mubashwer/git-mob-mcp-server)** - MCP server that interfaces with the [git-mob](https://github.com/Mubashwer/git-mob) CLI app for managing co-authors in git commits during pair/mob programming.\n- **[Github](https://github.com/0xshariq/github-mcp-server)** - A Model Context Protocol (MCP) server that provides 29 Git operations + 11 workflow combinations for AI assistants and developers. This server exposes comprehensive Git repository management through a standardized interface, enabling AI models and developers to safely manage complex version control workflows.\n- **[GitHub Actions](https://github.com/ko1ynnky/github-actions-mcp-server)** - A Model Context Protocol (MCP) server for interacting with GitHub Actions.\n- **[GitHub Enterprise MCP](https://github.com/ddukbg/github-enterprise-mcp)** - A Model Context Protocol (MCP) server for interacting with GitHub Enterprise.\n- **[GitHub GraphQL](https://github.com/QuentinCody/github-graphql-mcp-server)** - Unofficial GitHub MCP server that provides access to GitHub's GraphQL API, enabling more powerful and flexible queries for repository data, issues, pull requests, and other GitHub resources.\n- **[GitHub Projects](https://github.com/redducklabs/github-projects-mcp)** — Manage GitHub Projects with full GraphQL API access including items, fields, and milestones.\n- **[GitHub Repos Manager MCP Server](https://github.com/kurdin/github-repos-manager-mcp)** - Token-based GitHub automation management. No Docker, Flexible configuration, 80+ tools with direct API integration.\n- **[GitMCP](https://github.com/idosal/git-mcp)** - gitmcp.io is a generic remote MCP server to connect to ANY GitHub repository or project documentation effortlessly\n- **[Glean](https://github.com/longyi1207/glean-mcp-server)** - A server that uses Glean API to search and chat.\n- **[Gmail](https://github.com/GongRzhe/Gmail-MCP-Server)** - A Model Context Protocol (MCP) server for Gmail integration in Claude Desktop with auto authentication support.\n- **[Gmail](https://github.com/Ayush-k-Shukla/gmail-mcp-server)** - A Simple MCP server for Gmail with support for all basic operations with oauth2.0.\n- **[Gmail Headless](https://github.com/baryhuang/mcp-headless-gmail)** - Remote hostable MCP server that can get and send Gmail messages without local credential or file system setup.\n- **[Gmail MCP](https://github.com/gangradeamitesh/mcp-google-email)** - A Gmail service implementation using MCP (Model Context Protocol) that provides functionality for sending, receiving, and managing emails through Gmail's API.\n- **[Gnuradio](https://github.com/yoelbassin/gnuradioMCP)** - An MCP server for GNU Radio that enables LLMs to autonomously create and modify RF .grc flowcharts.\n- **[Goal Story](https://github.com/hichana/goalstory-mcp)** - a Goal Tracker and Visualization Tool for personal and professional development.\n- **[GOAT](https://github.com/goat-sdk/goat/tree/main/typescript/examples/by-framework/model-context-protocol)** - Run more than +200 onchain actions on any blockchain including Ethereum, Solana and Base.\n- **[Godot](https://github.com/Coding-Solo/godot-mcp)** - An MCP server providing comprehensive Godot engine integration for project editing, debugging, and scene management.\n- **[Golang Filesystem Server](https://github.com/mark3labs/mcp-filesystem-server)** - Secure file operations with configurable access controls built with Go!\n- **[Goodnews](https://github.com/VectorInstitute/mcp-goodnews)** - A simple MCP server that delivers curated positive and uplifting news stories.\n- **[Gopher MCP](https://github.com/cameronrye/gopher-mcp)** - Modern, cross-platform MCP server that enables AI assistants to browse and interact with both Gopher protocol and Gemini protocol resources safely and efficiently.\n- **[Google Ads](https://github.com/gomarble-ai/google-ads-mcp-server)** - MCP server acting as an interface to the Google Ads, enabling programmatic access to Facebook Ads data and management features.\n- **[Google Analytics](https://github.com/surendranb/google-analytics-mcp)** - Google Analytics MCP Server to bring data across 200+ dimensions & metrics for LLMs to analyse.\n- **[Google Calendar](https://github.com/v-3/google-calendar)** - Integration with Google Calendar to check schedules, find time, and add/delete events\n- **[Google Calendar](https://github.com/nspady/google-calendar-mcp)** - Google Calendar MCP Server for managing Google calendar events. Also supports searching for events by attributes like title and location.\n- **[Google Custom Search](https://github.com/adenot/mcp-google-search)** - Provides Google Search results via the Google Custom Search API\n- **[Google Maps](https://github.com/Mastan1301/google_maps_mcp)** - Provides location results using Google Places API.\n- **[Google Sheets](https://github.com/xing5/mcp-google-sheets)** - Access and editing data to your Google Sheets.\n- **[Google Sheets](https://github.com/rohans2/mcp-google-sheets)** - An MCP Server written in TypeScript to access and edit data in your Google Sheets.\n- **[Google Tasks](https://github.com/zcaceres/gtasks-mcp)** - Google Tasks API Model Context Protocol Server.\n- **[Google Vertex AI Search](https://github.com/ubie-oss/mcp-vertexai-search)** - Provides Google Vertex AI Search results by grounding a Gemini model with your own private data\n- **[Google Workspace](https://github.com/taylorwilsdon/google_workspace_mcp)** - Comprehensive Google Workspace MCP with full support for Calendar, Drive, Gmail, and Docs using Streamable HTTP or SSE transport.\n- **[Google-Scholar](https://github.com/JackKuo666/Google-Scholar-MCP-Server)** - Enable AI assistants to search and access Google Scholar papers through a simple MCP interface.\n- **[Google-Scholar](https://github.com/mochow13/google-scholar-mcp)** - An MCP server for Google Scholar written in TypeScript with Streamable HTTP transport, along with a `client` implementations that integrates with the server and interacts with `gemini-2.5-flash`.\n- **[gx-mcp-server](https://github.com/davidf9999/gx-mcp-server)** - Expose Great Expectations data validation and quality checks as MCP tools for AI agents.\n- **[Gralio SaaS Database](https://github.com/tymonTe/gralio-mcp)** - Find and compare SaaS products, including data from G2 reviews, Trustpilot, Crunchbase, Linkedin, pricing, features and more, using [Gralio MCP](https://gralio.ai/mcp) server\n- **[GraphQL](https://github.com/drestrepom/mcp_graphql)** - Comprehensive GraphQL API integration that automatically exposes each GraphQL query as a separate tool.\n- **[GraphQL Schema](https://github.com/hannesj/mcp-graphql-schema)** - Allow LLMs to explore large GraphQL schemas without bloating the context.\n- **[HackMD](https://github.com/yuna0x0/hackmd-mcp)** (by yuna0x0) - An MCP server for HackMD, a collaborative markdown editor. It allows users to create, read, and update documents in HackMD using the Model Context Protocol.\n- **[HAProxy](https://github.com/tuannvm/haproxy-mcp-server)** - A Model Context Protocol (MCP) server for HAProxy implemented in Go, leveraging HAProxy Runtime API.\n- **[Hashing MCP Server](https://github.com/kanad13/MCP-Server-for-Hashing)** - MCP Server with cryptographic hashing functions e.g. SHA256, MD5, etc.\n- **[HDW LinkedIn](https://github.com/horizondatawave/hdw-mcp-server)** - Access to profile data and management of user account with [HorizonDataWave.ai](https://horizondatawave.ai/).\n- **[HeatPump](https://github.com/jiweiqi/heatpump-mcp-server)** — Residential heat - pump sizing & cost-estimation tools by **HeatPumpHQ**.\n- **[Helm Chart CLI](https://github.com/jeff-nasseri/helm-chart-cli-mcp)** - Helm MCP provides a bridge between AI assistants and the Helm package manager for Kubernetes. It allows AI assistants to interact with Helm through natural language requests, executing commands like installing charts, managing repositories, and more.\n- **[Heurist Mesh Agent](https://github.com/heurist-network/heurist-mesh-mcp-server)** - Access specialized web3 AI agents for blockchain analysis, smart contract security, token metrics, and blockchain interactions through the [Heurist Mesh network](https://github.com/heurist-network/heurist-agent-framework/tree/main/mesh).\n- **[HLedger MCP](https://github.com/iiAtlas/hledger-mcp)** - Double entry plain text accounting, right in your LLM! This MCP enables comprehensive read, and (optional) write access to your local [HLedger](https://hledger.org/) accounting journals.\n- **[Holaspirit](https://github.com/syucream/holaspirit-mcp-server)** - Interact with [Holaspirit](https://www.holaspirit.com/).\n- **[Home Assistant](https://github.com/tevonsb/homeassistant-mcp)** - Interact with [Home Assistant](https://www.home-assistant.io/) including viewing and controlling lights, switches, sensors, and all other Home Assistant entities.\n- **[Home Assistant](https://github.com/voska/hass-mcp)** - Docker-ready MCP server for Home Assistant with entity management, domain summaries, automation support, and guided conversations. Includes pre-built container images for easy installation.\n- **[HubSpot](https://github.com/buryhuang/mcp-hubspot)** - HubSpot CRM integration for managing contacts and companies. Create and retrieve CRM data directly through Claude chat.\n- **[HuggingFace Spaces](https://github.com/evalstate/mcp-hfspace)** - Server for using HuggingFace Spaces, supporting Open Source Image, Audio, Text Models and more. Claude Desktop mode for easy integration.\n- **[Human-In-the-Loop](https://github.com/GongRzhe/Human-In-the-Loop-MCP-Server)** - A powerful MCP Server that enables AI assistants like Claude to interact with humans through intuitive GUI dialogs. This server bridges the gap between automated AI processes and human decision-making by providing real-time user input tools, choices, confirmations, and feedback mechanisms.\n- **[Human-use](https://github.com/RapidataAI/human-use)** - Instant human feedback through an MCP, have your AI interact with humans around the world. Powered by [Rapidata](https://www.rapidata.ai/)\n- **[Hyperledger Fabric Agent Suite](https://github.com/padmarajkore/hlf-fabric-agent)** - Modular toolkit for managing Fabric test networks and chaincode lifecycle via MCP tools.\n- **[Hyperliquid](https://github.com/mektigboy/server-hyperliquid)** - An MCP server implementation that integrates the Hyperliquid SDK for exchange data.\n- **[Hypertool](https://github.com/toolprint/hypertool-mcp)** – MCP that let's you create hot - swappable, \"persona toolsets\" from multiple MCP servers to reduce tool overload and improve tool execution.\n- **[hyprmcp](https://github.com/stefanoamorelli/hyprmcp)** (by Stefano Amorelli) - Lightweight MCP server for `hyprland`.\n- **[iFlytek SparkAgent Platform](https://github.com/iflytek/ifly-spark-agent-mcp)** - This is a simple example of using MCP Server to invoke the task chain of the  iFlytek SparkAgent Platform.\n- **[iFlytek Workflow](https://github.com/iflytek/ifly-workflow-mcp-server)** - Connect to iFlytek Workflow via the MCP server and run your own Agent.\n- **[IIIF](https://github.com/code4history/IIIF_MCP)** - Comprehensive IIIF (International Image Interoperability Framework) protocol support for searching, navigating, and manipulating digital collections from museums, libraries, and archives worldwide.\n- **[Image Generation](https://github.com/GongRzhe/Image-Generation-MCP-Server)** - This MCP server provides image generation capabilities using the Replicate Flux model.\n- **[ImageSorcery MCP](https://github.com/sunriseapps/imagesorcery-mcp)** - ComputerVision-based 🪄 sorcery of image recognition and editing tools for AI assistants.\n- **[IMAP MCP](https://github.com/dominik1001/imap-mcp)** - 📧 An IMAP Model Context Protocol (MCP) server to expose IMAP operations as tools for AI assistants.\n- **[iMCP](https://github.com/loopwork-ai/iMCP)** - A macOS app that provides an MCP server for your iMessage, Reminders, and other Apple services.\n- **[InfluxDB](https://github.com/idoru/influxdb-mcp-server)** - Run queries against InfluxDB OSS API v2.\n- **[Intelligent Image Generator](https://github.com/shinpr/mcp-image)** - Turn casual prompts into professional-quality images with AI enhancement\n- **[Inner Monologue MCP](https://github.com/abhinav-mangla/inner-monologue-mcp)** - A cognitive reasoning tool that enables LLMs to engage in private, structured self-reflection and multi-step reasoning before generating responses, improving response quality and problem-solving capabilities.\n- **[Inoyu](https://github.com/sergehuber/inoyu-mcp-unomi-server)** - Interact with an Apache Unomi CDP customer data platform to retrieve and update customer profiles\n- **[Instagram DM](https://github.com/trypeggy/instagram_dm_mcp)** - Send DMs on Instagram via your LLM\n- **[interactive-mcp](https://github.com/ttommyth/interactive-mcp)** - Enables interactive LLM workflows by adding local user prompts and chat capabilities directly into the MCP loop.\n- **[Intercom](https://github.com/raoulbia-ai/mcp-server-for-intercom)** - An MCP-compliant server for retrieving customer support tickets from Intercom. This tool enables AI assistants like Claude Desktop and Cline to access and analyze your Intercom support tickets.\n- **[iOS Simulator](https://github.com/InditexTech/mcp-server-simulator-ios-idb)** - A Model Context Protocol (MCP) server that enables LLMs to interact with iOS simulators (iPhone, iPad, etc.) through natural language commands.\n- **[ipybox](https://github.com/gradion-ai/ipybox)** - Python code execution sandbox based on IPython and Docker. Stateful code execution, file transfer between host and container, configurable network access. See [ipybox MCP server](https://gradion-ai.github.io/ipybox/mcp-server/) for details.\n- **[it-tools-mcp](https://github.com/wrenchpilot/it-tools-mcp)** - A Model Context Protocol server that recreates [CorentinTh it-tools](https://github.com/CorentinTh/it-tools) utilities for AI agents, enabling access to a wide range of developer tools (encoding, decoding, conversions, and more) via MCP.\n- **[itemit MCP](https://github.com/umin-ai/itemit-mcp)** - itemit is Asset Tracking MCP that manage the inventory, monitoring and location tracking that powers over +300 organizations.\n- **[iTerm MCP](https://github.com/ferrislucas/iterm-mcp)** - Integration with iTerm2 terminal emulator for macOS, enabling LLMs to execute and monitor terminal commands.\n- **[iTerm MCP Server](https://github.com/rishabkoul/iTerm-MCP-Server)** - A Model Context Protocol (MCP) server implementation for iTerm2 terminal integration. Able to manage multiple iTerm Sessions.\n- **[Java Decompiler](https://github.com/idachev/mcp-javadc)** - Decompile Java bytecode into readable source code from .class files, package names, or JAR archives using CFR decompiler\n- **[JavaFX](https://github.com/quarkiverse/quarkus-mcp-servers/tree/main/jfx)** - Make drawings using a JavaFX canvas\n- **[JDBC](https://github.com/quarkiverse/quarkus-mcp-servers/tree/main/jdbc)** - Connect to any JDBC-compatible database and query, insert, update, delete, and more. Supports MySQL, PostgreSQL, Oracle, SQL Server, SQLite and [more](https://github.com/quarkiverse/quarkus-mcp-servers/tree/main/jdbc#supported-jdbc-variants).\n- **[Jenkins](https://github.com/jasonkylelol/jenkins-mcp-server)** - This MCP server allow you to create Jenkins tasks.\n- **[JMeter](https://github.com/QAInsights/jmeter-mcp-server)** - Run load testing using Apache JMeter via MCP-compliant tools.\n- **[Job Searcher](https://github.com/0xDAEF0F/job-searchoor)** - A FastMCP server that provides tools for retrieving and filtering job listings based on time period, keywords, and remote work preferences.\n- **[jobswithgpt](https://github.com/jobswithgpt/mcp)** - Job search MCP using jobswithgpt which indexes 500K+ public job listings and refreshed continously.\n- **[joinly](https://github.com/joinly-ai/joinly)** - MCP server to interact with browser-based meeting platforms (Zoom, Teams, Google Meet). Enables AI agents to send bots to online meetings, gather live transcripts, speak text, and send messages in the meeting chat.\n- **[JSON](https://github.com/GongRzhe/JSON-MCP-Server)** - JSON handling and processing server with advanced query capabilities using JSONPath syntax and support for array, string, numeric, and date operations.\n- **[JSON](https://github.com/kehvinbehvin/json-mcp-filter)** - JSON schema generation and filtering server with TypeScript type creation optimised for retrieving relevant context JSON data using quicktype-core and support for shape-based data extraction, nested object filtering, and array processing operations.\n- **[JSON to Excel by WTSolutions](https://github.com/he-yang/json-to-excel-mcp)** - Converting JSON into CSV format string from (1) JSON data, (2) URLs pointing to publiclly available .json files.\n- **[JSON2Video MCP](https://github.com/omergocmen/json2video-mcp-server)** - A Model Context Protocol (MCP) server implementation for programmatically generating videos using the json2video API. This server exposes powerful video generation and status-checking tools for use with LLMs, agents, or any MCP-compatible client.\n- **[jupiter-mcp](https://github.com/kukapay/jupiter-mcp)** - An MCP server for executing token swaps on the Solana blockchain using Jupiter's new Ultra API.\n- **[Jupyter MCP Server](https://github.com/datalayer/jupyter-mcp-server)** – Real-time interaction with Jupyter Notebooks, allowing AI to edit, document and execute code for data analysis, visualization etc. Compatible with any Jupyter deployment (local, JupyterHub, ...).\n- **[Jupyter Notebook](https://github.com/jjsantos01/jupyter-notebook-mcp)** - connects Jupyter Notebook to Claude AI, allowing Claude to directly interact with and control Jupyter Notebooks. This integration enables AI-assisted code execution, data analysis, visualization, and more.\n- **[k8s-multicluster-mcp](https://github.com/razvanmacovei/k8s-multicluster-mcp)** - An MCP server for interact with multiple Kubernetes clusters simultaneously using multiple kubeconfig files.\n- **[Kafka](https://github.com/tuannvm/kafka-mcp-server)** - A Model Context Protocol (MCP) server for Apache Kafka implemented in Go, leveraging [franz-go](https://github.com/twmb/franz-go).\n- **[Kafka Schema Registry MCP](https://github.com/aywengo/kafka-schema-reg-mcp)** \\ - A comprehensive MCP server for Kafka Schema Registry with 48 tools, multi-registry support, authentication, and production safety features. Enables AI-powered schema management with enterprise-grade capabilities including schema contexts, migration tools, and comprehensive export capabilities.\n- **[kafka-mcp](https://github.com/shivamxtech/kafka-mcp)** - An MCP Server for Kafka clusters to interact with kafka environment via tools on messages, topics, offsets, partitions for consumer and producers along with seamless integration with MCP clients.\n- **[Keycloak](https://github.com/idoyudha/mcp-keycloak)** - The Keycloak MCP Server designed for agentic applications to manage and search data in Keycloak efficiently.\n- **[Keycloak MCP](https://github.com/ChristophEnglisch/keycloak-model-context-protocol)** - This MCP server enables natural language interaction with Keycloak for user and realm management including creating, deleting, and listing users and realms.\n- **[Keycloak MCP Server](https://github.com/sshaaf/keycloak-mcp-server)** - designed to work with Keycloak for identity and access management, with about 40+ tools covering, Users, Realms, Clients, Roles, Groups, IDPs, Authentication. Native builds available.\n- **[Kibana MCP](https://github.com/TocharianOU/mcp-server-kibana.git)** (by TocharianOU) - A community-maintained MCP server implementation that allows any MCP-compatible client to access and manage Kibana instances through natural language or programmatic requests.\n- **[Kibela](https://github.com/kiwamizamurai/mcp-kibela-server)** (by kiwamizamurai) - Interact with Kibela API.\n- **[KiCad MCP](https://github.com/lamaalrajih/kicad-mcp)** - MCP server for KiCad on Mac, Windows, and Linux.\n- **[kill-process-mcp](https://github.com/misiektoja/kill-process-mcp)** - List and terminate OS processes via natural language queries\n- **[Kindred Offers & Discounts MCP](https://github.com/kindred-app/mcp-server-kindred-offers)** (by kindred.co) - This MCP server allows you to get live deals and offers/coupons from e-commerce merchant sites all over the world.\n- **[kintone](https://github.com/macrat/mcp-server-kintone)** - Manage records and apps in [kintone](https://kintone.com) through LLM tools.\n- **[Kokoro TTS](https://github.com/mberg/kokoro-tts-mcp)** - Use Kokoro text to speech to convert text to MP3s with optional autoupload to S3.\n- **[Kong Konnect](https://github.com/Kong/mcp-konnect)** - A Model Context Protocol (MCP) server for interacting with Kong Konnect APIs, allowing AI assistants to query and analyze Kong Gateway configurations, traffic, and analytics.\n- **[Korea Stock Analyzer](https://github.com/Mrbaeksang/korea-stock-analyzer-mcp)** - Analyze Korean stocks (KOSPI/KOSDAQ) with 6 legendary investment strategies including Buffett, Lynch, Graham, Greenblatt, Fisher, and Templeton.\n- **[Kubernetes](https://github.com/Flux159/mcp-server-kubernetes)** - Connect to Kubernetes cluster and manage pods, deployments, and services.\n- **[Kubernetes and OpenShift](https://github.com/manusa/kubernetes-mcp-server)** - A powerful Kubernetes MCP server with additional support for OpenShift. Besides providing CRUD operations for any Kubernetes resource, this server provides specialized tools to interact with your cluster.\n- **[KubeSphere](https://github.com/kubesphere/ks-mcp-server)** - The KubeSphere MCP Server is a Model Context Protocol(MCP) server that provides integration with KubeSphere APIs, enabling to get resources from KubeSphere. Divided into four tools modules: Workspace Management, Cluster Management, User and Roles, Extensions Center.\n- **[Kukapay MCP Servers](https://github.com/kukapay/kukapay-mcp-servers)** - A comprehensive suite of Model Context Protocol (MCP) servers dedicated to cryptocurrency, blockchain, and Web3 data aggregation, analysis, and services from Kukapay.\n- **[kwrds.ai](https://github.com/mkotsollaris/kwrds_ai_mcp)** - Keyword research, people also ask, SERP and other SEO tools for [kwrds.ai](https://www.kwrds.ai/)\n- **[KYC-mcp-server](https://github.com/vishnurudra-ai/KYC-mcp-server)** - Know Your Computer (KYC) - MCP Server compatible with Claude Desktop. Comprehensive system diagnostics for Windows, Mac OS and Linux operating system with AI-powered recommendations.\n- **[Langflow-DOC-QA-SERVER](https://github.com/GongRzhe/Langflow-DOC-QA-SERVER)** - A Model Context Protocol server for document Q&A powered by Langflow. It demonstrates core MCP concepts by providing a simple interface to query documents through a Langflow backend.\n- **[Language Server](https://github.com/isaacphi/mcp-language-server)** - MCP Language Server helps MCP enabled clients navigate codebases more easily by giving them access to semantic tools like get definition, references, rename, and diagnostics.\n- **[Lark(Feishu)](https://github.com/kone-net/mcp_server_lark)** - A Model Context Protocol(MCP) server for Lark(Feishu) sheet, message, doc and etc.\n- **[Lazy Toggl MCP](https://github.com/movstox/lazy-toggl-mcp)** - Simple unofficial MCP server to track time via Toggl API\n- **[lean-lsp-mcp](https://github.com/oOo0oOo/lean-lsp-mcp)** - Interact with the [Lean theorem prover](https://lean-lang.org/) via the Language Server Protocol.\n- **[librenms-mcp](https://github.com/mhajder/librenms-mcp)** - MCP server for [LibreNMS](https://www.librenms.org/) management\n- **[libvirt-mcp](https://github.com/MatiasVara/libvirt-mcp)** - Allows LLM to interact with libvirt thus enabling to create, destroy or list the Virtual Machines in a system.\n- **[Lightdash](https://github.com/syucream/lightdash-mcp-server)** - Interact with [Lightdash](https://www.lightdash.com/), a BI tool.\n- **[LINE](https://github.com/amornpan/py-mcp-line)** (by amornpan) - Implementation for LINE Bot integration that enables Language Models to read and analyze LINE conversations through a standardized interface. Features asynchronous operation, comprehensive logging, webhook event handling, and support for various message types.\n- **[Linear](https://github.com/tacticlaunch/mcp-linear)** - Interact with Linear project management system.\n- **[Linear](https://github.com/jerhadf/linear-mcp-server)** - Allows LLM to interact with Linear's API for project management, including searching, creating, and updating issues.\n- **[Linear (Go)](https://github.com/geropl/linear-mcp-go)** - Allows LLM to interact with Linear's API via a single static binary.\n- **[Linear MCP](https://github.com/anoncam/linear-mcp)** - Full blown implementation of the Linear SDK to support comprehensive Linear management of projects, initiatives, issues, users, teams and states.\n- **[Linked API MCP](https://github.com/Linked-API/linkedapi-mcp)** - MCP server that lets AI assistants control LinkedIn accounts and retrieve real-time data.\n- **[Listmonk MCP Server](https://github.com/rhnvrm/listmonk-mcp)** (by rhnvrm) - Full API coverage of [Listmonk](https://github.com/knadh/listmonk) email marketing FOSS.\n- **[LlamaCloud](https://github.com/run-llama/mcp-server-llamacloud)** (by marcusschiesser) - Integrate the data stored in a managed index on [LlamaCloud](https://cloud.llamaindex.ai/)\n- **[lldb-mcp](https://github.com/stass/lldb-mcp)** - A Model Context Protocol server for LLDB that provides LLM-driven debugging.\n- **[llm-context](https://github.com/cyberchitta/llm-context.py)** - Provides a repo-packing MCP tool with configurable profiles that specify file inclusion/exclusion patterns and optional prompts.\n- **[Local History](https://github.com/xxczaki/local-history-mcp)** – MCP server for accessing VS Code/Cursor's Local History.\n- **[Locust](https://github.com/QAInsights/locust-mcp-server)** - Allows running and analyzing Locust tests using MCP compatible clients.\n- **[Loki](https://github.com/scottlepp/loki-mcp)** - Golang based MCP Server to query logs from [Grafana Loki](https://github.com/grafana/loki).\n- **[Loki MCP Server](https://github.com/mo-silent/loki-mcp-server)** - Python based MCP Server for querying and analyzing logs from Grafana Loki with advanced filtering and authentication support.\n- **[LottieFiles](https://github.com/junmer/mcp-server-lottiefiles)** - Searching and retrieving Lottie animations from [LottieFiles](https://lottiefiles.com/)\n- **[lsp-mcp](https://github.com/Tritlo/lsp-mcp)** - Interact with Language Servers usint the Language Server Protocol to provide additional context information via hover, code actions and completions.\n- **[Lspace](https://github.com/Lspace-io/lspace-server)** - Turn scattered ChatGPT/Claude/Cursor conversations into persistent, searchable knowledge.\n- **[lucene-mcp-server](https://github.com/VivekKumarNeu/MCP-Lucene-Server)** - spring boot server using Lucene for fast document search and management.\n- **[lucid-mcp-server](https://github.com/smartzan63/lucid-mcp-server)** – An MCP server for Lucidchart and Lucidspark: connect, search, and obtain text representations of your Lucid documents and diagrams via LLM - driven AI Vision analysis. [npm](https://www.npmjs.com/package/lucid-mcp-server)\n- **[LunarCrush Remote MCP](https://github.com/lunarcrush/mcp-server)** - Get the latest social metrics and posts for both current live social context as well as historical metrics in LLM and token optimized outputs. Ideal for automated trading / financial advisory.\n- **[mac-messages-mcp](https://github.com/carterlasalle/mac_messages_mcp)** - An MCP server that securely interfaces with your iMessage database via the Model Context Protocol (MCP), allowing LLMs to query and analyze iMessage conversations. It includes robust phone number validation, attachment processing, contact management, group chat handling, and full support for sending and receiving messages.\n- **[Maestro MCP](https://github.com/maestro-org/maestro-mcp)** - An MCP server for interacting with Bitcoin via the Maestro RPC API.\n- **[Magg: The MCP Aggregator](https://github.com/sitbon/magg)** - A meta-MCP server that acts as a universal hub, allowing LLMs to autonomously discover, install, and orchestrate multiple MCP servers - essentially giving AI assistants the power to extend their own capabilities on-demand. Includes `mbro`, a powerful CLI MCP server browser with scripting capability.\n- **[Mailchimp MCP](https://github.com/AgentX-ai/mailchimp-mcp)** - Allows AI agents to interact with the Mailchimp API (read-only)\n- **[MalwareBazaar_MCP](https://github.com/mytechnotalent/MalwareBazaar_MCP)** (by Kevin Thomas) - An AI-driven MCP server that autonomously interfaces with MalwareBazaar, delivering real-time threat intel and sample metadata for authorized cybersecurity research workflows.\n- **[Mandoline](https://github.com/mandoline-ai/mandoline-mcp-server)** - Enable AI assistants to reflect on, critique, and continuously improve their own performance using Mandoline's evaluation framework.\n- **[Matrix](https://github.com/mjknowles/matrix-mcp-server)** - Interact with a Matrix homeserver.\n- **[man-mcp-server](https://github.com/guyru/man-mcp-server)** - MCP to search and access man pages on the local machine.\n- **[MariaDB](https://github.com/abel9851/mcp-server-mariadb)** - MariaDB database integration with configurable access controls in Python.\n- **[Markdown2doc](https://github.com/Klavis-AI/klavis/tree/main/mcp_servers/pandoc)** - Convert between various file formats using Pandoc\n- **[Markdownify](https://github.com/zcaceres/mcp-markdownify-server)** - MCP to convert almost anything to Markdown (PPTX, HTML, PDF, Youtube Transcripts and more)\n- **[market-fiyati](https://github.com/mtcnbzks/market-fiyati-mcp-server)** - The MCP server for marketfiyati.org.tr, offering grocery price search and comparison across Turkish markets.)\n- **[Markitdown](https://github.com/Klavis-AI/klavis/tree/main/mcp_servers/markitdown)** - Convert files to Markdown\n- **[Masquerade](https://github.com/postralai/masquerade)** - Redact sensitive information from your PDF documents before sending them to Claude. Masquerade serves as a privacy firewall for LLMs.\n- **[MasterGo](https://github.com/mastergo-design/mastergo-magic-mcp)** - The server designed to connect MasterGo design tools with AI models. It enables AI models to directly retrieve DSL data from MasterGo design files.\n- **[Matlab-MCP-Tools](https://github.com/neuromechanist/matlab-mcp-tools)** - An MCP to write and execute MATLAB scripts, maintain workspace context between MCP calls, visualize plots, and perform section-by-section analysis of MATLAB code with full access to MATLAB's computational capabilities.\n- **[Maton](https://github.com/maton-ai/agent-toolkit/tree/main/modelcontextprotocol)** - Connect to your SaaS tools like HubSpot, Salesforce, and more.\n- **[Maven Tools MCP](https://github.com/arvindand/maven-tools-mcp)** - Maven Central dependency intelligence for JVM build tools. Supports all build tools (Maven, Gradle, SBT, Mill) with Context7 integration for documentation support.\n- **[MCP-Airflow-API](https://github.com/call518/MCP-Airflow-API)** - Model Context Protocol (MCP) server for Apache Airflow API integration. Provides comprehensive tools for managing Airflow clusters including service operations, configuration management, status monitoring, and request tracking.\n- **[mcpcap](https://github.com/mcpcap/mcpcap)** - A modular Python MCP (Model Context Protocol) Server for analyzing PCAP files.\n- **[MCP Compass](https://github.com/liuyoshio/mcp-compass)** - Suggest the right MCP server for your needs\n- **[MCP Create](https://github.com/tesla0225/mcp-create)** - A dynamic MCP server management service that creates, runs, and manages Model Context Protocol servers on-the-fly.\n- **[MCP Documentation Server](https://github.com/andrea9293/mcp-documentation-server)** - Server that provides local-first document management and semantic search via embeddings or Gemini AI (recommended). Optimized for performance with disk persistence, an in-memory index, and caching.\n- **[MCP Installer](https://github.com/anaisbetts/mcp-installer)** - This server is a server that installs other MCP servers for you.\n- **[MCP ProjectManage OpenProject](https://github.com/boma086/mcp-projectmanage-openproject)** - This server provides the MCP service for project weekly reports, with project management information supplied by OpenProject.\n- **[MCP Proxy Server](https://github.com/TBXark/mcp-proxy)** - An MCP proxy server that aggregates and serves multiple MCP resource servers through a single HTTP server.\n- **[MCP Server Creator](https://github.com/GongRzhe/MCP-Server-Creator)** - A powerful Model Context Protocol (MCP) server that creates other MCP servers! This meta-server provides tools for dynamically generating FastMCP server configurations and Python code.\n- **[MCP Server Generator](https://github.com/SerhatUzbas/mcp-server-generator)** - An MCP server that creates and manages  MCP servers! Helps both non-technical users and developers build custom JavaScript MCP servers with AI guidance, automatic dependency management, and Claude Desktop integration.\n- **[MCP STDIO to Streamable HTTP Adapter](https://github.com/pyroprompts/mcp-stdio-to-streamable-http-adapter)** - Connect to Streamable HTTP MCP Servers even if the MCP Client only supports STDIO.\n- **[MCP-Ambari-API](https://github.com/call518/MCP-Ambari-API)** - Model Context Protocol (MCP) server for Apache Ambari API integration. This project provides tools for managing Hadoop clusters, including service operations, configuration management, status monitoring, and request tracking.\n- **[MCP-OpenStack-Ops](https://github.com/call518/MCP-OpenStack-Ops)** - Professional OpenStack operations automation via MCP server. Specialized tools for cluster monitoring, instance management, volume control & network analysis. FastMCP + OpenStack SDK + Bearer auth. Claude Desktop ready. Perfect for DevOps & cloud automation.\n- **[MCP-PostgreSQL-Ops](https://github.com/call518/MCP-PostgreSQL-Ops)** - Model Context Protocol (MCP) server for Apache Ambari API integration. This project provides tools for managing Hadoop clusters, including service operations, configuration management, status monitoring, and request tracking.\n- **[mcp-containerd](https://github.com/jokemanfire/mcp-containerd)** - The containerd MCP implemented by Rust supports the operation of the CRI interface.\n- **[MCP-Database-Server](https://github.com/executeautomation/mcp-database-server)** - Fastest way to interact with your Database such as SQL Server, SQLite and PostgreSQL\n- **[mcp-grep](https://github.com/erniebrodeur/mcp-grep)** - Python-based MCP server that brings grep functionality to LLMs. Supports common grep features including pattern searching, case-insensitive matching, context lines, and recursive directory searches.\n- **[mcp-k8s-go](https://github.com/strowk/mcp-k8s-go)** - Golang-based Kubernetes server for MCP to browse pods and their logs, events, namespaces and more. Built to be extensible.\n- **[mcp-local-rag](https://github.com/nkapila6/mcp-local-rag)** - \"primitive\" RAG-like web search model context protocol (MCP) server that runs locally using Google's MediaPipe Text Embedder and DuckDuckGo Search.\n- **[mcp-mcp](https://github.com/wojtyniak/mcp-mcp)** - Meta-MCP Server that acts as a tool discovery service for MCP clients.\n- **[mcp-meme-sticky](https://github.com/nkapila6/mcp-meme-sticky)** - Make memes or stickers using MCP server for WhatsApp or Telegram.\n- **[mcp-memory-service](https://github.com/doobidoo/mcp-memory-service)** - Universal MCP memory service providing semantic memory search, persistent storage, and autonomous memory consolidation for AI assistants across 13+ AI applications.\n- **[MCP-NixOS](https://github.com/utensils/mcp-nixos)** - A Model Context Protocol server that provides AI assistants with accurate, real-time information about NixOS packages, system options, Home Manager settings, and nix-darwin macOS configurations.\n- **[mcp-open-library](https://github.com/8enSmith/mcp-open-library)** - A Model Context Protocol (MCP) server for the Open Library API that enables AI assistants to search for book and author information.\n- **[mcp-proxy](https://github.com/sparfenyuk/mcp-proxy)** - Connect to MCP servers that run on SSE transport, or expose stdio servers as an SSE server.\n- **[mcp-read-website-fast](https://github.com/just-every/mcp-read-website-fast)** - Fast, token-efficient web content extraction that converts websites to clean Markdown. Features Mozilla Readability, smart caching, polite crawling with robots.txt support, and concurrent fetching with minimal dependencies.\n- **[mcp-salesforce](https://github.com/lciesielski/mcp-salesforce-example)** - MCP server with basic demonstration of interactions with your Salesforce instance\n- **[mcp-sanctions](https://github.com/madupay/mcp-sanctions)** - Screen individuals and organizations against global sanctions lists (OFAC, SDN, UN, etc). Query by prompt or document upload.\n- **[mcp-screenshot-website-fast](https://github.com/just-every/mcp-screenshot-website-fast)** - High-quality screenshot capture optimized for Claude Vision API. Automatically tiles full pages into 1072x1072 chunks (1.15 megapixels) with configurable viewports and wait strategies for dynamic content.\n- **[mcp-server-leetcode](https://github.com/doggybee/mcp-server-leetcode)** - Practice and retrieve problems from LeetCode. Automate problem retrieval, solutions, and insights for coding practice and competitions.\n- **[Mcp-Swagger-Server](https://github.com/zaizaizhao/mcp-swagger-server)** (by zaizaizhao) - This MCP server transforms OpenAPI specifications into MCP tools, enabling AI assistants to interact with REST APIs through standardized protocol\n- **[MCP Dynamic Tool Groups](https://github.com/ECF/MCPToolGroups)** - Example MCP servers that use [annotated](https://github.com/spring-ai-community/mcp-annotations) Java interfaces/classes as 'tool groups'.  Using standard MCP annotations, service implementations can then, at runtime, be used to generate tool specifications, and then dynamically added or removed from MCP servers.   The functionality is demonstrated in a sample tool group, but can be similarly used for any API or service.\n- **[mcp-vision](https://github.com/groundlight/mcp-vision)** - An MCP server exposing HuggingFace computer vision models such as zero-shot object detection as tools, enhancing the vision capabilities of large language or vision-language models.\n- **[mcp-weather](https://github.com/TimLukaHorstmann/mcp-weather)** - Accurate weather forecasts via the AccuWeather API (free tier available).\n- **[KnowAir Weather MCP](https://github.com/shuowang-ai/Weather-MCP)** - A comprehensive Model Context Protocol (MCP) server providing real-time weather data, air quality monitoring, forecasts, and astronomical information powered by Caiyun Weather API.\n- **[mcp-youtube-extract](https://github.com/sinjab/mcp_youtube_extract)** - A Model Context Protocol server for YouTube operations, extracting video information and transcripts with intelligent fallback logic. Features comprehensive logging, error handling, and support for both auto-generated and manual transcripts.\n- **[mcp_weather](https://github.com/isdaniel/mcp_weather_server)** - Get weather information from https://api.open-meteo.com API.\n- **[MCPfinder](https://github.com/mcpfinder/server)** - The AI Agent's \"App Store\": Discover, install, and monetize AI capabilities — all within the MCP ecosystem.\n- **[MCPIgnore Filesytem](https://github.com/CyberhavenInc/filesystem-mcpignore)** - A Data Security First filesystem MCP server that implements .mcpignore to prevent MCP clients from accessing sensitive data.\n- **[MCPJungle](https://github.com/mcpjungle/MCPJungle)** - Self-hosted MCP Registry and Gateway for enterprise AI Agents\n- **[Md2doc](https://github.com/Yorick-Ryu/md2doc-mcp)** - Convert Markdown text to DOCX format using an external conversion service\n- **[MeasureSpace MCP](https://github.com/MeasureSpace/measure-space-mcp-server)** - A free [Model Context Protocol (MCP) Server](https://smithery.ai/server/@MeasureSpace/measure-space-mcp-server) that provides global weather, climate, air quality forecast and geocoding services by [measurespace.io](https://measurespace.io).\n- **[MediaWiki](https://github.com/ProfessionalWiki/MediaWiki-MCP-Server)** - A Model Context Protocol (MCP) Server that interacts with any MediaWiki wiki\n- **[MediaWiki MCP adapter](https://github.com/lucamauri/MediaWiki-MCP-adapter)** - A custom Model Context Protocol adapter for MediaWiki and WikiBase APIs\n- **[medRxiv](https://github.com/JackKuo666/medRxiv-MCP-Server)** - Enable AI assistants to search and access medRxiv papers through a simple MCP interface.\n- **[mem0-mcp](https://github.com/mem0ai/mem0-mcp)** - A Model Context Protocol server for Mem0, which helps with managing coding preferences.\n- **[Membase](https://github.com/unibaseio/membase-mcp)** - Save and query your agent memory in distributed way by Membase.\n- **[Meme MCP](https://github.com/lidorshimoni/meme-mcp)** - Generate memes via AI using the Imgflip API through the Model Context Protocol.\n- **[memento-mcp](https://github.com/gannonh/memento-mcp)** - Knowledge graph memory system built on Neo4j with semantic search, temporal awareness.\n- **[Meta Ads Remote MCP](https://github.com/pipeboard-co/meta-ads-mcp)** - Remote MCP server to interact with Meta Ads API - access, analyze, and manage Facebook, Instagram, and other Meta platforms advertising campaigns.\n- **[MetaTrader MCP](https://github.com/ariadng/metatrader-mcp-server)** - Enable AI LLMs to execute trades using MetaTrader 5 platform.\n- **[Metricool MCP](https://github.com/metricool/mcp-metricool)** - A Model Context Protocol server that integrates with Metricool's social media analytics platform to retrieve performance metrics and schedule content across networks like Instagram, Facebook, Twitter, LinkedIn, TikTok and YouTube.\n- **[Microsoft 365](https://github.com/merill/lokka)** - (by Merill) A Model Context Protocol (MCP) server for Microsoft 365. Includes support for all services including Teams, SharePoint, Exchange, OneDrive, Entra, Intune and more. See [Lokka](https://lokka.dev/) for more details.\n- **[Microsoft 365](https://github.com/softeria/ms-365-mcp-server)** - MCP server that connects to Microsoft Office and the whole Microsoft 365 suite using Graph API (including Outlook/mail, files, Excel, calendar)\n- **[Microsoft 365](https://github.com/pnp/cli-microsoft365-mcp-server)** - Single MCP server that allows to manage many different areas of Microsoft 365, for example: Entra ID, OneDrive, OneNote, Outlook, Planner, Power Apps, Power Automate, Power Platform, SharePoint Embedded, SharePoint Online, Teams, Viva Engage, and many more.\n- **[Microsoft 365 Files (SharePoint/OneDrive)](https://github.com/godwin3737/mcp-server-microsoft365-filesearch)** (by godwin3737) - MCP server with tools to search and get file content from Microsoft 365 including Onedrive and SharePoint. Works with Documents (pdf/docx), Presentations, Spreadsheets and Images.\n- **[Microsoft Teams](https://github.com/InditexTech/mcp-teams-server)** - MCP server that integrates Microsoft Teams messaging (read, post, mention, list members and threads)\n- **[Mifos X](https://github.com/openMF/mcp-mifosx)** - An MCP server for the Mifos X Open Source Banking useful for managing clients, loans, savings, shares, financial transactions and generating financial reports.\n- **[Mikrotik](https://github.com/jeff-nasseri/mikrotik-mcp)** - Mikrotik MCP server which cover networking operations (IP, DHCP, Firewall, etc)\n- **[Mindmap](https://github.com/YuChenSSR/mindmap-mcp-server)** (by YuChenSSR) - A server that generates mindmaps from input containing markdown code.\n- **[Minima](https://github.com/dmayboroda/minima)** - MCP server for RAG on local files\n- **[Modao Proto MCP](https://github.com/modao-dev/modao-proto-mcp)** - AI-powered HTML prototype generation server that converts natural language descriptions into complete HTML code with modern design and responsive layouts. Supports design description expansion and seamless integration with Modao workspace.\n- **[Mobile MCP](https://github.com/mobile-next/mobile-mcp)** (by Mobile Next) - MCP server for Mobile(iOS/Android) automation, app scraping and development using physical devices or simulators/emulators.\n- **[Monday.com (unofficial)](https://github.com/sakce/mcp-server-monday)** - MCP Server to interact with Monday.com boards and items.\n- **[MongoDB](https://github.com/kiliczsh/mcp-mongo-server)** - A Model Context Protocol Server for MongoDB.\n- **[MongoDB & Mongoose](https://github.com/nabid-pf/mongo-mongoose-mcp)** - MongoDB MCP Server with Mongoose Schema and Validation.\n- **[MongoDB Lens](https://github.com/furey/mongodb-lens)** - Full Featured MCP Server for MongoDB Databases.\n- **[Monzo](https://github.com/BfdCampos/monzo-mcp-bfdcampos)** - Access and manage your Monzo bank accounts through natural language, including balance checking, pot management, transaction listing, and transaction annotation across multiple account types (personal, joint, flex).\n- **[Morningstar](https://github.com/Morningstar/morningstar-mcp-server)** - MCP Server to interact with Morningstar Research, Editorial and Datapoints\n- **[MSSQL](https://github.com/aekanun2020/mcp-server/)** - MSSQL database integration with configurable access controls and schema inspection\n- **[MSSQL](https://github.com/JexinSam/mssql_mcp_server)** (by jexin) - MCP Server for MSSQL database in Python\n- **[MSSQL-MCP](https://github.com/daobataotie/mssql-mcp)** (by daobataotie) - MSSQL MCP that refer to the official website's SQLite MCP for modifications to adapt to MSSQL\n- **[MSSQL-MCP-Node](https://github.com/mihai-dulgheru/mssql-mcp-node)** (by mihai - dulgheru) – Node.js MCP server for Microsoft SQL Server featuring auto-detected single / multi-database configs, execute-SQL and schema tools, robust Zod validation, and optional Express endpoints for local testing\n- **[MSSQL-Python](https://github.com/amornpan/py-mcp-mssql)** (by amornpan) - A read-only Python implementation for MSSQL database access with enhanced security features, configurable access controls, and schema inspection capabilities. Focuses on safe database interaction through Python ecosystem.\n- **[Multi-Model Advisor](https://github.com/YuChenSSR/multi-ai-advisor-mcp)** - A Model Context Protocol (MCP) server that orchestrates queries across multiple Ollama models, synthesizing their insights to deliver a comprehensive and multifaceted AI perspective on any given query.\n- **[Multicluster-MCP-Sever](https://github.com/yanmxa/multicluster-mcp-server)** - The gateway for GenAI systems to interact with multiple Kubernetes clusters.\n- **[MySQL](https://github.com/benborla/mcp-server-mysql)** (by benborla) - MySQL database integration in NodeJS with configurable access controls and schema inspection\n- **[MySQL](https://github.com/designcomputer/mysql_mcp_server)** (by DesignComputer) - MySQL database integration in Python with configurable access controls and schema inspection\n- **[MySQL-Server](https://github.com/tonycai/mcp-mysql-server)** (by TonyCai) - MySQL Database Integration using Python script with configurable access controls and schema inspection, usng stdio mode to suitable local deployment, you can run it in docker container.\n- **[n8n](https://github.com/leonardsellem/n8n-mcp-server)** - This MCP server provides tools and resources for AI assistants to manage n8n workflows and executions, including listing, creating, updating, and deleting workflows, as well as monitoring their execution status.\n- **[Nacos MCP Router](https://github.com/nacos-group/nacos-mcp-router)** - This MCP(Model Context Protocol) Server provides tools to search, install, proxy other MCP servers.\n- **[NASA](https://github.com/ProgramComputer/NASA-MCP-server)** (by ProgramComputer) - Access to a unified gateway of NASA's data sources including but not limited to APOD, NEO, EPIC, GIBS.\n- **[NASA Image MCP Server](https://github.com/adithya1012/NASA-MCP-Server/blob/main/README.md)** - MCP server providing access to NASA's visual data APIs including Mars Rover photos, Earth satellite imagery (EPIC/GIBS), and Astronomy picture of the day. Features built-in image analysis tools with automatic format detection, compression, and base64 conversion for LLM integration.\n- **[Nasdaq Data Link](https://github.com/stefanoamorelli/nasdaq-data-link-mcp)** (by stefanoamorelli) - An MCP server to access, explore, and interact with Nasdaq Data Link's extensive and valuable financial and economic datasets.\n- **[National Parks](https://github.com/KyrieTangSheng/mcp-server-nationalparks)** - The server provides latest information of park details, alerts, visitor centers, campgrounds, hiking trails, and events for U.S. National Parks.\n- **[NAVER](https://github.com/pfldy2850/py-mcp-naver)** (by pfldy2850) - This MCP server provides tools to interact with various Naver services, such as searching blogs, news, books, and more.\n- **[Naver](https://github.com/isnow890/naver-search-mcp)** (by isnow890) - MCP server for Naver Search API integration, supporting blog, news, shopping search and DataLab analytics features.\n- **[NBA](https://github.com/Taidgh-Robinson/nba-mcp-server)** - This MCP server provides tools to fetch recent and historical NBA games including basic and advanced statistics.\n- **[NCI GDC](https://github.com/QuentinCody/nci-gdc-mcp-server)** - Unofficial MCP server for the National Cancer Institute's Genomic Data Commons (GDC), providing access to harmonized cancer genomic and clinical data for oncology research.\n- **[Neo4j](https://github.com/da-okazaki/mcp-neo4j-server)** - A community built server that interacts with Neo4j Graph Database.\n- **[Neovim](https://github.com/bigcodegen/mcp-neovim-server)** - An MCP Server for your Neovim session.\n- **[Netbird](https://github.com/aantti/mcp-netbird)** - List and analyze Netbird network peers, groups, policies, and more.\n- **[NetMind ParsePro](https://github.com/protagolabs/Netmind-Parse-PDF-MCP)** - The PDF Parser AI service, built and customized by the [NetMind](https://www.netmind.ai/) team.\n- **[Nikto MCP](https://github.com/weldpua2008/nikto-mcp)** (by weldpua2008) - A secure MCP server that enables AI agents to interact with Nikto web server scanner](- use with npx or docker).\n- **[NocoDB](https://github.com/edwinbernadus/nocodb-mcp-server)** - Read and write access to NocoDB database.\n- **[Node Code Sandbox](https://github.com/alfonsograziano/node-code-sandbox-mcp)** – A Node.js MCP server that spins up isolated Docker - based sandboxes for executing JavaScript snippets with on-the-fly npm dependency installation\n- **[nomad-mcp](https://github.com/kocierik/mcp-nomad)** - A server that provides a set of tools for managing Nomad clusters through the MCP.\n- **[Notion](https://github.com/suekou/mcp-notion-server)** (by suekou) - Interact with Notion API.\n- **[Notion](https://github.com/v-3/notion-server)** (by v-3) - Notion MCP integration. Search, Read, Update, and Create pages through Claude chat.\n- **[NPM Plus](https://github.com/shacharsol/js-package-manager-mcp)** - AI-powered JavaScript package management with security scanning, bundle analysis, and intelligent dependency management for MCP-compatible editors.\n- **[NS Travel Information](https://github.com/r-huijts/ns-mcp-server)** - Access Dutch Railways (NS) real-time train travel information and disruptions through the official NS API.\n- **[ntfy-mcp](https://github.com/teddyzxcv/ntfy-mcp)** (by teddyzxcv) - The MCP server that keeps you informed by sending the notification on phone using ntfy\n- **[ntfy-me-mcp](https://github.com/gitmotion/ntfy-me-mcp)** (by gitmotion) - An ntfy MCP server for sending/fetching ntfy notifications to your self-hosted ntfy server from AI Agents 📤 (supports secure token auth & more - use with npx or docker!)\n- **[oatpp-mcp](https://github.com/oatpp/oatpp-mcp)** - C++ MCP integration for Oat++. Use [Oat++](https://oatpp.io) to build MCP servers.\n- **[Obsidian Markdown Notes](https://github.com/calclavia/mcp-obsidian)** - Read and search through your Obsidian vault or any directory containing Markdown notes\n- **[obsidian-mcp](https://github.com/StevenStavrakis/obsidian-mcp)** - (by Steven Stavrakis) An MCP server for Obsidian.md with tools for searching, reading, writing, and organizing notes.\n- **[OceanBase](https://github.com/yuanoOo/oceanbase_mcp_server)** - (by yuanoOo) A Model Context Protocol (MCP) server that enables secure interaction with OceanBase databases.\n- **[Octocode](https://github.com/bgauryy/octocode-mcp)** - (by Guy Bary) AI-powered developer assistant that enables advanced code research, analysis and discovery across GitHub and NPM realms in realtime\n- **[Odoo](https://github.com/ivnvxd/mcp-server-odoo)** - Connect AI assistants to Odoo ERP systems for business data access and workflow automation.\n- **[Office-PowerPoint-MCP-Server](https://github.com/GongRzhe/Office-PowerPoint-MCP-Server)** - A Model Context Protocol (MCP) server for creating, reading, and manipulating Microsoft PowerPoint documents.\n- **[Office-Visio-MCP-Server](https://github.com/GongRzhe/Office-Visio-MCP-Server)** - A Model Context Protocol (MCP) server for creating, reading, and manipulating Microsoft Visio documents.\n- **[Office-Word-MCP-Server](https://github.com/GongRzhe/Office-Word-MCP-Server)** - A Model Context Protocol (MCP) server for creating, reading, and manipulating Microsoft Word documents.\n- **[Okta](https://github.com/kapilduraphe/okta-mcp-server)** - Interact with Okta API.\n- **[OKX-MCP-Server](https://github.com/memetus/okx-mcp-playground)** - An MCP server provides various blockchain data and market price data via the OKX API. The server enables Claude to perform operations like retrieve assets prices, transaction data, account history data and trade instruction data.\n- **[OneNote](https://github.com/rajvirtual/MCP-Servers/tree/master/onenote)** - (by Rajesh Vijay) An MCP server that connects to Microsoft OneNote using the Microsoft Graph API. Reading notebooks, sections, and pages from OneNote,Creating new notebooks, sections, and pages in OneNote.\n- **[Onyx MCP Sandbox](https://github.com/avd1729/Onyx)** – (by Aravind) A secure MCP server that executes code in isolated Docker sandboxes. Supports Python, Java, C, C++, JavaScript, and Rust. Provides the `run_code` tool, enforces CPU/memory limits, includes comprehensive tests, and detailed setup instructions.\n- **[Open Strategy Partners Marketing Tools](https://github.com/open-strategy-partners/osp_marketing_tools)** - Content editing codes, value map, and positioning tools for product marketing.\n- **[OpenAI WebSearch MCP](https://github.com/ConechoAI/openai-websearch-mcp)** - This is a Python-based MCP server that provides OpenAI `web_search` built-in tool.\n- **[OpenAlex.org MCP](https://github.com/drAbreu/alex-mcp)** - Professional MCP server providing ML-powered author disambiguation and comprehensive researcher profiles using the OpenAlex database.\n- **[OpenAPI](https://github.com/snaggle-ai/openapi-mcp-server)** - Interact with [OpenAPI](https://www.openapis.org/) APIs.\n- **[OpenAPI AnyApi](https://github.com/baryhuang/mcp-server-any-openapi)** - Interact with large [OpenAPI](https://www.openapis.org/) docs using built-in semantic search for endpoints. Allows for customizing the MCP server prefix.\n- **[OpenAPI Schema](https://github.com/hannesj/mcp-openapi-schema)** - Allow LLMs to explore large [OpenAPI](https://www.openapis.org/) schemas without bloating the context.\n- **[OpenAPI Schema Explorer](https://github.com/kadykov/mcp-openapi-schema-explorer)** - Token-efficient access to local or remote OpenAPI/Swagger specs via MCP Resources.\n- **[OpenCTI](https://github.com/Spathodea-Network/opencti-mcp)** - Interact with OpenCTI platform to retrieve threat intelligence data including reports, indicators, malware and threat actors.\n- **[OpenCV](https://github.com/GongRzhe/opencv-mcp-server)** - An MCP server providing OpenCV computer vision capabilities. This allows AI assistants and language models to access powerful computer vision tools.\n- **[OpenDota](https://github.com/asusevski/opendota-mcp-server)** - Interact with OpenDota API to retrieve Dota 2 match data, player statistics, and more.\n- **[OpenLink Generic Java Database Connectivity](https://github.com/OpenLinkSoftware/mcp-jdbc-server)** - Generic Database Management System (DBMS) access via Open Database Connectivity (ODBC) Connectors (Drivers)\n- **[OpenLink Generic Open Database Connectivity](https://github.com/OpenLinkSoftware/mcp-odbc-server)** - Generic Database Management System (DBMS) access via Open Database Connectivity (ODBC) Connectors (Drivers)\n- **[OpenLink Generic Python Open Database Connectivity](https://github.com/OpenLinkSoftware/mcp-pyodbc-server)** - Generic Database Management System (DBMS) access via Open Database Connectivity (ODBC) Connectors (Drivers) for PyODBC\n- **[OpenLink Generic SQLAlchemy Object-Relational Database Connectivity for PyODBC](https://github.com/OpenLinkSoftware/mcp-sqlalchemy-server)** - Generic Database Management System (DBMS) access via SQLAlchemy (PyODBC) Connectors (Drivers)\n- **[OpenMetadata](https://github.com/yangkyeongmo/mcp-server-openmetadata)** - MCP Server for OpenMetadata, an open-source metadata management platform.\n- **[OpenNeuro](https://github.com/QuentinCody/open-neuro-mcp-server)** - Unofficial MCP server for OpenNeuro, providing access to open neuroimaging datasets, study metadata, and brain imaging data for neuroscience research and analysis.\n- **[OpenReview](https://github.com/anyakors/openreview-mcp-server)** - An MCP server for [OpenReview](https://openreview.net/) to fetch, read and save manuscripts from AI/ML conferences.\n- **[OpenRPC](https://github.com/shanejonas/openrpc-mpc-server)** - Interact with and discover JSON-RPC APIs via [OpenRPC](https://open-rpc.org).\n- **[OpenStack](https://github.com/wangsqly0407/openstack-mcp-server)** - MCP server implementation that provides OpenStack interaction.\n- **[Open Targets](https://github.com/QuentinCody/open-targets-mcp-server)** - Unofficial MCP server for the Open Targets Platform, providing access to target-disease associations, drug discovery data, and therapeutic hypothesis generation for biomedical research.\n- **[OpenWeather](https://github.com/mschneider82/mcp-openweather)** - Interact with the free openweathermap API to get the current and forecast weather for a location.\n- **[OpenZIM MCP](https://github.com/cameronrye/openzim-mcp)** - Modern, secure, and high-performance MCP server that enables AI models to access and search ZIM format knowledge bases offline, including Wikipedia and educational content archives.\n- **[Operative WebEvalAgent](https://github.com/Operative-Sh/web-eval-agent)** (by [Operative.sh](https://www.operative.sh)) - An MCP server to test, debug, and fix web applications autonomously.\n- **[OPNSense MCP](https://github.com/vespo92/OPNSenseMCP)** - MCP Server for OPNSense Firewall Management and API access\n- **[OpenAI GPT Image](https://github.com/SureScaleAI/openai-gpt-image-mcp)** - OpenAI GPT image generation/editing MCP server.\n- **[Optimade MCP](https://github.com/dianfengxiaobo/optimade-mcp-server)** - An MCP server conducts real-time material science data queries with the Optimade database (for example, elemental composition, crystal structure).\n- **[Oracle](https://github.com/marcelo-ochoa/servers)** (by marcelo-ochoa) - Oracle Database integration in NodeJS with configurable access controls, query explain, stats and schema inspection\n- **[Oracle Cloud Infrastructure (OCI)](https://github.com/karthiksuku/oci-mcp)** (by karthiksukumar) - Python MCP server for OCI infrastructure (Compute, Autonomous Database, Object Storage). Read-heavy by default with safe instance actions (start/stop/reset). Includes Claude Desktop config and `.env` compartment scoping.\n- **[Oura MCP server](https://github.com/tomekkorbak/oura-mcp-server)** - MCP server for Oura API to retrieve one's sleep data\n- **[Oura Ring](https://github.com/rajvirtual/oura-mcp-server)** (by Rajesh Vijay) - MCP Server to access and analyze your Oura Ring data. It provides a structured way to fetch and understand your health metrics.\n- **[Outline](https://github.com/Vortiago/mcp-outline)** - MCP Server to interact with [Outline](https://www.getoutline.com) knowledge base to search, read, create, and manage documents and their content, access collections, add comments, and manage document backlinks.\n- **[Outlook Mail + Calendar + OneDrive](https://github.com/Norcim133/OutlookMCPServer) - Virtual assistant with Outlook Mail, Calendar, and early OneDrive support (requires Azure admin).\n- **[Pacman](https://github.com/oborchers/mcp-server-pacman)** - An MCP server that provides package index querying capabilities. This server is able to search and retrieve information from package repositories like PyPI, npm, crates.io, Docker Hub, and Terraform Registry.\n- **[pancakeswap-poolspy-mcp](https://github.com/kukapay/pancakeswap-poolspy-mcp)** - An MCP server that tracks newly created liquidity pools on Pancake Swap.\n- **[Pandoc](https://github.com/vivekVells/mcp-pandoc)** - MCP server for seamless document format conversion using Pandoc, supporting Markdown, HTML, PDF, DOCX (.docx), csv and more.\n- **[Paradex MCP](https://github.com/sv/mcp-paradex-py)** - MCP native server for interacting with Paradex platform, including fully features trading.\n- **[Parliament MCP]([https://github.com/sv/mcp-paradex-py](https://github.com/i-dot-ai/parliament-mcp))** - MCP server for querying UK parliamentary data.\n- **[PDF reader MCP](https://github.com/gpetraroli/mcp_pdf_reader)** - MCP server to read and search text in a local PDF file.\n- **[PDF Tools MCP](https://github.com/Sohaib-2/pdf-mcp-server)** - Comprehensive PDF manipulation toolkit (merge, split, encrypt, optimize and much more)\n- **[PDMT](https://github.com/paiml/pdmt)** - Pragmatic Deterministic MCP Templating - High-performance deterministic templating library with comprehensive todo validation, quality enforcement, and 0.0 temperature generation for reproducible outputs.\n- **[Peacock for VS Code](https://github.com/johnpapa/peacock-mcp)** - MCP Server for the Peacock extension for VS Code, coloring your world, one Code editor at a time. The main goal of the project is to show how an MCP server can be used to interact with APIs.\n- **[persistproc](https://github.com/irskep/persistproc)** - MCP server + command line tool that allows agents to see & control long-running processes like web servers.\n- **[Pexels](https://github.com/garylab/pexels-mcp-server)** - A MCP server providing access to Pexels Free Image API, enabling seamless search, retrieval, and download of high-quality royalty-free images.\n- **[Pharos](https://github.com/QuentinCody/pharos-mcp-server)** - Unofficial MCP server for the Pharos database by the National Center for Advancing Translational Sciences (NCATS), providing access to target, drug, and disease information for drug discovery research.\n- **[Phone MCP](https://github.com/hao-cyber/phone-mcp)** - 📱 A powerful plugin that lets you control your Android phone. Enables AI agents to perform complex tasks like automatically playing music based on weather or making calls and sending texts.\n- **[PIF](https://github.com/hungryrobot1/MCP-PIF)** - A Personal Intelligence Framework (PIF), providing tools for file operations, structured reasoning, and journal-based documentation to support continuity and evolving human-AI collaboration across sessions.\n- **[Pinecone](https://github.com/sirmews/mcp-pinecone)** - MCP server for searching and uploading records to Pinecone. Allows for simple RAG features, leveraging Pinecone's Inference API.\n- **[Pinner MCP](https://github.com/safedep/pinner-mcp)** - An MCP server for pinning GitHub Actions and container base images to their immutable SHA hashes to prevent supply chain attacks.\n- **[Pixelle MCP](https://github.com/AIDC-AI/Pixelle-MCP)** - An omnimodal AIGC framework that seamlessly converts ComfyUI workflows into MCP tools with zero code, enabling full-modal support for Text, Image, Sound, and Video generation with Chainlit-based web interface.\n- **[Placid.app](https://github.com/felores/placid-mcp-server)** - Generate image and video creatives using Placid.app templates\n- **[Plane](https://github.com/kelvin6365/plane-mcp-server)** - This MCP Server will help you to manage projects and issues through Plane's API\n- **[Playwright](https://github.com/executeautomation/mcp-playwright)** - This MCP Server will help you run browser automation and webscraping using Playwright\n- **[Podbean](https://github.com/amurshak/podbeanMCP)** - MCP server for managing your podcasts, episodes, and analytics through the Podbean API. Allows for updating, adding, deleting podcasts, querying show description, notes, analytics, and more.\n- **[Polarsteps](https://github.com/remuzel/polarsteps-mcp)** - An MCP server to help you review your previous Trips and plan new ones!\n- **[PostgreSQL](https://github.com/ahmedmustahid/postgres-mcp-server)** - A PostgreSQL MCP server offering dual HTTP/Stdio transports for database schema inspection and read-only query execution with session management and Podman(or Docker) support.\n- **[Postman](https://github.com/shannonlal/mcp-postman)** - MCP server for running Postman Collections locally via Newman. Allows for simple execution of Postman Server and returns the results of whether the collection passed all the tests.\n- **[Powerdrill](https://github.com/powerdrillai/powerdrill-mcp)** - Interact with Powerdrill datasets, authenticated with [Powerdrill](https://powerdrill.ai) User ID and Project API Key.\n- **[Prefect](https://github.com/allen-munsch/mcp-prefect)** - MCP Server for workflow orchestration and ELT/ETL with Prefect Server, and Prefect Cloud [https://www.prefect.io/] using the `prefect` python client.\n- **[Productboard](https://github.com/kenjihikmatullah/productboard-mcp)** - Integrate the Productboard API into agentic workflows via MCP.\n- **[Prometheus](https://github.com/pab1it0/prometheus-mcp-server)** - Query and analyze Prometheus - open-source monitoring system.\n- **[Prometheus (TypeScript)](https://github.com/yanmxa/prometheus-mcp-server)** - Enable AI assistants to query Prometheus using natural language with TypeScript implementation.\n- **[Prometheus (Golang)](https://github.com/tjhop/prometheus-mcp-server/)** - A Prometheus MCP server with full API support for comprehensive management and deep interaction with Prometheus beyond basic query support. Written in go, it is a single binary install that is capable of STDIO, SSE, and HTTP transports for complex deployments. \n- **[PubChem](https://github.com/sssjiang/pubchem_mcp_server)** - extract drug information from pubchem API.\n- **[PubMed](https://github.com/JackKuo666/PubMed-MCP-Server)** - Enable AI assistants to search, access, and analyze PubMed articles through a simple MCP interface.\n- **[Pulumi](https://github.com/dogukanakkaya/pulumi-mcp-server)** - MCP Server to Interact with Pulumi API, creates and lists Stacks\n- **[Puppeteer vision](https://github.com/djannot/puppeteer-vision-mcp)** - Use Puppeteer to browse a webpage and return a high quality Markdown. Use AI vision capabilities to handle cookies, captchas, and other interactive elements automatically.\n- **[Pushover](https://github.com/ashiknesin/pushover-mcp)** - Send instant notifications to your devices using [Pushover.net](https://pushover.net/)\n- **[py-mcp-qdrant-rag](https://github.com/amornpan/py-mcp-qdrant-rag)** (by amornpan) - A Model Context Protocol server implementation that provides RAG capabilities through Qdrant vector database integration, enabling AI agents to perform semantic search and document retrieval with local or cloud-based embedding generation support across Mac, Linux, and Windows platforms.\n- **[pydantic/pydantic-ai/mcp-run-python](https://github.com/pydantic/pydantic-ai/tree/main/mcp-run-python)** - Run Python code in a secure sandbox via MCP tool calls, powered by Deno and Pyodide\n- **[Python CLI MCP](https://github.com/ofek/pycli-mcp)** - Interact with local Python command line applications.\n- **[QGIS](https://github.com/jjsantos01/qgis_mcp)** - connects QGIS to Claude AI through the MCP. This integration enables prompt-assisted project creation, layer loading, code execution, and more.\n- **[Qiniu MCP Server](https://github.com/qiniu/qiniu-mcp-server)** - The Model Context Protocol (MCP) Server built on Qiniu Cloud products supports users in accessing Qiniu Cloud Storage, intelligent multimedia services, and more through this MCP Server within the context of AI large model clients.\n- **[QuantConnect](https://github.com/taylorwilsdon/quantconnect-mcp)** - QuantConnect Algorithmic Trading Platform Orchestration MCP - Agentic LLM Driven Trading Strategy Design, Research & Implementation.\n- **[Quarkus](https://github.com/quarkiverse/quarkus-mcp-servers)** - MCP servers for the Quarkus Java framework.\n- **[QuickChart](https://github.com/GongRzhe/Quickchart-MCP-Server)** - A Model Context Protocol server for generating charts using QuickChart.io\n- **[Qwen_Max](https://github.com/66julienmartin/MCP-server-Qwen_Max)** - A Model Context Protocol (MCP) server implementation for the Qwen models.\n- **[RabbitMQ](https://github.com/kenliao94/mcp-server-rabbitmq)** - The MCP server that interacts with RabbitMQ to publish and consume messages.\n- **[RAE](https://github.com/rae-api-com/rae-mcp)** - MPC Server to connect your preferred model with rae-api.com, Roya Academy of Spanish Dictionary\n- **[RAG Local](https://github.com/renl/mcp-rag-local)** - This MCP server for storing and retrieving text passages locally based on their semantic meaning.\n- **[RAG Web Browser](https://github.com/apify/mcp-server-rag-web-browser)** An MCP server for Apify's open-source RAG Web Browser [Actor](https://apify.com/apify/rag-web-browser) to perform web searches, scrape URLs, and return content in Markdown.\n- **[Raindrop.io](https://github.com/hiromitsusasaki/raindrop-io-mcp-server)** - An integration that allows LLMs to interact with Raindrop.io bookmarks using the Model Context Protocol (MCP).\n- **[Random Number](https://github.com/zazencodes/random-number-mcp)** - Provides LLMs with essential random generation abilities, built entirely on Python's standard library.\n- **[RCSB PDB](https://github.com/QuentinCody/rcsb-pdb-mcp-server)** - Unofficial MCP server for the Research Collaboratory for Structural Bioinformatics Protein Data Bank (RCSB PDB), providing access to 3D protein structures, experimental data, and structural bioinformatics information.\n- **[Reaper](https://github.com/dschuler36/reaper-mcp-server)** - Interact with your [Reaper](https://www.reaper.fm/) (Digital Audio Workstation) projects.\n- **[Redbee](https://github.com/Tamsi/redbee-mcp)** - Redbee MCP server that provides support for interacting with Redbee API.\n- **[Redfish](https://github.com/nokia/mcp-redfish)** - Redfish MCP server that provides support for interacting with [DMTF Redfish API](https://www.dmtf.org/standards/redfish).\n- **[Redis](https://github.com/GongRzhe/REDIS-MCP-Server)** - Redis database operations and caching microservice server with support for key-value operations, expiration management, and pattern-based key listing.\n- **[Redis](https://github.com/prajwalnayak7/mcp-server-redis)** MCP server to interact with Redis Server, AWS Memory DB, etc for caching or other use-cases where in-memory and key-value based storage is appropriate\n- **[RedNote MCP](https://github.com/ifuryst/rednote-mcp)** - MCP server for accessing RedNote(XiaoHongShu, xhs) content\n- **[Reed Jobs](https://github.com/kld3v/reed_jobs_mcp)** - Search and retrieve job listings from Reed.co.uk.\n- **[Rememberizer AI](https://github.com/skydeckai/mcp-server-rememberizer)** - An MCP server designed for interacting with the Rememberizer data source, facilitating enhanced knowledge retrieval.\n- **[Replicate](https://github.com/deepfates/mcp-replicate)** - Search, run and manage machine learning models on Replicate through a simple tool-based interface. Browse models, create predictions, track their status, and handle generated images.\n- **[Resend](https://github.com/Klavis-AI/klavis/tree/main/mcp_servers/resend)** - Send email using Resend services\n- **[Revit MCP](https://github.com/revit-mcp)** - A service implementing the MCP protocol for Autodesk Revit.\n- **[Rijksmuseum](https://github.com/r-huijts/rijksmuseum-mcp)** - Interface with the Rijksmuseum API to search artworks, retrieve artwork details, access image tiles, and explore user collections.\n- **[Riot Games](https://github.com/jifrozen0110/mcp-riot)** - MCP server for League of Legends – fetch player info, ranks, champion stats, and match history via Riot API.\n- **[Rohlik](https://github.com/tomaspavlin/rohlik-mcp)** - Shop groceries across the Rohlik Group platforms (Rohlik.cz, Knuspr.de, Gurkerl.at, Kifli.hu, Sezamo.ro)\n- **[Rquest](https://github.com/xxxbrian/mcp-rquest)** - An MCP server providing realistic browser-like HTTP request capabilities with accurate TLS/JA3/JA4 fingerprints for bypassing anti-bot measures.\n- **[Rust MCP Filesystem](https://github.com/rust-mcp-stack/rust-mcp-filesystem)** - Fast, asynchronous MCP server for efficient handling of various filesystem operations built with the power of Rust.\n- **[SafetySearch](https://github.com/surabhya/SafetySearch)** - Real-time FDA food safety data: recalls, adverse events, analysis.\n- **[Salesforce MCP](https://github.com/smn2gnt/MCP-Salesforce)** - Interact with Salesforce Data and Metadata\n- **[Salesforce MCP (AiondaDotCom)](https://github.com/AiondaDotCom/mcp-salesforce)** - Universal Salesforce integration with OAuth authentication, smart learning system, comprehensive backup capabilities, and full CRUD operations for any Salesforce org including custom objects and fields.\n- **[Salesforce MCP Server](https://github.com/tsmztech/mcp-server-salesforce)** - Comprehensive Salesforce integration with tools for querying records, executing Apex, managing fields/objects, and handling debug logs\n- **[Scanova MCP Server](https://github.com/trycon/scanova-mcp)** - MCP server for creating and managing QR codes using the [Scanova](https://scanova.io) API. Provides tools for generating, managing, and downloading QR codes.\n- **[SchemaCrawler](https://github.com/schemacrawler/SchemaCrawler-MCP-Server-Usage)** - Connect to any relational database, and be able to get valid SQL, and ask questions like what does a certain column prefix mean.\n- **[SchemaFlow](https://github.com/CryptoRadi/schemaflow-mcp-server)** - Real-time PostgreSQL & Supabase database schema access for AI-IDEs via Model Context Protocol. Provides live database context through secure SSE connections with three powerful tools: get_schema, analyze_database, and check_schema_alignment. [SchemaFlow](https://schemaflow.dev)\n- **[Scholarly](https://github.com/adityak74/mcp-scholarly)** - An MCP server to search for scholarly and academic articles.\n- **[scrapling-fetch](https://github.com/cyberchitta/scrapling-fetch-mcp)** - Access text content from bot-protected websites. Fetches HTML/markdown from sites with anti-automation measures using Scrapling.\n- **[Screeny](https://github.com/rohanrav/screeny)** - Privacy-first macOS MCP server that provides visual context for AI agents through window screenshots\n- **[ScriptFlow](https://github.com/yanmxa/scriptflow-mcp)** - Transform complex, repetitive AI interactions into persistent, executable scripts with comprehensive script management (add, edit, remove, list, search, execute) and multi-language support (Bash, Python, Node.js, TypeScript).\n- **[SearXNG](https://github.com/ihor-sokoliuk/mcp-searxng)** - A Model Context Protocol Server for [SearXNG](https://docs.searxng.org)\n- **[SearXNG](https://github.com/erhwenkuo/mcp-searxng)** - An MCP server provide web searching via [SearXNG](https://docs.searxng.org) & retrieve url as makrdown.\n- **[SearXNG Public](https://github.com/pwilkin/mcp-searxng-public)** - A Model Context Protocol Server for retrieving data from public [SearXNG](https://docs.searxng.org) instances, with fallback support\n- **[SEC EDGAR](https://github.com/stefanoamorelli/sec-edgar-mcp)** - (by Stefano Amorelli) A community Model Context Protocol Server to access financial filings and data through the U.S. Securities and Exchange Commission ([SEC](https://www.sec.gov/)) `Electronic Data Gathering, Analysis, and Retrieval` ([EDGAR](https://www.sec.gov/submit-filings/about-edgar)) database\n- **[SEO MCP](https://github.com/cnych/seo-mcp)** - A free SEO tool MCP (Model Control Protocol) service based on Ahrefs data. Includes features such as backlinks, keyword ideas, and more. by [claudemcp](https://www.claudemcp.com/servers/seo-mcp).\n- **[Serper](https://github.com/garylab/serper-mcp-server)** - An MCP server that performs Google searches using [Serper](https://serper.dev).\n- **[ServiceNow](https://github.com/osomai/servicenow-mcp)** - An MCP server to interact with a ServiceNow instance\n- **[ShaderToy](https://github.com/wilsonchenghy/ShaderToy-MCP)** - This MCP server lets LLMs to interact with the ShaderToy API, allowing LLMs to learn from compute shaders examples and enabling them to create complex GLSL shaders that they are previously not capable of.\n- **[ShareSeer](https://github.com/shareseer/shareseer-mcp-server)** - MCP to Access SEC filings, financials & insider trading data in real time using [ShareSeer](https://shareseer.com)\n- **[Shell](https://github.com/sonirico/mcp-shell)** - Give hands to AI. MCP server to run shell commands securely, auditably, and on demand\n- **[Shodan MCP](https://github.com/Hexix23/shodan-mcp)** - MCP server to interact with [Shodan](https://www.shodan.io/)\n- **[Shopify](https://github.com/GeLi2001/shopify-mcp)** - MCP to interact with Shopify API including order, product, customers and so on.\n- **[Shopify Storefront](https://github.com/QuentinCody/shopify-storefront-mcp-server)** - Unofficial MCP server that allows AI agents to discover Shopify storefronts and interact with them to fetch products, collections, and other store data through the Storefront API.\n- **[Simple Loki MCP](https://github.com/ghrud92/simple-loki-mcp)** - A simple MCP server to query Loki logs using logcli.\n- **[Siri Shortcuts](https://github.com/dvcrn/mcp-server-siri-shortcuts)** - MCP to interact with Siri Shortcuts on macOS. Exposes all Shortcuts as MCP tools.\n- **[Skyvern](https://github.com/Skyvern-AI/skyvern/tree/main/integrations/mcp)** - MCP to let Claude / Windsurf / Cursor / your LLM control the browser\n- **[Slack](https://github.com/korotovsky/slack-mcp-server)** - The most powerful MCP server for Slack Workspaces. This integration supports both Stdio and SSE transports, proxy settings and does not require any permissions or bots being created or approved by Workspace admins 😏.\n- **[Slack](https://github.com/zencoderai/slack-mcp-server)** - Slack MCP server which supports both stdio and Streamable HTTP transports. Extended from the original Anthropic's implementation which is now [archived](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/slack)\n- **[Slidespeak](https://github.com/SlideSpeak/slidespeak-mcp)** - Create PowerPoint presentations using the [Slidespeak](https://slidespeak.com/) API.\n- **[Smartlead](https://github.com/jean-technologies/smartlead-mcp-server-local)** - MCP to connect to Smartlead. Additional, tooling, functionality, and connection to workflow automation platforms also available.\n- **[Snowflake](https://github.com/Snowflake-Labs/mcp)** - Open-source MCP server for Snowflake from official Snowflake-Labs supports prompting Cortex Agents, querying structured & unstructured data, object management, SQL execution, semantic view querying, and more. RBAC, fine-grained CRUD controls, and all authentication methods supported.\n- **[Snowflake](https://github.com/isaacwasserman/mcp-snowflake-server)** - This MCP server enables LLMs to interact with Snowflake databases, allowing for secure and controlled data operations.\n- **[Snowflake Cortex MCP Server](https://github.com/thisisbhanuj/Snowflake-Cortex-MCP-Server)** -This Snowflake MCP server provides tooling for Snowflake Cortex AI features, bringing these capabilities to the MCP ecosystem. When connected to an MCP Client (e.g. Claude for Desktop, fast-agent, Agentic Orchestration Framework), users can leverage these Cortex AI features.\n- **[SoccerDataAPI](https://github.com/yeonupark/mcp-soccer-data)** - This MCP server provides real-time football match data based on the SoccerDataAPI.\n- **[Solana Agent Kit](https://github.com/sendaifun/solana-agent-kit/tree/main/examples/agent-kit-mcp-server)** - This MCP server enables LLMs to interact with the Solana blockchain with help of Solana Agent Kit by SendAI, allowing for 40+ protocol actions and growing\n- **[Solr MCP](https://github.com/mjochum64/mcp-solr-search)** - This MCP server offers a basic functionality to perform a search on Solr servers.\n- **[Solver](https://github.com/szeider/mcp-solver)** - Solves constraint satisfaction and optimization problems .\n- **[Solvitor](https://github.com/Adeptus-Innovatio/solvitor-mcp)** – Solvitor MCP server provides tools to access reverse engineering tools that help developers extract IDL files from closed - source Solana smart contracts and decompile them.\n- **[Sourcerer](https://github.com/st3v3nmw/sourcerer-mcp)** - MCP for semantic code search & navigation that reduces token waste.\n- **[Specbridge](https://github.com/TBosak/specbridge)** - Easily turn your OpenAPI specs into MCP Tools.\n- **[Splunk](https://github.com/jkosik/mcp-server-splunk)** - Golang MCP server for Splunk (lists saved searches, alerts, indexes, macros...). Supports SSE and STDIO.\n- **[Spotify](https://github.com/varunneal/spotify-mcp)** - This MCP allows an LLM to play and use Spotify.\n- **[Spring Initializr](https://github.com/hpalma/springinitializr-mcp)** - This MCP allows an LLM to create Spring Boot projects with custom configurations. Instead of manually visiting start.spring.io, you can now ask your AI assistant to generate projects with specific dependencies, Java versions, and project structures.\n- **[Squad AI](https://github.com/the-basilisk-ai/squad-mcp)** – Product‑discovery and strategy platform integration. Create, query and update opportunities, solutions, outcomes, requirements and feedback from any MCP‑aware LLM.\n- **[SSH](https://github.com/AiondaDotCom/mcp-ssh)** - Agent for managing and controlling SSH connections.\n- **[SSH](https://github.com/classfang/ssh-mcp-server)** - An MCP server that can execute SSH commands remotely, upload files, download files, and so on.\n- **[SSH MCP Server](https://github.com/sinjab/mcp_ssh)** - A production-ready Model Context Protocol server for SSH automation with background execution, file transfers, and comprehensive timeout protection. Features structured output, progress tracking, and enterprise-grade testing (87% coverage).\n- **[sslmon](https://github.com/firesh/sslmon-mcp)** - Domain/HTTPS/SSL domain registration information and SSL certificate monitoring capabilities. Query domain registration and expiration information, and SSL certificate information and validity status for any domain.\n- **[Standard Korean Dictionary](https://github.com/privetin/stdict)** - Search the dictionary using API\n- **[Star Wars](https://github.com/johnpapa/mcp-starwars)** -MCP Server for the SWAPI Star Wars API. The main goal of the project is to show how an MCP server can be used to interact with APIs.\n- **[Starknet MCP Server](https://github.com/mcpdotdirect/starknet-mcp-server)** - A comprehensive MCP server for interacting with the Starknet blockchain, providing tools for querying blockchain data, resolving StarknetIDs, and performing token transfers.\n- **[Starwind UI](https://github.com/Boston343/starwind-ui-mcp/)** - This MCP provides relevant commands, documentation, and other information to allow LLMs to take full advantage of Starwind UI's open source Astro components.\n- **[Stellar](https://github.com/syronlabs/stellar-mcp/)** - This MCP server enables LLMs to interact with the Stellar blockchain to create accounts, check address balances, analyze transactions, view transaction history, mint new assets, interact with smart contracts and much more.\n- **[Stitch AI](https://github.com/StitchAI/stitch-ai-mcp/)** - Knowledge management system for AI agents with memory space creation and retrieval capabilities.\n- **[Stockfish](https://github.com/sonirico/mcp-stockfish)** - MCP server connecting AI systems to Stockfish chess engine\n- **[Storybook](https://github.com/stefanoamorelli/storybook-mcp-server)** (by Stefano Amorelli) - Interact with Storybook component libraries, enabling component discovery, story management, prop inspection, and visual testing across different viewports.\n- **[Strava](https://github.com/r-huijts/strava-mcp)** - Connect to the Strava API to access activity data, athlete profiles, segments, and routes, enabling fitness tracking and analysis with Claude.\n- **[Strava API](https://github.com/tomekkorbak/strava-mcp-server)** - MCP server for Strava API to retrieve one's activities\n- **[Stripe](https://github.com/atharvagupta2003/mcp-stripe)** - This MCP allows integration with Stripe for handling payments, customers, and refunds.\n- **[Substack/Medium](https://github.com/jonathan-politzki/mcp-writer-substack)** - Connect Claude to your Substack/Medium writing, enabling semantic search and analysis of your published content.\n- **[System Health](https://github.com/thanhtung0201/mcp-remote-system-health)** - The MCP (Multi-Channel Protocol) System Health Monitoring is a robust, real-time monitoring solution designed to provide comprehensive health metrics and alerts for remote Linux servers.\n- **[SystemSage](https://github.com/Tarusharma1/SystemSage)** - A powerful, cross-platform system management and monitoring tool for Windows, Linux, and macOS.\n- **[Talk To Figma](https://github.com/sonnylazuardi/cursor-talk-to-figma-mcp)** - This MCP server enables LLMs to interact with Figma, allowing them to read and modify designs programmatically.\n- **[Talk To Figma via Claude](https://github.com/gaganmanku96/talk-with-figma-claude)** - TMCP server that provides seamless Figma integration specifically for Claude Desktop, enabling design creation, modification, and real-time collaboration through natural language commands.\n- **[TAM MCP Server](https://github.com/gvaibhav/TAM-MCP-Server)** - Market research and business intelligence with TAM/SAM calculations and integration across 8 economic data sources: Alpha Vantage, BLS, Census Bureau, FRED, IMF, Nasdaq Data Link, OECD, and World Bank.\n- **[Tasks](https://github.com/flesler/mcp-tasks)** - An efficient task manager. Designed to minimize tool confusion and maximize LLM budget efficiency while providing powerful search, filtering, and organization capabilities across multiple file formats (Markdown, JSON, YAML)\n- **[Tavily search](https://github.com/RamXX/mcp-tavily)** - An MCP server for Tavily's search & news API, with explicit site inclusions/exclusions\n- **[TcpSocketMCP](https://github.com/SpaceyKasey/TcpSocketMCP/)** - A Model Context Protocol (MCP) server that provides raw TCP socket access, enabling AI models to interact directly with network services using raw TCP Sockets. Supports multiple concurrent connections, buffering of response data and triggering automatic responses.\n- **[TeamRetro](https://github.com/adepanges/teamretro-mcp-server)** - This MCP server allows LLMs to interact with TeamRetro, allowing LLMs to manage user, team, team member, retrospective, health check, action, agreement and fetch the reports.\n- **[Telegram](https://github.com/chigwell/telegram-mcp)** - An MCP server that provides paginated chat reading, message retrieval, and message sending capabilities for Telegram through Telethon integration.\n- **[Telegram-Client](https://github.com/chaindead/telegram-mcp)** - A Telegram API bridge that manages user data, dialogs, messages, drafts, read status, and more for seamless interactions.\n- **[Telegram-mcp-server](https://github.com/DLHellMe/telegram-mcp-server)** - Access Telegram channels and groups directly in Claude. Features dual-mode operation with API access (100x faster) or web scraping, unlimited post retrieval, and search functionality.\n- **[Template MCP Server](https://github.com/mcpdotdirect/template-mcp-server)** - A CLI tool to create a new Model Context Protocol server project with TypeScript support, dual transport options, and an extensible structure\n- **[Tempo](https://github.com/scottlepp/tempo-mcp-server)** - An MCP server to query traces/spans from [Grafana Tempo](https://github.com/grafana/tempo).\n- **[Teradata](https://github.com/arturborycki/mcp-teradata)** - his MCP server enables LLMs to interact with Teradata databases. This MCP Server support tools and prompts for multi task data analytics\n- **[Terminal-Control](https://github.com/GongRzhe/terminal-controller-mcp)** - An MCP server that enables secure terminal command execution, directory navigation, and file system operations through a standardized interface.\n- **[Terraform-Cloud](https://github.com/severity1/terraform-cloud-mcp)** - An MCP server that integrates AI assistants with the Terraform Cloud API, allowing you to manage your infrastructure through natural conversation.\n- **[Tideways](https://github.com/abuhamza/tideways-mcp-server)** - A Model Context Protocol server that enables AI assistants to query Tideways performance monitoring data and provide conversational performance insights for PHP applications.\n- **[TFT-Match-Analyzer](https://github.com/GeLi2001/tft-mcp-server)** - MCP server for teamfight tactics match history & match details fetching, providing user the detailed context for every match.\n- **[Thales CDSP CAKM MCP Server](https://github.com/sanyambassi/thales-cdsp-cakm-mcp-server)** - An MCP server for the Thales CipherTrust Data Security Platform (CDSP) Cloud Key Management (CAKM) connector. This MCP server supports Ms SQL and Oracle databases.\n- **[Thales CDSP CRDP MCP Server](https://github.com/sanyambassi/thales-cdsp-crdp-mcp-server)** - A Model Context Protocol (MCP) server that allows interacting with the CipherTrust RestFul Data Protection (CRDP) data protection service.\n- **[Thales CipherTrust Manager MCP Server](https://github.com/sanyambassi/ciphertrust-manager-mcp-server)** - MCP server for Thales CipherTrust Manager integration, enabling secure key management and cryptographic operations.\n- **[thegraph-mcp](https://github.com/kukapay/thegraph-mcp)** - An MCP server that powers AI agents with indexed blockchain data from The Graph.\n- **[TheHive MCP Server](https://github.com/redwaysecurity/the-hive-mcp-server)** - An MCP server for [TheHive](https://strangebee.com/thehive/) Security Incident Response Platform.\n- **[Things3 MCP](https://github.com/urbanogardun/things3-mcp)** - Things3 task management integration for macOS with comprehensive TODO, project, and tag management.\n- **[Think MCP](https://github.com/Rai220/think-mcp)** - Enhances any agent's reasoning capabilities by integrating the think-tools, as described in [Anthropic's article](https://www.anthropic.com/engineering/claude-think-tool).\n- **[Think Node MCP](https://github.com/abhinav-mangla/think-tool-mcp)** - Enhances any agent's reasoning capabilities by integrating the think-tools, as described in [Anthropic's article](https://www.anthropic.com/engineering/claude-think-tool). (Works with Node)\n- **[Ticketmaster](https://github.com/delorenj/mcp-server-ticketmaster)** - Search for events, venues, and attractions through the Ticketmaster Discovery API\n- **[Ticketmaster MCP Server](https://github.com/mochow13/ticketmaster-mcp-server)** - A Model Context Protocol (MCP) server implemented in Streamable HTTP transport that allows AI models to interact with the Ticketmaster Discovery API, enabling searching events, venues, and attractions.\n- **[TickTick](https://github.com/alexarevalo9/ticktick-mcp-server)** - A Model Context Protocol (MCP) server designed to integrate with the TickTick task management platform, enabling intelligent context-aware task operations and automation.\n- **[TigerGraph](https://github.com/custom-discoveries/TigerGraph_MCP)** - A community built MCP server that interacts with TigerGraph Graph Database.\n- **[tip.md](https://github.com/tipdotmd#-mcp-server-for-ai-assistants)** - An MCP server that enables AI assistants to interact with tip.md's crypto tipping functionality, allowing agents or supporters to tip registered developers directly from AI chat interfaces.\n- **[TMD Earthquake](https://github.com/amornpan/tmd-earthquake-server-1.0)** - 🌍 Real-time earthquake monitoring from Thai Meteorological Department. Features magnitude filtering, location-based search (Thai/English), today's events tracking, dangerous earthquake alerts, and comprehensive statistics. Covers regional and global seismic activities.\n- **[TMDB](https://github.com/Laksh-star/mcp-server-tmdb)** - This MCP server integrates with The Movie Database (TMDB) API to provide movie information, search capabilities, and recommendations.\n- **[Todoist](https://github.com/abhiz123/todoist-mcp-server)** - Interact with Todoist to manage your tasks.\n- **[Todos](https://github.com/tomelliot/todos-mcp)** - A practical todo list manager to use with your favourite chatbot.\n- **[token-minter-mcp](https://github.com/kukapay/token-minter-mcp)** - An MCP server providing tools for AI agents to mint ERC-20 tokens across multiple blockchains.\n- **[token-revoke-mcp](https://github.com/kukapay/token-revoke-mcp)** - An MCP server for checking and revoking ERC-20 token allowances across multiple blockchains.\n- **[Ton Blockchain MCP](https://github.com/devonmojito/ton-blockchain-mcp)** - An MCP server for interacting with Ton Blockchain.\n- **[TouchDesigner](https://github.com/8beeeaaat/touchdesigner-mcp)** - An MCP server for TouchDesigner, enabling interaction with TouchDesigner projects, nodes, and parameters.\n- **[Transcribe](https://github.com/transcribe-app/mcp-transcribe)** - An MCP server provides fast and reliable transcriptions for audio/video files and voice memos. It allows LLMs to interact with the text content of audio/video file.\n- **[Travel Planner](https://github.com/GongRzhe/TRAVEL-PLANNER-MCP-Server)** - Travel planning and itinerary management server integrating with Google Maps API for location search, place details, and route calculations.\n- **[Trello MCP Server](https://github.com/lioarce01/trello-mcp-server)** - An MCP server that interact with user Trello boards, modifying them with prompting.\n- **[Trino](https://github.com/tuannvm/mcp-trino)** - A high-performance Model Context Protocol (MCP) server for Trino implemented in Go.\n- **[Tripadvisor](https://github.com/pab1it0/tripadvisor-mcp)** - An MCP server that enables LLMs to interact with Tripadvisor API, supporting location data, reviews, and photos through standardized MCP interfaces\n- **[Triplyfy MCP](https://github.com/helpful-AIs/triplyfy-mcp)** - An MCP server that lets LLMs plan and manage itineraries with interactive maps in Triplyfy; manage itineraries, places and notes, and search/save flights.\n- **[TrueNAS Core MCP](https://github.com/vespo92/TrueNasCoreMCP)** - An MCP server for interacting with TrueNAS Core.\n- **[TuriX Computer Automation MCP](https://github.com/TurixAI/TuriX-CUA/tree/mac_mcp)** - MCP server for helping automation control your computer complete your pre-setting task.\n- **[Tyk API Management](https://github.com/TykTechnologies/tyk-dashboard-mcp)** - Chat with all of your organization's managed APIs and perform other API lifecycle operations, managing tokens, users, analytics, and more.\n- **[Typesense](https://github.com/suhail-ak-s/mcp-typesense-server)** - A Model Context Protocol (MCP) server implementation that provides AI models with access to Typesense search capabilities. This server enables LLMs to discover, search, and analyze data stored in Typesense collections.\n- **[UniFi Dream Machine](https://github.com/sabler/mcp-unifi)** An MCP server that gets your network telemetry from the UniFi Site Manager and your local UniFi router.\n- **[UniProt](https://github.com/QuentinCody/uniprot-mcp-server)** - Unofficial MCP server for UniProt, providing access to protein sequence data, functional annotations, taxonomic information, and cross-references for proteomics and bioinformatics research.\n- **[uniswap-poolspy-mcp](https://github.com/kukapay/uniswap-poolspy-mcp)** - An MCP server that tracks newly created liquidity pools on Uniswap across nine blockchain networks.\n- **[uniswap-trader-mcp](https://github.com/kukapay/uniswap-trader-mcp)** -An MCP server for AI agents to automate token swaps on Uniswap DEX across multiple blockchains.\n- **[Unity Catalog](https://github.com/ognis1205/mcp-server-unitycatalog)** - An MCP server that enables LLMs to interact with Unity Catalog AI, supporting CRUD operations on Unity Catalog Functions and executing them as MCP tools.\n- **[Unity Integration (Advanced)](https://github.com/quazaai/UnityMCPIntegration)** - Advanced Unity3d Game Engine MCP which supports ,Execution of Any Editor Related Code Directly Inside of Unity, Fetch Logs, Get Editor State and Allow File Access of the Project making it much more useful in Script Editing or asset creation.\n- **[Unity3d Game Engine](https://github.com/CoderGamester/mcp-unity)** - An MCP server that enables LLMs to interact with Unity3d Game Engine, supporting access to a variety of the Unit's Editor engine tools (e.g. Console Logs, Test Runner logs, Editor functions, hierarchy state, etc) and executing them as MCP tools or gather them as resources.\n- **[Universal MCP Servers](https://github.com/universal-mcp)** - A collection of MCP servers created using the [AgentR Universal MCP SDK](https://github.com/universal-mcp/universal-mcp).\n- **[Unleash Integration (Feature Toggle)](https://github.com/cuongtl1992/unleash-mcp)** - A Model Context Protocol (MCP) server implementation that integrates with Unleash Feature Toggle system. Provide a bridge between LLM applications and Unleash feature flag system\n- **[Upbit MCP Server](https://github.com/solangii/upbit-mcp-server)** – An MCP server that enables real - time access to cryptocurrency prices, market summaries, and asset listings from the Upbit exchange.\n- **[use_aws_mcp](https://github.com/runjivu/use_aws_mcp)** - amazon-q-cli's use_aws tool extracted into independent mcp, for general aws api usage.\n- **[User Feedback](https://github.com/mrexodia/user-feedback-mcp)** - Simple MCP Server to enable a human-in-the-loop workflow in tools like Cline and Cursor.\n- **[USPTO](https://github.com/riemannzeta/patent_mcp_server)** - MCP server for accessing United States Patent & Trademark Office data through its Open Data Protocol (ODP) API.\n- **[Vectara](https://github.com/vectara/vectara-mcp)** - Query Vectara's trusted RAG-as-a-service platform.\n- **[Vega-Lite](https://github.com/isaacwasserman/mcp-vegalite-server)** - Generate visualizations from fetched data using the VegaLite format and renderer.\n- **[Vertica](https://github.com/nolleh/mcp-vertica)** - Vertica database integration in Python with configurable access controls and schema inspection\n- **[Vibe Check](https://github.com/PV-Bhat/vibe-check-mcp-server)** - An MCP server leveraging an external oversight layer to \"vibe check\" agents, and also self-improve accuracy & user alignment over time. Prevents scope creep, code bloat, misalignment, misinterpretation, tunnel vision, and overcomplication.\n- **[Video Editor](https://github.com/burningion/video-editing-mcp)** - A Model Context Protocol Server to add, edit, and search videos with [Video Jungle](https://www.video-jungle.com/).\n- **[Video Still Capture](https://github.com/13rac1/videocapture-mcp)** - 📷 Capture video stills from an OpenCV-compatible webcam or other video source.\n- **[Virtual location (Google Street View,etc.)](https://github.com/mfukushim/map-traveler-mcp)** - Integrates Google Map, Google Street View, PixAI, Stability.ai, ComfyUI API and Bluesky to provide a virtual location simulation in LLM (written in Effect.ts)\n- **[VMware Fusion](https://github.com/yeahdongcn/vmware-fusion-mcp-server)** - Manage VMware Fusion virtual machines via the Fusion REST API.\n- **[VoiceMode](https://github.com/mbailey/voicemode)** - Enable voice conversations with Claude using any OpenAI-compatible STT/TTS service [getvoicemode.com](https://getvoicemode.com/)\n- **[Voice Status Report](https://github.com/tomekkorbak/voice-status-report-mcp-server)** - An MCP server that provides voice status updates using OpenAI's text-to-speech API, to be used with Cursor or Claude Code.\n- **[VolcEngine TOS](https://github.com/dinghuazhou/sample-mcp-server-tos)** - A sample MCP server for VolcEngine TOS that flexibly get objects from TOS.\n- **[Voyp](https://github.com/paulotaylor/voyp-mcp)** - VOYP MCP server for making calls using Artificial Intelligence.\n- **[vulnicheck](https://github.com/andrasfe/vulnicheck)** - Real-time Python package vulnerability scanner that checks dependencies against OSV and NVD databases, providing comprehensive security analysis with CVE details, lock file support, and actionable upgrade recommendations.\n- **[Wanaku MCP Router](https://github.com/wanaku-ai/wanaku/)** - The Wanaku MCP Router is a SSE-based MCP server that provides an extensible routing engine that allows integrating your enterprise systems with AI agents.\n- **[weather-mcp-server](https://github.com/devilcoder01/weather-mcp-server)** - Get real-time weather data for any location using weatherapi.\n- **[Web Search MCP](https://github.com/mrkrsl/web-search-mcp)** - A server that provides full web search, summaries and page extration for use with Local LLMs.\n- **[Webex](https://github.com/Kashyap-AI-ML-Solutions/webex-messaging-mcp-server)** - A Model Context Protocol (MCP) server that provides AI assistants with comprehensive access to Cisco Webex messaging capabilities.\n- **[Webflow](https://github.com/kapilduraphe/webflow-mcp-server)** - Interact with the Webflow APIs\n- **[webhook-mcp](https://github.com/noobnooc/webhook-mcp)** (by Nooc) - A Model Context Protocol (MCP) server that sends webhook notifications when called.\n- **[whale-tracker-mcp](https://github.com/kukapay/whale-tracker-mcp)**  -  A mcp server for tracking cryptocurrency whale transactions.\n- **[WhatsApp MCP Server](https://github.com/lharries/whatsapp-mcp)** - MCP server for your personal WhatsApp handling individuals, groups, searching and sending.\n- **[Whois MCP](https://github.com/bharathvaj-ganesan/whois-mcp)** - MCP server that performs whois lookup against domain, IP, ASN and TLD.\n- **[Wikidata MCP](https://github.com/zzaebok/mcp-wikidata)** - Wikidata MCP server that interact with Wikidata, by searching identifiers, extracting metadata, and executing sparql query.\n- **[Wikidata SPARQL](https://github.com/QuentinCody/wikidata-sparql-mcp-server)** - Unofficial REMOTE MCP server for Wikidata's SPARQL endpoint, providing access to structured knowledge data, entity relationships, and semantic queries for research and data analysis.\n- **[Wikifunctions](https://github.com/Fredibau/wikifunctions-mcp-fredibau)** - Allowing AI models to discover and execute functions from the WikiFunctions library.\n- **[Wikipedia MCP](https://github.com/Rudra-ravi/wikipedia-mcp)** - Access and search Wikipedia articles via MCP for AI-powered information retrieval.\n- **[WildFly MCP](https://github.com/wildfly-extras/wildfly-mcp)** - WildFly MCP server that enables LLM to interact with running WildFly servers (retrieve metrics, logs, invoke operations, ...).\n- **[Windows CLI](https://github.com/SimonB97/win-cli-mcp-server)** - MCP server for secure command-line interactions on Windows systems, enabling controlled access to PowerShell, CMD, and Git Bash shells.\n- **[Windsor](https://github.com/windsor-ai/windsor_mcp)** - Windsor MCP (Model Context Protocol) enables your LLM to query, explore, and analyze your full-stack business data integrated into Windsor.ai with zero SQL writing or custom scripting.\n- **[Wordle MCP](https://github.com/cr2007/mcp-wordle-python)** - MCP Server that gets the Wordle Solution for a particular date.\n- **[WordPress MCP](https://github.com/Automattic/wordpress-mcp)** - Make your WordPress site into a simple MCP server, exposing functionality to LLMs and AI agents.\n- **[Workflowy](https://github.com/danield137/mcp-workflowy)** - A server that interacts with [workflowy](https://workflowy.com/).\n- **[World Bank data API](https://github.com/anshumax/world_bank_mcp_server)** - A server that fetches data indicators available with the World Bank as part of their data API\n- **[Wren Engine](https://github.com/Canner/wren-engine)** - The Semantic Engine for Model Context Protocol(MCP) Clients and AI Agents\n- **[X (Twitter)](https://github.com/EnesCinr/twitter-mcp)** (by EnesCinr) - Interact with twitter API. Post tweets and search for tweets by query.\n- **[X (Twitter)](https://github.com/vidhupv/x-mcp)** (by vidhupv) - Create, manage and publish X/Twitter posts directly through Claude chat.\n- **[Xcode](https://github.com/r-huijts/xcode-mcp-server)** - MCP server that brings AI to your Xcode projects, enabling intelligent code assistance, file operations, project management, and automated development tasks.\n- **[Xcode-mcp-server](https://github.com/drewster99/xcode-mcp-server)** (by drewster99) - Best Xcode integration - ClaudeCode and Cursor can build your project *with* Xcode and see the same errors you do. Fast easy setup.\n- **[xcodebuild](https://github.com/ShenghaiWang/xcodebuild)**  - 🍎 Build iOS Xcode workspace/project and feed back errors to llm.\n- **[Xero-mcp-server](https://github.com/john-zhang-dev/xero-mcp)** - Enabling clients to interact with Xero system for streamlined accounting, invoicing, and business operations.\n- **[XiYan](https://github.com/XGenerationLab/xiyan_mcp_server)** - 🗄️ An MCP server that supports fetching data from a database using natural language queries, powered by XiyanSQL as the text-to-SQL LLM.\n- **[XMind](https://github.com/apeyroux/mcp-xmind)** - Read and search through your XMind directory containing XMind files.\n- **[Yahoo Finance](https://github.com/AgentX-ai/yahoo-finance-server)** - 📈 Lets your AI interact with Yahoo Finance to get comprehensive stock market data, news, financials, and more. Proxy supported.\n- **[yfinance](https://github.com/Adity-star/mcp-yfinance-server)** -💹The MCP YFinance Stock Server provides real-time and historical stock data in a standard format, powering dashboards, AI agents,and research tools with seamless financial insights.\n- **[YNAB](https://github.com/ChuckBryan/ynabmcpserver)** - A Model Context Protocol (MCP) server for integrating with YNAB (You Need A Budget), allowing AI assistants to securely access and analyze your financial data.\n- **[YouTrack](https://github.com/tonyzorin/youtrack-mcp)** - A Model Context Protocol (MCP) server implementation for JetBrains YouTrack, allowing AI assistants to interact with YouTrack issue tracking system.\n- **[YouTube](https://github.com/Klavis-AI/klavis/tree/main/mcp_servers/youtube)** - Extract Youtube video information (with proxies support).\n- **[YouTube](https://github.com/ZubeidHendricks/youtube-mcp-server)** - Comprehensive YouTube API integration for video management, Shorts creation, and analytics.\n- **[YouTube DLP](https://github.com/AgentX-ai/youtube-dlp-server)** - Retrieve video information, subtitles, and top comments with proxies.\n- **[YouTube MCP](https://github.com/aardeshir/youtube-mcp)** - Create playlists from song lists with OAuth2. Search videos, manage playlists, let AI curate your YouTube collections.\n- **[Youtube Uploader MCP](https://github.com/anwerj/youtube-uploader-mcp)** - AI‑powered YouTube uploader—no CLI, no YouTube Studio.\n- **[YouTube Video Summarizer](https://github.com/nabid-pf/youtube-video-summarizer-mcp)** - Summarize lengthy youtube videos.\n- **[yutu](https://github.com/eat-pray-ai/yutu)** - A fully functional MCP server and CLI for YouTube to automate YouTube operation.\n- **[ZapCap](https://github.com/bogdan01m/zapcap-mcp-server)** - MCP server for ZapCap API providing video caption and B-roll generation via natural language\n- **[Zettelkasten](https://github.com/joshylchen/zettelkasten)**- Comprehensive AI-powered knowledge management system implementing the Zettelkasten method. Features atomic note creation, full-text search, AI-powered CEQRC workflows (Capture→Explain→Question→Refine→Connect), intelligent link discovery, and multi-interface access (CLI, API, Web UI, MCP). Perfect for researchers, students, and knowledge workers.\n- **[ZincBind](https://github.com/QuentinCody/zincbind-mcp-server)** - Unofficial MCP server for ZincBind, providing access to a comprehensive database of zinc binding sites in proteins, structural coordination data, and metalloproteomics research information.\n- **[Zoom](https://github.com/Prathamesh0901/zoom-mcp-server/tree/main)** - Create, update, read and delete your zoom meetings.\n## 📚 Frameworks\n\nThese are high-level frameworks that make it easier to build MCP servers or clients.\n\n### For servers\n\n* **[Anubis MCP](https://github.com/zoedsoupe/anubis-mcp)** (Elixir) - A high-performance and high-level Model Context Protocol (MCP) implementation in Elixir. Think like \"Live View\" for MCP.\n* **[ModelFetch](https://github.com/phuctm97/modelfetch/)** (TypeScript) - Runtime-agnostic SDK to create and deploy MCP servers anywhere TypeScript/JavaScript runs\n* **[EasyMCP](https://github.com/zcaceres/easy-mcp/)** (TypeScript)\n* **[FastAPI to MCP auto generator](https://github.com/tadata-org/fastapi_mcp)** – A zero-configuration tool for automatically exposing FastAPI endpoints as MCP tools by **[Tadata](https://tadata.com/)**\n* **[FastMCP](https://github.com/punkpeye/fastmcp)** (TypeScript)\n* **[Foobara MCP Connector](https://github.com/foobara/mcp-connector)** - Easily expose Foobara commands written in Ruby as tools via MCP\n* **[Foxy Contexts](https://github.com/strowk/foxy-contexts)** – A library to build MCP servers in Golang by **[strowk](https://github.com/strowk)**\n* **[Higress MCP Server Hosting](https://github.com/alibaba/higress/tree/main/plugins/wasm-go/mcp-servers)** - A solution for hosting MCP Servers by extending the API Gateway (based on Envoy) with wasm plugins.\n* **[MCP Declarative Java SDK](https://github.com/codeboyzhou/mcp-declarative-java-sdk)** Annotation-driven MCP servers development with Java, no Spring Framework Required, minimize dependencies as much as possible.\n* **[MCP-Framework](https://mcp-framework.com)** Build MCP servers with elegance and speed in TypeScript. Comes with a CLI to create your project with `mcp create app`. Get started with your first server in under 5 minutes by **[Alex Andru](https://github.com/QuantGeekDev)**\n* **[MCP Plexus](https://github.com/Super-I-Tech/mcp_plexus)**: A secure, **multi-tenant** and Multi-user MCP python server framework built to integrate easily with external services via OAuth 2.1, offering scalable and robust solutions for managing complex AI applications.\n* **[mcp_sse (Elixir)](https://github.com/kEND/mcp_sse)** An SSE implementation in Elixir for rapidly creating MCP servers.\n* **[mxcp](https://github.com/raw-labs/mxcp)** (Python) - Open-source framework for building enterprise-grade MCP servers using just YAML, SQL, and Python, with built-in auth, monitoring, ETL and policy enforcement.\n* **[Next.js MCP Server Template](https://github.com/vercel-labs/mcp-for-next.js)** (Typescript) - A starter Next.js project that uses the MCP Adapter to allow MCP clients to connect and access resources.\n* **[PayMCP](https://github.com/blustAI/paymcp)** (Python & TypeScript) - Lightweight payments layer for MCP servers: turn tools into paid endpoints with a two-line decorator. [PyPI](https://pypi.org/project/paymcp/) · [npm](https://www.npmjs.com/package/paymcp) · [TS repo](https://github.com/blustAI/paymcp-ts)\n* **[Perl SDK](https://github.com/mojolicious/mojo-mcp)** - An SDK for building MCP servers and clients with the Perl programming language.\n* **[Quarkus MCP Server SDK](https://github.com/quarkiverse/quarkus-mcp-server)** (Java)\n- **[R mcptools](https://github.com/posit-dev/mcptools)** - An R SDK for creating R-based MCP servers and retrieving functionality from third-party MCP servers as R functions.\n* **[SAP ABAP MCP Server SDK](https://github.com/abap-ai/mcp)** - Build SAP ABAP based MCP servers. ABAP 7.52 based with 7.02 downport; runs on R/3 & S/4HANA on-premises, currently not cloud-ready.\n* **[Spring AI MCP Server](https://docs.spring.io/spring-ai/reference/api/mcp/mcp-server-boot-starter-docs.html)** - Provides auto-configuration for setting up an MCP server in Spring Boot applications.\n* **[Template MCP Server](https://github.com/mcpdotdirect/template-mcp-server)** - A CLI tool to create a new Model Context Protocol server project with TypeScript support, dual transport options, and an extensible structure\n* **[AgentR Universal MCP SDK](https://github.com/universal-mcp/universal-mcp)** - A python SDK to build MCP Servers with inbuilt credential management by **[Agentr](https://agentr.dev/home)**\n* **[Vercel MCP Adapter](https://github.com/vercel/mcp-adapter)** (TypeScript) - A simple package to start serving an MCP server on most major JS meta-frameworks including Next, Nuxt, Svelte, and more.\n* **[PHP MCP Server](https://github.com/php-mcp/server)** (PHP) - Core PHP implementation for the Model Context Protocol (MCP) server\n\n### For clients\n\n* **[codemirror-mcp](https://github.com/marimo-team/codemirror-mcp)** - CodeMirror extension that implements the Model Context Protocol (MCP) for resource mentions and prompt commands\n* **[llm-analysis-assistant](https://github.com/xuzexin-hz/llm-analysis-assistant)** <img height=\"12\" width=\"12\" src=\"https://raw.githubusercontent.com/xuzexin-hz/llm-analysis-assistant/refs/heads/main/src/llm_analysis_assistant/pages/html/imgs/favicon.ico\" alt=\"Langfuse Logo\" /> - A very streamlined mcp client that supports calling and monitoring stdio/sse/streamableHttp, and can also view request responses through the /logs page. It also supports monitoring and simulation of ollama/openai interface.\n* **[MCP-Agent](https://github.com/lastmile-ai/mcp-agent)** - A simple, composable framework to build agents using Model Context Protocol by **[LastMile AI](https://www.lastmileai.dev)**\n* **[Spring AI MCP Client](https://docs.spring.io/spring-ai/reference/api/mcp/mcp-client-boot-starter-docs.html)** - Provides auto-configuration for MCP client functionality in Spring Boot applications.\n* **[MCP CLI Client](https://github.com/vincent-pli/mcp-cli-host)** - A CLI host application that enables Large Language Models (LLMs) to interact with external tools through the Model Context Protocol (MCP).\n* **[OpenMCP Client](https://github.com/LSTM-Kirigaya/openmcp-client/)** - An all-in-one vscode/trae/cursor plugin for MCP server debugging. [Document](https://kirigaya.cn/openmcp/) & [OpenMCP SDK](https://kirigaya.cn/openmcp/sdk-tutorial/).\n* **[PHP MCP Client](https://github.com/php-mcp/client)** - Core PHP implementation for the Model Context Protocol (MCP) Client\n\n\n## 📚 Resources\n\nAdditional resources on MCP.\n\n- **[A2A-MCP Java Bridge](https://github.com/vishalmysore/a2ajava)** - A2AJava brings powerful A2A-MCP integration directly into your Java applications. It enables developers to annotate standard Java methods and instantly expose them as MCP Server, A2A-discoverable actions — with no boilerplate or service registration overhead.\n- **[AiMCP](https://www.aimcp.info)** - A collection of MCP clients&servers to find the right mcp tools by **[Hekmon](https://github.com/hekmon8)**\n- **[Awesome Crypto MCP Servers by badkk](https://github.com/badkk/awesome-crypto-mcp-servers)** - A curated list of MCP servers by **[Luke Fan](https://github.com/badkk)**\n- **[Awesome MCP Servers by appcypher](https://github.com/appcypher/awesome-mcp-servers)** - A curated list of MCP servers by **[Stephen Akinyemi](https://github.com/appcypher)**\n- **[Awesome MCP Servers by punkpeye](https://github.com/punkpeye/awesome-mcp-servers)** (**[website](https://glama.ai/mcp/servers)**) - A curated list of MCP servers by **[Frank Fiegel](https://github.com/punkpeye)**\n- **[Awesome MCP Servers by wong2](https://github.com/wong2/awesome-mcp-servers)** (**[website](https://mcpservers.org)**) - A curated list of MCP servers by **[wong2](https://github.com/wong2)**\n- **[Awesome Remote MCP Servers by JAW9C](https://github.com/jaw9c/awesome-remote-mcp-servers)** - A curated list of **remote** MCP servers, including their authentication support by **[JAW9C](https://github.com/jaw9c)**\n- **[Discord Server](https://glama.ai/mcp/discord)** – A community discord server dedicated to MCP by **[Frank Fiegel](https://github.com/punkpeye)**\n- **[Discord Server (ModelContextProtocol)](https://discord.gg/jHEGxQu2a5)** – Connect with developers, share insights, and collaborate on projects in an active Discord community dedicated to the Model Context Protocol by **[Alex Andru](https://github.com/QuantGeekDev)**\n- <img height=\"12\" width=\"12\" src=\"https://raw.githubusercontent.com/klavis-ai/klavis/main/static/klavis-ai.png\" alt=\"Klavis Logo\" /> **[Klavis AI](https://www.klavis.ai)** - Open Source MCP Infra. Hosted MCP servers and MCP clients on Slack and Discord.\n- **[MCP Badges](https://github.com/mcpx-dev/mcp-badges)** – Quickly highlight your MCP project with clear, eye-catching badges, by **[Ironben](https://github.com/nanbingxyz)**\n- **[MCPRepository.com](https://mcprepository.com/)** - A repository that indexes and organizes all MCP servers for easy discovery.\n- **[mcp-cli](https://github.com/wong2/mcp-cli)** - A CLI inspector for the Model Context Protocol by **[wong2](https://github.com/wong2)**\n- **[mcp-dockmaster](https://mcp-dockmaster.com)** - An Open-Sourced UI to install and manage MCP servers for Windows, Linux and macOS.\n- **[mcp-get](https://mcp-get.com)** - Command line tool for installing and managing MCP servers by **[Michael Latman](https://github.com/michaellatman)**\n- **[mcp-guardian](https://github.com/eqtylab/mcp-guardian)** - GUI application + tools for proxying / managing control of MCP servers by **[EQTY Lab](https://eqtylab.io)**\n- **[MCP Linker](https://github.com/milisp/mcp-linker)** - A cross-platform Tauri GUI tool for one-click setup and management of MCP servers, supporting Claude Desktop, Cursor, Windsurf, VS Code, Cline, and Neovim.\n- **[mcp-manager](https://github.com/zueai/mcp-manager)** - Simple Web UI to install and manage MCP servers for Claude Desktop by **[Zue](https://github.com/zueai)**\n- **[MCP Marketplace Web Plugin](https://github.com/AI-Agent-Hub/mcp-marketplace)** MCP Marketplace is a small Web UX plugin to integrate with AI applications, Support various MCP Server API Endpoint (e.g pulsemcp.com/deepnlp.org and more). Allowing user to browse, paginate and select various MCP servers by different categories. [Pypi](https://pypi.org/project/mcp-marketplace) | [Maintainer](https://github.com/AI-Agent-Hub) | [Website](http://www.deepnlp.org/store/ai-agent/mcp-server)\n- **[mcp.natoma.ai](https://mcp.natoma.ai)** – A Hosted MCP Platform to discover, install, manage and deploy MCP servers by **[Natoma Labs](https://www.natoma.ai)**\n- **[mcp.run](https://mcp.run)** - A hosted registry and control plane to install & run secure + portable MCP Servers.\n- **[MCPHub](https://www.mcphub.com)** - Website to list high quality MCP servers and reviews by real users. Also provide online chatbot for popular LLM models with MCP server support.\n- **[MCP Router](https://mcp-router.net)** – Free Windows and macOS app that simplifies MCP management while providing seamless app authentication and powerful log visualization by **[MCP Router](https://github.com/mcp-router/mcp-router)**\n- **[MCP Servers Hub](https://github.com/apappascs/mcp-servers-hub)** (**[website](https://mcp-servers-hub-website.pages.dev/)**) - A curated list of MCP servers by **[apappascs](https://github.com/apappascs)**\n- **[MCPServers.com](https://mcpservers.com)** - A growing directory of high-quality MCP servers with clear setup guides for a variety of MCP clients. Built by the team behind the **[Highlight MCP client](https://highlightai.com/)**\n- **[MCP Servers Rating and User Reviews](http://www.deepnlp.org/store/ai-agent/mcp-server)** - Website to rate MCP servers, write authentic user reviews, and [search engine for agent & mcp](http://www.deepnlp.org/search/agent)\n- **[MCP Sky](https://bsky.app/profile/brianell.in/feed/mcp)** - Bluesky feed for MCP related news and discussion by **[@brianell.in](https://bsky.app/profile/brianell.in)**\n- **[MCP X Community](https://x.com/i/communities/1861891349609603310)** – A X community for MCP by **[Xiaoyi](https://x.com/chxy)**\n- **[MCPHub](https://github.com/Jeamee/MCPHub-Desktop)** – An Open Source macOS & Windows GUI Desktop app for discovering, installing and managing MCP servers by **[Jeamee](https://github.com/jeamee)**\n- **[mcpm](https://github.com/pathintegral-institute/mcpm.sh)** ([website](https://mcpm.sh)) - MCP Manager (MCPM) is a Homebrew-like service for managing Model Context Protocol (MCP) servers across clients by **[Pathintegral](https://github.com/pathintegral-institute)**\n- **[MCPVerse](https://mcpverse.dev)** - A portal for creating & hosting authenticated MCP servers and connecting to them securely.\n- **[MCP Servers Search](https://github.com/atonomus/mcp-servers-search)** - An MCP server that provides tools for querying and discovering available MCP servers from this list.\n- **[Search MCP Server](https://github.com/krzysztofkucmierz/search-mcp-server)** - Recommends the most relevant MCP servers based on the client's query by searching this README file.\n- **[MCPWatch](https://github.com/kapilduraphe/mcp-watch)** - A comprehensive security scanner for Model Context Protocol (MCP) servers that detects vulnerabilities and security issues in your MCP server implementations.\n- <img height=\"12\" width=\"12\" src=\"https://mkinf.io/favicon-lilac.png\" alt=\"mkinf Logo\" /> **[mkinf](https://mkinf.io)** - An Open Source registry of hosted MCP Servers to accelerate AI agent workflows.\n- **[Open-Sourced MCP Servers Directory](https://github.com/chatmcp/mcp-directory)** - A curated list of MCP servers by **[mcpso](https://mcp.so)**\n- <img height=\"12\" width=\"12\" src=\"https://opentools.com/favicon.ico\" alt=\"OpenTools Logo\" /> **[OpenTools](https://opentools.com)** - An open registry for finding, installing, and building with MCP servers by **[opentoolsteam](https://github.com/opentoolsteam)**\n- **[PulseMCP](https://www.pulsemcp.com)** ([API](https://www.pulsemcp.com/api)) - Community hub & weekly newsletter for discovering MCP servers, clients, articles, and news by **[Tadas Antanavicius](https://github.com/tadasant)**, **[Mike Coughlin](https://github.com/macoughl)**, and **[Ravina Patel](https://github.com/ravinahp)**\n- **[r/mcp](https://www.reddit.com/r/mcp)** – A Reddit community dedicated to MCP by **[Frank Fiegel](https://github.com/punkpeye)**\n- **[r/modelcontextprotocol](https://www.reddit.com/r/modelcontextprotocol)** – A Model Context Protocol community Reddit page - discuss ideas, get answers to your questions, network with like-minded people, and showcase your projects! by **[Alex Andru](https://github.com/QuantGeekDev)**\n- **[MCP.ing](https://mcp.ing/)** - A list of MCP services for discovering MCP servers in the community and providing a convenient search function for MCP services by **[iiiusky](https://github.com/iiiusky)**\n- **[MCP Hunt](https://mcp-hunt.com)** - Realtime platform for discovering trending MCP servers with momentum tracking, upvoting, and community discussions - like Product Hunt meets Reddit for MCP\n- **[Smithery](https://smithery.ai/)** - A registry of MCP servers to find the right tools for your LLM agents by **[Henry Mao](https://github.com/calclavia)**\n- **[Toolbase](https://gettoolbase.ai)** - Desktop application that manages tools and MCP servers with just a few clicks - no coding required by **[gching](https://github.com/gching)**\n- **[ToolHive](https://github.com/StacklokLabs/toolhive)** - A lightweight utility designed to simplify the deployment and management of MCP servers, ensuring ease of use, consistency, and security through containerization by **[StacklokLabs](https://github.com/StacklokLabs)**\n- **[NetMind](https://www.netmind.ai/AIServices)** - Access powerful AI services via simple APIs or MCP servers to supercharge your productivity.\n\n## 🚀 Getting Started\n\n### Using MCP Servers in this Repository\nTypeScript-based servers in this repository can be used directly with `npx`.\n\nFor example, this will start the [Memory](src/memory) server:\n```sh\nnpx -y @modelcontextprotocol/server-memory\n```\n\nPython-based servers in this repository can be used directly with [`uvx`](https://docs.astral.sh/uv/concepts/tools/) or [`pip`](https://pypi.org/project/pip/). `uvx` is recommended for ease of use and setup.\n\nFor example, this will start the [Git](src/git) server:\n```sh\n# With uvx\nuvx mcp-server-git\n\n# With pip\npip install mcp-server-git\npython -m mcp_server_git\n```\n\nFollow [these](https://docs.astral.sh/uv/getting-started/installation/) instructions to install `uv` / `uvx` and [these](https://pip.pypa.io/en/stable/installation/) to install `pip`.\n\n### Using an MCP Client\nHowever, running a server on its own isn't very useful, and should instead be configured into an MCP client. For example, here's the Claude Desktop configuration to use the above server:\n\n```json\n{\n  \"mcpServers\": {\n    \"memory\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-memory\"]\n    }\n  }\n}\n```\n\nAdditional examples of using the Claude Desktop as an MCP client might look like:\n\n```json\n{\n  \"mcpServers\": {\n    \"filesystem\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-filesystem\", \"/path/to/allowed/files\"]\n    },\n    \"git\": {\n      \"command\": \"uvx\",\n      \"args\": [\"mcp-server-git\", \"--repository\", \"path/to/git/repo\"]\n    },\n    \"github\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-github\"],\n      \"env\": {\n        \"GITHUB_PERSONAL_ACCESS_TOKEN\": \"<YOUR_TOKEN>\"\n      }\n    },\n    \"postgres\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-postgres\", \"postgresql://localhost/mydb\"]\n    }\n  }\n}\n```\n\n## 🛠️ Creating Your Own Server\n\nInterested in creating your own MCP server? Visit the official documentation at [modelcontextprotocol.io](https://modelcontextprotocol.io/introduction) for comprehensive guides, best practices, and technical details on implementing MCP servers.\n\n## 🤝 Contributing\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md) for information about contributing to this repository.\n\n## 🔒 Security\n\nSee [SECURITY.md](SECURITY.md) for reporting security vulnerabilities.\n\n## 📜 License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## 💬 Community\n\n- [GitHub Discussions](https://github.com/orgs/modelcontextprotocol/discussions)\n\n## ⭐ Support\n\nIf you find MCP servers useful, please consider starring the repository and contributing new servers or improvements!\n\n---\n\nManaged by Anthropic, but built together with the community. The Model Context Protocol is open source and we encourage everyone to contribute their own servers and improvements!",
      "npm_url": "https://www.npmjs.com/package/servers",
      "npm_downloads": 2441,
      "keywords": [
        "memory",
        "persistent",
        "chats",
        "persistent memory",
        "memory management",
        "chats defining"
      ],
      "category": "memory-management"
    },
    "movibe--memory-bank-mcp": {
      "owner": "movibe",
      "name": "memory-bank-mcp",
      "url": "https://github.com/movibe/memory-bank-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/movibe.webp",
      "description": "Manage and interact with structured repositories of information for AI assistants, enabling the storage, retrieval, and tracking of context across sessions to enhance AI capabilities. Supports operational modes for tasks like coding, debugging, and system design.",
      "stars": 43,
      "forks": 14,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-23T00:28:02Z",
      "readme_content": "# Memory Bank MCP 🧠\n\n[![NPM Version](https://img.shields.io/npm/v/@movibe/memory-bank-mcp.svg)](https://www.npmjs.com/package/@movibe/memory-bank-mcp)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Tests](https://github.com/movibe/memory-bank-mcp/actions/workflows/test.yml/badge.svg)](https://github.com/movibe/memory-bank-mcp/actions/workflows/test.yml)\n\nA Model Context Protocol (MCP) server for managing Memory Banks, allowing AI assistants to store and retrieve information across sessions.\n\n<a href=\"https://glama.ai/mcp/servers/riei9a6dhx\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/riei9a6dhx/badge\" alt=\"Memory Bank MCP server\" />\n</a>\n\n## Overview 📋\n\nMemory Bank Server provides a set of tools and resources for AI assistants to interact with Memory Banks. Memory Banks are structured repositories of information that help maintain context and track progress across multiple sessions.\n\n## Features ✨\n\n- **Memory Bank Management**: Initialize, find, and manage Memory Banks\n- **File Operations**: Read and write files in Memory Banks\n- **Progress Tracking**: Track progress and update Memory Bank files\n- **Decision Logging**: Log important decisions with context and alternatives\n- **Active Context Management**: Maintain and update active context information\n- **Mode Support**: Detect and use .clinerules files for mode-specific behavior\n- **UMB Command**: Update Memory Bank files temporarily with the UMB command\n- **Robust Error Handling**: Gracefully handle errors and continue operation when possible\n- **Status Prefix System**: Immediate visibility into Memory Bank operational state\n\n## Directory Structure 📁\n\nBy default, Memory Bank uses a `memory-bank` directory in the root of your project. When you specify a project path using the `--path` option, the Memory Bank will be created or accessed at `<project_path>/memory-bank`.\n\nYou can customize the name of the Memory Bank folder using the `--folder` option. For example, if you set `--folder custom-memory`, the Memory Bank will be created or accessed at `<project_path>/custom-memory`.\n\nFor more details on customizing the folder name, see [Custom Memory Bank Folder Name](docs/custom-folder-name.md).\n\n## Recent Improvements 🛠️\n\n- **Customizable Folder Name**: You can now specify a custom folder name for the Memory Bank\n- **Consistent Directory Structure**: Memory Bank now always uses the configured folder name in the project root\n- **Enhanced Initialization**: Memory Bank now works even when .clinerules files don't exist\n- **Better Path Handling**: Improved handling of absolute and relative paths\n- **Improved Directory Detection**: Better detection of existing memory-bank directories\n- **More Robust Error Handling**: Graceful handling of errors related to .clinerules files\n\nFor more details, see [Memory Bank Bug Fixes](docs/memory-bank-bug-fixes.md).\n\n## Installation 🚀\n\n```bash\n# Install from npm\nnpm install @movibe/memory-bank-mcp\n\n# Or install globally\nnpm install -g @movibe/memory-bank-mcp\n\n# Or run directly with npx (no installation required)\nnpx @movibe/memory-bank-mcp\n```\n\n## Usage with npx 💻\n\nYou can run Memory Bank MCP directly without installation using npx:\n\n```bash\n# Run with default settings\nnpx @movibe/memory-bank-mcp\n\n# Run with specific mode\nnpx @movibe/memory-bank-mcp --mode code\n\n# Run with custom project path\nnpx @movibe/memory-bank-mcp --path /path/to/project\n\n# Run with custom folder name\nnpx @movibe/memory-bank-mcp --folder custom-memory-bank\n\n# Show help\nnpx @movibe/memory-bank-mcp --help\n```\n\nFor more detailed information about using npx, see [npx-usage.md](docs/npx-usage.md).\n\n## Configuring in Cursor 🖱️\n\nCursor is an AI-powered code editor that supports the Model Context Protocol (MCP). To configure Memory Bank MCP in Cursor:\n\n1. **Use Memory Bank MCP with npx**:\n\n   No need to install the package globally. You can use npx directly:\n\n   ```bash\n   # Verify npx is working correctly\n   npx @movibe/memory-bank-mcp --help\n   ```\n\n2. **Open Cursor Settings**:\n\n   - Go to Settings (⚙️) > Extensions > MCP\n   - Click on \"Add MCP Server\"\n\n3. **Configure the MCP Server**:\n\n   - **Name**: Memory Bank MCP\n   - **Command**: npx\n   - **Arguments**: `@movibe/memory-bank-mcp --mode code` (or other mode as needed)\n\n4. **Save and Activate**:\n\n   - Click \"Save\"\n   - Enable the MCP server by toggling it on\n\n5. **Verify Connection**:\n   - Open a project in Cursor\n   - The Memory Bank MCP should now be active and available in your AI interactions\n\nFor detailed instructions and advanced usage with Cursor, see [cursor-integration.md](docs/cursor-integration.md).\n\n### Using with Cursor 🤖\n\nOnce configured, you can interact with Memory Bank MCP in Cursor through AI commands:\n\n- **Initialize a Memory Bank**: `/mcp memory-bank-mcp initialize_memory_bank path=./memory-bank`\n- **Track Progress**: `/mcp memory-bank-mcp track_progress action=\"Feature Implementation\" description=\"Implemented feature X\"`\n- **Log Decision**: `/mcp memory-bank-mcp log_decision title=\"API Design\" context=\"...\" decision=\"...\"`\n- **Switch Mode**: `/mcp memory-bank-mcp switch_mode mode=code`\n\n## MCP Modes and Their Usage 🔄\n\nMemory Bank MCP supports different operational modes to optimize AI interactions for specific tasks:\n\n### Available Modes\n\n1. **Code Mode** 👨‍💻\n\n   - Focus: Code implementation and development\n   - Usage: `npx @movibe/memory-bank-mcp --mode code`\n   - Best for: Writing, refactoring, and optimizing code\n\n2. **Architect Mode** 🏗️\n\n   - Focus: System design and architecture\n   - Usage: `npx @movibe/memory-bank-mcp --mode architect`\n   - Best for: Planning project structure, designing components, and making architectural decisions\n\n3. **Ask Mode** ❓\n\n   - Focus: Answering questions and providing information\n   - Usage: `npx @movibe/memory-bank-mcp --mode ask`\n   - Best for: Getting explanations, clarifications, and information\n\n4. **Debug Mode** 🐛\n\n   - Focus: Troubleshooting and problem-solving\n   - Usage: `npx @movibe/memory-bank-mcp --mode debug`\n   - Best for: Finding and fixing bugs, analyzing issues\n\n5. **Test Mode** ✅\n   - Focus: Testing and quality assurance\n   - Usage: `npx @movibe/memory-bank-mcp --mode test`\n   - Best for: Writing tests, test-driven development\n\n### Switching Modes\n\nYou can switch modes in several ways:\n\n1. **When starting the server**:\n\n   ```bash\n   npx @movibe/memory-bank-mcp --mode architect\n   ```\n\n2. **During a session**:\n\n   ```bash\n   memory-bank-mcp switch_mode mode=debug\n   ```\n\n3. **In Cursor**:\n\n   ```\n   /mcp memory-bank-mcp switch_mode mode=test\n   ```\n\n4. **Using .clinerules files**:\n   Create a `.clinerules-[mode]` file in your project to automatically switch to that mode when the file is detected.\n\n## How Memory Bank MCP Works 🧠\n\nMemory Bank MCP is built on the Model Context Protocol (MCP), which enables AI assistants to interact with external tools and resources. Here's how it works:\n\n### Core Components 🧩\n\n1. **Memory Bank**: A structured repository of information stored as markdown files:\n\n   - `product-context.md`: Overall project information and goals\n   - `active-context.md`: Current state, ongoing tasks, and next steps\n   - `progress.md`: History of project updates and milestones\n   - `decision-log.md`: Record of important decisions with context and rationale\n   - `system-patterns.md`: Architecture and code patterns used in the project\n\n2. **MCP Server**: Provides tools and resources for AI assistants to interact with Memory Banks:\n\n   - Runs as a standalone process\n   - Communicates with AI assistants through the MCP protocol\n   - Provides a set of tools for managing Memory Banks\n\n3. **Mode System**: Supports different operational modes:\n   - `code`: Focus on code implementation\n   - `ask`: Focus on answering questions\n   - `architect`: Focus on system design\n   - `debug`: Focus on debugging issues\n   - `test`: Focus on testing\n\n### Data Flow 🔄\n\n1. **Initialization**: The AI assistant connects to the MCP server and initializes a Memory Bank\n2. **Tool Calls**: The AI assistant calls tools provided by the MCP server to read/write Memory Bank files\n3. **Context Maintenance**: The Memory Bank maintains context across sessions, allowing the AI to recall previous decisions and progress\n\n### Memory Bank Structure 📂\n\nMemory Banks use a standardized structure to organize information:\n\n- **Product Context**: Project overview, objectives, technologies, and architecture\n- **Active Context**: Current state, ongoing tasks, known issues, and next steps\n- **Progress**: Chronological record of project updates and milestones\n- **Decision Log**: Record of important decisions with context, alternatives, and consequences\n- **System Patterns**: Architecture patterns, code patterns, and documentation patterns\n\n### Advanced Features 🚀\n\n- **UMB Command**: Temporarily update Memory Bank files during a session without committing changes\n- **Mode Detection**: Automatically detect and switch modes based on user input\n- **File Migration**: Tools for migrating between different file naming conventions\n- **Language Standardization**: All Memory Bank files are generated in English for consistency\n\n## Versioning 📌\n\nThis project follows [Semantic Versioning](https://semver.org/) and uses [Conventional Commits](https://www.conventionalcommits.org/) for commit messages. The version is automatically bumped and a changelog is generated based on commit messages when changes are merged into the main branch.\n\n- **Major version** is bumped when there are breaking changes (commit messages with `BREAKING CHANGE` or `!:`)\n- **Minor version** is bumped when new features are added (commit messages with `feat:` or `feat(scope):`)\n- **Patch version** is bumped for all other changes (bug fixes, documentation, etc.)\n\nFor the complete history of changes, see the [CHANGELOG.md](CHANGELOG.md) file.\n\n## Usage 📝\n\n### As a Command Line Tool 💻\n\n```bash\n# Initialize a Memory Bank\nmemory-bank-mcp initialize_memory_bank path=./memory-bank\n\n# Track progress\nmemory-bank-mcp track_progress action=\"Feature Implementation\" description=\"Implemented feature X\"\n\n# Log a decision\nmemory-bank-mcp log_decision title=\"API Design\" context=\"...\" decision=\"...\"\n\n# Switch mode\nmemory-bank-mcp switch_mode mode=code\n```\n\n### As a Library 📚\n\n```typescript\nimport { MemoryBankServer } from \"@movibe/memory-bank-mcp\";\n\n// Create a new server instance\nconst server = new MemoryBankServer();\n\n// Start the server\nserver.run().catch(console.error);\n```\n\n## Contributing 👥\n\nPlease see [CONTRIBUTING.md](CONTRIBUTING.md) for details on our code of conduct and the process for submitting pull requests.\n\n## License 📄\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Memory Bank Status System 🚦\n\nMemory Bank MCP implements a status prefix system that provides immediate visibility into the operational state of the Memory Bank:\n\n### Status Indicators\n\nEvery response from an AI assistant using Memory Bank MCP begins with one of these status indicators:\n\n- **`[MEMORY BANK: ACTIVE]`**: The Memory Bank is available and being used to provide context-aware responses\n- **`[MEMORY BANK: INACTIVE]`**: The Memory Bank is not available or not properly configured\n- **`[MEMORY BANK: UPDATING]`**: The Memory Bank is currently being updated (during UMB command execution)\n\nThis system ensures users always know whether the AI assistant is operating with full context awareness or limited information.\n\n### Benefits\n\n- **Transparency**: Users always know whether the AI has access to the full project context\n- **Troubleshooting**: Makes it immediately obvious when Memory Bank is not properly configured\n- **Context Awareness**: Helps users understand why certain responses may lack historical context\n\nFor more details, see [Memory Bank Status Prefix System](docs/memory-bank-status-prefix.md).",
      "npm_url": "https://www.npmjs.com/package/memory-bank-mcp",
      "npm_downloads": 3190,
      "keywords": [
        "memory",
        "movibe",
        "ai",
        "movibe memory",
        "memory management",
        "management movibe"
      ],
      "category": "memory-management"
    },
    "neo4j-contrib--mcp-neo4j": {
      "owner": "neo4j-contrib",
      "name": "mcp-neo4j",
      "url": "https://github.com/neo4j-contrib/mcp-neo4j",
      "imageUrl": "/freedevtools/mcp/pfp/neo4j-contrib.webp",
      "description": "Integrates with the Neo4j graph database to maintain complex relationships between memory nodes, enabling long-term retention and querying of knowledge across multiple conversations. Facilitates the construction of an interconnected knowledge base that acts as an external memory system.",
      "stars": 725,
      "forks": 186,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-02T12:42:40Z",
      "readme_content": "# Neo4j MCP Clients & Servers\n\nModel Context Protocol (MCP) is a [standardized protocol](https://modelcontextprotocol.io/introduction) for managing context between large language models (LLMs) and external systems. \n\nThis lets you use Claude Desktop, or any other MCP Client (VS Code, Cursor, Windsurf), to use natural language to accomplish things with Neo4j and your Aura account, e.g.:\n\n* What is in this graph?\n* Render a chart from the top products sold by frequency, total and average volume\n* List my instances\n* Create a new instance named mcp-test for Aura Professional with 4GB and Graph Data Science enabled\n* Store the fact that I worked on the Neo4j MCP Servers today with Andreas and Oskar\n\n## Servers\n\n### `mcp-neo4j-cypher` - natural language to Cypher queries\n\n[Details in Readme](./servers/mcp-neo4j-cypher/)\n\nGet database schema for a configured database and execute generated read and write Cypher queries on that database.\n\n### `mcp-neo4j-memory` - knowledge graph memory stored in Neo4j\n\n[Details in Readme](./servers/mcp-neo4j-memory/)\n\nStore and retrieve entities and relationships from your personal knowledge graph in a local or remote Neo4j instance.\nAccess that information over different sessions, conversations, clients.\n\n### `mcp-neo4j-cloud-aura-api` - Neo4j Aura cloud service management API\n\n[Details in Readme](./servers/mcp-neo4j-cloud-aura-api//)\n\nManage your [Neo4j Aura](https://console.neo4j.io) instances directly from the comfort of your AI assistant chat.\n\nCreate and destroy instances, find instances by name, scale them up and down and enable features.\n\n### `mcp-neo4j-data-modeling` - interactive graph data modeling and visualization\n\n[Details in Readme](./servers/mcp-neo4j-data-modeling/)\n\nCreate, validate, and visualize Neo4j graph data models. Allows for model import/export from Arrows.app.\n\n## Transport Modes\n\nAll servers support multiple transport modes:\n\n- **STDIO** (default): Standard input/output for local tools and Claude Desktop integration\n- **SSE**: Server-Sent Events for web-based deployments\n- **HTTP**: Streamable HTTP for modern web deployments and microservices\n\n### HTTP Transport Configuration\n\nTo run a server in HTTP mode, use the `--transport http` flag:\n\n```bash\n# Basic HTTP mode\nmcp-neo4j-cypher --transport http\n\n# Custom HTTP configuration\nmcp-neo4j-cypher --transport http --host 127.0.0.1 --port 8080 --path /api/mcp/\n```\n\nEnvironment variables are also supported:\n\n```bash\nexport NEO4J_TRANSPORT=http\nexport NEO4J_MCP_SERVER_HOST=127.0.0.1\nexport NEO4J_MCP_SERVER_PORT=8080\nexport NEO4J_MCP_SERVER_PATH=/api/mcp/\nmcp-neo4j-cypher\n```\n\n## Cloud Deployment\n\nAll servers in this repository are containerized and ready for cloud deployment on platforms like AWS ECS Fargate and Azure Container Apps. Each server supports HTTP transport mode specifically designed for scalable, production-ready deployments with auto-scaling and load balancing capabilities.\n\n📋 **[Complete Cloud Deployment Guide →](README-Cloud.md)**\n\nThe deployment guide covers:\n- **AWS ECS Fargate**: Step-by-step deployment with auto-scaling and Application Load Balancer\n- **Azure Container Apps**: Serverless container deployment with built-in scaling and traffic management\n- **Configuration Best Practices**: Security, monitoring, resource recommendations, and troubleshooting\n- **Integration Examples**: Connecting MCP clients to cloud-deployed servers\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## Blog Posts\n\n* [Everything a Developer Needs to Know About the Model Context Protocol (MCP)](https://neo4j.com/blog/developer/model-context-protocol/)\n* [Claude Converses With Neo4j Via MCP - Graph Database & Analytics](https://neo4j.com/blog/developer/claude-converses-neo4j-via-mcp/)\n* [Building Knowledge Graphs With Claude and Neo4j: A No-Code MCP Approach - Graph Database & Analytics](https://neo4j.com/blog/developer/knowledge-graphs-claude-neo4j-mcp/)\n\n## License\n\nMIT License\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "neo4j",
        "nodes",
        "memory",
        "management neo4j",
        "neo4j contrib",
        "memory nodes"
      ],
      "category": "memory-management"
    },
    "neobundy--cwkCursorPippaMCP": {
      "owner": "neobundy",
      "name": "cwkCursorPippaMCP",
      "url": "https://github.com/neobundy/cwkCursorPippaMCP",
      "imageUrl": "/freedevtools/mcp/pfp/null.webp",
      "description": "Manage and enhance memory capabilities for AI assistants within Cursor IDE, enabling seamless storage, recall, and management of information across conversations for more personalized interactions.",
      "stars": 0,
      "forks": 0,
      "license": "Unknown",
      "language": "Unknown",
      "updated_at": "",
      "readme_content": "",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "cursor",
        "cwkcursorpippamcp",
        "memory",
        "assistants cursor",
        "ai assistants",
        "cursor ide"
      ],
      "category": "memory-management"
    },
    "oculairmedia--Letta-MCP-server": {
      "owner": "oculairmedia",
      "name": "Letta-MCP-server",
      "url": "https://github.com/oculairmedia/Letta-MCP-server",
      "imageUrl": "/freedevtools/mcp/pfp/oculairmedia.webp",
      "description": "Manage agents and memory blocks within the Letta system, enabling the creation, listing, and attachment of memory blocks to agents while facilitating seamless communication through message sending and response receiving.",
      "stars": 38,
      "forks": 11,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-29T02:32:37Z",
      "readme_content": "[![npm version](https://img.shields.io/npm/v/letta-mcp-server.svg)](https://www.npmjs.com/package/letta-mcp-server)\n[![npm downloads](https://img.shields.io/npm/dm/letta-mcp-server.svg)](https://www.npmjs.com/package/letta-mcp-server)\n[![npm downloads total](https://img.shields.io/npm/dt/letta-mcp-server.svg)](https://www.npmjs.com/package/letta-mcp-server)\n[![Docker Image](https://img.shields.io/badge/Docker-ghcr.io-blue)](https://github.com/oculairmedia/Letta-MCP-server/pkgs/container/letta-mcp-server)\n[![MseeP.ai Security Assessment Badge](https://mseep.net/mseep-audited.png)](https://mseep.ai/app/oculairmedia-letta-mcp-server)\n[![CI/CD](https://github.com/oculairmedia/letta-MCP-server/actions/workflows/test.yml/badge.svg)](https://github.com/oculairmedia/letta-MCP-server/actions/workflows/test.yml)\n[![Docker Build](https://github.com/oculairmedia/letta-MCP-server/actions/workflows/docker-build.yml/badge.svg)](https://github.com/oculairmedia/letta-MCP-server/actions/workflows/docker-build.yml)\n[![CodeQL](https://github.com/oculairmedia/letta-MCP-server/actions/workflows/codeql.yml/badge.svg)](https://github.com/oculairmedia/letta-MCP-server/actions/workflows/codeql.yml)\n[![Coverage Status](https://codecov.io/gh/oculairmedia/letta-MCP-server/branch/main/graph/badge.svg)](https://codecov.io/gh/oculairmedia/letta-MCP-server)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\n# Letta MCP Server\n\nA Model Context Protocol (MCP) server that provides comprehensive tools for agent management, memory operations, and integration with the Letta system. This server implements the full MCP specification including tools, prompts, and resources, with enhanced descriptions, output schemas, and behavioral annotations.\n\n**[View on npm](https://www.npmjs.com/package/letta-mcp-server)** | **[View on GitHub](https://github.com/oculairmedia/Letta-MCP-server)**\n\n## Features\n\n- 🤖 **Agent Management** - Create, modify, clone, and manage Letta agents\n- 🧠 **Memory Operations** - Handle memory blocks and passages\n- 🔧 **Tool Integration** - Attach and manage tools for agents with full MCP support\n- 💬 **Prompts** - Interactive wizards and assistants for common workflows\n- 📚 **Resources** - Access system information, documentation, and agent data\n- 🌐 **Multiple Transports** - HTTP, SSE, and stdio support\n- 🔗 **MCP Server Integration** - Integrate with other MCP servers\n- 📊 **Enhanced Metadata** - Output schemas and behavioral annotations for all tools\n- 📦 **Docker Support** - Easy deployment with Docker\n\n## Environment Configuration\n\nCreate a `.env` file with the following variables:\n\n```bash\n# Required\nLETTA_BASE_URL=https://your-letta-instance.com/v1\nLETTA_PASSWORD=your-secure-password\n\n# Optional\nPORT=3001\nNODE_ENV=production\n```\n\n## Installation\n\n### Install from npm\n\n```bash\n# Global installation (recommended for CLI usage)\nnpm install -g letta-mcp-server\n\n# Or local installation\nnpm install letta-mcp-server\n```\n\n### Use with Claude Desktop\n\nAfter installing globally, add to your Claude Desktop configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"letta\": {\n      \"command\": \"letta-mcp\",\n      \"args\": [],\n      \"env\": {\n        \"LETTA_BASE_URL\": \"https://your-letta-instance.com/v1\",\n        \"LETTA_PASSWORD\": \"your-secure-password\"\n      }\n    }\n  }\n}\n```\n\n### Quick Start with npm\n\n```bash\n# Install globally\nnpm install -g letta-mcp-server\n\n# Set environment variables\nexport LETTA_BASE_URL=https://your-letta-instance.com/v1\nexport LETTA_PASSWORD=your-secure-password\n\n# Run the server\nletta-mcp              # stdio (for Claude Desktop)\nletta-mcp --http       # HTTP transport\nletta-mcp --sse        # SSE transport\n```\n\n## Quick Setup\n\n### Option 1: Run from source\n\n```bash\n# Clone the repository\ngit clone https://github.com/oculairmedia/letta-MCP-server.git\ncd letta-MCP-server\n\n# Install dependencies\nnpm install\n\n# Development\nnpm run dev         # Default (stdio) transport\nnpm run dev:sse     # SSE transport\nnpm run dev:http    # HTTP transport (recommended)\n\n# Production\nnpm run start       # Default (stdio) transport\nnpm run start:sse   # SSE transport\nnpm run start:http  # HTTP transport (recommended)\n```\n\n### Option 2: Run with Docker\n\n#### Using the prebuilt image from GitHub Container Registry\n\nAvailable tags:\n- `latest` - Latest stable release\n- `2.0.1`, `2.0`, `2` - Specific version tags\n- `master` - Latest master branch build\n\n```bash\n# Pull the latest image\ndocker pull ghcr.io/oculairmedia/letta-mcp-server:latest\n\n# Run with environment variables\ndocker run -d \\\n  -p 3001:3001 \\\n  -e LETTA_BASE_URL=https://your-letta-instance.com/v1 \\\n  -e LETTA_PASSWORD=your-secure-password \\\n  -e PORT=3001 \\\n  -e NODE_ENV=production \\\n  --name letta-mcp \\\n  ghcr.io/oculairmedia/letta-mcp-server:latest\n\n# Or use a specific version\ndocker run -d \\\n  -p 3001:3001 \\\n  -e LETTA_BASE_URL=https://your-letta-instance.com/v1 \\\n  -e LETTA_PASSWORD=your-secure-password \\\n  --name letta-mcp \\\n  ghcr.io/oculairmedia/letta-mcp-server:2.0.1\n```\n\n#### Using Docker Compose\n\n```yaml\nversion: '3.8'\nservices:\n  letta-mcp:\n    image: ghcr.io/oculairmedia/letta-mcp-server:latest\n    container_name: letta-mcp\n    ports:\n      - \"3001:3001\"\n    environment:\n      - LETTA_BASE_URL=https://your-letta-instance.com/v1\n      - LETTA_PASSWORD=your-secure-password\n      - PORT=3001\n      - NODE_ENV=production\n    restart: unless-stopped\n```\n\n#### Building from source\n\n```bash\n# Clone and build locally\ngit clone https://github.com/oculairmedia/letta-MCP-server.git\ncd letta-MCP-server\ndocker build -t letta-mcp-server .\ndocker run -d -p 3001:3001 --env-file .env --name letta-mcp letta-mcp-server\n```\n\n### Option 3: Run with stdio for local MCP\n\n```bash\n# Create startup script\nchmod +x /opt/stacks/letta-MCP-server/start-mcp.sh\n\n# Add to Claude\nclaude mcp add --transport stdio letta-tools \"/opt/stacks/letta-MCP-server/start-mcp.sh\"\n```\n\n## Architecture\n\nSee the [Architecture Documentation](docs/ARCHITECTURE.md) for detailed system diagrams and component relationships.\n\n## MCP Protocol Support\n\nThis server implements the full MCP specification with all three capabilities:\n\n### 🔧 Tools\nAll tools include:\n- **Enhanced Descriptions**: Detailed explanations with use cases and best practices\n- **Output Schemas**: Structured response definitions for predictable outputs\n- **Behavioral Annotations**: Hints about tool behavior (readOnly, costLevel, executionTime, etc.)\n\n### 💬 Prompts\nInteractive prompts for common workflows:\n- `letta_agent_wizard` - Guided agent creation with memory and tool setup\n- `letta_memory_optimizer` - Analyze and optimize agent memory usage\n- `letta_debug_assistant` - Troubleshoot agent issues\n- `letta_tool_config` - Discover, attach, create, or audit tools\n- `letta_migration` - Export, import, upgrade, or clone agents\n\n### 📚 Resources\nAccess system information and documentation:\n- `letta://system/status` - System health and version info\n- `letta://system/models` - Available LLM and embedding models\n- `letta://agents/list` - Overview of all agents\n- `letta://tools/all/docs` - Complete tool documentation with examples\n- `letta://docs/mcp-integration` - Integration guide\n- `letta://docs/api-reference` - API quick reference\n\nResource templates for dynamic content:\n- `letta://agents/{agent_id}/config` - Agent configuration\n- `letta://agents/{agent_id}/memory/{block_id}` - Memory block content\n- `letta://tools/{tool_name}/docs` - Individual tool documentation\n\n## Available Tools\n\n### Agent Management\n\n| Tool | Description | Annotations |\n|------|-------------|-------------|\n| `create_agent` | Create a new Letta agent | 💰 Medium cost, ⚡ Fast |\n| `list_agents` | List all available agents | 👁️ Read-only, 💰 Low cost |\n| `prompt_agent` | Send a message to an agent | 💰 High cost, ⏱️ Variable time, 🔒 Rate limited |\n| `retrieve_agent` | Get agent details by ID | 👁️ Read-only, ⚡ Fast |\n| `get_agent_summary` | Get agent summary information | 👁️ Read-only, ⚡ Fast |\n| `modify_agent` | Update an existing agent | ✏️ Modifies state, ⚡ Fast |\n| `delete_agent` | Delete an agent | ⚠️ Dangerous, 🗑️ Permanent |\n| `clone_agent` | Clone an existing agent | 💰 Medium cost, ⏱️ Medium time |\n| `bulk_delete_agents` | Delete multiple agents | ⚠️ Dangerous, 📦 Bulk operation |\n| `export_agent` | Export agent configuration and memory | 👁️ Read-only, ⚡ Fast, 📦 Full backup |\n| `import_agent` | Import agent from backup | 💰 High cost, ⏱️ Slow, ✏️ Creates state |\n\n### Memory Management\n\n| Tool | Description | Annotations |\n|------|-------------|-------------|\n| `list_memory_blocks` | List all memory blocks | 👁️ Read-only, ⚡ Fast |\n| `create_memory_block` | Create a new memory block | ✏️ Creates state, ⚡ Fast |\n| `read_memory_block` | Read a memory block | 👁️ Read-only, ⚡ Fast |\n| `update_memory_block` | Update a memory block | ✏️ Modifies state, ⚡ Fast |\n| `attach_memory_block` | Attach memory to an agent | ✏️ Links resources, ⚡ Fast |\n\n### Passage Management\n\n| Tool | Description | Annotations |\n|------|-------------|-------------|\n| `list_passages` | Search archival memory | 👁️ Read-only, ⚡ Fast |\n| `create_passage` | Create archival memory | 💰 Medium cost (embeddings), ⚡ Fast |\n| `modify_passage` | Update archival memory | 💰 Medium cost (re-embedding), ⚡ Fast |\n| `delete_passage` | Delete archival memory | 🗑️ Permanent, ⚡ Fast |\n\n### Tool Management\n\n| Tool | Description | Annotations |\n|------|-------------|-------------|\n| `list_agent_tools` | List tools for an agent | 👁️ Read-only, ⚡ Fast |\n| `attach_tool` | Attach tools to an agent | ✏️ Modifies capabilities, ⚡ Fast |\n| `upload_tool` | Upload a custom tool | 🔒 Security: Executes code, ⚡ Fast |\n| `bulk_attach_tool_to_agents` | Attach tool to multiple agents | 📦 Bulk operation, ⏱️ Slow |\n\n### Model Management\n\n| Tool | Description | Annotations |\n|------|-------------|-------------|\n| `list_llm_models` | List available LLM models | 👁️ Read-only, ⚡ Fast |\n| `list_embedding_models` | List available embedding models | 👁️ Read-only, ⚡ Fast |\n\n### MCP Integration\n\n| Tool | Description | Annotations |\n|------|-------------|-------------|\n| `list_mcp_servers` | List configured MCP servers | 👁️ Read-only, ⚡ Fast |\n| `list_mcp_tools_by_server` | List tools from an MCP server | 👁️ Read-only, ⚡ Fast |\n| `add_mcp_tool_to_letta` | Import MCP tool to Letta | ✏️ Creates tool, ⚡ Fast |\n\n### Prompt Tools\n\n| Tool | Description | Annotations |\n|------|-------------|-------------|\n| `list_prompts` | List available prompt templates | 👁️ Read-only, ⚡ Fast |\n| `use_prompt` | Execute a prompt template | 💰 Variable cost, ⏱️ Variable time |\n\n## Directory Structure\n\n- `src/index.js` - Main entry point\n- `src/core/` - Core server functionality\n- `src/handlers/` - Prompt and resource handlers\n- `src/examples/` - Example prompts and resources\n- `src/tools/` - Tool implementations organized by category:\n  - `agents/` - Agent management tools\n  - `memory/` - Memory block tools\n  - `passages/` - Passage management tools\n  - `tools/` - Tool attachment and management\n  - `mcp/` - MCP server integration tools\n  - `models/` - Model listing tools\n  - `enhanced-descriptions.js` - Detailed tool descriptions\n  - `output-schemas.js` - Structured output definitions\n  - `annotations.js` - Behavioral hints\n- `src/transports/` - Server transport implementations\n\n## Transport Protocols\n\nThe server supports three transport protocols:\n\n1. **HTTP (Recommended)** - Streamable HTTP transport with full duplex communication\n   - Endpoint: `http://your-server:3001/mcp`\n   - Best for production use and remote connections\n   - Supports health checks at `/health`\n\n2. **SSE (Server-Sent Events)** - Real-time event streaming\n   - Endpoint: `http://your-server:3001/sse`\n   - Good for unidirectional server-to-client updates\n\n3. **stdio** - Standard input/output\n   - Direct process communication\n   - Best for local development and Claude integration\n\n## Configuration with MCP Settings\n\nAdd the server to your mcp_settings.json:\n\n```json\n\"letta\": {\n  \"command\": \"node\",\n  \"args\": [\n    \"--no-warnings\",\n    \"--experimental-modules\",\n    \"path/to/letta-server/src/index.js\"\n  ],\n  \"env\": {\n    \"LETTA_BASE_URL\": \"https://your-letta-instance.com\",\n    \"LETTA_PASSWORD\": \"yourPassword\"\n  },\n  \"disabled\": false,\n  \"alwaysAllow\": [\n    \"upload_tool\",\n    \"attach_tool\",\n    \"list_agents\",\n    \"list_memory_blocks\"\n  ],\n  \"timeout\": 300\n}\n```\n\nFor remote instances with HTTP transport (recommended):\n\n```json\n\"remote_letta_tools\": {\n  \"url\": \"http://your-server:3001/mcp\",\n  \"transport\": \"http\",\n  \"disabled\": false,\n  \"alwaysAllow\": [\n    \"attach_tool\", \n    \"list_agents\",\n    \"list_tools\",\n    \"get_agent\"\n  ],\n  \"timeout\": 120\n}\n```\n\n## Docker Operations\n\n```bash\n# View container logs\ndocker logs -f letta-mcp\n\n# Stop the container\ndocker stop letta-mcp\n\n# Update to latest version\ndocker pull ghcr.io/oculairmedia/letta-mcp-server:latest\ndocker stop letta-mcp\ndocker rm letta-mcp\ndocker run -d -p 3001:3001 -e PORT=3001 -e NODE_ENV=production --name letta-mcp ghcr.io/oculairmedia/letta-mcp-server:latest\n```\n\n## Troubleshooting\n\n### Common Issues\n\n1. **Connection refused errors**\n   - Ensure the server is running and accessible\n   - Check firewall settings for port 3001\n   - Verify the correct transport protocol is being used\n\n2. **Authentication failures**\n   - Verify LETTA_BASE_URL includes `/v1` suffix\n   - Check LETTA_PASSWORD is correct\n   - Ensure environment variables are loaded\n   - When self-hosting the Letta-Server, set environment variables accordingly:\n     ```json\n     \"env\": {\n        \"LETTA_BASE_URL\": \"http://localhost:8283\",\n        \"LETTA_PASSWORD\": \"\",\n        \"LOG_LEVEL\": \"info\"\n      }\n     ```\n\n\n3. **Tool execution timeouts**\n   - Increase timeout values in MCP configuration\n   - Check network latency for remote connections\n   - Consider using HTTP transport for better reliability\n\n### Health Check\n\nThe HTTP transport provides a health endpoint:\n\n```bash\ncurl http://your-server:3001/health\n```\n\nResponse:\n```json\n{\n  \"status\": \"healthy\",\n  \"transport\": \"streamable_http\",\n  \"protocol_version\": \"2025-06-18\",\n  \"sessions\": 0,\n  \"uptime\": 12345.678\n}\n```\n\n## Development\n\n### Testing\n\n```bash\n# Run tests\nnpm test\n\n# Run tests with coverage\nnpm run test:coverage\n\n# Run linter\nnpm run lint\n```\n\n### Contributing\n\nWe welcome contributions! Please see our [Contributing Guide](docs/CONTRIBUTING.md) for details on:\n\n- Development setup\n- Code style and standards\n- Adding new tools\n- Testing requirements\n- Pull request process\n\n## Security\n\nFor security vulnerabilities, please see our [Security Policy](docs/SECURITY.md).\n\n## License\n\nMIT License - see LICENSE file for details\n",
      "npm_url": "https://www.npmjs.com/package/letta-mcp-server",
      "npm_downloads": 229,
      "keywords": [
        "letta",
        "oculairmedia",
        "memory",
        "oculairmedia letta",
        "letta enabling",
        "management oculairmedia"
      ],
      "category": "memory-management"
    },
    "pinkpixel-dev--mem0-mcp": {
      "owner": "pinkpixel-dev",
      "name": "mem0-mcp",
      "url": "https://github.com/pinkpixel-dev/mem0-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/pinkpixel-dev.webp",
      "description": "Provides a memory system for AI applications where information can be stored and retrieved across user sessions. It enables personalized interactions by managing user-specific data efficiently.",
      "stars": 76,
      "forks": 8,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-29T09:06:00Z",
      "readme_content": "![Mem0 Logo](https://res.cloudinary.com/di7ctlowx/image/upload/v1741739911/mem0-logo_dlssjm.svg)\n\n[![npm version](https://badge.fury.io/js/@pinkpixel%2Fmem0-mcp.svg)](https://badge.fury.io/js/@pinkpixel%2Fmem0-mcp)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Node.js](https://img.shields.io/badge/Node.js-18%2B-green.svg)](https://nodejs.org/)\n[![TypeScript](https://img.shields.io/badge/TypeScript-5.3%2B-blue.svg)](https://www.typescriptlang.org/)\n[![MCP](https://img.shields.io/badge/MCP-0.6.0-purple.svg)](https://modelcontextprotocol.io/)\n[![Mem0](https://img.shields.io/badge/Mem0-2.1%2B-orange.svg)](https://mem0.ai)\n[![Downloads](https://img.shields.io/npm/dm/@pinkpixel/mem0-mcp.svg)](https://www.npmjs.com/package/@pinkpixel/mem0-mcp)\n[![GitHub Stars](https://img.shields.io/github/stars/pinkpixel-dev/mem0-mcp.svg)](https://github.com/pinkpixel-dev/mem0-mcp)\n[![smithery badge](https://smithery.ai/badge/@pinkpixel-dev/mem0-mcp-server)](https://smithery.ai/server/@pinkpixel-dev/mem0-mcp-server)\n\n# @pinkpixel/mem0-mcp MCP Server ✨\n\nA Model Context Protocol (MCP) server that integrates with [Mem0.ai](https://mem0.ai/) to provide persistent memory capabilities for LLMs. It allows AI agents to store and retrieve information across sessions.\n\nThis server uses the `mem0ai` Node.js SDK for its core functionality.\n\n## Features 🧠\n\n### Tools\n*   **`add_memory`**: Stores a piece of text content as a memory associated with a specific `userId`.\n    *   **Required:** `content` (string), `userId` (string)\n    *   **Optional:** `sessionId` (string), `agentId` (string), `appId` (string), `metadata` (object)\n    *   **Advanced (Cloud API):** `includes` (string), `excludes` (string), `infer` (boolean), `outputFormat` (string), `customCategories` (object), `customInstructions` (string), `immutable` (boolean), `expirationDate` (string)\n    *   Stores the provided text, enabling recall in future interactions.\n*   **`search_memory`**: Searches stored memories based on a natural language query for a specific `userId`.\n    *   **Required:** `query` (string), `userId` (string)\n    *   **Optional:** `sessionId` (string), `agentId` (string), `appId` (string), `filters` (object), `threshold` (number)\n    *   **Advanced (Cloud API):** `topK` (number), `fields` (array), `rerank` (boolean), `keywordSearch` (boolean), `filterMemories` (boolean)\n    *   Retrieves relevant memories based on semantic similarity.\n*   **`delete_memory`**: Deletes a specific memory from storage by its ID.\n    *   **Required:** `memoryId` (string), `userId` (string)\n    *   **Optional:** `agentId` (string), `appId` (string)\n    *   Permanently removes the specified memory.\n\n## Prerequisites 🔑\n\nThis server supports three storage modes:\n\n1. **Cloud Storage Mode** ☁️ (Recommended for production)\n   * Requires a **Mem0 API key** (provided as `MEM0_API_KEY` environment variable)\n   * Memories are persistently stored on Mem0's cloud servers\n   * No local database needed\n   * Full feature support with advanced filtering and search\n\n2. **Supabase Storage Mode** 🗄️ (Recommended for self-hosting)\n   * Requires **Supabase credentials** (`SUPABASE_URL` and `SUPABASE_KEY` environment variables)\n   * Requires **OpenAI API key** (`OPENAI_API_KEY` environment variable) for embeddings\n   * Memories are persistently stored in your Supabase database\n   * Free tier available, self-hostable option\n   * Requires initial database setup (SQL migrations provided below)\n\n3. **Local Storage Mode** 💾 (Development/testing only)\n   * Requires an **OpenAI API key** (provided as `OPENAI_API_KEY` environment variable)\n   * Memories are stored in an in-memory vector database (non-persistent by default)\n   * Data is lost when the server restarts unless configured for persistent storage\n\n## Installation & Configuration ⚙️\n\nYou can run this server in three main ways:\n\n### Installing via Smithery\n\nTo install Mem0 Memory Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@pinkpixel-dev/mem0-mcp-server):\n\n```bash\nnpx -y @smithery/cli install @pinkpixel-dev/mem0-mcp-server --client claude\n```\n\n### 1. Global Installation (Recommended for frequent use)\n\nInstall the package globally and use the `mem0-mcp` command:\n\n```bash\nnpm install -g @pinkpixel/mem0-mcp\n```\n\nAfter global installation, you can run the server directly:\n\n```bash\nmem0-mcp\n```\n\nConfigure your MCP client to use the global command:\n\n#### Cloud Storage Configuration (Global Install)\n\n```json\n{\n  \"mcpServers\": {\n    \"mem0-mcp\": {\n      \"command\": \"mem0-mcp\",\n      \"args\": [],\n      \"env\": {\n        \"MEM0_API_KEY\": \"YOUR_MEM0_API_KEY_HERE\",\n        \"DEFAULT_USER_ID\": \"user123\",\n        \"DEFAULT_AGENT_ID\": \"your-agent-id\",\n        \"DEFAULT_APP_ID\": \"your-app-id\"\n      },\n      \"disabled\": false,\n      \"alwaysAllow\": [\n        \"add_memory\",\n        \"search_memory\",\n        \"delete_memory\"\n      ]\n    }\n  }\n}\n```\n\n#### Supabase Storage Configuration (Global Install)\n\n```json\n{\n  \"mcpServers\": {\n    \"mem0-mcp\": {\n      \"command\": \"mem0-mcp\",\n      \"args\": [],\n      \"env\": {\n        \"SUPABASE_URL\": \"YOUR_SUPABASE_PROJECT_URL\",\n        \"SUPABASE_KEY\": \"YOUR_SUPABASE_ANON_KEY\",\n        \"OPENAI_API_KEY\": \"YOUR_OPENAI_API_KEY_HERE\",\n        \"DEFAULT_USER_ID\": \"user123\",\n        \"DEFAULT_AGENT_ID\": \"your-agent-id\",\n        \"DEFAULT_APP_ID\": \"your-app-id\"\n      },\n      \"disabled\": false,\n      \"alwaysAllow\": [\n        \"add_memory\",\n        \"search_memory\",\n        \"delete_memory\"\n      ]\n    }\n  }\n}\n```\n\n#### Local Storage Configuration (Global Install)\n\n```json\n{\n  \"mcpServers\": {\n    \"mem0-mcp\": {\n      \"command\": \"mem0-mcp\",\n      \"args\": [],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"YOUR_OPENAI_API_KEY_HERE\",\n        \"DEFAULT_USER_ID\": \"user123\"\n      },\n      \"disabled\": false,\n      \"alwaysAllow\": [\n        \"add_memory\",\n        \"search_memory\",\n        \"delete_memory\"\n      ]\n    }\n  }\n}\n```\n\n### 2. Using `npx` (Recommended for occasional use)\n\nConfigure your MCP client (e.g., Claude Desktop, Cursor, Cline, Roo Code, etc.) to run the server using `npx`:\n\n#### Cloud Storage Configuration (npx)\n\n```json\n{\n  \"mcpServers\": {\n    \"mem0-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@pinkpixel/mem0-mcp\"\n      ],\n      \"env\": {\n        \"MEM0_API_KEY\": \"YOUR_MEM0_API_KEY_HERE\",\n        \"DEFAULT_USER_ID\": \"user123\",\n        \"DEFAULT_AGENT_ID\": \"your-agent-id\",\n        \"DEFAULT_APP_ID\": \"your-app-id\"\n      },\n      \"disabled\": false,\n      \"alwaysAllow\": [\n        \"add_memory\",\n        \"search_memory\",\n        \"delete_memory\"\n      ]\n    }\n  }\n}\n```\n\n#### Supabase Storage Configuration (npx)\n\n```json\n{\n  \"mcpServers\": {\n    \"mem0-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@pinkpixel/mem0-mcp\"\n      ],\n      \"env\": {\n        \"SUPABASE_URL\": \"YOUR_SUPABASE_PROJECT_URL\",\n        \"SUPABASE_KEY\": \"YOUR_SUPABASE_ANON_KEY\",\n        \"OPENAI_API_KEY\": \"YOUR_OPENAI_API_KEY_HERE\",\n        \"DEFAULT_USER_ID\": \"user123\",\n        \"DEFAULT_AGENT_ID\": \"your-agent-id\",\n        \"DEFAULT_APP_ID\": \"your-app-id\"\n      },\n      \"disabled\": false,\n      \"alwaysAllow\": [\n        \"add_memory\",\n        \"search_memory\",\n        \"delete_memory\"\n      ]\n    }\n  }\n}\n```\n\n#### Local Storage Configuration (npx)\n\n```json\n{\n  \"mcpServers\": {\n    \"mem0-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@pinkpixel/mem0-mcp\"\n      ],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"YOUR_OPENAI_API_KEY_HERE\",\n        \"DEFAULT_USER_ID\": \"user123\"\n      },\n      \"disabled\": false,\n      \"alwaysAllow\": [\n        \"add_memory\",\n        \"search_memory\",\n        \"delete_memory\"\n      ]\n    }\n  }\n}\n```\n\n### 3. Running from Cloned Repository\n\n**Note: This method requires you to git clone the repository first.**\n\nClone the repository, install dependencies, and build the server:\n\n```bash\ngit clone https://github.com/pinkpixel-dev/mem0-mcp\ncd mem0-mcp\nnpm install\nnpm run build\n```\n\nThen, configure your MCP client to run the built script directly using `node`:\n\n#### Cloud Storage Configuration (Cloned Repository)\n\n```json\n{\n  \"mcpServers\": {\n    \"mem0-mcp\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/absolute/path/to/mem0-mcp/build/index.js\"\n      ],\n      \"env\": {\n        \"MEM0_API_KEY\": \"YOUR_MEM0_API_KEY_HERE\",\n        \"DEFAULT_USER_ID\": \"user123\",\n        \"DEFAULT_AGENT_ID\": \"your-agent-id\",\n        \"DEFAULT_APP_ID\": \"your-app-id\"\n      },\n      \"disabled\": false,\n      \"alwaysAllow\": [\n        \"add_memory\",\n        \"search_memory\",\n        \"delete_memory\"\n      ]\n    }\n  }\n}\n```\n\n#### Supabase Storage Configuration (Cloned Repository)\n\n```json\n{\n  \"mcpServers\": {\n    \"mem0-mcp\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/absolute/path/to/mem0-mcp/build/index.js\"\n      ],\n      \"env\": {\n        \"SUPABASE_URL\": \"YOUR_SUPABASE_PROJECT_URL\",\n        \"SUPABASE_KEY\": \"YOUR_SUPABASE_ANON_KEY\",\n        \"OPENAI_API_KEY\": \"YOUR_OPENAI_API_KEY_HERE\",\n        \"DEFAULT_USER_ID\": \"user123\",\n        \"DEFAULT_AGENT_ID\": \"your-agent-id\",\n        \"DEFAULT_APP_ID\": \"your-app-id\"\n      },\n      \"disabled\": false,\n      \"alwaysAllow\": [\n        \"add_memory\",\n        \"search_memory\",\n        \"delete_memory\"\n      ]\n    }\n  }\n}\n```\n\n#### Local Storage Configuration (Cloned Repository)\n\n```json\n{\n  \"mcpServers\": {\n    \"mem0-mcp\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/absolute/path/to/mem0-mcp/build/index.js\"\n      ],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"YOUR_OPENAI_API_KEY_HERE\",\n        \"DEFAULT_USER_ID\": \"user123\"\n      },\n      \"disabled\": false,\n      \"alwaysAllow\": [\n        \"add_memory\",\n        \"search_memory\",\n        \"delete_memory\"\n      ]\n    }\n  }\n}\n```\n\n**Important Notes:**\n1. Replace `/absolute/path/to/mem0-mcp/` with the actual absolute path to your cloned repository\n2. Use the `build/index.js` file, not the `src/index.ts` file\n3. The MCP server requires clean stdout for protocol communication - any libraries or code that writes to stdout may interfere with the protocol\n\n## Supabase Setup 🗄️\n\nIf you choose to use Supabase storage mode, you'll need to set up your Supabase database with the required table.\n\n### 1. Create a Supabase Project\n\n1. Go to [supabase.com](https://supabase.com) and create a new project\n2. Note your project URL and anon key from the project settings\n\n### 2. Run SQL Migrations\n\nRun these SQL commands in your Supabase SQL Editor:\n\n```sql\n-- Enable the vector extension\ncreate extension if not exists vector;\n\n-- Create the memories table\ncreate table if not exists memories (\n  id text primary key,\n  embedding vector(1536),\n  metadata jsonb,\n  created_at timestamp with time zone default timezone('utc', now()),\n  updated_at timestamp with time zone default timezone('utc', now())\n);\n\n-- Create the vector similarity search function\ncreate or replace function match_vectors(\n  query_embedding vector(1536),\n  match_count int,\n  filter jsonb default '{}'::jsonb\n)\nreturns table (\n  id text,\n  similarity float,\n  metadata jsonb\n)\nlanguage plpgsql\nas $$\nbegin\n  return query\n  select\n    t.id::text,\n    1 - (t.embedding <=> query_embedding) as similarity,\n    t.metadata\n  from memories t\n  where case\n    when filter::text = '{}'::text then true\n    else t.metadata @> filter\n  end\n  order by t.embedding <=> query_embedding\n  limit match_count;\nend;\n$$;\n\n-- Create the memory_history table for history tracking\ncreate table if not exists memory_history (\n  id text primary key,\n  memory_id text not null,\n  previous_value text,\n  new_value text,\n  action text not null,\n  created_at timestamp with time zone default timezone('utc', now()),\n  updated_at timestamp with time zone,\n  is_deleted integer default 0\n);\n```\n\n### 3. Set Environment Variables\n\nAdd these to your MCP configuration:\n\n- `SUPABASE_URL`: Your Supabase project URL (e.g., `https://your-project.supabase.co`)\n- `SUPABASE_KEY`: Your Supabase anon key\n- `OPENAI_API_KEY`: Your OpenAI API key (for embeddings)\n\n### Benefits of Supabase Mode\n\n✅ **Persistent Storage** - Data survives server restarts\n✅ **Free Tier Available** - Generous free tier for development\n✅ **Self-Hostable** - Can run your own Supabase instance\n✅ **Scalable** - Grows with your needs\n✅ **SQL Access** - Direct database access for advanced queries\n✅ **Real-time Features** - Built-in real-time subscriptions\n\n## Parameter Configuration 🎯\n\n### Understanding Mem0 Parameters\n\nThe server uses four key parameters to organize and scope memories:\n\n1. **`userId`** - Identifies the user (required)\n2. **`agentId`** - Identifies the LLM/agent making the tool call (optional)\n3. **`appId`** - Identifies the user's project/application - **this controls project scope!** (optional)\n4. **`sessionId`** - Identifies the conversation session (maps to `run_id` in Mem0) (optional)\n\n### Environment Variable Fallbacks 🔄\n\nThe MCP server supports environment variable fallbacks for user identification and project settings:\n\n- `DEFAULT_USER_ID`: Fallback user ID when not provided in tool calls\n- `DEFAULT_AGENT_ID`: Fallback agent ID for identifying the LLM/agent\n- `DEFAULT_APP_ID`: Fallback app ID for project scoping\n\n#### **Priority Order (Important!)**\n1. **Tool Parameters** (highest priority) - Values provided by the LLM in tool calls\n2. **Environment Variables** (fallback) - Values from your MCP configuration\n\n#### **Example Behavior:**\n```json\n// Your MCP config\n\"env\": {\n  \"DEFAULT_USER_ID\": \"john-doe\",\n  \"DEFAULT_AGENT_ID\": \"my-assistant\",\n  \"DEFAULT_APP_ID\": \"my-project\"\n}\n```\n\n**If LLM provides parameters:**\n```json\n{\n  \"tool\": \"add_memory\",\n  \"arguments\": {\n    \"content\": \"Remember this\",\n    \"userId\": \"session-123\",        // ← Overrides DEFAULT_USER_ID\n    \"agentId\": \"different-agent\",   // ← Overrides DEFAULT_AGENT_ID\n    \"appId\": \"special-project\"      // ← Overrides DEFAULT_APP_ID\n    // sessionId omitted           // ← No fallback, will be undefined\n  }\n}\n```\n**Result**: Uses `session-123`, `different-agent`, and `special-project`\n\n**If LLM omits parameters:**\n```json\n{\n  \"tool\": \"add_memory\",\n  \"arguments\": {\n    \"content\": \"Remember this\"\n    // All IDs omitted - uses environment variables\n  }\n}\n```\n**Result**: Uses `john-doe`, `my-assistant`, and `my-project`\n\n#### **Controlling LLM Behavior**\nTo ensure your environment variables are used, instruct your LLM:\n- *\"Use the default user ID configured in the environment\"*\n- *\"Don't specify userId, agentId, or appId parameters\"*\n- *\"Let the server use the configured defaults\"*\n\n#### **System Prompt Recommendation**\nFor best results, include instructions in your system prompt like:\n\n```\nWhen creating memories, use:\n- agentId: \"my-assistant\"\n- appId: \"my-project\"\n- sessionId: \"current-conversation-id\"\n```\n\nExample configuration using `DEFAULT_USER_ID`:\n\n```json\n{\n  \"mcpServers\": {\n    \"mem0-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@pinkpixel/mem0-mcp\"\n      ],\n      \"env\": {\n        \"MEM0_API_KEY\": \"YOUR_MEM0_API_KEY_HERE\",\n        \"DEFAULT_USER_ID\": \"user123\",\n        \"ORG_ID\": \"your-org-id\",\n        \"PROJECT_ID\": \"your-project-id\"\n      }\n    }\n  }\n}\n```\n\nOr when running directly with `node`:\n\n```bash\ngit clone https://github.com/pinkpixel-dev/mem0-mcp\ncd mem0-mcp\nnpm install\nnpm run build\n```\n\n```json\n{\n  \"mcpServers\": {\n    \"mem0-mcp\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"path/to/mem0-mcp/build/index.js\"\n      ],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"YOUR_OPENAI_API_KEY_HERE\",\n        \"DEFAULT_USER_ID\": \"user123\"\n      }\n    }\n  }\n}\n```\n\n## Storage Mode Comparison 🔄\n\n### Cloud Storage (Mem0 API) ☁️\n* **Persistent by default** - Your memories remain available across sessions and server restarts\n* **No local database required** - All data is stored on Mem0's servers\n* **Higher retrieval quality** - Uses Mem0's optimized search algorithms\n* **Additional fields** - Supports `agent_id` and `threshold` parameters\n* **Fully managed** - No setup or maintenance required\n* **Requires** - A Mem0 API key\n\n### Supabase Storage 🗄️\n* **Persistent storage** - Data is stored in your Supabase PostgreSQL database\n* **Free tier available** - Generous free tier for development and small projects\n* **Self-hostable** - Can run your own Supabase instance for complete control\n* **SQL access** - Direct database access for advanced queries and analytics\n* **Scalable** - Grows with your needs, from free tier to enterprise\n* **Vector search** - Uses pgvector extension for efficient similarity search\n* **Real-time features** - Built-in real-time subscriptions and webhooks\n* **Requires** - Supabase project setup and OpenAI API key for embeddings\n\n### Local Storage (OpenAI API) 💾\n* **In-memory by default** - Data is stored only in RAM and is **not persistent long-term**. While some caching may occur, you should not rely on this for permanent storage.\n* **Data loss risk** - Memory data will be lost on server restart, system reboot, or if the process is terminated\n* **Recommended for** - Development, testing, or temporary use only\n* **For persistent storage** - Use the Cloud Storage or Supabase options if you need reliable long-term memory\n* **Uses OpenAI embeddings** - For vector search functionality\n* **Self-contained** - All data stays on your machine\n* **Requires** - An OpenAI API key\n\n## Development 💻\n\nClone the repository and install dependencies:\n\n```bash\ngit clone https://github.com/pinkpixel-dev/mem0-mcp\ncd mem0-mcp\nnpm install\n```\n\nBuild the server:\n\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild on file changes:\n\n```bash\nnpm run watch\n```\n\n## Debugging 🐞\n\nSince MCP servers communicate over stdio, debugging can be challenging. Here are some approaches:\n\n1. **Use the MCP Inspector**: This tool can monitor the MCP protocol communication:\n```bash\nnpm run inspector\n```\n\n2. **Console Logging**: When adding console logs, always use `console.error()` instead of `console.log()` to avoid interfering with the MCP protocol\n\n3. **Environment Files**: Use a `.env` file for local development to simplify setting API keys and other configuration options\n\n## Technical Implementation Notes 🔧\n\n### Advanced Mem0 API Parameters\n\nWhen using the Cloud Storage mode with the Mem0 API, you can leverage additional parameters for more sophisticated memory management. While not explicitly exposed in the tool schema, these can be included in the `metadata` object when adding memories:\n\n#### Advanced Parameters for `add_memory`:\n\n| Parameter | Type | Description |\n|-----------|------|-------------|\n| `metadata` | object | Store additional context about the memory (e.g., location, time, identifiers). This can be used for filtering during retrieval. |\n| `includes` | string | Specific preferences to include in the memory. |\n| `excludes` | string | Specific preferences to exclude from the memory. |\n| `infer` | boolean | Whether to infer memories or directly store messages (default: true). |\n| `output_format` | string | Format version, either v1.0 (default, deprecated) or v1.1 (recommended). |\n| `custom_categories` | object | List of categories with names and descriptions. |\n| `custom_instructions` | string | Project-specific guidelines for handling and organizing memories. |\n| `immutable` | boolean | Whether the memory is immutable (default: false). |\n| `expiration_date` | string | When the memory will expire (format: YYYY-MM-DD). |\n| `org_id` | string | Organization ID associated with this memory. |\n| `project_id` | string | Project ID associated with this memory. |\n| `version` | string | Memory version (v1 is deprecated, v2 recommended for new applications). |\n\nTo use these parameters with the MCP server, include them in your metadata object when calling the `add_memory` tool. For example:\n\n```json\n{\n  \"content\": \"Important information to remember\",\n  \"userId\": \"user123\",\n  \"sessionId\": \"project-abc\",\n  \"metadata\": {\n    \"includes\": \"important context\",\n    \"excludes\": \"sensitive data\",\n    \"immutable\": true,\n    \"expiration_date\": \"2025-12-31\",\n    \"custom_instructions\": \"Prioritize this memory for financial questions\",\n    \"version\": \"v2\"\n  }\n}\n```\n\n#### Advanced Parameters for `search_memory`:\n\nThe Mem0 v2 search API offers powerful filtering capabilities that can be utilized through the `filters` parameter:\n\n| Parameter | Type | Description |\n|-----------|------|-------------|\n| `filters` | object | Complex filters with logical operators and comparison conditions |\n| `top_k` | integer | Number of top results to return (default: 10) |\n| `fields` | string[] | Specific fields to include in the response |\n| `rerank` | boolean | Whether to rerank the memories (default: false) |\n| `keyword_search` | boolean | Whether to search based on keywords (default: false) |\n| `filter_memories` | boolean | Whether to filter the memories (default: false) |\n| `threshold` | number | Minimum similarity threshold for results (default: 0.3) |\n| `org_id` | string | Organization ID for filtering memories |\n| `project_id` | string | Project ID for filtering memories |\n\nThe `filters` parameter supports complex logical operations (AND, OR) and various comparison operators:\n\n| Operator | Description |\n|----------|-------------|\n| `in` | Matches any of the values specified |\n| `gte` | Greater than or equal to |\n| `lte` | Less than or equal to |\n| `gt` | Greater than |\n| `lt` | Less than |\n| `ne` | Not equal to |\n| `icontains` | Case-insensitive containment check |\n\nExample of using complex filters with the `search_memory` tool:\n\n```json\n{\n  \"query\": \"What are Alice's hobbies?\",\n  \"userId\": \"user123\",\n  \"filters\": {\n    \"AND\": [\n      {\n        \"user_id\": \"alice\"\n      },\n      {\n        \"agent_id\": {\"in\": [\"travel-agent\", \"sports-agent\"]}\n      }\n    ]\n  },\n  \"threshold\": 0.5,\n  \"top_k\": 5\n}\n```\n\nThis would search for memories related to Alice's hobbies where the user_id is \"alice\" AND the agent_id is either \"travel-agent\" OR \"sports-agent\", returning at most 5 results with a similarity score of at least 0.5.\n\nFor more detailed information on these parameters, refer to the [Mem0 API documentation](https://mem0.ai).\n\n### SafeLogger\n\nThe MCP server implements a `SafeLogger` class that selectively redirects console.log calls from the mem0ai library to stderr without disrupting MCP protocol:\n\n- Intercepts console.log calls and examines stack traces to determine source\n- Only redirects log calls from mem0ai library or our own code\n- Preserves clean stdout for MCP protocol communication\n- Automatically cleans up resources on process exit\n\nThis allows proper functioning within MCP clients while maintaining useful debug information.\n\n### Environment Variables\n\nThe server recognizes several environment variables that control its behavior:\n\n- `MEM0_API_KEY`: API key for cloud storage mode\n- `OPENAI_API_KEY`: API key for local storage mode (embeddings)\n- `DEFAULT_USER_ID`: Default user ID for memory operations\n- `DEFAULT_AGENT_ID`: Default agent ID for identifying the LLM/agent\n- `DEFAULT_APP_ID`: Default app ID for project scoping\n\n**Important Notes:**\n- **Session IDs** are passed as tool parameters (e.g., `\"sessionId\": \"my-session\"`), not environment variables\n- When using the tools, parameters provided directly (e.g., `agentId`, `appId`, `sessionId`) take precedence over environment variables, giving you maximum flexibility\n- **org_id and project_id are set automatically by Mem0** and cannot be changed by users - use `appId` for project scoping instead\n\n---\n\nMade with ❤️ by Pink Pixel\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "memory",
        "mem0",
        "pinkpixel",
        "memory management",
        "memory ai",
        "provides memory"
      ],
      "category": "memory-management"
    },
    "rmtech1--txtai-assistant-mcp": {
      "owner": "rmtech1",
      "name": "txtai-assistant-mcp",
      "url": "https://github.com/rmtech1/txtai-assistant-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/rmtech1.webp",
      "description": "Provides semantic memory and search capabilities for AI assistants, enabling the storage, retrieval, and management of text-based memories. Enhances context awareness during conversations through advanced features like tagging and health monitoring.",
      "stars": 11,
      "forks": 3,
      "license": "Other",
      "language": "Python",
      "updated_at": "2025-10-02T06:40:36Z",
      "readme_content": "# TxtAI Assistant MCP\n\nA Model Context Protocol (MCP) server implementation for semantic search and memory management using [txtai](https://github.com/neuml/txtai). This server provides a robust API for storing, retrieving, and managing text-based memories with semantic search capabilities.\n\n## About txtai\n\nThis project is built on top of [txtai](https://github.com/neuml/txtai), an excellent open-source AI-powered search engine created by [NeuML](https://github.com/neuml). txtai provides:\n\n- 🔍 All-in-one semantic search solution\n- 🧠 Neural search with transformers\n- 💡 Zero-shot text classification\n- 🔄 Text extraction and embeddings\n- 🌐 Multi-language support\n- 🚀 High performance and scalability\n\nWe extend txtai's capabilities by integrating it with the Model Context Protocol (MCP), enabling AI assistants like Claude and Cline to leverage its powerful semantic search capabilities. Special thanks to the txtai team for creating such a powerful and flexible tool.\n\n## Features\n\n- 🔍 Semantic search across stored memories\n- 💾 Persistent storage with file-based backend\n- 🏷️ Tag-based memory organization and retrieval\n- 📊 Memory statistics and health monitoring\n- 🔄 Automatic data persistence\n- 📝 Comprehensive logging\n- 🔒 Configurable CORS settings\n- 🤖 Integration with Claude and Cline AI\n\n## Prerequisites\n\n- Python 3.8 or higher\n- pip (Python package installer)\n- virtualenv (recommended)\n\n## Installation\n\n1. Clone this repository:\n```bash\ngit clone https://github.com/yourusername/txtai-assistant-mcp.git\ncd txtai-assistant-mcp\n```\n\n2. Run the start script:\n```bash\n./scripts/start.sh\n```\n\nThe script will:\n- Create a virtual environment\n- Install required dependencies\n- Set up necessary directories\n- Create a configuration file from template\n- Start the server\n\n## Configuration\n\nThe server can be configured using environment variables in the `.env` file. A template is provided at `.env.template`:\n\n```ini\n# Server Configuration\nHOST=0.0.0.0\nPORT=8000\n\n# CORS Configuration\nCORS_ORIGINS=*\n\n# Logging Configuration\nLOG_LEVEL=DEBUG\n\n# Memory Configuration\nMAX_MEMORIES=0\n```\n\n## Integration with Claude and Cline AI\n\nThis TxtAI Assistant can be used as an MCP server with Claude and Cline AI to enhance their capabilities with semantic memory and search functionality.\n\n### Configuration for Claude\n\nTo use this server with Claude, add it to Claude's MCP configuration file (typically located at `~/Library/Application Support/Claude/claude_desktop_config.json` on macOS):\n\n```json\n{\n  \"mcpServers\": {\n    \"txtai-assistant\": {\n      \"command\": \"path/to/txtai-assistant-mcp/scripts/start.sh\",\n      \"env\": {}\n    }\n  }\n}\n```\n\n### Configuration for Cline\n\nTo use with Cline, add the server configuration to Cline's MCP settings file (typically located at `~/Library/Application Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"txtai-assistant\": {\n      \"command\": \"path/to/txtai-assistant-mcp/scripts/start.sh\",\n      \"env\": {}\n    }\n  }\n}\n```\n\n### Available MCP Tools\n\nOnce configured, the following tools become available to Claude and Cline:\n\n1. `store_memory`: Store new memory content with metadata and tags\n```json\n{\n  \"content\": \"Memory content to store\",\n  \"metadata\": {\n    \"source\": \"conversation\",\n    \"timestamp\": \"2023-01-01T00:00:00Z\"\n  },\n  \"tags\": [\"important\", \"context\"],\n  \"type\": \"conversation\"\n}\n```\n\n2. `retrieve_memory`: Retrieve memories based on semantic search\n```json\n{\n  \"query\": \"search query\",\n  \"n_results\": 5\n}\n```\n\n3. `search_by_tag`: Search memories by tags\n```json\n{\n  \"tags\": [\"important\", \"context\"]\n}\n```\n\n4. `delete_memory`: Delete a specific memory by content hash\n```json\n{\n  \"content_hash\": \"hash_value\"\n}\n```\n\n5. `get_stats`: Get database statistics\n```json\n{}\n```\n\n6. `check_health`: Check database and embedding model health\n```json\n{}\n```\n\n### Usage Examples\n\nIn Claude or Cline, you can use these tools through the MCP protocol:\n\n```python\n# Store a memory\n<use_mcp_tool>\n<server_name>txtai-assistant</server_name>\n<tool_name>store_memory</tool_name>\n<arguments>\n{\n  \"content\": \"Important information to remember\",\n  \"tags\": [\"important\"]\n}\n</arguments>\n</use_mcp_tool>\n\n# Retrieve memories\n<use_mcp_tool>\n<server_name>txtai-assistant</server_name>\n<tool_name>retrieve_memory</tool_name>\n<arguments>\n{\n  \"query\": \"what was the important information?\",\n  \"n_results\": 5\n}\n</arguments>\n</use_mcp_tool>\n```\n\nThe AI will automatically use these tools to maintain context and retrieve relevant information during conversations.\n\n## API Endpoints\n\n### Store Memory\n```http\nPOST /store\n```\nStore a new memory with optional metadata and tags.\n\n**Request Body:**\n```json\n{\n    \"content\": \"Memory content to store\",\n    \"metadata\": {\n        \"source\": \"example\",\n        \"timestamp\": \"2023-01-01T00:00:00Z\"\n    },\n    \"tags\": [\"example\", \"memory\"],\n    \"type\": \"general\"\n}\n```\n\n### Search Memories\n```http\nPOST /search\n```\nSearch memories using semantic search.\n\n**Request Body:**\n```json\n{\n    \"query\": \"search query\",\n    \"n_results\": 5,\n    \"similarity_threshold\": 0.7\n}\n```\n\n### Search by Tags\n```http\nPOST /search_tags\n```\nSearch memories by tags.\n\n**Request Body:**\n```json\n{\n    \"tags\": [\"example\", \"memory\"]\n}\n```\n\n### Delete Memory\n```http\nDELETE /memory/{content_hash}\n```\nDelete a specific memory by its content hash.\n\n### Get Statistics\n```http\nGET /stats\n```\nGet system statistics including memory counts and tag distribution.\n\n### Health Check\n```http\nGET /health\n```\nCheck the health status of the server.\n\n## Directory Structure\n\n```\ntxtai-assistant-mcp/\n├── server/\n│   ├── main.py           # Main server implementation\n│   └── requirements.txt  # Python dependencies\n├── scripts/\n│   └── start.sh         # Server startup script\n├── data/                # Data storage directory\n├── logs/                # Log files directory\n├── .env.template        # Environment configuration template\n└── README.md           # This file\n```\n\n## Data Storage\n\nMemories and tags are stored in JSON files in the `data` directory:\n- `memories.json`: Contains all stored memories\n- `tags.json`: Contains the tag index\n\n## Logging\n\nLogs are stored in the `logs` directory. The default log file is `server.log`.\n\n## Development\n\nTo contribute to this project:\n\n1. Fork the repository\n2. Create a feature branch\n3. Make your changes\n4. Submit a pull request\n\n## Error Handling\n\nThe server implements comprehensive error handling:\n- Invalid requests return appropriate HTTP status codes\n- Errors are logged with stack traces\n- User-friendly error messages are returned in responses\n\n## Security Considerations\n\n- CORS settings are configurable via environment variables\n- File paths are sanitized to prevent directory traversal\n- Input validation is performed on all endpoints\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## Support\n\nIf you encounter any issues or have questions, please file an issue on the GitHub repository.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "txtai",
        "memory",
        "rmtech1",
        "txtai assistant",
        "semantic memory",
        "rmtech1 txtai"
      ],
      "category": "memory-management"
    },
    "shaneholloman--mcp-knowledge-graph": {
      "owner": "shaneholloman",
      "name": "mcp-knowledge-graph",
      "url": "https://github.com/shaneholloman/mcp-knowledge-graph",
      "imageUrl": "/freedevtools/mcp/pfp/shaneholloman.webp",
      "description": "Enables persistent memory for AI models using a local knowledge graph, allowing them to remember user information across chats. Customizable memory paths enhance the management of stored knowledge.",
      "stars": 674,
      "forks": 87,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-10-03T01:16:29Z",
      "readme_content": "# MCP Knowledge Graph\n\n**Persistent memory for AI models through a local knowledge graph.**\n\nStore and retrieve information across conversations using entities, relations, and observations. Works with Claude Code/Desktop and any MCP-compatible AI platform.\n\n## Why \".aim\" and \"aim_\" prefixes?\n\nAIM stands for **AI Memory** - the core concept of this knowledge graph system. The three AIM elements provide clear organization and safety:\n\n- **`.aim` directories**: Keep AI memory files organized and easily identifiable\n- **`aim_` tool prefixes**: Group related memory functions together in multi-tool setups\n- **`_aim` safety markers**: Each memory file starts with `{\"type\":\"_aim\",\"source\":\"mcp-knowledge-graph\"}` to prevent accidental overwrites of unrelated JSONL files\n\nThis consistent AIM naming makes it obvious which directories, tools, and files belong to our AI memory system.\n\n## Storage Logic\n\n**File Location Priority:**\n\n1. **Project with `.aim`** - Uses `.aim/memory.jsonl` (project-local)\n2. **No project/no .aim** - Uses configured global directory\n3. **Contexts** - Adds suffix: `memory-work.jsonl`, `memory-personal.jsonl`\n\n**Safety System:**\n\n- Every memory file starts with `{\"type\":\"_aim\",\"source\":\"mcp-knowledge-graph\"}`\n- System refuses to write to files without this marker\n- Prevents accidental overwrite of unrelated JSONL files\n\n## Master Database Concept\n\n**The master database is your primary memory store** - used by default when no specific database is requested. It's always named `default` in listings and stored as `memory.jsonl`.\n\n- **Default Behavior**: All memory operations use the master database unless you specify a different one\n- **Always Available**: Exists in both project-local and global locations\n- **Primary Storage**: Your main knowledge graph that persists across all conversations\n- **Named Databases**: Optional additional databases (`work`, `personal`, `health`) for organizing specific topics\n\n## Key Features\n\n- **Master Database**: Primary memory store used by default for all operations\n- **Multiple Databases**: Optional named databases for organizing memories by topic\n- **Project Detection**: Automatic project-local memory using `.aim` directories\n- **Location Override**: Force operations to use project or global storage\n- **Safe Operations**: Built-in protection against overwriting unrelated files\n- **Database Discovery**: List all available databases in both locations\n\n## Quick Start\n\n### Global Memory (Recommended)\n\nAdd to your `claude_desktop_config.json` or `.claude.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"memory\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"mcp-knowledge-graph\",\n        \"--memory-path\",\n        \"/Users/yourusername/.aim/\"\n      ]\n    }\n  }\n}\n```\n\nThis creates memory files in your specified directory:\n\n- `memory.jsonl` - **Master Database** (default for all operations)\n- `memory-work.jsonl` - Work database\n- `memory-personal.jsonl` - Personal database\n- etc.\n\n### Project-Local Memory\n\nIn any project, create a `.aim` directory:\n\n```bash\nmkdir .aim\n```\n\nNow memory tools automatically use `.aim/memory.jsonl` (project-local **master database**) instead of global storage when run from this project.\n\n## How AI Uses Databases\n\nOnce configured, AI models use the **master database by default** or can specify named databases with a `context` parameter. New databases are created automatically - no setup required:\n\n```json\n// Master Database (default - no context needed)\naim_create_entities({\n  entities: [{\n    name: \"John_Doe\",\n    entityType: \"person\",\n    observations: [\"Met at conference\"]\n  }]\n})\n\n// Work database\naim_create_entities({\n  context: \"work\",\n  entities: [{\n    name: \"Q4_Project\",\n    entityType: \"project\",\n    observations: [\"Due December 2024\"]\n  }]\n})\n\n// Personal database\naim_create_entities({\n  context: \"personal\",\n  entities: [{\n    name: \"Mom\",\n    entityType: \"person\",\n    observations: [\"Birthday March 15th\"]\n  }]\n})\n\n// Master database in specific location\naim_create_entities({\n  location: \"global\",\n  entities: [{\n    name: \"Important_Info\",\n    entityType: \"reference\",\n    observations: [\"Stored in global master database\"]\n  }]\n})\n```\n\n## File Organization\n\n**Global Setup:**\n\n```tree\n/Users/yourusername/.aim/\n├── memory.jsonl           # Master Database (default)\n├── memory-work.jsonl      # Work database\n├── memory-personal.jsonl  # Personal database\n└── memory-health.jsonl    # Health database\n```\n\n**Project Setup:**\n\n```tree\nmy-project/\n├── .aim/\n│   ├── memory.jsonl       # Project Master Database (default)\n│   └── memory-work.jsonl  # Project Work database\n└── src/\n```\n\n## Available Tools\n\n- `aim_create_entities` - Add new people, projects, events\n- `aim_create_relations` - Link entities together\n- `aim_add_observations` - Add facts to existing entities\n- `aim_search_nodes` - Find information by keyword\n- `aim_read_graph` - View entire memory\n- `aim_open_nodes` - Retrieve specific entities by name\n- `aim_list_databases` - Show all available databases and current location\n- `aim_delete_entities` - Remove entities\n- `aim_delete_observations` - Remove specific facts\n- `aim_delete_relations` - Remove connections\n\n### Parameters\n\n- `context` (optional) - Specify named database (`work`, `personal`, etc.). Defaults to **master database**\n- `location` (optional) - Force `project` or `global` storage location. Defaults to auto-detection\n\n## Database Discovery\n\nUse `aim_list_databases` to see all available databases:\n\n```json\n{\n  \"project_databases\": [\n    \"default\",      // Master Database (project-local)\n    \"project-work\"  // Named database\n  ],\n  \"global_databases\": [\n    \"default\",      // Master Database (global)\n    \"work\",\n    \"personal\",\n    \"health\"\n  ],\n  \"current_location\": \"project (.aim directory detected)\"\n}\n```\n\n**Key Points:**\n\n- **\"default\"** = Master Database in both locations\n- **Current location** shows whether you're using project or global storage\n- **Master database exists everywhere** - it's your primary memory store\n- **Named databases** are optional additions for specific topics\n\n## Configuration Examples\n\n**Important:** Always specify `--memory-path` to control where your memory files are stored.\n\n**Home directory:**\n\n```json\n{\n  \"mcpServers\": {\n    \"memory\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"mcp-knowledge-graph\",\n        \"--memory-path\",\n        \"/Users/yourusername/.aim\"\n      ]\n    }\n  }\n}\n```\n\n**Custom location (e.g., Dropbox):**\n\n```json\n{\n  \"mcpServers\": {\n    \"memory\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"mcp-knowledge-graph\",\n        \"--memory-path\",\n        \"/Users/yourusername/Dropbox/.aim\"\n      ]\n    }\n  }\n}\n```\n\n**Auto-approve all operations:**\n\n```json\n{\n  \"mcpServers\": {\n    \"memory\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"mcp-knowledge-graph\",\n        \"--memory-path\",\n        \"/Users/yourusername/.aim\"\n      ],\n      \"autoapprove\": [\n        \"aim_create_entities\",\n        \"aim_create_relations\",\n        \"aim_add_observations\",\n        \"aim_search_nodes\",\n        \"aim_read_graph\",\n        \"aim_open_nodes\",\n        \"aim_list_databases\"\n      ]\n    }\n  }\n}\n```\n\n## Troubleshooting\n\n**\"File does not contain required _aim safety marker\" error:**\n\n- The file may not belong to this system\n- Manual JSONL files need `{\"type\":\"_aim\",\"source\":\"mcp-knowledge-graph\"}` as first line\n- If you created the file manually, add the `_aim` marker or delete and let the system recreate it\n\n**Memories going to unexpected locations:**\n\n- Check if you're in a project directory with `.aim` folder (uses project-local storage)\n- Otherwise uses the configured global `--memory-path` directory\n- Use `aim_list_databases` to see all available databases and current location\n- Use `ls .aim/` or `ls /Users/yourusername/.aim/` to see your memory files\n\n**Too many similar databases:**\n\n- AI models try to use consistent names, but may create variations\n- Manually delete unwanted database files if needed\n- Encourage AI to use simple, consistent database names\n- **Remember**: Master database is always available as the default - named databases are optional\n\n## Requirements\n\n- Node.js 18+\n- MCP-compatible AI platform\n\n## License\n\nMIT\n",
      "npm_url": "https://www.npmjs.com/package/mcp-knowledge-graph",
      "npm_downloads": 9675,
      "keywords": [
        "memory",
        "knowledge",
        "persistent",
        "stored knowledge",
        "memory ai",
        "persistent memory"
      ],
      "category": "memory-management"
    },
    "sizzlebop--context-mcp": {
      "owner": "sizzlebop",
      "name": "context-mcp",
      "url": "https://github.com/sizzlebop/context-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/null.webp",
      "description": "A memory system that maintains and retrieves comprehensive project and conversation memory, enabling contextually aware AI assistance. It supports multiple memory types including short-term, long-term, episodic, and semantic memory for enhanced development workflows.",
      "stars": 0,
      "forks": 0,
      "license": "Unknown",
      "language": "Unknown",
      "updated_at": "",
      "readme_content": "",
      "npm_url": "https://www.npmjs.com/package/context-mcp",
      "npm_downloads": 0,
      "keywords": [
        "memory",
        "sizzlebop",
        "context",
        "conversation memory",
        "semantic memory",
        "context mcp"
      ],
      "category": "memory-management"
    },
    "spences10--mcp-memory-libsql": {
      "owner": "spences10",
      "name": "mcp-memory-libsql",
      "url": "https://github.com/spences10/mcp-memory-libsql",
      "imageUrl": "/freedevtools/mcp/pfp/spences10.webp",
      "description": "High-performance vector search and persistent memory system using libSQL, offering efficient knowledge storage and semantic search capabilities. Supports knowledge graph management and secure token-based authentication for accessing local and remote databases.",
      "stars": 71,
      "forks": 13,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-02T04:11:59Z",
      "readme_content": "# mcp-memory-libsql\n\nA high-performance, persistent memory system for the Model Context\nProtocol (MCP) powered by libSQL. This server provides vector search\ncapabilities and efficient knowledge storage using libSQL as the\nbacking store.\n\n<a href=\"https://glama.ai/mcp/servers/22lg4lq768\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/22lg4lq768/badge\" alt=\"Glama badge\" />\n</a>\n\n## Features\n\n- 🚀 High-performance vector search using libSQL\n- 💾 Persistent storage of entities and relations\n- 🔍 Semantic search capabilities\n- 🔄 Knowledge graph management\n- 🌐 Compatible with local and remote libSQL databases\n- 🔒 Secure token-based authentication for remote databases\n\n## Configuration\n\nThis server is designed to be used as part of an MCP configuration.\nHere are examples for different environments:\n\n### Cline Configuration\n\nAdd this to your Cline MCP settings:\n\n```json\n{\n\t\"mcpServers\": {\n\t\t\"mcp-memory-libsql\": {\n\t\t\t\"command\": \"npx\",\n\t\t\t\"args\": [\"-y\", \"mcp-memory-libsql\"],\n\t\t\t\"env\": {\n\t\t\t\t\"LIBSQL_URL\": \"file:/path/to/your/database.db\"\n\t\t\t}\n\t\t}\n\t}\n}\n```\n\n### Claude Desktop with WSL Configuration\n\nFor a detailed guide on setting up this server with Claude Desktop in\nWSL, see\n[Getting MCP Server Working with Claude Desktop in WSL](https://scottspence.com/posts/getting-mcp-server-working-with-claude-desktop-in-wsl).\n\nAdd this to your Claude Desktop configuration for WSL environments:\n\n```json\n{\n\t\"mcpServers\": {\n\t\t\"mcp-memory-libsql\": {\n\t\t\t\"command\": \"wsl.exe\",\n\t\t\t\"args\": [\n\t\t\t\t\"bash\",\n\t\t\t\t\"-c\",\n\t\t\t\t\"source ~/.nvm/nvm.sh && LIBSQL_URL=file:/path/to/database.db /home/username/.nvm/versions/node/v20.12.1/bin/npx mcp-memory-libsql\"\n\t\t\t]\n\t\t}\n\t}\n}\n```\n\n### Database Configuration\n\nThe server supports both local SQLite and remote libSQL databases\nthrough the LIBSQL_URL environment variable:\n\nFor local SQLite databases:\n\n```json\n{\n\t\"env\": {\n\t\t\"LIBSQL_URL\": \"file:/path/to/database.db\"\n\t}\n}\n```\n\nFor remote libSQL databases (e.g., Turso):\n\n```json\n{\n\t\"env\": {\n\t\t\"LIBSQL_URL\": \"libsql://your-database.turso.io\",\n\t\t\"LIBSQL_AUTH_TOKEN\": \"your-auth-token\"\n\t}\n}\n```\n\nNote: When using WSL, ensure the database path uses the Linux\nfilesystem format (e.g., `/home/username/...`) rather than Windows\nformat.\n\nBy default, if no URL is provided, it will use `file:/memory-tool.db`\nin the current directory.\n\n## API\n\nThe server implements the standard MCP memory interface with\nadditional vector search capabilities:\n\n- Entity Management\n  - Create/Update entities with embeddings\n  - Delete entities\n  - Search entities by similarity\n- Relation Management\n  - Create relations between entities\n  - Delete relations\n  - Query related entities\n\n## Architecture\n\nThe server uses a libSQL database with the following schema:\n\n- Entities table: Stores entity information and embeddings\n- Relations table: Stores relationships between entities\n- Vector search capabilities implemented using libSQL's built-in\n  vector operations\n\n## Development\n\n### Publishing\n\nDue to npm 2FA requirements, publishing needs to be done manually:\n\n1. Create a changeset (documents your changes):\n\n```bash\npnpm changeset\n```\n\n2. Version the package (updates version and CHANGELOG):\n\n```bash\npnpm changeset version\n```\n\n3. Publish to npm (will prompt for 2FA code):\n\n```bash\npnpm release\n```\n\n## Contributing\n\nContributions are welcome! Please read our contributing guidelines\nbefore submitting pull requests.\n\n## License\n\nMIT License - see the [LICENSE](LICENSE) file for details.\n\n## Acknowledgments\n\n- Built on the\n  [Model Context Protocol](https://github.com/modelcontextprotocol)\n- Powered by [libSQL](https://github.com/tursodatabase/libsql)\n",
      "npm_url": "https://www.npmjs.com/package/mcp-memory-libsql",
      "npm_downloads": 4827,
      "keywords": [
        "libsql",
        "databases",
        "memory",
        "memory libsql",
        "persistent memory",
        "using libsql"
      ],
      "category": "memory-management"
    },
    "stippi--code-assistant": {
      "owner": "stippi",
      "name": "code-assistant",
      "url": "https://github.com/stippi/code-assistant",
      "imageUrl": "/freedevtools/mcp/pfp/stippi.webp",
      "description": "Assists with code-related tasks by exploring codebases, managing file contents, and providing insights through summarization. Facilitates interactive communication for effective code manipulation.",
      "stars": 101,
      "forks": 17,
      "license": "MIT License",
      "language": "Rust",
      "updated_at": "2025-10-03T00:45:37Z",
      "readme_content": "# Code Assistant\n\n[![CI](https://github.com/stippi/code-assistant/actions/workflows/build.yml/badge.svg)](https://github.com/stippi/code-assistant/actions/workflows/build.yml)\n\nAn AI coding assistant built in Rust that provides both command-line and graphical interfaces for autonomous code analysis and modification.\n\n## Key Features\n\n**Multi-Modal Tool Execution**: Adapts to different LLM capabilities with pluggable tool invocation modes - native function calling, XML-style tags, and triple-caret blocks - ensuring compatibility across various AI providers.\n\n**Real-Time Streaming Interface**: Advanced streaming processors parse and display tool invocations as they stream from the LLM, with smart filtering to prevent unsafe tool combinations.\n\n**Session-Based Project Management**: Each chat session is tied to a specific project and maintains persistent state, working memory, and draft messages with attachment support.\n\n**Multiple Interface Options**: Choose between a modern GUI built on Zed's GPUI framework, traditional terminal interface, or headless MCP server mode for integration with MCP clients such as Claude Desktop.\n\n**Intelligent Project Exploration**: Autonomously builds understanding of codebases through working memory that tracks file structures, dependencies, and project context.\n\n**Auto-Loaded Repository Guidance**: Automatically includes `AGENTS.md` (or `CLAUDE.md` fallback) from the project root in the assistant's system context to align behavior with repo-specific instructions.\n\n## Installation\n\n```bash\ngit clone https://github.com/stippi/code-assistant\ncd code-assistant\ncargo build --release\n```\n\nThe binary will be available at `target/release/code-assistant`.\n\n## Project Configuration\n\nCreate `~/.config/code-assistant/projects.json` to define available projects:\n\n```jsonc\n{\n  \"code-assistant\": {\n    \"path\": \"/Users/<username>/workspace/code-assistant\",\n    \"format_on_save\": {\n      \"**/*.rs\": \"cargo fmt\" // Formats all files in project, so make sure files are already formatted\n    }\n  },\n  \"my-project\": {\n    \"path\": \"/Users/<username>/workspace/my-project\",\n    \"format_on_save\": {\n      \"**/*.ts\": \"prettier --write {path}\" // If the formatter accepts a path, provide \"{path}\"\n    }\n  }\n}\n```\n\n### Format-on-Save Feature\n\nThe _optional_ `format_on_save` field allows automatic formatting of files after modifications. It maps file patterns (using glob syntax) to shell commands:\n- Files matching the glob patterns will be automatically formatted after being modified by the assistant\n- The tool parameters are updated to reflect the formatted content, keeping the LLM's mental model in sync\n- This prevents edit conflicts caused by auto-formatting\n\nSee [docs/format-on-save-feature.md](docs/format-on-save-feature.md) for detailed documentation.\n\n**Important Notes:**\n- When launching from a folder not in this configuration, a temporary project is created automatically\n- The assistant has access to the current project (including temporary ones) plus all configured projects\n- Each chat session is permanently associated with its initial project and folder - this cannot be changed later\n- Tool syntax (native/xml/caret) is also fixed per session at creation time\n- The LLM provider selected at startup is used for the entire application session (UI switching planned for future releases)\n\n## Usage\n\n### GUI Mode (Recommended)\n\n```bash\n# Start with graphical interface\ncode-assistant --ui\n\n# Start GUI with initial task\ncode-assistant --ui --task \"Analyze the authentication system\"\n```\n\n### Terminal Mode\n\n```bash\n# Basic usage\ncode-assistant --task \"Explain the purpose of this codebase\"\n\n# With specific provider and model\ncode-assistant --task \"Add error handling\" --provider openai --model gpt-5\n```\n\n### MCP Server Mode\n\n```bash\ncode-assistant server\n```\n\n## Configuration\n\n<details>\n<summary>Claude Desktop Integration</summary>\n\nConfigure in Claude Desktop settings (**Developer** tab → **Edit Config**):\n\n```jsonc\n{\n  \"mcpServers\": {\n    \"code-assistant\": {\n      \"command\": \"/path/to/code-assistant/target/release/code-assistant\",\n      \"args\": [\"server\"],\n      \"env\": {\n        \"PERPLEXITY_API_KEY\": \"pplx-...\", // optional, enables perplexity_ask tool\n        \"SHELL\": \"/bin/zsh\" // your login shell, required when configuring \"env\" here\n      }\n    }\n  }\n}\n```\n</details>\n\n<details>\n<summary>LLM Providers</summary>\n\n**Anthropic** (default):\n```bash\nexport ANTHROPIC_API_KEY=\"sk-ant-...\"\ncode-assistant --provider anthropic --model claude-sonnet-4-20250514\n```\n\n**OpenAI**:\n```bash\nexport OPENAI_API_KEY=\"sk-...\"\ncode-assistant --provider openai --model gpt-4o\n```\n\n**SAP AI Core**:\nCreate `~/.config/code-assistant/ai-core.json`:\n```json\n{\n  \"auth\": {\n    \"client_id\": \"<service-key-client-id>\",\n    \"client_secret\": \"<service-key-client-secret>\",\n    \"token_url\": \"https://<your-url>/oauth/token\",\n    \"api_base_url\": \"https://<your-url>/v2/inference\"\n  },\n  \"models\": {\n    \"claude-sonnet-4\": \"<deployment-id>\"\n  }\n}\n```\n\n**Ollama**:\n```bash\ncode-assistant --provider ollama --model llama2 --num-ctx 4096\n```\n\n**Other providers**: Vertex AI (Google), OpenRouter, Groq, MistralAI\n</details>\n\n<details>\n<summary>Advanced Options</summary>\n\n**Tool Syntax Modes**:\n- `--tool-syntax native`: Use the provider's built-in tool calling (most reliable, but streaming of parameters depends on provider)\n- `--tool-syntax xml`: XML-style tags for streaming of parameters\n- `--tool-syntax caret`: Triple-caret blocks for token-efficency and streaming of parameters\n\n**Session Recording**:\n```bash\n# Record session (Anthropic only)\ncode-assistant --record session.json --task \"Optimize database queries\"\n\n# Playback session\ncode-assistant --playback session.json --fast-playback\n```\n\n**Other Options**:\n- `--continue-task`: Resume from previous session state\n- `--use-diff-format`: Enable alternative diff format for file editing\n- `--verbose`: Enable detailed logging\n- `--base-url`: Custom API endpoint\n</details>\n\n## Architecture Highlights\n\nThe code-assistant features several innovative architectural decisions:\n\n**Adaptive Tool Syntax**: Automatically generates different system prompts and streaming processors based on the target LLM's capabilities, allowing the same core logic to work across providers with varying function calling support.\n\n**Smart Tool Filtering**: Real-time analysis of tool invocation patterns prevents logical errors like attempting to edit files before reading them, with the ability to truncate responses mid-stream when unsafe combinations are detected.\n\n**Multi-Threaded Streaming**: Sophisticated async architecture that handles real-time parsing of tool invocations while maintaining responsive UI updates and proper state management across multiple chat sessions.\n\n## Contributing\n\nContributions are welcome! The codebase demonstrates advanced patterns in async Rust, AI agent architecture, and cross-platform UI development.\n\n## Roadmap\n\nThis section is not really a roadmap, as the items are in no particular order.\nBelow are some topics that are likely the next focus.\n\n- **Block Replacing in Changed Files**: When streaming a tool use block, we already know the LLM attempts to use `replace_in_file` and we know in which file quite early.\n  If we also know this file has changed since the LLM last read it, we can block the attempt with an appropriate error message.\n- **Compact Tool Use Failures**: When the LLM produces an invalid tool call, or a mismatching search block, we should be able to strip the failed attempt from the message history, saving tokens.\n- **Improve UI**: There are various ways in which the UI can be improved.\n- **Add Memory Tools**: Add tools that facilitate building up a knowledge base useful work working in a given project.\n- **Security**: Ideally, the execution for all tools would run in some sort of sandbox that restricts access to the files in the project tracked by git.\n  Currently, the tools reject absolute paths, but do not check whether the relative paths point outside the project or try to access git-ignored files.\n  The `execute_command` tool runs a shell with the provided command line, which at the moment is completely unchecked.\n- **Fuzzy matching search blocks**: Investigate the benefit of fuzzy matching search blocks.\n  Currently, files are normalized (always `\\n` line endings, no trailing white space).\n  This increases the success rate of matching search blocks quite a bit, but certain ways of fuzzy matching might increase the success even more.\n  Failed matches introduce quite a bit of inefficiency, since they almost always trigger the LLM to re-read a file.\n  Even when the error output of the `replace_in_file` tool includes the complete file and tells the LLM *not* to re-read the file.\n- **Edit user messages**: Editing a user message should create a new branch in the session.\n  The user should still be able to toggle the active banches.\n- **Select in messages**: Allow to copy/paste from any message in the session.\n",
      "npm_url": "https://www.npmjs.com/package/code-assistant-mcp",
      "npm_downloads": 730,
      "keywords": [
        "codebases",
        "code",
        "memory",
        "code assistant",
        "stippi code",
        "exploring codebases"
      ],
      "category": "memory-management"
    },
    "t3ta--memory-bank-mcp-server": {
      "owner": "t3ta",
      "name": "memory-bank-mcp-server",
      "url": "https://github.com/t3ta/memory-bank-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/t3ta.webp",
      "description": "Manage project documentation and context effectively across sessions with structured memory banks in JSON format. Facilitate consistent knowledge retention for AI agents and support multilingual documentation through a powerful API for document management and retrieval.",
      "stars": 11,
      "forks": 1,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-06-29T07:39:48Z",
      "readme_content": "# Memory Bank MCP Server\n\nA Memory Bank implementation for managing project documentation and context\nacross sessions using the Model Context Protocol (MCP). This server helps AI agents\nlike Claude maintain consistent project knowledge through global and branch-specific\nmemory banks stored in a structured JSON format.\n\nThis project is inspired by\n[Cline Memory Bank](https://github.com/nickbaumann98/cline_docs/blob/main/prompting/custom%20instructions%20library/cline-memory-bank.md)\nfrom the [nickbaumann98/cline_docs](https://github.com/nickbaumann98/cline_docs)\nrepository.\n\n## Packages\n\nThis repository is a monorepo managed with Yarn Workspaces. It contains the following packages:\n\n- **[`packages/mcp`](./packages/mcp/README.md)**: The core MCP server implementation. Contains the main logic for handling memory bank operations, MCP tool execution, and server startup.\n- **[`packages/schemas`](./packages/schemas/README.md)**: Defines the JSON schemas used for memory bank documents (e.g., `memory_document_v2`).\n- **[`packages/vscode-extension`](./packages/vscode-extension/README.md)**: A VSCode extension providing integration with the Memory Bank MCP server (details TBD).\n\n## Getting Started\n\n### Prerequisites\n\n- Node.js (see `.tool-versions` for recommended version)\n- Yarn (v1.x)\n\n### Installation\n\nClone the repository and install dependencies from the root directory:\n\n```bash\ngit clone https://github.com/t3ta/memory-bank-mcp-server.git\ncd memory-bank-mcp-server\nyarn install\n```\n\n### Running the MCP Server\n\nYou can run the MCP server directly from the monorepo:\n\n```bash\n# From the monorepo root directory\nyarn workspace @memory-bank/mcp start --docs /path/to/your/docs\n```\n\nReplace `/path/to/your/docs` with the actual path to your project's documentation directory (where `global-memory-bank` and `branch-memory-bank` will reside or be created).\n\nSee the [`packages/mcp/README.md`](./packages/mcp/README.md) for more details on running the server and its options.\n\n## Development\n\n- **Build all packages:** `yarn build`\n- **Run tests for all packages:** `yarn test`\n- **Lint code:** `yarn lint`\n\nRefer to the README file within each package directory for package-specific development instructions.\n\n## License\n\nThis project is licensed under the MIT License. See the LICENSE file for details.\n",
      "npm_url": "https://www.npmjs.com/package/memory-bank-mcp-server",
      "npm_downloads": 0,
      "keywords": [
        "documentation",
        "t3ta",
        "document",
        "management t3ta",
        "document management",
        "t3ta memory"
      ],
      "category": "memory-management"
    },
    "tejpalvirk--contextmanager": {
      "owner": "tejpalvirk",
      "name": "contextmanager",
      "url": "https://github.com/tejpalvirk/contextmanager",
      "imageUrl": "/freedevtools/mcp/pfp/tejpalvirk.webp",
      "description": "Track courses, assignments, and exams while optimizing study sessions and monitoring progress through a structured knowledge graph. Manage deadlines and priorities effectively within an academic context.",
      "stars": 7,
      "forks": 4,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-07-11T04:46:29Z",
      "readme_content": "# MCP Context Manager\n\nA collection of Model Context Protocol (MCP) servers to enhance AI models with persistent context across work sessions throughout the project lifecycle. \n\nContext for each project is stored in a domain-specific knowledge graph handled by the domain's server. All domain servers can be managed through a central Context Manager that provides unified access. \n\nEach domain server is also a standalone MCP Server that you can use on its own without the Context Manager.\n\n## Features\n\n- **Persistent Context**: Easily `buildcontext`, `loadcontext`, and `deletecontext` as you progress from idea to production/publication/completion\n- **Efficienct Access**: Let AI models grab the exact context they need when they need it\n- **Session Management**: \n  1. `startsession` tool to get an overview of what you've been working on in past sessions\n  2. `endsession` tool to analyze the entire session and update knowledge graph for future sessions\n- **Cross-Domain Support**: Work with multiple knowledge domains through a single interface, including creating relationships between entities in different domains\n\n## Why knowledge graphs?\n\nTo free up the context window (performance), and minimize token cost (efficiency).\n\n## Available Servers\n\nThe contextmanager orchestrates several domain-specific MCP servers:\n\n1. **Developer MCP Server**: software development context with entities like projects, components, and tasks. Includes status tracking (inactive, active, complete), priority management (high, low), and task sequencing through precedes relations.\n\n2. **Project MCP Server**: project management context with entities like projects, tasks, and resources. Features status management (inactive, active, complete), priority assignment (high, low), and task sequencing capabilities.\n\n3. **Student MCP Server**: educational context with entities like courses, assignments, and exams. Supports tracking status (active, completed, pending, abandoned), prioritizing assignments (high, low), and creating learning sequences.\n\n4. **Qualitative Research MCP Server**: qualitative research context with entities like studies, participants, and interviews. Includes research activity status tracking (active, completed, pending, abandoned), priority management (high, low), and analysis sequencing.\n\n5. **Quantitative Research MCP Server**: quantitative research context with entities like datasets, variables, and analyses. Features status management (active, completed, pending, abandoned), priority assignment (high, low), and sequential process management.\n\nFor detailed documentation on each domain server, see the README files in their respective directories:\n- [Developer Server](./developer/README.md)\n- [Project Server](./project/README.md)\n- [Student Server](./student/README.md)\n- [Qualitative Research Server](./qualitativeresearch/README.md)\n- [Quantitative Research Server](./quantitativeresearch/README.md)\n\n## Context Manager Benefits\n\nThe Context Manager provides:\n\n- **Unified Interface**: Access all domain servers through a single interface.\n- **Smart Routing**: Automatically routes requests to the appropriate domain server.\n- **Cross-Domain Context**: Maintains references across different domains.\n- **Consistent Status Management**: Standardized approach to status tracking across domains.\n- **Unified Priority System**: Consistent priority management across different contexts.\n- **Integrated Sequencing**: Harmonized approach to sequential workflows across domains.\n\n## Implementation\n\nThe Context Manager uses the MCP Client SDK to communicate with domain-specific MCP servers. It:\n\n1. Maintains a registry of domain servers with their connection information\n2. Creates MCP clients to connect to each domain server\n3. Routes requests to the appropriate domain server based on the active domain\n4. Provides cross-domain functionality for relating entities across domains\n5. Ensures consistent handling of status, priority, and sequential relations\n\n## Path Resolution\n\nThe Context Manager uses absolute paths constructed at runtime to locate domain servers. If you need to modify paths to domain servers, update the `domains` array in `main/index.ts`.\n\n## Installation & Usage\n\nYou can use the MCP Context Manager in several ways:\n\n### Using npx (Recommended)\n\nRun directly with npx:\n\n```bash\nnpx github:tejpalvirk/contextmanager\n```\n\n### Global Installation\n\nInstall globally to make all servers available as commands:\n\n```bash\nnpm install -g github:tejpalvirk/contextmanager\n```\n\nThen run:\n\n```bash\nmcp-server-contextmanager\n```\n\nOr run a specific domain server directly:\n\n```bash\ncontextmanager-developer\ncontextmanager-project\ncontextmanager-student\ncontextmanager-qualitativeresearch\ncontextmanager-quantitativeresearch\n```\n\n### Clone and Build from Source\n\nFor development or customization:\n\n```bash\ngit clone https://github.com/tejpalvirk/contextmanager.git\ncd contextmanager\nnpm install\nnpm run build\n```\n\nThen run:\n\n```bash\nnode main/index.js\n```\n\n## Command-Line Arguments\n\nThe Context Manager and domain servers accept the following command-line arguments:\n\n```bash\n# Run on a specific port (default: 3000)\nnpx github:tejpalvirk/contextmanager --port 3001\n\n# Enable debug logging\nnpx github:tejpalvirk/contextmanager --debug\n\n# Specify a config file\nnpx github:tejpalvirk/contextmanager --config ./my-config.json\n\n# Run only specific domain servers\nnpx github:tejpalvirk/contextmanager --domains developer,project\n```\n\n## Environment Variables\n\nEach domain server supports the following environment variables to customize where data is stored:\n\n- **MEMORY_FILE_PATH**: Path where the knowledge graph data will be stored\n  - Can be absolute or relative (relative paths use current working directory)\n  - Default: `<domain_directory>/memory.json`\n\n- **SESSIONS_FILE_PATH**: Path where session data will be stored\n  - Can be absolute or relative (relative paths use current working directory)\n  - Default: `<domain_directory>/sessions.json`\n\nExample usage:\n\n```bash\n# Store data in the current directory\nMEMORY_FILE_PATH=\"./my-dev-memory.json\" SESSIONS_FILE_PATH=\"./my-dev-sessions.json\" npx github:tejpalvirk/contextmanager\n\n# Store data in a specific location (absolute path)\nMEMORY_FILE_PATH=\"/path/to/data/developer-memory.json\" npx github:tejpalvirk/contextmanager\n\n# Store data in user's home directory\nMEMORY_FILE_PATH=\"$HOME/contextmanager/memory.json\" npx github:tejpalvirk/contextmanager\n```\n\n## Interacting with Domain Servers\n\n### Domain Management\n\nUse the `setActiveDomain` tool to select which domain you want to work with:\n\n```\nsetActiveDomain(domain=\"developer\")\n```\n\n### Session Management\n\nStart a new session for the active domain:\n\n```\nstartsession(domain=\"developer\")\n```\n\nEnd a session when you're done:\n\n```\nendsession(sessionId=\"session_id_here\", stage=\"assembly\", stageNumber=6, totalStages=6, nextStageNeeded=false)\n```\n\n### Context Operations\n\nBuild context for the active domain:\n\n```\nbuildcontext(type=\"entities\", data={...})\n```\n\nLoad context for a specific entity:\n\n```\nloadcontext(entityName=\"MyProject\", entityType=\"project\")\n```\n\nDelete context:\n\n```\ndeletecontext(type=\"entities\", data={...})\n```\n\n### Entity Status and Priority Management\n\nAssign status to entities:\n\n```\nbuildcontext(type=\"relations\", data=[\n  { from: \"LoginFeature\", to: \"active\", relationType: \"has_status\" }\n])\n```\n\nSet entity priorities:\n\n```\nbuildcontext(type=\"relations\", data=[\n  { from: \"BugFix\", to: \"high\", relationType: \"has_priority\" }\n])\n```\n\nDefine sequential relationships:\n\n```\nbuildcontext(type=\"relations\", data=[\n  { from: \"DataModel\", to: \"UserInterface\", relationType: \"precedes\" }\n])\n```\n\n### Example: Working with the Developer Domain\n\n```javascript\n// Set the active domain to developer\nsetActiveDomain(domain=\"developer\")\n\n// Start a new session\nstartsession(domain=\"developer\")\n\n// Create a new project entity\nbuildcontext(type=\"entities\", data={\n  \"entityType\": \"project\",\n  \"name\": \"MyProject\",\n  \"description\": \"A sample project\",\n  \"language\": \"TypeScript\",\n  \"framework\": \"React\"\n})\n\n// Load context for the project\nloadcontext(entityName=\"MyProject\", entityType=\"project\")\n\n// Create a component for the project and set its status to active\nbuildcontext(type=\"entities\", data={\n  \"entityType\": \"component\",\n  \"name\": \"AuthService\",\n  \"project\": \"MyProject\",\n  \"description\": \"Authentication service component\",\n  \"dependencies\": [\"UserService\"]\n})\n\nbuildcontext(type=\"relations\", data=[\n  { from: \"AuthService\", to: \"active\", relationType: \"has_status\" },\n  { from: \"AuthService\", to: \"high\", relationType: \"has_priority\" }\n])\n```\n\n### Cross-Domain Operations\n\nCreate relationships between entities in different domains:\n\n```\nrelateCrossDomain(fromDomain=\"developer\", fromEntity=\"ProjectX\", toDomain=\"project\", toEntity=\"ProjectX\", relationType=\"manages\")\n```\n\n### Example: Cross-Domain Integration\n\n```javascript\n// Create relationship between developer project and project management task\nrelateCrossDomain(\n  fromDomain=\"developer\", \n  fromEntity=\"MyProject\", \n  toDomain=\"project\", \n  toEntity=\"ProjectX\", \n  relationType=\"manages\"\n)\n```\n\n## Integration with Claude\n\nIn Claude Desktop, configure the Context Manager in settings:\n\n```json\n{\n  \"mcpServers\": {\n    \"contextmanager\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"github:tejpalvirk/contextmanager\"\n      ],\n      \"options\": {\n        \"port\": 3000,\n        \"domains\": [\"developer\", \"project\", \"student\"]\n      }\n    }\n  }\n}\n```\n\n## Troubleshooting\n\n### Common Issues\n\n1. **Port Already in Use**:\n   ```\n   Error: listen EADDRINUSE: address already in use :::3000\n   ```\n   Solution: Use the `--port` option to specify a different port.\n\n2. **Connection Refused**:\n   ```\n   Error: connect ECONNREFUSED 127.0.0.1:3000\n   ```\n   Solution: Ensure the server is running and accessible at the specified address.\n\n3. **Domain Server Not Found**:\n   ```\n   Error: Domain server 'developer' not found\n   ```\n   Solution: Check that the domain name is correct and the server is registered in the Context Manager.\n\n4. **Path Resolution Errors**:\n   ```\n   Error: Cannot find module '...'\n   ```\n   Solution: Ensure all paths in the `domains` array in `main/index.ts` are correctly specified.\n\n5. **Method Not Found**:\n   ```\n   Error: Method 'buildcontext' not found in domain 'developer'\n   ```\n   Solution: Verify the method name and ensure it is supported by the domain server.\n\n6. **Invalid Status or Priority Value**:\n   ```\n   Error: Invalid status value 'in_progress'. Valid values are: inactive, active, complete\n   ```\n   Solution: Ensure you're using the correct status values for the specific domain.\n\n## Next Steps\n- Replace JSON for YAML for 20-30% improvement in token efficiency\n- Explore Knowledge Graphs in Markdown\n\n## Versioning\n\nThis package follows [Semantic Versioning](https://semver.org/):\n\n- **MAJOR**: Incompatible API changes\n- **MINOR**: Backwards-compatible functionality additions\n- **PATCH**: Backwards-compatible bug fixes\n\nCurrent version: 1.0.0\n\n## Contributing\n\nContributions are welcome! Please follow these steps:\n\n1. Fork the repository\n2. Create a feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add some amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n\n### Coding Standards\n\n- Use TypeScript for all new code\n- Follow the existing code style\n- Add tests for new functionality\n- Update documentation as needed\n\n## Development\n\n### Prerequisites\n\n- Node.js v16 or higher\n- npm v7 or higher\n\n### Building\n\n```bash\nnpm install\nnpm run build\n```\n\n### Testing\n\n```bash\nnpm test\n```\n\n## License\n\nMIT\n\n## Acknowledgments\n\nThis project builds on the Model Context Protocol created by Anthropic for Claude. \n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "contextmanager",
        "manage",
        "management",
        "management tejpalvirk",
        "tejpalvirk contextmanager",
        "memory management"
      ],
      "category": "memory-management"
    },
    "tjwells47--chroma-mcp": {
      "owner": "tjwells47",
      "name": "chroma-mcp",
      "url": "https://github.com/tjwells47/chroma-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/tjwells47.webp",
      "description": "A vector database designed for integrating LLM applications, enabling seamless data retrieval and management through advanced search capabilities and document operations. Supports memory and context enhancement for AI models with efficient embedding functions.",
      "stars": 0,
      "forks": 0,
      "license": "Apache License 2.0",
      "language": "",
      "updated_at": "2025-04-09T04:30:49Z",
      "readme_content": "<p align=\"center\">\n  <a href=\"https://trychroma.com\"><img src=\"https://user-images.githubusercontent.com/891664/227103090-6624bf7d-9524-4e05-9d2c-c28d5d451481.png\" alt=\"Chroma logo\"></a>\n</p>\n\n<p align=\"center\">\n    <b>Chroma - the open-source embedding database</b>. <br />\n    The fastest way to build Python or JavaScript LLM apps with memory!\n</p>\n\n<p align=\"center\">\n  <a href=\"https://discord.gg/MMeYNTmh3x\" target=\"_blank\">\n      <img src=\"https://img.shields.io/discord/1073293645303795742?cacheSeconds=3600\" alt=\"Discord\">\n  </a> |\n  <a href=\"https://github.com/chroma-core/chroma/blob/master/LICENSE\" target=\"_blank\">\n      <img src=\"https://img.shields.io/static/v1?label=license&message=Apache 2.0&color=white\" alt=\"License\">\n  </a> |\n  <a href=\"https://docs.trychroma.com/\" target=\"_blank\">\n      Docs\n  </a> |\n  <a href=\"https://www.trychroma.com/\" target=\"_blank\">\n      Homepage\n  </a>\n</p>\n\n# Chroma MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@chroma-core/chroma-mcp)](https://smithery.ai/server/@chroma-core/chroma-mcp)\n\n[The Model Context Protocol (MCP)](https://modelcontextprotocol.io/introduction) is an open protocol designed for effortless integration between LLM applications and external data sources or tools, offering a standardized framework to seamlessly provide LLMs with the context they require.\n\nThis server provides data retrieval capabilities powered by Chroma, enabling AI models to create collections over generated data and user inputs, and retrieve that data using vector search, full text search, metadata filtering, and more.\n\n## Features\n\n- **Flexible Client Types**\n  - Ephemeral (in-memory) for testing and development\n  - Persistent for file-based storage\n  - HTTP client for self-hosted Chroma instances\n  - Cloud client for Chroma Cloud integration (automatically connects to api.trychroma.com)\n\n- **Collection Management**\n  - Create, modify, and delete collections\n  - List all collections with pagination support\n  - Get collection information and statistics\n  - Configure HNSW parameters for optimized vector search\n  - Select embedding functions when creating collections\n\n- **Document Operations**\n  - Add documents with optional metadata and custom IDs\n  - Query documents using semantic search\n  - Advanced filtering using metadata and document content\n  - Retrieve documents by IDs or filters\n  - Full text search capabilities\n\n### Supported Tools\n\n- `chroma_list_collections` - List all collections with pagination support\n- `chroma_create_collection` - Create a new collection with optional HNSW configuration\n- `chroma_peek_collection` - View a sample of documents in a collection\n- `chroma_get_collection_info` - Get detailed information about a collection\n- `chroma_get_collection_count` - Get the number of documents in a collection\n- `chroma_modify_collection` - Update a collection's name or metadata\n- `chroma_delete_collection` - Delete a collection\n- `chroma_add_documents` - Add documents with optional metadata and custom IDs\n- `chroma_query_documents` - Query documents using semantic search with advanced filtering\n- `chroma_get_documents` - Retrieve documents by IDs or filters with pagination\n- `chroma_update_documents` - Update existing documents' content, metadata, or embeddings\n- `chroma_delete_documents` - Delete specific documents from a collection\n\n### Embedding Functions\nChroma MCP supports several embedding functions: `default`, `cohere`, `openai`, `jina`, `voyageai`, and `roboflow`.\n\nThe embedding functions utilize Chroma's collection configuration, which persists the selected embedding function of a collection for retrieval. Once a collection is created using the collection configuration, on retrieval for future queries and inserts, the same embedding function will be used, without needing to specify the embedding function again. Embedding function persistance was added in v1.0.0 of Chroma, so if you created a collection using version <=0.6.3, this feature is not supported.\n\nWhen accessing embedding functions that utilize external APIs, please be sure to add the environment variable for the API key with the correct format, found in [Embedding Function Environment Variables](#embedding-function-environment-variables)\n\n## Usage with Claude Desktop\n\n1. To add an ephemeral client, add the following to your `claude_desktop_config.json` file:\n\n```json\n\"chroma\": {\n    \"command\": \"uvx\",\n    \"args\": [\n        \"chroma-mcp\"\n    ]\n}\n```\n\n2. To add a persistent client, add the following to your `claude_desktop_config.json` file:\n\n```json\n\"chroma\": {\n    \"command\": \"uvx\",\n    \"args\": [\n        \"chroma-mcp\",\n        \"--client-type\",\n        \"persistent\",\n        \"--data-dir\",\n        \"/full/path/to/your/data/directory\"\n    ]\n}\n```\n\nThis will create a persistent client that will use the data directory specified.\n\n3. To connect to Chroma Cloud, add the following to your `claude_desktop_config.json` file:\n\n```json\n\"chroma\": {\n    \"command\": \"uvx\",\n    \"args\": [\n        \"chroma-mcp\",\n        \"--client-type\",\n        \"cloud\",\n        \"--tenant\",\n        \"your-tenant-id\",\n        \"--database\",\n        \"your-database-name\",\n        \"--api-key\",\n        \"your-api-key\"\n    ]\n}\n```\n\nThis will create a cloud client that automatically connects to api.trychroma.com using SSL.\n\n**Note:** Adding API keys in arguments is fine on local devices, but for safety, you can also specify a custom path for your environment configuration file using the `--dotenv-path` argument within the `args` list, for example: `\"args\": [\"chroma-mcp\", \"--dotenv-path\", \"/custom/path/.env\"]`.\n\n4. To connect to a [self-hosted Chroma instance on your own cloud provider](https://docs.trychroma.com/\nproduction/deployment), add the following to your `claude_desktop_config.json` file:\n\n```json\n\"chroma\": {\n    \"command\": \"uvx\",\n    \"args\": [\n      \"chroma-mcp\", \n      \"--client-type\", \n      \"http\", \n      \"--host\", \n      \"your-host\", \n      \"--port\", \n      \"your-port\", \n      \"--custom-auth-credentials\",\n      \"your-custom-auth-credentials\",\n      \"--ssl\",\n      \"true\"\n    ]\n}\n```\n\nThis will create an HTTP client that connects to your self-hosted Chroma instance.\n\n### Demos\n\nFind reference usages, such as shared knowledge bases & adding memory to context windows in the [Chroma MCP Docs](https://docs.trychroma.com/integrations/frameworks/anthropic-mcp#using-chroma-with-claude)\n\n### Using Environment Variables\n\nYou can also use environment variables to configure the client. The server will automatically load variables from a `.env` file located at the path specified by `--dotenv-path` (defaults to `.chroma_env` in the working directory) or from system environment variables. Command-line arguments take precedence over environment variables.\n\n```bash\n# Common variables\nexport CHROMA_CLIENT_TYPE=\"http\"  # or \"cloud\", \"persistent\", \"ephemeral\"\n\n# For persistent client\nexport CHROMA_DATA_DIR=\"/full/path/to/your/data/directory\"\n\n# For cloud client (Chroma Cloud)\nexport CHROMA_TENANT=\"your-tenant-id\"\nexport CHROMA_DATABASE=\"your-database-name\"\nexport CHROMA_API_KEY=\"your-api-key\"\n\n# For HTTP client (self-hosted)\nexport CHROMA_HOST=\"your-host\"\nexport CHROMA_PORT=\"your-port\"\nexport CHROMA_CUSTOM_AUTH_CREDENTIALS=\"your-custom-auth-credentials\"\nexport CHROMA_SSL=\"true\"\n\n# Optional: Specify path to .env file (defaults to .chroma_env)\nexport CHROMA_DOTENV_PATH=\"/path/to/your/.env\" \n```\n\n#### Embedding Function Environment Variables\nWhen using external embedding functions that access an API key, follow the naming convention\n`CHROMA_<>_API_KEY=\"<key>\"`.\nSo to set a Cohere API key, set the environment variable `CHROMA_COHERE_API_KEY=\"\"`. We recommend adding this to a .env file somewhere and using the `CHROMA_DOTENV_PATH` environment variable or `--dotenv-path` flag to set that location for safekeeping.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "memory",
        "retrieval",
        "database",
        "vector database",
        "memory management",
        "retrieval management"
      ],
      "category": "memory-management"
    },
    "tjwells47--mcp-qdrant-memory": {
      "owner": "tjwells47",
      "name": "mcp-qdrant-memory",
      "url": "https://github.com/tjwells47/mcp-qdrant-memory",
      "imageUrl": "/freedevtools/mcp/pfp/tjwells47.webp",
      "description": "Leverage a knowledge graph with entities and relations, enabling semantic search capabilities using OpenAI embeddings and Qdrant for data persistence. Supports HTTPS and Docker for streamlined deployment.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "",
      "updated_at": "2025-04-08T08:23:45Z",
      "readme_content": "# MCP Memory Server with Qdrant Persistence\n[![smithery badge](https://smithery.ai/badge/@delorenj/mcp-qdrant-memory)](https://smithery.ai/server/@delorenj/mcp-qdrant-memory)\n\nThis MCP server provides a knowledge graph implementation with semantic search capabilities powered by Qdrant vector database.\n\n## Features\n\n- Graph-based knowledge representation with entities and relations\n- File-based persistence (memory.json)\n- Semantic search using Qdrant vector database\n- OpenAI embeddings for semantic similarity\n- HTTPS support with reverse proxy compatibility\n- Docker support for easy deployment\n\n## Environment Variables\n\nThe following environment variables are required:\n\n```bash\n# OpenAI API key for generating embeddings\nOPENAI_API_KEY=your-openai-api-key\n\n# Qdrant server URL (supports both HTTP and HTTPS)\nQDRANT_URL=https://your-qdrant-server\n\n# Qdrant API key (if authentication is enabled)\nQDRANT_API_KEY=your-qdrant-api-key\n\n# Name of the Qdrant collection to use\nQDRANT_COLLECTION_NAME=your-collection-name\n```\n\n## Setup\n\n### Local Setup\n\n1. Install dependencies:\n```bash\nnpm install\n```\n\n2. Build the server:\n```bash\nnpm run build\n```\n\n### Docker Setup\n\n1. Build the Docker image:\n```bash\ndocker build -t mcp-qdrant-memory .\n```\n\n2. Run the Docker container with required environment variables:\n```bash\ndocker run -d \\\n  -e OPENAI_API_KEY=your-openai-api-key \\\n  -e QDRANT_URL=http://your-qdrant-server:6333 \\\n  -e QDRANT_COLLECTION_NAME=your-collection-name \\\n  -e QDRANT_API_KEY=your-qdrant-api-key \\\n  --name mcp-qdrant-memory \\\n  mcp-qdrant-memory\n```\n\n### Add to MCP settings:\n```json\n{\n  \"mcpServers\": {\n    \"memory\": {\n      \"command\": \"/bin/zsh\",\n      \"args\": [\"-c\", \"cd /path/to/server && node dist/index.js\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"your-openai-api-key\",\n        \"QDRANT_API_KEY\": \"your-qdrant-api-key\",\n        \"QDRANT_URL\": \"http://your-qdrant-server:6333\",\n        \"QDRANT_COLLECTION_NAME\": \"your-collection-name\"\n      },\n      \"alwaysAllow\": [\n        \"create_entities\",\n        \"create_relations\",\n        \"add_observations\",\n        \"delete_entities\",\n        \"delete_observations\",\n        \"delete_relations\",\n        \"read_graph\",\n        \"search_similar\"\n      ]\n    }\n  }\n}\n```\n\n## Tools\n\n### Entity Management\n- `create_entities`: Create multiple new entities\n- `create_relations`: Create relations between entities\n- `add_observations`: Add observations to entities\n- `delete_entities`: Delete entities and their relations\n- `delete_observations`: Delete specific observations\n- `delete_relations`: Delete specific relations\n- `read_graph`: Get the full knowledge graph\n\n### Semantic Search\n- `search_similar`: Search for semantically similar entities and relations\n  ```typescript\n  interface SearchParams {\n    query: string;     // Search query text\n    limit?: number;    // Max results (default: 10)\n  }\n  ```\n\n## Implementation Details\n\nThe server maintains two forms of persistence:\n\n1. File-based (memory.json):\n   - Complete knowledge graph structure\n   - Fast access to full graph\n   - Used for graph operations\n\n2. Qdrant Vector DB:\n   - Semantic embeddings of entities and relations\n   - Enables similarity search\n   - Automatically synchronized with file storage\n\n### Synchronization\n\nWhen entities or relations are modified:\n1. Changes are written to memory.json\n2. Embeddings are generated using OpenAI\n3. Vectors are stored in Qdrant\n4. Both storage systems remain consistent\n\n### Search Process\n\nWhen searching:\n1. Query text is converted to embedding\n2. Qdrant performs similarity search\n3. Results include both entities and relations\n4. Results are ranked by semantic similarity\n\n## Example Usage\n\n```typescript\n// Create entities\nawait client.callTool(\"create_entities\", {\n  entities: [{\n    name: \"Project\",\n    entityType: \"Task\",\n    observations: [\"A new development project\"]\n  }]\n});\n\n// Search similar concepts\nconst results = await client.callTool(\"search_similar\", {\n  query: \"development tasks\",\n  limit: 5\n});\n```\n\n## HTTPS and Reverse Proxy Configuration\n\nThe server supports connecting to Qdrant through HTTPS and reverse proxies. This is particularly useful when:\n- Running Qdrant behind a reverse proxy like Nginx or Apache\n- Using self-signed certificates\n- Requiring custom SSL/TLS configurations\n\n### Setting up with a Reverse Proxy\n\n1. Configure your reverse proxy (example using Nginx):\n```nginx\nserver {\n    listen 443 ssl;\n    server_name qdrant.yourdomain.com;\n\n    ssl_certificate /path/to/cert.pem;\n    ssl_certificate_key /path/to/key.pem;\n\n    location / {\n        proxy_pass http://localhost:6333;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n    }\n}\n```\n\n2. Update your environment variables:\n```bash\nQDRANT_URL=https://qdrant.yourdomain.com\n```\n\n### Security Considerations\n\nThe server implements robust HTTPS handling with:\n- Custom SSL/TLS configuration\n- Proper certificate verification options\n- Connection pooling and keepalive\n- Automatic retry with exponential backoff\n- Configurable timeouts\n\n### Troubleshooting HTTPS Connections\n\nIf you experience connection issues:\n\n1. Verify your certificates:\n```bash\nopenssl s_client -connect qdrant.yourdomain.com:443\n```\n\n2. Test direct connectivity:\n```bash\ncurl -v https://qdrant.yourdomain.com/collections\n```\n\n3. Check for any proxy settings:\n```bash\nenv | grep -i proxy\n```\n\n## Contributing\n\n1. Fork the repository\n2. Create a feature branch\n3. Make your changes\n4. Submit a pull request\n\n## License\n\nMIT",
      "npm_url": "https://www.npmjs.com/package/mcp-qdrant-memory",
      "npm_downloads": 280,
      "keywords": [
        "openai",
        "memory",
        "entities",
        "openai embeddings",
        "qdrant memory",
        "using openai"
      ],
      "category": "memory-management"
    },
    "tomschell--mcp-long-term-memory": {
      "owner": "tomschell",
      "name": "mcp-long-term-memory",
      "url": "https://github.com/tomschell/mcp-long-term-memory",
      "imageUrl": "/freedevtools/mcp/pfp/null.webp",
      "description": "Long-term memory storage for LLMs that maintains project context across sessions, enabling efficient retrieval and recall of past interactions and decisions via semantic search. Organizes memories by type, tags, and relationships for streamlined management.",
      "stars": 0,
      "forks": 0,
      "license": "Unknown",
      "language": "Unknown",
      "updated_at": "",
      "readme_content": "",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "memory",
        "llms",
        "memories",
        "memory management",
        "organizes memories",
        "storage llms"
      ],
      "category": "memory-management"
    },
    "tosin2013--mcp-memory-cache-server": {
      "owner": "tosin2013",
      "name": "mcp-memory-cache-server",
      "url": "https://github.com/tosin2013/mcp-memory-cache-server",
      "imageUrl": "/freedevtools/mcp/pfp/tosin2013.webp",
      "description": "Caches data between interactions with AI language models to reduce token consumption and enhance performance by automatically storing and retrieving frequently accessed data.",
      "stars": 2,
      "forks": 2,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-06-01T20:05:22Z",
      "readme_content": "# Memory Cache Server\n[![smithery badge](https://smithery.ai/badge/@tosin2013/mcp-memory-cache-server)](https://smithery.ai/server/@tosin2013/mcp-memory-cache-server)\n\nA Model Context Protocol (MCP) server that reduces token consumption by efficiently caching data between language model interactions. Works with any MCP client and any language model that uses tokens.\n\n## Installation\n\n### Installing via Smithery\n\nTo install Memory Cache Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@tosin2013/mcp-memory-cache-server):\n\n```bash\nnpx -y @smithery/cli install @tosin2013/mcp-memory-cache-server --client claude\n```\n\n### Installing Manually\n1. Clone the repository:\n```bash\ngit clone https://github.com/tosin2013/mcp-memory-cache-server.git\ncd mcp-memory-cache-server\n```\n\n2. Install dependencies:\n```bash\nnpm install\n```\n\n3. Build the project:\n```bash\nnpm run build\n```\n\n4. Add to your MCP client settings:\n```json\n{\n  \"mcpServers\": {\n    \"memory-cache\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/ib-mcp-cache-server/build/index.js\"]\n    }\n  }\n}\n```\n\n5. The server will automatically start when you use your MCP client\n\n## Verifying It Works\n\nWhen the server is running properly, you'll see:\n1. A message in the terminal: \"Memory Cache MCP server running on stdio\"\n2. Improved performance when accessing the same data multiple times\n3. No action required from you - the caching happens automatically\n\nYou can verify the server is running by:\n1. Opening your MCP client\n2. Looking for any error messages in the terminal where you started the server\n3. Performing operations that would benefit from caching (like reading the same file multiple times)\n\n## Configuration\n\nThe server can be configured through `config.json` or environment variables:\n\n```json\n{\n  \"maxEntries\": 1000,        // Maximum number of items in cache\n  \"maxMemory\": 104857600,    // Maximum memory usage in bytes (100MB)\n  \"defaultTTL\": 3600,        // Default time-to-live in seconds (1 hour)\n  \"checkInterval\": 60000,    // Cleanup interval in milliseconds (1 minute)\n  \"statsInterval\": 30000     // Stats update interval in milliseconds (30 seconds)\n}\n```\n\n### Configuration Settings Explained\n\n1. **maxEntries** (default: 1000)\n   - Maximum number of items that can be stored in cache\n   - Prevents cache from growing indefinitely\n   - When exceeded, oldest unused items are removed first\n\n2. **maxMemory** (default: 100MB)\n   - Maximum memory usage in bytes\n   - Prevents excessive memory consumption\n   - When exceeded, least recently used items are removed\n\n3. **defaultTTL** (default: 1 hour)\n   - How long items stay in cache by default\n   - Items are automatically removed after this time\n   - Prevents stale data from consuming memory\n\n4. **checkInterval** (default: 1 minute)\n   - How often the server checks for expired items\n   - Lower values keep memory usage more accurate\n   - Higher values reduce CPU usage\n\n5. **statsInterval** (default: 30 seconds)\n   - How often cache statistics are updated\n   - Affects accuracy of hit/miss rates\n   - Helps monitor cache effectiveness\n\n## How It Reduces Token Consumption\n\nThe memory cache server reduces token consumption by automatically storing data that would otherwise need to be re-sent between you and the language model. You don't need to do anything special - the caching happens automatically when you interact with any language model through your MCP client.\n\nHere are some examples of what gets cached:\n\n### 1. File Content Caching\nWhen reading a file multiple times:\n- First time: Full file content is read and cached\n- Subsequent times: Content is retrieved from cache instead of re-reading the file\n- Result: Fewer tokens used for repeated file operations\n\n### 2. Computation Results\nWhen performing calculations or analysis:\n- First time: Full computation is performed and results are cached\n- Subsequent times: Results are retrieved from cache if the input is the same\n- Result: Fewer tokens used for repeated computations\n\n### 3. Frequently Accessed Data\nWhen the same data is needed multiple times:\n- First time: Data is processed and cached\n- Subsequent times: Data is retrieved from cache until TTL expires\n- Result: Fewer tokens used for accessing the same information\n\n## Automatic Cache Management\n\nThe server automatically manages the caching process by:\n- Storing data when first encountered\n- Serving cached data when available\n- Removing old/unused data based on settings\n- Tracking effectiveness through statistics\n\n## Optimization Tips\n\n### 1. Set Appropriate TTLs\n- Shorter for frequently changing data\n- Longer for static content\n\n### 2. Adjust Memory Limits\n- Higher for more caching (more token savings)\n- Lower if memory usage is a concern\n\n### 3. Monitor Cache Stats\n- High hit rate = good token savings\n- Low hit rate = adjust TTL or limits\n\n## Environment Variable Configuration\n\nYou can override config.json settings using environment variables in your MCP settings:\n\n```json\n{\n  \"mcpServers\": {\n    \"memory-cache\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/build/index.js\"],\n      \"env\": {\n        \"MAX_ENTRIES\": \"5000\",\n        \"MAX_MEMORY\": \"209715200\",  // 200MB\n        \"DEFAULT_TTL\": \"7200\",      // 2 hours\n        \"CHECK_INTERVAL\": \"120000\",  // 2 minutes\n        \"STATS_INTERVAL\": \"60000\"    // 1 minute\n      }\n    }\n  }\n}\n```\n\nYou can also specify a custom config file location:\n```json\n{\n  \"env\": {\n    \"CONFIG_PATH\": \"/path/to/your/config.json\"\n  }\n}\n```\n\nThe server will:\n1. Look for config.json in its directory\n2. Apply any environment variable overrides\n3. Use default values if neither is specified\n\n## Testing the Cache in Practice\n\nTo see the cache in action, try these scenarios:\n\n1. **File Reading Test**\n   - Read and analyze a large file\n   - Ask the same question about the file again\n   - The second response should be faster as the file content is cached\n\n2. **Data Analysis Test**\n   - Perform analysis on some data\n   - Request the same analysis again\n   - The second analysis should use cached results\n\n3. **Project Navigation Test**\n   - Explore a project's structure\n   - Query the same files/directories again\n   - Directory listings and file contents will be served from cache\n\nThe cache is working when you notice:\n- Faster responses for repeated operations\n- Consistent answers about unchanged content\n- No need to re-read files that haven't changed\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "memory",
        "cache",
        "caches",
        "memory cache",
        "mcp memory",
        "memory management"
      ],
      "category": "memory-management"
    },
    "unibaseio--membase-mcp": {
      "owner": "unibaseio",
      "name": "membase-mcp",
      "url": "https://github.com/unibaseio/membase-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/unibaseio.webp",
      "description": "Enables AI agents to store and retrieve historical interactions and persistent data on a decentralized memory layer. Facilitates conversation management by saving and fetching messages, ensuring continuity and traceability of interactions.",
      "stars": 14,
      "forks": 4,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-09-24T09:13:46Z",
      "readme_content": "# membase mcp server\n\n## Description\n\nMembase is the first decentralized memory layer for AI agents, powered by Unibase. It provides secure, persistent storage for conversation history, interaction records, and knowledge — ensuring agent continuity, personalization, and traceability.\n\nThe Membase-MCP Server enables seamless integration with the Membase protocol, allowing agents to upload and retrieve memory from the Unibase DA network for decentralized, verifiable storage.\n\n## Functions\n\nMessages or memoiries can be visit at: <https://testnet.hub.membase.io/>\n\n- **get_conversation_id**: Get the current conversation id.\n- **switch_conversation**: Switch to a different conversation.\n- **save_message**: Save a message/memory into the current conversation.\n- **get_messages**: Get the last n messages from the current conversation.\n\n## Installation\n\n```shell\ngit clone https://github.com/unibaseio/membase-mcp.git\ncd membase-mcp\nuv run src/membase_mcp/server.py\n```\n\n## Environment variables\n\n- MEMBASE_ACCOUNT: your account to upload\n- MEMBASE_CONVERSATION_ID: your conversation id, should be unique, will preload its history\n- MEMBASE_ID: your instance id\n\n## Configuration on Claude/Windsurf/Cursor/Cline\n\n```json\n{\n  \"mcpServers\": {\n    \"membase\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"path/to/membase-mcp\",\n        \"run\", \n        \"src/membase_mcp/server.py\"\n      ],\n      \"env\": {\n        \"MEMBASE_ACCOUNT\": \"your account, 0x...\",\n        \"MEMBASE_CONVERSATION_ID\": \"your conversation id, should be unique\",\n        \"MEMBASE_ID\": \"your sub account, any string\"\n      }\n    }\n  }\n}\n```\n\n## Usage\n\ncall functions in llm chat\n\n- get conversation id and switch conversation\n\n\n\n- save message and get messages",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "memory",
        "ai",
        "persistent",
        "conversation management",
        "ai agents",
        "facilitates conversation"
      ],
      "category": "memory-management"
    },
    "wuyunmei--momedb-mcp": {
      "owner": "wuyunmei",
      "name": "momedb-mcp",
      "url": "https://github.com/wuyunmei/momedb-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/wuyunmei.webp",
      "description": "Manage conversation context and a personal knowledge base for AI applications with efficient APIs. Create, update, and query user data while handling dialogue and knowledge management seamlessly.",
      "stars": 1,
      "forks": 1,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-03-23T09:07:18Z",
      "readme_content": "# MemoDB MCP Server\n\nMCP 服务器，用于管理 AI 应用的对话上下文和个人知识库。该服务器通过模型上下文协议(MCP)提供用户数据、对话内容和知识管理的工具。\n\n## 主要功能\n\n### 1. 用户管理\n- `create_user`: 创建新用户\n- `get_user`: 获取用户信息\n- `update_user`: 更新用户信息\n- `delete_user`: 删除用户\n\n### 2. 对话数据管理\n- `insert_blob`: 插入对话数据\n- `get_blob`: 获取对话数据\n- `delete_blob`: 删除对话数据\n\n### 3. 知识库管理\n- `query_knowledge`: 查询知识库\n  * 支持全文搜索\n  * 支持按类型、标签、来源过滤\n  * 支持限制返回结果数量\n- `add_knowledge`: 添加新知识\n  * 支持设置知识来源\n  * 支持设置知识类型\n  * 支持添加标签\n- `update_knowledge`: 更新已有知识\n  * 支持更新内容和元数据\n  * 支持修改标签\n- `relate_knowledge`: 创建知识关联\n  * 支持设置关联类型\n  * 支持设置关联权重\n\n## 技术亮点\n\n1. **类型安全**\n   - 使用 TypeScript 实现\n   - 完整的类型定义和检查\n   - 编译时错误检测\n\n2. **错误处理**\n   - 全面的错误处理机制\n   - 详细的错误信息\n   - 错误日志记录\n\n3. **API 设计**\n   - 基于 JSON-RPC 2.0 协议\n   - RESTful API 风格\n   - 清晰的接口定义\n\n4. **可扩展性**\n   - 模块化设计\n   - 插件式工具注册\n   - 易于添加新功能\n\n## 安装和配置\n\n1. 安装依赖:\n```bash\nnpm install\n```\n\n2. 配置环境变量:\n创建 `.env` 文件并设置:\n```env\nMEMOBASE_API_URL=your_api_url    # API 服务器地址\nMEMOBASE_API_KEY=your_api_key    # API 访问密钥\n```\n\n3. 构建项目:\n```bash\nnpm run build\n```\n\n4. 运行服务器:\n```bash\n# 生产环境\nnpm start\n\n# 开发环境\nnpm run dev\n```\n\n## API 示例\n\n### 1. 添加知识\n```typescript\nconst result = await callTool('add_knowledge', {\n  uid: 'user123',\n  content: '人工智能是计算机科学的一个分支...',\n  metadata: {\n    source: 'wiki',\n    type: 'article',\n    tags: ['AI', '计算机科学', '技术']\n  }\n});\n```\n\n### 2. 查询知识\n```typescript\nconst result = await callTool('query_knowledge', {\n  uid: 'user123',\n  query: '人工智能',\n  filters: {\n    types: ['article'],\n    tags: ['AI'],\n    sources: ['wiki']\n  },\n  limit: 10\n});\n```\n\n### 3. 关联知识\n```typescript\nconst result = await callTool('relate_knowledge', {\n  uid: 'user123',\n  source_kid: 'knowledge1',\n  target_kid: 'knowledge2',\n  relation_type: 'related_to',\n  weight: 0.8\n});\n```\n\n## 开发指南\n\n1. **添加新工具**\n   - 在 `src/tools` 目录下创建工具实现\n   - 在 `src/api/types.ts` 添加类型定义\n   - 在 `src/index.ts` 注册工具\n\n2. **修改配置**\n   - 编辑 `src/config.ts` 更新配置项\n   - 在 `.env` 文件中添加新的环境变量\n\n3. **运行测试**\n```bash\nnpm test\n```\n\n## 常见问题\n\n如果您在使用过程中遇到问题，请参考 [常见问题与解决方案](docs/TROUBLESHOOTING.md) 文档。\n\n## 许可证\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "conversation",
        "ai",
        "dialogue",
        "manage conversation",
        "dialogue knowledge",
        "conversation context"
      ],
      "category": "memory-management"
    },
    "yellnuts--mcp-mem0": {
      "owner": "yellnuts",
      "name": "mcp-mem0",
      "url": "https://github.com/yellnuts/mcp-mem0",
      "imageUrl": "/freedevtools/mcp/pfp/yellnuts.webp",
      "description": "Manage long-term memory for AI agents by storing and retrieving memories efficiently with a lightweight Python-based solution. Customize and extend memory capabilities easily through a robust template designed for integration.",
      "stars": 0,
      "forks": 1,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-03T08:07:12Z",
      "readme_content": "# MCP-Mem0: Your Gateway to Long-Term Agent Memory 🚀\n\nWelcome to the **MCP-Mem0** repository! This project provides a robust server for managing long-term agent memory using Mem0. It also serves as a helpful template for anyone looking to build their own MCP server with Python.\n\n[![Download Releases](https://img.shields.io/badge/Download%20Releases-blue.svg)](https://github.com/yellnuts/mcp-mem0/releases)\n\n## Table of Contents\n\n- [Features](#features)\n- [Getting Started](#getting-started)\n- [Installation](#installation)\n- [Usage](#usage)\n- [Contributing](#contributing)\n- [License](#license)\n- [Contact](#contact)\n\n## Features ✨\n\n- **Long-Term Memory Management**: Efficiently store and retrieve agent memories.\n- **Python-Based**: Built with Python, making it easy to customize and extend.\n- **Template Structure**: A great starting point for your own MCP server development.\n- **Lightweight**: Minimal resource requirements for easy deployment.\n\n## Getting Started 🏁\n\nTo get started with MCP-Mem0, you will need to download the latest release. Visit the [Releases section](https://github.com/yellnuts/mcp-mem0/releases) to find the latest version. Download the file and execute it to set up your server.\n\n## Installation ⚙️\n\nFollow these steps to install MCP-Mem0:\n\n1. **Clone the Repository**:\n   ```bash\n   git clone https://github.com/yellnuts/mcp-mem0.git\n   cd mcp-mem0\n   ```\n\n2. **Install Dependencies**:\n   Ensure you have Python 3.6 or higher installed. Use pip to install the required packages:\n   ```bash\n   pip install -r requirements.txt\n   ```\n\n3. **Run the Server**:\n   After installing the dependencies, you can start the server with:\n   ```bash\n   python server.py\n   ```\n\n4. **Access the API**:\n   Open your web browser and navigate to `http://localhost:5000` to access the server.\n\n## Usage 📚\n\nOnce the server is running, you can interact with it using HTTP requests. Below are some example endpoints you can use:\n\n- **Create Memory**:\n  ```http\n  POST /memory\n  ```\n  Body:\n  ```json\n  {\n    \"agent_id\": \"unique_agent_id\",\n    \"memory_data\": \"Your memory data here\"\n  }\n  ```\n\n- **Retrieve Memory**:\n  ```http\n  GET /memory/{agent_id}\n  ```\n\n- **Delete Memory**:\n  ```http\n  DELETE /memory/{agent_id}\n  ```\n\nFor more detailed API documentation, refer to the `API.md` file in the repository.\n\n## Contributing 🤝\n\nWe welcome contributions to MCP-Mem0! Here’s how you can help:\n\n1. **Fork the Repository**: Click the \"Fork\" button at the top right corner of the page.\n2. **Create a Branch**: \n   ```bash\n   git checkout -b feature/YourFeature\n   ```\n3. **Make Changes**: Implement your feature or fix.\n4. **Commit Your Changes**:\n   ```bash\n   git commit -m \"Add your message here\"\n   ```\n5. **Push to the Branch**:\n   ```bash\n   git push origin feature/YourFeature\n   ```\n6. **Open a Pull Request**: Go to the original repository and click on \"New Pull Request\".\n\n## License 📄\n\nThis project is licensed under the MIT License. See the `LICENSE` file for more details.\n\n## Contact 📬\n\nFor any inquiries or support, please contact the maintainer:\n\n- **Name**: [Your Name]\n- **Email**: [your.email@example.com]\n- **GitHub**: [your-github-profile](https://github.com/your-github-profile)\n\nThank you for checking out MCP-Mem0! We hope you find it useful. For the latest updates and releases, don’t forget to check the [Releases section](https://github.com/yellnuts/mcp-mem0/releases) again.\n\n\n\n---\n\n## Advanced Configuration 🔧\n\nMCP-Mem0 allows for advanced configurations to suit your specific needs. You can adjust settings in the `config.json` file located in the root directory. Here are some of the key configurations you can modify:\n\n- **Memory Expiry**: Set how long memories should be retained.\n- **Logging Level**: Adjust the verbosity of server logs.\n- **Port Configuration**: Change the port number if needed.\n\n### Example Configuration\n\nHere’s an example of what your `config.json` might look like:\n\n```json\n{\n  \"memory_expiry\": \"30 days\",\n  \"logging_level\": \"info\",\n  \"port\": 5000\n}\n```\n\n## Troubleshooting 🛠️\n\nIf you encounter issues while using MCP-Mem0, consider the following common problems:\n\n- **Server Not Starting**: Ensure that all dependencies are installed correctly.\n- **API Errors**: Check the request format and ensure the server is running.\n- **Memory Not Saving**: Verify that the `agent_id` is unique and correctly formatted.\n\n## Roadmap 🗺️\n\nWe have exciting plans for future updates! Here are some features we aim to implement:\n\n- **User Authentication**: Secure your memory management with user accounts.\n- **Data Visualization**: Graphical representation of memory data.\n- **Multi-Agent Support**: Handle multiple agents simultaneously.\n\nStay tuned for these features and more!\n\n## Community 💬\n\nJoin our community to share your experiences, ask questions, and get support:\n\n- **Discord**: [Join our Discord Server](https://discord.gg/example)\n- **Forum**: [Visit our Forum](https://forum.example.com)\n\nWe encourage you to engage with other users and contribute to discussions.\n\n## Final Thoughts 💭\n\nThank you for exploring MCP-Mem0! We believe this tool will be a valuable asset for anyone working with agent memory management. Your feedback is essential, so feel free to reach out with suggestions or improvements.\n\nFor the latest updates, don’t forget to visit the [Releases section](https://github.com/yellnuts/mcp-mem0/releases) again. Happy coding!",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "memory",
        "mem0",
        "ai",
        "memory ai",
        "mem0 manage",
        "memory management"
      ],
      "category": "memory-management"
    },
    "yodakeisuke--mcp-memory-domain-knowledge": {
      "owner": "yodakeisuke",
      "name": "mcp-memory-domain-knowledge",
      "url": "https://github.com/yodakeisuke/mcp-memory-domain-knowledge",
      "imageUrl": "/freedevtools/mcp/pfp/yodakeisuke.webp",
      "description": "Persistently remembers user information across chats using a local knowledge graph, allowing connections between different entities and their relationships. Facilitates the storage and retrieval of observations linked to specific entities for improved contextual interactions.",
      "stars": 5,
      "forks": 4,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-06-09T06:08:46Z",
      "readme_content": "forked https://github.com/modelcontextprotocol/servers/tree/main\n\n# Knowledge Graph Memory Server\nA basic implementation of persistent memory using a local knowledge graph. This lets Claude remember information about the user across chats.\n\n## Core Concepts\n\n### Entities\nEntities are the primary nodes in the knowledge graph. Each entity has:\n- A unique name (identifier)\n- An entity type (e.g., \"person\", \"organization\", \"event\")\n- A list of observations\n\nExample:\n```json\n{\n  \"name\": \"John_Smith\",\n  \"entityType\": \"person\",\n  \"observations\": [\"Speaks fluent Spanish\"]\n}\n```\n\n### Relations\nRelations define directed connections between entities. They are always stored in active voice and describe how entities interact or relate to each other.\n\nExample:\n```json\n{\n  \"from\": \"John_Smith\",\n  \"to\": \"Anthropic\",\n  \"relationType\": \"works_at\"\n}\n```\n### Observations\nObservations are discrete pieces of information about an entity. They are:\n\n- Stored as strings\n- Attached to specific entities\n- Can be added or removed independently\n- Should be atomic (one fact per observation)\n\nExample:\n```json\n{\n  \"entityName\": \"John_Smith\",\n  \"observations\": [\n    \"Speaks fluent Spanish\",\n    \"Graduated in 2019\",\n    \"Prefers morning meetings\"\n  ]\n}\n```\n\n## API\n\n### Tools\n- **create_entities**\n  - Create multiple new entities in the knowledge graph\n  - Input: `entities` (array of objects)\n    - Each object contains:\n      - `name` (string): Entity identifier\n      - `entityType` (string): Type classification\n      - `observations` (string[]): Associated observations\n  - Ignores entities with existing names\n\n- **create_relations**\n  - Create multiple new relations between entities\n  - Input: `relations` (array of objects)\n    - Each object contains:\n      - `from` (string): Source entity name\n      - `to` (string): Target entity name\n      - `relationType` (string): Relationship type in active voice\n  - Skips duplicate relations\n\n- **add_observations**\n  - Add new observations to existing entities\n  - Input: `observations` (array of objects)\n    - Each object contains:\n      - `entityName` (string): Target entity\n      - `contents` (string[]): New observations to add\n  - Returns added observations per entity\n  - Fails if entity doesn't exist\n\n- **delete_entities**\n  - Remove entities and their relations\n  - Input: `entityNames` (string[])\n  - Cascading deletion of associated relations\n  - Silent operation if entity doesn't exist\n\n- **delete_observations**\n  - Remove specific observations from entities\n  - Input: `deletions` (array of objects)\n    - Each object contains:\n      - `entityName` (string): Target entity\n      - `observations` (string[]): Observations to remove\n  - Silent operation if observation doesn't exist\n\n- **delete_relations**\n  - Remove specific relations from the graph\n  - Input: `relations` (array of objects)\n    - Each object contains:\n      - `from` (string): Source entity name\n      - `to` (string): Target entity name\n      - `relationType` (string): Relationship type\n  - Silent operation if relation doesn't exist\n\n- **read_graph**\n  - Read the entire knowledge graph\n  - No input required\n  - Returns complete graph structure with all entities and relations\n\n- **search_nodes**\n  - Search for nodes based on one or more keywords\n  - Input: `query` (string)\n    - Space-separated keywords (e.g., \"budget utility\")\n    - Multiple keywords are treated as OR conditions\n  - Searches across:\n    - Entity names\n    - Entity types\n    - Subdomains\n    - Observation content\n  - Matching behavior:\n    - Case-insensitive\n    - Partial word matching\n    - Any keyword can match any field\n    - Returns entities matching ANY of the keywords\n  - Returns matching entities and their relations\n  - Example queries:\n    - Single keyword: \"budget\"\n    - Multiple keywords: \"budget utility\"\n    - With special chars: \"budget & utility\"\n\n- **open_nodes**\n  - Retrieve specific nodes by name\n  - Input: `names` (string[])\n  - Returns:\n    - Requested entities\n    - Relations between requested entities\n  - Silently skips non-existent nodes\n\n# Usage with Claude Desktop\n\n### Setup\n\nAdd this to your claude_desktop_config.json:\n\n#### Docker\n\n```json\n{\n  \"mcpServers\": {\n    \"memory\": {\n      \"command\": \"docker\",\n      \"args\": [\"run\", \"-i\", \"--rm\", \"mcp/memory\"]\n    }\n  }\n}\n```\n\n#### NPX\n```json\n{\n  \"mcpServers\": {\n    \"memory\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@modelcontextprotocol/server-memory\"\n      ]\n    }\n  }\n}\n```\n\n#### NPX with custom setting\n\nThe server can be configured using the following environment variables:\n\n```json\n{\n  \"mcpServers\": {\n    \"memory\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@modelcontextprotocol/server-memory\"\n      ],\n      \"env\": {\n        \"MEMORY_FILE_PATH\": \"/path/to/custom/memory.json\"\n      }\n    }\n  }\n}\n```\n\n- `MEMORY_FILE_PATH`: Path to the memory storage JSON file (default: `memory.json` in the server directory)\n\n### System Prompt\n\nThe prompt for utilizing memory depends on the use case. Changing the prompt will help the model determine the frequency and types of memories created.\n\nHere is an example prompt for chat personalization. You could use this prompt in the \"Custom Instructions\" field of a [Claude.ai Project](https://www.anthropic.com/news/projects). \n\n```\nFollow these steps for each interaction:\n\n1. User Identification:\n   - You should assume that you are interacting with default_user\n   - If you have not identified default_user, proactively try to do so.\n\n2. Memory Retrieval:\n   - Always begin your chat by saying only \"Remembering...\" and retrieve all relevant information from your knowledge graph\n   - Always refer to your knowledge graph as your \"memory\"\n   - When searching your memory, you can use multiple keywords to find related information\n   - Example searches:\n     * Single concept: \"programming\"\n     * Related concepts: \"programming python\"\n     * Specific domain with role: \"work engineer\"\n\n3. Memory Creation:\n   - While conversing with the user, be attentive to any new information that falls into these categories:\n     a) Basic Identity (age, gender, location, job title, education level, etc.)\n     b) Behaviors (interests, habits, etc.)\n     c) Preferences (communication style, preferred language, etc.)\n     d) Goals (goals, targets, aspirations, etc.)\n     e) Relationships (personal and professional relationships up to 3 degrees of separation)\n   - When storing information, use specific and descriptive keywords that will help in future searches\n\n4. Memory Update:\n   - If any new information was gathered during the interaction, update your memory as follows:\n     a) Create entities for recurring organizations, people, and significant events\n     b) Connect them to the current entities using relations\n     c) Store facts about them as observations\n     d) Use clear and searchable terms in entity names and observations to facilitate future retrieval\n```\n\n## Building\n\nDocker:\n\n```sh\ndocker build -t mcp/memory -f src/memory/Dockerfile . \n```\n\n## License\n\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "chats",
        "memory",
        "remembers",
        "information chats",
        "chats using",
        "knowledge persistently"
      ],
      "category": "memory-management"
    },
    "zacharyliner1xds--my-sequential-thinking-mcp": {
      "owner": "zacharyliner1xds",
      "name": "my-sequential-thinking-mcp",
      "url": "https://github.com/zacharyliner1xds/my-sequential-thinking-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/zacharyliner1xds.webp",
      "description": "Facilitates structured sequential thinking by breaking down complex problems into logical steps, validating reasoning chains, and visualizing thinking pathways. Integrates with a Memory Bank for managing and storing reasoning patterns to enhance problem-solving workflows.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-05-01T14:41:11Z",
      "readme_content": "# Sequential Thinking MCP Server\n\nA Model Context Protocol (MCP) server focused on structured sequential thinking capabilities, designed to integrate with Cline's Memory Bank. This server helps break down complex problems into structured sequential steps, track reasoning chains, and store thinking patterns.\n\n## Features\n\n- Create and manage sequential thinking chains for problem-solving\n- Track chains of thought with validation at each step\n- Store and retrieve reasoning patterns\n- Analyze the quality of reasoning processes\n- Visualize thinking pathways\n- Seamlessly integrate with the Memory Bank system\n\n## Architecture\n\nThe server consists of the following core components:\n\n- **Sequential Thinking Engine**: Manages thinking chains, steps, and reasoning validation\n- **Memory Bank Connector**: Integrates with Cline's Memory Bank\n- **Tag Manager**: Implements a comprehensive tagging system\n- **Visualization Generator**: Creates visual representations of thinking chains\n- **Utilities**: File storage, thinking validation, and other helpers\n\n## Available Tools\n\nThe server provides the following MCP tools:\n\n### create_thinking_chain\nCreate a new sequential thinking process with specified parameters.\n- **Input**: problem description, thinking type, context\n- **Output**: chain_id and initial structure\n\n### add_thinking_step\nAdd a step to an existing thinking chain.\n- **Input**: chain_id, step description, reasoning, evidence\n- **Output**: updated step information\n\n### validate_step\nValidate logical connections between steps.\n- **Input**: chain_id, step_id\n- **Output**: validation results, potential issues\n\n### get_chain\nRetrieve a complete thinking chain.\n- **Input**: chain_id\n- **Output**: full chain with all steps\n\n### generate_visualization\nCreate visual representation of a thinking chain.\n- **Input**: chain_id, format (mermaid, json, text)\n- **Output**: visualization code/data\n\n### save_to_memory\nSave a thinking chain to Memory Bank.\n- **Input**: chain_id, memory_name, tags\n- **Output**: confirmation and memory_id\n\n### load_from_memory\nLoad a thinking chain from Memory Bank.\n- **Input**: memory_id or search parameters\n- **Output**: complete chain\n\n### search_related_thinking\nFind related thinking chains based on parameters.\n- **Input**: keywords, tags, thinking_type\n- **Output**: list of relevant chains\n\n### apply_template\nApply a reasoning template to current thinking.\n- **Input**: template_name, problem_context\n- **Output**: pre-structured thinking chain\n\n## Thinking Types\n\nThe server supports various thinking types, each with specific patterns and structures:\n\n- **Analytical** - Break down, analyze, synthesize\n- **Creative** - Diverge, explore, converge\n- **Critical** - Question, evaluate, conclude\n- **Systems** - Map, analyze, model\n- **First-Principles** - Identify, break down, reassemble\n- **Divergent** - Generate alternatives, explore\n- **Convergent** - Analyze, evaluate, select\n- **Inductive** - Observe, pattern, hypothesize\n- **Deductive** - Premise, logic, conclusion\n\n## Templates\n\nThe server includes ready-to-use reasoning templates to jumpstart the thinking process:\n\n- **First Principles Analysis** - Break down a complex problem into its fundamental principles\n- **Systems Thinking Analysis** - Analyze complex systems holistically\n\n## Installation\n\n1. Ensure Node.js v14+ is installed\n2. Clone the repository\n3. Install dependencies:\n   ```\n   npm install\n   ```\n\n## Usage\n\n1. Start the server:\n   ```\n   node index.js\n   ```\n\n2. The server will be available as an MCP server that you can connect to via Claude/Cline\n\n## Memory Bank Integration\n\nThis server is designed to integrate with Cline's Memory Bank, allowing:\n\n1. Reading from Memory Bank files (projectbrief.md, activeContext.md, etc.)\n2. Storing complete thinking chains as structured memories\n3. Updating activeContext.md with reasoning outcomes\n4. Creating links between reasoning and Memory Bank sections\n\n## Example Tool Usage\n\n```javascript\n// Example: Create a new thinking chain\n{\n  \"problem\": \"How to improve user engagement on our platform\",\n  \"thinking_type\": \"systems\",\n  \"context\": \"Our user engagement metrics have decreased by 15% over the past quarter\"\n}\n\n// Example: Add a thinking step\n{\n  \"chain_id\": \"3a7e4fc0-5c1d-4b9f-9d1a-8b5e7c5a9d3e\",\n  \"description\": \"Identify key components of the engagement system\",\n  \"reasoning\": \"User engagement consists of several interconnected components including onboarding, core user actions, notification systems, and retention mechanisms.\",\n  \"evidence\": \"Analysis of our user journey maps and analytics data\",\n  \"confidence\": 0.8\n}\n\n// Example: Generate a visualization\n{\n  \"chain_id\": \"3a7e4fc0-5c1d-4b9f-9d1a-8b5e7c5a9d3e\",\n  \"format\": \"mermaid\",\n  \"options\": {\n    \"showValidation\": true,\n    \"showConfidence\": true\n  }\n}\n```\n\n## Tag System\n\nThe server implements a comprehensive tagging system with multiple dimensions:\n\n- **Thinking Type** - analytical, creative, critical, systems, etc.\n- **Domain** - business, science, technology, art, etc.\n- **Complexity** - simple, moderate, complex\n- **Status** - draft, validated, complete\n- **Custom** - user-defined tags\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "sequential",
        "thinking",
        "memory",
        "sequential thinking",
        "thinking pathways",
        "structured sequential"
      ],
      "category": "memory-management"
    }
  }
}