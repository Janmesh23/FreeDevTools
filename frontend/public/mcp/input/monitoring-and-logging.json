{
  "category": "monitoring-and-logging",
  "categoryDisplay": "Monitoring and Logging",
  "description": "",
  "totalRepositories": 72,
  "repositories": {
    "0xKoda--WireMCP": {
      "owner": "0xKoda",
      "name": "WireMCP",
      "url": "https://github.com/0xKoda/WireMCP",
      "imageUrl": "/freedevtools/mcp/pfp/0xKoda.webp",
      "description": "WireMCP is a server that helps analyze live network traffic for security purposes. It captures and processes network data, making it easier for AI models to detect threats and understand network behavior.",
      "stars": 233,
      "forks": 30,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-10-03T15:42:03Z",
      "readme_content": "# WireMCP\nWireMCP is a Model Context Protocol (MCP) server designed to empower Large Language Models (LLMs) with real-time network traffic analysis capabilities. By leveraging tools built on top of Wireshark's `tshark`, WireMCP captures and processes live network data, providing LLMs with structured context to assist in tasks like threat hunting, network diagnostics, and anomaly detection.\n\n# Features\nWireMCP exposes the following tools to MCP clients, enhancing LLM understanding of network activity:\n\n- **`capture_packets`**: Captures live traffic and returns raw packet data as JSON, enabling LLMs to analyze packet-level details (e.g., IP addresses, ports, HTTP methods).\n- **`get_summary_stats`**: Provides protocol hierarchy statistics, giving LLMs an overview of traffic composition (e.g., TCP vs. UDP usage).\n- **`get_conversations`**: Delivers TCP/UDP conversation statistics, allowing LLMs to track communication flows between endpoints.\n- **`check_threats`**: Captures IPs and checks them against the URLhaus blacklist, equipping LLMs with threat intelligence context for identifying malicious activity.\n- **`check_ip_threats`**: Performs targeted threat intelligence lookups for specific IP addresses against multiple threat feeds, providing detailed reputation and threat data.\n- **`analyze_pcap`**: Analyzes PCAP files to provide comprehensive packet data in JSON format, enabling detailed post-capture analysis of network traffic.\n- **`extract_credentials`**: Scans PCAP files for potential credentials from various protocols (HTTP Basic Auth, FTP, Telnet), aiding in security audits and forensic analysis.\n\n\n## How It Helps LLMs\nWireMCP bridges the gap between raw network data and LLM comprehension by:\n- **Contextualizing Traffic**: Converts live packet captures into structured outputs (JSON, stats) that LLMs can parse and reason about.\n- **Threat Detection**: Integrates IOCs (currently URLhaus) to flag suspicious IPs, enhancing LLM-driven security analysis.\n- **Diagnostics**: Offers detailed traffic insights, enabling LLMs to assist with troubleshooting or identifying anomalies.\n- **Narrative Generation**: LLM's can Transform complex packet captures into coherent stories, making network analysis accessible to non-technical users.\n\n# Installation\n\n## Prerequisites\n- Mac / Windows / Linux\n- [Wireshark](https://www.wireshark.org/download.html) (with `tshark` installed and accessible in PATH)\n- Node.js (v16+ recommended)\n- npm (for dependency installation)\n\n## Setup\n1. Clone the repository:\n   ```bash\n   git clone https://github.com/0xkoda/WireMCP.git\n   cd WireMCP\n   ```\n\n2. Install dependencies:\n   ```bash\n   npm install\n   ```\n\n3. Run the MCP server:\n   ```bash\n   node index.js\n   ```\n\n> **Note**: Ensure `tshark` is in your PATH. WireMCP will auto-detect it or fall back to common install locations (e.g., `/Applications/Wireshark.app/Contents/MacOS/tshark` on macOS).\n\n# Usage with MCP Clients\n\nWireMCP works with any MCP-compliant client. Below are examples for popular clients:\n\n## Example 1: Cursor\n\nEdit `mcp.json` in Cursor -> Settings -> MCP :\n\n```json\n{\n  \"mcpServers\": {\n    \"wiremcp\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/ABSOLUTE_PATH_TO/WireMCP/index.js\"\n      ]\n    }\n  }\n}\n```\n\n**Location (macOS)**: `/Users/YOUR_USER/Library/Application Support/Claude/claude_desktop_config.json`\n\n## Other Clients\n\nThis MCP will work well with any client. Use the command `node /path/to/WireMCP/index.js` in their MCP server settings.\n\n# Example Output\n\nRunning `check_threats` might yield:\n\n```\nCaptured IPs:\n174.67.0.227\n52.196.136.253\n\nThreat check against URLhaus blacklist:\nNo threats detected in URLhaus blacklist.\n```\n\nRunning `analyze_pcap` on a capture file:\n\n```json\n{\n  \"content\": [{\n    \"type\": \"text\",\n    \"text\": \"Analyzed PCAP: ./capture.pcap\\n\\nUnique IPs:\\n192.168.0.2\\n192.168.0.1\\n\\nProtocols:\\neth:ethertype:ip:tcp\\neth:ethertype:ip:tcp:telnet\\n\\nPacket Data:\\n[{\\\"layers\\\":{\\\"frame.number\\\":[\\\"1\\\"],\\\"ip.src\\\":[\\\"192.168.0.2\\\"],\\\"ip.dst\\\":[\\\"192.168.0.1\\\"],\\\"tcp.srcport\\\":[\\\"1550\\\"],\\\"tcp.dstport\\\":[\\\"23\\\"]}}]\"\n  }]\n}\n```\n\n\nLLMs can use these outputs to:\n- Provide natural language explanations of network activity\n- Identify patterns and potential security concerns\n- Offer context-aware recommendations\n- Generate human-readable reports\n\n# Roadmap\n\n- **Expand IOC Providers**: Currently uses URLhaus for threat checks. Future updates will integrate additional sources (e.g., IPsum, Emerging Threats) for broader coverage.\n\n\n# Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.\n\n# License\n\n[MIT](LICENSE)\n\n# Acknowledgments\n\n- Wireshark/tshark team for their excellent packet analysis tools\n- Model Context Protocol community for the framework and specifications\n- URLhaus for providing threat intelligence data",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "wiremcp",
        "monitoring",
        "logging",
        "wiremcp server",
        "0xkoda wiremcp",
        "wiremcp wiremcp"
      ],
      "category": "monitoring-and-logging"
    },
    "0xPratikPatil--NmapMCP": {
      "owner": "0xPratikPatil",
      "name": "NmapMCP",
      "url": "https://github.com/0xPratikPatil/NmapMCP",
      "imageUrl": "/freedevtools/mcp/pfp/0xPratikPatil.webp",
      "description": "NmapMCP is a tool that allows users to perform various types of network scans, helping to identify open ports and discover associated subdomains. It is integrated with the Model Context Protocol for easy use in different applications.",
      "stars": 4,
      "forks": 2,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-09-11T02:35:31Z",
      "readme_content": "# NmapMCP \n[![smithery badge](https://smithery.ai/badge/@0xPratikPatil/nmapmcp)](https://smithery.ai/server/@0xPratikPatil/nmapmcp)\nNmapMCP  is a robust integration of the Nmap scanning tool with the Model Context Protocol (MCP), enabling seamless network scanning capabilities within MCP-compatible environments. This project allows users to perform various network scans, such as top ports scanning, DNS brute force, and more, directly through MCP interfaces.\n\n## Features\n\n-   **Top Ports Scanning:** Quickly identify the most commonly used ports on target hosts to assess potential entry points.\n    \n-   **DNS Brute Force:** Discover subdomains associated with a target domain, aiding in comprehensive domain mapping.\n    \n-   **List Scan:** Obtain a list of active hosts within a specified range without port scanning, useful for network inventory.\n    \n-   **OS Detection:** Determine the operating system of a target host by analyzing network responses, assisting in vulnerability assessment.\n    \n-   **Version Detection:** Identify service versions running on open ports to detect outdated or vulnerable services.\n    \n-   **FIN Scan:** Perform stealthy scans by sending FIN packets to detect open ports without establishing a full connection.\n    \n-   **Idle Scan:** Conduct highly stealthy scans by leveraging idle hosts to probe target systems, minimizing detection risks.\n    \n-   **Ping Scan:** Detect active hosts in a network by sending ICMP echo requests, useful for network mapping.\n    \n-   **SYN Scan:** Perform half-open TCP scans to identify open ports without completing the TCP handshake, reducing detection likelihood.\n    \n-   **TCP Connect Scan:** Establish full TCP connections to probe open ports, useful when SYN scans are not feasible.\n    \n-   **UDP Scan:** Identify open UDP ports on a target host to detect services that do not use TCP.\n    \n-   **Port Scan Only:** Focus solely on scanning ports without additional host discovery, streamlining the scanning process.\n    \n-   **No Port Scan:** Perform host discovery without scanning ports, useful for identifying live hosts without probing services.\n    \n-   **ARP Discovery:** Identify active devices within a local network segment using ARP requests, effective in LAN environments.\n    \n-   **Disable DNS Resolution:** Perform scans without resolving IP addresses to hostnames, enhancing scan speed and reducing DNS query traffic.\n\n## Installation\n\n### Installing via Smithery\n\nTo install Nmap Integration for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@0xPratikPatil/nmapmcp):\n\n```bash\nnpx -y @smithery/cli install @0xPratikPatil/nmapmcp --client claude\n```\n\n### Manual Installation\n1.  **Clone the Repository:**\n    \n    ```bash\n    git clone https://github.com/0xPratikPatil/NmapMCP.git\n    cd NmapMCP\n    ```\n2.  **Install `uv`:**\n    \n    ```bash\n    curl -LsSf https://astral.sh/uv/install.sh | sh\n    ```    \n\n3. **Create environment:**\n\t```bash\n\tuv venv\n\t```\n5.  **Install dependencies from `pyproject.toml`**\n    \n    ```bash\n    uv pip install\n    ```\n    or\n    ```bash\n    uv pip install -r pyproject.toml\n    ```\n\n## Configuration\n\nTo configure the Nmap MCP Server, edit the `claude_desktop_config.json` file located in the project root. This file allows you to set default scan arguments, define MCP tool behaviors, and adjust logging settings.\n\n**Example `claude_desktop_config.json`:**\n\n```json\n{\n  \"mcpServers\": {\n    \"NmapMCP\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/path/to/NmapMCP\",\n        \"run\",\n        \"main.py\"\n      ]\n    }\n  }\n}\n```\n\n## Contributing\n\nContributions are welcome! To contribute:\n\n1.  **Fork the Repository:** Click the \"Fork\" button at the top right of the repository page.\n    \n2.  **Clone Your Fork:**\n    \n    ```bash\n    git clone https://github.com/0xPratikPatil/NmapMCP.git\n    ```\n    \n3.  **Create a New Branch:**\n    \n    ```bash\n    git checkout -b feature/your-feature-name\n    ```\n4.  **Make Your Changes:** Implement your feature or fix.\n    \n5.  **Run Tests:** Ensure all tests pass.\n    \n6.  **Commit Changes:**\n    \n    ```bash\n    git commit -m \"Add feature: your feature name\"\n    ```\n7.  **Push to Your Fork:**\n    \n    ```bash\n    git push origin feature/your-feature-name\n    ```\n8.  **Submit a Pull Request:** Navigate to the original repository and click \"New Pull Request.\"\n    \n\n## License\n\nThis project is licensed under the MIT License.\n\n## Acknowledgments\n\nSpecial thanks to the Nmap and MCP communities for their invaluable tools and support.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "nmapmcp",
        "scans",
        "monitoring",
        "nmapmcp tool",
        "nmapmcp nmapmcp",
        "0xpratikpatil nmapmcp"
      ],
      "category": "monitoring-and-logging"
    },
    "7gugu--whistle-mcp": {
      "owner": "7gugu",
      "name": "whistle-mcp",
      "url": "https://github.com/7gugu/whistle-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/7gugu.webp",
      "description": "The Whistle MCP Server is a tool that allows users to manage their Whistle proxy servers using AI. It simplifies tasks such as network debugging, API testing, and proxy rule management through easy, natural language interactions.",
      "stars": 20,
      "forks": 2,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-17T09:43:13Z",
      "readme_content": "# Whistle MCP Server\n\nEnglish | [中文](README_CN.md)\n[![smithery badge](https://smithery.ai/badge/@7gugu/whistle-mcp)](https://smithery.ai/server/@7gugu/whistle-mcp)\n\n## Project Introduction\n\nWhistle MCP Server is a Whistle proxy management tool based on the Model Context Protocol (MCP), allowing AI assistants to directly operate and control local Whistle proxy servers. Through this tool, AI can help users manage rules, groups, values, monitor network requests, replay and modify requests, etc., without requiring manual operation of the Whistle interface. It greatly simplifies the process of network debugging, API testing, and proxy rule management, enabling users to complete complex network proxy configuration tasks through natural language interaction with AI.\n\n## Features\n\n- **Rule Management**: Create, update, rename, delete, and enable/disable Whistle rules\n- **Group Management**: Create, rename, delete groups, and associate operations between rules and groups\n- **Value Management**: Create, update, rename, and delete values, with support for value group management\n- **Proxy Control**: Enable/disable proxy, HTTP/HTTPS interception, HTTP/2 protocol, etc.\n- **Request Interception**: View intercepted network request information, with URL filtering support\n- **Request Replay**: Support for replaying captured requests with custom request parameters\n- **Multi-Rule Mode**: Support for enabling/disabling multi-rule mode\n\n## Installation\n\n### Installing via Smithery\n\nTo install Whistle MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@7gugu/whistle-mcp):\n\n```bash\nnpx -y @smithery/cli install @7gugu/whistle-mcp --client claude\n```\n\n### Manual Installation\nYou can install Whistle MCP Server globally via npm:\n\n```bash\nnpm install -g whistle-mcp-tool\n```\n\n## MCP Configuration\n\nAfter installation, you can configure Whistle MCP in your MCP JSON configuration file:\n\n```json\n{\n  \"mcpServers\": {\n    \"whistle-mcp\": {\n      \"command\": \"whistle-mcp\",\n      \"args\": [\n        \"--host=<whistle server IP address>\",\n        \"--port=<whistle server port number>\"\n      ]\n    }\n  }\n}\n```\n\n### Configuration Details\n\n- host: Whistle server IP address, defaults to localhost if not configured\n- port: Whistle server port number, defaults to 8899 if not configured\n\n## Configuring MCP JSON in AI Clients\n\n- Claude Client: [https://modelcontextprotocol.io/quickstart/user](https://modelcontextprotocol.io/quickstart/user)\n- Raycast: Requires MCP plugin installation\n- Cursor: [https://docs.cursor.com/context/model-context-protocol#configuring-mcp-servers](https://docs.cursor.com/context/model-context-protocol#configuring-mcp-servers)\n\n## MCP Tools Description\n\nWhistle MCP Server provides the following tools, which can be called via the MCP protocol:\n\n### Rule Management\n\n| Tool Name | Description | Function |\n| ------- | --- | ---- |\n| getRules | Get all rules | List all created rules and their content |\n| createRule | Create new rule | Create a new rule with the specified name |\n| updateRule | Update rule content | Modify the content of a specified rule |\n| renameRule | Rename rule | Rename a rule to a new name |\n| deleteRule | Delete rule | Delete a rule with the specified name |\n| selectRule | Enable rule | Enable a rule with the specified name |\n| unselectRule | Disable rule | Disable a rule with the specified name |\n| disableAllRules | Disable all rules | Disable all created rules at once |\n\n### Group Management\n\n| Tool Name | Description | Function |\n| ------- | --- | ---- |\n| createGroup | Create group | Create a new rule group with the specified name |\n| renameGroup | Rename group | Rename a rule group to a new name |\n| deleteGroup | Delete group | Delete a rule group with the specified name |\n| moveRuleToGroup | Move rule to group | Move a specified rule to a specific group |\n| moveRuleOutOfGroup | Move rule out of group | Move a rule out of its group to the top level |\n\n### Value Management\n\n| Tool Name | Description | Function |\n| ------- | --- | ---- |\n| getAllValues | Get all values | List all created values and value groups |\n| createValue | Create new value | Create a new value with the specified name |\n| updateValue | Update value content | Modify the content of a specified value |\n| renameValue | Rename value | Rename a value to a new name |\n| deleteValue | Delete value | Delete a value with the specified name |\n| createValueGroup | Create value group | Create a new value group with the specified name |\n| renameValueGroup | Rename value group | Rename a value group to a new name |\n| deleteValueGroup | Delete value group | Delete a value group with the specified name |\n| moveValueToGroup | Move value to group | Move a specified value to a specific group |\n| moveValueOutOfGroup | Move value out of group | Move a value out of its group to the top level |\n\n### Proxy Control\n\n| Tool Name | Description | Function |\n| ------- | --- | ---- |\n| getStatus | Get server status | Get the current status information of the Whistle server |\n| toggleProxy | Enable/disable proxy | Toggle the enabled state of the Whistle proxy |\n| toggleHttpsInterception | Enable/disable HTTPS interception | Toggle the enabled state of HTTPS request interception |\n| toggleHttp2 | Enable/disable HTTP2 | Toggle the enabled state of HTTP/2 protocol support |\n| toggleMultiRuleMode | Enable/disable multi-rule mode | Toggle whether to allow multiple rules to be enabled simultaneously |\n\n### Request Management\n\n| Tool Name | Description | Function |\n| ------- | --- | ---- |\n| getInterceptInfo | Get interception information | Get network request information intercepted by Whistle, with filtering support |\n| replayRequest | Replay request | Resend a specified network request with customizable parameters |\n\n## Contact Information\n\n- Email: [gz7gugu@qq.com](mailto:gz7gugu@qq.com)\n- Blog: [https://7gugu.com](https://7gugu.com)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "whistle",
        "logging",
        "monitoring",
        "whistle mcp",
        "mcp whistle",
        "whistle proxy"
      ],
      "category": "monitoring-and-logging"
    },
    "AVIMBU--uptime_agent_mcp": {
      "owner": "AVIMBU",
      "name": "uptime_agent_mcp",
      "url": "https://github.com/AVIMBU/uptime_agent_mcp",
      "imageUrl": "/freedevtools/mcp/pfp/AVIMBU.webp",
      "description": "Connects Uptime Agent monitoring systems to AI assistants for real-time monitoring, incident management, and creation of monitoring tasks using natural language commands. Enables secure integration of uptime monitoring with AI workflows for improved operational insights.",
      "stars": 1,
      "forks": 2,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-09-20T12:16:05Z",
      "readme_content": "# 🚀 Uptime Agent MCP Server\n\n[![GitHub license](https://img.shields.io/badge/license-MIT-blue.svg)](https://opensource.org/licenses/MIT)\n[![Node.js Version](https://img.shields.io/badge/node-%3E%3D18.0.0-brightgreen)](https://nodejs.org/)\n[![Model Context Protocol](https://img.shields.io/badge/MCP-Compliant-orange)](https://modelcontextprotocol.io/)\n[![smithery badge](https://smithery.ai/badge/@AVIMBU/uptime_agent_mcp)](https://smithery.ai/server/@AVIMBU/uptime_agent_mcp)\n\nConnect your [Uptime Agent](https://uptime-agent.io) monitoring system directly to AI assistants like Claude through the Model Context Protocol (MCP).\n\n## ✨ Features\n\n- **Real-time Monitoring Access**: Allow AI assistants to check your system's uptime status\n- **Incident Management**: View and analyze downtime incidents through natural conversation\n- **Monitor Creation**: Set up new monitoring endpoints with simple voice or text commands\n- **Secure Integration**: Enterprise-grade security for your monitoring infrastructure\n\n## 🔍 What is Uptime Agent?\n\n[Uptime Agent](https://uptime-agent.io) is a powerful monitoring solution that tracks your websites and API endpoints, alerting you when they go down. This MCP server extends Uptime Agent's capabilities by letting you interact with your monitoring system through AI assistants.\n\n## 🛠️ Installation\n\n### Prerequisites\n\n- Node.js 18 or higher\n- An active Uptime Agent account\n- Your Uptime Agent API key\n\nTo obtain your Uptime Agent API key:\n1. Log in to your [Uptime Agent Dashboard](https://uptime-agent.io/dashboard)\n2. Navigate to Account → API Keys\n3. Create a new API key with appropriate permissions\n4. Copy the generated key for use with the MCP server\n\n### Option 1: Quick Install via NPM (Recommended)\n\nThe fastest way to get started is with our setup command:\n\n```bash\nnpx uptime-agent-mcp setup\n```\n\nThis command will:\n- Install the MCP server\n- Configure it for use with Claude Desktop\n- Prompt you for your Uptime Agent API key\n- Set up all necessary configurations automatically\n\n### Option 2: Install via Smithery.ai\n\nTo install using Smithery.ai:\n\n1. Create an account at [smithery.ai](https://smithery.ai)\n2. Get your personal key from your Smithery account\n3. Run the following command:\n\n```bash\nnpx -y @smithery/cli@latest install @AVIMBU/uptime_agent_mcp --client claude --key <personal_key>\n```\n\nReplace `<personal_key>` with your actual Smithery personal key.\n\n### Option 3: Manual Local Installation\n\nFor advanced users who want more control:\n\n```bash\n# Clone the repository\ngit clone https://github.com/AVIMBU/uptime_agent_mcp.git\ncd uptime_agent_mcp\n\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n```\n\nConfigure with your API key by creating a `.env` file:\n\n```\nUPTIME_API_KEY=your-api-key-here\nPORT=3000  # Optional, defaults to 3000\n```\n\nStart the server:\n\n```bash\nnpm start\n# or directly with\nnode dist/index.js\n```\n\n## 🤖 AI Assistant Integration\n\n### Setting Up with Claude Desktop\n\nAfter installing using one of the methods above, your MCP server is automatically configured for Claude Desktop.\n\nIf you installed manually, add the following to your `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"uptime-agent\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"uptime-agent-mcp\"\n      ],\n      \"env\": {\n        \"UPTIME_API_KEY\": \"<YOUR_API_KEY>\"\n      }\n    }\n  }\n}\n```\n\nAlternatively, you can use Docker:\n\n```json\n{\n  \"mcpServers\": {\n    \"uptime-agent\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-e\",\n        \"UPTIME_API_KEY\",\n        \"uptime-agent-mcp\"\n      ],\n      \"env\": {\n        \"UPTIME_API_KEY\": \"<YOUR_API_KEY>\"\n      }\n    }\n  }\n}\n```\n\n### Example Conversations\n\n**Checking Monitors:**\n> \"Claude, show me all my active uptime monitors.\"\n\n**Creating a New Monitor:**\n> \"Please create a new monitor for our API endpoint at https://api.mycompany.com/v2/health\"\n\n**Analyzing Incidents:**\n> \"What incidents happened on our production servers last week, and what was the average downtime?\"\n\n## 📊 Available Functions\n\n### Monitor Operations\n\n| Function | Description | Parameters |\n|----------|-------------|------------|\n| `listMonitors` | Get a complete list of all monitoring endpoints | None required |\n| `getMonitor` | Retrieve detailed information about a specific monitor | `id`: Monitor identifier |\n| `createMonitor` | Set up a new endpoint to monitor | `name`: Monitor name<br>`url`: URL to monitor<br>`tracking_type`: Type of monitoring (http, ping, etc.)<br>`check_frequency`: Check interval in seconds |\n\n### Incident Management\n\n| Function | Description | Parameters |\n|----------|-------------|------------|\n| `listIncidents` | View all detected downtime incidents | None required |\n| `getIncident` | Get detailed information about a specific incident | `id`: Incident identifier |\n| `listIncidentsByMonitor` | See all incidents for a particular endpoint | `monitor_id`: Monitor identifier |\n\n### Public Tracking\n\n| Function | Description | Parameters |\n|----------|-------------|------------|\n| `createAnonymousTracking` | Create public tracking without authentication | `url`: URL to monitor<br>`name`: (Optional) Name for the tracking |\n\n### Integration with Slack (Coming Soon)\n\n| Function | Description | Parameters |\n|----------|-------------|------------|\n| `slack_get_users` | List all users in connected Slack workspace | `limit`: Max number of users<br>`cursor`: Pagination cursor |\n| `slack_post_message` | Post notifications to Slack | `channel_id`: Channel to post to<br>`text`: Message content |\n\n## 🐳 Docker Deployment\n\nWe provide Docker support for easy deployment:\n\n```bash\n# Build the Docker image\ndocker build -t uptime-agent-mcp .\n\n# Run the container\ndocker run -p 3000:3000 -e UPTIME_API_KEY=your-api-key uptime-agent-mcp\n```\n\n## 📬 Support\n\nIf you have questions or need assistance:\n\n- [Open an issue](https://github.com/AVIMBU/uptime_agent_mcp/issues) on GitHub\n- Contact us through our website: [AVIMBU](https://avimbu.com)\n\n## 📜 License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n---\n\n<p align=\"center\">Developed with ❤️ by <a href=\"https://avimbu.com\">AVIMBU</a></p>",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "uptime_agent_mcp",
        "monitoring",
        "uptime",
        "avimbu uptime_agent_mcp",
        "uptime agent",
        "uptime monitoring"
      ],
      "category": "monitoring-and-logging"
    },
    "Arize-ai--phoenix": {
      "owner": "Arize-ai",
      "name": "phoenix",
      "url": "https://github.com/Arize-ai/phoenix",
      "imageUrl": "/freedevtools/mcp/pfp/Arize-ai.webp",
      "description": "Provides advanced observability and evaluation tools for AI applications, facilitating performance tracking, dataset management, and prompt engineering. Integrates with various frameworks and large language model providers for seamless operation.",
      "stars": 7159,
      "forks": 582,
      "license": "Other",
      "language": "Jupyter Notebook",
      "updated_at": "2025-10-04T10:53:21Z",
      "readme_content": "<p align=\"center\">\n    <a target=\"_blank\" href=\"https://phoenix.arize.com\" style=\"background:none\">\n        <img alt=\"phoenix banner\" src=\"https://github.com/Arize-ai/phoenix-assets/blob/main/images/socal/github-large-banner-phoenix-v2.jpg?raw=true\" width=\"auto\" height=\"auto\"></img>\n    </a>\n    <br/>\n    <br/>\n    <a href=\"https://arize.com/docs/phoenix/\">\n        <img alt=\"CA7LwkvHqaIJ9pLI6Lmy1BigDy2EV8tjdzh_8XB6MGSLKH4INsZXDJ8MGhIBK_Mrpo_GnRIBO_MrZjFAFxoTNBwCvj6u4qvSZJiM3iNX4yvmHoA9Sh4PF0QAzBEBMEcEwBwRAHNEAMwRAXBGKfUfr5hKvglRfO4AAAAASUVORK5CYII_labelColor_grey_color_blue_logoColor_white_label\" src=\"https://img.shields.io/static/v1?message=Docs&logo=data:image/png;base64,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&labelColor=grey&color=blue&logoColor=white&label=%20\"/>\n    </a>\n    <a target=\"_blank\" href=\"https://arize-ai.slack.com/join/shared_invite/zt-11t1vbu4x-xkBIHmOREQnYnYDH1GDfCg?__hstc=259489365.a667dfafcfa0169c8aee4178d115dc81.1733501603539.1733501603539.1733501603539.1&__hssc=259489365.1.1733501603539&__hsfp=3822854628&submissionGuid=381a0676-8f38-437b-96f2-fc10875658df#/shared-invite/email\">\n        <img alt=\"v1_message_Community_logo_slack_labelColor_grey_color_blue_logoColor_white_label\" src=\"https://img.shields.io/static/v1?message=Community&logo=slack&labelColor=grey&color=blue&logoColor=white&label=%20\"/>\n    </a>\n     <a target=\"_blank\" href=\"https://bsky.app/profile/arize-phoenix.bsky.social\">\n        <img alt=\"phoenix_blue_svg_color_blue_labelColor_gray_logo_bluesky\" src=\"https://img.shields.io/badge/-phoenix-blue.svg?color=blue&labelColor=gray&logo=bluesky\">\n    </a>\n    <a target=\"_blank\" href=\"https://x.com/ArizePhoenix\">\n        <img alt=\"ArizePhoenix_blue_svg_color_blue_labelColor_gray_logo_x\" src=\"https://img.shields.io/badge/-ArizePhoenix-blue.svg?color=blue&labelColor=gray&logo=x\">\n    </a>\n    <a target=\"_blank\" href=\"https://pypi.org/project/arize-phoenix/\">\n        <img alt=\"arize_phoenix_color_blue\" src=\"https://img.shields.io/pypi/v/arize-phoenix?color=blue\">\n    </a>\n    <a target=\"_blank\" href=\"https://anaconda.org/conda-forge/arize-phoenix\">\n        <img alt=\"arize_phoenix_svg_color_blue\" src=\"https://img.shields.io/conda/vn/conda-forge/arize-phoenix.svg?color=blue\">\n    </a>\n    <a target=\"_blank\" href=\"https://pypi.org/project/arize-phoenix/\">\n        <img alt=\"arize_phoenix\" src=\"https://img.shields.io/pypi/pyversions/arize-phoenix\">\n    </a>\n    <a target=\"_blank\" href=\"https://hub.docker.com/r/arizephoenix/phoenix/tags\">\n        <img alt=\"phoenix_sort_semver_logo_docker_label_image_color_blue\" src=\"https://img.shields.io/docker/v/arizephoenix/phoenix?sort=semver&logo=docker&label=image&color=blue\">\n    </a>\n    <a target=\"_blank\" href=\"https://hub.docker.com/r/arizephoenix/phoenix-helm\">\n        <img alt=\"Helm_blue_style_flat_logo_helm_labelColor_grey\" src=\"https://img.shields.io/badge/Helm-blue?style=flat&logo=helm&labelColor=grey\"/>\n    </a>\n    <a target=\"_blank\" href=\"https://github.com/Arize-ai/phoenix/tree/main/js/packages/phoenix-mcp\">\n        <img alt=\"badge_mcpx_dev_status_on\" src=\"https://badge.mcpx.dev?status=on\" title=\"MCP Enabled\"/>\n    </a>\n    <a href=\"cursor://anysphere.cursor-deeplink/mcp/install?name=phoenix&config=eyJjb21tYW5kIjoibnB4IC15IEBhcml6ZWFpL3Bob2VuaXgtbWNwQGxhdGVzdCAtLWJhc2VVcmwgaHR0cHM6Ly9teS1waG9lbml4LmNvbSAtLWFwaUtleSB5b3VyLWFwaS1rZXkifQ%3D%3D\"><img src=\"https://cursor.com/deeplink/mcp-install-dark.svg\" alt=\"Add Arize Phoenix MCP server to Cursor\" height=20 /></a>\n</p>\n\nPhoenix is an open-source AI observability platform designed for experimentation, evaluation, and troubleshooting. It provides:\n\n- [**_Tracing_**](https://arize.com/docs/phoenix/tracing/llm-traces) - Trace your LLM application's runtime using OpenTelemetry-based instrumentation.\n- [**_Evaluation_**](https://arize.com/docs/phoenix/evaluation/llm-evals) - Leverage LLMs to benchmark your application's performance using response and retrieval evals.\n- [**_Datasets_**](https://arize.com/docs/phoenix/datasets-and-experiments/overview-datasets) - Create versioned datasets of examples for experimentation, evaluation, and fine-tuning.\n- [**_Experiments_**](https://arize.com/docs/phoenix/datasets-and-experiments/overview-datasets#experiments) - Track and evaluate changes to prompts, LLMs, and retrieval.\n- [**_Playground_**](https://arize.com/docs/phoenix/prompt-engineering/overview-prompts)- Optimize prompts, compare models, adjust parameters, and replay traced LLM calls.\n- [**_Prompt Management_**](https://arize.com/docs/phoenix/prompt-engineering/overview-prompts/prompt-management)- Manage and test prompt changes systematically using version control, tagging, and experimentation.\n\nPhoenix is vendor and language agnostic with out-of-the-box support for popular frameworks (🦙[LlamaIndex](https://arize.com/docs/phoenix/tracing/integrations-tracing/llamaindex), 🦜⛓[LangChain](https://arize.com/docs/phoenix/tracing/integrations-tracing/langchain), [Haystack](https://arize.com/docs/phoenix/tracing/integrations-tracing/haystack), 🧩[DSPy](https://arize.com/docs/phoenix/tracing/integrations-tracing/dspy), 🤗[smolagents](https://arize.com/docs/phoenix/tracing/integrations-tracing/hfsmolagents)) and LLM providers ([OpenAI](https://arize.com/docs/phoenix/tracing/integrations-tracing/openai), [Bedrock](https://arize.com/docs/phoenix/tracing/integrations-tracing/bedrock), [MistralAI](https://arize.com/docs/phoenix/tracing/integrations-tracing/mistralai), [VertexAI](https://arize.com/docs/phoenix/tracing/integrations-tracing/vertexai), [LiteLLM](https://arize.com/docs/phoenix/tracing/integrations-tracing/litellm), [Google GenAI](https://arize.com/docs/phoenix/tracing/integrations-tracing/google-genai) and more). For details on auto-instrumentation, check out the [OpenInference](https://github.com/Arize-ai/openinference) project.\n\nPhoenix runs practically anywhere, including your local machine, a Jupyter notebook, a containerized deployment, or in the cloud.\n\n## Installation\n\nInstall Phoenix via `pip` or `conda`\n\n```shell\npip install arize-phoenix\n```\n\nPhoenix container images are available via [Docker Hub](https://hub.docker.com/r/arizephoenix/phoenix) and can be deployed using Docker or Kubernetes. Arize AI also provides cloud instances at [app.phoenix.arize.com](https://app.phoenix.arize.com/).\n\n## Packages\n\nThe `arize-phoenix` package includes the entire Phoenix platfom. However if you have deployed the Phoenix platform, there are light-weight Python sub-packages and TypeScript packages that can be used in conjunction with the platfrom.\n\n### Subpackages\n\n| Package                                                                                             | Version & Docs                                                                                                                                                                                                                                                                      | Description                                                                                       |\n| --------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------- |\n| [arize-phoenix-otel](https://github.com/Arize-ai/phoenix/tree/main/packages/phoenix-otel)           | [![PyPI Version](https://img.shields.io/pypi/v/arize-phoenix-otel)](https://pypi.org/project/arize-phoenix-otel/) [![Docs](https://img.shields.io/badge/docs-blue?logo=readthedocs&logoColor=white)](https://arize-phoenix.readthedocs.io/projects/otel/en/latest/index.html)       | Provides a lightweight wrapper around OpenTelemetry primitives with Phoenix-aware defaults        |\n| [arize-phoenix-client](https://github.com/Arize-ai/phoenix/tree/main/packages/phoenix-client)       | [![PyPI Version](https://img.shields.io/pypi/v/arize-phoenix-client)](https://pypi.org/project/arize-phoenix-client/) [![Docs](https://img.shields.io/badge/docs-blue?logo=readthedocs&logoColor=white)](https://arize-phoenix.readthedocs.io/projects/client/en/latest/index.html) | Lightweight client for interacting with the Phoenix server via its OpenAPI REST interface         |\n| [arize-phoenix-evals](https://github.com/Arize-ai/phoenix/tree/main/packages/phoenix-evals)         | [![PyPI Version](https://img.shields.io/pypi/v/arize-phoenix-evals)](https://pypi.org/project/arize-phoenix-evals/) [![Docs](https://img.shields.io/badge/docs-blue?logo=readthedocs&logoColor=white)](https://arize-phoenix.readthedocs.io/projects/evals/en/latest/index.html)    | Tooling to evaluate LLM applications including RAG relevance, answer relevance, and more          |\n| [@arizeai/phoenix-client](https://github.com/Arize-ai/phoenix/tree/main/js/packages/phoenix-client) | [![NPM Version](https://img.shields.io/npm/v/%40arizeai%2Fphoenix-client)](https://www.npmjs.com/package/@arizeai/phoenix-client) [![Docs](https://img.shields.io/badge/docs-blue?logo=typescript&logoColor=white)](https://arize-ai.github.io/phoenix/)                            | Client for the Arize Phoenix API                                                                  |\n| [@arizeai/phoenix-evals](https://github.com/Arize-ai/phoenix/tree/main/js/packages/phoenix-evals)   | [![NPM Version](https://img.shields.io/npm/v/%40arizeai%2Fphoenix-evals)](https://www.npmjs.com/package/@arizeai/phoenix-evals) [![Docs](https://img.shields.io/badge/docs-blue?logo=typescript&logoColor=white)](https://arize-ai.github.io/phoenix/)                              | TypeScript evaluation library for LLM applications (alpha release)                                |\n| [@arizeai/phoenix-mcp](https://github.com/Arize-ai/phoenix/tree/main/js/packages/phoenix-mcp)       | [![NPM Version](https://img.shields.io/npm/v/%40arizeai%2Fphoenix-mcp)](https://www.npmjs.com/package/@arizeai/phoenix-mcp) [![Docs](https://img.shields.io/badge/docs-blue?logo=markdown&logoColor=white)](./js/packages/phoenix-mcp/README.md)                                    | MCP server implementation for Arize Phoenix providing unified interface to Phoenix's capabilities |\n\n## Tracing Integrations\n\nPhoenix is built on top of OpenTelemetry and is vendor, language, and framework agnostic. For details about tracing integrations and example applications, see the [OpenInference](https://github.com/Arize-ai/openinference) project.\n\n**Python Integrations**\n| Integration | Package | Version Badge |\n|------------------|-----------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------|\n| [OpenAI](https://arize.com/docs/phoenix/tracing/integrations-tracing/openai) | `openinference-instrumentation-openai` | [![PyPI Version](https://img.shields.io/pypi/v/openinference-instrumentation-openai.svg)](https://pypi.python.org/pypi/openinference-instrumentation-openai) |\n| [OpenAI Agents](https://arize.com/docs/phoenix/tracing/integrations-tracing/openai-agents-sdk) | `openinference-instrumentation-openai-agents` | [![PyPI Version](https://img.shields.io/pypi/v/openinference-instrumentation-openai-agents.svg)](https://pypi.python.org/pypi/openinference-instrumentation-openai-agents) |\n| [LlamaIndex](https://arize.com/docs/phoenix/tracing/integrations-tracing/llamaindex) | `openinference-instrumentation-llama-index` | [![PyPI Version](https://img.shields.io/pypi/v/openinference-instrumentation-llama-index.svg)](https://pypi.python.org/pypi/openinference-instrumentation-llama-index) |\n| [DSPy](https://arize.com/docs/phoenix/tracing/integrations-tracing/dspy) | `openinference-instrumentation-dspy` | [![PyPI Version](https://img.shields.io/pypi/v/openinference-instrumentation-dspy.svg)](https://pypi.python.org/pypi/openinference-instrumentation-dspy) |\n| [AWS Bedrock](https://arize.com/docs/phoenix/tracing/integrations-tracing/bedrock) | `openinference-instrumentation-bedrock` | [![PyPI Version](https://img.shields.io/pypi/v/openinference-instrumentation-bedrock.svg)](https://pypi.python.org/pypi/openinference-instrumentation-bedrock) |\n| [LangChain](https://arize.com/docs/phoenix/tracing/integrations-tracing/langchain) | `openinference-instrumentation-langchain` | [![PyPI Version](https://img.shields.io/pypi/v/openinference-instrumentation-langchain.svg)](https://pypi.python.org/pypi/openinference-instrumentation-langchain) |\n| [MistralAI](https://arize.com/docs/phoenix/tracing/integrations-tracing/mistralai) | `openinference-instrumentation-mistralai` | [![PyPI Version](https://img.shields.io/pypi/v/openinference-instrumentation-mistralai.svg)](https://pypi.python.org/pypi/openinference-instrumentation-mistralai) |\n| [Google GenAI](https://arize.com/docs/phoenix/tracing/integrations-tracing/google-gen-ai) | `openinference-instrumentation-google-genai` | [![PyPI Version](https://img.shields.io/pypi/v/openinference-instrumentation-google-genai.svg)](https://pypi.python.org/pypi/openinference-instrumentation-google-genai) |\n| [Google ADK](https://arize.com/docs/phoenix/integrations/llm-providers/google-gen-ai/google-adk-tracing) | `openinference-instrumentation-google-adk` | [![PyPI Version](https://img.shields.io/pypi/v/openinference-instrumentation-google-adk.svg)](https://pypi.python.org/pypi/openinference-instrumentation-google-adk) |\n| [Guardrails](https://arize.com/docs/phoenix/tracing/integrations-tracing/guardrails) | `openinference-instrumentation-guardrails` | [![PyPI Version](https://img.shields.io/pypi/v/openinference-instrumentation-guardrails.svg)](https://pypi.python.org/pypi/openinference-instrumentation-guardrails) |\n| [VertexAI](https://arize.com/docs/phoenix/tracing/integrations-tracing/vertexai) | `openinference-instrumentation-vertexai` | [![PyPI Version](https://img.shields.io/pypi/v/openinference-instrumentation-vertexai.svg)](https://pypi.python.org/pypi/openinference-instrumentation-vertexai) |\n| [CrewAI](https://arize.com/docs/phoenix/tracing/integrations-tracing/crewai) | `openinference-instrumentation-crewai` | [![PyPI Version](https://img.shields.io/pypi/v/openinference-instrumentation-crewai.svg)](https://pypi.python.org/pypi/openinference-instrumentation-crewai) |\n| [Haystack](https://arize.com/docs/phoenix/tracing/integrations-tracing/haystack) | `openinference-instrumentation-haystack` | [![PyPI Version](https://img.shields.io/pypi/v/openinference-instrumentation-haystack.svg)](https://pypi.python.org/pypi/openinference-instrumentation-haystack) |\n| [LiteLLM](https://arize.com/docs/phoenix/tracing/integrations-tracing/litellm) | `openinference-instrumentation-litellm` | [![PyPI Version](https://img.shields.io/pypi/v/openinference-instrumentation-litellm.svg)](https://pypi.python.org/pypi/openinference-instrumentation-litellm) |\n| [Groq](https://arize.com/docs/phoenix/tracing/integrations-tracing/groq) | `openinference-instrumentation-groq` | [![PyPI Version](https://img.shields.io/pypi/v/openinference-instrumentation-groq.svg)](https://pypi.python.org/pypi/openinference-instrumentation-groq) |\n| [Instructor](https://arize.com/docs/phoenix/tracing/integrations-tracing/instructor) | `openinference-instrumentation-instructor` | [![PyPI Version](https://img.shields.io/pypi/v/openinference-instrumentation-instructor.svg)](https://pypi.python.org/pypi/openinference-instrumentation-instructor) |\n| [Anthropic](https://arize.com/docs/phoenix/tracing/integrations-tracing/anthropic) | `openinference-instrumentation-anthropic` | [![PyPI Version](https://img.shields.io/pypi/v/openinference-instrumentation-anthropic.svg)](https://pypi.python.org/pypi/openinference-instrumentation-anthropic) |\n| [Smolagents](https://huggingface.co/docs/smolagents/en/tutorials/inspect_runs) | `openinference-instrumentation-smolagents` | [![PyPI Version](https://img.shields.io/pypi/v/openinference-instrumentation-smolagents.svg)](https://pypi.python.org/pypi/openinference-instrumentation-smolagents) |\n| [Agno](https://arize.com/docs/phoenix/tracing/integrations-tracing/agno) | `openinference-instrumentation-agno` | [![PyPI Version](https://img.shields.io/pypi/v/openinference-instrumentation-agno.svg)](https://pypi.python.org/pypi/openinference-instrumentation-agno) |\n| [MCP](https://arize.com/docs/phoenix/tracing/integrations-tracing/model-context-protocol-mcp) | `openinference-instrumentation-mcp` | [![PyPI Version](https://img.shields.io/pypi/v/openinference-instrumentation-mcp.svg)](https://pypi.python.org/pypi/openinference-instrumentation-mcp) |\n| [Pydantic AI](https://arize.com/docs/phoenix/integrations/pydantic) | `openinference-instrumentation-pydantic-ai` | [![PyPI Version](https://img.shields.io/pypi/v/openinference-instrumentation-pydantic-ai.svg)](https://pypi.python.org/pypi/openinference-instrumentation-pydantic-ai) |\n| [Autogen AgentChat](https://arize.com/docs/phoenix/integrations/frameworks/autogen/autogen-tracing) | `openinference-instrumentation-autogen-agentchat` | [![PyPI Version](https://img.shields.io/pypi/v/openinference-instrumentation-autogen-agentchat.svg)](https://pypi.python.org/pypi/openinference-instrumentation-autogen-agentchat) |\n| [Portkey](https://arize.com/docs/phoenix/integrations/portkey) | `openinference-instrumentation-portkey` | [![PyPI Version](https://img.shields.io/pypi/v/openinference-instrumentation-portkey.svg)](https://pypi.python.org/pypi/openinference-instrumentation-portkey) |\n\n## Span Processors\n\nNormalize and convert data across other instrumentation libraries by adding span processors that unify data.\n\n| Package                                                                                                           | Description                                                      | Version                                                                                                                                                                |\n| ----------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| [`openinference-instrumentation-openlit`](./python/instrumentation/openinference-instrumentation-openlit)         | OpenInference Span Processor for OpenLIT traces.                 | [![PyPI Version](https://img.shields.io/pypi/v/openinference-instrumentation-openlit.svg)](https://pypi.python.org/pypi/openinference-instrumentation-openlit)         |\n| [`openinference-instrumentation-openllmetry`](./python/instrumentation/openinference-instrumentation-openllmetry) | OpenInference Span Processor for OpenLLMetry (Traceloop) traces. | [![PyPI Version](https://img.shields.io/pypi/v/openinference-instrumentation-openllmetry.svg)](https://pypi.python.org/pypi/openinference-instrumentation-openllmetry) |\n\n### JavaScript Integrations\n\n| Integration                                                                                | Package                                            | Version Badge                                                                                                                                                                       |\n| ------------------------------------------------------------------------------------------ | -------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| [OpenAI](https://arize.com/docs/phoenix/tracing/integrations-tracing/openai-node-sdk)      | `@arizeai/openinference-instrumentation-openai`    | [![NPM Version](https://img.shields.io/npm/v/@arizeai/openinference-instrumentation-openai.svg)](https://www.npmjs.com/package/@arizeai/openinference-instrumentation-openai)       |\n| [LangChain.js](https://arize.com/docs/phoenix/tracing/integrations-tracing/langchain)      | `@arizeai/openinference-instrumentation-langchain` | [![NPM Version](https://img.shields.io/npm/v/@arizeai/openinference-instrumentation-langchain.svg)](https://www.npmjs.com/package/@arizeai/openinference-instrumentation-langchain) |\n| [Vercel AI SDK](https://arize.com/docs/phoenix/tracing/integrations-tracing/vercel-ai-sdk) | `@arizeai/openinference-vercel`                    | [![NPM Version](https://img.shields.io/npm/v/@arizeai/openinference-vercel)](https://www.npmjs.com/package/@arizeai/openinference-vercel)                                           |\n| [BeeAI](https://arize.com/docs/phoenix/tracing/integrations-tracing/beeai)                 | `@arizeai/openinference-instrumentation-beeai`     | [![NPM Version](https://img.shields.io/npm/v/@arizeai/openinference-vercel)](https://www.npmjs.com/package/@arizeai/openinference-instrumentation-beeai)                            |\n| [Mastra](https://arize.com/docs/phoenix/integrations/mastra)                               | `@arizeai/openinference-mastra`                    | [![NPM Version](https://img.shields.io/npm/v/@arizeai/openinference-mastra.svg)](https://www.npmjs.com/package/@arizeai/openinference-mastra)                                       |\n\n### Java Integrations\n\n| Integration                                                                                                                       | Package                                     | Version Badge                                                                                                                                                                                                 |\n| --------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| [LangChain4j](https://github.com/Arize-ai/openinference/tree/main/java/instrumentation/openinference-instrumentation-langchain4j) | `openinference-instrumentation-langchain4j` | [![Maven Central](https://img.shields.io/maven-central/v/com.arize/openinference-instrumentation-langchain4j.svg)](https://central.sonatype.com/artifact/com.arize/openinference-instrumentation-langchain4j) |\n| SpringAI                                                                                                                          | `openinference-instrumentation-springAI`    | [![Maven Central](https://img.shields.io/maven-central/v/com.arize/openinference-instrumentation-springAI.svg)](https://central.sonatype.com/artifact/com.arize/openinference-instrumentation-springAI)       |\n\n### Platforms\n\n| Platform                                                                                                 | Description                                                    | Docs                                                                                                              |\n| -------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------- |\n| [BeeAI](https://docs.beeai.dev/observability/agents-traceability)                                        | AI agent framework with built-in observability                 | [Integration Guide](https://docs.beeai.dev/observability/agents-traceability)                                     |\n| [Dify](https://docs.dify.ai/en/guides/monitoring/integrate-external-ops-tools/integrate-phoenix)         | Open-source LLM app development platform                       | [Integration Guide](https://docs.dify.ai/en/guides/monitoring/integrate-external-ops-tools/integrate-phoenix)     |\n| [Envoy AI Gateway](https://github.com/envoyproxy/ai-gateway)                                             | AI Gateway built on Envoy Proxy for AI workloads               | [Integration Guide](https://github.com/envoyproxy/ai-gateway/tree/main/cmd/aigw#opentelemetry-setup-with-phoenix) |\n| [LangFlow](https://arize.com/docs/phoenix/tracing/integrations-tracing/langflow)                         | Visual framework for building multi-agent and RAG applications | [Integration Guide](https://arize.com/docs/phoenix/tracing/integrations-tracing/langflow)                         |\n| [LiteLLM Proxy](https://docs.litellm.ai/docs/observability/phoenix_integration#using-with-litellm-proxy) | Proxy server for LLMs                                          | [Integration Guide](https://docs.litellm.ai/docs/observability/phoenix_integration#using-with-litellm-proxy)      |\n\n## Community\n\nJoin our community to connect with thousands of AI builders.\n\n- 🌍 Join our [Slack community](https://arize-ai.slack.com/join/shared_invite/zt-11t1vbu4x-xkBIHmOREQnYnYDH1GDfCg?__hstc=259489365.a667dfafcfa0169c8aee4178d115dc81.1733501603539.1733501603539.1733501603539.1&__hssc=259489365.1.1733501603539&__hsfp=3822854628&submissionGuid=381a0676-8f38-437b-96f2-fc10875658df#/shared-invite/email).\n- 📚 Read our [documentation](https://arize.com/docs/phoenix).\n- 💡 Ask questions and provide feedback in the _#phoenix-support_ channel.\n- 🌟 Leave a star on our [GitHub](https://github.com/Arize-ai/phoenix).\n- 🐞 Report bugs with [GitHub Issues](https://github.com/Arize-ai/phoenix/issues).\n- 𝕏 Follow us on [𝕏](https://twitter.com/ArizePhoenix).\n- 🗺️ Check out our [roadmap](https://github.com/orgs/Arize-ai/projects/45) to see where we're heading next.\n- 🧑‍🏫 Deep dive into everything [Agents](http://arize.com/ai-agents/) and [LLM Evaluations](https://arize.com/llm-evaluation) on Arize's Learning Hubs.\n\n## Breaking Changes\n\nSee the [migration guide](./MIGRATION.md) for a list of breaking changes.\n\n## Copyright, Patent, and License\n\nCopyright 2025 Arize AI, Inc. All Rights Reserved.\n\nPortions of this code are patent protected by one or more U.S. Patents. See the [IP_NOTICE](https://github.com/Arize-ai/phoenix/blob/main/IP_NOTICE).\n\nThis software is licensed under the terms of the Elastic License 2.0 (ELv2). See [LICENSE](https://github.com/Arize-ai/phoenix/blob/main/LICENSE).\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ai",
        "arize",
        "monitoring",
        "arize ai",
        "ai phoenix",
        "logging arize"
      ],
      "category": "monitoring-and-logging"
    },
    "EdgeCloudX--ceph_exporter": {
      "owner": "EdgeCloudX",
      "name": "ceph_exporter",
      "url": "https://github.com/EdgeCloudX/ceph_exporter",
      "imageUrl": "/freedevtools/mcp/pfp/EdgeCloudX.webp",
      "description": "Collects and exposes detailed metrics from a Ceph cluster for Prometheus monitoring, providing real-time insights to optimize performance and reliability without requiring additional configuration.",
      "stars": 0,
      "forks": 1,
      "license": "Apache License 2.0",
      "language": "Go",
      "updated_at": "2025-04-11T02:48:39Z",
      "readme_content": "# Ceph Exporter  [![GoDoc](https://godoc.org/github.com/digitalocean/ceph_exporter?status.svg)](https://godoc.org/github.com/digitalocean/ceph_exporter) ![build](https://github.com/digitalocean/ceph_exporter/actions/workflows/run_build.yml/badge.svg) ![tests](https://github.com/digitalocean/ceph_exporter/actions/workflows/run_tests.yml/badge.svg)  [![Go Report Card](https://goreportcard.com/badge/digitalocean/ceph_exporter)](https://goreportcard.com/report/digitalocean/ceph_exporter)\n\nA Prometheus exporter that scrapes meta information about a running Ceph\ncluster. All the information gathered from the cluster is done by interacting\nwith the monitors using an appropriate wrapper over\n`rados_mon_command()`. Hence, no additional setup is necessary other than\nhaving a working Ceph cluster.\n\nA List of all the metrics collected is available on [METRICS.md](./METRICS.md) page.\n\n## Dependencies\n\nYou should ideally run this exporter from the client that can talk to the Ceph\ncluster. Like any other Ceph client, it needs the following files to run\ncorrectly.\n\n* `ceph.conf` containing your Ceph configuration.\n* `ceph.client.<user>.keyring` in order to authenticate to your Ceph cluster.\n\nThe `ceph_exporter` will automatically pick those up if they are present in\nany of the [default\nlocations](http://docs.ceph.com/docs/master/rados/configuration/ceph-conf/#the-configuration-file). Otherwise\nyou will need to provide the configuration manually using environment\nvariables:\n\n* `CEPH_CLUSTER`: cluster's name (default `ceph`)\n* `CEPH_CONFIG`: configuration file that a Ceph client uses to connect to\n  the cluster (default `/etc/ceph/ceph.conf`)\n* `CEPH_USER`: a Ceph client user used to connect to the cluster (default\n  `admin`)\n\nWe use Ceph's [official Golang client](https://github.com/ceph/go-ceph) to run\ncommands on the cluster.\n\n`ceph_exporter` is currently in use and tested against Nautilus, Pacific, and Reef.\nIt might not work as expected with older or non-LTS versions of Ceph.\n\n## Environment Variables\n\n| Name                    | Description                                                                                    | Default                  |\n|-------------------------|------------------------------------------------------------------------------------------------|--------------------------|\n| `TELEMETRY_ADDR`        | Host:Port for ceph_exporter's metrics endpoint                                                 | `*:9128`                 |\n| `TELEMETRY_PATH`        | URL Path for surfacing metrics to Prometheus                                                   | `/metrics`               |\n| `EXPORTER_CONFIG`       | Path to ceph_exporter configuration file                                                       | `/etc/ceph/exporter.yml` |\n| `RGW_MODE`              | Enable collection of stats from RGW (0:disabled 1:enabled 2:background)                        | `0`                      |\n| `CEPH_CLUSTER`          | Ceph cluster name                                                                              | `ceph`                   |\n| `CEPH_CONFIG`           | Path to Ceph configuration file                                                                | `/etc/ceph/ceph.conf`    |\n| `CEPH_USER`             | Ceph user to connect to cluster                                                                | `admin`                  |\n| `CEPH_RADOS_OP_TIMEOUT` | Ceph rados_osd_op_timeout and rados_mon_op_timeout used to contact cluster (0s means no limit) | `30s`                    |\n| `LOG_LEVEL`             | Logging level. One of: [trace, debug, info, warn, error, fatal, panic]                         | `info`                   |\n| `TLS_CERT_FILE_PATH`    | Path to the x509 certificate file for enabling TLS (the key file path must also be specified)  |                          |\n| `TLS_KEY_FILE_PATH`     | Path to the x509 key file for enabling TLS (the cert file path must also be specified)         |                          |\n\n## Installation\n\nThe typical Go way of installing or building should work provided you have the [cgo dependencies](https://github.com/ceph/go-ceph#installation).\n\n```\n$ go install -tags nautilus\n```\n\n```\n$ go build -o ceph_exporter -tags nautilus\n```\n\nWe build the client with support for nautilus specifically but the binary will work for Octopus and Pacific as well.\n\n## Docker Image\n\n### Docker Hub\n\nThe official docker image is available at\n[digitalocean/ceph_exporter](https://hub.docker.com/r/digitalocean/ceph_exporter/).\n\n### Build From Source\n\nIt is also possible to build your own locally from the source. The port `9128`\nis exposed as a default port for `ceph_exporter`.\n\nThe exporter needs your Ceph configuration in order to establish communication\nwith the Ceph monitors. You can either pass it in as an additional command or\nmount the directory containing both your `ceph.conf` and your user's keyring\nunder the default `/etc/ceph` location that Ceph checks for.\n\nA sample build command would look like:\n\n```bash\n$ docker build -t digitalocean/ceph_exporter .\n```\n\nA `--build-args TEST=true` flag can be added to the build command above to\nalso run Golang's unit tests during build:\n\n```bash\ndocker build -t digitalocean/ceph_exporter . --build-arg TEST=true --no-cache\n```\n\nYou can start running your `ceph_exporter` container now.\n\n```bash\n$ docker run -v /etc/ceph:/etc/ceph -p=9128:9128 -it digitalocean/ceph_exporter\n```\n\nYou would have to ensure your image can talk over to the monitors. If it needs\naccess to your host's network stack you might need to add `--net=host` to the\nabove command. It makes the port mapping redundant so the `-p` flag can be\nremoved.\n\nPoint your Prometheus to scrape from `:9128` on your host now (or your port\nof choice if you decide to change it).\n\n## Contributing\n\nPlease refer to the [CONTRIBUTING](CONTRIBUTING.md) guide for more\ninformation on how to submit your changes to this repository.\n\n## Sample view\n\nSee `./examples` for a `docker-compose` file with Grafana if you'd like to\nquickly get a test environment up and running.\n\nLink to official documentation explaining `docker-compose`:\nhttps://docs.docker.com/compose/\n\nThe `docker-compose` file itself has comments on how to change it to adapt to\nyour environment. It does use volumes in order to persist data.  Docker\nvolumes documentation: https://docs.docker.com/engine/tutorials/dockervolumes/\n\nIf you have [promdash](https://github.com/prometheus/promdash) set up you\ncan generate views like:\n\n\n\nCopyright @ 2016-2023 DigitalOcean™ Inc.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "edgecloudx",
        "ceph_exporter",
        "prometheus",
        "edgecloudx ceph_exporter",
        "prometheus monitoring",
        "cluster prometheus"
      ],
      "category": "monitoring-and-logging"
    },
    "GeLi2001--datadog-mcp-server": {
      "owner": "GeLi2001",
      "name": "datadog-mcp-server",
      "url": "https://github.com/GeLi2001/datadog-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/GeLi2001.webp",
      "description": "Interacts with the Datadog API to monitor systems, access monitor data, retrieve dashboards, query metrics, and manage incidents. Provides comprehensive error handling and advanced log searching capabilities.",
      "stars": 55,
      "forks": 9,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-12T01:20:56Z",
      "readme_content": "# Datadog MCP Server\n\nA Model Context Protocol (MCP) server for interacting with the Datadog API.\n\n<a href=\"https://glama.ai/mcp/servers/@GeLi2001/datadog-mcp-server\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@GeLi2001/datadog-mcp-server/badge\" alt=\"Datadog MCP server\" />\n</a>\n\n## Features\n\n- **Monitoring**: Access monitor data and configurations\n- **Dashboards**: Retrieve and view dashboard definitions\n- **Metrics**: Query available metrics and their metadata\n- **Events**: Search and retrieve events within timeframes\n- **Logs**: Search logs with advanced filtering and sorting options\n- **Incidents**: Access incident management data\n- **API Integration**: Direct integration with Datadog's v1 and v2 APIs\n- **Comprehensive Error Handling**: Clear error messages for API and authentication issues\n- **Service-Specific Endpoints**: Support for different endpoints for logs and metrics\n\n## Prerequisites\n\n1. Node.js (version 16 or higher)\n2. Datadog account with:\n   - API key - Found in Organization Settings > API Keys\n   - Application key - Found in Organization Settings > Application Keys\n\n## Installation\n\n### Via npm (recommended)\n\n```bash\nnpm install -g datadog-mcp-server\n```\n\n### From Source\n\n1. Clone this repository\n2. Install dependencies:\n   ```bash\n   npm install\n   ```\n3. Build the project:\n   ```bash\n   npm run build\n   ```\n\n## Configuration\n\nYou can configure the Datadog MCP server using either environment variables or command-line arguments.\n\n### Environment Variables\n\nCreate a `.env` file with your Datadog credentials:\n\n```\nDD_API_KEY=your_api_key_here\nDD_APP_KEY=your_app_key_here\nDD_SITE=datadoghq.com\nDD_LOGS_SITE=datadoghq.com\nDD_METRICS_SITE=datadoghq.com\n```\n\n**Note**: `DD_LOGS_SITE` and `DD_METRICS_SITE` are optional and will default to the value of `DD_SITE` if not specified.\n\n### Command-line Arguments\n\nBasic usage with global site setting:\n\n```bash\ndatadog-mcp-server --apiKey=your_api_key --appKey=your_app_key --site=datadoghq.eu\n```\n\nAdvanced usage with service-specific endpoints:\n\n```bash\ndatadog-mcp-server --apiKey=your_api_key --appKey=your_app_key --site=datadoghq.com --logsSite=logs.datadoghq.com --metricsSite=metrics.datadoghq.com\n```\n\nNote: Site arguments don't need `https://` - it will be added automatically.\n\n### Regional Endpoints\n\nDifferent Datadog regions have different endpoints:\n\n- US (Default): `datadoghq.com`\n- EU: `datadoghq.eu`\n- US3 (GovCloud): `ddog-gov.com`\n- US5: `us5.datadoghq.com`\n- AP1: `ap1.datadoghq.com`\n\n### Usage with Claude Desktop\n\nAdd this to your `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"datadog\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"datadog-mcp-server\",\n        \"--apiKey\",\n        \"<YOUR_API_KEY>\",\n        \"--appKey\",\n        \"<YOUR_APP_KEY>\",\n        \"--site\",\n        \"<YOUR_DD_SITE>(e.g us5.datadoghq.com)\"\n      ]\n    }\n  }\n}\n```\n\nFor more advanced configurations with separate endpoints for logs and metrics:\n\n```json\n{\n  \"mcpServers\": {\n    \"datadog\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"datadog-mcp-server\",\n        \"--apiKey\",\n        \"<YOUR_API_KEY>\",\n        \"--appKey\",\n        \"<YOUR_APP_KEY>\",\n        \"--site\",\n        \"<YOUR_DD_SITE>\",\n        \"--logsSite\",\n        \"<YOUR_LOGS_SITE>\",\n        \"--metricsSite\",\n        \"<YOUR_METRICS_SITE>\"\n      ]\n    }\n  }\n}\n```\n\nLocations for the Claude Desktop config file:\n\n- MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n- Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n## Usage with MCP Inspector\n\nTo use with the MCP Inspector tool:\n\n```bash\nnpx @modelcontextprotocol/inspector datadog-mcp-server --apiKey=your_api_key --appKey=your_app_key\n```\n\n## Available Tools\n\nThe server provides these MCP tools:\n\n- **get-monitors**: Fetch monitors with optional filtering\n- **get-monitor**: Get details of a specific monitor by ID\n- **get-dashboards**: List all dashboards\n- **get-dashboard**: Get a specific dashboard by ID\n- **get-metrics**: List available metrics\n- **get-metric-metadata**: Get metadata for a specific metric\n- **get-events**: Fetch events within a time range\n- **get-incidents**: List incidents with optional filtering\n- **search-logs**: Search logs with advanced query filtering\n- **aggregate-logs**: Perform analytics and aggregations on log data\n\n## Examples\n\n### Example: Get Monitors\n\n```javascript\n{\n  \"method\": \"tools/call\",\n  \"params\": {\n    \"name\": \"get-monitors\",\n    \"arguments\": {\n      \"groupStates\": [\"alert\", \"warn\"],\n      \"limit\": 5\n    }\n  }\n}\n```\n\n### Example: Get a Dashboard\n\n```javascript\n{\n  \"method\": \"tools/call\",\n  \"params\": {\n    \"name\": \"get-dashboard\",\n    \"arguments\": {\n      \"dashboardId\": \"abc-def-123\"\n    }\n  }\n}\n```\n\n### Example: Search Logs\n\n```javascript\n{\n  \"method\": \"tools/call\",\n  \"params\": {\n    \"name\": \"search-logs\",\n    \"arguments\": {\n      \"filter\": {\n        \"query\": \"service:web-app status:error\",\n        \"from\": \"now-15m\",\n        \"to\": \"now\"\n      },\n      \"sort\": \"-timestamp\",\n      \"limit\": 20\n    }\n  }\n}\n```\n\n### Example: Aggregate Logs\n\n```javascript\n{\n  \"method\": \"tools/call\",\n  \"params\": {\n    \"name\": \"aggregate-logs\",\n    \"arguments\": {\n      \"filter\": {\n        \"query\": \"service:web-app\",\n        \"from\": \"now-1h\",\n        \"to\": \"now\"\n      },\n      \"compute\": [\n        {\n          \"aggregation\": \"count\"\n        }\n      ],\n      \"groupBy\": [\n        {\n          \"facet\": \"status\",\n          \"limit\": 10,\n          \"sort\": {\n            \"aggregation\": \"count\",\n            \"order\": \"desc\"\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\n### Example: Get Incidents\n\n```javascript\n{\n  \"method\": \"tools/call\",\n  \"params\": {\n    \"name\": \"get-incidents\",\n    \"arguments\": {\n      \"includeArchived\": false,\n      \"query\": \"state:active\",\n      \"pageSize\": 10\n    }\n  }\n}\n```\n\n## Troubleshooting\n\nIf you encounter a 403 Forbidden error, verify that:\n\n1. Your API key and Application key are correct\n2. The keys have the necessary permissions to access the requested resources\n3. Your account has access to the requested data\n4. You're using the correct endpoint for your region (e.g., `datadoghq.eu` for EU customers)\n\n## Debugging\n\nIf you encounter issues, check Claude Desktop's MCP logs:\n\n```bash\n# On macOS\ntail -n 20 -f ~/Library/Logs/Claude/mcp*.log\n\n# On Windows\nGet-Content -Path \"$env:APPDATA\\Claude\\Logs\\mcp*.log\" -Tail 20 -Wait\n```\n\nCommon issues:\n\n- 403 Forbidden: Authentication issue with Datadog API keys\n- API key or App key format invalid: Ensure you're using the full key strings\n- Site configuration errors: Make sure you're using the correct Datadog domain\n- Endpoint mismatches: Verify that service-specific endpoints are correctly set if you're using separate domains for logs and metrics\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "datadog",
        "logging",
        "monitoring",
        "datadog mcp",
        "datadog api",
        "interacts datadog"
      ],
      "category": "monitoring-and-logging"
    },
    "GetSherlog--mcp-grafana": {
      "owner": "GetSherlog",
      "name": "mcp-grafana",
      "url": "https://github.com/GetSherlog/mcp-grafana",
      "imageUrl": "/freedevtools/mcp/pfp/GetSherlog.webp",
      "description": "Provides access to Grafana instances and their ecosystem, enabling dashboard search, datasource querying, and incident management. Integrates Prometheus and Loki functionalities, including log and metric queries, along with alert rules and metadata fetching.",
      "stars": 0,
      "forks": 0,
      "license": "Apache License 2.0",
      "language": "",
      "updated_at": "2025-04-21T06:20:19Z",
      "readme_content": "# Grafana MCP server\n\nA [Model Context Protocol][mcp] (MCP) server for Grafana.\n\nThis provides access to your Grafana instance and the surrounding ecosystem.\n\n## Features\n\n- [x] Search for dashboards\n- [x] Get dashboard by UID\n- [x] List and fetch datasource information\n- [ ] Query datasources\n  - [x] Prometheus\n  - [x] Loki\n    - [x] Log queries\n    - [x] Metric queries\n  - [ ] Tempo\n  - [ ] Pyroscope\n- [x] Query Prometheus metadata\n  - [x] Metric metadata\n  - [x] Metric names\n  - [x] Label names\n  - [x] Label values\n- [x] Query Loki metadata\n  - [x] Label names\n  - [x] Label values\n  - [x] Stats\n- [x] Search, create, update and close incidents\n- [ ] Start Sift investigations and view the results\n- [ ] Alerting\n  - [x] List and fetch alert rule information\n  - [x] Get alert rule statuses (firing/normal/error/etc.)\n  - [ ] Create and change alert rules\n  - [x] List contact points\n  - [ ] Create and change contact points\n- [x] Access Grafana OnCall functionality\n  - [x] List and manage schedules\n  - [x] Get shift details\n  - [x] Get current on-call users\n  - [x] List teams and users\n  - [ ] List alert groups\n\nThe list of tools is configurable, so you can choose which tools you want to make available to the MCP client.\nThis is useful if you don't use certain functionality or if you don't want to take up too much of the context window.\nTo disable a category of tools, use the `--disable-<category>` flag when starting the server. For example, to disable\nthe OnCall tools, use `--disable-oncall`.\n\n### Tools\n\n| Tool                              | Category    | Description                                                        |\n|-----------------------------------|-------------|--------------------------------------------------------------------|\n| `search_dashboards`               | Search      | Search for dashboards                                              |\n| `get_dashboard_by_uid`            | Dashboard   | Get a dashboard by uid                                             |\n| `list_datasources`                | Datasources | List datasources                                                   |\n| `get_datasource_by_uid`           | Datasources | Get a datasource by uid                                            |\n| `get_datasource_by_name`          | Datasources | Get a datasource by name                                           |\n| `query_prometheus`                | Prometheus  | Execute a query against a Prometheus datasource                    |\n| `list_prometheus_metric_metadata` | Prometheus  | List metric metadata                                               |\n| `list_prometheus_metric_names`    | Prometheus  | List available metric names                                        |\n| `list_prometheus_label_names`     | Prometheus  | List label names matching a selector                               |\n| `list_prometheus_label_values`    | Prometheus  | List values for a specific label                                   |\n| `list_incidents`                  | Incident    | List incidents in Grafana Incident                                 |\n| `create_incident`                 | Incident    | Create an incident in Grafana Incident                             |\n| `add_activity_to_incident`        | Incident    | Add an activity item to an incident in Grafana Incident            |\n| `resolve_incident`                | Incident    | Resolve an incident in Grafana Incident                            |\n| `query_loki_logs`                 | Loki        | Query and retrieve logs using LogQL (either log or metric queries) |\n| `list_loki_label_names`           | Loki        | List all available label names in logs                             |\n| `list_loki_label_values`          | Loki        | List values for a specific log label                               |\n| `query_loki_stats`                | Loki        | Get statistics about log streams                                   |\n| `list_alert_rules`                | Alerting    | List alert rules                                                   |\n| `get_alert_rule_by_uid`           | Alerting    | Get alert rule by UID                                              |\n| `list_oncall_schedules`           | OnCall      | List schedules from Grafana OnCall                                 |\n| `get_oncall_shift`                | OnCall      | Get details for a specific OnCall shift                           |\n| `get_current_oncall_users`        | OnCall      | Get users currently on-call for a specific schedule                |\n| `list_oncall_teams`               | OnCall      | List teams from Grafana OnCall                                     |\n| `list_oncall_users`               | OnCall      | List users from Grafana OnCall                                     |\n\n## Usage\n\n1. Create a service account in Grafana with enough permissions to use the tools you want to use,\n   generate a service account token, and copy it to the clipboard for use in the configuration file.\n   Follow the [Grafana documentation][service-account] for details.\n\n2. Download the latest release of `mcp-grafana` from the [releases page](https://github.com/grafana/mcp-grafana/releases) and place it in your `$PATH`.\n\n   If you have a Go toolchain installed you can also build and install it from source, using the `GOBIN` environment variable\n   to specify the directory where the binary should be installed. This should also be in your `PATH`.\n\n   ```bash\n   GOBIN=\"$HOME/go/bin\" go install github.com/grafana/mcp-grafana/cmd/mcp-grafana@latest\n   ```\n\n3. Add the server configuration to your client configuration file. For example, for Claude Desktop:\n\n   ```json\n   {\n     \"mcpServers\": {\n       \"grafana\": {\n         \"command\": \"mcp-grafana\",\n         \"args\": [],\n         \"env\": {\n           \"GRAFANA_URL\": \"http://localhost:3000\",\n           \"GRAFANA_API_KEY\": \"<your service account token>\"\n         }\n       }\n     }\n   }\n   ```\n\n> Note: if you see `Error: spawn mcp-grafana ENOENT` in Claude Desktop, you need to specify the full path to `mcp-grafana`.\n\n### Debug Mode\n\nYou can enable debug mode for the Grafana transport by adding the `-debug` flag to the command. This will provide detailed logging of HTTP requests and responses between the MCP server and the Grafana API, which can be helpful for troubleshooting.\n\nTo use debug mode with the Claude Desktop configuration, update your config as follows:\n\n```json\n{\n  \"mcpServers\": {\n    \"grafana\": {\n      \"command\": \"mcp-grafana\",\n      \"args\": [\"-debug\"],\n      \"env\": {\n        \"GRAFANA_URL\": \"http://localhost:3000\",\n        \"GRAFANA_API_KEY\": \"<your service account token>\"\n      }\n    }\n  }\n}\n```\n\n## Development\n\nContributions are welcome! Please open an issue or submit a pull request if you have any suggestions or improvements.\n\nThis project is written in Go. Install Go following the instructions for your platform.\n\nTo run the server, use:\n\n```bash\nmake run\n```\n\nYou can also run the server using the SSE transport inside Docker. To build the image, use\n\n```\nmake build-image\n```\n\nAnd to run the image, use:\n\n```\ndocker run -it --rm -p 8000:8000 mcp-grafana:latest\n```\n\n### Testing\n\nThere are three types of tests available:\n\n1. Unit Tests (no external dependencies required):\n```bash\nmake test-unit\n```\n\nYou can also run unit tests with:\n```bash\nmake test\n```\n\n2. Integration Tests (requires docker containers to be up and running):\n```bash\nmake test-integration\n```\n\n3. Cloud Tests (requires cloud Grafana instance and credentials):\n```bash\nmake test-cloud\n```\n> Note: Cloud tests are automatically configured in CI. For local development, you'll need to set up your own Grafana Cloud instance and credentials.\n\nMore comprehensive integration tests will require a Grafana instance to be running locally on port 3000; you can start one with Docker Compose:\n\n```bash\ndocker-compose up -d\n```\n\nThe integration tests can be run with:\n\n```bash\nmake test-all\n```\n\nIf you're adding more tools, please add integration tests for them. The existing tests should be a good starting point.\n\n### Linting\n\nTo lint the code, run:\n\n```bash\nmake lint\n```\n\nThis includes a custom linter that checks for unescaped commas in `jsonschema` struct tags. The commas in `description` fields must be escaped with `\\\\,` to prevent silent truncation. You can run just this linter with:\n\n```bash\nmake lint-jsonschema\n```\n\nSee the [JSONSchema Linter documentation](internal/linter/jsonschema/README.md) for more details.\n\n## License\n\nThis project is licensed under the [Apache License, Version 2.0](LICENSE).\n\n[mcp]: https://modelcontextprotocol.io/\n[service-account]: https://grafana.com/docs/grafana/latest/administration/service-accounts/\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "grafana",
        "logging",
        "monitoring",
        "grafana instances",
        "grafana provides",
        "access grafana"
      ],
      "category": "monitoring-and-logging"
    },
    "Heht571--ops-mcp-server": {
      "owner": "Heht571",
      "name": "ops-mcp-server",
      "url": "https://github.com/Heht571/ops-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/Heht571.webp",
      "description": "A server toolset for monitoring and managing remote servers, providing functionalities for system checks, service status updates, network diagnostics, and security audits. It includes features for memory information retrieval, system load monitoring, and process management.",
      "stars": 38,
      "forks": 13,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-03T10:03:18Z",
      "readme_content": "---\n\n# ops-mcp-server\n\n[![中文](https://img.shields.io/badge/Language-中文-blue.svg)](README_zh.md)\n\n`ops-mcp-server`: an AI-driven IT operations platform that fuses LLMs and MCP architecture to enable intelligent monitoring, anomaly detection, and natural human-infrastructure interaction with enterprise-grade security and scalability.\n\n---\n\n## 📖 Table of Contents\n\n- [Project Overview](#project-overview)\n- [Key Features](#key-features)\n- [Demo Videos](#demo-videos)\n- [Installation](#installation)\n- [Deployment](#deployment)\n- [Local MCP Server Configuration](#local-mcp-server-configuration)\n- [Interactive Client Usage](#interactive-client-usage)\n- [License](#license)\n- [Notes](#notes)\n\n---\n\n## 🚀 Project Overview\n\n`ops-mcp-server` is an IT operations management solution for the AI era. It achieves intelligent IT operations through the seamless integration of the Model Context Protocol (MCP) and Large Language Models (LLMs). By leveraging the power of LLMs and MCP's distributed architecture, it transforms traditional IT operations into an AI-driven experience, enabling automated server monitoring, intelligent anomaly detection, and context-aware troubleshooting. The system acts as a bridge between human operators and complex IT infrastructure, providing natural language interaction for tasks ranging from routine maintenance to complex problem diagnosis, while maintaining enterprise-grade security and scalability.\n\n---\n\n## 🌟 Key Features\n\n### 🖥️ Server Monitoring\n\n- Real-time CPU, memory, disk inspections.\n- System load and process monitoring.\n- Service and network interface checks.\n- Log analysis and configuration backup.\n- Security vulnerability scans (SSH login, firewall status).\n- Detailed OS information retrieval.\n\n### 📦 Container Management (Docker)\n\n- Container, image, and volume management.\n- Container resource usage monitoring.\n- Log retrieval and health checks.\n\n### 🌐 Network Device Management\n\n- Multi-vendor support (Cisco, Huawei, H3C).\n- Switch port, VLAN, and router route checks.\n- ACL security configuration analysis.\n- Optical module and device performance monitoring.\n\n### ➕ Additional Capabilities\n\n- Extensible plugin architecture.\n- Batch operations across multiple devices.\n- Tool listing and descriptive commands.\n\n---\n\n## 🎬 Demo Videos\n\n### 📌 Project Demo\n\n_On Cherry Studio_\n\n\n\n### 📌 Interactive Client Demo\n\n_On Terminal_\n\n\n\n---\n\n## ⚙️ Installation\n\nEnsure you have **Python 3.10+** installed. This project uses [`uv`](https://github.com/astral-sh/uv) for dependency and environment management.\n\n### 1. Install UV\n\n```bash\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n```\n\n### 2. Set Up Virtual Environment\n\n```bash\nuv venv .venv\n\n# Activate the environment\nsource .venv/bin/activate      # Linux/macOS\n.\\.venv\\Scripts\\activate       # Windows\n```\n\n### 3. Install Dependencies\n\n```bash\nuv pip install -r requirements.txt\n```\n\n> Dependencies are managed via `pyproject.toml`.\n\n---\n\n## 🚧 Deployment\n\n### 📡 SSE Remote Deployment (UV)\n\n```bash\ncd server_monitor_sse\n\n# Install dependencies\npip install -r requirements.txt\n\n# Start service\ncd ..\nuv run server_monitor_sse --transport sse --port 8000\n```\n\n### 🐳 SSE Remote Deployment (Docker Compose)\n\nEnsure Docker and Docker Compose are installed.\n\n```bash\ncd server_monitor_sse\ndocker compose up -d\n\n# Check status\ndocker compose ps\n\n# Logs monitoring\ndocker compose logs -f\n```\n\n---\n\n## 🛠️ Local MCP Server Configuration (Stdio)\n\nAdd this configuration to your MCP settings:\n\n```json\n{\n  \"ops-mcp-server\": {\n    \"command\": \"uv\",\n    \"args\": [\n      \"--directory\", \"YOUR_PROJECT_PATH_HERE\",\n      \"run\", \"server_monitor.py\"\n    ],\n    \"env\": {},\n    \"disabled\": true,\n    \"autoApprove\": [\"list_available_tools\"]\n  },\n  \"network_tools\": {\n    \"command\": \"uv\",\n    \"args\": [\n      \"--directory\", \"YOUR_PROJECT_PATH_HERE\",\n      \"run\", \"network_tools.py\"\n    ],\n    \"env\": {},\n    \"disabled\": false,\n    \"autoApprove\": []\n  },\n}\n```\n\n> **Note**: Replace `YOUR_PROJECT_PATH_HERE` with your project's actual path.\n\n---\n\n## 💬 Interactive Client Usage\n\nAn interactive client (`client.py`) allows you to interact with MCP services using natural language.\n\n### 1. Install Client Dependencies\n\n```bash\nuv pip install openai rich\n```\n\n### 2. Configure Client\n\nEdit these configurations within `client.py`:\n\n```python\n# Initialize OpenAI client\nself.client = AsyncOpenAI(\n    base_url=\"https://your-api-endpoint\",\n    api_key=\"YOUR_API_KEY\"\n)\n\n# Set model\nself.model = \"your-preferred-model\"\n```\n\n### 3. Run the Client\n\n```bash\nuv run client.py [path/to/server.py]\n```\n\nExample:\n\n```bash\nuv run client.py ./server_monitor.py\n```\n\n### Client Commands\n\n- `help` - Display help.\n- `quit` - Exit client.\n- `clear` - Clear conversation history.\n- `model <name>` - Switch models.\n\n---\n\n## 📄 License\n\nThis project is licensed under the [MIT License](LICENSE).\n\n---\n\n## 📌 Notes\n\n- Ensure remote SSH access is properly configured.\n- Adjust tool parameters based on actual deployment conditions.\n- This project is under active development; feedback and contributions are welcome.\n\n---",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "monitoring",
        "servers",
        "logging",
        "server toolset",
        "mcp server",
        "toolset monitoring"
      ],
      "category": "monitoring-and-logging"
    },
    "Ivlad003--mcp_newrelic": {
      "owner": "Ivlad003",
      "name": "mcp_newrelic",
      "url": "https://github.com/Ivlad003/mcp_newrelic",
      "imageUrl": "/freedevtools/mcp/pfp/Ivlad003.webp",
      "description": "Query New Relic logs and metrics using NRQL queries for insights and monitoring. Provides detailed error logging and outputs that are formatted for readability.",
      "stars": 26,
      "forks": 9,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-10-03T13:48:00Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/ivlad003-mcp-newrelic-badge.png)](https://mseep.ai/app/ivlad003-mcp-newrelic)\n\n# New Relic MCP Server\n\nA simple Model Context Protocol (MCP) server for querying New Relic logs using NRQL queries. This server enables Large Language Models (LLMs) like Claude to interact with your New Relic data.\n\n## Features\n\n- Query New Relic logs and metrics using NRQL\n- Detailed error logging\n- Easy integration with Claude Desktop\n- Human-readable output formatting\n- Configurable New Relic account ID\n\n## Setup Instructions\n\n### Prerequisites\n\n- Python 3.10 or higher\n- New Relic account and API key\n- Claude Desktop application\n\n### Installation Steps\n\n1. Install `uv` package manager:\n```bash\n# On macOS/Linux\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# On Windows (PowerShell)\npowershell -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n```\n\n2. Create and setup project:\n```bash\n# Create directory\nmkdir newrelic-mcp\ncd newrelic-mcp\n\n# Create virtual environment\nuv venv\n\n# Activate virtual environment\nsource .venv/bin/activate  # On Unix/macOS\n.venv\\Scripts\\activate     # On Windows\n\n# Install dependencies\nuv pip install \"mcp[cli]\" httpx\n```\n\n3. Create server file `newrelic_logs_server.py` with the provided code.\n\n4. Configure your environment variables:\n```bash\n# On Unix/macOS\nexport NEW_RELIC_API_KEY=\"your-api-key-here\"\nexport NEW_RELIC_ACCOUNT_ID=\"your-account-id-here\"\n\n# On Windows (CMD)\nset NEW_RELIC_API_KEY=your-api-key-here\nset NEW_RELIC_ACCOUNT_ID=your-account-id-here\n\n# On Windows (PowerShell)\n$env:NEW_RELIC_API_KEY = \"your-api-key-here\"\n$env:NEW_RELIC_ACCOUNT_ID = \"your-account-id-here\"\n```\n\n### Claude Desktop Integration\n\nConfigure Claude Desktop by editing your configuration file:\n\n- macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n- Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n\nAdd the following configuration:\n```json\n{\n    \"mcpServers\": {\n        \"newrelic\": {\n            \"command\": \"uv\",\n            \"args\": [\n                \"--directory\",\n                \"/absolute/path/to/newrelic-mcp\",\n                \"run\",\n                \"newrelic_logs_server.py\"\n            ],\n            \"env\": {\n                \"NEW_RELIC_API_KEY\": \"your-api-key-here\",\n                \"NEW_RELIC_ACCOUNT_ID\": \"your-account-id-here\"\n            }\n        }\n    }\n}\n```\n\n## Usage\n\n### Example NRQL Queries\n\n1. Basic Transaction Query:\n```sql\nSELECT * FROM Transaction SINCE 1 hour ago\n```\n\n2. Error Analysis:\n```sql\nSELECT * FROM Transaction WHERE error IS TRUE SINCE 1 hour ago LIMIT 10\n```\n\n3. Performance Analysis:\n```sql\nSELECT average(duration) FROM Transaction FACET name ORDER BY average(duration) DESC LIMIT 5\n```\n\n### Example Claude Prompts\n\nYou can ask Claude questions like:\n- \"Show me all transactions from the last hour\"\n- \"Are there any errors in our application?\"\n- \"What are our slowest endpoints?\"\n\n## Debugging\n\n### Viewing Logs\n\n```bash\n# On macOS/Linux\ntail -f ~/Library/Logs/Claude/mcp-server-newrelic.log\n\n# On Windows\ntype %APPDATA%\\Claude\\logs\\mcp-server-newrelic.log\n```\n\n### Testing with MCP Inspector\n\nTest your server functionality using:\n```bash\nnpx @modelcontextprotocol/inspector uv run newrelic_logs_server.py\n```\n\n### Common Issues\n\n1. Authentication Errors:\n- Check if NEW_RELIC_API_KEY is set correctly\n- Verify API key has correct permissions\n- Ensure API key is valid\n\n2. Query Errors:\n- Verify NRQL syntax\n- Check account ID in code matches your account\n- Ensure queried data exists in the time range\n\n3. Connection Issues:\n- Check network connectivity\n- Verify GraphQL endpoint is accessible\n- Ensure no firewalls are blocking connections\n\n## Security Notes\n\n- Never commit API keys to version control\n- Use environment variables for sensitive data\n- Keep dependencies updated\n- Monitor query patterns and access logs\n\n## Development\n\n### Local Testing\n\n1. Set environment variables:\n```bash\nexport NEW_RELIC_API_KEY=\"your-api-key-here\"\nexport NEW_RELIC_ACCOUNT_ID=\"your-account-id-here\"\n```\n\n2. Run the server:\n```bash\nuv run newrelic_logs_server.py\n```\n\n### Code Structure\n\nThe server implements:\n- Single NRQL query tool\n- Configurable New Relic account ID\n- Comprehensive error handling\n- Detailed logging\n- Response formatting\n\n### Testing Changes\n\n1. Modify code as needed\n2. Test with MCP Inspector\n3. Restart Claude Desktop to apply changes\n\n## Troubleshooting Guide\n\n1. Server Not Starting:\n- Check Python version\n- Verify all dependencies are installed\n- Ensure virtual environment is activated\n\n2. Query Not Working:\n- Check logs for detailed error messages\n- Verify NRQL syntax\n- Ensure data exists in queried time range\n\n3. Claude Not Connecting:\n- Verify configuration file syntax\n- Check paths are absolute\n- Restart Claude Desktop\n\n## Contributing\n\n1. Fork the repository\n2. Create a feature branch\n3. Submit a pull request\n\n## License\n\nThis project is licensed under the MIT License.\n\n## Support\n\nIf you encounter issues:\n1. Check the logs\n2. Review common issues section\n3. Test with MCP Inspector\n4. File an issue on GitHub",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "nrql",
        "logging",
        "logs",
        "relic logs",
        "monitoring logging",
        "logs metrics"
      ],
      "category": "monitoring-and-logging"
    },
    "JackXuyi--env-mcp": {
      "owner": "JackXuyi",
      "name": "env-mcp",
      "url": "https://github.com/JackXuyi/env-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/JackXuyi.webp",
      "description": "Retrieve detailed system information such as platform, memory, CPU, network, and user data for use in applications. Supports cross-platform operation and is easily integratable with MCP-enabled tools.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-04-21T15:32:03Z",
      "readme_content": "# env-mcp\n\n一个用于获取当前环境系统信息的 MCP 工具包。\n\n## 功能特性\n\n- 获取详细的系统信息\n- 支持跨平台使用\n- 易于集成到支持 MCP 的应用程序中\n- 提供 TypeScript 类型支持\n\n## 安装\n\n```bash\nnpm install @zhijianren/env-mcp -g\n```\n\n## 在支持 MCP 的应用中使用\n\n### 1. 配置 MCP 服务\n\n在应用的 MCP 配置中添加以下内容：\n\n```json\n{\n  \"mcpServers\": {\n    \"env-mcp\": {\n      \"name\": \"env-mcp\",\n      \"type\": \"command\",\n      \"command\": \"node\",\n      \"args\": [\n        \"/usr/local/lib/node_modules/@zhijianren/env-mcp/dist/index.js\"\n      ],\n      \"enabled\": true\n    }\n  }\n}\n```\n\n### 2. 调用服务\n\n```typescript\n// 获取平台信息\nconst platformInfo = await mcp.env.getPlatformInfo();\n\n// 获取内存信息\nconst memoryInfo = await mcp.env.getMemoryInfo();\n\n// 获取 CPU 信息\nconst cpuInfo = await mcp.env.getCpuInfo();\n\n// 获取网络信息\nconst networkInfo = await mcp.env.getNetworkInfo();\n\n// 获取用户信息\nconst userInfo = await mcp.env.getUserInfo();\n\n// 获取 CPU 使用率\nconst cpuUsage = await mcp.env.getCpuUsage();\n\n// 获取硬盘使用率\nconst diskUsage = await mcp.env.getDiskUsage();\n\n// 获取终端类型\nconst terminalTypes = await mcp.env.getTerminalTypes();\n\n// 获取 IPv4 信息\nconst ipv4Info = await mcp.env.getIpv4Info();\n\n// 获取 IPv6 信息\nconst ipv6Info = await mcp.env.getIpv6Info();\n\n// 获取代理信息\nconst proxyInfo = await mcp.env.getProxyInfo();\n\n// 获取 Docker 信息\nconst dockerInfo = await mcp.env.getDockerInfo();\n\n// 获取 Node.js 版本信息\nconst nodeInfo = await mcp.env.getNodeInfo();\n```\n\n### 支持的工具列表\n\n| 工具名称         | 描述                           | 返回数据结构示例                                                                 |\n|------------------|--------------------------------|----------------------------------------------------------------------------------|\n| `getBatteryInfo` | 获取当前设备的电池信息         | `{ hasBattery: boolean, isCharging: boolean, maxCapacity: number, currentCapacity: number }` |\n| `getGraphicsInfo` | 获取当前设备的显卡信息        | `{ controllers: Array<{ model: string, vendor: string, bus: string, vram: number }>, displays: Array<{ model: string, resolutionX: number, resolutionY: number }> }` |\n| `getProcesses`   | 获取当前设备的进程信息         | `{ all: number, running: number, blocked: number, sleeping: number, list: Array<{ pid: number, name: string, cpu: number, memory: number }> }` |\n| `getBluetoothInfo` | 获取当前设备的蓝牙信息       | `Array<{ name: string, address: string, connected: boolean }>`                   |\n| `getAudioInfo`   | 获取当前设备的音频设备信息     | `Array<{ name: string, manufacturer: string, default: boolean }>`                |\n| `getAvailableNetworks` | 获取当前设备可用的网络信息 | `{ networkInterfaces: { [key: string]: Array<{ address: string, netmask: string, family: string, internal: boolean }> }, wifiNetworks: Array<{ ssid: string, bssid: string, mode: string, channel: number, frequency: number, signalLevel: number, quality: number, security: string[] }> }` |\n| `getTimezone`    | 获取当前设备的时区信息         | `{ timezone: string }`                                                           |\n| `getAppSchemas`  | 获取当前设备所有注册唤醒的 App Schema 信息 | `{ [bundle: string]: string[] }`                                                 |\n| `getWifiInfo`    | 获取当前设备的 Wi-Fi 信息      | `Array<{ ssid: string, bssid: string, mode: string, channel: number, frequency: number, signalLevel: number, quality: number, security: string[] }>` |\n| `getInstalledApps` | 获取当前设备已安装的应用信息   | `{ installedApps: string[] }`                                                    |\n| `getVpnInfo`     | 获取当前设备的 VPN 信息        | `{ [key: string]: Array<{ address: string, netmask: string, family: string, internal: boolean }> }` |\n| `getHardwareInfo` | 获取当前设备的硬件信息，包括生产日期等 | `{ manufacturer: string, model: string, version: string, serial: string, uuid: string, sku: string, virtual: boolean }` |\n| `getPlatformInfo` | 获取当前系统的平台信息         | `{ platform: string, arch: string, hostname: string, type: string, release: string, version: string }` |\n| `getMemoryInfo`   | 获取当前系统的内存信息         | `{ totalMemory: number, freeMemory: number, usedMemory: number }`                |\n| `getCpuInfo`      | 获取当前系统的 CPU 信息        | `{ cpus: Array<{ model: string, speed: number, times: { user: number, nice: number, sys: number, idle: number, irq: number } }> }` |\n| `getNetworkInfo`  | 获取当前系统的网络信息         | `{ networkInterfaces: { [key: string]: Array<{ address: string, netmask: string, family: string, mac: string, internal: boolean }> } }` |\n| `getUserInfo`     | 获取当前系统的用户信息         | `{ userInfo: { uid: number, gid: number, username: string, homedir: string, shell: string }, tmpdir: string, homedir: string }` |\n| `getCpuUsage`     | 获取当前平台的 CPU 占用率      | `{ cpuUsage: string }`                                                           |\n| `getDiskUsage`    | 获取当前平台的硬盘使用率       | `string`（`df -h` 命令的输出）                                                   |\n| `getTerminalTypes`| 获取系统上支持的所有终端类型   | `{ terminalTypes: string[] }`                                                    |\n| `getIpv4Info`     | 获取当前设备的 IPv4 信息       | `{ [key: string]: Array<{ address: string, netmask: string, family: string, internal: boolean }> }` |\n| `getIpv6Info`     | 获取当前设备的 IPv6 信息       | `{ [key: string]: Array<{ address: string, netmask: string, family: string, internal: boolean }> }` |\n| `getProxyInfo`    | 获取当前网络的所有代理信息     | `{ httpProxy: string, httpsProxy: string, noProxy: string }`                     |\n| `getUsbInfo`     | 获取当前设备的 USB 设备信息    | `Array<{ bus: number, device: number, vendor: string, product: string, serial: string, type: string }>` |\n| `getPrinterInfo` | 获取当前设备的打印机信息       | `Array<{ name: string, status: string, type: string, driver: string }>`        |\n| `getSshPublicKey` | 获取当前用户的 SSH 公钥       | `Array<string>`（包含所有找到的公钥）                                           |\n| `getDockerInfo`  | 获取当前设备的 Docker 信息     | `{ version: object, images: Array<object>, containers: Array<object> }` 或 `{}` （未安装时）|\n| `getNodeInfo`  | 获取当前设备安装的 Node.js 版本信息 | `{ version: string, fullVersion: string, npmVersion: string, platform: string, arch: string, globalPackages: object, execPath: string, features: object, modules: object }` |\n## 开发指南\n\n```bash\n# 安装依赖\nnpm install\n\n# 开发模式（监听文件变化）\nnpm run dev\n\n# 构建项目\nnpm run build\n\n# 运行项目\nnpm start\n```\n\n## 环境变量配置\n\n通过 `.env` 文件配置环境变量：\n\n- `PORT`：服务器端口号（默认：3000）\n- `NODE_ENV`：运行环境（development/production）\n\n## 许可证\n\n本项目采用 ISC 许可证\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "jackxuyi",
        "monitoring",
        "logging",
        "logging jackxuyi",
        "jackxuyi env",
        "mcp retrieve"
      ],
      "category": "monitoring-and-logging"
    },
    "MCP-100--mcp-sentry": {
      "owner": "MCP-100",
      "name": "mcp-sentry",
      "url": "https://github.com/MCP-100/mcp-sentry",
      "imageUrl": "/freedevtools/mcp/pfp/MCP-100.webp",
      "description": "Retrieve and analyze Sentry issues to facilitate debugging by inspecting error reports and stack traces. Integrate insights directly from Sentry into applications for enhanced workflow efficiency.",
      "stars": 21,
      "forks": 5,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-08-06T09:38:51Z",
      "readme_content": "# mcp-sentry: A Sentry MCP server\n\n[![smithery badge](https://smithery.ai/badge/@qianniuspace/mcp-sentry)](https://smithery.ai/server/@qianniuspace/mcp-sentry)\n\n## Overview\n\nA Model Context Protocol server for retrieving and analyzing issues from Sentry.io. This server provides tools to inspect error reports, stacktraces, and other debugging information from your Sentry account.\n\n### Tools\n\n1. `get_sentry_issue`\n   - Retrieve and analyze a Sentry issue by ID or URL\n   - Input:\n     - `issue_id_or_url` (string): Sentry issue ID or URL to analyze\n   - Returns: Issue details including:\n     - Title\n     - Issue ID\n     - Status\n     - Level\n     - First seen timestamp\n     - Last seen timestamp\n     - Event count\n     - Full stacktrace\n2. `get_list_issues`\n   - Retrieve and analyze Sentry issues by project slug\n   - Input:\n     - `project_slug` (string): Sentry project slug to analyze\n     - `organization_slug` (string): Sentry organization slug to analyze\n   - Returns: List of issues with details including:\n     - Title\n     - Issue ID\n     - Status\n     - Level\n     - First seen timestamp\n     - Last seen timestamp\n     - Event count\n     - Basic issue information\n\n### Prompts\n\n1. `sentry-issue`\n   - Retrieve issue details from Sentry\n   - Input:\n     - `issue_id_or_url` (string): Sentry issue ID or URL\n   - Returns: Formatted issue details as conversation context\n\n## Installation\n\n### Installing via Smithery\n\nTo install mcp-sentry for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@qianniuspace/mcp-sentry):\n\n```bash\nnpx -y @smithery/cli install @qianniuspace/mcp-sentry --client claude\n```\n\n### Using uv (recommended)\n\nWhen using [`uv`](https://docs.astral.sh/uv/) no specific installation is needed. We will\nuse [`uvx`](https://docs.astral.sh/uv/guides/tools/) to directly run *mcp-sentry*.\n\n### Using PIP\n\nAlternatively you can install `mcp-sentry` via pip:\n\n```\npip install mcp-sentry\n```\n\nor use uv\n```\nuv pip install -e .\n```\n\nAfter installation, you can run it as a script using:\n\n```\npython -m mcp_sentry\n```\n\n## Configuration\n\n### Usage with Claude Desktop\n\nAdd this to your `claude_desktop_config.json`:\n\n<details>\n<summary>Using uvx</summary>\n\n```json\n\"mcpServers\": {\n  \"sentry\": {\n    \"command\": \"uvx\",\n    \"args\": [\"mcp-sentry\", \"--auth-token\", \"YOUR_SENTRY_TOKEN\",\"--project-slug\" ,\"YOUR_PROJECT_SLUG\", \"--organization-slug\",\"YOUR_ORGANIZATION_SLUG\"]\n  }\n}\n```\n</details>\n\n\n<details>\n<summary>Using docker</summary>\n\n```json\n\"mcpServers\": {\n  \"sentry\": {\n    \"command\": \"docker\",\n    \"args\": [\"run\", \"-i\", \"--rm\", \"mcp/sentry\", \"--auth-token\", \"YOUR_SENTRY_TOKEN\",\"--project-slug\" ,\"YOUR_PROJECT_SLUG\", \"--organization-slug\",\"YOUR_ORGANIZATION_SLUG\"]\n  }\n}\n```\n</details>\n\n<details>\n\n<summary>Using pip installation</summary>\n\n```json\n\"mcpServers\": {\n  \"sentry\": {\n    \"command\": \"python\",\n    \"args\": [\"-m\", \"mcp_sentry\", \"--auth-token\", \"YOUR_SENTRY_TOKEN\",\"--project-slug\" ,\"YOUR_PROJECT_SLUG\", \"--organization-slug\",\"YOUR_ORGANIZATION_SLUG\"]\n  }\n}\n```\n</details>\n\n### Usage with [Zed](https://github.com/zed-industries/zed)\n\nAdd to your Zed settings.json:\n\n<details>\n<summary>Using uvx</summary>\n\nFor Example Curson  \n\n```json\n\"context_servers\": [\n  \"mcp-sentry\": {\n    \"command\": {\n      \"path\": \"uvx\",\n      \"args\": [\"mcp-sentry\", \"--auth-token\", \"YOUR_SENTRY_TOKEN\",\"--project-slug\" ,\"YOUR_PROJECT_SLUG\", \"--organization-slug\",\"YOUR_ORGANIZATION_SLUG\"]\n    }\n  }\n],\n```\n</details>\n\n<details>\n<summary>Using pip installation</summary>\n\n```json\n\"context_servers\": {\n  \"mcp-sentry\": {\n    \"command\": \"python\",\n    \"args\": [\"-m\", \"mcp_sentry\", \"--auth-token\", \"YOUR_SENTRY_TOKEN\",\"--project-slug\" ,\"YOUR_PROJECT_SLUG\", \"--organization-slug\",\"YOUR_ORGANIZATION_SLUG\"]\n  }\n},\n```\n</details>\n\n<details>\n<summary>Using pip installation with custom path</summary>\n\n```json\n\"context_servers\": {\n  \"sentry\": {\n      \"command\": \"python\",\n      \"args\": [\n        \"-m\",\n        \"mcp_sentry\",\n        \"--auth-token\",\n        \"YOUR_SENTRY_TOKEN\",\n        \"--project-slug\",\n        \"YOUR_PROJECT_SLUG\",\n        \"--organization-slug\",\n        \"YOUR_ORGANIZATION_SLUG\"\n      ],\n      \"env\": {\n        \"PYTHONPATH\": \"path/to/mcp-sentry/src\"\n      }\n    }\n},\n```\n\n\n</details>\n\n\n\n\n\n\n\n## Debugging\n\nYou can use the MCP inspector to debug the server. For uvx installations:\n\n```\nnpx @modelcontextprotocol/inspector uvx mcp-sentry --auth-token YOUR_SENTRY_TOKEN --project-slug YOUR_PROJECT_SLUG --organization-slug YOUR_ORGANIZATION_SLUG\n```\n\nOr if you've installed the package in a specific directory or are developing on it:\n\n```\ncd path/to/servers/src/sentry\nnpx @modelcontextprotocol/inspector uv run mcp-sentry --auth-token YOUR_SENTRY_TOKEN --project-slug YOUR_PROJECT_SLUG --organization-slug YOUR_ORGANIZATION_SLUG  \n```\nor in term\n```\nnpx @modelcontextprotocol/inspector uv --directory /Volumes/ExtremeSSD/MCP/mcp-sentry/src run mcp_sentry --auth-token YOUR_SENTRY_TOKEN\n--project-slug YOUR_PROJECT_SLUG --organization-slug YOUR_ORGANIZATION_SLUG\n```\n\n\n## Fork From\n- [https://github.com/modelcontextprotocol/servers/tree/main/src/sentr](https://github.com/modelcontextprotocol/servers/tree/main/src/sentry)\n## License\n\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "sentry",
        "debugging",
        "logging",
        "mcp sentry",
        "sentry issues",
        "sentry applications"
      ],
      "category": "monitoring-and-logging"
    },
    "MindscapeHQ--mcp-server-raygun": {
      "owner": "MindscapeHQ",
      "name": "mcp-server-raygun",
      "url": "https://github.com/MindscapeHQ/mcp-server-raygun",
      "imageUrl": "/freedevtools/mcp/pfp/MindscapeHQ.webp",
      "description": "Access Raygun's error tracking and monitoring data, enabling users to view errors, crashes, and performance issues in applications. Provides comprehensive access to Raygun's API for managing applications and errors.",
      "stars": 17,
      "forks": 11,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-09-10T22:50:36Z",
      "readme_content": "# Raygun MCP Server\n\nMCP Server for Raygun's API V3 endpoints for interacting with your Crash Reporting and Real User Monitoring applications. This server provides comprehensive access to Raygun's API features through the Model Context Protocol.\n\n## Features\n\n### Tools\n\n#### Applications\n- `list_applications` - List all applications under your account\n- `get_application` - Get application details by identifier\n- `get_application_by_api_key` - Get application details by API key\n- `regenerate_application_api_key` - Generate a new API key for an application\n\n#### Error Management\n- `list_error_groups` - List error groups for an application\n- `get_error_group` - Get detailed information about an error group\n- `resolve_error_group` - Set error group status to resolved\n- `activate_error_group` - Set error group status to active\n- `ignore_error_group` - Set error group status to ignored\n- `permanently_ignore_error_group` - Set error group status to permanently ignored\n\n#### Deployment Management\n- `list_deployments` - List deployments for an application\n- `get_deployment` - Get deployment details by identifier\n- `delete_deployment` - Remove a deployment\n- `update_deployment` - Update deployment information\n- `reprocess_deployment_commits` - Reprocess deployment commit data\n\n#### User & Session Management\n- `list_customers` - List customers for an application\n- `list_sessions` - List user sessions for an application\n- `get_session` - Get detailed session information\n\n#### Performance Monitoring\n- `list_pages` - List monitored pages for an application\n- `get_page_metrics_time_series` - Get time-series performance metrics\n- `get_page_metrics_histogram` - Get histogram of performance metrics\n- `get_error_metrics_time_series` - Get time-series error metrics\n\n#### Source Maps\n- `list_source_maps` - List source maps for an application\n- `get_source_map` - Get source map details\n- `update_source_map` - Update source map information\n- `delete_source_map` - Remove a source map\n- `upload_source_map` - Upload a new source map\n- `delete_all_source_maps` - Remove all source maps\n\n#### Team Management\n- `list_invitations` - List pending team invitations\n- `send_invitation` - Send a new team invitation\n- `get_invitation` - Get invitation details\n- `revoke_invitation` - Revoke a pending invitation\n\n## Configuration\n\nThe server requires the following environment variables:\n\n- `RAYGUN_PAT_TOKEN` (required): Your [Raygun PAT token](https://raygun.com/documentation/product-guides/raygun-api/)\n- `SOURCEMAP_ALLOWED_DIRS` (optional): Comma-separated list of directories allowed for source map operations\n\n## Usage with Claude Desktop\n\nAdd to your `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"raygun\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@raygun.io/mcp-server-raygun\"],\n      \"env\": {\n        \"RAYGUN_PAT_TOKEN\": \"your-pat-token-here\"\n      }\n    }\n  }\n}\n```\n\n## Development\n\nInstall dependencies:\n```bash\nnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n```bash\nnpm run watch\n```\n\n## Installation\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"raygun\": {\n      \"command\": \"/path/to/server-raygun/build/index.js\",\n      \"env\": {\n        \"RAYGUN_PAT_TOKEN\": \"your-pat-token-ken\"\n      }\n    }\n  }\n}\n```\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "raygun",
        "mindscapehq",
        "logging",
        "server raygun",
        "raygun api",
        "logging mindscapehq"
      ],
      "category": "monitoring-and-logging"
    },
    "MissionSquad--mcp-helper-tools": {
      "owner": "MissionSquad",
      "name": "mcp-helper-tools",
      "url": "https://github.com/MissionSquad/mcp-helper-tools",
      "imageUrl": "/freedevtools/mcp/pfp/MissionSquad.webp",
      "description": "Enhances LLM agents with utilities for encoding, geolocation, network diagnostics, and security. Provides tools for automation, data handling, and QR code generation.",
      "stars": 3,
      "forks": 4,
      "license": "Apache License 2.0",
      "language": "TypeScript",
      "updated_at": "2025-07-22T16:52:03Z",
      "readme_content": "# mcp-helper-tools\n\nbased on toolkit-mcp-server\n\n[![TypeScript](https://img.shields.io/badge/TypeScript-5.3-blue.svg)](https://www.typescriptlang.org/)\n[![Model Context Protocol](https://img.shields.io/badge/MCP-1.4.0-green.svg)](https://modelcontextprotocol.io/)\n[![Version](https://img.shields.io/badge/Version-1.0.1-blue.svg)]()\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n[![Status](https://img.shields.io/badge/Status-Stable-blue.svg)]()\n[![GitHub](https://img.shields.io/github/stars/cyanheads/toolkit-mcp-server?style=social)](https://github.com/cyanheads/toolkit-mcp-server)\n\nA Model Context Protocol server providing LLM Agents with system utilities and tools, including IP geolocation, network diagnostics, system monitoring, cryptographic operations, and QR code generation.\n\n## Model Context Protocol\n\nThe Model Context Protocol (MCP) enables communication between:\n\n- **Clients**: Claude Desktop, IDEs, and other MCP-compatible clients\n- **Servers**: Tools and resources for task management and automation\n- **LLM Agents**: AI models that leverage the server's capabilities\n\n## Table of Contents\n\n- [Features](#features)\n- [Installation](#installation)\n- [Configuration](#configuration)\n- [Tools](#tools)\n- [Contributing](#contributing)\n- [License](#license)\n\n## Features\n\n### Encoding Tools\n- Base64 encoding/decoding\n- URL encoding/decoding\n- HTML encoding/decoding\n\n### Network & Geolocation\n- IP geolocation with intelligent caching\n- Rate limiting (45 requests/minute)\n\n### Security Tools\n- Cryptographic hash generation (MD5, SHA-1, SHA-256, SHA-512)\n- Constant-time hash comparison\n- UUID generation\n\n### Generator Tools\n- QR code generation\n  - Terminal output\n  - SVG format\n  - Base64 encoded images\n\n## Installation\n\n```bash\n# Using npm (recommended)\nnpm install @cyanheads/toolkit-mcp-server\n\n# Or install from source\ngit clone git@github.com:cyanheads/toolkit-mcp-server.git\ncd toolkit-mcp-server\nnpm install\nnpm run build\n```\n\n## Configuration\n\nAdd to your MCP client settings:\n\n```json\n{\n  \"mcpServers\": {\n    \"toolkit\": {\n      \"command\": \"node\",\n      \"args\": [\"node_modules/@cyanheads/toolkit-mcp-server/build/index.js\"],\n      \"env\": {\n        \"NODE_ENV\": \"production\"\n      }\n    }\n  }\n}\n```\n\n## Tools\n\n### Network Operations\n```typescript\n// Get geolocation data\nconst geo = await mcp.use('toolkit-mcp-server', 'geolocate', {\n  query: '8.8.8.8'\n});\n\n// Check connectivity\nconst conn = await mcp.use('toolkit-mcp-server', 'checkConnectivity', {\n  host: 'example.com',\n  port: 443\n});\n```\n\n### System Operations\n```typescript\n// Get system information\nconst sysInfo = await mcp.use('toolkit-mcp-server', 'getSystemInfo', {});\n\n// Get load average\nconst load = await mcp.use('toolkit-mcp-server', 'getLoadAverage', {});\n```\n\n### Security Operations\n```typescript\n// Generate hash\nconst hash = await mcp.use('toolkit-mcp-server', 'hashData', {\n  input: 'test data',\n  algorithm: 'sha256'\n});\n\n// Generate UUID\nconst uuid = await mcp.use('toolkit-mcp-server', 'generateUUID', {});\n```\n\n### Generator Operations\n```typescript\n// Generate QR code\nconst qr = await mcp.use('toolkit-mcp-server', 'generateQRCode', {\n  data: 'https://example.com',\n  type: 'svg'\n});\n```\n\n## Contributing\n\n1. Fork the repository\n2. Create your feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add some amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n\n## License\n\nApache License 2.0. See [LICENSE](LICENSE) for more information.\n\n---\n\n<div align=\"center\">\nBuilt with the Model Context Protocol\n</div>",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "missionsquad",
        "llm",
        "tools",
        "missionsquad mcp",
        "logging missionsquad",
        "mcp helper"
      ],
      "category": "monitoring-and-logging"
    },
    "Nozomuts--datadog-mcp": {
      "owner": "Nozomuts",
      "name": "datadog-mcp",
      "url": "https://github.com/Nozomuts/datadog-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/Nozomuts.webp",
      "description": "Enables powerful search and aggregation of logs and trace spans from Datadog, allowing for flexible queries and detailed data retrieval. Facilitates the integration of Datadog monitoring data into applications for insightful analysis.",
      "stars": 0,
      "forks": 1,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-04-28T14:00:49Z",
      "readme_content": "# Datadog MCP Server\n\n[English (This Document)](/README.md) | [日本語](/README-ja.md)\n\nMCP Server for Datadog API, enabling log search, trace span search, and trace span aggregation functionalities.\n\n<a href=\"https://glama.ai/mcp/servers/@Nozomuts/datadog-mcp\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@Nozomuts/datadog-mcp/badge\" alt=\"Datadog Server MCP server\" />\n</a>\n\n## Features\n\n- **Log Search**: Search and retrieve logs from Datadog with flexible query options\n- **Trace Span Search**: Search for distributed trace spans with various filtering options\n- **Trace Span Aggregation**: Aggregate trace spans by different dimensions for analysis\n\n## Tools\n\n1. `search_logs`\n   - Search for logs in Datadog\n   - Inputs:\n     - `filterQuery` (optional string): Query string to search logs (default: \"*\")\n     - `filterFrom` (optional number): Search start time as UNIX timestamp in seconds (default: 15 minutes ago)\n     - `filterTo` (optional number): Search end time as UNIX timestamp in seconds (default: current time)\n     - `pageLimit` (optional number): Maximum number of logs to retrieve (default: 25, max: 1000)\n     - `pageCursor` (optional string): Pagination cursor for retrieving additional results\n   - Returns: Formatted text containing:\n     - Search conditions (query and time range)\n     - Number of logs found\n     - Next page cursor (if available)\n     - Log details including:\n       - Service name\n       - Tags\n       - Timestamp\n       - Status\n       - Message (truncated to 300 characters)\n       - Host\n       - Important attributes (http.method, http.url, http.status_code, error)\n\n2. `search_spans`\n   - Search for trace spans in Datadog\n   - Inputs:\n     - `filterQuery` (optional string): Query string to search spans (default: \"*\")\n     - `filterFrom` (optional number): Search start time as UNIX timestamp in seconds (default: 15 minutes ago)\n     - `filterTo` (optional number): Search end time as UNIX timestamp in seconds (default: current time)\n     - `pageLimit` (optional number): Maximum number of spans to retrieve (default: 25, max: 1000)\n     - `pageCursor` (optional string): Pagination cursor for retrieving additional results\n   - Returns: Formatted text containing:\n     - Search conditions (query and time range)\n     - Number of spans found\n     - Next page cursor (if available)\n     - Span details including:\n       - Service name\n       - Timestamp\n       - Resource name\n       - Duration (in seconds)\n       - Host\n       - Environment\n       - Type\n       - Important attributes (http.method, http.url, http.status_code, error)\n\n3. `aggregate_spans`\n   - Aggregate trace spans in Datadog by specified dimensions\n   - Inputs:\n     - `filterQuery` (optional string): Query string to filter spans for aggregation (default: \"*\")\n     - `filterFrom` (optional number): Start time as UNIX timestamp in seconds (default: 15 minutes ago)\n     - `filterTo` (optional number): End time as UNIX timestamp in seconds (default: current time)\n     - `groupBy` (optional string[]): Dimensions to group by (e.g., [\"service\", \"resource_name\", \"status\"])\n     - `aggregation` (optional string): Aggregation method - \"count\", \"avg\", \"sum\", \"min\", \"max\", \"pct\" (default: \"count\")\n     - `interval` (optional string): Time interval for time series data (only when type is \"timeseries\")\n     - `type` (optional string): Result type, either \"timeseries\" or \"total\" (default: \"timeseries\")\n   - Returns: Formatted text containing:\n     - Aggregation results in buckets, each including:\n       - Bucket ID\n       - Group by values (if groupBy is specified)\n       - Computed values based on the aggregation method\n     - Additional metadata:\n       - Processing time (elapsed)\n       - Request ID\n       - Status\n       - Warnings (if any)\n\n## Setup\nYou need to set up Datadog API and application keys:\n\n1. Get your API key and application key from the [Datadog API Keys page](https://app.datadoghq.com/organization-settings/api-keys)\n2. Install dependencies in the datadog-mcp project:\n   ```bash\n   npm install\n   # or\n   pnpm install\n   ```\n3. Build the TypeScript project:\n   ```bash\n   npm run build\n   # or\n   pnpm run build\n   ```\n\n### Docker Setup\nYou can build using Docker with the following command:\n\n```bash\ndocker build -t datadog-mcp .\n```\n\n### Usage with Claude Desktop\nTo use this with Claude Desktop, add the following to your `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"datadog\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/path/to/datadog-mcp/build/index.js\"\n      ],\n      \"env\": {\n        \"DD_API_KEY\": \"<YOUR_DATADOG_API_KEY>\",\n        \"DD_APP_KEY\": \"<YOUR_DATADOG_APP_KEY>\"\n      }\n    }\n  }\n}\n```\n\nIf you're using Docker, you can configure it like this:\n\n```json\n{\n  \"mcpServers\": {\n    \"datadog\": {\n      \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"-i\",\n          \"--rm\",\n          \"-e\",\n          \"DD_API_KEY\",\n          \"-e\",\n          \"DD_APP_KEY\",\n          \"datadog-mcp\"\n        ],\n      \"env\": {\n        \"DD_API_KEY\": \"<YOUR_DATADOG_API_KEY>\",\n        \"DD_APP_KEY\": \"<YOUR_DATADOG_APP_KEY>\"\n      }\n    }\n  }\n}\n```\n\n### Usage with VS Code\n\nFor quick installation in VS Code, configure your settings:\n\n1. Open User Settings (JSON) in VS Code (`Ctrl+Shift+P` → `Preferences: Open User Settings (JSON)`)\n2. Add the following configuration:\n\n```json\n{\n  \"mcp\": {\n    \"servers\": {\n      \"datadog\": {\n        \"command\": \"node\",\n        \"args\": [\n          \"/path/to/datadog-mcp/build/index.js\"\n        ],\n        \"env\": {\n          \"DD_API_KEY\": \"<YOUR_DATADOG_API_KEY>\",\n          \"DD_APP_KEY\": \"<YOUR_DATADOG_APP_KEY>\"\n        }\n      }\n    }\n  }\n}\n```\n\nIf you're using Docker, you can configure it like this:\n\n```json\n{\n  \"mcp\": {\n    \"servers\": {\n      \"datadog\": {\n        \"command\": \"docker\",\n          \"args\": [\n          \"run\",\n          \"-i\",\n          \"--rm\",\n          \"-e\",\n          \"DD_API_KEY\",\n          \"-e\",\n          \"DD_APP_KEY\",\n          \"datadog-mcp\"\n        ],\n        \"env\": {\n          \"DD_API_KEY\": \"<YOUR_DATADOG_API_KEY>\",\n          \"DD_APP_KEY\": \"<YOUR_DATADOG_APP_KEY>\"\n        }\n      }\n    }\n  }\n}\n```\n\nAlternatively, you can add this to a `.vscode/mcp.json` file in your workspace (without the `mcp` key):\n\n```json\n{\n  \"servers\": {\n    \"datadog\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/path/to/datadog-mcp/build/index.js\"\n      ],\n      \"env\": {\n        \"DD_API_KEY\": \"<YOUR_DATADOG_API_KEY>\",\n        \"DD_APP_KEY\": \"<YOUR_DATADOG_APP_KEY>\"\n      }\n    }\n  }\n}\n```\n\nIf you're using Docker, you can configure it like this:\n\n```json\n{\n  \"servers\": {\n    \"datadog\": {\n      \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"-i\",\n          \"--rm\",\n          \"-e\",\n          \"DD_API_KEY\",\n          \"-e\",\n          \"DD_APP_KEY\",\n          \"datadog-mcp\"\n        ],\n      \"env\": {\n        \"DD_API_KEY\": \"<YOUR_DATADOG_API_KEY>\",\n        \"DD_APP_KEY\": \"<YOUR_DATADOG_APP_KEY>\"\n      }\n    }\n  }\n}\n```",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "datadog",
        "logging",
        "logs",
        "datadog monitoring",
        "monitoring logging",
        "nozomuts datadog"
      ],
      "category": "monitoring-and-logging"
    },
    "Operative-Sh--playwright-consolelogs-mcp": {
      "owner": "Operative-Sh",
      "name": "playwright-consolelogs-mcp",
      "url": "https://github.com/Operative-Sh/playwright-consolelogs-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/null.webp",
      "description": "Open a browser to monitor console logs and track network requests for improved debugging and analysis. Retrieve structured log data and network activity while maintaining a clean environment post-session.",
      "stars": 0,
      "forks": 0,
      "license": "Unknown",
      "language": "Unknown",
      "updated_at": "",
      "readme_content": "",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "consolelogs",
        "logging",
        "debugging",
        "consolelogs mcp",
        "playwright consolelogs",
        "console logs"
      ],
      "category": "monitoring-and-logging"
    },
    "QAInsights--k6-mcp-server": {
      "owner": "QAInsights",
      "name": "k6-mcp-server",
      "url": "https://github.com/QAInsights/k6-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/QAInsights.webp",
      "description": "Run load tests using k6 with custom configurations and obtain real-time execution output. Integrates with the Model Context Protocol to streamline load testing processes and enhance performance insights.",
      "stars": 15,
      "forks": 8,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-11T16:28:07Z",
      "readme_content": "# 🚀 ⚡️ k6-mcp-server\n\nA Model Context Protocol (MCP) server implementation for running k6 load tests.\n\n## ✨ Features\n\n- Simple integration with Model Context Protocol framework\n- Support for custom test durations and virtual users (VUs)\n- Easy-to-use API for running k6 load tests\n- Configurable through environment variables\n- Real-time test execution output\n\n## 🔧 Prerequisites\n\nBefore you begin, ensure you have the following installed:\n\n- Python 3.12 or higher\n- k6 load testing tool ([Installation guide](https://grafana.com/docs/k6/latest/set-up/install-k6/))\n- uv package manager ([Installation guide](https://github.com/astral-sh/uv))\n\n## 📦 Installation\n\n1. Clone the repository:\n\n```bash\ngit clone https://github.com/qainsights/k6-mcp-server.git\n```\n\n2. Install the required dependencies:\n\n```bash\nuv pip install -r requirements.txt\n```\n\n3. Set up environment variables (optional):\n   Create a `.env` file in the project root:\n\n```bash\nK6_BIN=/path/to/k6  # Optional: defaults to 'k6' in system PATH\n```\n\n## 🚀 Getting Started\n\n1. Create a k6 test script (e.g., `test.js`):\n\n```javascript\nimport http from \"k6/http\";\nimport { sleep } from \"k6\";\n\nexport default function () {\n  http.get(\"http://test.k6.io\");\n  sleep(1);\n}\n```\n\n2. Configure the MCP server using the below specs in your favorite MCP client (Claude Desktop, Cursor, Windsurf and more):\n\n```json\n{\n  \"mcpServers\": {\n    \"k6\": {\n      \"command\": \"/path/to/bin/uv\",\n      \"args\": [\n        \"--directory\",\n        \"/path/to/k6-mcp-server\",\n        \"run\",\n        \"k6_server.py\"\n      ]\n    }\n  }\n}\n\n```\n3. Now ask the LLM to run the test e.g. `run k6 test for hello.js`. The k6 mcp server will leverage either one of the below tools to start the test.\n\n- `execute_k6_test`: Run a test with default options (30s duration, 10 VUs)\n- `execute_k6_test_with_options`: Run a test with custom duration and VUs\n\n\n\n\n## 📝 API Reference\n\n### Execute K6 Test\n\n```python\nexecute_k6_test(\n    script_file: str,\n    duration: str = \"30s\",  # Optional\n    vus: int = 10          # Optional\n)\n```\n\n### Execute K6 Test with Custom Options\n\n```python\nexecute_k6_test_with_options(\n    script_file: str,\n    duration: str,\n    vus: int\n)\n```\n\n## ✨ Use cases\n\n- LLM powered results analysis\n- Effective debugging of load tests\n\n## 🤝 Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## 📄 License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "k6",
        "monitoring",
        "testing",
        "load testing",
        "load tests",
        "using k6"
      ],
      "category": "monitoring-and-logging"
    },
    "QAInsights--locust-mcp-server": {
      "owner": "QAInsights",
      "name": "locust-mcp-server",
      "url": "https://github.com/QAInsights/locust-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/QAInsights.webp",
      "description": "Integrates Locust load testing capabilities into AI development environments, enabling configurable load tests with real-time output in both headless and UI modes. Supports customizable test scenarios through an easy-to-use API.",
      "stars": 9,
      "forks": 5,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-19T14:58:05Z",
      "readme_content": "# 🚀 ⚡️ locust-mcp-server\n\nA Model Context Protocol (MCP) server implementation for running Locust load tests. This server enables seamless integration of Locust load testing capabilities with AI-powered development environments.\n\n## ✨ Features\n\n- Simple integration with Model Context Protocol framework\n- Support for headless and UI modes\n- Configurable test parameters (users, spawn rate, runtime)\n- Easy-to-use API for running Locust load tests\n- Real-time test execution output\n- HTTP/HTTPS protocol support out of the box\n- Custom task scenarios support\n\n\n\n## 🔧 Prerequisites\n\nBefore you begin, ensure you have the following installed:\n\n- Python 3.13 or higher\n- uv package manager ([Installation guide](https://github.com/astral-sh/uv))\n\n## 📦 Installation\n\n1. Clone the repository:\n\n```bash\ngit clone https://github.com/qainsights/locust-mcp-server.git\n```\n\n2. Install the required dependencies:\n\n```bash\nuv pip install -r requirements.txt\n```\n\n3. Set up environment variables (optional):\n   Create a `.env` file in the project root:\n\n```bash\nLOCUST_HOST=http://localhost:8089  # Default host for your tests\nLOCUST_USERS=3                     # Default number of users\nLOCUST_SPAWN_RATE=1               # Default user spawn rate\nLOCUST_RUN_TIME=10s               # Default test duration\n```\n\n## 🚀 Getting Started\n\n1. Create a Locust test script (e.g., `hello.py`):\n\n```python\nfrom locust import HttpUser, task, between\n\nclass QuickstartUser(HttpUser):\n    wait_time = between(1, 5)\n\n    @task\n    def hello_world(self):\n        self.client.get(\"/hello\")\n        self.client.get(\"/world\")\n\n    @task(3)\n    def view_items(self):\n        for item_id in range(10):\n            self.client.get(f\"/item?id={item_id}\", name=\"/item\")\n            time.sleep(1)\n\n    def on_start(self):\n        self.client.post(\"/login\", json={\"username\":\"foo\", \"password\":\"bar\"})\n```\n\n2. Configure the MCP server using the below specs in your favorite MCP client (Claude Desktop, Cursor, Windsurf and more):\n\n```json\n{\n  \"mcpServers\": {\n    \"locust\": {\n      \"command\": \"/Users/naveenkumar/.local/bin/uv\",\n      \"args\": [\n        \"--directory\",\n        \"/Users/naveenkumar/Gits/locust-mcp-server\",\n        \"run\",\n        \"locust_server.py\"\n      ]\n    }\n  }\n}\n```\n\n3. Now ask the LLM to run the test e.g. `run locust test for hello.py`. The Locust MCP server will use the following tool to start the test:\n\n- `run_locust`: Run a test with configurable options for headless mode, host, runtime, users, and spawn rate\n\n## 📝 API Reference\n\n### Run Locust Test\n\n```python\nrun_locust(\n    test_file: str,\n    headless: bool = True,\n    host: str = \"http://localhost:8089\",\n    runtime: str = \"10s\",\n    users: int = 3,\n    spawn_rate: int = 1\n)\n```\n\nParameters:\n\n- `test_file`: Path to your Locust test script\n- `headless`: Run in headless mode (True) or with UI (False)\n- `host`: Target host to load test\n- `runtime`: Test duration (e.g., \"30s\", \"1m\", \"5m\")\n- `users`: Number of concurrent users to simulate\n- `spawn_rate`: Rate at which users are spawned\n\n## ✨ Use Cases\n\n- LLM powered results analysis\n- Effective debugging with the help of LLM\n\n## 🤝 Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## 📄 License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "monitoring",
        "locust",
        "testing",
        "load testing",
        "locust load",
        "testing capabilities"
      ],
      "category": "monitoring-and-logging"
    },
    "ThijsdeZeeuw--avg-kwintes": {
      "owner": "ThijsdeZeeuw",
      "name": "avg-kwintes",
      "url": "https://github.com/ThijsdeZeeuw/avg-kwintes",
      "imageUrl": "/freedevtools/mcp/pfp/ThijsdeZeeuw.webp",
      "description": "Deploys a comprehensive self-hosted AI stack on VPS, supporting automation, monitoring, vector search, and speech-to-text capabilities. Integrates tools such as n8n, Ollama, Qdrant, Prometheus, and Grafana for efficient AI processing and maintenance.",
      "stars": 1,
      "forks": 0,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-04-01T11:23:24Z",
      "readme_content": "# Local AI Stack for VPS Deployment\n\nA comprehensive self-hosted AI stack designed for VPS deployment, featuring n8n, Ollama, Qdrant, Prometheus, Grafana, Whisper, and more.\n\n> **Note:** This project is based on work from [coleam00/local-ai-packaged](https://github.com/coleam00/local-ai-packaged) and [Digitl-Alchemyst/Automation-Stack](https://github.com/Digitl-Alchemyst/Automation-Stack) with customizations and improvements.\n\n## Features\n\n- ✅ [**n8n**](https://n8n.io/) - Low-code automation platform with 400+ integrations\n- ✅ [**Ollama**](https://ollama.com/) - Local LLM platform\n- ✅ [**Qdrant**](https://qdrant.tech/) - High-performance vector store\n- ✅ [**Prometheus**](https://prometheus.io/) - Monitoring and alerting toolkit\n- ✅ [**Grafana**](https://grafana.com/) - Metrics visualization and analytics\n- ✅ [**Whisper**](https://github.com/openai/whisper) - Speech-to-text processing\n- ✅ [**Caddy**](https://caddyserver.com/) - Automatic HTTPS/TLS\n- ✅ [**Supabase**](https://supabase.com/) - Database and authentication\n- ✅ [**Flowise**](https://flowiseai.com/) - AI agent builder\n- ✅ [**Open WebUI**](https://openwebui.com/) - ChatGPT-like interface\n- ✅ [**SearXNG**](https://docs.searxng.org/) - Privacy-focused search engine\n\n## Prerequisites\n\n- Ubuntu VPS (tested on Ubuntu 22.04 LTS)\n- Domain name with DNS access\n- Minimum 16GB RAM recommended\n- 100GB+ storage recommended\n- Docker installed (version 20.10.0 or later recommended)\n- Docker Compose installed:\n  - Either Docker Compose plugin (`docker compose`) \n  - Or standalone Docker Compose binary (`docker-compose`)\n\n> **Note:** The setup script will automatically detect whether to use `docker compose` or `docker-compose` based on what's available on your system.\n\n## Installation\n\n1. Connect to your VPS via SSH: \n```bash\nssh root@your-vps-ip\n```\n\n2. Install required packages:\n```bash\nsudo apt update && sudo apt install -y nano git docker.io python3 python3-pip docker-compose\n```\n\n3. Configure firewall:\n```bash\nsudo ufw enable\nsudo ufw allow 5678  # n8n (using port 5678 to avoid conflict with Supabase)\nsudo ufw allow 3001  # Flowise\nsudo ufw allow 8080  # Open WebUI\nsudo ufw allow 3000  # Grafana\nsudo ufw allow 80    # HTTP\nsudo ufw allow 443   # HTTPS\nsudo ufw allow 8000  # Supabase API (Kong)\nsudo ufw allow 11434 # Ollama\nsudo ufw allow 6333  # Qdrant\nsudo ufw allow 9090  # Prometheus\nsudo ufw allow 54321 # Supabase Studio\nsudo ufw reload\n```\n\n4. Clone the repository:\n```bash\ngit clone https://github.com/ThijsdeZeeuw/avg-kwintes.git\ncd avg-kwintes\n```\n\n5. Run the configuration script to prepare the environment:\n```bash\n# Make the script executable\nchmod +x fix_config.sh\n\n# Run the configuration script\nsudo ./fix_config.sh\n```\n\nThe configuration script will:\n- Check and install all necessary system dependencies\n- Configure the correct firewall rules for all services\n- Detect and resolve any port conflicts\n- Generate utility scripts for maintenance\n- Create a basic .env file if one doesn't exist\n\n6. Run the interactive setup to complete configuration:\n```bash\npython3 start_services.py --interactive\n```\n\n7. Start the services:\n```bash\npython3 start_services.py --profile cpu\n```\n\nThis sequence ensures that everything is properly configured before starting the services, avoiding port conflicts and other setup issues.\n\n## Utility Scripts\n\nThe configuration process creates several helpful utility scripts:\n\n### Update Script\nTo update your Local AI Stack to the latest version:\n```bash\nsudo ./update_stack.sh\n```\nThis script will pull the latest Docker images, apply necessary configuration fixes, and restart all services.\n\n### Backup Script\nTo create a complete backup of your Local AI Stack data:\n```bash\nsudo ./backup_stack.sh\n```\nThis script will back up all Docker volumes, configuration files, and secrets to a timestamped archive.\n\n## Ollama Models\n\nThe following models are automatically installed and available in the system:\n\n### Large Language Models (LLMs)\n\n| Model | Source | Description |\n|-------|---------|-------------|\n| gemma3:12b | Google | A 12B parameter model from Google's Gemma family, optimized for general text understanding and generation |\n| granite3-guardian:8b | IBM | An 8B parameter model focused on safety and ethical considerations in AI interactions |\n| granite3.1-dense:latest | IBM | Latest version of IBM's dense transformer model for general language tasks |\n| granite3.1-moe:3b | IBM | A 3B parameter mixture-of-experts model optimized for efficient inference |\n| granite3.2:latest | IBM | Latest version of IBM's advanced language model with improved capabilities |\n| llama3.2-vision | Meta | A multimodal model capable of understanding both text and images |\n| minicpm-v:8b | OpenBMB | A compact 8B parameter model optimized for efficient deployment |\n| mistral-nemo:12b | Mistral AI | A 12B parameter model based on Mistral's architecture with enhanced capabilities |\n| qwen2.5:7b-instruct-q4_K_M | Alibaba | A quantized 7B parameter instruction-tuned model optimized for efficiency |\n| reader-lm:latest | OpenBMB | A specialized model for document understanding and question answering |\n\n### Embedding Models\n\n| Model | Source | Description |\n|-------|---------|-------------|\n| granite-embedding:278m | IBM | A compact embedding model for efficient text vectorization |\n| jeffh/intfloat-multilingual-e5-large-instruct:f16 | Hugging Face | A multilingual embedding model optimized for instruction following |\n| nomic-embed-text:latest | Nomic AI | A general-purpose text embedding model for semantic search and similarity |\n\nThese models are automatically downloaded during the initial setup process. The system supports both CPU and GPU (NVIDIA/AMD) inference depending on your hardware configuration.\n\n## Accessing Services\n\nAfter installation, you can access the following services:\n\n- n8n: https://n8n.kwintes.cloud\n- Web UI: https://openwebui.kwintes.cloud\n- Flowise: https://flowise.kwintes.cloud\n- Supabase: https://supabase.kwintes.cloud\n- Supabase Studio: http://localhost:54321 or https://studio.supabase.kwintes.cloud\n- Grafana: https://grafana.kwintes.cloud\n- Prometheus: https://prometheus.kwintes.cloud\n- Whisper API: https://whisper.kwintes.cloud\n- Qdrant API: https://qdrant.kwintes.cloud\n\n## Monitoring\n\nThe stack includes comprehensive monitoring:\n\n1. Access Grafana at https://grafana.kwintes.cloud\n   - Default credentials: admin / (password from secrets.txt)\n   - Add Prometheus as a data source (URL: http://prometheus:9090)\n\n2. Access Prometheus at https://prometheus.kwintes.cloud\n   - View metrics and create alerts\n\n## Security Notes\n\n1. All secrets are saved to secrets.txt - keep this file secure\n2. All services are configured to use HTTPS through Caddy\n3. Firewall rules are configured to allow only necessary ports\n4. Default credentials should be changed after first login\n\n## Maintenance\n\nTo update the stack:\n```bash\ncd local-ai-packaged\ngit pull\npython3 start_services.py --profile cpu\n```\n\nTo restart services:\n```bash\ndocker compose -p localai down\npython3 start_services.py --profile cpu\n```\n\n## Troubleshooting\n\n1. **Docker Compose Issues**\n   \n   If you encounter errors with Docker Compose commands like:\n   ```\n   unknown shorthand flag: 'p' in -p\n   ```\n   This indicates incompatibility between the command format and your Docker Compose version.\n   \n   **Solution:** The script now automatically detects and uses the correct Docker Compose command format for your system. If you're manually running commands, use:\n   - For Docker Compose plugin: `docker compose -p localai ...` \n   - For standalone binary: `docker-compose -p localai ...`\n   \n   If neither works, install the standalone Docker Compose binary:\n   ```bash\n   sudo curl -L \"https://github.com/docker/compose/releases/download/v2.24.5/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose\n   sudo chmod +x /usr/local/bin/docker-compose\n   ```\n\n2. Check service logs:\n```bash\ndocker compose -p localai logs -f [service_name]\n# or\ndocker-compose -p localai logs -f [service_name]\n```\n\n3. Verify service status:\n```bash\ndocker compose -p localai ps\n# or\ndocker-compose -p localai ps\n```\n\n4. Check monitoring:\n- Visit Grafana dashboard\n- Check Prometheus targets\n- Review service health endpoints\n\n5. Service Restart:\n```bash\n# Restart all services\ndocker compose down\ndocker compose up -d\n```\n\n## Support\n\nFor issues and feature requests, please open an issue on the GitHub repository.\n\n---\nCreated and maintained by Z4Y\n\n## Security Features\n\nThis setup prioritizes security through multiple layers:\n\n1. **Local Deployment**\n   - All AI models run locally on your VPS\n   - No data is sent to external AI services\n   - Complete control over data privacy and security\n\n2. **Secure Infrastructure**\n   - Automatic HTTPS/TLS encryption via Caddy\n   - Firewall rules limiting access to necessary ports\n   - Secure secret management with environment variables\n   - Regular security updates through Docker containers\n\n3. **Access Control**\n   - Supabase authentication for user management\n   - Role-based access control\n   - Audit logging for all system activities\n   - Secure API endpoints with authentication\n\n4. **Data Protection**\n   - Local vector database (Qdrant) for secure document storage\n   - Encrypted communication between services\n   - No external API dependencies for core functionality\n   - Regular backup capabilities\n\n## Local AI Capabilities\n\nThe system leverages powerful local models for various tasks:\n\n### Text Processing\n- Document summarization and analysis\n- Multi-language support (via multilingual models)\n- Question answering and information extraction\n- Text classification and sentiment analysis\n\n### Vision Capabilities\n- Image analysis and description\n- Document scanning and text extraction\n- Visual understanding and reasoning\n- Accessibility features for visual content\n\n### Example Use Cases\n\n1. **Document Analysis**\n   ```python\n   # Example: Analyzing client reports\n   input_text = \"Client report from session...\"\n   model = \"qwen2.5:7b-instruct-q4_K_M\"\n   # Process and analyze the report locally\n   ```\n\n2. **Multi-language Support**\n   ```python\n   # Example: Processing documents in multiple languages\n   text = \"Document in Dutch...\"\n   model = \"jeffh/intfloat-multilingual-e5-large-instruct:f16\"\n   # Process multilingual content\n   ```\n\n3. **Visual Document Processing**\n   ```python\n   # Example: Analyzing scanned documents\n   image = \"scanned_report.jpg\"\n   model = \"llama3.2-vision\"\n   # Extract and analyze visual content\n   ```\n\n## GGZ/FBW Client Support\n\nThis system is particularly valuable for GGZ (Mental Healthcare) and FBW (Forensic Protected Living) organizations:\n\n### Document Generation and Analysis\n\n1. **Client Report Generation**\n   - Automatically generate structured reports from session notes\n   - Maintain consistent documentation standards\n   - Support multiple languages for diverse client populations\n   - Ensure privacy by processing all data locally\n\n2. **Treatment Plan Analysis**\n   - Analyze treatment plans for completeness and consistency\n   - Identify potential gaps in documentation\n   - Suggest improvements based on best practices\n   - Track progress over time\n\n3. **Risk Assessment Support**\n   - Process and analyze risk assessment documents\n   - Identify patterns and trends in risk factors\n   - Generate structured risk reports\n   - Support evidence-based decision making\n\n### Client Understanding and Support\n\n1. **Communication Analysis**\n   - Process and analyze client communications\n   - Identify key themes and concerns\n   - Support multilingual communication\n   - Track changes in client status over time\n\n2. **Documentation Quality**\n   - Ensure consistent documentation standards\n   - Identify missing or incomplete information\n   - Suggest improvements in documentation\n   - Support quality assurance processes\n\n3. **Knowledge Management**\n   - Create searchable knowledge bases from client documents\n   - Support evidence-based practice\n   - Enable quick access to relevant information\n   - Maintain privacy and security of sensitive data\n\n### Benefits for GGZ/FBW Organizations\n\n1. **Privacy and Compliance**\n   - All processing happens locally\n   - No external data transmission\n   - Compliant with healthcare privacy regulations\n   - Full control over data security\n\n2. **Efficiency Improvements**\n   - Automated document processing\n   - Reduced administrative burden\n   - Faster access to relevant information\n   - Support for evidence-based practice\n\n3. **Quality Enhancement**\n   - Consistent documentation standards\n   - Improved risk assessment\n   - Better tracking of client progress\n   - Enhanced decision support\n\n## Port Configuration\n\nTo avoid port conflicts between services, we've set up consistent port mappings:\n\n```bash\nsudo ufw enable\nsudo ufw allow 5678  # n8n (using port 5678 to avoid conflict with Supabase)\nsudo ufw allow 3001  # Flowise\nsudo ufw allow 8080  # Open WebUI\nsudo ufw allow 3000  # Grafana\nsudo ufw allow 80    # HTTP\nsudo ufw allow 443   # HTTPS\nsudo ufw allow 8000  # Supabase API (Kong)\nsudo ufw allow 11434 # Ollama\nsudo ufw allow 6333  # Qdrant\nsudo ufw allow 9090  # Prometheus\nsudo ufw allow 54321 # Supabase Studio\nsudo ufw reload\n```\n\nKey points about our port configuration:\n1. n8n uses port 5678 instead of 8000 to avoid conflicts with Supabase\n2. Each service uses consistent internal and external port mappings\n3. Port settings are handled automatically by the setup scripts\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ai",
        "monitoring",
        "avg",
        "hosted ai",
        "ai stack",
        "avg kwintes"
      ],
      "category": "monitoring-and-logging"
    },
    "Yaswanth-ampolu--smithery-mcp-server": {
      "owner": "Yaswanth-ampolu",
      "name": "smithery-mcp-server",
      "url": "https://github.com/Yaswanth-ampolu/smithery-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/Yaswanth-ampolu.webp",
      "description": "Provides terminal access through a web interface for executing shell commands, browsing directories, and managing server tasks without requiring root access. Supports real-time updates of command outputs for immediate feedback.",
      "stars": 3,
      "forks": 2,
      "license": "No License",
      "language": "HTML",
      "updated_at": "2025-06-22T17:46:47Z",
      "readme_content": "# MCP Terminal Server\n\nMCP Terminal Server provides terminal access and system tools via a clean web interface. It enables remote command execution, directory listing, and other terminal operations through a simple HTTP server.\n\n\n\n## Features\n\n- 🚀 **Remote Terminal Access**: Execute shell commands from a web browser\n- 📁 **Directory Listing**: Browse and list files in any directory\n- 🔒 **Secure Local Installation**: Runs without requiring root access\n- 🌐 **Web Interface**: Clean, modern UI for easy interaction\n- 🔄 **Real-time Updates**: See command outputs as they happen\n- 🛠️ **Easy Management**: Simple commands to start, stop, and manage the server\n\n## Prerequisites\n\nBefore installing the MCP Terminal Server, ensure your system meets these requirements:\n\n- **Node.js** (version 14 or higher)\n- **curl** (for downloading the installation script)\n- **tar** (for extracting the package)\n\n## Quick Installation\n\nInstall the MCP Terminal Server with a single command:\n\n```bash\ncurl -o- https://github.com/Yaswanth-ampolu/smithery-mcp-server/raw/main/main/install-mcp.sh | bash\n```\n\nThis will:\n1. Download the installation script\n2. Check for dependencies\n3. Download and extract the server files\n4. Set up the necessary directories\n5. Add the command to your PATH\n\n## Manual Installation\n\nIf you prefer to inspect the script before running it:\n\n1. Download the installation script:\n   ```bash\n   curl -o install-mcp.sh https://github.com/Yaswanth-ampolu/smithery-mcp-server/raw/main/main/install-mcp.sh\n   ```\n\n2. Review the script content:\n   ```bash\n   less install-mcp.sh\n   ```\n\n3. Run the installation:\n   ```bash\n   bash install-mcp.sh\n   ```\n\n## Usage\n\nAfter installation, the MCP Terminal Server can be managed with the following commands:\n\n### Starting the Server\n\n```bash\nmcp-terminal start\n```\n\nBy default, the server starts on port 8080. To use a different port:\n\n```bash\nmcp-terminal start --port 9000\n```\n\n### Stopping the Server\n\n```bash\nmcp-terminal stop\n```\n\n### Checking Server Status\n\n```bash\nmcp-terminal status\n```\n\nThis shows:\n- Whether the server is running\n- The PID of the running server\n- Memory usage\n- The URL to access the web interface\n\n### Restarting the Server\n\n```bash\nmcp-terminal restart\n```\n\n### Uninstalling\n\nTo completely remove the MCP Terminal Server:\n\n```bash\nmcp-terminal uninstall\n```\n\n## Web Interface\n\nOnce the server is running, access the web interface at:\n\n```\nhttp://localhost:8080\n```\n\n(or the custom port you specified)\n\nThe web interface provides:\n- A command execution tool\n- A directory listing tool\n- Real-time output display\n\n## Configuration\n\nThe MCP Terminal Server stores its files in:\n- `~/mcp-terminal` - Main installation directory\n- `~/bin/mcp-terminal` - Command script\n\nLog files and PID information are stored in:\n- `~/mcp-terminal/mcp.log` - Server log file\n- `~/mcp-terminal/mcp.pid` - Server PID file\n\n## Troubleshooting\n\n### Server Won't Start\n\nIf the server fails to start:\n\n1. Check if Node.js is installed and version 14+:\n   ```bash\n   node -v\n   ```\n\n2. Check the log file for errors:\n   ```bash\n   tail -n 50 ~/mcp-terminal/mcp.log\n   ```\n\n3. Verify the installation directory exists:\n   ```bash\n   ls -la ~/mcp-terminal\n   ```\n\n### Port Already in Use\n\nIf the default port (8080) is already in use:\n\n```bash\nmcp-terminal start --port 9000\n```\n\n### Missing Command\n\nIf the `mcp-terminal` command is not found:\n\n1. Ensure `~/bin` is in your PATH:\n   ```bash\n   echo $PATH\n   ```\n\n2. If not, add it manually:\n   ```bash\n   export PATH=\"$HOME/bin:$PATH\"\n   ```\n\n3. For permanent addition, add to your shell configuration:\n   ```bash\n   echo 'export PATH=\"$HOME/bin:$PATH\"' >> ~/.bashrc\n   source ~/.bashrc\n   ```\n\n## Security Considerations\n\n- The MCP Terminal Server executes commands with the same permissions as the user who started it\n- It's recommended to run the server on a local network or behind a firewall\n- Consider using a reverse proxy with authentication for public-facing deployments\n\n## License\n\n[MIT License](LICENSE)\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## Support\n\nFor issues, questions, or feedback, please open an issue on the [GitHub repository](https://github.com/Yaswanth-ampolu/smithery-mcp-server/issues).",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "monitoring",
        "yaswanth",
        "terminal",
        "logging yaswanth",
        "provides terminal",
        "mcp server"
      ],
      "category": "monitoring-and-logging"
    },
    "Zwe1--error-monitor-frontend": {
      "owner": "Zwe1",
      "name": "error-monitor-frontend",
      "url": "https://github.com/Zwe1/error-monitor-frontend",
      "imageUrl": "/freedevtools/mcp/pfp/Zwe1.webp",
      "description": "构建一个错误监控系统，集中收集、存储和展示 B 端应用的远程错误信息，旨在提升错误处理效率和用户体验。该系统支持前端错误上报和展示处理后的错误信息。",
      "stars": 10,
      "forks": 4,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2024-11-25T05:56:28Z",
      "readme_content": "## 错误监控系统 (client)\n\n### 目标\n\n针对 B 端应用难以分析远程错误，设想构建一个错误收集监控系统，以便错误记录与收集并展示。\n\n### 架构\n\n整个系统包含前端系统，source-map [插件](https://github.com/Zwe1/error-monitor-webpack-plugin) 和 [后端系统](https://github.com/Zwe1/error-monitor-node-server)，及数据库服务。前端收集上报发送错误信息到服务端，服务端处理收集存储错误信息到数据库，并支持前端获取处理后的错误信息，在前端进行集中展示。\n\n\n\n### 项目表述\n\n该项目由 create-react-app 搭建，进行 override webpack config 操作来扩展打包配置。进行错误生产，作为整个系统的前端实验室。\n\n### 基本功能\n\n1. 错误上报\n2. 错误展示\n3. ci 系统 (hard)\n\n### 难点\n\n1. 分层拦截错误\n\n2. 如何在本地搭建一个生产环境？\n\n为了能够验证 production 模式打包后的 sourcemap。我们需要在本地搭建一个前端生产环境。这里考虑用 nginx 作为前端服务器，放置在 docker 容器当中，这种方式十分方便和高效，一台物理机就可以完成所有工作。\n\n````md\n1. 首先我们需要安装 [docker](https://www.docker.com/)\n\n2. 下来拉取 nginx 镜像。\n\n   docker pull nginx\n\n3. 创建 nginx 相关目录\n\nmkdir -p /data/nginx/{conf, conf.d,logs}\n\n这里我们在宿主机的 /data/nginx 目录放置 nginx 相关的文件，这个目录是可自定义的，但后续的目录映射一定要保证和这个目录相同。\n\n4. 新建 nginx 配置文件\n\n   touch /data/nginx/conf/nginx.conf\n   vim /data/nginx/conf/nginx.conf\n\n   ```conf\n   user nginx;\n   worker_processes  1;\n   error_log  /var/log/nginx/error.log warn;\n   pid        /var/run/nginx.pid;\n   events {\n       worker_connections  1024;\n   }\n\n   http {\n       include      /etc/nginx/mime.types;\n       default_type  application/octet-stream;\n       log_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" '\n\n                       '$status $body_bytes_sent \"$http_referer\" '\n\n                       '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n       access_log  /var/log/nginx/access.log  main;\n       sendfile        on;\n       #tcp_nopush    on;\n       keepalive_timeout  65;\n       #gzip  on;\n       include /etc/nginx/conf.d/*.conf;\n   }\n   ```\n\n   5. 新建 default.conf\n\n   touch /data/nginx/conf.d/default.conf\n   vim /data/nginx/conf.d/default.conf\n\n   ```conf\n\n    server {\n    listen      80;\n    server_name  localhost;\n    location / {\n        root  /usr/share/nginx/html;\n        index  index.html index.htm;\n        autoindex  on;\n    }\n\n    error_page  500 502 503 504  /50x.html;\n\n    location = /50x.html {\n\n        root  /usr/share/nginx/html;\n\n    }\n   ```\n\n   到这里，有关于 nginx 配置的处理就完成了，下来我们要做的就是进行 docker 容器与宿主机的目录映射\n\n   6. 将 nginx 内容挂载到宿主机\n\n   docker run -p 80:80 -d -v /Users/xxx/Documents/lab/error-monitor/react-repo/build:/usr/share/nginx/html -v /data/nginx/logs:/var/log/nginx -v /data/nginx/conf/nginx.conf:/etc/nginx/nginx.conf -v /data/nginx/conf.d:/etc/nginx/conf.d docker.io/nginx\n\n   这里可以看到我们映射了两个目录和两个配置文件，包括了前端 html 文件目录，log 目录以及两个 nginx 配置文件。这里我直接将我们前端项目的打包目录映射到了容器中的 html 目录中，这样会比较方便一些。\n\n   这里我们选择宿主机的 80 端口映射 nginx 容器的 80 端口，我们直接打开本机的浏览器访问 localhost ，就可以看到打包完后的前端项目运行起来了。如果 80 端口有其他用途 ，可以自行切换到其他端口。\n````\n\n\n\n\n\n2. source-map 解析\n\n使用 Mozilla source-map 解析 .map 文件生成源代码",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "zwe1",
        "logging",
        "monitoring",
        "logging zwe1",
        "error monitor",
        "zwe1 error"
      ],
      "category": "monitoring-and-logging"
    },
    "Zzzccs123--mcp-sentry": {
      "owner": "Zzzccs123",
      "name": "mcp-sentry",
      "url": "https://github.com/Zzzccs123/mcp-sentry",
      "imageUrl": "/freedevtools/mcp/pfp/Zzzccs123.webp",
      "description": "Connect to Sentry's error tracking service to retrieve and analyze error reports and gain insights into application issues with detailed information such as status and stack traces.",
      "stars": 1,
      "forks": 0,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-03-22T20:30:16Z",
      "readme_content": "# MCP Server Sentry - TypeScript Implementation\n\nThis is a Model Context Protocol (MCP) server implemented in TypeScript for connecting to the Sentry error tracking service. This server allows AI models to query and analyze error reports and events on Sentry.\n\n## Features\n\n1. `get_sentry_issue` Tool\n   * Retrieves and analyzes Sentry issues by ID or URL\n   * Input:\n     * `issue_id_or_url` (string): Sentry issue ID or URL to analyze\n   * Returns: Issue details including:\n     * Title\n     * Issue ID\n     * Status\n     * Level\n     * First seen timestamp\n     * Last seen timestamp\n     * Event count\n     * Complete stack trace\n\n2. `sentry-issue` Prompt Template\n   * Retrieves issue details from Sentry\n   * Input:\n     * `issue_id_or_url` (string): Sentry issue ID or URL\n   * Returns: Formatted issue details as conversation context\n\n## Installation\n\n```bash\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n```\n\n## Configuration\n\nThe server is configured using environment variables. Create a `.env` file in the project root directory:\n\n```\n# Required: Sentry authentication token\nSENTRY_AUTH_TOKEN=your_sentry_auth_token\n\n# Optional: Sentry organization name\nSENTRY_ORGANIZATION_SLUG=your_organization_slug\n\n# Optional: Sentry project name\nSENTRY_PROJECT_SLUG=your_project_slug\n\n# Optional: Sentry base url\nSENTRY_BASE_URL=https://sentry.com/api/0\n```\n\nAlternatively, you can set these environment variables at runtime.\n\n## Running\n\nRun the server via standard IO:\n\n```bash\nnode dist/index.js\n```\n\nDebug with MCP Inspector:\n\n```bash\nnpx @modelcontextprotocol/inspector node dist/index.js\n```\n\n## Environment Variables Description\n\n- `SENTRY_AUTH_TOKEN` (required): Your Sentry API access token\n- `SENTRY_PROJECT_SLUG` (optional): The slug of your Sentry project\n- `SENTRY_ORGANIZATION_SLUG` (optional): The slug of your Sentry organization\n\nThe latter two variables can be omitted if project and organization information are provided in the URL.\n\n## License\n\nThis project is licensed under the MIT License. ",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "sentry",
        "monitoring",
        "logging",
        "sentry connect",
        "connect sentry",
        "mcp sentry"
      ],
      "category": "monitoring-and-logging"
    },
    "abhinav7895--system-mcp": {
      "owner": "abhinav7895",
      "name": "system-mcp",
      "url": "https://github.com/abhinav7895/system-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/abhinav7895.webp",
      "description": "Provides real-time system monitoring capabilities for CPU, memory, disk, network, battery, and internet speed metrics. Enables querying of detailed system resource usage and internet performance for enhanced diagnostics and management.",
      "stars": 1,
      "forks": 1,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-05-10T06:30:43Z",
      "readme_content": "# System Resource Monitor MCP Server\n\nAn MCP server that provides Claude with real-time system monitoring capabilities, including CPU, memory, disk, network, battery, and internet speed metrics using `systeminformation` and multi-source speed tests.\n\n  \n\n## Tools\n\n- **get_cpu_usage**\n  - Retrieves the current CPU load as a percentage, including overall and per-core usage.\n  - **Inputs**: None\n  - **Output**: Text (e.g., `CPU Load: 12.34% (Cores: 10.50, 15.20, 8.90, 14.60%)`)\n\n- **get_memory_usage**\n  - Reports total, used, and free memory in GB, plus percentage used.\n  - **Inputs**: None\n  - **Output**: Text (e.g., `Memory: 65.43% used (7.82GB / 16.00GB)`)\n\n- **get_disk_space**\n  - Shows disk usage for the largest drive in GB and percentage.\n  - **Inputs**: None\n  - **Output**: Text (e.g., `Disk (/): 78.90% used (189.50GB / 250.00GB)`)\n\n- **get_network_usage**\n  - Returns real-time network RX/TX rates (KB/s) and total data since boot (MB).\n  - **Inputs**: None\n  - **Output**: Text (e.g., `Network (eth0): RX: 25.50KB/s, TX: 10.20KB/s (Total: RX 150.34MB, TX 75.89MB)`)\n\n- **get_battery_status**\n  - Provides battery charge percentage, charging status, and time remaining (if applicable).\n  - **Inputs**: None\n  - **Output**: Text (e.g., `Battery: 85% (charging), 120 min remaining` or `No battery detected`)\n\n- **get_internet_speed**\n  - Measures internet speed using multiple download sources (including a user-uploaded file) and upload tests, returning median speeds in Mbps.\n  - **Inputs**: None\n  - **Output**: Text (e.g., `Internet Speed: Download 45.67Mbps, Upload 8.45Mbps`)\n\n## Configuration\n\n### Step 1: Clone and Install\n\nClone this repository:\n\n```bash\ngit clone git@github.com:abhinav7895/system-mcp.git\n```\n\nNavigate to the directory and install dependencies:\n\n```bash\ncd system-resource-monitor && npm install\n```\n\n### Step 2: Build the Project\n\nCompile the TypeScript code:\n\n```bash\nnpm run build\n```\n\nThis generates the `dist/index.js` file, ready to run as an MCP server.\n\n### Step 3: Configure Claude Desktop\n\n1. Download Claude Desktop [here](https://claude.ai/download).\n2. Add this to your `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"system-resource-monitor\": {\n      \"command\": \"node\",\n      \"args\": [\"/absolute/path/to/dist/index.js\"]\n    }\n  }\n}\n```\n\nAccess the config file:\n\n```bash\nvim ~/Library/Application\\ Support/Claude/claude_desktop_config.json\n```\n\n*(Adjust the path to `dist/index.js` based on your project location.)*\n\n\n\n### Step 4: Testing\n\nEnsure Claude Desktop recognizes the tools by checking for the hammer icon:\n\n\n\nClick the hammer icon to see available tools:\n\n\n\nIf all six tools (`get_cpu_usage`, `get_memory_usage`, etc.) appear, the integration is active. You can now ask questions like:\n- \"What’s my CPU usage?\"\n- \"How fast is my internet?\"\n\n### Step 5: Advanced Customization\n\n- **Internet Speed Test**: Modify `testUrls` in `index.ts` to use different download sources or adjust `uploadSizeBytes` (default 80KB) for upload tests.\n- **Logging**: Console logs provide detailed test output; disable them in production by removing `console.log` statements.\n\n### Troubleshooting\n\n- **Tool Not Showing**: Verify the server is running (`node dist/index.js`) and the config path is correct.\n- **Internet Speed Errors**: Ensure network connectivity and test URLs are accessible. Check console logs for specific failures.\n- Refer to the [MCP troubleshooting guide](https://modelcontextprotocol.io/docs/tools/debugging)\n\n## License\n\nThis MCP server is licensed under the MIT License. You are free to use, modify, and distribute the software under the terms of the MIT License. See the `LICENSE` file for details.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "monitoring",
        "logging",
        "mcp",
        "monitoring capabilities",
        "monitoring logging",
        "logging abhinav7895"
      ],
      "category": "monitoring-and-logging"
    },
    "ahmad2x4--mcp-server-seq": {
      "owner": "ahmad2x4",
      "name": "mcp-server-seq",
      "url": "https://github.com/ahmad2x4/mcp-server-seq",
      "imageUrl": "/freedevtools/mcp/pfp/ahmad2x4.webp",
      "description": "Interact with Seq's logging and monitoring system via its API endpoints, providing access to various features for managing signals and events.",
      "stars": 7,
      "forks": 7,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-08-19T03:06:37Z",
      "readme_content": "# Seq MCP Server\n\nMCP Server for Seq's API endpoints for interacting with your logging and monitoring system. This server provides comprehensive access to Seq's API features through the Model Context Protocol.\n\n<a href=\"https://glama.ai/mcp/servers/yljb00fc2g\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/yljb00fc2g/badge\" alt=\"Seq Server MCP server\" /></a>\n\n## Features\n\n### Tools\n\n#### Signals Management\n- `get-signals` - Fetch signals with filtering options\n  - Filter by owner ID\n  - Filter shared/private signals\n  - Support for partial matches\n\n#### Event Management\n- `get-events` - Retrieve events with extensive filtering options\n  - Filter by signal IDs\n  - Custom filter expressions\n  - Configurable event count (max 100)\n  - Flexible time range options\n  - Date range filtering\n\n#### Alert Management\n- `get-alertstate` - Retrieve the current state of alerts\n\n### Resources\n\n#### Signals Listing\n- `signals` - List all shared signals with detailed information\n  - Signal ID\n  - Title\n  - Description\n  - Sharing status\n  - Owner information\n\n## Configuration\n\nThe server requires the following environment variables:\n\n- `SEQ_BASE_URL` (optional): Your Seq server URL (defaults to 'http://localhost:8080')\n- `SEQ_API_KEY` (required): Your Seq API key\n\n## Usage with Claude Desktop\n\nAdd to your `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"seq\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"mcp-seq\"],\n      \"env\": {\n        \"SEQ_BASE_URL\": \"your-seq-url\",\n        \"SEQ_API_KEY\": \"your-api-key\"\n      }\n    }\n  }\n}\n```\n\n## Development\n\nInstall dependencies:\n```bash\nnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n```bash\nnpm run dev\n```\n\nRun tests:\n```bash\nnpm run test-script\n```\n\n## Time Range Options\n\nThe `get-events` tool supports the following time range options:\n- `1m` - Last minute\n- `15m` - Last 15 minutes\n- `30m` - Last 30 minutes\n- `1h` - Last hour\n- `2h` - Last 2 hours\n- `6h` - Last 6 hours\n- `12h` - Last 12 hours\n- `1d` - Last day\n- `7d` - Last 7 days\n- `14d` - Last 14 days\n- `30d` - Last 30 days\n\n## Installation\n\nThis tool is still in development and we havn't pushed to the npm repository. You need to clone this repository on your local then build `npm run build`\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"seq\": {\n      \"command\":\"node\",\n      \"args\": [\"/Users/ahmadreza/source/ahmad2x4/mcp-server-seq/build/seq-server.js\"],\n      \"env\": {\n        \"SEQ_BASE_URL\": \"your-seq-url\",\n        \"SEQ_API_KEY\": \"your-api-key\"\n      }\n    }\n  }\n}\n```\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. The server implements proper error handling and logging for all operations. You can run the test script to verify functionality:\n\n```bash\nnpm run test-script\n```\n## Type Safety\n\nThe server implements comprehensive type safety using:\n- TypeScript for static type checking\n- Zod schema validation for runtime type checking\n- Proper error handling and response formatting\n=======\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "seq",
        "monitoring",
        "logging",
        "seq logging",
        "server seq",
        "logging ahmad2x4"
      ],
      "category": "monitoring-and-logging"
    },
    "ai-mcp-garage--agent_construct": {
      "owner": "ai-mcp-garage",
      "name": "agent_construct",
      "url": "https://github.com/ai-mcp-garage/agent_construct",
      "imageUrl": "/freedevtools/mcp/pfp/ai-mcp-garage.webp",
      "description": "Standardizes access to tools and data for AI applications, facilitating dynamic tool discovery and execution through a unified interface. It serves as a central hub for managing context and tool integration in AI models.",
      "stars": 13,
      "forks": 4,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-13T05:20:39Z",
      "readme_content": "# Agent Construct\n\n<p align=\"center\">\n  \n</p>\n\n> \"We can load anything, from clothing to equipment, weapons, training simulations, anything we need.\" - The Matrix (1999)\n\nAgent Construct is a Model Context Protocol (MCP) server implementation that standardizes how AI applications access tools and context. Just as the Construct in The Matrix provided operators with instant access to any equipment they needed, Agent Construct provides a standardized interface for AI models to access tools and data through the MCP specification.\n\nBuilt on the [Model Context Protocol](https://modelcontextprotocol.io/introduction) specification, it acts as a central hub that manages tool discovery, execution, and context management for AI applications. It provides a robust and scalable way to expose capabilities to AI models through a standardized protocol. It also provides a simplified configuration and tool structure to make adding new capabilities a breeze! An example tool for searching the web with Gemini is included.\n\n## Core Features\n\n### MCP Protocol Implementation\n- **Full MCP Compliance**: Complete implementation of the Model Context Protocol specification\n- **Tool Discovery**: Dynamic tool registration and discovery mechanism\n- **Standardized Communication**: Implements MCP's communication patterns for tool interaction\n\n### Server Architecture\n- **FastAPI Backend**: High-performance asynchronous server implementation\n- **Event Streaming**: Real-time updates via Server-Sent Events (SSE)\n- **Modular Design**: Clean separation between core protocol handling and tool implementations\n- **Handler System**: Extensible request handler architecture for different MCP operations\n- **Tool-Based Rate Limiting**: Let the server handle your configurable per-tool rate limiting.\n\n### Development Features\n- **Tool Decorator System**: Simple way to expose new tools via MCP\n- **Logging & Monitoring**: Comprehensive logging system for debugging and monitoring\n- **Configuration Management**: Environment-based configuration with secure defaults\n- **Testing Framework**: Extensive test suite for protocol compliance\n- **Agent Framework Friendly**: Included implementation examples for custom clients or frameworks like smolagents.\n\n## Getting Started\n\n### Prerequisites\n\n- Python 3.8 or higher\n- pip package manager\n\n### Installation\n\n1. Clone the repository:\n   ```bash\n   git clone https://github.com/yourusername/agent-construct.git\n   cd agent-construct\n   ```\n\n2. Install dependencies:\n   ```bash\n   pip install -r requirements.txt\n   ```\n\n3. Set up environment variables:\n   Create a `.env` file in the root directory with the following variables:\n   ```\n   # Server Configuration\n   SERVER_HOST=localhost\n   SERVER_PORT=8000\n   \n   # MCP Protocol Settings\n   MCP_VERSION=1.0\n   TOOL_DISCOVERY_ENABLED=true\n   \n   # Security Settings\n   ENABLE_AUTH=false  # Enable for production\n   ```\n\n4. Run the server:\n   ```bash\n   python -m mcp_server\n   ```\n\n## Core Architecture\n\n```\nmcp_server/\n├── core/               # Core MCP protocol implementation\n│   ├── server.py      # Main server implementation\n│   ├── protocol.py    # MCP protocol handlers\n│   └── context.py     # Context management\n├── handlers/          # MCP operation handlers\n│   ├── discovery.py   # Tool discovery\n│   ├── execution.py   # Tool execution\n│   └── context.py     # Context operations\n├── utils/            # Utility functions\n│   ├── logging.py    # Logging configuration\n│   ├── security.py   # Security utilities\n│   └── config.py     # Configuration management\n└── __main__.py       # Server entry point\n```\n\n## MCP Protocol Features\n\n### Tool Discovery\n- Dynamic tool registration system\n- Tool capability advertisement\n- Version management\n- Tool metadata and documentation\n\n### Context Management\n- Efficient context storage and retrieval\n- Context scoping and isolation\n- Real-time context updates\n- Context persistence options\n\n### Communication Patterns\n- Synchronous request/response\n- Server-sent events for updates\n- Streaming responses\n- Error handling and recovery\n\n## Future Enhancements\n\n### Protocol Extensions\n- [ ] Advanced context management features\n- [ ] Custom protocol extensions\n- [ ] Plugin system for protocol handlers\n\n### Security\n- [ ] Authentication and authorization\n- [ ] Tool access control\n- [-] Rate limiting and quota management\n- [ ] Audit logging\n- [ ] End-to-end encryption\n\n### Performance\n- [ ] Tool execution optimization\n- [ ] Context caching\n- [ ] Load balancing\n- [ ] Request queuing\n- [ ] Resource management\n\n### Development\n- [ ] Interactive protocol explorer\n- [ ] Tool development SDK\n- [ ] Protocol compliance testing tools\n- [ ] Performance monitoring dashboard\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## Acknowledgements\n\n- [Model Context Protocol](https://modelcontextprotocol.io/) for the protocol specification\n- FastAPI for the excellent web framework\n- The open-source community for various tools and libraries used in this project",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ai",
        "tools",
        "tool",
        "garage agent_construct",
        "logging ai",
        "tool discovery"
      ],
      "category": "monitoring-and-logging"
    },
    "amitdeshmukh--stdout-mcp-server": {
      "owner": "amitdeshmukh",
      "name": "stdout-mcp-server",
      "url": "https://github.com/amitdeshmukh/stdout-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/amitdeshmukh.webp",
      "description": "Captures and manages stdout logs from multiple processes, providing real-time monitoring and a standardized interface for querying, filtering, and analyzing logs. Facilitates debugging by enabling easy log retrieval through named pipes.",
      "stars": 6,
      "forks": 5,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-08-21T17:17:55Z",
      "readme_content": "# stdout-mcp-server\n\nA Model Context Protocol (MCP) server that captures and manages stdout logs through a named pipe system. This server is particularly useful for:\n- Capturing logs from multiple processes or applications and making them available for debugging in Cursor IDE.\n- Monitoring application output in real-time and providing a MCP interface to query, filter, and analyze logs\n\n## How It Works\n\n1. The server creates a named pipe at a specific location (`/tmp/stdout_pipe` on Unix/MacOS or `\\\\.\\pipe\\stdout_pipe` on Windows)\n\n2. Any application can write logs to this pipe using standard output redirection. For example:\n```bash\nyour_application | tee /tmp/stdout_pipe # or\nyour_application > /tmp/stdout_pipe\n```\n3. The server monitors the pipe, captures all incoming logs, and maintains a history of the last 100 entries\n\n4. Through MCP tools, you can query, filter, and analyze these logs\n\n## System Requirements\n\nBefore installing, please ensure you have:\n\n* Node.js v18 or newer\n\n## Installation Options\n\n### Option 1: Installation in Cursor\n\n1. Open Cursor and navigate to `Cursor > Settings > MCP Servers`\n2. Click on \"Add new MCP Server\"\n3. Update your MCP settings file with the following configuration:\n\n```sh\nname: stdout-mcp-server\ntype: command\ncommand: npx stdout-mcp-server\n```\n\n### Option 2: Installation in other MCP clients\n\n## Installation in other MCP clients\nFor macOS/Linux:\n```json\n{\n  \"mcpServers\": {\n    \"stdio-mcp-server\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"stdio-mcp-server\"\n      ]\n    }\n  }\n}\n```\n\nFor Windows:\n```json\n{\n  \"mcpServers\": {\n    \"mcp-installer\": {\n      \"command\": \"cmd.exe\",\n      \"args\": [\"/c\", \"npx\", \"stdio-mcp-server\"]\n    }\n  }\n}\n```\n\n## Usage Examples\n\n### Redirecting Application Logs\n\nTo send your application's output to the pipe:\n\n```bash\n# Unix/MacOS\nyour_application > /tmp/stdout_pipe\n\n# Windows (PowerShell)\nyour_application > \\\\.\\pipe\\stdout_pipe\n```\n\n### Monitoring Multiple Applications\n\nYou can redirect logs from multiple sources:\n\n```bash\n# Application 1\napp1 > /tmp/stdout_pipe &\n\n# Application 2\napp2 > /tmp/stdout_pipe &\n```\n\n### Querying Logs\n\nYour AI will use the `get-logs` tool in your MCP client to retrieve and filter logs:\n\n```typescript\n// Get last 50 logs\nget-logs()\n\n// Get last 100 logs containing \"error\"\nget-logs({ lines: 100, filter: \"error\" })\n\n// Get logs since a specific timestamp\nget-logs({ since: 1648675200000 }) // Unix timestamp in milliseconds\n```\n\n## Features\n\n- Named pipe creation and monitoring\n- Real-time log capture and storage\n- Log filtering and retrieval through MCP tools\n- Configurable log history (default: 100 entries)\n- Cross-platform support (Windows and Unix-based systems)\n\n## Named Pipe Locations\n\n- Windows: `\\\\.\\pipe\\stdout_pipe`\n- Unix/MacOS: `/tmp/stdout_pipe`\n\n## Available Tools\n\n### get-logs\n\nRetrieve logs from the named pipe with optional filtering:\n\nParameters:\n- `lines` (optional, default: 50): Number of log lines to return\n- `filter` (optional): Text to filter logs by\n- `since` (optional): Timestamp to get logs after\n\nExample responses:\n```typescript\n// Response format\n{\n  content: [{\n    type: \"text\",\n    text: \"[2024-03-20T10:15:30.123Z] Application started\\n[2024-03-20T10:15:31.456Z] Connected to database\"\n  }]\n}\n```\n\n## License\n\nMIT License\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "stdout",
        "logging",
        "logs",
        "stdout logs",
        "stdout mcp",
        "manages stdout"
      ],
      "category": "monitoring-and-logging"
    },
    "awslabs--Log-Analyzer-with-MCP": {
      "owner": "awslabs",
      "name": "Log-Analyzer-with-MCP",
      "url": "https://github.com/awslabs/Log-Analyzer-with-MCP",
      "imageUrl": "/freedevtools/mcp/pfp/awslabs.webp",
      "description": "Access AWS CloudWatch Logs for efficient analysis, searching, and correlation. Provides functionalities for browsing log groups, executing queries, generating summaries, and identifying error patterns across AWS services.",
      "stars": 129,
      "forks": 19,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-09-28T03:42:30Z",
      "readme_content": "# Log Analyzer with MCP\n\nA [Model Context Protocol (MCP)](https://modelcontextprotocol.io) server that provides AI assistants access to AWS CloudWatch Logs for analysis, searching, and correlation.\n\n## 🏗️ Architecture\n\n\n## 🔌 Model Context Protocol (MCP)\n\nAs outlined by Anthropic:\n> MCP is an open protocol that standardizes how applications provide context to LLMs. Think of MCP like a USB-C port for AI applications. Just as USB-C provides a standardized way to connect your devices to various peripherals and accessories, MCP provides a standardized way to connect AI models to different data sources and tools.\n\nThis repository is an example client and server that allows an AI assistant like Claude to interact with CloudWatch logs in an AWS account. To learn more about MCP, read through the [introduction](https://modelcontextprotocol.io/introduction). \n\n## ✨ Features\n\n- Browse and search CloudWatch Log Groups\n- Search logs using CloudWatch Logs Insights query syntax\n- Generate log summaries and identify error patterns\n- Correlate logs across multiple AWS services\n- AI-optimized tools for assistants like Claude\n\n[Detailed feature list](./docs/features.md)\n\n## 🚀 Installation\n\n### Prerequisites\n\n- The [uv](https://github.com/astral-sh/uv) Python package and project manager\n- An AWS account with CloudWatch Logs\n- Configured [AWS credentials](./docs/aws-config.md)\n\n\n### Setup\n\n```bash\n# Clone the repository\ngit clone https://github.com/awslabs/Log-Analyzer-with-MCP.git\ncd Log-Analyzer-with-MCP\n\n# Create a virtual environment and install dependencies\nuv sync\nsource .venv/bin/activate  # On Windows, use `.venv\\Scripts\\activate`\n```\n\n## 🚦 Quick Start\n\n1. Make sure to have configured your AWS credentials as [described here](./docs/aws-config.md)\n\n2. Update your `claude_desktop_config.json` file with the proper configuration outlined in the [AI integration guide](./docs/ai-integration.md)\n\n3. Open Claude for Desktop and start chatting!\n\nFor more examples and advanced usage, see the [detailed usage guide](./docs/usage.md).\n\n## 🤖 AI Integration\n\nThis project can be easily integrated with AI assistants like Claude for Desktop. See the [AI integration guide](./docs/ai-integration.md) for details.\n\n## 📚 Documentation\n\n- [Detailed Features](./docs/features.md)\n- [Usage Guide](./docs/usage.md)\n- [AWS Configuration](./docs/aws-config.md)\n- [Architecture Details](./docs/architecture.md)\n- [AI Integration](./docs/ai-integration.md)\n- [Troubleshooting](./docs/troubleshooting.md)\n\n## 🔒 Security\n\nSee [CONTRIBUTING](CONTRIBUTING.md#security-issue-notifications) for more information.\n\n## 📄 License\n\nThis project is licensed under the Apache-2.0 License.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "awslabs",
        "cloudwatch",
        "aws",
        "logging awslabs",
        "cloudwatch logs",
        "aws cloudwatch"
      ],
      "category": "monitoring-and-logging"
    },
    "bright8192--esxi-mcp-server": {
      "owner": "bright8192",
      "name": "esxi-mcp-server",
      "url": "https://github.com/bright8192/esxi-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/bright8192.webp",
      "description": "Manage VMware ESXi and vCenter environments through a REST API interface, allowing for the creation, cloning, deletion, and monitoring of virtual machines. Supports real-time performance insights and secure operations through API key authentication and SSL/TLS connections.",
      "stars": 40,
      "forks": 20,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-03T08:50:19Z",
      "readme_content": "# ESXi MCP Server\n\nA VMware ESXi/vCenter management server based on MCP (Model Control Protocol), providing simple REST API interfaces for virtual machine management.\n\n## Features\n\n- Support for ESXi and vCenter Server connections\n- Real-time communication based on SSE (Server-Sent Events)\n- RESTful API interface with JSON-RPC support\n- API key authentication\n- Complete virtual machine lifecycle management\n- Real-time performance monitoring\n- SSL/TLS secure connection support\n- Flexible configuration options (YAML/JSON/Environment Variables)\n\n## Core Functions\n\n- Virtual Machine Management\n  - Create VM\n  - Clone VM\n  - Delete VM\n  - Power On/Off operations\n  - List all VMs\n- Performance Monitoring\n  - CPU usage\n  - Memory usage\n  - Storage usage\n  - Network traffic statistics\n\n## Requirements\n\n- Python 3.7+\n- pyVmomi\n- PyYAML\n- uvicorn\n- mcp-core (Machine Control Protocol core library)\n\n## Quick Start\n\n1. Install dependencies:\n\n```bash\npip install pyvmomi pyyaml uvicorn mcp-core\n```\n\n2. Create configuration file `config.yaml`:\n\n```yaml\nvcenter_host: \"your-vcenter-ip\"\nvcenter_user: \"administrator@vsphere.local\"\nvcenter_password: \"your-password\"\ndatacenter: \"your-datacenter\"        # Optional\ncluster: \"your-cluster\"              # Optional\ndatastore: \"your-datastore\"          # Optional\nnetwork: \"VM Network\"                # Optional\ninsecure: true                       # Skip SSL certificate verification\napi_key: \"your-api-key\"             # API access key\nlog_file: \"./logs/vmware_mcp.log\"   # Log file path\nlog_level: \"INFO\"                    # Log level\n```\n\n3. Run the server:\n\n```bash\npython server.py -c config.yaml\n```\n\n## API Interface\n\n### Authentication\n\nAll privileged operations require authentication first:\n\n```http\nPOST /sse/messages\nAuthorization: Bearer your-api-key\n```\n\n### Main Tool Interfaces\n\n1. Create VM\n```json\n{\n    \"name\": \"vm-name\",\n    \"cpu\": 2,\n    \"memory\": 4096,\n    \"datastore\": \"datastore-name\",\n    \"network\": \"network-name\"\n}\n```\n\n2. Clone VM\n```json\n{\n    \"template_name\": \"source-vm\",\n    \"new_name\": \"new-vm-name\"\n}\n```\n\n3. Delete VM\n```json\n{\n    \"name\": \"vm-name\"\n}\n```\n\n4. Power Operations\n```json\n{\n    \"name\": \"vm-name\"\n}\n```\n\n### Resource Monitoring Interface\n\nGet VM performance data:\n```http\nGET vmstats://{vm_name}\n```\n\n## Configuration\n\n| Parameter | Description | Required | Default |\n|-----------|-------------|----------|---------|\n| vcenter_host | vCenter/ESXi server address | Yes | - |\n| vcenter_user | Login username | Yes | - |\n| vcenter_password | Login password | Yes | - |\n| datacenter | Datacenter name | No | Auto-select first |\n| cluster | Cluster name | No | Auto-select first |\n| datastore | Storage name | No | Auto-select largest available |\n| network | Network name | No | VM Network |\n| insecure | Skip SSL verification | No | false |\n| api_key | API access key | No | - |\n| log_file | Log file path | No | Console output |\n| log_level | Log level | No | INFO |\n\n## Environment Variables\n\nAll configuration items support environment variable settings, following these naming rules:\n- VCENTER_HOST\n- VCENTER_USER\n- VCENTER_PASSWORD\n- VCENTER_DATACENTER\n- VCENTER_CLUSTER\n- VCENTER_DATASTORE\n- VCENTER_NETWORK\n- VCENTER_INSECURE\n- MCP_API_KEY\n- MCP_LOG_FILE\n- MCP_LOG_LEVEL\n\n## Security Recommendations\n\n1. Production Environment:\n   - Use valid SSL certificates\n   - Enable API key authentication\n   - Set appropriate log levels\n   - Restrict API access scope\n\n2. Testing Environment:\n   - Set insecure: true to skip SSL verification\n   - Use more detailed log level (DEBUG)\n\n## License\n\nMIT License\n\n## Contributing\n\nIssues and Pull Requests are welcome!\n\n## Changelog\n\n### v0.0.1\n- Initial release\n- Basic VM management functionality\n- SSE communication support\n- API key authentication\n- Performance monitoring\n\n## Author\n\nBright8192\n\n## Acknowledgments\n\n- VMware pyvmomi team\n- MCP Protocol development team\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "esxi",
        "vmware",
        "vcenter",
        "esxi vcenter",
        "vmware esxi",
        "esxi mcp"
      ],
      "category": "monitoring-and-logging"
    },
    "carterlasalle--system_information_mcp": {
      "owner": "carterlasalle",
      "name": "system_information_mcp",
      "url": "https://github.com/carterlasalle/system_information_mcp",
      "imageUrl": "/freedevtools/mcp/pfp/carterlasalle.webp",
      "description": "Provides detailed information about the development environment, including system configuration, installed tools, and running processes to enhance context-aware assistance for the Cursor code editor.",
      "stars": 5,
      "forks": 2,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-05T04:50:02Z",
      "readme_content": "# DevEnvInfoServer - Cursor MCP Server for Development Environment Information\n\n[![GitHub Repository](https://img.shields.io/badge/GitHub-Repository-blue?logo=github)](https://github.com/carterlasalle/system_information_mcp)\n[![smithery badge](https://smithery.ai/badge/@carterlasalle/system_information_mcp)](https://smithery.ai/server/@carterlasalle/system_information_mcp)\n\nThis project implements a Cursor Model Context Protocol (MCP) server that provides detailed information about your development environment to the Cursor code editor.  By leveraging this server, Cursor's intelligent agent can gain a deeper understanding of your system's configuration, installed tools, and running processes, enabling more context-aware and helpful assistance.\n\n## Features\n\nThis MCP server provides the following information categories about your development environment:\n\n* **System Information:**\n    * Operating System Version and Platform Details\n    * Hardware Details (Processor, Machine, System Architecture)\n    * Python Versions and Locations\n    * Installed Package Managers (brew, npm, pip, yarn, uv, conda) and their versions\n    * Virtual Environment Information (detected environments and active environment)\n    * System Locale and Timezone\n    * Top 20 Environment Variables\n    * Available Shells (bash, zsh, fish, sh, powershell, cmd.exe)\n    * Simplified Firewall and Network Configurations (OS-dependent)\n* **Development Environment Details:**\n    * Installed Compilers and Interpreters (gcc, clang, javac, node, ruby, perl, php, ghc, rustc, go)\n    * Jupyter Kernels and Running Containers (Docker, Podman)\n    * Virtual Machines (Hyper-V, VMware, VirtualBox)\n    * GPU and CUDA Information (NVIDIA GPUs and CUDA Compiler Version)\n    * Top Running Development Processes and Services\n* **Python Specific Information:**\n    * Installed Python Packages (pip, conda, poetry, pyenv)\n    * Python Site-Packages Locations\n    * Active Python Environments\n* **Package Manager Details:**\n    * Homebrew Installed Packages (macOS and Linux)\n    * Global Packages (npm, yarn, Rust toolchain, Go environment)\n* **Configuration and Dotfiles:**\n    * Shell Configuration Files (.bashrc, .zshrc, .profile, .bash_profile, .config/fish/config.fish)\n    * Git, NPM, and Editor Configurations (VSCode, JetBrains, Neovim)\n    * Shell Aliases, Functions, and Custom Scripts (from shell config files)\n* **Installed Applications:**\n    * Installed IDEs and Extensions (VSCode, JetBrains, Vim, Emacs)\n    * System Installed Applications (Simplified List)\n* **System and Hardware Performance (Simplified Metrics):**\n    * CPU Load Average\n    * Battery and Power Management Configurations\n    * Temperature Sensors and Fan Speeds\n* **Network and Security (Simplified):**\n    * Running Network Services and Open Ports\n    * VPN and Proxy Settings\n    * SSH Keys and Active Connections\n    * Simplified Firewall Logs and Rules\n* **Containerization and Virtualization:**\n    * WSL (Windows Subsystem for Linux)\n    * Docker and Kubernetes (kubectl)\n    * Vagrant\n    * Virtual Machines (Hyper-V, VMware, VirtualBox)\n* **Development Tools and Languages:**\n    * Installed Development Languages (Rust, Node.js, Perl, Ruby, PHP, Haskell)\n    * Version Management Tools (nvm, rbenv, rustup, pyenv)\n* **Debugging and Performance Monitoring:**\n    * Load Averages, Memory Usage, IO Bottlenecks, GPU Utilization\n    * Available Debugger Tools (lldb, gdb, strace, dtrace)\n* **Version Control and CI/CD:**\n    * Git Configuration and Remote Origins\n    * CI/CD Pipeline Configuration Files (Common types)\n* **Cloud and Remote Development:**\n    * SSH Configurations and Active Remote Sessions\n    * Cloud SDKs (AWS, GCP, Azure, DigitalOcean)\n    * Remote Code Execution Environments (GitHub Codespaces, Gitpod)\n* **Code Execution and Debugging:**\n    * Active Debugger Sessions (Basic check)\n    * Installed Debugging Tools (lldb, gdb, xdebug, pdb)\n* **Build Systems and Dependency Management:**\n    * Installed Build Tools (Make, CMake, Bazel, Ninja)\n    * Detected Dependency Files (requirements.txt, package.json, Cargo.toml, etc.)\n    * Installed Compilers (gcc, clang, javac)\n* **Infrastructure and DevOps Tools:**\n    * Local Kubernetes Configuration\n    * DevOps Tools (Terraform, Pulumi)\n    * Local Databases and Running Services (Simplified check for common DB services)\n* **Testing and Quality Assurance:**\n    * Installed Testing Frameworks (pytest, Jest, Mocha)\n    * Code Linters and Formatters (flake8, pylint, eslint, prettier)\n* **Machine Learning and AI Development:**\n    * GPU and CUDA Information\n    * PyTorch and TensorFlow Status (Installation and GPU availability)\n* **Embedded Development / IoT:**\n    * Installed Embedded SDKs (Arduino, ESP-IDF, Raspberry Pi Tools)\n    * Connected Devices and Serial Ports (Simplified list of serial ports)\n* **Productivity and Workflow Enhancements:**\n    * Shell Aliases, Functions, and Custom Scripts\n    * Shell History Analysis (Basic - last 20 lines of history)\n    * Background Automation and Task Scheduling (Simplified check for cron/Scheduled Tasks)\n\n## How it Works\n\nThis server is built using the Model Context Protocol (MCP) and operates as follows:\n\n1.  **MCP Protocol:** It implements the MCP server protocol, allowing Cursor to communicate with it to discover and utilize its capabilities.\n2.  **Stdio Transport:** The server uses the `stdio` transport, meaning it communicates with Cursor through standard input and output streams.\n3.  **Information Gathering:** When Cursor's Agent requests information, this server executes various system commands (using `subprocess`) and Python libraries (`platform`, `os`, `sys`, `psutil`, `pyserial`, etc.) to collect data about your development environment.\n4.  **Tool-Based Access:** Each information category is exposed as a tool within the MCP server. Cursor's Agent can then call these tools to retrieve specific pieces of information.\n5.  **Markdown Output (Optional):** The server can optionally generate a Markdown file (`development_environment_info.md`) containing all the collected information for easier review and debugging.\n6.  **Cursor Integration:** Cursor, acting as an MCP client, can connect to this server and automatically utilize the provided tools to enhance its understanding of your development context.\n\n## Installation\n\nTo install and run this MCP server, follow these steps:\n\n1.  **Clone the Repository:**\n    ```bash\n    git clone https://github.com/carterlasalle/system_information_mcp.git\n    cd system_information_mcp\n    ```\n\n2.  **Create a Python Virtual Environment (Recommended):**\n    ```bash\n    python -m venv venv\n    ```\n\n3.  **Activate the Virtual Environment:**\n    *   **On Linux/macOS:**\n        ```bash\n        source venv/bin/activate\n        ```\n    *   **On Windows:**\n        ```bash\n        venv\\Scripts\\activate\n        ```\n\n4.  **Install Dependencies:**\n    ```bash\n    pip install -r requirements.txt\n    ```\n\n## Configuration for Cursor\n\nTo connect this MCP server to Cursor, you need to configure it within Cursor's settings:\n\n1.  **Open Cursor Settings:** Go to `Cursor Settings` > `Features` > `MCP`.\n2.  **Add New MCP Server:** Click on the `+ Add New MCP Server` button.\n3.  **Configure Server:** Fill in the form with the following details:\n    *   **Type:** `stdio`\n    *   **Name:** `DevEnvInfoServer` (or any name you prefer)\n    *   **Command:**  Enter the command to run the server. If you are in the `system_information_mcp` directory and have activated the virtual environment, you can use:\n        ```bash\n        python claudemcp.py\n        ```\n        **Note:** If `python` is not in your system's PATH or you are using a specific Python executable, you may need to provide the full path to your Python interpreter followed by the path to `claudemcp.py`. For example:\n        ```bash\n        /path/to/your/python venv/bin/python claudemcp.py\n        ```\n4.  **Add Server:** Click the \"Add Server\" button.\n5.  **Refresh Tool List (Optional):** You might need to manually press the refresh button in the top right corner of the MCP server list in Cursor to populate the tool list.\n\nThe server `DevEnvInfoServer` should now appear in your list of MCP servers in Cursor, and its tools should be available to the Agent in Composer.\n\n## Usage in Cursor\n\nOnce configured, Cursor's Agent will automatically leverage the tools provided by `DevEnvInfoServer` when it deems them relevant to your requests.\n\n*   **Automatic Tool Usage:**  When you interact with Cursor's Agent in Composer, it will intelligently decide if information about your development environment is needed to answer your questions or fulfill your requests. If so, it will automatically use the tools provided by this server in the background.\n*   **Intentional Tool Prompting:** You can also explicitly instruct the Agent to use these tools by referring to them by name or description in your prompts. For example, you could ask:\n    *   \"What Python packages are installed in my current environment?\"\n    *   \"List the available shells on my system using the DevEnvInfoServer tools.\"\n*   **Tool Approval:** By default, Cursor will ask for your approval before executing any MCP tool. You can review the tool call arguments before approving.\n*   **YOLO Mode (Optional):** If you prefer automatic tool execution without approval prompts, you can enable \"YOLO Mode\" in Cursor's MCP settings. Use this mode with caution, as it allows automatic execution of MCP tools.\n\nCursor will display the responses from the `DevEnvInfoServer` tools directly in the chat, providing you with the requested development environment information.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "system_information_mcp",
        "monitoring",
        "logging",
        "carterlasalle system_information_mcp",
        "system_information_mcp provides",
        "logging carterlasalle"
      ],
      "category": "monitoring-and-logging"
    },
    "chikingsley--browser-tools-mcp": {
      "owner": "chikingsley",
      "name": "browser-tools-mcp",
      "url": "https://github.com/chikingsley/browser-tools-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/null.webp",
      "description": "Monitor and interact with browser data, capturing console logs, network activity, and screenshots to facilitate AI applications. Provides a secure, local solution for data privacy while enhancing AI tools with browser insights.",
      "stars": 0,
      "forks": 0,
      "license": "Unknown",
      "language": "Unknown",
      "updated_at": "",
      "readme_content": "",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "monitoring",
        "logging",
        "browser",
        "browser insights",
        "browser tools",
        "chikingsley browser"
      ],
      "category": "monitoring-and-logging"
    },
    "codyde--mcp-sentry-ts": {
      "owner": "codyde",
      "name": "mcp-sentry-ts",
      "url": "https://github.com/codyde/mcp-sentry-ts",
      "imageUrl": "/freedevtools/mcp/pfp/codyde.webp",
      "description": "Interact with Sentry's API to retrieve and analyze error data, manage projects, and monitor application performance.",
      "stars": 20,
      "forks": 5,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-09-03T09:13:52Z",
      "readme_content": "# Sentry MCP Server\n\nA Model Context Protocol (MCP) server for interacting with Sentry. This MCP server provides tools to interact with the Sentry API, allowing AI assistants to retrieve and analyze error data, manage projects, and monitor application performance.\n\n## Requirements\n\n- Node.js (v14 or higher)\n- npm or yarn\n- Sentry account with API access\n- Sentry authentication token with appropriate permissions\n\n## Setup\n\n1. Install dependencies:\n   ```\n   npm install\n   ```\n\n## Using this within an IDE \n\nThis MCP has been verified to work against Codeium Windsurf.\n\nCursor is currently having issues with its MCP implementation; and this tool is not yet fully functional.\n\n## Using with Claude\n\nTo use this MCP server with Claude, add the following configuration to your Claude settings:\n\n```json\n{\n    \"mcpServers\": {\n        \"sentry\": {\n            \"command\": \"npx\",\n            \"args\": [\"ts-node\", \"/Users/<your-user-directory>/mcp-sentry-ts/index.ts\"],\n            \"env\": {\n                \"SENTRY_AUTH\": \"<YOUR_AUTH_TOKEN>\"\n            }\n        }\n    }\n}\n```\n\n* Update with your directory path in the `args` field.\n* Replace `<YOUR_AUTH_TOKEN>` with your Sentry authentication token.\n\n## Available Tools\n\n### list_projects\n\nLists all accessible Sentry projects for a given organization.\n\n**Parameters:**\n- `organization_slug` (string, required): The slug of the organization to list projects from\n- `view` (string, optional): View type, either \"summary\" or \"detailed\" (default: \"detailed\")\n- `format` (string, optional): Output format, either \"plain\" or \"markdown\" (default: \"markdown\")\n\n### resolve_short_id\n\nRetrieves details about an issue using its short ID.\n\n**Parameters:**\n- `organization_slug` (string, required): The slug of the organization the issue belongs to\n- `short_id` (string, required): The short ID of the issue to resolve (e.g., PROJECT-123)\n- `format` (string, optional): Output format, either \"plain\" or \"markdown\" (default: \"markdown\")\n\n### get_sentry_event\n\nRetrieves and analyzes a specific Sentry event from an issue.\n\n**Parameters:**\n- `issue_id_or_url` (string, required): Either a full Sentry issue URL or just the numeric issue ID\n- `event_id` (string, required): The specific event ID to retrieve\n- `view` (string, optional): View type, either \"summary\" or \"detailed\" (default: \"detailed\")\n- `format` (string, optional): Output format, either \"plain\" or \"markdown\" (default: \"markdown\")\n\n### list_error_events_in_project\n\nLists error events from a specific Sentry project.\n\n**Parameters:**\n- `organization_slug` (string, required): The slug of the organization the project belongs to\n- `project_slug` (string, required): The slug of the project to list events from\n- `view` (string, optional): View type, either \"summary\" or \"detailed\" (default: \"detailed\")\n- `format` (string, optional): Output format, either \"plain\" or \"markdown\" (default: \"markdown\")\n\n### create_project\n\nCreates a new project in Sentry and retrieves its client keys.\n\n**Parameters:**\n- `organization_slug` (string, required): The slug of the organization to create the project in\n- `team_slug` (string, required): The slug of the team to assign the project to\n- `name` (string, required): The name of the new project\n- `platform` (string, optional): The platform for the new project\n- `view` (string, optional): View type, either \"summary\" or \"detailed\" (default: \"detailed\")\n- `format` (string, optional): Output format, either \"plain\" or \"markdown\" (default: \"markdown\")\n\n### list_project_issues\n\nLists issues from a specific Sentry project.\n\n**Parameters:**\n- `organization_slug` (string, required): The slug of the organization the project belongs to\n- `project_slug` (string, required): The slug of the project to list issues from\n- `view` (string, optional): View type, either \"summary\" or \"detailed\" (default: \"detailed\")\n- `format` (string, optional): Output format, either \"plain\" or \"markdown\" (default: \"markdown\")\n\n### list_issue_events\n\nLists events for a specific Sentry issue.\n\n**Parameters:**\n- `organization_slug` (string, required): The slug of the organization the issue belongs to\n- `issue_id` (string, required): The ID of the issue to list events from\n- `view` (string, optional): View type, either \"summary\" or \"detailed\" (default: \"detailed\")\n- `format` (string, optional): Output format, either \"plain\" or \"markdown\" (default: \"markdown\")\n\n### get_sentry_issue\n\nRetrieves and analyzes a Sentry issue.\n\n**Parameters:**\n- `issue_id_or_url` (string, required): Either a full Sentry issue URL or just the numeric issue ID\n- `view` (string, optional): View type, either \"summary\" or \"detailed\" (default: \"detailed\")\n- `format` (string, optional): Output format, either \"plain\" or \"markdown\" (default: \"markdown\")\n\n### list_organization_replays\n\nLists replays from a specific Sentry organization.\n\n**Parameters:**\n- `organization_slug` (string, required): The slug of the organization to list replays from\n- `project_ids` (string[], optional): List of project IDs to filter replays by\n- `environment` (string, optional): Environment to filter replays by\n- `stats_period` (string, optional): Time period for stats (e.g., \"24h\", \"7d\")\n- `start` (string, optional): Start date for filtering replays\n- `end` (string, optional): End date for filtering replays\n- `sort` (string, optional): Field to sort replays by\n- `query` (string, optional): Search query to filter replays\n- `per_page` (number, optional): Number of replays per page\n- `cursor` (string, optional): Cursor for pagination\n- `view` (string, optional): View type, either \"summary\" or \"detailed\" (default: \"detailed\")\n- `format` (string, optional): Output format, either \"plain\" or \"markdown\" (default: \"markdown\")\n\n## Running the Server\n\n```\nnpx ts-node index.ts\n```\n\n## Authentication\n\nThis tool requires a Sentry authentication token with appropriate permissions to access the Sentry API. You can generate a token in your Sentry account settings under \"API Keys\".\n\n## Error Handling\n\nThe server includes comprehensive error handling for:\n- Missing authentication token\n- API request failures\n- Invalid parameters\n- Network errors\n\nAll errors are logged to the console for debugging.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "sentry",
        "monitoring",
        "logging",
        "sentry api",
        "mcp sentry",
        "interact sentry"
      ],
      "category": "monitoring-and-logging"
    },
    "cyanheads--toolkit-mcp-server": {
      "owner": "cyanheads",
      "name": "toolkit-mcp-server",
      "url": "https://github.com/cyanheads/toolkit-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/cyanheads.webp",
      "description": "Provides LLM Agents with access to various system utilities and tools, enabling functionalities such as IP geolocation, network diagnostics, system monitoring, cryptographic operations, and QR code generation.",
      "stars": 13,
      "forks": 6,
      "license": "Apache License 2.0",
      "language": "TypeScript",
      "updated_at": "2025-09-30T12:04:53Z",
      "readme_content": "# toolkit-mcp-server\n\n[![TypeScript](https://img.shields.io/badge/TypeScript-5.3-blue.svg)](https://www.typescriptlang.org/)\n[![Model Context Protocol](https://img.shields.io/badge/MCP-1.4.0-green.svg)](https://modelcontextprotocol.io/)\n[![Version](https://img.shields.io/badge/Version-1.0.1-blue.svg)]()\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n[![Status](https://img.shields.io/badge/Status-Stable-blue.svg)]()\n[![GitHub](https://img.shields.io/github/stars/cyanheads/toolkit-mcp-server?style=social)](https://github.com/cyanheads/toolkit-mcp-server)\n\nA Model Context Protocol server providing LLM Agents with system utilities and tools, including IP geolocation, network diagnostics, system monitoring, cryptographic operations, and QR code generation.\n\n## Model Context Protocol\n\nThe Model Context Protocol (MCP) enables communication between:\n\n- **Clients**: Claude Desktop, IDEs, and other MCP-compatible clients\n- **Servers**: Tools and resources for task management and automation\n- **LLM Agents**: AI models that leverage the server's capabilities\n\n## Table of Contents\n\n- [Features](#features)\n- [Installation](#installation)\n- [Configuration](#configuration)\n- [Tools](#tools)\n- [Contributing](#contributing)\n- [License](#license)\n\n## Features\n\n### Network & Geolocation\n- IP geolocation with intelligent caching\n- Network connectivity testing\n- Ping and traceroute utilities\n- Public IP detection\n- Rate limiting (45 requests/minute)\n\n### System Utilities\n- System information retrieval\n- Resource monitoring\n- Load average tracking\n- Network interface details\n\n### Security Tools\n- Cryptographic hash generation (MD5, SHA-1, SHA-256, SHA-512)\n- Constant-time hash comparison\n- UUID generation\n\n### Generator Tools\n- QR code generation\n  - Terminal output\n  - SVG format\n  - Base64 encoded images\n\n## Installation\n\n```bash\n# Using npm (recommended)\nnpm install @cyanheads/toolkit-mcp-server\n\n# Or install from source\ngit clone git@github.com:cyanheads/toolkit-mcp-server.git\ncd toolkit-mcp-server\nnpm install\nnpm run build\n```\n\n## Configuration\n\nAdd to your MCP client settings:\n\n```json\n{\n  \"mcpServers\": {\n    \"toolkit\": {\n      \"command\": \"node\",\n      \"args\": [\"node_modules/@cyanheads/toolkit-mcp-server/build/index.js\"],\n      \"env\": {\n        \"NODE_ENV\": \"production\"\n      }\n    }\n  }\n}\n```\n\n## Tools\n\n### Network Operations\n```typescript\n// Get geolocation data\nconst geo = await mcp.use('toolkit-mcp-server', 'geolocate', {\n  query: '8.8.8.8'\n});\n\n// Check connectivity\nconst conn = await mcp.use('toolkit-mcp-server', 'checkConnectivity', {\n  host: 'example.com',\n  port: 443\n});\n```\n\n### System Operations\n```typescript\n// Get system information\nconst sysInfo = await mcp.use('toolkit-mcp-server', 'getSystemInfo', {});\n\n// Get load average\nconst load = await mcp.use('toolkit-mcp-server', 'getLoadAverage', {});\n```\n\n### Security Operations\n```typescript\n// Generate hash\nconst hash = await mcp.use('toolkit-mcp-server', 'hashData', {\n  input: 'test data',\n  algorithm: 'sha256'\n});\n\n// Generate UUID\nconst uuid = await mcp.use('toolkit-mcp-server', 'generateUUID', {});\n```\n\n### Generator Operations\n```typescript\n// Generate QR code\nconst qr = await mcp.use('toolkit-mcp-server', 'generateQRCode', {\n  data: 'https://example.com',\n  type: 'svg'\n});\n```\n\n## Contributing\n\n1. Fork the repository\n2. Create your feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add some amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n\n## License\n\nApache License 2.0. See [LICENSE](LICENSE) for more information.\n\n---\n\n<div align=\"center\">\nBuilt with the Model Context Protocol\n</div>",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llm",
        "toolkit",
        "monitoring",
        "toolkit mcp",
        "logging cyanheads",
        "cyanheads toolkit"
      ],
      "category": "monitoring-and-logging"
    },
    "didlawowo--mcp-collection": {
      "owner": "didlawowo",
      "name": "mcp-collection",
      "url": "https://github.com/didlawowo/mcp-collection",
      "imageUrl": "/freedevtools/mcp/pfp/didlawowo.webp",
      "description": "Interact with Datadog API to fetch monitoring data and analyze specific monitor states and Kubernetes logs from infrastructure.",
      "stars": 8,
      "forks": 1,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-06-08T09:11:18Z",
      "readme_content": "# Datadog Model Context Protocol (MCP) 🔍\n\n[![smithery badge](https://smithery.ai/badge/@didlawowo/mcp-collection)](https://smithery.ai/server/@didlawowo/mcp-collection)\n\nA Python-based tool to interact with Datadog API and fetch monitoring data from your infrastructure. This MCP provides easy access to monitor states and Kubernetes logs through a simple interface.\n\n## Datadog Features 🌟\n\n- **Monitor State Tracking**: Fetch and analyze specific monitor states\n- **Kubernetes Log Analysis**: Extract and format error logs from Kubernetes clusters\n\n## Prerequisites 📋\n\n- Python 3.11+\n- Datadog API and Application keys (with correct permissions)\n- Access to Datadog site\n\n## Installation 🔧\n\n### Installing via Smithery\n\nTo install Datadog for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@didlawowo/mcp-collection):\n\n```bash\nnpx -y @smithery/cli install @didlawowo/mcp-collection --client claude\n```\n\nRequired packages:\n\n```text\ndatadog-api-client\nfastmcp\nloguru\nicecream\npython-dotenv\nuv\n```\n\n## Environment Setup 🔑\n\nCreate a `.env` file with your Datadog credentials:\n\n```env\nDD_API_KEY=your_api_key\nDD_APP_KEY=your_app_key\n```\n\n## Setup Claude Desktop Setup for MCP 🖥️\n\n1. Install Claude Desktop\n\n```bash\n# Assuming you're on macOS\nbrew install claude-desktop\n\n# Or download from official website\nhttps://claude.ai/desktop\n```\n\n2. Set up Datadog MCP config:\n\n```bash\n# on mac is \n~/Library/Application\\ Support/Claude/claude_desktop_config.json\n\n\n# Add this to your claude config json\n```json\n    \"Datadog-MCP-Server\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"run\",\n        \"--with\",\n        \"datadog-api-client\",\n        \"--with\",\n        \"fastmcp\",\n        \"--with\",\n        \"icecream\",\n        \"--with\",\n        \"loguru\",\n        \"--with\",\n        \"python-dotenv\",\n        \"fastmcp\",\n        \"run\",\n        \"/your-path/mcp-collection/datadog/main.py\"\n      ],\n      \"env\": {\n        \"DD_API_KEY\": \"xxxx\",\n        \"DD_APP_KEY\": \"xxx\"\n      }\n    },\n```\n\n## Usage 💻\n\n\n\n\n\n## Architecture 🏗\n\n- **FastMCP Base**: Utilizes FastMCP framework for tool management\n- **Modular Design**: Separate functions for monitors and logs\n- **Type Safety**: Full typing support with Python type hints\n- **API Abstraction**: Wrapped Datadog API calls with error handling\n\nI'll add a section about MCP and Claude Desktop setup:\n\n# Model Context Protocol (MCP) Introduction 🤖\n\n## What is MCP?\n\nModel Context Protocol (MCP) is a framework allowing AI models to interact with external tools and APIs in a standardized way. It enables models like Claude to:\n\n- Access external data\n- Execute commands\n- Interact with APIs\n- Maintain context across conversations\n\n## some examples of MCP servers\n\n<https://github.com/punkpeye/awesome-mcp-servers?tab=readme-ov-file>\n\n## Tutorial for setup MCP\n\n<https://medium.com/@pedro.aquino.se/how-to-use-mcp-tools-on-claude-desktop-app-and-automate-your-daily-tasks-1c38e22bc4b0>\n\n## How it works - Available Functions 🛠️\n\nthe LLM use provided function to get the data and use it\n\n### 1. Get Monitor States\n\n```python\nget_monitor_states(\n    name: str,           # Monitor name to search\n    timeframe: int = 1   # Hours to look back\n)\n```\n\nExample:\n\n```python\n\nresponse = get_monitor_states(name=\"traefik\")\n\n# Sample Output\n{\n    \"id\": \"12345678\",\n    \"name\": \"traefik\",\n    \"status\": \"OK\",\n    \"query\": \"avg(last_5m):avg:traefik.response_time{*} > 1000\",\n    \"message\": \"Response time is too high\",\n    \"type\": \"metric alert\",\n    \"created\": \"2024-01-14T10:00:00Z\",\n    \"modified\": \"2024-01-14T15:30:00Z\"\n}\n```\n\n### 2. Get Kubernetes Logs\n\n```python\nget_k8s_logs(\n    cluster: str,            # Kubernetes cluster name\n    timeframe: int = 5,      # Hours to look back\n    namespace: str = None    # Optional namespace filter\n)\n```\n\nExample:\n\n```python\nlogs = get_k8s_logs(\n    cluster=\"prod-cluster\",\n    timeframe=3,\n    namespace=\"default\"\n)\n\n# Sample Output\n{\n    \"timestamp\": \"2024-01-14T22:00:00Z\",\n    \"host\": \"worker-1\",\n    \"service\": \"nginx-ingress\",\n    \"pod_name\": \"nginx-ingress-controller-abc123\",\n    \"namespace\": \"default\",\n    \"container_name\": \"controller\",\n    \"message\": \"Connection refused\",\n    \"status\": \"error\"\n}\n```\n\n```bash\n# Install as MCP extension\ncd datadog\ntask install-mcp\n```\n\n## 4. Verify Installation\n\n### In Claude chat desktop\n\n check datadog connection in claude\n\n\n\n## 5. Use Datadog MCP Tools\n\n## Security Considerations 🔒\n\n- Store API keys in `.env`\n- MCP runs in isolated environment\n- Each tool has defined permissions\n- Rate limiting is implemented\n\n## Troubleshooting 🔧\n\n### Using MCP Inspector\n\n```bash\n# Launch MCP Inspector for debugging\ntask run-mcp-inspector\n```\n\nThe MCP Inspector provides:\n\n- Real-time view of MCP server status\n- Function call logs\n- Error tracing\n- API response monitoring\n\n### Common issues and solutions\n\n1. **API Authentication Errors**\n\n   ```bash\n   Error: (403) Forbidden\n   ```\n\n   ➡️ Check your DD_API_KEY and DD_APP_KEY in .env\n\n2. **MCP Connection Issues**\n\n   ```bash\n   Error: Failed to connect to MCP server\n   ```\n\n   ➡️ Verify your claude_desktop_config.json path and content\n\n3. **Monitor Not Found**\n\n   ```bash\n   Error: No monitor found with name 'xxx'\n   ```\n\n   ➡️ Check monitor name spelling and case sensitivity\n\n4. **logs can be found here**\n\n\n\n## Contributing 🤝\n\nFeel free to:\n\n1. Open issues for bugs\n2. Submit PRs for improvements\n3. Add new features\n\n## Notes 📝\n\n- API calls are made to Datadog EU site\n- Default timeframe is 1 hour for monitor states\n- Page size limits are set to handle most use cases",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "datadog",
        "kubernetes",
        "monitoring",
        "kubernetes logs",
        "datadog api",
        "monitoring logging"
      ],
      "category": "monitoring-and-logging"
    },
    "dvladimirov--MCP": {
      "owner": "dvladimirov",
      "name": "MCP",
      "url": "https://github.com/dvladimirov/MCP",
      "imageUrl": "/freedevtools/mcp/pfp/dvladimirov.webp",
      "description": "Integrates OpenAI services with Git repository analysis and local filesystem operations. Also supports Prometheus for monitoring and provides utilities for seamless development workflows.",
      "stars": 0,
      "forks": 0,
      "license": "GNU General Public License v3.0",
      "language": "Python",
      "updated_at": "2025-04-24T21:09:05Z",
      "readme_content": "# MCP Server with OpenAI, Git, Filesystem, and Prometheus Integration\n\nThis repository contains a Model Control Plane (MCP) server implementation that supports OpenAI services, Git repository analysis, local filesystem operations, and Prometheus integration.\n\n## Project Structure\n\n```\nMCP/\n├── mcp/               # Core MCP library modules\n├── scripts/           # Utility scripts and test tools\n├── prometheus/        # Prometheus configuration\n├── docker-compose.yml # Docker configuration\n├── mcp_server.py      # Main server implementation\n├── mcp_run            # Main runner script (shortcut)\n└── README.md          # This file\n```\n\n## Requirements\n\n- Python 3.8+\n- FastAPI\n- Uvicorn\n- OpenAI SDK\n- GitPython\n- Requests\n- Docker and Docker Compose (for Prometheus features)\n\n## Installation\n\n1. Clone this repository\n2. Install the dependencies:\n\n```bash\npip install -r requirements.txt\n```\n\n## Environment Variables\n\nSet the following environment variables:\n\nFor Azure OpenAI:\n```bash\nexport AZURE_OPENAI_ENDPOINT=\"your-azure-endpoint\"\nexport AZURE_OPENAI_API_KEY=\"your-azure-api-key\"\nexport AZURE_OPENAI_API_VERSION=\"2023-05-15\"\nexport AZURE_DEPLOYMENT_NAME=\"your-deployment-name\"\n```\n\nFor Standard OpenAI:\n```bash\nexport OPENAI_API_KEY=\"your-openai-api-key\"\n# Optional: Specify which models to use\nexport OPENAI_CHAT_MODEL=\"gpt-4o-mini\"  # Default if not specified\nexport OPENAI_COMPLETION_MODEL=\"gpt-3.5-turbo-instruct\"  # Default if not specified\n```\n\nFor Prometheus:\n```bash\nexport PROMETHEUS_URL=\"http://localhost:9090\"  # Default if not specified\n```\n\n## Running the Server\n\nStart the MCP server:\n\n```bash\npython scripts/start_mcp_server.py\n```\n\nOr for more options:\n\n```bash\npython scripts/start_mcp_server.py --host 0.0.0.0 --port 8000 --debug\n```\n\nThe server will be available at http://localhost:8000.\n\n## Unified Testing Tool\n\nWe provide a unified testing script that gives you a user-friendly interface to all testing functionality:\n\n```bash\n./mcp_run\n```\n\nThis interactive script provides:\n- Filesystem tests\n- Git integration tests\n- Memory analysis tools\n- Prometheus tests & memory stress\n- MCP server management\n- Environment setup\n\n## Individual Tests\n\nYou can also run individual tests directly:\n\nTest the OpenAI integration:\n```bash\npython scripts/test_mcp_client.py\n```\n\nTest the Git integration (provide a Git repository URL):\n```bash\npython scripts/test_git_integration.py https://github.com/username/repository\n```\n\nTest the Git diff functionality (analyze requirements compatibility):\n```bash\npython scripts/test_git_diff.py https://github.com/username/repository [commit-sha]\n```\n\nTest the filesystem functionality:\n```bash\npython scripts/test_filesystem.py\n```\n\nTest the langflow integration with MCP:\n```bash\npython scripts/test_langflow_integration.py [OPTIONAL_REPO_URL]\n```\n\nTest the Prometheus integration:\n```bash\npython scripts/test_prometheus.py [prometheus_url]\n```\n\n## Advanced Git Analysis\n\nFor more advanced Git repository analysis with AI recommendations:\n\n```bash\npython scripts/langflow_git_analyzer.py https://github.com/username/repository\n```\n\nYou can also search for specific patterns in the repository:\n\n```bash\npython scripts/langflow_git_analyzer.py https://github.com/username/repository --search \"def main\"\n```\n\nOr analyze the last commit diff with AI insights:\n\n```bash\npython scripts/langflow_git_analyzer.py https://github.com/username/repository --diff\n```\n\n## Memory Analysis Tools\n\nMCP includes several tools for memory monitoring and analysis:\n\n```bash\n# Basic memory diagnostics with AI analysis\npython scripts/ai_memory_diagnostics.py\n\n# Interactive memory dashboard\npython scripts/mcp_memory_dashboard.py\n\n# Memory alerting system\npython scripts/mcp_memory_alerting.py\n```\n\nYou can also simulate memory pressure for testing:\n\n```bash\npython scripts/simulate_memory_pressure.py --target 85 --duration 300\n```\n\n## Prometheus Integration\n\n### Setup\n\n1. Start the Prometheus stack using Docker Compose:\n\n```bash\ndocker compose up -d\n```\n\nThis will start:\n- Prometheus server (accessible at http://localhost:9090)\n- Node Exporter (for host metrics)\n- cAdvisor (for container metrics)\n\n2. For stress testing, you can start the memory stress container:\n\n```bash\ndocker compose up -d --build memory-stress\n```\n\nOr use the container test script:\n```bash\n./scripts/container-memory-test.sh start\n```\n\n### Docker Configuration and Reset Scripts\n\nThis project includes multiple Docker configurations and reset scripts for reliable operation across different environments:\n\n#### Docker Configurations\n- **Standard Configuration** (`docker-compose.yml`): Uses custom Dockerfiles for Prometheus and Langflow to ensure consistent permissions across systems.\n- **Bridge Network Configuration** (`docker-compose.bridge.yml`): Alternative configuration that uses bridge networking for environments where host networking is problematic.\n\n#### Custom Dockerfiles for Solving Permission Issues\nThe project uses custom Dockerfiles for both Prometheus and Langflow to solve common permission issues:\n\n- **Dockerfile.prometheus**: Sets up the Prometheus configuration with proper permissions for the `nobody` user.\n- **Dockerfile.langflow**: Copies the components directory into the container without changing file ownership, allowing Langflow to access the components without permission errors.\n\nThis approach eliminates the need for volume mounts that can lead to permission conflicts across different machines and user configurations.\n\n#### Reset Scripts\n- **All Services Reset** (`reset-all.sh`): Reset all containers with a single command.\n  ```bash\n  # Basic reset (rebuilds containers with existing volumes)\n  ./reset-all.sh\n  \n  # Full reset (removes volumes and rebuilds containers)\n  ./reset-all.sh --clean\n  ```\n\n- **Individual Service Reset**:\n  ```bash\n  # Reset only Prometheus\n  ./reset-prometheus.sh\n  \n  # Reset only Langflow\n  ./reset-langflow.sh\n  ```\n\nThese scripts ensure that the containers are properly configured with correct permissions and the latest code changes.\n\n#### Troubleshooting\nIf you encounter permission issues:\n1. Use the reset scripts to rebuild the containers\n2. Check the logs with `docker compose logs <service_name>`\n3. Make sure any components added to Langflow are included in the Dockerfile.langflow\n\n#### Cross-Machine Deployment\nWhen deploying to a new machine:\n1. Clone the repository\n2. Make reset scripts executable: `chmod +x *.sh`\n3. Run the reset script: `./reset-all.sh`\n\nThe custom Dockerfiles automatically handle all permission issues that might occur across different systems.\n\n### Using Prometheus Client\n\nThe `MCPAIComponent` class includes Prometheus capabilities:\n\n```python\nfrom langflow import MCPAIComponent\n\n# Initialize the client\nmcp = MCPAIComponent(mcp_server_url=\"http://localhost:8000\")\n\n# Instant query (current metric values)\nresult = mcp.prometheus_query(\"up\")\n\n# Range query (metrics over time)\nresult = mcp.prometheus_query_range(\n    query=\"rate(node_cpu_seconds_total{mode='system'}[1m])\",\n    start=\"2023-03-01T00:00:00Z\",\n    end=\"2023-03-01T01:00:00Z\",\n    step=\"15s\"\n)\n\n# Get all labels\nlabels = mcp.prometheus_get_labels()\n\n# Get label values\nvalues = mcp.prometheus_get_label_values(\"job\")\n\n# Get targets\ntargets = mcp.prometheus_get_targets()\n\n# Get alerts\nalerts = mcp.prometheus_get_alerts()\n```\n\n### Useful PromQL Queries\n\n- CPU Usage: `rate(node_cpu_seconds_total{mode!=\"idle\"}[1m])`\n- Memory Usage: `node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes`\n- Disk Usage: `node_filesystem_avail_bytes{mountpoint=\"/\"} / node_filesystem_size_bytes{mountpoint=\"/\"}`\n- Container CPU Usage: `rate(container_cpu_usage_seconds_total[1m])`\n- Container Memory Usage: `container_memory_usage_bytes`\n\n## API Endpoints\n\n### OpenAI Endpoints\n- GET `/v1/models` - List all available models\n- GET `/v1/models/{model_id}` - Get information about a specific model\n- POST `/v1/models/azure-gpt-4/completion` - Generate text completion using Azure OpenAI\n- POST `/v1/models/azure-gpt-4/chat` - Generate chat response using Azure OpenAI\n- POST `/v1/models/openai-gpt-chat/chat` - Generate chat response using OpenAI chat model\n- POST `/v1/models/openai-gpt-completion/completion` - Generate text completion using OpenAI completion model\n\n### Git Integration Endpoints\n- POST `/v1/models/git-analyzer/analyze` - Analyze a Git repository\n- POST `/v1/models/git-analyzer/search` - Search a Git repository for files matching a pattern\n- POST `/v1/models/git-analyzer/diff` - Get the diff of the last commit in a repository\n\n### Filesystem Endpoints\n- POST `/v1/models/filesystem/list` - List contents of a directory\n- POST `/v1/models/filesystem/read` - Read a file's contents\n- POST `/v1/models/filesystem/read-multiple` - Read multiple files at once\n- POST `/v1/models/filesystem/write` - Write content to a file\n- POST `/v1/models/filesystem/edit` - Edit a file with multiple replacements\n- POST `/v1/models/filesystem/mkdir` - Create a directory\n- POST `/v1/models/filesystem/move` - Move a file or directory\n- POST `/v1/models/filesystem/search` - Search for files matching a pattern\n- POST `/v1/models/filesystem/info` - Get information about a file or directory\n\n### Prometheus Endpoints\n- POST `/v1/models/prometheus/query` - Execute an instant query\n- POST `/v1/models/prometheus/query_range` - Execute a range query\n- POST `/v1/models/prometheus/series` - Get series data\n- GET `/v1/models/prometheus/labels` - Get all available labels\n- POST `/v1/models/prometheus/label_values` - Get values for a specific label\n- GET `/v1/models/prometheus/targets` - Get all targets\n- GET `/v1/models/prometheus/rules` - Get all rules\n- GET `/v1/models/prometheus/alerts` - Get all alerts\n\n## Client Usage\n\nYou can use the `MCPAIComponent` in your LangFlow pipelines by providing the MCP server URL:\n\n```python\nfrom langflow import MCPAIComponent\n\nmcp = MCPAIComponent(mcp_server_url=\"http://localhost:8000\")\n\n# List available models\nmodels = mcp.list_models()\nprint(models)\n\n# Generate chat completion with OpenAI model\nchat_response = mcp.chat(\n    model_id=\"openai-gpt-chat\",\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n        {\"role\": \"user\", \"content\": \"Tell me a joke about programming.\"}\n    ],\n    max_tokens=100,\n    temperature=0.7\n)\nprint(chat_response)\n\n# Generate text completion with OpenAI model\ncompletion_response = mcp.completion(\n    model_id=\"openai-gpt-completion\",\n    prompt=\"Write a function in Python to calculate the factorial of a number:\",\n    max_tokens=150,\n    temperature=0.7\n)\nprint(completion_response)\n\n# Analyze a Git repository\nrepo_analysis = mcp.analyze_git_repo(\"https://github.com/username/repository\")\nprint(repo_analysis)\n\n# Search a Git repository\nsearch_results = mcp.search_git_repo(\"https://github.com/username/repository\", \"def main\")\nprint(search_results)\n\n# Get the diff of the last commit\ndiff_info = mcp.get_git_diff(\"https://github.com/username/repository\")\nprint(diff_info)\n\n# List files in the current directory\ndir_contents = mcp.list_directory()\nprint(dir_contents)\n\n# Read a file\nfile_content = mcp.read_file(\"path/to/file.txt\")\nprint(file_content)\n\n# Write to a file\nwrite_result = mcp.write_file(\"path/to/new_file.txt\", \"Hello, world!\")\nprint(write_result)\n\n# Search for files\nsearch_result = mcp.search_files(\"*.py\")\nprint(search_result)\n```\n\n## Using the GitCodeAnalyzer Class\n\nFor more structured Git analysis, you can use the `GitCodeAnalyzer` class:\n\n```python\nfrom langflow_git_analyzer import GitCodeAnalyzer\n\n# Initialize the analyzer\nanalyzer = GitCodeAnalyzer(mcp_server_url=\"http://localhost:8000\")\n\n# Analyze a repository\nanalyzer.analyze_repository(\"https://github.com/username/repository\")\n\n# Get a summary\nsummary = analyzer.get_repository_summary()\nprint(summary)\n\n# Get AI recommendations\nrecommendations = analyzer.get_repository_recommendations()\nprint(recommendations)\n\n# Analyze code patterns\npattern_analysis = analyzer.analyze_code_pattern(\"def process\")\nprint(pattern_analysis)\n\n# Get the last commit diff\ndiff_info = analyzer.get_last_commit_diff()\nprint(diff_info)\n\n# Get a formatted summary of the diff\ndiff_summary = analyzer.get_formatted_diff_summary()\nprint(diff_summary)\n\n# Get AI analysis of the commit changes\ndiff_analysis = analyzer.analyze_commit_diff()\nprint(diff_analysis)\n```\n\n## Troubleshooting\n\n### Prometheus Issues\n1. Verify Prometheus is running: `docker ps | grep prometheus`\n2. Check you can access the Prometheus UI: http://localhost:9090\n3. Verify the MCP server is running and accessible\n4. Check the MCP server logs for errors\n5. Try simple queries first to verify connectivity (e.g., `up` query)\n\n### OpenAI Issues\n1. Verify your API keys are set correctly\n2. Check for rate limiting or quota issues\n3. Verify you're using supported models for your API key\n\n### Git Issues\n1. Ensure the Git repository URL is accessible\n2. Check for authentication issues if using private repositories\n3. Ensure GitPython is installed correctly ",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "openai",
        "git",
        "monitoring",
        "services git",
        "openai services",
        "prometheus monitoring"
      ],
      "category": "monitoring-and-logging"
    },
    "dynatrace-oss--dynatrace-mcp": {
      "owner": "dynatrace-oss",
      "name": "dynatrace-mcp",
      "url": "https://github.com/dynatrace-oss/dynatrace-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/dynatrace-oss.webp",
      "description": "Connect to the Dynatrace observability platform to retrieve real-time observability data, including production problems, security vulnerabilities, logs, and events. Utilize natural language queries to automate notifications and integrate monitoring within development workflows.",
      "stars": 148,
      "forks": 41,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-02T13:49:09Z",
      "readme_content": "# Dynatrace MCP Server\n\n<h4 align=\"center\">\n  <a href=\"https://github.com/dynatrace-oss/dynatrace-mcp/releases\">\n    <img alt=\"dynatrace_mcp\" src=\"https://img.shields.io/github/release/dynatrace-oss/dynatrace-mcp\" />\n  </a>\n  <a href=\"https://github.com/dynatrace-oss/dynatrace-mcp/blob/main/LICENSE\">\n    <img src=\"https://img.shields.io/badge/license-mit-blue.svg\" alt=\"Dynatrace MCP Server is released under the MIT License\" />\n  </a>\n  <a href=\"https://www.npmjs.com/package/@dynatrace-oss/dynatrace-mcp-server\">\n    <img src=\"https://img.shields.io/npm/dm/@dynatrace-oss/dynatrace-mcp-server?logo=npm&style=flat&color=red\" alt=\"npm\" />\n  </a>\n  <a href=\"https://github.com/dynatrace-oss/dynatrace-mcp\">\n    <img src=\"https://img.shields.io/github/stars/dynatrace-oss/dynatrace-mcp\" alt=\"Dynatrace MCP Server Stars on GitHub\" />\n  </a>\n  <a href=\"https://github.com/dynatrace-oss/dynatrace-mcp\">\n    <img src=\"https://img.shields.io/github/contributors/dynatrace-oss/dynatrace-mcp?color=green\" alt=\"Dynatrace MCP Server Contributors on GitHub\" />\n  </a>\n</h4>\n\nThe local _Dynatrace MCP server_ allows AI Assistants to interact with the [Dynatrace](https://www.dynatrace.com/) observability platform,\nbringing real-time observability data directly into your development workflow.\n\n> Note: This product is not officially supported by Dynatrace.\n\nIf you need help, please contact us via [GitHub Issues](https://github.com/dynatrace-oss/dynatrace-mcp/issues) if you have feature requests, questions, or need help.\n\nhttps://github.com/user-attachments/assets/25c05db1-8e09-4a7f-add2-ed486ffd4b5a\n\n## Quickstart\n\nYou can add this MCP server to your MCP Client like VSCode, Claude, Cursor, Amazon Q, Windsurf, ChatGPT, or Github Copilot via the npmjs package `@dynatrace-oss/dynatrace-mcp-server`, and type `stdio`.\nYou can find more details about the configuration for different AI Assistants, Agents and MCP Clients in the [Configuration section below](#configuration).\n\nFurthermore, you need your Dynatrace environment URL, e.g., `https://abc12345.apps.dynatrace.com`, as well as a [Platform Token](https://docs.dynatrace.com/docs/manage/identity-access-management/access-tokens-and-oauth-clients/platform-tokens), e.g., `dt0s16.SAMPLE.abcd1234`, with [required scopes](#scopes-for-authentication).\n\nDepending on your MCP Client, you need to configure these as environment variables or as settings in the UI:\n\n- `DT_ENVIRONMENT` (string, e.g., `https://abc12345.apps.dynatrace.com`) - URL to your Dynatrace Platform (do not use Dynatrace classic URLs like `abc12345.live.dynatrace.com`)\n- `DT_PLATFORM_TOKEN` (string, e.g., `dt0s16.SAMPLE.abcd1234`) - **Recommended**: Dynatrace Platform Token\n\nOnce you are done, we recommend looking into [example prompts](#-example-prompts-), like `Get all details of the entity 'my-service'` or `Show me error logs`. Please mind that these prompts lead to executing DQL statements which may incur [costs](#costs) in accordance to your licence.\n\n## Architecture\n\n![Architecture](https://github.com/dynatrace-oss/dynatrace-mcp/blob/main/assets/dynatrace-mcp-arch.png?raw=true)\n\n## Use cases\n\n- **Real-time observability** - Fetch production-level data for early detection and proactive monitoring\n- **Contextual debugging** - Fix issues with full context from monitored exceptions, logs, and anomalies\n- **Security insights** - Get detailed vulnerability analysis and security problem tracking\n- **Natural language queries** - Use AI-powered DQL generation and explanation\n- **Multi-phase incident investigation** - Systematic 4-phase approach with automated impact assessment\n- **Advanced transaction analysis** - Precise root cause identification with file/line-level accuracy\n- **Cross-data source correlation** - Connect problems → spans → logs with trace ID correlation\n- **DevOps automation** - Deployment health gates with automated promotion/rollback logic\n- **Security compliance monitoring** - Multi-cloud compliance assessment with evidence-based investigation\n\n## Capabilities\n\n- List and get [problem](https://www.dynatrace.com/hub/detail/problems/) details from your services (for example Kubernetes)\n- List and get security problems / [vulnerability](https://www.dynatrace.com/hub/detail/vulnerabilities/) details\n- Execute DQL (Dynatrace Query Language) and retrieve logs, events, spans and metrics\n- Send Slack messages (via Slack Connector)\n- Set up notification Workflow (via Dynatrace [AutomationEngine](https://docs.dynatrace.com/docs/discover-dynatrace/platform/automationengine))\n- Get more information about a monitored entity\n- Get Ownership of an entity\n\n### Costs\n\n**Important:** While this local MCP server is provided for free, using certain capabilities to access data in Dynatrace Grail may incur additional costs based\non your Dynatrace consumption model. This affects `execute_dql` tool and other capabilities that **query** Dynatrace Grail storage, and costs\ndepend on the volume (GB scanned).\n\n**Before using this MCP server extensively, please:**\n\n1. Review your current Dynatrace consumption model and pricing\n2. Understand the cost implications of the specific data you plan to query (logs, events, metrics) - see [Dynatrace Pricing and Rate Card](https://www.dynatrace.com/pricing/)\n3. Start with smaller timeframes (e.g., 12h-24h) and make use of [buckets](https://docs.dynatrace.com/docs/discover-dynatrace/platform/grail/data-model#built-in-grail-buckets) to reduce the cost impact\n4. Set an appropriate `DT_GRAIL_QUERY_BUDGET_GB` environment variable (default: 1000 GB) to control and monitor your Grail query consumption\n\n**Grail Budget Tracking:**\n\nThe MCP server includes built-in budget tracking for Grail queries to help you monitor and control costs:\n\n- Set `DT_GRAIL_QUERY_BUDGET_GB` (default: 1000 GB) to define your session budget limit\n- The server tracks bytes scanned across all Grail queries in the current session\n- You'll receive warnings when approaching 80% of your budget\n- Budget exceeded alerts help prevent unexpected high consumption\n- Budget resets when you restart the MCP server session\n\n**To understand costs that occured:**\n\nExecute the following DQL statement in a notebook to see how much bytes have been queried from Grail (Logs, Events, etc...):\n\n```\nfetch dt.system.events\n| filter event.kind == \"QUERY_EXECUTION_EVENT\" and contains(client.client_context, \"dynatrace-mcp\")\n| sort timestamp desc\n| fields timestamp, query_id, query_string, scanned_bytes, table, bucket, user.id, user.email, client.client_context\n| maketimeSeries sum(scanned_bytes), by: { user.email, user.id, table }\n```\n\n### AI-Powered Assistance (Preview)\n\n- **Natural Language to DQL** - Convert plain English queries to Dynatrace Query Language\n- **DQL Explanation** - Get plain English explanations of complex DQL queries\n- **AI Chat Assistant** - Get contextual help and guidance for Dynatrace questions\n- **Feedback System** - Provide feedback to improve AI responses over time\n\n> **Note:** While Davis CoPilot AI is generally available (GA), the Davis CoPilot APIs are currently in preview. For more information, visit the [Davis CoPilot Preview Community](https://dt-url.net/copilot-community).\n\n## 🎯 AI-Powered Observability Workshop Rules\n\nEnhance your AI assistant with comprehensive Dynatrace observability analysis capabilities through our streamlined workshop rules. These rules provide hierarchical workflows for security, compliance, incident response, and distributed systems investigation.\n\n### **🚀 Quick Setup for AI Assistants**\n\nCopy the comprehensive rule files from the [`dynatrace-agent-rules/rules/`](./dynatrace-agent-rules/rules/) directory to your AI assistant's rules directory:\n\n**IDE-Specific Locations:**\n\n- **Amazon Q**: `.amazonq/rules/` (project) or `~/.aws/amazonq/rules/` (global)\n- **Cursor**: `.cursor/rules/` (project) or via Settings → Rules (global)\n- **Windsurf**: `.windsurfrules/` (project) or via Customizations → Rules (global)\n- **Cline**: `.clinerules/` (project) or `~/Documents/Cline/Rules/` (global)\n- **GitHub Copilot**: `.github/copilot-instructions.md` (project only)\n\nThen initialize the agent in your AI chat:\n\n```\nload dynatrace mcp\n```\n\n### **🏗️ Enhanced Analysis Capabilities**\n\nThe workshop rules unlock advanced observability analysis modes:\n\n#### **🚨 Incident Response & Problem Investigation**\n\n- **4-phase structured investigation** workflow (Detection → Impact → Root Cause → Resolution)\n- **Cross-data source correlation** (problems → logs → spans → metrics)\n- **Kubernetes-aware incident analysis** with namespace and pod context\n- **User impact assessment** with Davis AI integration\n\n#### **📊 Comprehensive Data Investigation**\n\n- **Unified log-service-process analysis** in single workflow\n- **Business logic error detection** patterns\n- **Deployment correlation analysis** with ArgoCD/GitOps integration\n- **Golden signals monitoring** (Rate, Errors, Duration, Saturation)\n\n#### **🔗 Advanced Transaction Analysis**\n\n- **Precise root cause identification** with file/line numbers\n- **Exception stack trace analysis** with business context\n- **Multi-service cascade failure analysis**\n- **Performance impact correlation** across distributed systems\n\n#### **🛡️ Enhanced Security & Compliance**\n\n- **Latest-scan analysis** prevents outdated data aggregation\n- **Multi-cloud compliance** (AWS, Azure, GCP, Kubernetes)\n- **Evidence-based investigation** with detailed remediation paths\n- **Risk-based scoring** with team-specific guidance\n\n#### **⚡ DevOps Automation & SRE**\n\n- **Deployment health gates** with automated promotion/rollback\n- **SLO/SLI automation** with error budget calculations\n- **Infrastructure as Code remediation** with auto-generated templates\n- **Alert optimization workflows** with pattern recognition\n\n### **📁 Hierarchical Rule Architecture**\n\nThe rules are organized in a context-window optimized structure:\n\n```\nrules/\n├── DynatraceMcpIntegration.md                    # 🎯 MAIN ORCHESTRATOR\n├── workflows/                                    # 🔧 ANALYSIS WORKFLOWS\n│   ├── incidentResponse.md                       # Core incident investigation\n│   ├── DynatraceSecurityCompliance.md           # Security & compliance analysis\n│   ├── DynatraceDevOpsIntegration.md            # CI/CD automation\n│   └── dataSourceGuides/                        # 📊 DATA ANALYSIS GUIDES\n│       ├── dataInvestigation.md                 # Logs, services, processes\n│       └── DynatraceSpanAnalysis.md             # Transaction tracing\n└── reference/                                   # 📚 TECHNICAL DOCUMENTATION\n    ├── DynatraceQueryLanguage.md                # DQL syntax foundation\n    ├── DynatraceExplore.md                      # Field discovery patterns\n    ├── DynatraceSecurityEvents.md               # Security events schema\n    └── DynatraceProblemsSpec.md                 # Problems schema reference\n```\n\n**Key Architectural Benefits:**\n\n- **All files under 6,500 tokens** - Compatible with most LLM context limits\n- **Hierarchical organization** - Clear entry points and specialized guides\n- **Eliminated circular references** - No more confusing cross-referencing webs\n- **DQL-first approach** - Prefer flexible queries over rigid MCP calls\n\nFor detailed information about the workshop rules, see the [Rules README](./dynatrace-agent-rules/rules/README.md).\n\n## Configuration\n\nYou can add this MCP server (using STDIO) to your MCP Client like VS Code, Claude, Cursor, Amazon Q Developer CLI, Windsurf Github Copilot via the package `@dynatrace-oss/dynatrace-mcp-server`.\n\nWe recommend to always set it up for your current workspace instead of using it globally.\n\n**VS Code**\n\n```json\n{\n  \"servers\": {\n    \"npx-dynatrace-mcp-server\": {\n      \"command\": \"npx\",\n      \"cwd\": \"${workspaceFolder}\",\n      \"args\": [\"-y\", \"@dynatrace-oss/dynatrace-mcp-server@latest\"],\n      \"envFile\": \"${workspaceFolder}/.env\"\n    }\n  }\n}\n```\n\nPlease note: In this config, [the `${workspaceFolder}` variable](https://code.visualstudio.com/docs/reference/variables-reference#_predefined-variables) is used.\nThis only works if the config is stored in the current workspaces, e.g., `<your-repo>/.vscode/mcp.json`. Alternatively, this can also be stored in user-settings, and you can define `env` as follows:\n\n```json\n{\n  \"servers\": {\n    \"npx-dynatrace-mcp-server\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@dynatrace-oss/dynatrace-mcp-server@latest\"],\n      \"env\": {\n        \"DT_PLATFORM_TOKEN\": \"\",\n        \"DT_ENVIRONMENT\": \"\"\n      }\n    }\n  }\n}\n```\n\n**Claude Desktop**\n\n```json\n{\n  \"mcpServers\": {\n    \"dynatrace-mcp-server\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@dynatrace-oss/dynatrace-mcp-server@latest\"],\n      \"env\": {\n        \"DT_PLATFORM_TOKEN\": \"\",\n        \"DT_ENVIRONMENT\": \"\"\n      }\n    }\n  }\n}\n```\n\n**Amazon Q Developer CLI**\n\nThe [Amazon Q Developer CLI](https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-mcp-configuration.html) provides an interactive chat experience directly in your terminal. You can ask questions, get help with AWS services, troubleshoot issues, and generate code snippets without leaving your command line environment.\n\n```json\n{\n  \"mcpServers\": {\n    \"dynatrace-mcp-server\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@dynatrace-oss/dynatrace-mcp-server@latest\"],\n      \"env\": {\n        \"DT_PLATFORM_TOKEN\": \"\",\n        \"DT_ENVIRONMENT\": \"\"\n      }\n    }\n  }\n}\n```\n\nThis configuration should be stored in `<your-repo>/.amazonq/mcp.json`.\n\n**Google Gemini CLI**\n\nThe [Google Gemini CLI](https://github.com/google-gemini/gemini-cli) is Google's official command-line AI assistant that supports MCP server integration. You can add the Dynatrace MCP server using either the built-in management commands or manual configuration.\n\nUsing `gemini` CLI directly (recommended):\n\n```bash\ngemini extensions install https://github.com/dynatrace-oss/dynatrace-mcp\nexport DT_PLATFORM_TOKEN=...\nexport DT_ENVIRONMENT=https://...\n```\n\nand verify that the server is running via\n\n```bash\ngemini mcp list\n```\n\nOr manually in your `~/.gemini/settings.json` or `.gemini/settings.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"dynatrace\": {\n      \"command\": \"npx\",\n      \"args\": [\"@dynatrace-oss/dynatrace-mcp-server@latest\"],\n      \"env\": {\n        \"DT_PLATFORM_TOKEN\": \"\",\n        \"DT_ENVIRONMENT\": \"\"\n      },\n      \"timeout\": 30000,\n      \"trust\": false\n    }\n  }\n}\n```\n\n### HTTP Server Mode (Alternative)\n\nFor scenarios where you need to run the MCP server as an HTTP service instead of using stdio (e.g., for stateful sessions, load balancing, or integration with web clients), you can use the HTTP server mode:\n\n**Running as HTTP server:**\n\n```bash\n# Get help and see all available options\nnpx -y @dynatrace-oss/dynatrace-mcp-server@latest --help\n\n# Run with HTTP server on default port 3000\nnpx -y @dynatrace-oss/dynatrace-mcp-server@latest --http\n\n# Run with custom port (using short or long flag)\nnpx -y @dynatrace-oss/dynatrace-mcp-server@latest --server -p 8080\nnpx -y @dynatrace-oss/dynatrace-mcp-server@latest --http --port 3001\n\n# Run with custom host/IP (using short or long flag)\nnpx -y @dynatrace-oss/dynatrace-mcp-server@latest --http --host 127.0.0.1\nnpx -y @dynatrace-oss/dynatrace-mcp-server@latest --http -H 192.168.0.1\n\n# Check version\nnpx -y @dynatrace-oss/dynatrace-mcp-server@latest --version\n```\n\n**Configuration for MCP clients that support HTTP transport:**\n\n```json\n{\n  \"mcpServers\": {\n    \"dynatrace-http\": {\n      \"url\": \"http://localhost:3000\",\n      \"transport\": \"http\"\n    }\n  }\n}\n```\n\n### Rule File\n\nFor efficient result retrieval from Dynatrace, please consider creating a rule file (e.g., [.github/copilot-instructions.md](https://docs.github.com/en/copilot/how-tos/configure-custom-instructions/add-repository-instructions), [.amazonq/rules/](https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/context-project-rules.html)), instructing coding agents on how to get more details for your component/app/service. Here is an example for [easytrade](https://github.com/Dynatrace/easytrade), please adapt the names and filters to fit your use-cases and components:\n\n```\n# Observability\n\nWe use Dynatrace as an Observability solution. This document provides instructions on how to get data for easytrade from Dynatrace using DQL.\n\n## How to get any data for my App\n\nDepending on the query and tool used, the following filters can be applied to narrow down results:\n\n* `contains(entity.name, \"easytrade\")`\n* `contains(affected_entity.name, \"easytrade\")`\n* `contains(container.name, \"easytrade\")`\n\nFor best results, you can combine these filters with an `OR` operator.\n\n## Logs\n\nTo fetch logs for easytrade, execute `fetch logs | filter contains(container.name, \"easyatrade\")`.\nFor fetching just error-logs, add `| filter loglevel == \"ERROR\"`.\n```\n\n## Environment Variables\n\nYou can set up authentication via **Platform Tokens** (recommended) or **OAuth Client** via the following environment variables:\n\n- `DT_ENVIRONMENT` (string, e.g., `https://abc12345.apps.dynatrace.com`) - URL to your Dynatrace Platform (do not use Dynatrace classic URLs like `abc12345.live.dynatrace.com`)\n- `DT_PLATFORM_TOKEN` (string, e.g., `dt0s16.SAMPLE.abcd1234`) - **Recommended**: Dynatrace Platform Token\n- `OAUTH_CLIENT_ID` (string, e.g., `dt0s02.SAMPLE`) - Alternative: Dynatrace OAuth Client ID (for advanced use cases)\n- `OAUTH_CLIENT_SECRET` (string, e.g., `dt0s02.SAMPLE.abcd1234`) - Alternative: Dynatrace OAuth Client Secret (for advanced use cases)\n- `DT_GRAIL_QUERY_BUDGET_GB` (number, default: `1000`) - Budget limit in GB (base 1000) for Grail query bytes scanned per session. The MCP server tracks your Grail usage and warns when approaching or exceeding this limit.\n\n**Platform Tokens are recommended** for most use cases as they provide a simpler authentication flow. OAuth Clients should only be used when specific OAuth features are required.\n\nFor more information, please have a look at the documentation about\n[creating a Platform Token in Dynatrace](https://docs.dynatrace.com/docs/manage/identity-access-management/access-tokens-and-oauth-clients/platform-tokens), as well as\n[creating an OAuth Client in Dynatrace](https://docs.dynatrace.com/docs/manage/identity-access-management/access-tokens-and-oauth-clients/oauth-clients) for advanced scenarios.\n\nIn addition, depending on the features you use, the following variables can be configured:\n\n- `SLACK_CONNECTION_ID` (string) - connection ID of a [Slack Connection](https://docs.dynatrace.com/docs/analyze-explore-automate/workflows/actions/slack)\n\n### Scopes for Authentication\n\nDepending on the features you are using, the following scopes are needed:\n\n**Available for both Platform Tokens and OAuth Clients:**\n\n- `app-engine:apps:run` - needed for almost all tools\n- `app-engine:functions:run` - needed for for almost all tools\n- `environment-api:entities:read` - for retrieving ownership details from monitored entities (_currently not available for Platform Tokens_)\n- `automation:workflows:read` - read Workflows\n- `automation:workflows:write` - create and update Workflows\n- `automation:workflows:run` - run Workflows\n- `storage:buckets:read` - needed for `execute_dql` tool to read all system data stored on Grail\n- `storage:logs:read` - needed for `execute_dql` tool to read logs for reliability guardian validations\n- `storage:metrics:read` - needed for `execute_dql` tool to read metrics for reliability guardian validations\n- `storage:bizevents:read` - needed for `execute_dql` tool to read bizevents for reliability guardian validations\n- `storage:spans:read` - needed for `execute_dql` tool to read spans from Grail\n- `storage:entities:read` - needed for `execute_dql` tool to read Entities from Grail\n- `storage:events:read` - needed for `execute_dql` tool to read Events from Grail\n- `storage:security.events:read`- needed for `execute_dql` tool to read Security Events from Grail\n- `storage:system:read` - needed for `execute_dql` tool to read System Data from Grail\n- `storage:user.events:read` - needed for `execute_dql` tool to read User events from Grail\n- `storage:user.sessions:read` - needed for `execute_dql` tool to read User sessions from Grail\n- `davis-copilot:conversations:execute` - execute conversational skill (chat with Copilot)\n- `davis-copilot:nl2dql:execute` - execute Davis Copilot Natural Language (NL) to DQL skill\n- `davis-copilot:dql2nl:execute` - execute DQL to Natural Language (NL) skill\n- `email:emails:send` - needed for `send_email` tool to send emails\n- `settings:objects:read` - needed for reading ownership information and Guardians (SRG) from settings\n\n  **Note**: Please ensure that `settings:objects:read` is used, and _not_ the similarly named scope `app-settings:objects:read`.\n\n**Important**: Some features requiring `environment-api:entities:read` will only work with OAuth Clients. For most use cases, Platform Tokens provide all necessary functionality.\n\n## ✨ Example prompts ✨\n\nUse these example prompts as a starting point. Just copy them into your IDE or agent setup, adapt them to your services/stack/architecture,\nand extend them as needed. They're here to help you imagine how real-time observability and automation work together in the MCP context in your IDE.\n\n### **Basic Queries & AI Assistance**\n\n**Find a monitored entity**\n\n```\nGet all details of the entity 'my-service'\n```\n\n**Find error logs**\n\n```\nShow me error logs\n```\n\n**Write a DQL query from natural language:**\n\n```\nShow me error rates for the payment service in the last hour\n```\n\n**Explain a DQL query:**\n\n```\nWhat does this DQL do?\nfetch logs | filter dt.source_entity == 'SERVICE-123' | summarize count(), by:{severity} | sort count() desc\n```\n\n**Chat with Davis CoPilot:**\n\n```\nHow can I investigate slow database queries in Dynatrace?\n```\n\n**Send email notifications:**\n\n```\nSend an email notification about the incident to the responsible team at team@example.com with CC to manager@example.com\n```\n\n### **Advanced Incident Investigation**\n\n**Multi-phase incident response:**\n\n```\nOur checkout service is experiencing high error rates. Start a systematic 4-phase incident investigation:\n1. Detect and triage the active problems\n2. Assess user impact and affected services\n3. Perform cross-data source analysis (problems → spans → logs)\n4. Identify root cause with file/line-level precision\n```\n\n**Cross-service failure analysis:**\n\n```\nWe have cascading failures across our microservices architecture.\nAnalyze the entity relationships and trace the failure propagation from the initial problem\nthrough all downstream services. Show me the correlation timeline.\n```\n\n### **Security & Compliance Analysis**\n\n**Latest-scan vulnerability assessment:**\n\n```\nPerform a comprehensive security analysis using the latest scan data:\n- Check for new vulnerabilities in our production environment\n- Focus on critical and high-severity findings\n- Provide evidence-based remediation paths\n- Generate risk scores with team-specific guidance\n```\n\n**Multi-cloud compliance monitoring:**\n\n```\nRun a compliance assessment across our AWS, Azure, and Kubernetes environments.\nCheck for configuration drift and security posture changes in the last 24 hours.\n```\n\n### **DevOps & SRE Automation**\n\n**Deployment health gate analysis:**\n\n```\nOur latest deployment is showing performance degradation.\nRun deployment health gate analysis with:\n- Golden signals monitoring (Rate, Errors, Duration, Saturation)\n- SLO/SLI validation with error budget calculations\n- Generate automated rollback recommendation if needed\n```\n\n**Infrastructure as Code remediation:**\n\n```\nGenerate Infrastructure as Code templates to remediate the current alert patterns.\nInclude automated scaling policies and resource optimization recommendations.\n```\n\n### **Deep Transaction Analysis**\n\n**Business logic error investigation:**\n\n```\nOur payment processing is showing intermittent failures.\nPerform advanced transaction analysis:\n- Extract exception details with full stack traces\n- Correlate with deployment events and ArgoCD changes\n- Identify the exact code location causing the issue\n```\n\n**Performance correlation analysis:**\n\n```\nAnalyze the performance impact across our distributed system for the slow checkout flow.\nShow me the complete trace analysis with business context and identify bottlenecks.\n```\n\n### **Traditional Use Cases (Enhanced)**\n\n**Find open vulnerabilities on production, setup alert:**\n\n```\nI have this code snippet here in my IDE, where I get a dependency vulnerability warning for my code.\nCheck if I see any open vulnerability/cve on production.\nAnalyze a specific production problem.\nSetup a workflow that sends Slack alerts to the #devops-alerts channel when availability problems occur.\n```\n\n**Debug intermittent 503 errors:**\n\n```\nOur load balancer is intermittently returning 503 errors during peak traffic.\nPull all recent problems detected for our front-end services and\nrun a query to correlate error rates with service instance health indicators.\nI suspect we have circuit breakers triggering, but need confirmation from the telemetry data.\n```\n\n**Correlate memory issue with logs:**\n\n```\nThere's a problem with high memory usage on one of our hosts.\nGet the problem details and then fetch related logs to help understand\nwhat's causing the memory spike? Which file in this repo is this related to?\n```\n\n**Trace request flow analysis:**\n\n```\nOur users are experiencing slow checkout processes.\nCan you execute a DQL query to show me the full request trace for our checkout flow,\nso I can identify which service is causing the bottleneck?\n```\n\n**Analyze Kubernetes cluster events:**\n\n```\nOur application deployments seem to be failing intermittently.\nCan you fetch recent events from our \"production-cluster\"\nto help identify what might be causing these deployment issues?\n```\n\n## Troubleshooting\n\n### Authentication Issues\n\nIn most cases, authentication issues are related to missing scopes or invalid tokens. Please ensure that you have added all required scopes as listed above.\n\n**For Platform Tokens:**\n\n1. Verify your Platform Token has all the necessary scopes listed in the \"Scopes for Authentication\" section\n2. Ensure your token is valid and not expired\n3. Check that your user has the required permissions in your Dynatrace Environment\n\n**For OAuth Clients:**\nIn case of OAuth-related problems, you can troubleshoot SSO/OAuth issues based on our [Dynatrace Developer Documentation](https://developer.dynatrace.com/develop/access-platform-apis-from-outside/#get-bearer-token-and-call-app-function).\n\nIt is recommended to test access with the following API (which requires minimal scopes `app-engine:apps:run` and `app-engine:functions:run`):\n\n1. Use OAuth Client ID and Secret to retrieve a Bearer Token (only valid for a couple of minutes):\n\n```bash\ncurl --request POST 'https://sso.dynatrace.com/sso/oauth2/token' \\\n  --header 'Content-Type: application/x-www-form-urlencoded' \\\n  --data-urlencode 'grant_type=client_credentials' \\\n  --data-urlencode 'client_id={your-client-id}' \\\n  --data-urlencode 'client_secret={your-client-secret}' \\\n  --data-urlencode 'scope=app-engine:apps:run app-engine:functions:run'\n```\n\n2. Use `access_token` from the response of the above call as the bearer-token in the next call:\n\n```bash\ncurl -X GET https://abc12345.apps.dynatrace.com/platform/management/v1/environment \\\n  -H 'accept: application/json' \\\n  -H 'Authorization: Bearer {your-bearer-token}'\n```\n\n3. You should retrieve a result like this:\n\n```json\n{\n  \"environmentId\": \"abc12345\",\n  \"createTime\": \"2023-01-01T00:10:57.123Z\",\n  \"blockTime\": \"2025-12-07T00:00:00Z\",\n  \"state\": \"ACTIVE\"\n}\n```\n\n### Problem accessing data on Grail\n\nGrail has a dedicated section about permissions in the Dynatrace Docs. Please refer to https://docs.dynatrace.com/docs/discover-dynatrace/platform/grail/data-model/assign-permissions-in-grail for more details.\n\n## Telemetry\n\nThe Dynatrace MCP Server includes sending Telemetry Data via Dynatrace OpenKit to help improve the product. This includes:\n\n- Server start events\n- Tool usage (which tools are called, success/failure, execution duration)\n- Error tracking for debugging and improvement\n\n**Privacy and Opt-out:**\n\n- Telemetry is **enabled by default** but can be disabled by setting `DT_MCP_DISABLE_TELEMETRY=true`\n- No sensitive data from your Dynatrace environment is tracked\n- Only anonymous usage statistics and error information are collected\n- Usage statistics and error data are transmitted to Dynatrace’s analytics endpoint\n\n**Configuration options:**\n\n- `DT_MCP_DISABLE_TELEMETRY` (boolean, default: `false`) - Disable Telemetry\n- `DT_MCP_TELEMETRY_APPLICATION_ID` (string, default: `dynatrace-mcp-server`) - Application ID for tracking\n- `DT_MCP_TELEMETRY_ENDPOINT_URL` (string, default: Dynatrace endpoint) - OpenKit endpoint URL\n- `DT_MCP_TELEMETRY_DEVICE_ID` (string, default: auto-generated) - Device identifier for tracking\n\nTo disable usage tracking, add this to your environment:\n\n```bash\nDT_MCP_DISABLE_TELEMETRY=true\n```\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "dynatrace",
        "logging",
        "monitoring",
        "logging dynatrace",
        "monitoring development",
        "oss dynatrace"
      ],
      "category": "monitoring-and-logging"
    },
    "ghrud92--simple-loki-mcp": {
      "owner": "ghrud92",
      "name": "simple-loki-mcp",
      "url": "https://github.com/ghrud92/simple-loki-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/ghrud92.webp",
      "description": "Query and analyze Grafana Loki logs with full LogQL support to access log data directly from AI assistants. Simplifies log management by providing formatted results in various output formats and supporting metadata retrieval.",
      "stars": 5,
      "forks": 4,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-18T22:04:21Z",
      "readme_content": "# Simple Loki MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@ghrud92/simple-loki-mcp)](https://smithery.ai/server/@ghrud92/simple-loki-mcp)\n\nLoki MCP Server is a [Model Context Protocol (MCP)](https://github.com/modelcontextprotocol/mcp) interface for querying Grafana Loki logs using `logcli`. The server enables AI assistants to access and analyze log data from Loki directly.\n\n<a href=\"https://glama.ai/mcp/servers/@ghrud92/loki-mcp\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@ghrud92/loki-mcp/badge\" alt=\"Loki Server MCP server\" />\n</a>\n\n## Features\n\n- Query Loki logs with full LogQL support\n- Get label values and metadata\n- Authentication and configuration support via environment variables or config files\n- Provides formatted results in different output formats (default, raw, JSON lines)\n- Automatic fallback to HTTP API when `logcli` is not available in the environment\n\n## Prerequisites\n\n- Node.js v16 or higher\n- TypeScript\n- (Optional) [Grafana Loki logcli](https://grafana.com/docs/loki/latest/tools/logcli/) installed and accessible in your PATH. If `logcli` is not available, the server will automatically use the Loki HTTP API instead\n- Access to a Loki server instance\n\n## Installation\n\n### Installing via Smithery\n\nTo install Simple Loki MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@ghrud92/simple-loki-mcp):\n\n```bash\nnpx -y @smithery/cli install @ghrud92/simple-loki-mcp --client claude\n```\n\n### for MCP\n\n```json\n{\n  \"mcpServers\": {\n    \"simple-loki\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"simple-loki-mcp\"],\n      \"env\": {\n        \"LOKI_ADDR\": \"https://loki.sup.band\"\n      }\n    }\n  }\n}\n```\n\n### npm\n\n1. Clone the repository:\n\n```bash\ngit clone https://github.com/ghrud92/loki-mcp.git\ncd loki-mcp\n```\n\n2. Install dependencies:\n\n```bash\nnpm install\n```\n\n3. Build the project:\n\n```bash\nnpm run build\n```\n\n## Available MCP Tools\n\n### query-loki\n\nQuery logs from Loki with filtering options.\n\nParameters:\n\n- `query` (required): Loki query string (LogQL)\n- `from`: Start timestamp (e.g. \"2023-01-01T12:00:00Z\")\n- `to`: End timestamp (e.g. \"2023-01-01T13:00:00Z\")\n- `limit`: Maximum number of logs to return\n- `batch`: Batch size for query results\n- `output`: Output format (\"default\", \"raw\", or \"jsonl\")\n- `quiet`: Suppress query metadata\n- `forward`: Display results in chronological order\n\n### get-label-values\n\nRetrieve all values for a specific label.\n\nParameters:\n\n- `label` (required): Label name to get values for\n\n### get-labels\n\nRetrieve all available labels.\n\nNo parameters required.\n\n## Configuration\n\nYou can configure Loki access using:\n\n### Environment Variables\n\n- `LOKI_ADDR`: Loki server address (URL)\n- `LOKI_USERNAME`: Username for basic auth\n- `LOKI_PASSWORD`: Password for basic auth\n- `LOKI_TENANT_ID`: Tenant ID for multi-tenant Loki\n- `LOKI_BEARER_TOKEN`: Bearer token for authentication\n- `LOKI_BEARER_TOKEN_FILE`: File containing bearer token\n- `LOKI_CA_FILE`: Custom CA file for TLS\n- `LOKI_CERT_FILE`: Client certificate file for TLS\n- `LOKI_KEY_FILE`: Client key file for TLS\n- `LOKI_ORG_ID`: Organization ID for multi-org setups\n- `LOKI_TLS_SKIP_VERIFY`: Skip TLS verification (\"true\" or \"false\")\n- `LOKI_CONFIG_PATH`: Custom path to config file\n- `DEBUG`: Enable debug logging\n\n> **Note**: When the client is using the HTTP API mode (when `logcli` is not available), the same configuration parameters are used to authenticate and connect to the Loki server.\n\n### Config Files\n\nAlternatively, create a `logcli-config.yaml` file in one of these locations:\n\n- Custom path specified by `LOKI_CONFIG_PATH`\n- Current working directory\n- Your home directory (`~/.logcli-config.yaml`)\n\nExample config file:\n\n```yaml\naddr: https://loki.example.com\nusername: user\npassword: pass\ntenant_id: mytenant\n```\n\n## Usage\n\nStart the server:\n\n```bash\nnpm start\n```\n\nFor development:\n\n```bash\nnpm run dev\n```\n\n## Implementation Details\n\n### Automatic Fallback to HTTP API\n\nThe server will automatically check if `logcli` is installed and available in the environment:\n\n1. If `logcli` is available, it will be used for all queries, providing the full functionality of the CLI tool\n2. If `logcli` is not available, the server will automatically fall back to using the Loki HTTP API:\n   - No additional configuration is needed\n   - The same authentication parameters are used for the HTTP API\n   - Response formatting is consistent with the CLI output\n   - Default limit of 1000 logs per query is applied in both modes\n\nThis automatic detection ensures that the server works seamlessly in different environments without manual configuration.\n\n## Development\n\n```bash\n# Run linter\nnpm run lint\n\n# Fix linting issues\nnpm run lint:fix\n\n# Run tests\nnpm run test\n```\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "logging",
        "logs",
        "logql",
        "log data",
        "loki logs",
        "monitoring logging"
      ],
      "category": "monitoring-and-logging"
    },
    "imprvhub--mcp-status-observer": {
      "owner": "imprvhub",
      "name": "mcp-status-observer",
      "url": "https://github.com/imprvhub/mcp-status-observer",
      "imageUrl": "/freedevtools/mcp/pfp/imprvhub.webp",
      "description": "Monitor and query the operational status of major digital platforms in real-time, providing detailed information about specific services and components. Enables users to stay informed about platform health and respond to service disruptions promptly.",
      "stars": 5,
      "forks": 5,
      "license": "Mozilla Public License 2.0",
      "language": "TypeScript",
      "updated_at": "2025-09-14T04:13:39Z",
      "readme_content": "# MCP Status Observer\n[![Verified on MseeP](https://mseep.ai/badge.svg)](https://mseep.ai/app/d7d5a94b-3378-479b-b5a3-35efa8904d2e) [![Trust Score](https://archestra.ai/mcp-catalog/api/badge/quality/imprvhub/mcp-status-observer)](https://archestra.ai/mcp-catalog/imprvhub__mcp-status-observer)\n[![smithery badge](https://smithery.ai/badge/@imprvhub/mcp-status-observer)](https://smithery.ai/server/@imprvhub/mcp-status-observer)\n\n<table style=\"border-collapse: collapse; width: 100%; table-layout: fixed;\">\n<tr>\n<td style=\"padding: 15px; vertical-align: middle; border: none; text-align: center;\">\n  <a href=\"https://mseep.ai/app/imprvhub-mcp-status-observer\">\n    <img src=\"https://mseep.net/pr/imprvhub-mcp-status-observer-badge.png\" alt=\"MseeP.ai Security Assessment Badge\" />\n  </a>\n</td>\n<td style=\"width: 40%; padding: 15px; vertical-align: middle; border: none;\">An integration that allows Claude Desktop to monitor and query the operational status of major digital platforms including AI providers, cloud services, and developer tools using the Model Context Protocol (MCP).</td>\n<td style=\"width: 60%; padding: 0; vertical-align: middle; border: none; min-width: 300px; text-align: center;\">\n  <a href=\"https://glama.ai/mcp/servers/@imprvhub/mcp-status-observer\">\n    <img style=\"max-width: 100%; height: auto; min-width: 300px;\" src=\"https://glama.ai/mcp/servers/@imprvhub/mcp-status-observer/badge\" alt=\"Status Observer MCP server\" />\n  </a>\n</td>\n\n</tr>\n</table>\n\n> [!IMPORTANT]\n> This project is continuously updated with new platform integrations. If you're not seeing a service that should be available, or if Claude doesn't recognize a platform, please update by running `npm run build` from a freshly cloned repository. \n> \n> **Last updated**: 2025-09-12T07:22:15Z (UTC) - Added OpenRouter status integration with RSS incident tracking\n\n## Features\n\n- Monitor world's most used digital platforms (GitHub, Slack, Discord, etc.)\n- Track AI providers including OpenRouter, OpenAI, Anthropic, and Gemini\n- Get detailed status information for specific services with incident history\n- Check status of specific components within each platform\n- Real-time updates of service status with impact analysis\n- Comprehensive incident tracking with resolution status and timelines\n- Simple query interface with commands like `status --openrouter`\n\n## Demo\n\n<p>\n  <a href=\"https://www.youtube.com/watch?v=EV1ac0PMzKg\">\n    \n  </a>\n</p>\n\n<details>\n<summary> Timestamps </summary>\n\nClick on any timestamp to jump to that section of the video\n\n[**00:00**](https://www.youtube.com/watch?v=EV1ac0PMzKg&t=0s) - **LinkedIn Platform Status Assessment**  \nComprehensive analysis of LinkedIn's operational health, including detailed examination of core services such as LinkedIn.com, LinkedIn Learning, Campaign Manager, Sales Navigator, Recruiter, and Talent solutions. All systems confirmed fully operational with zero service disruptions.\n\n[**00:20**](https://www.youtube.com/watch?v=EV1ac0PMzKg&t=20s) - **GitHub Infrastructure Status Overview**  \nDetailed evaluation of GitHub's service availability, covering critical components including Git operations, API requests, Actions, Webhooks, Issues, Pull Requests, Packages, Pages, Codespaces, and Copilot functionality. Complete operational status confirmed across all GitHub services.\n\n[**00:40**](https://www.youtube.com/watch?v=EV1ac0PMzKg&t=40s) - **Vercel Platform Reliability Analysis**  \nIn-depth examination of Vercel's global edge network and deployment infrastructure, featuring comprehensive status reporting on core services such as API, Dashboard, Builds, Serverless Functions, Edge Functions, and global CDN locations. All Vercel services verified operational across all regions.\n\n[**01:08**](https://www.youtube.com/watch?v=EV1ac0PMzKg&t=68s) - **Cloudflare Network Status Examination**  \nExtensive analysis of Cloudflare's global infrastructure status, detailing service availability across geographic regions and specific service components. Identified performance degradation in multiple regions (Africa, Asia, Europe, Latin America, Middle East, North America) while core services remain functional. Includes detailed assessment of regional data centers under maintenance and technical impact analysis.\n\n[**01:46**](https://www.youtube.com/watch?v=EV1ac0PMzKg&t=106s) - **Global Operational Status Report**  \nConsolidated overview of operational status across all major technology platforms and service providers, highlighting both fully operational services (GitHub, Vercel, Netlify, Asana, Atlassian, OpenRouter, etc.) and services experiencing degraded performance (Cloudflare, Twilio). Includes strategic recommendations for organizations with dependencies on affected services.\n</details>\n\n## Requirements\n\n- Node.js 16 or higher\n- Claude Desktop\n- Internet connection to access status APIs\n\n## Installation\n\n### Installing Manually\n1. Clone or download this repository:\n```bash\ngit clone https://github.com/imprvhub/mcp-status-observer\ncd mcp-status-observer\n```\n\n2. Install dependencies:\n```bash\nnpm install\n```\n\n3. Build the project:\n```bash\nnpm run build\n```\n\n## Running the MCP Server\n\nThere are two ways to run the MCP server:\n\n### Option 1: Running manually\n\n1. Open a terminal or command prompt\n2. Navigate to the project directory\n3. Run the server directly:\n\n```bash\nnode build/index.js\n```\n\nKeep this terminal window open while using Claude Desktop. The server will run until you close the terminal.\n\n### Option 2: Auto-starting with Claude Desktop (recommended for regular use)\n\nThe Claude Desktop can automatically start the MCP server when needed. To set this up:\n\n#### Configuration\n\nThe Claude Desktop configuration file is located at:\n\n- **macOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`\n- **Windows**: `%APPDATA%\\Claude\\claude_desktop_config.json`\n- **Linux**: `~/.config/Claude/claude_desktop_config.json`\n\nEdit this file to add the Status Observer MCP configuration. If the file doesn't exist, create it:\n\n```json\n{\n  \"mcpServers\": {\n    \"statusObserver\": {\n      \"command\": \"node\",\n      \"args\": [\"ABSOLUTE_PATH_TO_DIRECTORY/mcp-status-observer/build/index.js\"]\n    }\n  }\n}\n```\n\n**Important**: Replace `ABSOLUTE_PATH_TO_DIRECTORY` with the **complete absolute path** where you installed the MCP\n  - macOS/Linux example: `/Users/username/mcp-status-observer`\n  - Windows example: `C:\\\\Users\\\\username\\\\mcp-status-observer`\n\nIf you already have other MCPs configured, simply add the \"statusObserver\" section inside the \"mcpServers\" object. Here's an example of a configuration with multiple MCPs:\n\n```json\n{\n  \"mcpServers\": {\n    \"otherMcp1\": {\n      \"command\": \"...\",\n      \"args\": [\"...\"]\n    },\n    \"otherMcp2\": {\n      \"command\": \"...\",\n      \"args\": [\"...\"]\n    },\n    \"statusObserver\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"ABSOLUTE_PATH_TO_DIRECTORY/mcp-status-observer/build/index.js\"\n      ]\n    }\n  }\n}\n```\n\nThe MCP server will automatically start when Claude Desktop needs it, based on the configuration in your `claude_desktop_config.json` file.\n\n## Usage\n\n1. Restart Claude Desktop after modifying the configuration\n2. In Claude, use the `status` command to interact with the Status Observer MCP Server\n3. The MCP server runs as a subprocess managed by Claude Desktop\n\n## Available Commands\n\nThe Status Observer MCP provides a single tool named `status` with several commands:\n\n| Command | Description | Parameters | Example |\n|---------|-------------|------------|---------|\n| `list` | List all available platforms | None | `status list` |\n| `--[platform]` | Get status for a specific platform | Platform name | `status --openrouter` |\n| `--all` | Get status for all platforms | None | `status --all` |\n\n## Supported Platforms\n\nThe Status Observer monitors 22 major digital platforms across various categories:\n\n### AI & Machine Learning (4)\n- **OpenRouter** - AI model routing and access platform\n- **OpenAI** - Leading AI services provider (ChatGPT, DALL-E, API)\n- **Anthropic** - AI assistant provider (Claude)\n- **Gemini** - Google's multimodal AI platform\n\n### Cloud Infrastructure (4)\n- **Google Cloud Platform** - Comprehensive cloud computing services\n- **DigitalOcean** - Developer-focused cloud infrastructure\n- **Vercel** - Frontend deployment and edge platform\n- **Netlify** - Web development and deployment platform\n\n### Developer Tools & Platforms (5)\n- **Docker** - Container platform and services\n- **GitHub** - Version control and collaboration platform\n- **npm** - JavaScript package manager and registry\n- **Atlassian** - Developer collaboration tools (Jira, Bitbucket, Confluence)\n- **Supabase** - Open source backend platform (PostgreSQL, auth, storage)\n\n### Productivity & Collaboration (5)\n- **LinkedIn** - Professional networking platform\n- **Slack** - Business communication and collaboration\n- **Asana** - Team workflow and project management\n- **Dropbox** - Cloud file storage and collaboration\n- **X (Twitter)** - Social media and real-time communication\n\n### Web Infrastructure & Security (3)\n- **Cloudflare** - Web infrastructure, CDN, and security\n- **Discord** - Developer community and communication platform\n- **Reddit** - Social news and developer community platform\n\n### Analytics & Business Tools (1)\n- **Amplitude** - Product analytics platform\n\n## Example Usage\n\nHere are various examples of how to use the Status Observer with Claude:\n\n### Direct Commands:\n\n```\n# AI Platforms\nstatus --openrouter\nstatus --openai\nstatus --anthropic\nstatus --gemini\n\n# Cloud Infrastructure\nstatus --gcp\nstatus --vercel\nstatus --digitalocean\nstatus --netlify\n\n# Developer Tools\nstatus --docker\nstatus --github\nstatus --atlassian\nstatus --supabase\nstatus --npm\n\n# Productivity & Social\nstatus --linkedin\nstatus --slack\nstatus --x\nstatus --dropbox\n\n# Web Infrastructure\nstatus --cloudflare\nstatus --discord\n\n# All platforms\nstatus --all\nstatus list\n```\n\n### Preview\n![OpenRouter Status Monitoring Preview](https://github.com/imprvhub/mcp-status-observer/raw/main/public/assets/openrouter.png)\n![GCP Status Monitoring Preview](https://github.com/imprvhub/mcp-status-observer/raw/main/public/assets/gcp.png)\n\n### Natural Language Prompts:\n\nYou can also interact with the MCP using natural language. Claude will interpret these requests and use the appropriate commands:\n\n- \"Could you check if OpenRouter is having any API issues right now?\"\n- \"What's the status of OpenAI's ChatGPT service?\"\n- \"Has there been any recent incidents with Claude or the Anthropic API?\"\n- \"Is Google Cloud Platform experiencing any outages in my region?\"\n- \"Check if Docker Hub is operational for automated builds\"\n- \"What's the current status of LinkedIn's Sales Navigator?\"\n- \"Can you tell me if Google's Gemini AI is experiencing any service disruptions?\"\n- \"Show me the status of all AI platforms including OpenRouter and OpenAI\"\n- \"Are there any active incidents affecting GitHub Actions or Git operations?\"\n- \"Check the overall health of Vercel and Netlify for my deployment pipeline\"\n- \"Has Supabase had any recent database or authentication issues?\"\n- \"What's the status of all major platforms right now?\"\n\n\n## Troubleshooting\n\n### \"Server disconnected\" error\nIf you see the error \"MCP Status Observer: Server disconnected\" in Claude Desktop:\n\n1. **Verify the server is running**:\n   - Open a terminal and manually run `node build/index.js` from the project directory\n   - If the server starts successfully, use Claude while keeping this terminal open\n\n2. **Check your configuration**:\n   - Ensure the absolute path in `claude_desktop_config.json` is correct for your system\n   - Double-check that you've used double backslashes (`\\\\`) for Windows paths\n   - Verify you're using the complete path from the root of your filesystem\n\n### Tools not appearing in Claude\nIf the Status Observer tools don't appear in Claude:\n- Make sure you've restarted Claude Desktop after configuration\n- Check the Claude Desktop logs for any MCP communication errors\n- Ensure the MCP server process is running (run it manually to confirm)\n- Verify that the MCP server is correctly registered in the Claude Desktop MCP registry\n\n### Checking if the server is running\nTo check if the server is running:\n\n- **Windows**: Open Task Manager, go to the \"Details\" tab, and look for \"node.exe\"\n- **macOS/Linux**: Open Terminal and run `ps aux | grep node`\n\nIf you don't see the server running, start it manually or use the auto-start method.\n\n## Contributing\n\n### Adding New Status APIs\n\nContributors can easily add support for additional platforms by modifying the `initializePlatforms` method in `src/index.ts`. The process is straightforward:\n\n1. Identify a platform's status API endpoint\n2. Add a new entry using the `addPlatform` method with the following parameters:\n   - `id`: A unique identifier for the platform (lowercase, no spaces)\n   - `name`: The display name of the platform\n   - `url`: The status API endpoint URL\n   - `description`: A brief description of the platform\n\nExample:\n```typescript\nthis.addPlatform('newservice', 'New Service', 'https://status.newservice.com/api/v2/summary.json', 'Description of the service');\n```\n\n### Custom API Integration\n\nFor platforms with non-standard status pages (like OpenRouter, OpenAI, Anthropic), you can create custom handlers:\n\n1. Add the platform to `initializePlatforms()`\n2. Create a TypeScript interface for the response format\n3. Add a specific handler method like `getOpenRouterStatus()`\n4. Update the main `getPlatformStatus()` method to route to your handler\n5. Add quick status support in `getQuickPlatformStatus()`\n\nExample structure for custom handlers:\n```typescript\nprivate async getCustomPlatformStatus(platform: PlatformStatus): Promise<string> {\n  // Custom parsing logic for your platform\n  // Return formatted status text\n}\n```\n\n### Platform Categories\n\nWhen adding new platforms, consider organizing them into logical categories:\n- **AI/ML**: OpenRouter, OpenAI, Anthropic, Gemini\n- **Cloud Infrastructure**: GCP, AWS, Azure, DigitalOcean\n- **Developer Tools**: GitHub, GitLab, Docker, npm\n- **Productivity**: Slack, Microsoft 365, Google Workspace\n- **Web Infrastructure**: Cloudflare, Fastly, Akamai\n\n## License\n\nThis project is licensed under the Mozilla Public License 2.0 - see the [LICENSE](https://github.com/imprvhub/mcp-claude-hackernews/blob/main/LICENSE) file for details.\n\n## Related Links\n\n- [Model Context Protocol](https://modelcontextprotocol.io/)\n- [Claude Desktop](https://claude.ai/download)\n- [MCP Series](https://github.com/mcp-series)\n\n## Changelog\n\n- **2025-09-12**: Added OpenRouter integration with RSS incident tracking and detailed impact analysis\n- **2025-04-26**: Added Docker status integration with comprehensive component monitoring\n- **2025-03-15**: Enhanced GCP regional status reporting with incident correlation\n- **2025-02-28**: Added Anthropic and Gemini AI platform monitoring\n- **2025-01-20**: Initial release with core platform support (GitHub, Vercel, Cloudflare, etc.)\n\n---\n\n*Built for the developer community by [imprvhub](https://github.com/imprvhub)*",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "monitoring",
        "imprvhub",
        "logging",
        "imprvhub mcp",
        "logging imprvhub",
        "status observer"
      ],
      "category": "monitoring-and-logging"
    },
    "jakenuts--mcp-solarwinds": {
      "owner": "jakenuts",
      "name": "mcp-solarwinds",
      "url": "https://github.com/jakenuts/mcp-solarwinds",
      "imageUrl": "/freedevtools/mcp/pfp/jakenuts.webp",
      "description": "Access and visualize SolarWinds Observability logs with advanced filtering capabilities and generate insights through real-time log analysis and reporting. Supports timestamped log entry retrieval, including advanced filtering options by group and entity.",
      "stars": 1,
      "forks": 2,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-06-28T20:37:09Z",
      "readme_content": "# SolarWinds Logs MCP Server\n\nA Model Context Protocol (MCP) server for accessing and visualizing SolarWinds Observability logs.\n\n## Note - \n\nThis server is currently incomplete as it does not support \nstructured data search (a limitation of the REST API?). I'm\nuncertain if it also needs to accept a data center to use\nin the api endpoint calls. Will address both when time allows \n(needed it for a real work problem, have to fix that first)\n\n### Tools\n\n#### search_logs\nSearch SolarWinds Observability logs with optional filtering\n- Takes search parameters including filter, time range, and pagination options\n- Returns formatted log entries with timestamps, hostnames, and messages\n- Supports advanced filtering by group, entity, and more\n- Default search range is the last 24 hours\n\n#### visualize_logs\nGenerate a histogram json response for of log events\n- Formatted for Claude and canvas representations\n- Configurable time intervals (minute, hour, day)\n- Supports UTC or local time zones\n- Customizable query filters and time ranges\n- Default visualization range is the last 24 hours\n\n### Resources\n\n#### SolarWinds Log Search\n- URI Template: `solarwinds://{query}/search`\n- Returns log entries matching the specified query\n- Example: `solarwinds://error/search`\n\n## Installation\n\nOptionally install from npm:\n```bash\nnpm install -g mcp-solarwinds\n```\n\nOr clone and build from source:\n```bash\ngit clone https://github.com/@jakenuts/mcp-solarwinds.git\ncd mcp-solarwinds\nnpm install\nnpm run build\n```\nOr just use npx in your configurations\n\n### For Cline VSCode Extension\n\nAdd to `%APPDATA%/Code - Insiders/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"solarwinds\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"mcp-solarwinds\"],\n      \"env\": {\n        \"SOLARWINDS_API_TOKEN\": \"your-api-token\"\n      },\n      \"autoApprove\": [\"search_logs\", \"visualize_logs\"]\n    }\n  }\n}\n```\n\n### For Claude Desktop\n\nAdd to the appropriate config file:\n\nWindows: `%APPDATA%/Claude/claude_desktop_config.json`\nMacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"solarwinds\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"mcp-solarwinds\"],\n      \"env\": {\n        \"SOLARWINDS_API_TOKEN\": \"your-api-token\"\n      }\n    }\n  }\n}\n```\n\n### Special Windows Configuration\n\nIf you encounter the ENOENT spawn npx issue on Windows, use this alternative configuration that specifies the full paths:\n\n```json\n{\n  \"mcpServers\": {\n    \"solarwinds\": {\n      \"command\": \"C:\\\\Users\\\\[username]\\\\AppData\\\\Roaming\\\\nvm\\\\[node-version]\\\\node.exe\",\n      \"args\": [\n        \"C:\\\\Users\\\\[username]\\\\AppData\\\\Roaming\\\\npm\\\\node_modules\\\\npm\\\\bin\\\\npx-cli.js\",\n        \"-y\",\n        \"mcp-solarwinds\"\n      ],\n      \"env\": {\n        \"SOLARWINDS_API_TOKEN\": \"your-api-token\"\n      }\n    }\n  }\n}\n```\n\n## Configuration\n\nThe SolarWinds Observability MCP server requires an API token to authenticate with the SolarWinds Observability API.\n\n### Configuration Methods\n\nThere are multiple ways to provide the API token:\n\n1. **MCP Settings Configuration (Recommended)**: Configure the token in your MCP settings file\n2. **Environment Variable**: Set the `SOLARWINDS_API_TOKEN` environment variable\n3. **Local .env File (For Testing)**: Create a `.env` file in the project root with `SOLARWINDS_API_TOKEN=your-token`\n\nFor local testing, you can:\n1. Copy `.env.example` to `.env` and add your token\n2. Run the example script: `node examples/local-test.js`\n\n## Tool Usage Examples\n\n### search_logs\n\nBasic search:\n```json\n{\n  \"filter\": \"error\"\n}\n```\n\nAdvanced search with time range and pagination:\n```json\n{\n  \"filter\": \"error\",\n  \"entityId\": \"web-server\",\n  \"startTime\": \"2025-03-01T00:00:00Z\",\n  \"endTime\": \"2025-03-05T23:59:59Z\",\n  \"pageSize\": 100,\n  \"direction\": \"backward\"\n}\n```\n\n### visualize_logs\n\nBasic histogram (ASCII chart):\n```json\n{\n  \"filter\": \"error\",\n  \"interval\": \"hour\"\n}\n```\n\nAdvanced visualization (ASCII chart):\n```json\n{\n  \"filter\": \"error\",\n  \"entityId\": \"web-server\",\n  \"startTime\": \"2025-03-01T00:00:00Z\",\n  \"endTime\": \"2025-03-05T23:59:59Z\",\n  \"interval\": \"day\",\n  \"use_utc\": true\n}\n```\n\nClaude visualization (JSON format):\n```json\n{\n  \"filter\": \"error\",\n  \"interval\": \"hour\",\n  \"format\": \"json\"\n}\n```\n\nThe JSON format returns data that Claude can visualize as a chart:\n```json\n{\n  \"timeRanges\": [\"12:02\", \"12:03\", \"12:04\", \"12:05\", \"12:06\", \"12:07\", \"12:08\", \"12:09\"],\n  \"counts\": [261, 47, 48, 48, 31, 262, 270, 33],\n  \"total\": 1000,\n  \"queryParams\": {\n    \"query\": \"error\",\n    \"startTime\": \"2025-03-05T00:00:00.000Z\",\n    \"endTime\": \"2025-03-05T23:59:59.000Z\"\n  }\n}\n```\n\n## Development\n\nInstall dependencies:\n```bash\nnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n```\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. The MCP Inspector provides helpful debugging tools:\n\n```bash\nnpm run debug:inspector\n```\n\nThis will provide a URL to access the inspector in your browser, where you can:\n- View all MCP messages\n- Inspect request/response payloads\n- Test tools interactively\n- Monitor server state\n\nFor local testing without the MCP framework:\n```bash\n# Create a .env file with your token\ncp .env.example .env\n# Edit .env to add your token\n# Run the example script\nnode examples/local-test.js\n```\n\n## Technical Details\n\n- Built with TypeScript and the MCP SDK\n- Uses axios for API communication\n- Supports ISO 8601 date formats for time ranges\n- Generates ASCII histograms for log visualization\n- Default search range: last 24 hours\n- Default page size: 50 logs\n- Supports multiple authentication methods\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "logging",
        "logs",
        "solarwinds",
        "monitoring logging",
        "observability logs",
        "solarwinds observability"
      ],
      "category": "monitoring-and-logging"
    },
    "jkosik--mcp-server-splunk": {
      "owner": "jkosik",
      "name": "mcp-server-splunk",
      "url": "https://github.com/jkosik/mcp-server-splunk",
      "imageUrl": "/freedevtools/mcp/pfp/jkosik.webp",
      "description": "Implements MCP Tools for managing Splunk resources including saved searches, alerts, and fired alerts. Supports STDIO and SSE transports for flexible deployment and interaction with Splunk data.",
      "stars": 6,
      "forks": 3,
      "license": "No License",
      "language": "Go",
      "updated_at": "2025-10-01T13:32:44Z",
      "readme_content": "# MCP Server for Splunk\n\nA Go implementation of the MCP server for Splunk.\nSupports STDIO and SSE (Server-Sent Events HTTP API). Uses github.com/mark3labs/mcp-go SDK.\n\n## MCP Tools implemented\n- `list_splunk_saved_searches`\n    - Parameters:\n        - `count` (number, optional): Number of results to return (max 100, default 100)\n        - `offset` (number, optional): Offset for pagination (default 0)\n- `list_splunk_alerts`\n    - Parameters:\n        - `count` (number, optional): Number of results to return (max 100, default 10)\n        - `offset` (number, optional): Offset for pagination (default 0)\n        - `title` (string, optional): Case-insensitive substring to filter alert titles\n- `list_splunk_fired_alerts`\n    - Parameters:\n        - `count` (number, optional): Number of results to return (max 100, default 10)\n        - `offset` (number, optional): Offset for pagination (default 0)\n        - `ss_name` (string, optional): Search name pattern to filter alerts (default \"*\")\n        - `earliest` (string, optional): Time range to look back (default \"-24h\")\n- `list_splunk_indexes`\n    - Parameters:\n        - `count` (number, optional): Number of results to return (max 100, default 10)\n        - `offset` (number, optional): Offset for pagination (default 0)\n- `list_splunk_macros`\n    - Parameters:\n        - `count` (number, optional): Number of results to return (max 100, default 10)\n        - `offset` (number, optional): Offset for pagination (default 0)\n\n## MCP Prompts and Resources\n- `internal/splunk/prompt.go` implements an MCP Prompt to find Splunk alerts for a specific keyword (e.g. GitHub or OKTA) and instructs Cursor to utilise multiple MCP tools to review all Splunk alerts, indexes and macros first to provide the best answer.\n- `cmd/mcp/server/main.go` implements MCP Resource in the form of local CSV file with Splunk related content, providing further context to the chat.\n\n## Usage\n### STDIO mode (default)\n```bash\nexport SPLUNK_URL=https://your-splunk-instance:8089\nexport SPLUNK_TOKEN=your-splunk-token\n\n# List available tools\necho '{\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"tools/list\",\"params\":{}}' | go run cmd/mcp-server-splunk/main.go | jq\n\n# Call list_splunk_saved_searches tool\necho '{\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"tools/call\",\"params\":{\"name\":\"list_splunk_saved_searches\",\"arguments\":{}}}' | go run cmd/mcp-server-splunk/main.go | jq\n```\n\n## SSE mode (Server-Sent Events HTTP API)\n```bash\nexport SPLUNK_URL=https://your-splunk-instance:8089\nexport SPLUNK_TOKEN=your-splunk-token\n\n# Start the server\ngo run cmd/mcp-server-splunk/main.go -transport sse -port 3001\n\n# Call the server and get Session ID from the output. Do not terminate the session.\ncurl http://localhost:3001/sse\n\n# Keep session running and and use different terminal window for the final MCP call\ncurl -X POST \"http://localhost:3001/message?sessionId=YOUR_SESSION_ID\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"tools/list\",\"params\":{}}' | jq\n```\n\n## Installing via Smithery\n[![smithery badge](https://smithery.ai/badge/@jkosik/mcp-server-splunk)](https://smithery.ai/server/@jkosik/mcp-server-splunk)\n\n`Dockerfile` and `smithery.yaml` are used to support hosting this MCP server at [Smithery](https://smithery.ai/server/@jkosik/.\n\n\n### Local Docker build and run\n```\ndocker build -t mcp-server-splunk .\n\necho '{\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"tools/list\",\"params\":{}}' | \\\ndocker run --rm -i \\\n  -e SPLUNK_URL=https://your-splunk-instance:8089 \\\n  -e SPLUNK_TOKEN=your-splunk-token \\\n  mcp-server-splunk | jq\n```\n\n## Cursor integration\nBy configuring MCP Settings in Cursor, you can include remote data directly into the LLM context.\n\n\n\nIntegrate STDIO or SSE MCP Servers (see below) and use Cursor Chat.\nCursor will automatically try to use MCP Tools, Prompts or Re\nSample prompts:\n- `How many MCP tools for Splunk are available?`\n- `How many Splunk indexes do we have?`\n- `Can you list first 5 Splunk macros including underlying queries?`\n- `How many alers with \"Alert_CRITICAL\" in the name were fired in the last day?`\n- `Read the MCP Resource \"Data Dictionary\" and find the contact person for the Splunk index XYZ.`\n\n### STDIO mode\nBuild the server:\n```\ngo build -o cmd/mcp-server-splunk/mcp-server-splunk cmd/mcp-server-splunk/main.go\n```\n\nUpdate `~/.cursor/mcp.json`\n```json\n{\n  \"mcpServers\": {\n    \"splunk_stdio\": {\n      \"name\": \"Splunk MCP Server (STDIO)\",\n      \"description\": \"MCP server for Splunk integration\",\n      \"type\": \"stdio\",\n      \"command\": \"/Users/juraj/data/github.com/jkosik/mcp-server-splunk/cmd/mcp-server-splunk/mcp-server-splunk\",\n      \"env\": {\n        \"SPLUNK_URL\": \"https://your-splunk-instance:8089\",\n        \"SPLUNK_TOKEN\": \"your-splunk-token\"\n      }\n    }\n  }\n}\n```\n\n### SSE mode\nStart the server:\n```bash\nexport SPLUNK_URL=https://your-splunk-instance:8089\nexport SPLUNK_TOKEN=your-splunk-token\n\n# Start the server\ngo run cmd/mcp-server-splunk/main.go -transport sse -port 3001\n```\n\nUpdate `~/.cursor/mcp.json`\n```json\n{\n  \"mcpServers\": {\n    \"splunk_sse\": {\n      \"name\": \"Splunk MCP Server (SSE)\",\n      \"description\": \"MCP server for Splunk integration (SSE mode)\",\n      \"type\": \"sse\",\n      \"url\": \"http://localhost:3001/sse\"\n    }\n  }\n}\n```\n\n_Certified by MCP Review: https://mcpreview.com/mcp-servers/jkosik/mcp-server-splunk_",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "splunk",
        "logging",
        "monitoring",
        "server splunk",
        "logging jkosik",
        "splunk implements"
      ],
      "category": "monitoring-and-logging"
    },
    "jyjune--mcp_vms": {
      "owner": "jyjune",
      "name": "mcp_vms",
      "url": "https://github.com/jyjune/mcp_vms",
      "imageUrl": "/freedevtools/mcp/pfp/jyjune.webp",
      "description": "Connects to CCTV recording software to retrieve live and recorded video streams, manage video channel information, and control VMS features like PTZ camera presets and playback dialogs.",
      "stars": 10,
      "forks": 3,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-03T17:24:47Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/jyjune-mcp-vms-badge.png)](https://mseep.ai/app/jyjune-mcp-vms)\n\n[![Trust Score](https://archestra.ai/mcp-catalog/api/badge/quality/jyjune/mcp_vms)](https://archestra.ai/mcp-catalog/jyjune__mcp_vms)\n\n# MCP Server - VMS Integration\n\nA Model Context Protocol (MCP) server designed to connect to a CCTV recording program (VMS) to retrieve recorded and live video streams. It also provides tools to control the VMS software, such as showing live or playback dialogs for specific channels at specified times.\n\n![diagram](https://github.com/jyjune/mcp_vms/blob/main/mcp_vms_diagram.png?raw=true)\n\n## Features\n\n- Retrieve video channel information, including connection and recording status.\n- Fetch recording dates and times for specific channels.\n- Fetch live or recorded images from video channels.\n- Show live video streams or playback dialogs for specific channels and timestamps.\n- Control PTZ (Pan-Tilt-Zoom) cameras by moving them to preset positions.\n- Comprehensive error handling and logging.\n\n## Prerequisites\n\n- Python 3.12+\n- `vmspy` library (for VMS integration)\n- `Pillow` library (for image processing)\n\n## MCP-server Configuration\n\nIf you want to use `mcp-vms` with Claude desktop, you need to set up the `claude_desktop_config.json` file as follows:\n\n```json\n{\n  \"mcpServers\": {\n\t\"vms\": {\n\t  \"command\": \"uv\",\n\t  \"args\": [\n\t\t\"--directory\",\n\t\t\"X:\\\\path\\\\to\\\\mcp-vms\",\n\t\t\"run\",\n\t\t\"mcp_vms.py\"\n\t  ]\n\t}\n  }\n}\n```\n\n## VMS Connection Configuration\n\nThe server uses the following default configuration for connecting to the VMS:\n- mcp_vms_config.py\n```python\nvms_config = {\n    'img_width': 320,\n    'img_height': 240,\n    'pixel_format': 'RGB',\n    'url': '127.0.0.1',\n    'port': 3300,\n    'access_id': 'admin',\n    'access_pw': 'admin',\n}\n```\n\n## Installation\n\n### 1. Install UV Package Manager\nRun the following command in PowerShell to install `UV`:\n\n```shell\npowershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n```\n\nFor alternative installation methods, see the [official UV documentation](https://docs.astral.sh/uv/getting-started/installation/).\n\n### 2.Install VMS Server\n   Download and install the VMS server from:  \n   [http://surveillance-logic.com/en/download.html](http://surveillance-logic.com/en/download.html)\n   (Required before using this MCP server)\n\n### 3.Install Python Dependencies\n   Download the vmspy library:  \n   [vmspy1.4-python3.12-x64.zip](https://sourceforge.net/projects/security-vms/files/vmspy1.4-python3.12-x64.zip/download)\n   Extract the contents into your `mcp_vms` directory\n\nThe mcp-vms directory should look like this:\n\n```shell\nmcp-vms/\n├── .gitignore\n├── .python-version\n├── LICENSE\n├── README.md\n├── pyproject.toml\n├── uv.lock\n├── mcp_vms.py            # Main server implementation\n├── mcp_vms_config.py     # VMS connection configuration\n├── vmspy.pyd             # VMS Python library\n├── avcodec-61.dll        # FFmpeg libraries\n├── avutil-59.dll\n├── swresample-5.dll\n├── swscale-8.dll\n```\n[![Verified on MseeP](https://mseep.ai/badge.svg)](https://mseep.ai/app/7027c4cd-a9c1-43dd-9e74-771fc7cc42da)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcp_vms",
        "cctv",
        "vms",
        "jyjune mcp_vms",
        "cctv recording",
        "connects cctv"
      ],
      "category": "monitoring-and-logging"
    },
    "klara-research--MCP-Analyzer": {
      "owner": "klara-research",
      "name": "MCP-Analyzer",
      "url": "https://github.com/klara-research/MCP-Analyzer",
      "imageUrl": "/freedevtools/mcp/pfp/klara-research.webp",
      "description": "Analyze and debug Model Context Protocol logs from various platforms. Filter, paginate, and retrieve log entries for troubleshooting and understanding tool interactions.",
      "stars": 13,
      "forks": 2,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-08-05T18:47:21Z",
      "readme_content": "# MCP Server: Analyze & Debug MCP Logs\n\n[![smithery badge](https://smithery.ai/badge/@klara-research/MCP-Analyzer)](https://smithery.ai/server/@klara-research/MCP-Analyzer)\n\n<div align=\"center\">\n  \n  \n  <br>\n  <br>\n  <br>\n  🔍 <b>Read logs from standard locations across all platforms</b>\n  <br>\n  <br>\n  🔎 <b>Filter, paginate, and analyze large log collections</b>\n  <br>\n  <br>\n</div>\n\n## 🎯 Overview\n\nMCP Log Reader is a specialized MCP server that helps you analyze and debug Model Context Protocol logs. It provides Claude with direct access to log files, making it easy to troubleshoot MCP integrations and understand how Claude interacts with your tools.\n\n- **Multi-platform Support**: Works on macOS, Windows, and Linux with platform-specific log paths\n- **Smart Filtering**: Find specific log entries with case-insensitive text search\n- **Paginated Browsing**: Navigate large log collections efficiently\n- **Size Management**: Handles large log files with intelligent truncation\n- **Seamless Claude Integration**: Works directly with Claude Desktop\n\n## 🚀 Quick Start\n\n### Installing via Smithery\n\nTo install MCP Log Reader for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@klara-research/MCP-Analyzer):\n\n```bash\nnpx -y @smithery/cli install @klara-research/MCP-Analyzer --client claude\n```\n\n### Installing Manually\n\nInstall directly from GitHub:\n```bash\n# Clone the repository\ngit clone https://github.com/klara-research/MCP-Analyzer.git\ncd MCP-Analyzer\n\n# Install dependencies\nnpm i\n```\n\nBuild and run:\n```bash\n# Compile TypeScript\nnpx tsc\n```\n\n## 🔌 Connecting to Claude\n\nAdd the server to your Claude Desktop configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"log-reader\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/absolute/path/MCP-Analyzer/build\"\n      ]\n    }\n  }\n}\n```\n\nThen restart Claude Desktop.\n\n## 📋 Available Parameters\n\nThe log reader supports these parameters:\n\n| Parameter | Description | Default |\n|-----------|-------------|---------|\n| `lines` | Number of lines to read from each log file | 100 |\n| `filter` | Text to filter log entries by (case-insensitive) | \"\" |\n| `customPath` | Custom path to log directory | OS-specific |\n| `fileLimit` | Maximum number of files to read per page | 5 |\n| `page` | Page number for pagination | 1 |\n\n## 💡 Example Usage\n\nAsk Claude to use the log reader tool:\n\n```\nCan you check my MCP logs for any connection errors in the last day?\n```\n\nOr with specific parameters:\n\n```\nCan you look through MCP logs with filter=\"error\" and lines=50 to find initialization issues?\n```\n\n## ⚙️ How It Works\n\n1. The server automatically detects your OS and finds the appropriate log directory\n2. It locates all MCP log files and sorts them by modification time (newest first)\n3. The requested page of log files is retrieved based on pagination settings\n4. Files are processed with size limits to prevent overwhelming responses\n5. Filtered content is returned in a structured format with pagination details\n\n## 📄 License\n\nMIT License",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "logging",
        "debug",
        "logs",
        "protocol logs",
        "mcp analyzer",
        "analyze debug"
      ],
      "category": "monitoring-and-logging"
    },
    "last9--last9-mcp-server": {
      "owner": "last9",
      "name": "last9-mcp-server",
      "url": "https://github.com/last9/last9-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/last9.webp",
      "description": "Integrates real-time production context including logs, metrics, and traces into local development environments for code auto-fixing. Supports various IDEs and allows for retrieving exceptions and service graphs related to those exceptions.",
      "stars": 46,
      "forks": 8,
      "license": "Apache License 2.0",
      "language": "Go",
      "updated_at": "2025-10-02T21:44:46Z",
      "readme_content": "# Last9 MCP Server\n\n\n\nA [Model Context Protocol](https://modelcontextprotocol.io/) server\nimplementation for [Last9](https://last9.io/mcp/) that enables AI agents to\nseamlessly bring real-time production context — logs, metrics, and traces — into\nyour local environment to auto-fix code faster.\n\n- [View demo](https://www.youtube.com/watch?v=AQH5xq6qzjI)\n- Read our\n  [announcement blog post](https://last9.io/blog/launching-last9-mcp-server/)\n\n## Status\n\nWorks with Claude desktop app, or Cursor, Windsurf, and VSCode (Github Copilot)\nIDEs. Implements the following MCP\n[tools](https://modelcontextprotocol.io/docs/concepts/tools):\n\n**Observability & APM Tools:**\n\n- `get_exceptions`: Get the list of exceptions.\n- `get_service_summary`: Get service summary with throughput, error rate, and response time.\n- `get_service_environments`: Get available environments for services.\n- `get_service_performance_details`: Get detailed performance metrics for a service.\n- `get_service_operations_summary`: Get operations summary for a service.\n- `get_service_dependency_graph`: Get service dependency graph showing incoming/outgoing dependencies.\n\n**Prometheus/PromQL Tools:**\n\n- `prometheus_range_query`: Execute PromQL range queries for metrics data.\n- `prometheus_instant_query`: Execute PromQL instant queries for metrics data.\n- `prometheus_label_values`: Get label values for PromQL queries.\n- `prometheus_labels`: Get available labels for PromQL queries.\n\n**Logs Management:**\n\n- `get_logs`: Get logs filtered by service name and/or severity level.\n- `get_drop_rules`: Get drop rules for logs that determine what logs get\n  filtered out at [Last9 Control Plane](https://last9.io/control-plane)\n- `add_drop_rule`: Create a drop rule for logs at\n  [Last9 Control Plane](https://last9.io/control-plane)\n- `get_service_logs`: Get raw log entries for a specific service over a time range. Can apply filters on severity and body.\n- `get_log_attributes`: Get available log attributes (labels) for a specified time window.\n\n**Traces Management:**\n\n- `get_service_traces`: Query traces for a specific service with filtering options for span kinds, status codes, and other trace attributes.\n- `get_trace_attributes`: Get available trace attributes (series) for a specified time window.\n\n**Change Events:**\n\n- `get_change_events`: Get change events from the last9_change_events prometheus metric over a given time range.\n\n**Alert Management:**\n\n- `get_alert_config`: Get alert configurations (alert rules) from Last9.\n- `get_alerts`: Get currently active alerts from Last9 monitoring system.\n\n## Tools Documentation\n\n### get_exceptions\n\nRetrieves server-side exceptions over a specified time range.\n\nParameters:\n\n- `limit` (integer, optional): Maximum number of exceptions to return.\n  Default: 20.\n- `lookback_minutes` (integer, recommended): Number of minutes to look back from\n  now. Default: 60. Examples: 60, 30, 15.\n- `start_time_iso` (string, optional): Start time in ISO format (YYYY-MM-DD\n  HH:MM:SS). Leave empty to use lookback_minutes.\n- `end_time_iso` (string, optional): End time in ISO format (YYYY-MM-DD\n  HH:MM:SS). Leave empty to default to current time.\n- `span_name` (string, optional): Name of the span to filter by.\n\n### get_service_summary\n\nGet service summary over a given time range. Includes service name, environment, throughput, error rate, and response time. All values are p95 quantiles over the time range.\n\nParameters:\n\n- `start_time_iso` (string, optional): Start time in ISO format (YYYY-MM-DD HH:MM:SS). Leave empty to default to end_time_iso - 1 hour.\n- `end_time_iso` (string, optional): End time in ISO format (YYYY-MM-DD HH:MM:SS). Leave empty to default to current time.\n- `env` (string, optional): Environment to filter by. Defaults to 'prod'.\n\n### get_service_environments\n\nGet available environments for services. Returns an array of environments that can be used with other APM tools.\n\nParameters:\n\n- `start_time_iso` (string, optional): Start time in ISO format (YYYY-MM-DD HH:MM:SS). Leave empty to default to end_time_iso - 1 hour.\n- `end_time_iso` (string, optional): End time in ISO format (YYYY-MM-DD HH:MM:SS). Leave empty to default to current time.\n\nNote: All other APM tools that retrieve service information (like `get_service_performance_details`, `get_service_dependency_graph`, `get_service_operations_summary`, `get_service_summary`) require an `env` parameter. This parameter must be one of the environments returned by this tool. If this tool returns an empty array, use an empty string `\"\"` for the env parameter.\n\n### get_service_performance_details\n\nGet detailed performance metrics for a specific service over a given time range.\n\nParameters:\n\n- `service_name` (string, required): Name of the service to get performance details for.\n- `start_time_iso` (string, optional): Start time in ISO format (YYYY-MM-DD HH:MM:SS). Leave empty to default to now - 60 minutes.\n- `end_time_iso` (string, optional): End time in ISO format (YYYY-MM-DD HH:MM:SS). Leave empty to default to current time.\n- `env` (string, optional): Environment to filter by. Defaults to 'prod'.\n\n### get_service_operations_summary\n\nGet a summary of operations inside a service over a given time range. Returns operations like HTTP endpoints, database queries, messaging producer and HTTP client calls.\n\nParameters:\n\n- `service_name` (string, required): Name of the service to get operations summary for.\n- `start_time_iso` (string, optional): Start time in ISO format (YYYY-MM-DD HH:MM:SS). Leave empty to default to now - 60 minutes.\n- `end_time_iso` (string, optional): End time in ISO format (YYYY-MM-DD HH:MM:SS). Leave empty to default to current time.\n- `env` (string, optional): Environment to filter by. Defaults to 'prod'.\n\n### get_service_dependency_graph\n\nGet details of the throughput, response times and error rates of incoming, outgoing and infrastructure components of a service. Useful for analyzing cascading effects of errors and performance issues.\n\nParameters:\n\n- `service_name` (string, optional): Name of the service to get the dependency graph for.\n- `start_time_iso` (string, optional): Start time in ISO format (YYYY-MM-DD HH:MM:SS). Leave empty to default to now - 60 minutes.\n- `end_time_iso` (string, optional): End time in ISO format (YYYY-MM-DD HH:MM:SS). Leave empty to default to current time.\n- `env` (string, optional): Environment to filter by. Defaults to 'prod'.\n\n### prometheus_range_query\n\nPerform a Prometheus range query to get metrics data over a specified time range. Recommended to check available labels first using `prometheus_labels` tool.\n\nParameters:\n\n- `query` (string, required): The range query to execute.\n- `start_time_iso` (string, optional): Start time in ISO format (YYYY-MM-DD HH:MM:SS). Leave empty to default to now - 60 minutes.\n- `end_time_iso` (string, optional): End time in ISO format (YYYY-MM-DD HH:MM:SS). Leave empty to default to current time.\n\n### prometheus_instant_query\n\nPerform a Prometheus instant query to get metrics data at a specific point in time. Typically should use rollup functions like sum_over_time, avg_over_time, quantile_over_time over a time window.\n\nParameters:\n\n- `query` (string, required): The instant query to execute.\n- `time_iso` (string, optional): Time in ISO format (YYYY-MM-DD HH:MM:SS). Leave empty to default to current time.\n\n### prometheus_label_values\n\nReturn the label values for a particular label and PromQL filter query. Similar to Prometheus /label_values call.\n\nParameters:\n\n- `match_query` (string, required): A valid PromQL filter query.\n- `label` (string, required): The label to get values for.\n- `start_time_iso` (string, optional): Start time in ISO format (YYYY-MM-DD HH:MM:SS). Leave empty to default to now - 60 minutes.\n- `end_time_iso` (string, optional): End time in ISO format (YYYY-MM-DD HH:MM:SS). Leave empty to default to current time.\n\n### prometheus_labels\n\nReturn the labels for a given PromQL match query. Similar to Prometheus /labels call.\n\nParameters:\n\n- `match_query` (string, required): A valid PromQL filter query.\n- `start_time_iso` (string, optional): Start time in ISO format (YYYY-MM-DD HH:MM:SS). Leave empty to default to now - 60 minutes.\n- `end_time_iso` (string, optional): End time in ISO format (YYYY-MM-DD HH:MM:SS). Leave empty to default to current time.\n\n### get_logs\n\nGets logs filtered by service name and/or severity level within a specified time range. This tool now uses the advanced v2 logs API with physical index optimization for better performance.\n\n**Note**: This tool now requires a `service_name` parameter and internally uses the same advanced infrastructure as `get_service_logs`.\n\nParameters:\n\n- `service_name` (string, required): Name of the service to get logs for.\n- `severity` (string, optional): Severity of the logs to get (automatically converted to severity_filters format).\n- `lookback_minutes` (integer, recommended): Number of minutes to look back from now. Default: 60. Examples: 60, 30, 15.\n- `start_time_iso` (string, optional): Start time in ISO format (YYYY-MM-DD HH:MM:SS). Leave empty to use lookback_minutes.\n- `end_time_iso` (string, optional): End time in ISO format (YYYY-MM-DD HH:MM:SS). Leave empty to default to current time.\n- `limit` (integer, optional): Maximum number of logs to return. Default: 20.\n- `env` (string, optional): Environment to filter by. Use \"get_service_environments\" tool to get available environments.\n\n### get_drop_rules\n\nGets drop rules for logs, which determine what logs get filtered out from\nreaching Last9.\n\n### add_drop_rule\n\nAdds a new drop rule to filter out specific logs at\n[Last9 Control Plane](https://last9.io/control-plane)\n\nParameters:\n\n- `name` (string, required): Name of the drop rule.\n- `filters` (array, required): List of filter conditions to apply. Each filter\n  has:\n  - `key` (string, required): The key to filter on. Only attributes and\n    resource.attributes keys are supported. For resource attributes, use format:\n    resource.attributes[key_name] and for log attributes, use format:\n    attributes[key_name] Double quotes in key names must be escaped.\n  - `value` (string, required): The value to filter against.\n  - `operator` (string, required): The operator used for filtering. Valid\n    values:\n    - \"equals\"\n    - \"not_equals\"\n  - `conjunction` (string, required): The logical conjunction between filters.\n    Valid values:\n    - \"and\"\n\n### get_alert_config\n\nGet alert configurations (alert rules) from Last9. Returns all configured alert rules including their conditions, labels, and annotations.\n\nParameters:\n\nNone - This tool retrieves all available alert configurations.\n\nReturns information about:\n\n- Alert rule ID and name\n- Primary indicator being monitored\n- Current state and severity\n- Algorithm used for alerting\n- Entity ID and organization details\n- Properties and configuration\n- Creation and update timestamps\n- Group timeseries notification settings\n\n### get_alerts\n\nGet currently active alerts from Last9 monitoring system. Returns all alerts that are currently firing or have fired recently within the specified time window.\n\nParameters:\n\n- `timestamp` (integer, optional): Unix timestamp for the query time. Leave empty to default to current time.\n- `window` (integer, optional): Time window in seconds to look back for alerts. Defaults to 900 seconds (15 minutes). Range: 60-86400 seconds.\n\nReturns information about:\n\n- Alert rule details (ID, name, group, type)\n- Current state and severity\n- Last fired timestamp and duration\n- Rule properties and configuration\n- Alert instances with current values\n- Metric degradation information\n- Group labels and annotations for each instance\n\n### get_service_logs\n\nGet raw log entries for a specific service over a time range. This tool retrieves actual log entries including log messages, timestamps, severity levels, and other metadata. Useful for debugging issues, monitoring service behavior, and analyzing specific log patterns.\n\nParameters:\n\n- `service_name` (string, required): Name of the service to get logs for.\n- `lookback_minutes` (integer, optional): Number of minutes to look back from now. Default: 60 minutes. Examples: 60, 30, 15.\n- `limit` (integer, optional): Maximum number of log entries to return. Default: 20.\n- `env` (string, optional): Environment to filter by. Use \"get_service_environments\" tool to get available environments.\n- `severity_filters` (array, optional): Array of severity patterns to filter logs (e.g., [\"error\", \"warn\"]). Uses OR logic.\n- `body_filters` (array, optional): Array of message content patterns to filter logs (e.g., [\"timeout\", \"failed\"]). Uses OR logic.\n- `start_time_iso` (string, optional): Start time in ISO format (YYYY-MM-DD HH:MM:SS). Leave empty to default to now - lookback_minutes.\n- `end_time_iso` (string, optional): End time in ISO format (YYYY-MM-DD HH:MM:SS). Leave empty to default to current time.\n\nFiltering behavior:\n- Multiple filter types are combined with AND logic (service AND severity AND body)\n- Each filter array uses OR logic (matches any pattern in the array)\n\nExamples:\n- service_name=\"api\" + severity_filters=[\"error\"] + body_filters=[\"timeout\"] → finds error logs containing \"timeout\"\n- service_name=\"web\" + body_filters=[\"timeout\", \"failed\", \"error 500\"] → finds logs containing any of these patterns\n\n### get_log_attributes\n\nGet available log attributes (labels) for a specified time window. This tool retrieves all attribute names that exist in logs during the specified time range, which can be used for filtering and querying logs.\n\nParameters:\n\n- `lookback_minutes` (integer, optional): Number of minutes to look back from now for the time window. Default: 15. Examples: 15, 30, 60.\n- `start_time_iso` (string, optional): Start time in ISO format (YYYY-MM-DD HH:MM:SS). Leave empty to use lookback_minutes.\n- `end_time_iso` (string, optional): End time in ISO format (YYYY-MM-DD HH:MM:SS). Leave empty to default to current time.\n- `region` (string, optional): AWS region to query. Leave empty to use default from configuration. Examples: ap-south-1, us-east-1, eu-west-1.\n\nReturns:\n- List of log attributes grouped into two categories:\n  - Log Attributes: Standard log fields like service, severity, body, level, etc.\n  - Resource Attributes: Resource-related fields prefixed with \"resource_\" like resource_k8s.pod.name, resource_service.name, etc.\n\n### get_service_traces\n\nQuery traces for a specific service with filtering options for span kinds, status codes, and other trace attributes. This tool retrieves distributed tracing data for debugging performance issues, understanding request flows, and analyzing service interactions.\n\nParameters:\n\n- `service_name` (string, required): Name of the service to get traces for.\n- `lookback_minutes` (integer, optional): Number of minutes to look back from now. Default: 60 minutes. Examples: 60, 30, 15.\n- `limit` (integer, optional): Maximum number of traces to return. Default: 10.\n- `env` (string, optional): Environment to filter by. Use \"get_service_environments\" tool to get available environments.\n- `span_kind` (array, optional): Filter by span types (server, client, internal, consumer, producer).\n- `span_name` (string, optional): Filter by specific span name.\n- `status_code` (array, optional): Filter by trace status (ok, error, unset, success).\n- `order` (string, optional): Field to order traces by. Default: \"Duration\". Options: Duration, Timestamp.\n- `direction` (string, optional): Sort direction. Default: \"backward\". Options: forward, backward.\n- `start_time_iso` (string, optional): Start time in ISO format (YYYY-MM-DD HH:MM:SS). Leave empty to default to now - lookback_minutes.\n- `end_time_iso` (string, optional): End time in ISO format (YYYY-MM-DD HH:MM:SS). Leave empty to default to current time.\n\nFiltering options:\n- Combine multiple filters to narrow down specific traces of interest\n- Use time range filters with lookback_minutes or explicit start/end times\n\nExamples:\n- service_name=\"api\" + span_kind=[\"server\"] + status_code=[\"error\"] → finds failed server-side traces\n- service_name=\"payment\" + span_name=\"process_payment\" + lookback_minutes=30 → finds payment processing traces from last 30 minutes\n\n### get_trace_attributes\n\nGet available trace attributes (series) for a specified time window. This tool retrieves all attribute names that exist in traces during the specified time range, which can be used for filtering and querying traces.\n\nParameters:\n\n- `lookback_minutes` (integer, optional): Number of minutes to look back from now for the time window. Default: 15. Examples: 15, 30, 60.\n- `start_time_iso` (string, optional): Start time in ISO format (YYYY-MM-DD HH:MM:SS). Leave empty to use lookback_minutes.\n- `end_time_iso` (string, optional): End time in ISO format (YYYY-MM-DD HH:MM:SS). Leave empty to default to current time.\n- `region` (string, optional): AWS region to query. Leave empty to use default from configuration. Examples: ap-south-1, us-east-1, eu-west-1.\n\nReturns:\n- An alphabetically sorted list of all available trace attributes (e.g., http.method, http.status_code, db.name, resource_service.name, duration, etc.)\n\n### get_change_events\n\nGet change events from the last9_change_events prometheus metric over a given time range. Returns change events that occurred in the specified time window, including deployments, configuration changes, and other system modifications.\n\nParameters:\n\n- `start_time_iso` (string, optional): Start time in ISO format (YYYY-MM-DD HH:MM:SS). Leave empty to default to now - lookback_minutes.\n- `end_time_iso` (string, optional): End time in ISO format (YYYY-MM-DD HH:MM:SS). Leave empty to default to current time.\n- `lookback_minutes` (integer, optional): Number of minutes to look back from now. Default: 60 minutes. Examples: 60, 30, 15.\n- `service` (string, optional): Name of the service to filter change events for.\n- `environment` (string, optional): Environment to filter by.\n- `event_name` (string, optional): Name of the change event to filter by (use available_event_names to see valid values).\n\nReturns:\n- `available_event_names`: List of all available event types that can be used for filtering\n- `change_events`: Array of timeseries data with metric labels and timestamp-value pairs\n- `count`: Total number of change events returned\n- `time_range`: Start and end time of the query window\n\nEach change event includes:\n- `metric`: Map of metric labels (service_name, env, event_type, message, etc.)\n- `values`: Array of timestamp-value pairs representing the timeseries data\n\nCommon event types include: deployment, config_change, rollback, scale_up/scale_down, restart, upgrade/downgrade, maintenance, backup/restore, health_check, certificate, database.\n\nBest practices:\n1. First call without event_name to get available_event_names\n2. Use exact event name from available_event_names for the event_name parameter\n3. Combine with other filters (service, environment, time) for precise results\n\n## Installation\n\nYou can install and run the Last9 Observability MCP server in several ways:\n\n### Local Installation\n\nFor local development and traditional STDIO usage:\n\n#### Homebrew\n\n```bash\n# Add the Last9 tap\nbrew tap last9/tap\n\n# Install the Last9 MCP CLI\nbrew install last9-mcp\n```\n\n#### NPM\n\n```bash\n# Install globally\nnpm install -g @last9/mcp-server\n\n# Or run directly with npx\nnpx @last9/mcp-server\n```\n\n## Configuration\n\n### Environment Variables\n\nThe Last9 MCP server requires the following environment variables:\n\n- `LAST9_BASE_URL`: (required) Last9 API URL from\n  [OTel integration](https://app.last9.io/integrations?integration=OpenTelemetry)\n- `LAST9_AUTH_TOKEN`: (required) Authentication token for Last9 MCP server from\n  [OTel integration](https://app.last9.io/integrations?integration=OpenTelemetry)\n- `LAST9_REFRESH_TOKEN`: (required) Refresh Token with Write permissions, needed\n  for accessing control plane APIs from\n  [API Access](https://app.last9.io/settings/api-access)\n\n## Usage\n\n## Usage with Claude Desktop\n\nConfigure the Claude app to use the MCP server:\n\n1. Open the Claude Desktop app, go to Settings, then Developer\n2. Click Edit Config\n3. Open the `claude_desktop_config.json` file\n4. Copy and paste the server config to your existing file, then save\n5. Restart Claude\n\n### If installed via Homebrew:\n```json\n{\n  \"mcpServers\": {\n    \"last9\": {\n      \"command\": \"/opt/homebrew/bin/last9-mcp\",\n      \"env\": {\n        \"LAST9_BASE_URL\": \"<last9_otlp_host>\",\n        \"LAST9_AUTH_TOKEN\": \"<last9_otlp_auth_token>\",\n        \"LAST9_REFRESH_TOKEN\": \"<last9_write_refresh_token>\"\n      }\n    }\n  }\n}\n```\n\n### If installed via NPM:\n```json\n{\n  \"mcpServers\": {\n    \"last9\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@last9/mcp-server\"],\n      \"env\": {\n        \"LAST9_BASE_URL\": \"<last9_otlp_host>\",\n        \"LAST9_AUTH_TOKEN\": \"<last9_otlp_auth_token>\",\n        \"LAST9_REFRESH_TOKEN\": \"<last9_write_refresh_token>\"\n      }\n    }\n  }\n}\n```\n\n## Usage with Cursor\n\nConfigure Cursor to use the MCP server:\n\n1. Open Cursor, go to Settings, then Cursor Settings\n2. Select MCP on the left\n3. Click Add \"New Global MCP Server\" at the top right\n4. Copy and paste the server config to your existing file, then save\n5. Restart Cursor\n\n### If installed via Homebrew:\n```json\n{\n  \"mcpServers\": {\n    \"last9\": {\n      \"command\": \"/opt/homebrew/bin/last9-mcp\",\n      \"env\": {\n        \"LAST9_BASE_URL\": \"<last9_otlp_host>\",\n        \"LAST9_AUTH_TOKEN\": \"<last9_otlp_auth_token>\",\n        \"LAST9_REFRESH_TOKEN\": \"<last9_write_refresh_token>\"\n      }\n    }\n  }\n}\n```\n\n### If installed via NPM:\n```json\n{\n  \"mcpServers\": {\n    \"last9\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@last9/mcp-server\"],\n      \"env\": {\n        \"LAST9_BASE_URL\": \"<last9_otlp_host>\",\n        \"LAST9_AUTH_TOKEN\": \"<last9_otlp_auth_token>\",\n        \"LAST9_REFRESH_TOKEN\": \"<last9_write_refresh_token>\"\n      }\n    }\n  }\n}\n```\n\n## Usage with Windsurf\n\nConfigure Windsurf to use the MCP server:\n\n1. Open Windsurf, go to Settings, then Developer\n2. Click Edit Config\n3. Open the `windsurf_config.json` file\n4. Copy and paste the server config to your existing file, then save\n5. Restart Windsurf\n\n### If installed via Homebrew:\n```json\n{\n  \"mcpServers\": {\n    \"last9\": {\n      \"command\": \"/opt/homebrew/bin/last9-mcp\",\n      \"env\": {\n        \"LAST9_BASE_URL\": \"<last9_otlp_host>\",\n        \"LAST9_AUTH_TOKEN\": \"<last9_otlp_auth_token>\",\n        \"LAST9_REFRESH_TOKEN\": \"<last9_write_refresh_token>\"\n      }\n    }\n  }\n}\n```\n\n### If installed via NPM:\n```json\n{\n  \"mcpServers\": {\n    \"last9\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@last9/mcp-server\"],\n      \"env\": {\n        \"LAST9_BASE_URL\": \"<last9_otlp_host>\",\n        \"LAST9_AUTH_TOKEN\": \"<last9_otlp_auth_token>\",\n        \"LAST9_REFRESH_TOKEN\": \"<last9_write_refresh_token>\"\n      }\n    }\n  }\n}\n```\n\n## Usage with VS Code\n\n> Note: MCP support in VS Code is available starting v1.99 and is currently in\n> preview. For advanced configuration options and alternative setup methods,\n> [view the VS Code MCP documentation](https://code.visualstudio.com/docs/copilot/chat/mcp-servers).\n\n1. Open VS Code, go to Settings, select the User tab, then Features, then Chat\n2. Click \"Edit settings.json\"\n3. Copy and paste the server config to your existing file, then save\n4. Restart VS Code\n\n### If installed via Homebrew:\n```json\n{\n  \"mcp\": {\n    \"servers\": {\n      \"last9\": {\n        \"type\": \"stdio\",\n        \"command\": \"/opt/homebrew/bin/last9-mcp\",\n        \"env\": {\n          \"LAST9_BASE_URL\": \"<last9_otlp_host>\",\n          \"LAST9_AUTH_TOKEN\": \"<last9_otlp_auth_token>\",\n          \"LAST9_REFRESH_TOKEN\": \"<last9_write_refresh_token>\"\n        }\n      }\n    }\n  }\n}\n```\n\n### If installed via NPM:\n```json\n{\n  \"mcp\": {\n    \"servers\": {\n      \"last9\": {\n        \"type\": \"stdio\",\n        \"command\": \"npx\",\n        \"args\": [\"-y\", \"@last9/mcp-server\"],\n        \"env\": {\n          \"LAST9_BASE_URL\": \"<last9_otlp_host>\",\n          \"LAST9_AUTH_TOKEN\": \"<last9_otlp_auth_token>\",\n          \"LAST9_REFRESH_TOKEN\": \"<last9_write_refresh_token>\"\n        }\n      }\n    }\n  }\n}\n```\n\n## Development\n\nFor local development and testing, you can run the MCP server in HTTP mode which makes it easier to debug requests and responses.\n\n### Running in HTTP Mode\n\nSet the `HTTP_MODE` environment variable to enable HTTP server mode:\n\n```bash\n# Export required environment variables\nexport LAST9_API_TOKEN=\"your_api_token\"\nexport LAST9_BASE_URL=\"https://your-last9-endpoint\"  # Your Last9 endpoint\nexport HTTP_MODE=true\nexport HTTP_PORT=8080  # Optional, defaults to 8080\n\n# Run the server\n./last9-mcp-server\n```\n\nThe server will start on `http://localhost:8080/mcp` and you can test it with curl:\n\n### Testing with curl\n\n```bash\n# Test get_service_logs\ncurl -X POST http://localhost:8080/mcp \\\n    -H \"Content-Type: application/json\" \\\n    -H \"Mcp-Session-Id: session_$(date +%s)000000000\" \\\n    -d '{\n      \"jsonrpc\": \"2.0\",\n      \"id\": 1,\n      \"method\": \"tools/call\",\n      \"params\": {\n        \"name\": \"get_service_logs\",\n        \"arguments\": {\n          \"service_name\": \"your-service-name\",\n          \"lookback_minutes\": 30,\n          \"limit\": 10\n        }\n      }\n    }'\n\n# Test get_service_traces\ncurl -X POST http://localhost:8080/mcp \\\n    -H \"Content-Type: application/json\" \\\n    -H \"Mcp-Session-Id: session_$(date +%s)000000000\" \\\n    -d '{\n      \"jsonrpc\": \"2.0\",\n      \"id\": 2,\n      \"method\": \"tools/call\",\n      \"params\": {\n        \"name\": \"get_service_traces\",\n        \"arguments\": {\n          \"service_name\": \"your-service-name\",\n          \"lookback_minutes\": 60,\n          \"limit\": 5\n        }\n      }\n    }'\n\n# List available tools\ncurl -X POST http://localhost:8080/mcp \\\n    -H \"Content-Type: application/json\" \\\n    -H \"Mcp-Session-Id: session_$(date +%s)000000000\" \\\n    -d '{\n      \"jsonrpc\": \"2.0\",\n      \"id\": 3,\n      \"method\": \"tools/list\",\n      \"params\": {}\n    }'\n```\n\n### Building from Source\n\n```bash\n# Clone the repository\ngit clone https://github.com/last9/last9-mcp-server.git\ncd last9-mcp-server\n\n# Build the binary\ngo build -o last9-mcp-server\n\n# Run in development mode\nHTTP_MODE=true ./last9-mcp-server\n```\n\n**Note**: HTTP mode is for development and testing only. When integrating with Claude Desktop or other MCP clients, use the default STDIO mode (without `HTTP_MODE=true`).\n\n## Badges\n\n[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/last9-last9-mcp-server-badge.png)](https://mseep.ai/app/last9-last9-mcp-server)",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "logging",
        "logs",
        "monitoring",
        "logging last9",
        "monitoring logging",
        "including logs"
      ],
      "category": "monitoring-and-logging"
    },
    "ljcloudy--Sentinel": {
      "owner": "ljcloudy",
      "name": "Sentinel",
      "url": "https://github.com/ljcloudy/Sentinel",
      "imageUrl": "/freedevtools/mcp/pfp/ljcloudy.webp",
      "description": "Enhance microservices with advanced flow control, traffic shaping, and circuit breaking capabilities. Monitor services in real-time while managing performance under varying loads through customizable rules and integration with popular frameworks.",
      "stars": 0,
      "forks": 0,
      "license": "Apache License 2.0",
      "language": "",
      "updated_at": "2020-11-07T12:42:52Z",
      "readme_content": "<img src=\"https://user-images.githubusercontent.com/9434884/43697219-3cb4ef3a-9975-11e8-9a9c-73f4f537442d.png\" alt=\"Sentinel Logo\" width=\"50%\">\n\n# Sentinel: The Sentinel of Your Microservices\n\n[![Travis Build Status](https://travis-ci.org/alibaba/Sentinel.svg?branch=master)](https://travis-ci.org/alibaba/Sentinel)\n[![Codecov](https://codecov.io/gh/alibaba/Sentinel/branch/master/graph/badge.svg)](https://codecov.io/gh/alibaba/Sentinel)\n[![Maven Central](https://img.shields.io/maven-central/v/com.alibaba.csp/sentinel-core.svg?label=Maven%20Central)](https://search.maven.org/search?q=g:com.alibaba.csp%20AND%20a:sentinel-core)\n[![License](https://img.shields.io/badge/license-Apache%202-4EB1BA.svg)](https://www.apache.org/licenses/LICENSE-2.0.html)\n[![Gitter](https://badges.gitter.im/alibaba/Sentinel.svg)](https://gitter.im/alibaba/Sentinel)\n\n## Introduction\n\nAs distributed systems become increasingly popular, the reliability between services is becoming more important than ever before.\nSentinel takes \"flow\" as breakthrough point, and works on multiple fields including **flow control**,\n**traffic shaping**, **circuit breaking** and **system adaptive protection**, to guarantee reliability and resilience for microservices.\n\nSentinel has the following features:\n\n- **Rich applicable scenarios**: Sentinel has been wildly used in Alibaba, and has covered almost all the core-scenarios in Double-11 (11.11) Shopping Festivals in the past 10 years, such as “Second Kill” which needs to limit burst flow traffic to meet the system capacity, message peak clipping and valley fills, circuit breaking for unreliable downstream services, cluster flow control, etc.\n- **Real-time monitoring**: Sentinel also provides real-time monitoring ability. You can see the runtime information of a single machine in real-time, and the aggregated runtime info of a cluster with less than 500 nodes.\n- **Widespread open-source ecosystem**: Sentinel provides out-of-box integrations with commonly-used frameworks and libraries such as Spring Cloud, Dubbo and gRPC. You can easily use Sentinel by simply add the adapter dependency to your services.\n- **Polyglot support**: Sentinel has provided native support for Java, [Go](https://github.com/alibaba/sentinel-golang) and [C++](https://github.com/alibaba/sentinel-cpp).\n- **Various SPI extensions**: Sentinel provides easy-to-use SPI extension interfaces that allow you to quickly customize your logic, for example, custom rule management, adapting data sources, and so on.\n\nFeatures overview:\n\n\n\n## Documentation\n\nSee the [中文文档](https://github.com/alibaba/Sentinel/wiki/%E4%BB%8B%E7%BB%8D) for document in Chinese.\n\nSee the [Wiki](https://github.com/alibaba/Sentinel/wiki) for full documentation, examples, blog posts, operational details and other information.\n\nSentinel provides integration modules for various open-source frameworks\n(e.g. Spring Cloud, Apache Dubbo, gRPC, Spring WebFlux, Reactor) and service mesh.\nYou can refer to [the document](https://github.com/alibaba/Sentinel/wiki/Adapters-to-Popular-Framework) for more information.\n\nIf you are using Sentinel, please [**leave a comment here**](https://github.com/alibaba/Sentinel/issues/18) to tell us your scenario to make Sentinel better.\nIt's also encouraged to add the link of your blog post, tutorial, demo or customized components to [**Awesome Sentinel**](./doc/awesome-sentinel.md).\n\n## Ecosystem Landscape\n\n\n\n## Quick Start\n\nBelow is a simple demo that guides new users to use Sentinel in just 3 steps. It also shows how to monitor this demo using the dashboard.\n\n### 1. Add Dependency\n\n**Note:** Sentinel Core requires Java 7 or later.\n\nIf your're using Maven, just add the following dependency in `pom.xml`.\n\n```xml\n<!-- replace here with the latest version -->\n<dependency>\n    <groupId>com.alibaba.csp</groupId>\n    <artifactId>sentinel-core</artifactId>\n    <version>1.8.0</version>\n</dependency>\n```\n\nIf not, you can download JAR in [Maven Center Repository](https://mvnrepository.com/artifact/com.alibaba.csp/sentinel-core).\n\n### 2. Define Resource\n\nWrap your code snippet via Sentinel API: `SphU.entry(resourceName)`.\nIn below example, it is `System.out.println(\"hello world\");`:\n\n```java\ntry (Entry entry = SphU.entry(\"HelloWorld\")) {\n    // Your business logic here.\n    System.out.println(\"hello world\");\n} catch (BlockException e) {\n    // Handle rejected request.\n    e.printStackTrace();\n}\n// try-with-resources auto exit\n```\n\nSo far the code modification is done. We've also provided [annotation support module](https://github.com/alibaba/Sentinel/blob/master/sentinel-extension/sentinel-annotation-aspectj/README.md) to define resource easier.\n\n### 3. Define Rules\n\nIf we want to limit the access times of the resource, we can **set rules to the resource**.\nThe following code defines a rule that limits access to the resource to 20 times per second at the maximum.\n\n```java\nList<FlowRule> rules = new ArrayList<>();\nFlowRule rule = new FlowRule();\nrule.setResource(\"HelloWorld\");\n// set limit qps to 20\nrule.setCount(20);\nrule.setGrade(RuleConstant.FLOW_GRADE_QPS);\nrules.add(rule);\nFlowRuleManager.loadRules(rules);\n```\n\nFor more information, please refer to [How To Use](https://github.com/alibaba/Sentinel/wiki/How-to-Use).\n\n### 4. Check the Result\n\nAfter running the demo for a while, you can see the following records in `~/logs/csp/${appName}-metrics.log.{date}` (When using the default `DateFileLogHandler`).\n\n```\n|--timestamp-|------date time----|-resource-|p |block|s |e|rt  |occupied\n1529998904000|2018-06-26 15:41:44|HelloWorld|20|0    |20|0|0   |0\n1529998905000|2018-06-26 15:41:45|HelloWorld|20|5579 |20|0|728 |0\n1529998906000|2018-06-26 15:41:46|HelloWorld|20|15698|20|0|0   |0\n1529998907000|2018-06-26 15:41:47|HelloWorld|20|19262|20|0|0   |0\n1529998908000|2018-06-26 15:41:48|HelloWorld|20|19502|20|0|0   |0\n1529998909000|2018-06-26 15:41:49|HelloWorld|20|18386|20|0|0   |0\n\np stands for incoming request, block for blocked by rules, success for success handled by Sentinel, e for exception count, rt for average response time (ms), occupied stands for occupiedPassQps since 1.5.0 which enable us booking more than 1 shot when entering.\n```\n\nThis shows that the demo can print \"hello world\" 20 times per second.\n\nMore examples and information can be found in the [How To Use](https://github.com/alibaba/Sentinel/wiki/How-to-Use) section.\n\nThe working principles of Sentinel can be found in [How it works](https://github.com/alibaba/Sentinel/wiki/How-it-works) section.\n\nSamples can be found in the [sentinel-demo](https://github.com/alibaba/Sentinel/tree/master/sentinel-demo) module.\n\n### 5. Start Dashboard\n\n> Note: Java 8 is required for building or running the dashboard.\n\nSentinel also provides a simple dashboard application, on which you can monitor the clients and configure the rules in real time.\n\n![dashboard](https://user-images.githubusercontent.com/9434884/55449295-84866d80-55fd-11e9-94e5-d3441f4a2b63.png)\n\nFor details please refer to [Dashboard](https://github.com/alibaba/Sentinel/wiki/Dashboard).\n\n## Trouble Shooting and Logs\n\nSentinel will generate logs for troubleshooting and real-time monitoring.\nAll the information can be found in [logs](https://github.com/alibaba/Sentinel/wiki/Logs).\n\n## Bugs and Feedback\n\nFor bug report, questions and discussions please submit [GitHub Issues](https://github.com/alibaba/sentinel/issues).\n\nContact us via [Gitter](https://gitter.im/alibaba/Sentinel) or [Email](mailto:sentinel@linux.alibaba.com).\n\n## Contributing\n\nContributions are always welcomed! Please refer to [CONTRIBUTING](./CONTRIBUTING.md) for detailed guidelines.\n\nYou can start with the issues labeled with [`good first issue`](https://github.com/alibaba/Sentinel/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22).\n\n## Credits\n\nThanks [Guava](https://github.com/google/guava), which provides some inspiration on rate limiting.\n\nAnd thanks for all [contributors](https://github.com/alibaba/Sentinel/graphs/contributors) of Sentinel!\n\n## Who is using\n\nThese are only part of the companies using Sentinel, for reference only.\nIf you are using Sentinel, please [add your company here](https://github.com/alibaba/Sentinel/issues/18) to tell us your scenario to make Sentinel better :)\n\n![Alibaba Group](https://docs.alibabagroup.com/assets2/images/en/global/logo_header.png)\n![AntFin](https://user-images.githubusercontent.com/9434884/90598732-30961c00-e226-11ea-8c86-0b1d7f7875c7.png)\n![Taiping Renshou](http://www.cntaiping.com/tplresource/cms/www/taiping/img/home_new/tp_logo_img.png)\n![拼多多](http://cdn.pinduoduo.com/assets/img/pdd_logo_v3.png)\n![爱奇艺](https://user-images.githubusercontent.com/9434884/90598445-a51c8b00-e225-11ea-9327-3543525f3f2a.png)\n![Shunfeng Technology](https://user-images.githubusercontent.com/9434884/48463502-2f48eb80-e817-11e8-984f-2f9b1b789e2d.png)\n![二维火](https://user-images.githubusercontent.com/9434884/49358468-bc43de00-f70d-11e8-97fe-0bf05865f29f.png)\n![Mandao](https://user-images.githubusercontent.com/9434884/48463559-6cad7900-e817-11e8-87e4-42952b074837.png)\n![文轩在线](http://static.winxuancdn.com/css/v2/images/logo.png)\n\n![亲宝宝](https://stlib.qbb6.com/wclt/img/home_hd/version1/title_logo.png)\n\n![金汇金融](https://res.jinhui365.com/r/images/logo2.png?v=1.527)\n![闪电购](http://cdn.52shangou.com/shandianbang/official-source/3.1.1/build/images/logo.png)",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "microservices",
        "sentinel",
        "monitoring",
        "microservices advanced",
        "ljcloudy sentinel",
        "enhance microservices"
      ],
      "category": "monitoring-and-logging"
    },
    "lkp474--alibabacloud-observability-mcp-server": {
      "owner": "lkp474",
      "name": "alibabacloud-observability-mcp-server",
      "url": "https://github.com/lkp474/alibabacloud-observability-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/lkp474.webp",
      "description": "Provides access to Alibaba Cloud observability products, including Log Service, Application Real-Time Monitoring Service, and Cloud Monitor through a standardized MCP interface for efficient querying and interaction with observability data.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "",
      "updated_at": "2025-04-24T07:19:59Z",
      "readme_content": "## 阿里云可观测MCP服务\n<p align=\"center\">\n  <a href=\"./README.md\"><img alt=\"中文自述文件\" src=\"https://img.shields.io/badge/简体中文-d9d9d9\"\"></a>\n  <a href=\"./README_EN.md\"><img alt=\"英文自述文件\" src=\"https://img.shields.io/badge/English-d9d9d9\")\n</p>\n\n### 简介\n\n阿里云可观测 MCP服务，提供了一系列访问阿里云可观测各产品的工具能力，覆盖产品包含阿里云日志服务SLS、阿里云应用实时监控服务ARMS、阿里云云监控等，任意支持 MCP 协议的智能体助手都可快速接入。支持的产品如下:\n\n- [阿里云日志服务SLS](https://help.aliyun.com/zh/sls/product-overview/what-is-log-service)\n- [阿里云应用实时监控服务ARMS](https://help.aliyun.com/zh/arms/?scm=20140722.S_help@@%E6%96%87%E6%A1%A3@@34364._.RL_arms-LOC_2024NSHelpLink-OR_ser-PAR1_215042f917434789732438827e4665-V_4-P0_0-P1_0)\n\n目前提供的 MCP 工具以阿里云日志服务为主，其他产品会陆续支持，工具详细如下:\n\n### 版本记录\n可以查看 [CHANGELOG.md](./CHANGELOG.md)\n\n### 常见问题\n可以查看 [FAQ.md](./FAQ.md)\n\n##### 场景举例\n\n- 场景一: 快速查询某个 logstore 相关结构\n    - 使用工具:\n        - `sls_list_logstores`\n        - `sls_describe_logstore`\n    \n\n\n- 场景二: 模糊查询最近一天某个 logstore下面访问量最高的应用是什么\n    - 分析:\n        - 需要判断 logstore 是否存在\n        - 获取 logstore 相关结构\n        - 根据要求生成查询语句(对于语句用户可确认修改)\n        - 执行查询语句\n        - 根据查询结果生成响应\n    - 使用工具:\n        - `sls_list_logstores`\n        - `sls_describe_logstore`\n        - `sls_translate_natural_language_to_query`\n        - `sls_execute_query`\n    \n\n    \n- 场景三: 查询 ARMS 某个应用下面响应最慢的几条 Trace\n    - 分析:\n        - 需要判断应用是否存在\n        - 获取应用相关结构\n        - 根据要求生成查询语句(对于语句用户可确认修改)\n        - 执行查询语句\n        - 根据查询结果生成响应\n    - 使用工具:\n        - `arms_search_apps`\n        - `arms_generate_trace_query`\n        - `sls_translate_natural_language_to_query`\n        - `sls_execute_query`\n    \n\n\n### 权限要求\n\n为了确保 MCP Server 能够成功访问和操作您的阿里云可观测性资源，您需要配置以下权限：\n\n1.  **阿里云访问密钥 (AccessKey)**：\n    *   服务运行需要有效的阿里云 AccessKey ID 和 AccessKey Secret。\n    *   获取和管理 AccessKey，请参考 [阿里云 AccessKey 管理官方文档](https://help.aliyun.com/document_detail/53045.html)。\n  \n2. 当你初始化时候不传入 AccessKey 和 AccessKey Secret 时，会使用[默认凭据链进行登录](https://www.alibabacloud.com/help/zh/sdk/developer-reference/v2-manage-python-access-credentials#62bf90d04dztq)\n   1. 如果环境变量 中的ALIBABA_CLOUD_ACCESS_KEY_ID 和 ALIBABA_CLOUD_ACCESS_KEY_SECRET均存在且非空，则使用它们作为默认凭据。\n   2. 如果同时设置了ALIBABA_CLOUD_ACCESS_KEY_ID、ALIBABA_CLOUD_ACCESS_KEY_SECRET和ALIBABA_CLOUD_SECURITY_TOKEN，则使用STS Token作为默认凭据。\n   \n3.  **RAM 授权 (重要)**：\n    *   与 AccessKey 关联的 RAM 用户或角色**必须**被授予访问相关云服务所需的权限。\n    *   **强烈建议遵循\"最小权限原则\"**：仅授予运行您计划使用的 MCP 工具所必需的最小权限集，以降低安全风险。\n    *   根据您需要使用的工具，参考以下文档进行权限配置：\n        *   **日志服务 (SLS)**：如果您需要使用 `sls_*` 相关工具，请参考 [日志服务权限说明](https://help.aliyun.com/zh/sls/overview-8)，并授予必要的读取、查询等权限。\n        *   **应用实时监控服务 (ARMS)**：如果您需要使用 `arms_*` 相关工具，请参考 [ARMS 权限说明](https://help.aliyun.com/zh/arms/security-and-compliance/overview-8?scm=20140722.H_74783._.OR_help-T_cn~zh-V_1)，并授予必要的查询权限。\n    *   请根据您的实际应用场景，精细化配置所需权限。\n\n### 安全与部署建议\n\n请务必关注以下安全事项和部署最佳实践：\n\n1.  **密钥安全**：\n    *   本 MCP Server 在运行时会使用您提供的 AccessKey 调用阿里云 OpenAPI，但**不会以任何形式存储您的 AccessKey**，也不会将其用于设计功能之外的任何其他用途。\n\n2.  **访问控制 (关键)**：\n    *   当您选择通过 **SSE (Server-Sent Events) 协议** 访问 MCP Server 时，**您必须自行负责该服务接入点的访问控制和安全防护**。\n    *   **强烈建议**将 MCP Server 部署在**内部网络或受信环境**中，例如您的私有 VPC (Virtual Private Cloud) 内，避免直接暴露于公共互联网。\n    *   推荐的部署方式是使用**阿里云函数计算 (FC)**，并配置其网络设置为**仅 VPC 内访问**，以实现网络层面的隔离和安全。\n    *   **注意**：**切勿**在没有任何身份验证或访问控制机制的情况下，将配置了您 AccessKey 的 MCP Server SSE 端点暴露在公共互联网上，这会带来极高的安全风险。\n\n### 使用说明\n\n\n在使用 MCP Server 之前，需要先获取阿里云的 AccessKeyId 和 AccessKeySecret，请参考 [阿里云 AccessKey 管理](https://help.aliyun.com/document_detail/53045.html)\n\n\n#### 使用 pip 安装\n> ⚠️ 需要 Python 3.10 及以上版本。\n\n直接使用 pip 安装即可，安装命令如下：\n\n```bash\npip install mcp-server-aliyun-observability\n```\n1. 安装之后，直接运行即可，运行命令如下：\n\n```bash\npython -m mcp_server_aliyun_observability --transport sse --access-key-id <your_access_key_id> --access-key-secret <your_access_key_secret>\n```\n可通过命令行传递指定参数:\n- `--transport` 指定传输方式，可选值为 `sse` 或 `stdio`，默认值为 `stdio`\n- `--access-key-id` 指定阿里云 AccessKeyId，不指定时会使用环境变量中的ALIBABA_CLOUD_ACCESS_KEY_ID\n- `--access-key-secret` 指定阿里云 AccessKeySecret，不指定时会使用环境变量中的ALIBABA_CLOUD_ACCESS_KEY_SECRET\n- `--log-level` 指定日志级别，可选值为 `DEBUG`、`INFO`、`WARNING`、`ERROR`，默认值为 `INFO`\n- `--transport-port` 指定传输端口，默认值为 `8000`,仅当 `--transport` 为 `sse` 时有效\n\n2. 使用uv 命令启动\n   可以指定下版本号，会自动拉取对应依赖，默认是 studio 方式启动\n```bash\nuvx --from 'mcp-server-aliyun-observability==0.2.1' mcp-server-aliyun-observability \n```\n\n3. 使用 uvx 命令启动\n\n```bash\nuvx run mcp-server-aliyun-observability\n```\n\n### 从源码安装\n\n```bash\n\n# clone 源码\ngit clone git@github.com:aliyun/alibabacloud-observability-mcp-server.git\n# 进入源码目录\ncd alibabacloud-observability-mcp-server\n# 安装\npip install -e .\n# 运行\npython -m mcp_server_aliyun_observability --transport sse --access-key-id <your_access_key_id> --access-key-secret <your_access_key_secret>\n```\n\n\n### AI 工具集成\n\n> 以 SSE 启动方式为例,transport 端口为 8888,实际使用时需要根据实际情况修改\n\n#### Cursor，Cline 等集成\n1. 使用 SSE 启动方式\n```json\n{\n  \"mcpServers\": {\n    \"alibaba_cloud_observability\": {\n      \"url\": \"http://localhost:7897/sse\"\n        }\n  }\n}\n```\n2. 使用 stdio 启动方式\n   直接从源码目录启动,注意\n    1. 需要指定 `--directory` 参数,指定源码目录，最好是绝对路径\n    2. uv命令 最好也使用绝对路径，如果使用了虚拟环境，则需要使用虚拟环境的绝对路径\n```json\n{\n  \"mcpServers\": {\n    \"alibaba_cloud_observability\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/path/to/your/alibabacloud-observability-mcp-server\",\n        \"run\",\n        \"mcp-server-aliyun-observability\"\n      ],\n      \"env\": {\n        \"ALIBABA_CLOUD_ACCESS_KEY_ID\": \"<your_access_key_id>\",\n        \"ALIBABA_CLOUD_ACCESS_KEY_SECRET\": \"<your_access_key_secret>\"\n      }\n    }\n  }\n}\n```\n1. 使用 stdio 启动方式-从 module 启动\n```json\n{\n  \"mcpServers\": {\n    \"alibaba_cloud_observability\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"run\",\n        \"mcp-server-aliyun-observability\"\n      ],\n      \"env\": {\n        \"ALIBABA_CLOUD_ACCESS_KEY_ID\": \"<your_access_key_id>\",\n        \"ALIBABA_CLOUD_ACCESS_KEY_SECRET\": \"<your_access_key_secret>\"\n      }\n    }\n  }\n}\n```\n\n#### Cherry Studio集成\n\n\n\n\n\n\n#### Cursor集成\n\n\n\n\n\n\n\n\n#### ChatWise集成",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "alibabacloud",
        "monitoring",
        "cloud",
        "alibabacloud observability",
        "cloud observability",
        "cloud monitor"
      ],
      "category": "monitoring-and-logging"
    },
    "loglmhq--mcp-server-prometheus": {
      "owner": "loglmhq",
      "name": "mcp-server-prometheus",
      "url": "https://github.com/loglmhq/mcp-server-prometheus",
      "imageUrl": "/freedevtools/mcp/pfp/loglmhq.webp",
      "description": "Connects to Prometheus metrics and data through the Model Context Protocol (MCP), providing access to metric schemas and detailed metadata, along with statistical information.",
      "stars": 16,
      "forks": 7,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-07-18T09:02:30Z",
      "readme_content": "# mcp-server-prometheus\n\nMCP server for interacting with Prometheus metrics and data.\n\nThis is a TypeScript-based MCP server that implements a Prometheus API interface. It provides a bridge between Claude and your Prometheus server through the Model Context Protocol (MCP).\n\n<a href=\"https://glama.ai/mcp/servers/y7b3qba8jy\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/y7b3qba8jy/badge\" alt=\"mcp-server-prometheus MCP server\" /></a>\n\n## Demo\n\n\n\n## Features\n\n### Resources\n\n- List and access Prometheus metric schema\n- Each metric resource provides:\n  - Metric name and description\n  - Detailed metadata from Prometheus\n  - Statistical information (count, min, max)\n- JSON mime type for structured data access\n\n### Current Capabilities\n\n- List all available Prometheus metrics with descriptions\n- Read detailed metric information including:\n  - Metadata and help text\n  - Current statistical data (count, min, max values)\n- Basic authentication support for secured Prometheus instances\n\n## Configuration\n\nThe server requires the following environment variable:\n\n- `PROMETHEUS_URL`: The base URL of your Prometheus instance\n\nOptional authentication configuration:\n\n- `PROMETHEUS_USERNAME`: Username for basic auth (if required)\n- `PROMETHEUS_PASSWORD`: Password for basic auth (if required)\n\n## Development\n\nInstall dependencies:\n\n```bash\nnpm install\n```\n\nBuild the server:\n\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n\n```bash\nnpm run watch\n```\n\n## Installation\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-server-prometheus\": {\n      \"command\": \"/path/to/mcp-server-prometheus/build/index.js\",\n      \"env\": {\n        \"PROMETHEUS_URL\": \"http://your-prometheus-instance:9090\"\n      }\n    }\n  }\n}\n```\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector):\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n\n## API Structure\n\nThe server exposes Prometheus metrics through the following URI structure:\n\n- Base URI: `http://your-prometheus-instance:9090`\n- Metric URIs: `http://your-prometheus-instance:9090/metrics/{metric_name}`\n\nEach metric resource returns JSON data containing:\n\n- Metric name\n- Metadata (help text, type)\n- Current statistics (count, min, max)",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "prometheus",
        "logging",
        "monitoring",
        "server prometheus",
        "prometheus metrics",
        "connects prometheus"
      ],
      "category": "monitoring-and-logging"
    },
    "marcoeg--mcp-server-ntopng": {
      "owner": "marcoeg",
      "name": "mcp-server-ntopng",
      "url": "https://github.com/marcoeg/mcp-server-ntopng",
      "imageUrl": "/freedevtools/mcp/pfp/marcoeg.webp",
      "description": "Enables AI agents to access and query network monitoring data stored in the NTOPNG database, facilitating traffic analysis and reporting through seamless integration. Utilizes ClickHouse for historical flows and alerts within the NTOPNG framework.",
      "stars": 0,
      "forks": 3,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-03-22T01:50:57Z",
      "readme_content": "# mcp-server-ntopng\n[![PyPI - Version](https://img.shields.io/pypi/v/mcp-ntopng)](https://pypi.org/project/mcp-ntopng)\n\nNTOPNG Model Context Protocol Server\n\n<a href=\"https://glama.ai/mcp/servers/@marcoeg/mcp-server-ntopng\">\n<img alt=\"badge\" width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@marcoeg/mcp-server-ntopng/badge\" />\n\nA [Model Context Protocol](https://modelcontextprotocol.io/) server implementation for [NTOPNG](https://www.ntop.org/products/traffic-analysis/ntop/) that enables AI agents to query networks monitoring data using the NTOPNG database.\n\nThis MCP Server assumes that `ntopng` is using ClickHouse to store historical flows and alert. Check [ntopng Clickhouse](https://www.ntop.org/guides/ntopng/flow_dump/clickhouse/index.html)\n\n\n## Tools\n\n* `fetch_ntopng_all_ifids`\n- Retrieve all available interface IDs from ntopng.\n* `get_ntopng_hosts_location`\n- Fetch geographical location and additional info for hosts.\n* `fetch_ntopng_top_local_talkers`\n- Retrieve the top 10 local talkers for a specified interface.\n* `fetch_ntopng_top_remote_talkers`\n- Retrieve the top 10 remote talkers for a specified interface.\n* `get_ntopng_all_alert_stats`\n- Retrieve statistics for all alerts.\n* `get_ntopng_flow_alert_stats`\n- Retrieve statistics for flow alerts.\n* `get_ntopng_host_alert_stats`\n- Retrieve statistics for host alerts.\n* `get_ntopng_interface_alert_stats`\n- Retrieve statistics for interface alerts.\n* `get_ntopng_mac_alert_stats`\n- Retrieve statistics for MAC alerts.\n* `get_ntopng_network_alert_stats`\n- Retrieve statistics for network alerts.\n* `get_ntopng_snmp_device_alert_list`\n- Retrieve a list of SNMP device alerts.\n* `get_ntopng_snmp_device_alert_stats`\n- Retrieve statistics for SNMP device alerts.\n* `get_ntopng_system_alert_stats`\n- Retrieve statistics for system alerts.\n* `query_ntopng_flows_data`\n- Retrieve detailed flows data from the ntopng flows database.\n* `get_ntopng_top-k_flows`\n- Retrieve top-k flows data from the ntopng flows database.\n* `get_ntopng_user_alert_stats`\n- Retrieve statistics for user alerts.\n* `get_ntopng_flow_devices_stats`\n- Retrieve statistics for all flow dev`ices.\n* `get_ntopng_sflow_devices_stats`\n- Retrieve statistics for all sFlow devices.\n* `list_tables_ntopng_database`\n- List tables structure of the ntopng database.\n* `query_ntopng_database`\n- Query the ntopng Clickhouse database.\n\n## Status\n\nWorks with Claude Desktop app and other MCP compliant hosts and clients. \n\nNo support for MCP [resources](https://modelcontextprotocol.io/docs/concepts/resources) or [prompts](https://modelcontextprotocol.io/docs/concepts/prompts) yet.\n\n## Configuration\n\n1. Create or edit the Claude Desktop configuration file located at:\n   - On macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - On Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n2. Add the following:\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-ntopng\": {\n      \"command\": \"/path/to/your/uv-binary\",\n      \"args\": [\"run\", \"--with\", \"mcp-ntopng\", \"--python\", \"3.13\", \"mcp-ntopng\"]\n      \"env\": {\n        \"NTOPNG_HOST\": \"<ntopng-host>\",\n        \"NTOPNG_DBPORT\": \"<ntopng-dbport>\",\n        \"NTOPNG_DBUSER\": \"<ntopng-dbuser>\",\n        \"NTOPNG_DBPASSWORD\": \"<ntopng-dbpassword>\",\n        \"NTOPNG_SECURE\": \"true\",\n        \"NTOPNG_VERIFY\": \"true\",\n        \"NTOPNG_CONNECT_TIMEOUT\": \"30\",\n        \"NTOPNG_SEND_RECEIVE_TIMEOUT\": \"300\",\n        \"NTOPNG_API_KEY\": \"NTOPNG_TOKEN\"\n      }\n    }\n  }\n}\n```\n\n\n3. Replace `/path/to/your/uv-binary` with the absolute path to the `uv` executable. Find the path with `which uv`. This ensures that the correct version of `uv` is used when starting the server.\n\n4. Restart Claude Desktop to apply the changes.\n\n\n## Development \n\n1. Set the environmental variables either in the `claude_desktop_config.json` file or in a `.env` file in the root of the repository.\n\n```\nNTOPNG_HOST=localhost\nNTOPNG_PORT=9000\nNTOPNG_USER=default\nNTOPNG_PASSWORD=\n```\n\n3. Run `uv sync` to install the dependencies. To install `uv` follow the instructions [here](https://docs.astral.sh/uv/). Then do `source .venv/bin/activate`.\n\n4. Install the `mcp-ntopng` package with `uv pip install -e .` from the project main directory. \n\n4. For easy testing, you can run `mcp dev mcp_ntopng/mcp_server.py` to start the MCP server. **CHANGE WITH A PROPER CHAT CLIENT**\n\n### Environment Variables\n\nThe following environment variables are used to configure the database connection:\n\n* `NTOPNG_HOST`: The hostname of the `ntopng` server\n* `NTOPNG_DBUSER`: The username for Clickhouse DB authentication\n* `NTOPNG_DBPASSWORD`: The password for Clickhouse DB authentication\n* `NTOPNG_API_KEY`: The `ntopng` authentication token.\n\n#### Optional\n* `NTOPNG_DBPORT`: The port number of the Clickhouse DB in the  `ntopng` server\n  - Default: `9000` if HTTPS is enabled, `8123` if disabled\n  - Usually doesn't need to be set unless using a non-standard port\n* `NTOPNG_SECURE`: Enable/disable a TLS connection\n  - Default: `false`\n  - Set to `true` for a secure TLS connections\n* `NTOPNG_VERIFY`: Enable/disable SSL certificate verification\n  - Default: `true`\n  - Set to `false to disable certificate verification (not recommended for production)\n* `NTOPNG_CONNECT_TIMEOUT`: Connection timeout in seconds\n  - Default: `30\n  - Increase this value if you experience connection timeouts\n* `NTOPNG_SEND_RECEIVE_TIMEOUT`: Send/receive timeout in seconds\n  - Default: `300`\n  - Increase this value for long-running queries\n\n\n> Check [TLS Setup](https://www.ntop.org/guides/ntopng/flow_dump/clickhouse/clickhouse.html#tls-connection) in the `ntopng` documentation for details about setting up a TLS connection to Clickhouse.\n\n### Development\nInstall the package on the local machine:\n```\n$ uv sync\n$ uv pip install -e .\n```\nRun the MCP Inspector\n```\n$ cd mcp_ntopng\n$ source .env\n$ CLIENT_PORT=8077 SERVER_PORT=8078  mcp dev run_mcp_ntopng.py --with clickhouse-driver --with python-dotenv --with uvicorn --with pip-system-certs\n```\nUse the local library in Claude Desktop.\n\nFind:  /Users/marco/Library/Application\\ Support/Claude/claude_desktop_config.json \n\nEdit the claude_desktop_config.json changing the local paths:\n```\n{\n    \"mcpServers\": {\n      \"mcp-ntopng\": {\n        \"command\": \"/Users/marco/Development/claude/mcp-server-ntopng/.venv/bin/python\",\n        \"args\": [\n           \"/Users/marco/Development/claude/mcp-server-ntopng/run_mcp_ntopng.py\"\n        ],\n        \"env\": {\n          \"NTOPNG_HOST\": \"marcoeg-nod004.ntoplink.com\",\n          \"NTOPNG_DBPORT\": \"9000\",\n          \"NTOPNG_DBUSER\": \"default\",\n          \"NTOPNG_DBPASSWORD\": \"\",\n          \"NTOPNG_SECURE\": \"false\",\n          \"NTOPNG_VERIFY\": \"false\",\n          \"NTOPNG_CONNECT_TIMEOUT\": \"30\",\n          \"NTOPNG_SEND_RECEIVE_TIMEOUT\": \"300\",\n          \"SELECT_QUERY_TIMEOUT_SECS\": \"30\",\n          \"NTOPNG_API_KEY\": \"NTOPNG_TOKEN\"\n        }\n      }\n    }\n  }\n  ```\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ntopng",
        "monitoring",
        "logging",
        "server ntopng",
        "alerts ntopng",
        "ntopng framework"
      ],
      "category": "monitoring-and-logging"
    },
    "mdwooky--logstash-input-pluginname": {
      "owner": "mdwooky",
      "name": "logstash-input-pluginname",
      "url": "https://github.com/mdwooky/logstash-input-pluginname",
      "imageUrl": "/freedevtools/mcp/pfp/mdwooky.webp",
      "description": "Streamlines data ingestion into Logstash pipelines by integrating various input sources, facilitating enhanced data processing capabilities.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "Jupyter Notebook",
      "updated_at": "2019-07-08T07:44:51Z",
      "readme_content": "# logstash-input-pluginname",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "logstash",
        "logging",
        "pipelines",
        "logstash pipelines",
        "logstash input",
        "mdwooky logstash"
      ],
      "category": "monitoring-and-logging"
    },
    "mgsrevolver--consolespy": {
      "owner": "mgsrevolver",
      "name": "consolespy",
      "url": "https://github.com/mgsrevolver/consolespy",
      "imageUrl": "/freedevtools/mcp/pfp/mgsrevolver.webp",
      "description": "Captures browser console logs and integrates them into the Cursor IDE for enhanced debugging. Facilitates real-time access to console data within the development environment.",
      "stars": 12,
      "forks": 5,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-07-07T22:30:10Z",
      "readme_content": "# ConsoleSpy: An MCP Server for Cursor\n\nA tool that captures browser console logs and makes them available in Cursor IDE through the Model Context Protocol (MCP).\n\n## Overview\n\nThis tool consists of:\n\n1. A server that captures console logs from your browser\n2. An MCP server that makes these logs available to Cursor\n3. A browser extension that sends console logs to the server\n\n## Installation\n\n### Server Setup\n\n1. Clone this repository:\n\n   ```bash\n   git clone https://github.com/mgsrevolver/consolespy.git\n   cd consolespy\n   ```\n\n2. Install dependencies:\n\n   ```bash\n   npm install\n   ```\n\n3. Run the setup script to configure the MCP connection for Cursor:\n   ```bash\n   ./setup.sh\n   ```\n\n### Browser Extension Installation\n\n1. Install the extension from the [Chrome Web Store](https://chromewebstore.google.com/detail/consolespy/dakkehkpcaahfjembkhchoplffakkcie?authuser=0&hl=en)\n\n   OR\n\n   Load the extension in developer mode:\n\n   - Open Chrome and go to `chrome://extensions/`\n   - Enable \"Developer mode\" (toggle in the top-right corner)\n   - Click \"Load unpacked\" and select the `extension` folder from this repository\n\n## Usage\n\n### Starting the Servers\n\n1. Start the console log server:\n\n   ```bash\n   node mcp-server.js\n   ```\n\n2. In a separate terminal, start the MCP server:\n   ```bash\n   npx supergateway --port 8766 --stdio \"node console-spy-mcp.js\"\n   ```\n\nAlternatively, you can use the start script to launch both servers at once:\n\n```bash\n./start-servers.sh\n```\n\n### Configuring Cursor\n\nAfter running the setup script, you still need to manually add the MCP server in Cursor:\n\n1. Go to Settings > Features > MCP in Cursor\n2. Add a new MCP server with:\n   - Name: ConsoleSpy\n   - Type: sse\n   - URL: http://localhost:8766/sse\n\n### Using the Extension\n\n1. Click the extension icon in your browser to toggle it on/off\n2. When enabled, all console logs from the current tab will be sent to the server\n3. In Cursor, you can now access these logs through the MCP interface\n\n## Customizing\n\n### Changing the Console Log Server Port\n\nIf you need to use a different port for the console log server (default is 3333), you'll need to update the port in multiple places:\n\n1. In `mcp-server.js`, change the port variable:\n\n   ```javascript\n   const port = 3333; // Change to your desired port\n   ```\n\n2. In `console-spy-mcp.js`, update the URL to match your new port:\n\n   ```javascript\n   const CONSOLE_SERVER_URL = 'http://localhost:3333/mcp'; // Change 3333 to your port\n   ```\n\n3. In the browser extension's `content.js`, update the server URL:\n\n   ```javascript\n   const serverUrl = 'http://localhost:3333/console-logs'; // Change 3333 to your port\n   ```\n\n4. If using `start-servers.sh`, update the port reference there as well.\n\n**Important:** You must use the same port number in all locations. We recommend doing a global search for \"3333\" in the project files and replacing all instances with your desired port number to ensure consistency.\n\nIf you're testing locally with another application already using port 3333, changing this port is essential for the tool to work correctly.\n\n## Troubleshooting\n\n- Make sure both servers are running\n- Verify the browser extension is enabled for the tab you're debugging\n- Check that you've added the MCP server in Cursor's settings\n- If logs aren't appearing, try refreshing the page or restarting the servers\n\n## License\n\n[MIT License](LICENSE)\n\n<a href=\"https://glama.ai/mcp/servers/uVY0ERoHE0\">\n  <img alt=\"badge\" width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/uVY0ERoHE0/badge\" />\n</a>\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "consolespy",
        "console",
        "debugging",
        "console logs",
        "mgsrevolver consolespy",
        "console data"
      ],
      "category": "monitoring-and-logging"
    },
    "modelcontextprotocol--servers": {
      "owner": "modelcontextprotocol",
      "name": "servers",
      "url": "https://github.com/modelcontextprotocol/servers",
      "imageUrl": "/freedevtools/mcp/pfp/modelcontextprotocol.webp",
      "description": "A test server that showcases all features of the Model Context Protocol, implementing prompts, tools, and resources for builders of MCP clients. Provides interactive tools for echoing messages, adding numbers, and demonstrating progress for long-running operations.",
      "stars": 69476,
      "forks": 8235,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-04T12:31:15Z",
      "readme_content": "# Model Context Protocol servers\n\nThis repository is a collection of *reference implementations* for the [Model Context Protocol](https://modelcontextprotocol.io/) (MCP), as well as references to community-built servers and additional resources.\n\nThe servers in this repository showcase the versatility and extensibility of MCP, demonstrating how it can be used to give Large Language Models (LLMs) secure, controlled access to tools and data sources.\nTypically, each MCP server is implemented with an MCP SDK:\n\n- [C# MCP SDK](https://github.com/modelcontextprotocol/csharp-sdk)\n- [Go MCP SDK](https://github.com/modelcontextprotocol/go-sdk)\n- [Java MCP SDK](https://github.com/modelcontextprotocol/java-sdk)\n- [Kotlin MCP SDK](https://github.com/modelcontextprotocol/kotlin-sdk)\n- [PHP MCP SDK](https://github.com/modelcontextprotocol/php-sdk)\n- [Python MCP SDK](https://github.com/modelcontextprotocol/python-sdk)\n- [Ruby MCP SDK](https://github.com/modelcontextprotocol/ruby-sdk)\n- [Rust MCP SDK](https://github.com/modelcontextprotocol/rust-sdk)\n- [Swift MCP SDK](https://github.com/modelcontextprotocol/swift-sdk)\n- [TypeScript MCP SDK](https://github.com/modelcontextprotocol/typescript-sdk)\n\n> [!NOTE]\n> Lists in this README are maintained in alphabetical order to minimize merge conflicts when adding new items.\n\n## 🌟 Reference Servers\n\nThese servers aim to demonstrate MCP features and the official SDKs.\n\n- **[Everything](src/everything)** - Reference / test server with prompts, resources, and tools.\n- **[Fetch](src/fetch)** - Web content fetching and conversion for efficient LLM usage.\n- **[Filesystem](src/filesystem)** - Secure file operations with configurable access controls.\n- **[Git](src/git)** - Tools to read, search, and manipulate Git repositories.\n- **[Memory](src/memory)** - Knowledge graph-based persistent memory system.\n- **[Sequential Thinking](src/sequentialthinking)** - Dynamic and reflective problem-solving through thought sequences.\n- **[Time](src/time)** - Time and timezone conversion capabilities.\n\n### Archived\n\nThe following reference servers are now archived and can be found at [servers-archived](https://github.com/modelcontextprotocol/servers-archived).\n\n- **[AWS KB Retrieval](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/aws-kb-retrieval-server)** - Retrieval from AWS Knowledge Base using Bedrock Agent Runtime.\n- **[Brave Search](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/brave-search)** - Web and local search using Brave's Search API.  Has been replaced by the [official server](https://github.com/brave/brave-search-mcp-server).\n- **[EverArt](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/everart)** - AI image generation using various models.\n- **[GitHub](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/github)** - Repository management, file operations, and GitHub API integration.\n- **[GitLab](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/gitlab)** - GitLab API, enabling project management.\n- **[Google Drive](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/gdrive)** - File access and search capabilities for Google Drive.\n- **[Google Maps](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/google-maps)** - Location services, directions, and place details.\n- **[PostgreSQL](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/postgres)** - Read-only database access with schema inspection.\n- **[Puppeteer](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/puppeteer)** - Browser automation and web scraping.\n- **[Redis](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/redis)** - Interact with Redis key-value stores.\n- **[Sentry](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/sentry)** - Retrieving and analyzing issues from Sentry.io.\n- **[Slack](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/slack)** - Channel management and messaging capabilities. Now maintained by [Zencoder](https://github.com/zencoderai/slack-mcp-server)\n- **[SQLite](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/sqlite)** - Database interaction and business intelligence capabilities.\n\n## 🤝 Third-Party Servers\n\n### 🎖️ Official Integrations\n\nOfficial integrations are maintained by companies building production ready MCP servers for their platforms.\n\n- <img height=\"12\" width=\"12\" src=\"https://www.21st.dev/favicon.ico\" alt=\"21st.dev Logo\" /> **[21st.dev Magic](https://github.com/21st-dev/magic-mcp)** - Create crafted UI components inspired by the best 21st.dev design engineers.\n- <img height=\"12\" width=\"12\" src=\"https://framerusercontent.com/images/LpSK1tSZweomrAHOMAj9Gea96lA.svg\" alt=\"Paragon Logo\" /> **[ActionKit by Paragon](https://github.com/useparagon/paragon-mcp)** - Connect to 130+ SaaS integrations (e.g. Slack, Salesforce, Gmail) with Paragon’s [ActionKit](https://www.useparagon.com/actionkit) API.\n- <img height=\"12\" width=\"12\" src=\"https://invoxx-public-bucket.s3.eu-central-1.amazonaws.com/frontend-resources/adfin-logo-small.svg\" alt=\"Adfin Logo\" /> **[Adfin](https://github.com/Adfin-Engineering/mcp-server-adfin)** - The only platform you need to get paid - all payments in one place, invoicing and accounting reconciliations with [Adfin](https://www.adfin.com/).\n- <img height=\"12\" width=\"12\" src=\"https://github.com/AgentOps-AI/agentops/blob/main/docs/favicon.png\" alt=\"AgentOps Logo\" /> **[AgentOps](https://github.com/AgentOps-AI/agentops-mcp)** - Provide observability and tracing for debugging AI agents with [AgentOps](https://www.agentops.ai/) API.\n- <img height=\"12\" width=\"12\" src=\"https://www.agentql.com/favicon/favicon.png\" alt=\"AgentQL Logo\" /> **[AgentQL](https://github.com/tinyfish-io/agentql-mcp)** - Enable AI agents to get structured data from unstructured web with [AgentQL](https://www.agentql.com/).\n- <img height=\"12\" width=\"12\" src=\"https://agentrpc.com/favicon.ico\" alt=\"AgentRPC Logo\" /> **[AgentRPC](https://github.com/agentrpc/agentrpc)** - Connect to any function, any language, across network boundaries using [AgentRPC](https://www.agentrpc.com/).\n- **[Agentset](https://github.com/agentset-ai/mcp-server)** - RAG for your knowledge base connected to [Agentset](https://agentset.ai).\n- <img height=\"12\" width=\"12\" src=\"https://aiven.io/favicon.ico\" alt=\"Aiven Logo\" /> **[Aiven](https://github.com/Aiven-Open/mcp-aiven)** - Navigate your [Aiven projects](https://go.aiven.io/mcp-server) and interact with the PostgreSQL®, Apache Kafka®, ClickHouse® and OpenSearch® services\n- <img height=\"12\" width=\"12\" src=\"https://www.alation.com/resource-center/download/7p3vnbbznfiw/34FMtBTex5ppvs2hNYa9Fc/c877c37e88e5339878658697c46d2d58/Alation-Logo-Bug-Primary.svg\" alt=\"Alation Logo\" /> **[Alation](https://github.com/Alation/alation-ai-agent-sdk)** - Unlock the power of the enterprise Data Catalog by harnessing tools provided by the Alation MCP server.\n- <img height=\"12\" width=\"12\" src=\"https://i.postimg.cc/5NYw9qjS/alby-icon-head-yellow-500x500.png\" alt=\"Alby Logo\" /> **[Alby Bitcoin Payments](https://github.com/getAlby/mcp)** - Connect any bitcoin lightning wallet to your agent to send and receive instant payments globally with your agent.\n- **[Algolia](https://github.com/algolia/mcp)** - Use AI agents to provision, configure, and query your [Algolia](https://algolia.com) search indices.\n- <img height=\"12\" width=\"12\" src=\"https://img.alicdn.com/imgextra/i4/O1CN01epkXwH1WLAXkZfV6N_!!6000000002771-2-tps-200-200.png\" alt=\"Alibaba Cloud AnalyticDB for MySQL Logo\" /> **[Alibaba Cloud AnalyticDB for MySQL](https://github.com/aliyun/alibabacloud-adb-mysql-mcp-server)** - Connect to an [AnalyticDB for MySQL](https://www.alibabacloud.com/en/product/analyticdb-for-mysql) cluster for getting database or table metadata, querying and analyzing data. It will be supported to add the OpenAPI for cluster operation in the future.\n- <img height=\"12\" width=\"12\" src=\"https://github.com/aliyun/alibabacloud-adbpg-mcp-server/blob/master/images/AnalyticDB.png\" alt=\"Alibaba Cloud AnalyticDB for PostgreSQL Logo\" /> **[Alibaba Cloud AnalyticDB for PostgreSQL](https://github.com/aliyun/alibabacloud-adbpg-mcp-server)** - An MCP server to connect to [AnalyticDB for PostgreSQL](https://github.com/aliyun/alibabacloud-adbpg-mcp-server) instances, query and analyze data.\n- <img height=\"12\" width=\"12\" src=\"https://img.alicdn.com/imgextra/i3/O1CN0101UWWF1UYn3rAe3HU_!!6000000002530-2-tps-32-32.png\" alt=\"DataWorks Logo\" /> **[Alibaba Cloud DataWorks](https://github.com/aliyun/alibabacloud-dataworks-mcp-server)** - A Model Context Protocol (MCP) server that provides tools for AI, allowing it to interact with the [DataWorks](https://www.alibabacloud.com/help/en/dataworks/) Open API through a standardized interface. This implementation is based on the Alibaba Cloud Open API and enables AI agents to perform cloud resources operations seamlessly.\n- <img height=\"12\" width=\"12\" src=\"https://opensearch-shanghai.oss-cn-shanghai.aliyuncs.com/ouhuang/aliyun-icon.png\" alt=\"Alibaba Cloud OpenSearch Logo\" /> **[Alibaba Cloud OpenSearch](https://github.com/aliyun/alibabacloud-opensearch-mcp-server)** - This MCP server equips AI Agents with tools to interact with [OpenSearch](https://help.aliyun.com/zh/open-search/?spm=5176.7946605.J_5253785160.6.28098651AaYZXC) through a standardized and extensible interface.\n- <img height=\"12\" width=\"12\" src=\"https://github.com/aliyun/alibaba-cloud-ops-mcp-server/blob/master/image/alibaba-cloud.png\" alt=\"Alibaba Cloud OPS Logo\" /> **[Alibaba Cloud OPS](https://github.com/aliyun/alibaba-cloud-ops-mcp-server)** - Manage the lifecycle of your Alibaba Cloud resources with [CloudOps Orchestration Service](https://www.alibabacloud.com/en/product/oos) and Alibaba Cloud OpenAPI.\n- <img height=\"12\" width=\"12\" src=\"https://github.com/aliyun/alibabacloud-rds-openapi-mcp-server/blob/main/assets/alibabacloudrds.png\" alt=\"Alibaba Cloud RDS MySQL Logo\" /> **[Alibaba Cloud RDS](https://github.com/aliyun/alibabacloud-rds-openapi-mcp-server)** - An MCP server designed to interact with the Alibaba Cloud RDS OpenAPI, enabling programmatic management of RDS resources via an LLM.\n- <img height=\"12\" width=\"12\" src=\"https://www.alipayplus.com/favicon.ico\" alt=\"AlipayPlus Logo\" /> **[AlipayPlus](https://github.com/alipay/global-alipayplus-mcp)** - Connect your AI Agents to AlipayPlus Checkout Payment.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.allvoicelab.com/resources/workbench/dist/icon-dark.ico\" alt=\"AllVoiceLab Logo\" /> **[AllVoiceLab](https://www.allvoicelab.com/mcp)** - An AI voice toolkit with TTS, voice cloning, and video translation, now available as an MCP server for smarter agent integration.\n- <img height=\"12\" width=\"12\" src=\"https://files.alpaca.markets/webassets/favicon-32x32.png\" alt=\"Alpaca Logo\" /> **[Alpaca](https://github.com/alpacahq/alpaca-mcp-server)** – Alpaca's MCP server lets you trade stocks and options, analyze market data, and build strategies through [Alpaca's Trading API](https://alpaca.markets/)\n- <img height=\"12\" width=\"12\" src=\"https://www.alphavantage.co/logo.png/\" alt=\"AlphaVantage Logo\" /> **[AlphaVantage](https://mcp.alphavantage.co/)** - Connect to 100+ APIs for financial market data, including stock prices, fundamentals, and more from [AlphaVantage](https://www.alphavantage.co)\n- <img height=\"12\" width=\"12\" src=\"https://alttester.com/app/themes/alttester-sage-theme/public/images/logo-alttester.038ec8.png\" alt=\"AltTester Logo\" /> **[AltTester®](https://alttester.com/docs/desktop/latest/pages/ai-extension.html)** - Use AltTester® capabilities to connect and test your Unity or Unreal game. Write game test automation faster and smarter, using [AltTester](https://alttester.com) and the AltTester® MCP server. \n- <img height=\"12\" width=\"12\" src=\"https://www.antom.com/favicon.ico\" alt=\"Antom Logo\" /> **[Antom](https://github.com/alipay/global-antom-mcp)** - Connect your AI Agents to Antom Checkout Payment.\n- <img height=\"12\" width=\"12\" src=\"https://developers.anytype.io/img/favicon.ico\" alt=\"Anytype Logo\" /> **[Anytype](https://github.com/anyproto/anytype-mcp)** - An MCP server enabling AI assistants to interact with [Anytype](https://anytype.io) - a local and collaborative wiki - to organize objects, lists, and more through natural language.\n- <img height=\"12\" width=\"12\" src=\"https://doris.apache.org/images/favicon.ico\" alt=\"Apache Doris Logo\" /> **[Apache Doris](https://github.com/apache/doris-mcp-server)** - MCP Server For [Apache Doris](https://doris.apache.org/), an MPP-based real-time data warehouse.\n- <img height=\"12\" width=\"12\" src=\"https://iotdb.apache.org/img/logo.svg\" alt=\"Apache IoTDB Logo\" /> **[Apache IoTDB](https://github.com/apache/iotdb-mcp-server)** - MCP Server for [Apache IoTDB](https://github.com/apache/iotdb) database and its tools\n- **[Apache Pinot](https://github.com/startreedata/mcp-pinot)** – MCP server for running real - time analytics queries on Apache Pinot, an open-source OLAP database built for high-throughput, low-latency powering real-time applications.\n- <img height=\"12\" width=\"12\" src=\"https://apify.com/favicon.ico\" alt=\"Apify Logo\" /> **[Apify](https://github.com/apify/apify-mcp-server)** - Use 6,000+ pre-built cloud tools to extract data from websites, e-commerce, social media, search engines, maps, and more\n- <img height=\"12\" width=\"12\" src=\"https://2052727.fs1.hubspotusercontent-na1.net/hubfs/2052727/cropped-cropped-apimaticio-favicon-1-32x32.png\" alt=\"APIMatic Logo\" /> **[APIMatic MCP](https://github.com/apimatic/apimatic-validator-mcp)** - APIMatic MCP Server is used to validate OpenAPI specifications using [APIMatic](https://www.apimatic.io/). The server processes OpenAPI files and returns validation summaries by leveraging APIMatic's API.\n- <img height=\"12\" width=\"12\" src=\"https://apollo-server-landing-page.cdn.apollographql.com/_latest/assets/favicon.png\" alt=\"Apollo Graph Logo\" /> **[Apollo MCP Server](https://github.com/apollographql/apollo-mcp-server/)** - Connect your GraphQL APIs to AI agents\n- <img height=\"12\" width=\"12\" src=\"https://developer.aqara.com/favicon.ico\" alt=\"Aqara Logo\" /> **[Aqara MCP Server](https://github.com/aqara/aqara-mcp-server/)** - Control  [Aqara](https://www.aqara.com/) smart home devices, query status, execute scenes, and much more using natural language.\n- <img height=\"12\" width=\"12\" src=\"https://media.licdn.com/dms/image/v2/C4D0BAQEeD7Dxbpadkw/company-logo_200_200/company-logo_200_200/0/1644692667545/archbee_logo?e=2147483647&v=beta&t=lTi9GRIoqzG6jN3kJC26uZWh0q3uiQelsH6mGoq_Wfw\" alt=\"Archbee Logo\" /> **[Archbee](https://www.npmjs.com/package/@archbee/mcp)** - Write and publish documentation that becomes the trusted source for instant answers with AI. Stop cobbling tools and use [Archbee](https://www.archbee.com/) — the first complete documentation platform.\n- <img height=\"12\" width=\"12\" src=\"https://phoenix.arize.com/wp-content/uploads/2023/04/cropped-Favicon-32x32.png\" alt=\"Arize-Phoenix Logo\" /> **[Arize Phoenix](https://github.com/Arize-ai/phoenix/tree/main/js/packages/phoenix-mcp)** - Inspect traces, manage prompts, curate datasets, and run experiments using [Arize Phoenix](https://github.com/Arize-ai/phoenix), an open-source AI and LLM observability tool.\n- <img height=\"12\" width=\"12\" src=\"https://731523176-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FaVUBXRZbpAgtjYf5HsvO%2Fuploads%2FaRRrVVocXCTr6GkepfCx%2Flogo_color.svg?alt=media&token=3ba24089-0ab2-421f-a9d9-41f2f94f954a\" alt=\"Armor Logo\" /> **[Armor Crypto MCP](https://github.com/armorwallet/armor-crypto-mcp)** - MCP to interface with multiple blockchains, staking, DeFi, swap, bridging, wallet management, DCA, Limit Orders, Coin Lookup, Tracking and more.\n- <img height=\"12\" width=\"12\" src=\"https://console.asgardeo.io/app/libs/themes/wso2is/assets/images/branding/favicon.ico\" alt=\"Asgardeo Logo\" /> **[Asgardeo](https://github.com/asgardeo/asgardeo-mcp-server)** - MCP server to interact with your [Asgardeo](https://wso2.com/asgardeo) organization through LLM tools.\n- <img height=\"12\" width=\"12\" src=\"https://www.datastax.com/favicon-32x32.png\" alt=\"DataStax logo\" /> **[Astra DB](https://github.com/datastax/astra-db-mcp)** - Comprehensive tools for managing collections and documents in a [DataStax Astra DB](https://www.datastax.com/products/datastax-astra) NoSQL database with a full range of operations such as create, update, delete, find, and associated bulk actions.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/66598898fd13d51606c3215d/66ccbfef13bd8bc19d587578_favicon-32x32.png\" alt=\"Atla Logo\" /> **[Atla](https://github.com/atla-ai/atla-mcp-server)** - Enable AI agents to interact with the [Atla API](https://docs.atla-ai.com/) for state-of-the-art LLMJ evaluation.\n- <img height=\"12\" width=\"12\" src=\"https://assets.atlan.com/assets/atlan-a-logo-blue-background.png\" alt=\"Atlan Logo\" /> **[Atlan](https://github.com/atlanhq/agent-toolkit/tree/main/modelcontextprotocol)** - The Atlan Model Context Protocol server allows you to interact with the [Atlan](https://www.atlan.com/) services through multiple tools.\n- <img height=\"12\" width=\"12\" src=\"https://www.atlassian.com/favicon.ico\" alt=\"Atlassian Logo\" /> **[Atlassian](https://www.atlassian.com/platform/remote-mcp-server)** - Securely interact with Jira work items and Confluence pages, and search across both.\n- <img height=\"12\" width=\"12\" src=\"https://res.oafimg.cn/-/737b3b3ffed9b19e/logo.png\" alt=\"AtomGit Logo\" /> **[AtomGit](https://atomgit.com/atomgit-open-source-ecosystem/atomgit-mcp-server)** - Official AtomGit server for integration with repository management, PRs, issues, branches, labels, and more.\n- <img height=\"12\" width=\"12\" src=\"https://resources.audiense.com/hubfs/favicon-1.png\" alt=\"Audiense Logo\" /> **[Audiense Insights](https://github.com/AudienseCo/mcp-audiense-insights)** - Marketing insights and audience analysis from [Audiense](https://www.audiense.com/products/audiense-insights) reports, covering demographic, cultural, influencer, and content engagement analysis.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.auth0.com/website/website/favicons/auth0-favicon.svg\" alt=\"Auth0 Logo\" /> **[Auth0](https://github.com/auth0/auth0-mcp-server)** - MCP server for interacting with your Auth0 tenant, supporting creating and modifying actions, applications, forms, logs, resource servers, and more.\n- <img height=\"12\" width=\"12\" src=\"https://firstorder.ai/favicon_auth.ico\" alt=\"Authenticator App Logo\" /> **[Authenticator App · 2FA](https://github.com/firstorderai/authenticator_mcp)** - A secure MCP (Model Context Protocol) server that enables AI agents to interact with the Authenticator App.\n- <img height=\"12\" width=\"12\" src=\"https://a0.awsstatic.com/libra-css/images/site/fav/favicon.ico\" alt=\"AWS Logo\" /> **[AWS](https://github.com/awslabs/mcp)** -  Specialized MCP servers that bring AWS best practices directly to your development workflow.\n- <img height=\"12\" width=\"12\" src=\"https://axiom.co/favicon.ico\" alt=\"Axiom Logo\" /> **[Axiom](https://github.com/axiomhq/mcp-server-axiom)** - Query and analyze your Axiom logs, traces, and all other event data in natural language\n- <img height=\"12\" width=\"12\" src=\"https://cdn-dynmedia-1.microsoft.com/is/content/microsoftcorp/acom_social_icon_azure\" alt=\"Microsoft Azure Logo\" /> **[Azure](https://github.com/microsoft/mcp/tree/main/servers/Azure.Mcp.Server)** - The Azure MCP Server gives MCP Clients access to key Azure services and tools like Azure Storage, Cosmos DB, the Azure CLI, and more.\n- <img height=\"12\" width=\"12\" src=\"https://cdn-dynmedia-1.microsoft.com/is/content/microsoftcorp/1062064-Products-1.2-24x24\" alt=\"Microsoft Azure DevOps Logo\" /> **[Azure DevOps](https://github.com/microsoft/azure-devops-mcp)** - Interact with Azure DevOps services like repositories, work items, builds, releases, test plans, and code search.\n- <img height=\"12\" width=\"12\" src=\"https://application.backdocket.com/favicon.ico\" alt=\"Backdocket Logo\" /> **[Backdocket](https://ai.backdocket.com)** - Search, Retrieve, and Update your **[Backdocket](https://backdocket.com)** data. This currently includes Claims, Matters, Contacts, Tasks and Advanced Searches. To easily use the Remote Mcp Server utilize the following url: **[https://ai.backdocket.com/mcp]([https://backdocket.com](https://ai.backdocket.com/mcp))**\n- <img height=\"12\" width=\"12\" src=\"https://mapopen-website-wiki.cdn.bcebos.com/LOGO/lbsyunlogo_icon.ico\" alt=\"Baidu Map Logo\" /> **[Baidu Map](https://github.com/baidu-maps/mcp)** - [Baidu Map MCP Server](https://lbsyun.baidu.com/faq/api?title=mcpserver/base) provides tools for AI agents to interact with Baidu Maps APIs, enabling location-based services and geospatial data analysis.\n- <img height=\"12\" width=\"12\" src=\"https://www.bankless.com/favicon.ico\" alt=\"Bankless Logo\" /> **[Bankless Onchain](https://github.com/bankless/onchain-mcp)** - Query Onchain data, like ERC20 tokens, transaction history, smart contract state.\n- <img height=\"12\" width=\"12\" src=\"https://baserow.io/img/logo_baserow_square_large.png\" alt=\"Baserow Logo\" /> **[Baserow](https://gitlab.com/baserow/baserow/-/tree/develop/backend/src/baserow/api/mcp)** - Query data from Baserow self-hosted or SaaS databases using MCP integration.\n- <img height=\"12\" width=\"12\" src=\"https://bicscan.io/favicon.png\" alt=\"BICScan Logo\" /> **[BICScan](https://github.com/ahnlabio/bicscan-mcp)** - Risk score / asset holdings of EVM blockchain address (EOA, CA, ENS) and even domain names.\n- <img height=\"12\" width=\"12\" src=\"https://web-cdn.bitrise.io/favicon.ico\" alt=\"Bitrise Logo\" /> **[Bitrise](https://github.com/bitrise-io/bitrise-mcp)** - Chat with your builds, CI, and [more](https://bitrise.io/blog/post/chat-with-your-builds-ci-and-more-introducing-the-bitrise-mcp-server).\n- <img height=\"12\" width=\"12\" src=\"https://boikot.xyz/assets/favicon.svg\" alt=\"boikot Logo\" /> **[Boikot](https://github.com/boikot-xyz/boikot)** - Learn about the ethical and unethical actions of major companies with [boikot.xyz](https://boikot.xyz/).\n- <img height=\"12\" width=\"12\" src=\"https://boldsign.com/favicon.ico\" alt=\"BoldSign Logo\" /> **[BoldSign](https://github.com/boldsign/boldsign-mcp)** - Search, request, and manage e-signature contracts effortlessly with [BoldSign](https://boldsign.com/).\n- <img height=\"12\" width=\"12\" src=\"https://boost.space/favicon.ico\" alt=\"Boost.space Logo\" /> **[Boost.space](https://github.com/boostspace/boostspace-mcp-server)** - An MCP server integrating with [Boost.space](https://boost.space) for centralized, automated business data from 2000+ sources.\n- <img height=\"12\" width=\"12\" src=\"https://www.box.com/favicon.ico\" alt=\"Box Logo\" /> **[Box](https://github.com/box-community/mcp-server-box)** - Interact with the Intelligent Content Management platform through Box AI.\n- <img height=\"12\" width=\"12\" src=\"https://www.brightdata.com/favicon.ico\" alt=\"BrightData Logo\" /> **[BrightData](https://github.com/luminati-io/brightdata-mcp)** - Discover, extract, and interact with the web - one interface powering automated access across the public internet.\n- <img height=\"12\" width=\"12\" src=\"https://browserbase.com/favicon.ico\" alt=\"Browserbase Logo\" /> **[Browserbase](https://github.com/browserbase/mcp-server-browserbase)** - Automate browser interactions in the cloud (e.g. web navigation, data extraction, form filling, and more)\n- <img height=\"12\" width=\"12\" src=\"https://browserstack.wpenginepowered.com/wp-content/themes/browserstack/img/favicons/favicon.ico\" alt=\"BrowserStack Logo\" /> **[BrowserStack](https://github.com/browserstack/mcp-server)** - Access BrowserStack's [Test Platform](https://www.browserstack.com/test-platform) to debug, write and fix tests, do accessibility testing and more.\n- <img height=\"12\" width=\"12\" src=\"https://www.google.com/s2/favicons?domain=buildkite.com&sz=24\" alt=\"Buildkite Logo\" /> **[Buildkite](https://github.com/buildkite/buildkite-mcp-server)** - Exposing Buildkite data (pipelines, builds, jobs, tests) to AI tooling and editors.\n- <img height=\"12\" width=\"12\" src=\"https://bldbl.dev/favico.png\" alt=\"Buildable Logo\" />**[Buildable](https://github.com/chunkydotdev/bldbl-mcp)** (TypeScript) - Official MCP server for Buildable AI-powered development platform. Enables AI assistants to manage tasks, track progress, get project context, and collaborate with humans on software projects.\n- <img height=\"12\" width=\"12\" src=\"https://builtwith.com/favicon.ico\" alt=\"BuiltWith Logo\" /> **[BuiltWith](https://github.com/builtwith/mcp)** - Identify the technology stack behind any website.\n- <img height=\"12\" width=\"12\" src=\"https://portswigger.net/favicon.ico\" alt=\"PortSwigger Logo\" /> **[Burp Suite](https://github.com/PortSwigger/mcp-server)** - MCP Server extension allowing AI clients to connect to [Burp Suite](https://portswigger.net)\n- <img src=\"https://app.cal.com/favicon.ico\" alt=\"Cal.com\" width=\"12\" height=\"12\"> **[Cal.com](https://www.npmjs.com/package/@calcom/cal-mcp?activeTab=readme)** - Connect to the Cal.com API to schedule and manage bookings and appointments.\n- <img height=\"12\" width=\"12\" src=\"https://campertunity.com/assets/icon/favicon.ico\" alt=\"Campertunity Logo\" /> **[Campertunity](https://github.com/campertunity/mcp-server)** - Search campgrounds around the world on campertunity, check availability, and provide booking links.\n- <img height=\"12\" width=\"12\" src=\"https://static.canva.com/static/images/favicon.ico\" alt=\"Canva logo\" /> **[Canva](https://www.canva.dev/docs/apps/mcp-server/)** — Provide AI - powered development assistance for [Canva](https://canva.com) apps and integrations.\n- <img height=\"12\" width=\"12\" src=\"https://carbonvoice.app/favicon.ico\" alt=\"Carbon Voice Logo\" /> **[Carbon Voice](https://github.com/PhononX/cv-mcp-server)** - MCP Server that connects AI Agents to [Carbon Voice](https://getcarbon.app). Create, manage, and interact with voice messages, conversations, direct messages, folders, voice memos, AI actions and more in [Carbon Voice](https://getcarbon.app).\n-  **[Cartesia](https://github.com/cartesia-ai/cartesia-mcp)** - Connect to the [Cartesia](https://cartesia.ai/) voice platform to perform text-to-speech, voice cloning etc.\n- <img height=\"12\" width=\"12\" src=\"https://www.cashfree.com/favicon.ico\" alt=\"Cashfree logo\" /> **[Cashfree](https://github.com/cashfree/cashfree-mcp)** - [Cashfree Payments](https://www.cashfree.com/) official MCP server.\n- **[CB Insights](https://github.com/cbinsights/cbi-mcp-server)** - Use the [CB Insights](https://www.cbinsights.com) MCP Server to connect to [ChatCBI](https://www.cbinsights.com/chatcbi/)\n- <img height=\"12\" width=\"12\" src=\"https://cleanupcrew.ai/favicon-light.png\" alt=\"Cleanup Crew logo\" /> **[Cleanup Crew](https://cleanupcrew.ai/install)** - Real-time human support service for non-technical founders using AI coding tools. When AI hits a wall, request instant human help directly from your IDE.\n- <img height=\"12\" width=\"12\" src=\"https://www.chargebee.com/static/resources/brand/favicon.png\" alt=\"Chargebee Logo\" /> **[Chargebee](https://github.com/chargebee/agentkit/tree/main/modelcontextprotocol)** - MCP Server that connects AI agents to [Chargebee platform](https://www.chargebee.com).\n- <img height=\"12\" width=\"12\" src=\"https://cheqd.io/wp-content/uploads/2023/03/logo_cheqd_favicon.png\" alt=\"Cheqd Logo\" /> **[Cheqd](https://github.com/cheqd/mcp-toolkit)** - Enable AI Agents to be trusted, verified, prevent fraud, protect your reputation, and more through [cheqd's](https://cheqd.io) Trust Registries and Credentials.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.chiki.studio/brand/logo.png\" alt=\"Chiki StudIO Logo\" /> **[Chiki StudIO](https://chiki.studio/galimybes/mcp/)** - Create your own configurable MCP servers purely via configuration (no code), with instructions, prompts, and tools support.\n- <img height=\"12\" width=\"12\" src=\"https://trychroma.com/_next/static/media/chroma-logo.ae2d6e4b.svg\" alt=\"Chroma Logo\" /> **[Chroma](https://github.com/chroma-core/chroma-mcp)** - Embeddings, vector search, document storage, and full-text search with the open-source AI application database\n- <img height=\"12\" width=\"12\" src=\"https://www.chronulus.com/favicon/chronulus-logo-blue-on-alpha-square-128x128.ico\" alt=\"Chronulus AI Logo\" /> **[Chronulus AI](https://github.com/ChronulusAI/chronulus-mcp)** - Predict anything with Chronulus AI forecasting and prediction agents.\n- <img height=\"12\" width=\"12\" src=\"https://circleci.com/favicon.ico\" alt=\"CircleCI Logo\" /> **[CircleCI](https://github.com/CircleCI-Public/mcp-server-circleci)** - Enable AI Agents to fix build failures from CircleCI.\n- <img height=\"12\" width=\"12\" src=\"https://assets.zilliz.com/Zilliz_Logo_Mark_White_20230223_041013_86057436cc.png\" alt=\"Claude Context Logo\" /> **[Claude Context](https://github.com/zilliztech/claude-context)** - Bring your codebase as context to Claude Code\n- <img height=\"12\" width=\"12\" src=\"https://clickhouse.com/favicon.ico\" alt=\"ClickHouse Logo\" /> **[ClickHouse](https://github.com/ClickHouse/mcp-clickhouse)** - Query your [ClickHouse](https://clickhouse.com/) database server.\n- <img height=\"12\" width=\"12\" src=\"https://brand.clicksend.com/_ipx/s_794x608/img/clicksend_icon_only.svg\" alt=\"ClickSend Logo\" /> **[ClickSend](https://github.com/ClickSend/clicksend-mcp-server/)** - This is the official ClickSend MCP Server developed by ClickSend team.\n- <img height=\"12\" width=\"12\" src=\"https://7463-tcb-advanced-a656fc-1257967285.tcb.qcloud.la/mcp/cloudbase-logo.svg\" alt=\"CloudBase Logo\" /> **[CloudBase](https://github.com/TencentCloudBase/CloudBase-AI-ToolKit)** - One-stop backend services for WeChat Mini-Programs and full-stack apps with serverless cloud functions and databases by [Tencent CloudBase](https://tcb.cloud.tencent.com/)\n- <img height=\"12\" width=\"12\" src=\"https://www.cloudbet.com/favicon.ico\" alt=\"Cloudbet Logo\" /> **[Cloudbet](https://github.com/cloudbet/sports-mcp-server)** - Structured sports and esports data via Cloudbet API: fixtures, live odds, stake limits, and markets.\n- <img height=\"12\" width=\"12\" src=\"https://www.cloudbees.com/favicon.ico\" alt=\"CloudBees Logo\" /> **[CloudBees](https://docs.cloudbees.com/docs/cloudbees-mcp/latest/)** - Enable AI access to your [CloudBees Unify](https://www.cloudbees.com/unify) environment.\n- <img src=\"http://www.google.com/s2/favicons?domain=www.cloudera.com\" alt=\"Cloudera Iceberg\" width=\"12\" height=\"12\"> **[Cloudera Iceberg](https://github.com/cloudera/iceberg-mcp-server)** - enabling AI on the [Open Data Lakehouse](https://www.cloudera.com/products/open-data-lakehouse.html).\n- <img alt=\"cloudflare\" height=\"12\" width=\"12\" src=\"https://cdn.simpleicons.org/cloudflare\" /> **[Cloudflare](https://github.com/cloudflare/mcp-server-cloudflare)** - Deploy, configure & interrogate your resources on the Cloudflare developer platform (e.g. Workers/KV/R2/D1)\n- <img src=\"https://cdn.prod.website-files.com/64d41aab8183c7c3324ddb29/67c0f1e272e51cf3c511c17c_Gyph.svg\" alt=\"Cloudinary\" width=\"12\" height=\"12\"> **[Cloudinary](https://github.com/cloudinary/mcp-servers)** - Exposes Cloudinary's media upload, transformation, AI analysis, management, optimization and delivery as tools usable by AI agents\n- <img height=\"12\" width=\"12\" src=\"https://raw.githubusercontent.com/Cloudsway-AI/smartsearch/refs/heads/main/plugin_cloudsway.ico\" alt=\"Cloudsway Logo\" /> **[Cloudsway SmartSearch](https://github.com/Cloudsway-AI/smartsearch)** - Web search MCP server powered by Cloudsway, supporting keyword search, language, and safety options. Returns structured JSON results.\n-  **[Codacy](https://github.com/codacy/codacy-mcp-server/)** - Interact with [Codacy](https://www.codacy.com) API to query code quality issues, vulnerabilities, and coverage insights about your code.\n-  **[CodeLogic](https://github.com/CodeLogicIncEngineering/codelogic-mcp-server)** - Interact with [CodeLogic](https://codelogic.com), a Software Intelligence platform that graphs complex code and data architecture dependencies, to boost AI accuracy and insight.\n- <img height=\"12\" width=\"12\" src=\"https://www.coingecko.com/favicon.ico\" alt=\"CoinGecko Logo\" /> **[CoinGecko](https://github.com/coingecko/coingecko-typescript/tree/main/packages/mcp-server)** - Official [CoinGecko API](https://www.coingecko.com/en/api) MCP Server for Crypto Price & Market Data, across 200+ Blockchain Networks and 8M+ Tokens.\n- <img height=\"12\" width=\"12\" src=\"https://www.comet.com/favicon.ico\" alt=\"Comet Logo\" /> **[Comet Opik](https://github.com/comet-ml/opik-mcp)** - Query and analyze your [Opik](https://github.com/comet-ml/opik) logs, traces, prompts and all other telemetry data from your LLMs in natural language.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/6572bd8c27ee5db3eb91f4b3/6572bd8d27ee5db3eb91f55e_favicon-dashflow-webflow-template.svg\" alt=\"OSS Conductor Logo\" /> <img height=\"12\" width=\"12\" src=\"https://orkes.io/icons/icon-48x48.png\" alt=\"Orkes Conductor Logo\" />**[Conductor](https://github.com/conductor-oss/conductor-mcp)** - Interact with Conductor (OSS and Orkes) REST APIs.\n- <img height=\"12\" width=\"12\" src=\"https://platform.composio.dev/favicon.ico\" alt=\"Composio Logo\" /> **[Composio](https://docs.composio.dev/docs/mcp-overview#-getting-started)** – Use [Composio](https://composio.dev) to connect 100+ tools. Zero setup. Auth built-in. Made for agents, works for humans.\n- <img height=\"12\" width=\"12\" src=\"https://www.confluent.io/favicon.ico\" alt=\"Confluent Logo\" /> **[Confluent](https://github.com/confluentinc/mcp-confluent)** - Interact with Confluent Kafka and Confluent Cloud REST APIs.\n- <img src=\"https://contrastsecurity.com/favicon.ico\" alt=\"Contrast Security\" width=\"12\" height=\"12\"> **[Contrast Security](https://github.com/Contrast-Security-OSS/mcp-contrast)** - Brings Contrast's vulnerability and SCA data into your coding agent to quickly remediate vulnerabilities.\n- <img height=\"12\" width=\"12\" src=\"https://www.convex.dev/favicon.ico\" alt=\"Convex Logo\" /> **[Convex](https://stack.convex.dev/convex-mcp-server)** - Introspect and query your apps deployed to Convex.\n- <img height=\"12\" width=\"12\" src=\"https://www.cortex.io/favicon.ico\" alt=\"Cortex Logo\" /> **[Cortex](https://github.com/cortexapps/cortex-mcp)** - Official MCP server for [Cortex](https://www.cortex.io).\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/605755?s=200&v=4\" alt=\"Couchbase Logo\" /> **[Couchbase](https://github.com/Couchbase-Ecosystem/mcp-server-couchbase)** - Interact with the data stored in Couchbase clusters.\n- <img height=\"12\" width=\"12\" src=\"https://github.com/user-attachments/assets/b256f9fa-2020-4b37-9644-c77229ef182b\" alt=\"CRIC 克而瑞 LOGO\"> **[CRIC Wuye AI](https://github.com/wuye-ai/mcp-server-wuye-ai)** - Interact with capabilities of the CRIC Wuye AI platform, an intelligent assistant specifically for the property management industry.\n- <img height=\"12\" width=\"12\" src=\"https://www.crowdstrike.com/etc.clientlibs/crowdstrike/clientlibs/crowdstrike-common/resources/favicon.ico\" alt=\"CrowdStrike Logo\" /> **[CrowdStrike Falcon](https://github.com/CrowdStrike/falcon-mcp)** - Connects AI agents with the CrowdStrike Falcon platform for intelligent security analysis, providing programmatic access to detections, incidents, behaviors, threat intelligence, hosts, vulnerabilities, and identity protection capabilities.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/58433296\" alt=\"CTERA Edge Filer\" /> **[CTERA Edge Filer](https://github.com/ctera/mcp-ctera-edge)** - CTERA Edge Filer delivers intelligent edge caching and multiprotocol file access, enabling fast, secure access to files across core and remote sites.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/58433296\" alt=\"CTERA Portal\" /> **[CTERA Portal](https://github.com/ctera/mcp-ctera-core)** - CTERA Portal is a multi-tenant, multi-cloud platform that delivers a global namespace and unified management across petabytes of distributed content.\n- <img height=\"12\" width=\"12\" src=\"https://app.cycode.com/img/favicon.ico\" alt=\"Cycode Logo\" /> **[Cycode](https://github.com/cycodehq/cycode-cli#mcp-command-experiment)** - Boost security in your dev lifecycle via SAST, SCA, Secrets & IaC scanning with [Cycode](https://cycode.com/).\n- <img height=\"12\" width=\"12\" src=\"http://app.itsdart.com/static/img/favicon.png\" alt=\"Dart Logo\" /> **[Dart](https://github.com/its-dart/dart-mcp-server)** - Interact with task, doc, and project data in [Dart](https://itsdart.com), an AI-native project management tool\n- <img height=\"12\" width=\"12\" src=\"https://cdn.bfldr.com/9AYANS2F/at/k8bgnnxhb4bggjk88r4x9snf/databricks-symbol-color.svg?auto=webp&format=png&width=12&height=13\" alt=\"Databricks Logo\" /> **[Databricks](https://docs.databricks.com/aws/en/generative-ai/mcp/)** - Connect to data, AI tools & agents, and the rest of the Databricks platform using turnkey managed MCP servers. Or, host your own custom MCP servers within the Databricks security and data governance boundary.\n- <img height=\"12\" width=\"12\" src=\"https://datahub.com/wp-content/uploads/2025/04/cropped-Artboard-1-32x32.png\" alt=\"DataHub Logo\" /> **[DataHub](https://github.com/acryldata/mcp-server-datahub)** - Search your data assets, traverse data lineage, write SQL queries, and more using [DataHub](https://datahub.com/) metadata.\n- <img height=\"12\" width=\"12\" src=\"https://www.daytona.io/brand/social-daytona-icon.png\" alt=\"Daytona Logo\" /> **[Daytona](https://github.com/daytonaio/daytona/tree/main/apps/cli/mcp)** - Fast and secure execution of your AI generated code with [Daytona](https://daytona.io) sandboxes\n- <img height=\"12\" width=\"12\" src=\"https://debugg.ai/favicon.svg\" alt=\"Debugg AI Logo\" /> **[Debugg.AI](https://github.com/debugg-ai/debugg-ai-mcp)** - Zero-Config, Fully AI-Managed End-to-End Testing for any code gen platform via [Debugg.AI](https://debugg.ai) remote browsing test agents.\n- <img height=\"12\" width=\"12\" src=\"https://www.deepl.com/img/logo/deepl-logo-blue.svg\" alt=\"DeepL Logo\" /> **[DeepL](https://github.com/DeepLcom/deepl-mcp-server)** - Translate or rewrite text with [DeepL](https://deepl.com)'s very own AI models using [the DeepL API](https://developers.deepl.com/docs)\n- <img height=\"12\" width=\"12\" src=\"https://defang.io/_next/static/media/defang-icon-dark-colour.25f95b77.svg\" alt=\"Defang Logo\" /> **[Defang](https://github.com/DefangLabs/defang/blob/main/src/pkg/mcp/README.md)** - Deploy your project to the cloud seamlessly with the [Defang](https://www.defang.io) platform without leaving your integrated development environment\n- <img height=\"12\" width=\"12\" src=\"https://detailer.ginylil.com/favicon.ico\" alt=\"Detailer Logo\" /> **[Detailer](https://detailer.ginylil.com/)** – Instantly generate rich, AI-powered documentation for your GitHub repositories. Designed for AI agents to gain deep project context before taking action.\n- <img height=\"12\" width=\"12\" src=\"https://devcycle.com/_next/image?url=%2Fassets%2Fbrand%2FColor-logo-mark.png&w=384&q=75\" alt=\"DevCycle Logo\" /> **[DevCycle](https://docs.devcycle.com/cli-mcp/mcp-getting-started)** - Create and monitor feature flags using natural language in your AI coding assistant.\n- <img height=\"12\" width=\"12\" src=\"https://www.devhub.com/img/upload/favicon-196x196-dh.png\" alt=\"DevHub Logo\" /> **[DevHub](https://github.com/devhub/devhub-cms-mcp)** - Manage and utilize website content within the [DevHub](https://www.devhub.com) CMS platform\n- <img height=\"12\" width=\"12\" src=\"https://devrev.ai/favicon.ico\" alt=\"DevRev Logo\" /> **[DevRev](https://github.com/devrev/mcp-server)** - An MCP server to integrate with DevRev APIs to search through your DevRev Knowledge Graph where objects can be imported from diff. Sources listed [here](https://devrev.ai/docs/import#available-sources).\n- <img height=\"12\" width=\"12\" src=\"https://dexpaprika.com/favicon.ico\" alt=\"DexPaprika Logo\" /> **[DexPaprika (CoinPaprika)](https://github.com/coinpaprika/dexpaprika-mcp)** - Access real-time DEX data, liquidity pools, token information, and trading analytics across multiple blockchain networks with [DexPaprika](https://dexpaprika.com) by CoinPaprika.\n- <img height=\"12\" width=\"12\" src=\"https://github.com/dolthub/dolt/raw/main/images/Dolt-Logo@3x.svg\" alt=\"Dolt Logo\" /> **[Dolt](https://github.com/dolthub/dolt-mcp)** - The official MCP server for version-controlled [Dolt](https://doltdb.com/) databases.\n- <img height=\"12\" width=\"12\" src=\"https://eu.getdot.ai/favicon.ico\" alt=\"GetDot.ai Logo\" /> **[Dot (GetDot.ai)](https://docs.getdot.ai/dot/integrations/mcp)** - Fetch, analyze or visualize data from your favorite database or data warehouse (Snowflake, BigQuery, Redshift, Databricks, Clickhouse, ...) with [Dot](https://getdot.ai), your AI Data Analyst. This remote MCP server is a one-click integration for user that have setup Dot.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/65421071?s=200&v=4\" alt=\"Drata Logo\" /> **[Drata](https://drata.com/mcp)** - Get hands-on with our experimental MCP server—bringing real-time compliance intelligence into your AI workflows.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/204530939?s=200&v=4\" alt=\"Dumpling AI Logo\" /> **[Dumpling AI](https://github.com/Dumpling-AI/mcp-server-dumplingai)** - Access data, web scraping, and document conversion APIs by [Dumpling AI](https://www.dumplingai.com/)\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/58178984\" alt=\"Dynatrace Logo\" /> **[Dynatrace](https://github.com/dynatrace-oss/dynatrace-mcp)** - Manage and interact with the [Dynatrace Platform ](https://www.dynatrace.com/platform) for real-time observability and monitoring.\n- <img height=\"12\" width=\"12\" src=\"https://e2b.dev/favicon.ico\" alt=\"E2B Logo\" /> **[E2B](https://github.com/e2b-dev/mcp-server)** - Run code in secure sandboxes hosted by [E2B](https://e2b.dev)\n- <img height=\"12\" width=\"12\" src=\"https://www.edgee.cloud/favicon.ico\" alt=\"Edgee Logo\" /> **[Edgee](https://github.com/edgee-cloud/mcp-server-edgee)** - Deploy and manage [Edgee](https://www.edgee.cloud) components and projects\n- <img height=\"12\" width=\"12\" src=\"https://static.edubase.net/media/brand/favicon/favicon-32x32.png\" alt=\"EduBase Logo\" /> **[EduBase](https://github.com/EduBase/MCP)** - Interact with [EduBase](https://www.edubase.net), a comprehensive e-learning platform with advanced quizzing, exam management, and content organization capabilities\n- <img height=\"12\" width=\"12\" src=\"https://www.elastic.co/favicon.ico\" alt=\"Elasticsearch Logo\" /> **[Elasticsearch](https://github.com/elastic/mcp-server-elasticsearch)** - Query your data in [Elasticsearch](https://www.elastic.co/elasticsearch)\n- <img height=\"12\" width=\"12\" src=\"https://github.com/EmberAGI/arbitrum-vibekit/blob/main/img/Ember%20Black.png?raw=true\" alt=\"Ember AI Logo\" /> **[Ember AI](https://docs.emberai.xyz/)** - A unified MCP server that enables AI agents to execute cross-chain DeFi strategies.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/656eaf5c6da3527caf362363/656ecc07555afac40df4c40e_Facicon.png\" alt=\"Endor Labs Logo\" /> **[Endor Labs](https://docs.endorlabs.com/deployment/ide/mcp/)** - Find and fix security risks in you code. Integrate [Endor Labs](https://endorlabs.com) to scan and secure your code from vulnerabilities and secret leaks.\n- <img height=\"12\" width=\"12\" src=\"https://esignatures.com/favicon.ico\" alt=\"eSignatures Logo\" /> **[eSignatures](https://github.com/esignaturescom/mcp-server-esignatures)** - Contract and template management for drafting, reviewing, and sending binding contracts.\n- <img height=\"12\" width=\"12\" src=\"https://rainmaker.espressif.com/favicon.ico\" alt=\"ESP RainMaker Logo\" /> **[ESP RainMaker](https://github.com/espressif/esp-rainmaker-mcp)** - Official Espressif MCP Server to Control and Manage ESP RainMaker Devices.\n- <img height=\"12\" width=\"12\" src=\"https://exa.ai/images/favicon-32x32.png\" alt=\"Exa Logo\" /> **[Exa](https://github.com/exa-labs/exa-mcp-server)** - Search Engine made for AIs by [Exa](https://exa.ai)\n- <img height=\"12\" width=\"12\" src=\"https://www.explorium.ai/wp-content/uploads/2025/04/Favicon-Purple-512x512-1-150x150.png\" alt=\"Explorium Logo\" /> **[Explorium](https://github.com/explorium-ai/mcp-explorium)** - B2B data and infrastructure for AI SDR & GTM Agents [Explorium](https://www.explorium.ai)\n- **[FalkorDB](https://github.com/FalkorDB/FalkorDB-MCPServer)** - FalkorDB graph database server get schema and read/write-cypher [FalkorDB](https://www.falkordb.com)\n- <img height=\"12\" width=\"12\" src=\"https://fetchserp.com/icon.png\" alt=\"fetchSERP Logo\" /> **[fetchSERP](https://github.com/fetchSERP/fetchserp-mcp-server-node)** - All-in-One SEO & Web Intelligence Toolkit API [fetchSERP](https://www.fetchserp.com/)\n- <img height=\"12\" width=\"12\" src=\"https://fewsats.com/favicon.svg\" alt=\"Fewsats Logo\" /> **[Fewsats](https://github.com/Fewsats/fewsats-mcp)** - Enable AI Agents to purchase anything in a secure way using [Fewsats](https://fewsats.com)\n- <img height=\"12\" width=\"12\" src=\"https://fibery.io/favicon.svg\" alt=\"Fibery Logo\" /> **[Fibery](https://github.com/Fibery-inc/fibery-mcp-server)** - Perform queries and entity operations in your [Fibery](https://fibery.io) workspace.\n- <img height=\"12\" width=\"12\" src=\"https://financialdatasets.ai/favicon.ico\" alt=\"Financial Datasets Logo\" /> **[Financial Datasets](https://github.com/financial-datasets/mcp-server)** - Stock market API made for AI agents\n- <img height=\"12\" width=\"12\" src=\"https://www.gstatic.com/devrel-devsite/prod/v7aeef7f1393bb1d75a4489145c511cdd5aeaa8e13ad0a83ec1b5b03612e66330/firebase/images/favicon.png\" alt=\"Firebase Logo\" /> **[Firebase](https://github.com/firebase/firebase-tools/blob/master/src/mcp)** - Firebase's experimental [MCP Server](https://firebase.google.com/docs/cli/mcp-server) to power your AI Tools\n- <img height=\"12\" width=\"12\" src=\"https://firecrawl.dev/favicon.ico\" alt=\"Firecrawl Logo\" /> **[Firecrawl](https://github.com/firecrawl/firecrawl-mcp-server)** - Extract web data with [Firecrawl](https://firecrawl.dev)\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/100200663?s=200&v=4\" alt=\"Firefly Logo\" /> **[Firefly](https://github.com/gofireflyio/firefly-mcp)** - Integrates, discovers, manages, and codifies cloud resources with [Firefly](https://firefly.ai).\n- <img height=\"12\" width=\"12\" src=\"https://fireproof.storage/favicon.ico\" alt=\"Fireproof Logo\" /> **[Fireproof](https://github.com/fireproof-storage/mcp-database-server)** - Immutable ledger database with live synchronization\n- <img height=\"12\" width=\"12\" src=\"https://fixparser.dev/favicon.ico\" alt=\"FIXParser Logo\" /> **[FIXParser](https://gitlab.com/logotype/fixparser/-/tree/main/packages/fixparser-plugin-mcp)** - A modern FIX Protocol engine for AI-powered trading agents\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/52471808\" alt=\"Fluid Attacks Logo\" /> **[Fluid Attacks](https://github.com/fluidattacks/mcp)** - Interact with the [Fluid Attacks](https://fluidattacks.com/) API, enabling vulnerability management, organization insights, and GraphQL query execution.\n- <img height=\"12\" width=\"12\" src=\"https://forevervm.com/icon.png\" alt=\"ForeverVM Logo\" /> **[ForeverVM](https://github.com/jamsocket/forevervm/tree/main/javascript/mcp-server)** - Run Python in a code sandbox.\n- <img height=\"12\" width=\"12\" src=\"https://flutterwave.com/favicon.ico\" alt=\"Flutterwave Logo\" /> **[Flutterwave](https://github.com/bajoski34/mcp-flutterwave/tree/main)** - Interact with Flutterwave payment solutions API, to manage transactions, payment links and more.\n- <img height=\"12\" width=\"12\" src=\"https://app.gibsonai.com/favicon.ico\" alt=\"GibsonAI Logo\" /> **[GibsonAI](https://github.com/GibsonAI/mcp)** - AI-Powered Cloud databases: Build, migrate, and deploy database instances with AI\n- <img height=\"12\" width=\"12\" src=\"https://gcore.com/assets/favicon/favicon-16x16.png\" alt=\"Gcore Logo\" /> **[Gcore](https://github.com/G-Core/gcore-mcp-server)** - Interact with Gcore platform services via LLM assistants, providing unified access to CDN, GPU Cloud & AI Inference, Video Streaming, WAAP, and cloud resources including instances and networks.\n- <img height=\"12\" width=\"12\" src=\"https://gitea.com/assets/img/favicon.svg\" alt=\"Gitea Logo\" /> **[Gitea](https://gitea.com/gitea/gitea-mcp)** - Interact with Gitea instances with MCP.\n- <img height=\"12\" width=\"12\" src=\"https://gitee.com/favicon.ico\" alt=\"Gitee Logo\" /> **[Gitee](https://github.com/oschina/mcp-gitee)** - Gitee API integration, repository, issue, and pull request management, and more.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/5ee25cbe47310017adf964da/6323888a9b9f4e22a7bc766b_GG%20Favicon.svg\" alt=\"GitGuardian Logo\" /> **[GitGuardian](https://github.com/GitGuardian/gg-mcp)** - GitGuardian official MCP server - Scan projects using GitGuardian's industry-leading API, which features over 500 secret detectors to prevent credential leaks before they reach public repositories. Resolve security incidents directly with rich contextual data for rapid, automated remediation.\n- <img height=\"12\" width=\"12\" src=\"https://gitlab.com/favicon.ico\" alt=\"GitLab Logo\" /> **[GitLab](https://docs.gitlab.com/user/gitlab_duo/model_context_protocol/mcp_server/)** - GitLab's official MCP server enabling AI tools to securely access GitLab project data, manage issues, and perform repository operations via OAuth 2.0.\n- <img height=\"12\" width=\"12\" src=\"https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png\" alt=\"GitHub Logo\" /> **[GitHub](https://github.com/github/github-mcp-server)** - GitHub's official MCP Server.\n- <img height=\"12\" width=\"12\" src=\"https://www.gitkraken.com/wp-content/uploads/2021/03/android-chrome-144x144-1.png\" alt=\"GitKraken Logo\" /> **[GitKraken](https://github.com/gitkraken/gk-cli?tab=readme-ov-file#mcp-server)** - A CLI for interacting with GitKraken APIs. Includes an MCP server via `gk mcp` that not only wraps GitKraken APIs, but also Jira, GitHub, GitLab, and more.\n- <img height=\"12\" width=\"12\" src=\"https://app.glean.com/images/favicon3-196x196.png\" alt=\"Glean Logo\" /> **[Glean](https://github.com/gleanwork/mcp-server)** - Enterprise search and chat using Glean's API.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.jsdelivr.net/gh/jsdelivr/globalping-media@refs/heads/master/icons/android-chrome-192x192.png\" alt=\"Globalping Logo\" /> **[Globalping](https://github.com/jsdelivr/globalping-mcp-server)** - Access a network of thousands of probes to run network commands like ping, traceroute, mtr, http and DNS resolve.\n- <img height=\"12\" width=\"12\" src=\"https://gnucleus.ai/favicon.ico\" alt=\"gNucleus Logo\" /> **[gNucleus Text-To-CAD](https://github.com/gNucleus/text-to-cad-mcp)** - Generate CAD parts and assemblies from text using gNucleus AI models.\n- <img height=\"12\" width=\"12\" src=\"https://www.gstatic.com/cgc/favicon.ico\" alt=\"Google Cloud Logo\" /> **[Google Cloud Run](https://github.com/GoogleCloudPlatform/cloud-run-mcp)** - Deploy code to Google Cloud Run\n- <img height=\"12\" width=\"12\" src=\"https://api.gologin.com/favicon.ico\" alt=\"GoLogin Logo\" /> **[GoLogin MCP server](https://github.com/gologinapp/gologin-mcp)** - Manage your GoLogin browser profiles and automation directly through AI conversations!\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/3717923?s=200&v=4\" alt=\"Google Maps Platform Logo\" /> **[Google Maps Platform Code Assist](https://github.com/googlemaps/platform-ai/tree/main/packages/code-assist)** - Ground agents on fresh, official documentation and code samples for optimal geo-related guidance and code..\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/6605a2979ff17b2cd1939cd4/6605a460de47e7596ed84f06_icon256.png\" alt=\"gotoHuman Logo\" /> **[gotoHuman](https://github.com/gotohuman/gotohuman-mcp-server)** - Human-in-the-loop platform - Allow AI agents and automations to send requests for approval to your [gotoHuman](https://www.gotohuman.com) inbox.\n- <img height=\"12\" width=\"12\" src=\"https://grafana.com/favicon.ico\" alt=\"Grafana Logo\" /> **[Grafana](https://github.com/grafana/mcp-grafana)** - Search dashboards, investigate incidents and query datasources in your Grafana instance\n- <img height=\"12\" width=\"12\" src=\"https://grafbase.com/favicon.ico\" alt=\"Grafbase Logo\" /> **[Grafbase](https://github.com/grafbase/grafbase/tree/main/crates/mcp)** - Turn your GraphQL API into an efficient MCP server with schema intelligence in a single command.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/5f5e90c17e7c9eb95c7acb17/61d3457a519242f2c75c725c_favicon.png\" alt=\"Grain Logo\" /> **[Grain](https://grain.com/release-note/06-18-2025)** - Access your Grain meetings notes & transcripts directly in claude and generate reports with native Claude Prompts.\n- <img height=\"12\" width=\"12\" src=\"https://framerusercontent.com/images/KCOWBYLKunDff1Dr452y6EfjiU.png\" alt=\"Graphlit Logo\" /> **[Graphlit](https://github.com/graphlit/graphlit-mcp-server)** - Ingest anything from Slack to Gmail to podcast feeds, in addition to web crawling, into a searchable [Graphlit](https://www.graphlit.com) project.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/64a5291e7847ac04fe1531ad/64a529af2f1fc7debc26f2a6_favicon-32x32.avif\" alt=\"Gremlin favicon\" /> **[Gremlin](https://github.com/gremlin/mcp)** - The official [Gremlin](https://www.gremlin.com) MCP server. Analyze your reliability posture, review recent tests and chaos engineering experiments, and create detailed reports.\n- <img height=\"12\" width=\"12\" src=\"https://greptime.com/favicon.ico\" alt=\"Greptime Logo\" /> **[GreptimeDB](https://github.com/GreptimeTeam/greptimedb-mcp-server)** - Provides AI assistants with a secure and structured way to explore and analyze data in [GreptimeDB](https://github.com/GreptimeTeam/greptimedb).\n- <img height=\"12\" width=\"12\" src=\"https://growi.org/assets/images/favicon.ico\" alt=\"GROWI Logo\" /> **[GROWI](https://github.com/growilabs/growi-mcp-server)** - Official MCP Server to integrate with GROWI APIs.\n- <img height=\"12\" width=\"12\" src=\"https://gyazo.com/favicon.ico\" alt=\"Gyazo Logo\" /> **[Gyazo](https://github.com/nota/gyazo-mcp-server)** - Search, fetch, upload, and interact with Gyazo images, including metadata and OCR data.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/6374050260446c42f94dc90f/63d828be3e13d32ee6973f35_favicon-32x32.png\" alt=\"Harper Logo\" /> **[Harper](https://github.com/HarperDB/mcp-server)** - An MCP server providing an interface for MCP clients to access data within [Harper](https://www.harpersystems.dev/).\n- <img height=\"12\" width=\"12\" src=\"https://www.herokucdn.com/favicons/favicon.ico\" alt=\"Heroku Logo\" /> **[Heroku](https://github.com/heroku/heroku-mcp-server)** - Interact with the Heroku Platform through LLM-driven tools for managing apps, add-ons, dynos, databases, and more.\n- <img height=\"12\" width=\"12\" src=\"https://heyoncall.com/favicon.ico\" alt=\"HeyOnCall Logo\" /> **[HeyOnCall](https://heyoncall.com/blog/mcp-server-for-paging-a-human)** - Page a human, sending critical or non-critical alerts to the free [HeyOnCall](https://heyoncall.com/) iOS or Android apps.\n- <img height=\"12\" width=\"12\" src=\"https://www.hiveflow.ai/favicon.ico\" alt=\"Hiveflow Logo\" /> **[Hiveflow](https://github.com/hiveflowai/hiveflow-mcp-server)** - Create, manage, and execute agentic AI workflows directly from your assistant.\n- <img height=\"12\" width=\"12\" src=\"https://hiveintelligence.xyz/favicon.ico\" alt=\"Hive Intelligence Logo\" /> **[Hive Intelligence](https://github.com/hive-intel/hive-crypto-mcp)** - Ultimate cryptocurrency MCP for AI assistants with unified access to crypto, DeFi, and Web3 analytics\n- <img height=\"12\" width=\"12\" src=\"https://img.alicdn.com/imgextra/i3/O1CN01d9qrry1i6lTNa2BRa_!!6000000004364-2-tps-218-200.png\" alt=\"Hologres Logo\" /> **[Hologres](https://github.com/aliyun/alibabacloud-hologres-mcp-server)** - Connect to a [Hologres](https://www.alibabacloud.com/en/product/hologres) instance, get table metadata, query and analyze data.\n- <img height=\"12\" width=\"12\" src=\"https://brew.sh/assets/img/favicon.ico\" alt=\"Homebrew Logo\" /> **[Homebrew](https://docs.brew.sh/MCP-Server)** Allows [Homebrew](https://brew.sh) users to run Homebrew commands locally.\n- <img height=\"12\" width=\"12\" src=\"https://www.honeycomb.io/favicon.ico\" alt=\"Honeycomb Logo\" /> **[Honeycomb](https://github.com/honeycombio/honeycomb-mcp)** Allows [Honeycomb](https://www.honeycomb.io/) Enterprise customers to query and analyze their data, alerts, dashboards, and more; and cross-reference production behavior with the codebase.\n- <img height=\"12\" width=\"12\" src=\"https://static.hsinfrastatic.net/StyleGuideUI/static-3.438/img/sprocket/favicon-32x32.png\" alt=\"HubSpot Logo\" /> **[HubSpot](https://developer.hubspot.com/mcp)** - Connect, manage, and interact with [HubSpot](https://www.hubspot.com/) CRM data\n- <img height=\"12\" width=\"12\" src=\"https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo.svg\" alt=\"HuggingFace Logo\" /> **[Hugging Face](https://huggingface.co/settings/mcp)** - Connect to the Hugging Face Hub APIs programmatically: semantic search for spaces and papers, exploration of datasets and models, and access to all compatible MCP Gradio tool spaces!\n- <img height=\"12\" width=\"12\" src=\"https://hunter.io/favicon.ico\" alt=\"Hunter Logo\" /> **[Hunter](https://github.com/hunter-io/hunter-mcp)** - Interact with the [Hunter API](https://hunter.io) to get B2B data using natural language.\n- <img height=\"12\" width=\"12\" src=\"https://app.hyperbolic.xyz/hyperbolic-logo.svg\" alt=\"Hyperbolic Labs Logo\" /> **[Hyperbolic](https://github.com/HyperbolicLabs/hyperbolic-mcp)** - Interact with Hyperbolic's GPU cloud, enabling agents and LLMs to view and rent available GPUs, SSH into them, and run GPU-powered workloads for you.\n- <img height=\"12\" width=\"12\" src=\"https://hyperbrowser-assets-bucket.s3.us-east-1.amazonaws.com/Hyperbrowser-logo.png\" alt=\"Hyperbrowsers23 Logo\" /> **[Hyperbrowser](https://github.com/hyperbrowserai/mcp)** - [Hyperbrowser](https://www.hyperbrowser.ai/) is the next-generation platform empowering AI agents and enabling effortless, scalable browser automation.\n- **[IBM wxflows](https://github.com/IBM/wxflows/tree/main/examples/mcp/javascript)** - Tool platform by IBM to build, test and deploy tools for any data source\n- <img height=\"12\" width=\"12\" src=\"https://www.getinboxzero.com/icon.png\" alt=\"Inbox Zero Logo\" /> **[Inbox Zero](https://github.com/elie222/inbox-zero/tree/main/apps/mcp-server)** - AI personal assistant for email [Inbox Zero](https://www.getinboxzero.com)\n- <img height=\"12\" width=\"12\" src=\"https://www.inflectra.com/Favicon.ico\" alt=\"Inflectra Logo\" /> **[Inflectra Spira](https://github.com/Inflectra/mcp-server-spira)** - Connect to your instance of the SpiraTest, SpiraTeam or SpiraPlan application lifecycle management platform by [Inflectra](https://www.inflectra.com)\n-  **[Inkeep](https://github.com/inkeep/mcp-server-python)** - RAG Search over your content powered by [Inkeep](https://inkeep.com)\n- <img height=\"12\" width=\"12\" src=\"https://integration.app/favicon.ico\" alt=\"Integration App Icon\" /> **[Integration App](https://github.com/integration-app/mcp-server)** - Interact with any other SaaS applications on behalf of your customers.\n- <img height=\"12\" width=\"12\" src=\"https://www.ip2location.io/favicon.ico\" alt=\"IP2Location.io Icon\" /> **[IP2Location.io](https://github.com/ip2location/mcp-ip2location-io)** - Interact with IP2Location.io API to retrieve the geolocation information for an IP address.\n- <img height=\"12\" width=\"12\" src=\"https://static.iplocate.io/custom/logo-square-rounded.png\" alt=\"IPLocate Icon\" /> **[IPLocate](https://github.com/iplocate/mcp-server-iplocate)** - Look up IP address geolocation, network information, detect proxies and VPNs, and find abuse contact details using [IPLocate.io](https://www.iplocate.io)\n- <img height=\"12\" width=\"12\" src=\"https://jellyfish.co/favicon.ico\" alt=\"Jellyfish Logo\" /> **[Jellyfish](https://github.com/Jellyfish-AI/jellyfish-mcp)** – Give your AI agent context about your team's software engineering allocations and workflow via the [Jellyfish](https://jellyfish.co) platform\n- <img alt=\"jetbrains\" height=\"12\" width=\"12\" src=\"https://cdn.simpleicons.org/jetbrains\" /> **[JetBrains](https://www.jetbrains.com/help/idea/mcp-server.html)** – Work on your code with JetBrains IDEs: IntelliJ IDEA, PhpStorm, etc.\n- <img height=\"12\" width=\"12\" src=\"https://speedmedia.jfrog.com/08612fe1-9391-4cf3-ac1a-6dd49c36b276/media.jfrog.com/wp-content/uploads/2019/04/20131046/Jfrog16-1.png\" alt=\"JFrog Logo\" /> **[JFrog](https://github.com/jfrog/mcp-jfrog)** - Model Context Protocol (MCP) Server for the [JFrog](https://jfrog.com/) Platform API, enabling repository management, build tracking, release lifecycle management, and more.\n- <img height=\"12\" width=\"12\" src=\"https://jenkins.io/images/logos/jenkins/jenkins.svg\" alt=\"Jenkins Logo\" /> **[Jenkins](https://plugins.jenkins.io/mcp-server/)** - Official Jenkins MCP Server plugin enabling AI assistants to manage builds, check job statuses, retrieve logs, and integrate with CI/CD pipelines through standardized MCP interface.\n- <img height=\"12\" width=\"12\" src=\"https://kagi.com/favicon.ico\" alt=\"Kagi Logo\" /> **[Kagi Search](https://github.com/kagisearch/kagimcp)** - Search the web using Kagi's search API\n- <img height=\"12\" width=\"12\" src=\"https://connection.keboola.com/favicon.ico\" alt=\"Keboola Logo\" /> **[Keboola](https://github.com/keboola/keboola-mcp-server)** - Build robust data workflows, integrations, and analytics on a single intuitive platform.\n- <img height=\"12\" width=\"12\" src=\"https://mcp.onkernel.com/favicon.svg\" alt=\"Kernel Logo\" /> **[Kernel](https://github.com/onkernel/kernel-mcp-server)** – Access Kernel's cloud‑based browsers via MCP.\n- <img height=\"12\" width=\"12\" src=\"https://keywordseverywhere.com/favicon.ico\" alt=\"Keywords Everywhere Logo\" /> **[Keywords Everywhere](https://api.keywordseverywhere.com/docs/#/mcp_integration)** – Access SEO data through the official Keywords Everywhere API MCP server.\n- <img height=\"12\" width=\"12\" src=\"https://keywordspeopleuse.com/favicon.ico\" alt=\"KeywordsPeopleUse Logo\" /> **[KeywordsPeopleUse.com](https://github.com/data-skunks/kpu-mcp)** - Find questions people ask online with [KeywordsPeopleUse](https://keywordspeopleuse.com).\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/4815054\" alt=\"Kintone Logo\" /> **[Kintone](https://github.com/kintone/mcp-server)** - The official local MCP server for [Kintone](https://kintone.com).\n- <img height=\"12\" width=\"12\" src=\"https://kirokuforms.com/favicon.svg\" alt=\"KirokuForms Logo\" /> **[KirokuForms](https://www.kirokuforms.com/ai/mcp)** - [KirokuForms](https://www.kirokuforms.com) is an AI-powered form platform combining professional form building with Human-in-the-Loop (HITL) capabilities. Create custom forms, collect submissions, and integrate human oversight into AI workflows through [MCP integration](https://kirokuforms.com/ai/mcp).\n- <img height=\"12\" width=\"12\" src=\"https://raw.githubusercontent.com/klavis-ai/klavis/main/static/klavis-ai.png\" alt=\"Klavis Logo\" /> **[Klavis ReportGen](https://github.com/Klavis-AI/klavis/tree/main/mcp_servers/report_generation)** - Create professional reports from a simple user query.\n- <img height=\"12\" width=\"12\" src=\"https://www.klaviyo.com/media/Favicon-16by16.png\" alt=\"Klaviyo Logo\" /> **[Klaviyo](https://developers.klaviyo.com/en/docs/klaviyo_mcp_server)** - Interact with your [Klaviyo](https://www.klaviyo.com/) marketing data.\n- <img height=\"12\" width=\"12\" src=\"https://platform.kluster.ai/logo-light.svg\" alt=\"kluster.ai Logo\" /> **[kluster.ai](https://docs.kluster.ai/get-started/mcp/overview/)** - kluster.ai provides MCP servers that bring AI services directly into your development workflow, including guardrails like hallucination detection.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/6347ea26001f0287c592ff91/649953ef7a9ffe1f3e492b5a_Knit%20Logo.svg\" alt=\"Knit Logo\" /> **[Knit MCP Server](https://developers.getknit.dev/docs/knit-mcp-server-getting-started)** - Production-ready remote MCP servers that enable you to connect with 10000+ tools across CRM, HRIS, Payroll, Accounting, ERP, Calendar, Expense Management, and Chat categories.\n- <img height=\"12\" width=\"12\" src=\"https://knock.app/favicon/favicon-dark.svg\" alt=\"Knock Logo\" /> **[Knock MCP Server](https://github.com/knocklabs/agent-toolkit#model-context-protocol-mcp)** - Send product and customer messaging across email, in-app, push, SMS, Slack, MS Teams.\n- <img height=\"12\" width=\"12\" src=\"https://kumo-sdk-public.s3.us-west-2.amazonaws.com/rfm-colabs/kumo_ai_logo.jpeg\" alt=\"Kumo Logo\" /> **[Kumo](https://github.com/kumo-ai/kumo-rfm-mcp)** - MCP Server to interact with KumoRFM, a foundation model for generating predictions from your relational data.\n- <img height=\"12\" width=\"12\" src=\"https://www.kurrent.io/favicon.ico\" alt=\"Kurrent Logo\" /> **[KurrentDB](https://github.com/kurrent-io/mcp-server)** - This is a simple MCP server to help you explore data and prototype projections faster on top of KurrentDB.\n- <img height=\"12\" width=\"12\" src=\"https://kuzudb.com/favicon.ico\" alt=\"Kuzu Logo\" /> **[Kuzu](https://github.com/kuzudb/kuzu-mcp-server)** - This server enables LLMs to inspect database schemas and execute queries on the provided Kuzu graph database. See [blog](https://blog.kuzudb.com/post/2025-03-23-kuzu-mcp-server/)) for a debugging use case.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/187484914\" alt=\"KWDB Logo\" /> **[KWDB](https://github.com/KWDB/kwdb-mcp-server)** - Reading, writing, querying, modifying data, and performing DDL operations with data in your KWDB Database.\n- <img height=\"12\" width=\"12\" src=\"https://labelstud.io/favicon-16x16.png\" alt=\"Label Studio Logo\" /> **[Label Studio](https://github.com/HumanSignal/label-studio-mcp-server)** - Open Source data labeling platform.\n- <img src=\"https://avatars.githubusercontent.com/u/188884511?s=48&v=4\" alt=\"Lambda Capture\" width=\"12\" height=\"12\"> **[Lambda Capture](https://github.com/lambda-capture/mcp-server)** - Macroeconomic Forecasts & Semantic Context from Federal Reserve, Bank of England, ECB.\n- <img src=\"https://www.lambdatest.com/resources/images/header/professional-service.svg\" alt=\"LambdaTest MCP server\" width=\"12\" height=\"12\"> **[LambdaTest](https://www.lambdatest.com/mcp)** - LambdaTest MCP Servers ranging from Accessibility, SmartUI, Automation, and HyperExecute allows you to connect AI assistants with your testing workflow, streamlining setup, analyzing failures, and generating fixes to speed up testing and improve efficiency.\n- <img height=\"12\" width=\"12\" src=\"https://langfuse.com/favicon.ico\" alt=\"Langfuse Logo\" /> **[Langfuse Prompt Management](https://github.com/langfuse/mcp-server-langfuse)** - Open-source tool for collaborative editing, versioning, evaluating, and releasing prompts.\n- <img height=\"12\" width=\"12\" src=\"https://laratranslate.com/favicon.ico\" alt=\"Lara Translate Logo\" /> **[Lara Translate](https://github.com/translated/lara-mcp)** - MCP Server for Lara Translate API, enabling powerful translation capabilities with support for language detection and context-aware translations.\n- <img height=\"12\" width=\"12\" src=\"https://last9.io/favicon.png\" alt=\"Last9 Logo\" /> **[Last9](https://github.com/last9/last9-mcp-server)** - Seamlessly bring real-time production context—logs, metrics, and traces—into your local environment to auto-fix code faster.\n- <img height=\"12\" width=\"12\" src=\"https://www.launchdarkly.com/favicon.ico\" alt=\"LaunchDarkly Logo\" /> **[LaunchDarkly](https://github.com/launchdarkly/mcp-server)** - LaunchDarkly is a continuous delivery platform that provides feature flags as a service and allows developers to iterate quickly and safely.\n- <img height=\"12\" width=\"12\" src=\"https://www.line.me/favicon-32x32.png\" alt=\"LINE Logo\" /> **[LINE](https://github.com/line/line-bot-mcp-server)** - Integrates the LINE Messaging API to connect an AI Agent to the LINE Official Account.\n- <img height=\"12\" width=\"12\" src=\"https://linear.app/favicon.ico\" alt=\"Linear Logo\" /> **[Linear](https://linear.app/docs/mcp)** - Search, create, and update Linear issues, projects, and comments.\n- <img height=\"12\" width=\"12\" src=\"https://lingo.dev/favicon.ico\" alt=\"Lingo.dev Logo\" /> **[Lingo.dev](https://github.com/lingodotdev/lingo.dev/blob/main/mcp.md)** - Make your AI agent speak every language on the planet, using [Lingo.dev](https://lingo.dev) Localization Engine.\n- <img height=\"12\" width=\"12\" src=\"https://ligo.ertiqah.com/favicon.avif\" alt=\"LiGo Logo\" /> **[LinkedIn MCP Runner](https://github.com/ertiqah/linkedin-mcp-runner)** - Write, edit, and schedule LinkedIn posts right from ChatGPT and Claude with [LiGo](https://ligo.ertiqah.com/).\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/175112039?s=200&v=4\" alt=\"Linkup Logo\" /> **[Linkup](https://github.com/LinkupPlatform/js-mcp-server)** - (JS version) MCP server that provides web search capabilities through Linkup's advanced search API. This server enables AI assistants and development tools to perform intelligent web searches with natural language queries.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/175112039?s=200&v=4\" alt=\"Linkup Logo\" /> **[Linkup](https://github.com/LinkupPlatform/python-mcp-server)** - (Python version) MCP server that provides web search capabilities through Linkup's advanced search API. This server enables AI assistants and development tools to perform intelligent web searches with natural language queries.\n- <img src=\"https://avatars.githubusercontent.com/u/149083471\" alt=\"Lippia.io\" width=\"12\" height=\"12\"> **[Lippia](https://github.com/Lippia-io/Lippia-MCP-Server/blob/main/getting-started.md)** - MCP Server to accelerate Test Automation using Lippia Framework.\n- <img src=\"https://gornschool.com/gorn.png\" alt=\"Lisply\" width=\"12\" height=\"12\"> **[Lisply](https://github.com/gornskew/lisply-mcp)** - Flexible frontend for compliant Lisp-speaking backends.\n- <img height=\"12\" width=\"12\" src=\"https://litmus.io/favicon.ico\" alt=\"Litmus.io Logo\" /> **[Litmus.io](https://github.com/litmusautomation/litmus-mcp-server)** - Official MCP server for configuring [Litmus](https://litmus.io) Edge for Industrial Data Collection, Edge Analytics & Industrial AI.\n- <img height=\"12\" width=\"12\" src=\"https://liveblocks.io/favicon.ico\" alt=\"Liveblocks Logo\" /> **[Liveblocks](https://github.com/liveblocks/liveblocks-mcp-server)** - Ready‑made features for AI & human collaboration—use this to develop your [Liveblocks](https://liveblocks.io) app quicker.\n- <img height=\"12\" width=\"12\" src=\"https://logfire.pydantic.dev/favicon.ico\" alt=\"Logfire Logo\" /> **[Logfire](https://github.com/pydantic/logfire-mcp)** - Provides access to OpenTelemetry traces and metrics through Logfire.\n- <img height=\"12\" width=\"12\" src=\"https://make.magicmealkits.com/favicon.ico\" alt=\"Magic Meal Kits Logo\" /> **[Magic Meal Kits](https://github.com/pureugong/mmk-mcp)** - Unleash Make's Full Potential by [Magic Meal Kits](https://make.magicmealkits.com/)\n- <img height=\"12\" width=\"12\" src=\"https://www.mailgun.com/favicon.ico\" alt=\"Mailgun Logo\" /> **[Mailgun](https://github.com/mailgun/mailgun-mcp-server)** - Interact with Mailgun API.\n- <img height=\"12\" width=\"12\" src=\"https://www.mailjet.com/favicon.ico\" alt=\"Mailjet Logo\" /> **[Mailjet](https://github.com/mailgun/mailjet-mcp-server)** - Official MCP server which allows AI agents to interact with contact, campaign, segmentation, statistics, workflow (and more) APIs from [Sinch Mailjet](https://www.mailjet.com).\n- <img height=\"12\" width=\"12\" src=\"https://www.make.com/favicon.ico\" alt=\"Make Logo\" /> **[Make](https://github.com/integromat/make-mcp-server)** - Turn your [Make](https://www.make.com/) scenarios into callable tools for AI assistants.\n- <img height=\"12\" width=\"12\" src=\"https://static-assets.mapbox.com/branding/favicon/v1/favicon.ico\" alt=\"Mapbox Logo\" /> **[Mapbox](https://github.com/mapbox/mcp-server)** - Unlock geospatial intelligence through Mapbox APIs like geocoding, POI search, directions, isochrones and more.\n- <img height=\"12\" width=\"12\" src=\"https://www.mariadb.com/favicon.ico\" alt=\"MariaDB Logo\" /> **[MariaDB](https://github.com/mariadb/mcp)** - A standard interface for managing and querying MariaDB databases, supporting both standard SQL operations and advanced vector/embedding-based search.\n- <img height=\"14\" width=\"14\" src=\"https://raw.githubusercontent.com/rust-mcp-stack/mcp-discovery/refs/heads/main/docs/_media/mcp-discovery-logo.png\" alt=\"mcp-discovery logo\" /> **[MCP Discovery](https://github.com/rust-mcp-stack/mcp-discovery)** - A lightweight CLI tool built in Rust for discovering MCP server capabilities.\n- <img height=\"12\" width=\"12\" src=\"https://googleapis.github.io/genai-toolbox/favicons/favicon.ico\" alt=\"MCP Toolbox for Databases Logo\" /> **[MCP Toolbox for Databases](https://github.com/googleapis/genai-toolbox)** - Open source MCP server specializing in easy, fast, and secure tools for Databases. Supports  AlloyDB, BigQuery, Bigtable, Cloud SQL, Dgraph, Looker, MySQL, Neo4j, Postgres, Spanner, and more.\n- <img height=\"12\" width=\"12\" src=\"https://www.meilisearch.com/favicon.ico\" alt=\"Meilisearch Logo\" /> **[Meilisearch](https://github.com/meilisearch/meilisearch-mcp)** - Interact & query with Meilisearch (Full-text & semantic search API)\n- <img height=\"12\" width=\"12\" src=\"https://memgraph.com/favicon.png\" alt=\"Memgraph Logo\" /> **[Memgraph](https://github.com/memgraph/ai-toolkit/tree/main/integrations/mcp-memgraph)** - Query your data in [Memgraph](https://memgraph.com/) graph database.\n- <img height=\"12\" width=\"12\" src=\"https://www.mercadolibre.com.ar/favicon.ico\" alt=\"MercadoLibre Logo\" /> **[Mercado Libre](https://mcp.mercadolibre.com/)** - Mercado Libre's official MCP server.\n- <img height=\"12\" width=\"12\" src=\"https://www.mercadopago.com/favicon.ico\" alt=\"MercadoPago Logo\" /> **[Mercado Pago](https://mcp.mercadopago.com/)** - Mercado Pago's official MCP server.\n- <img height=\"12\" width=\"12\" src=\"https://metoro.io/static/images/logos/MetoroLogo.png\" alt=\"Metoro Logo\" /> **[Metoro](https://github.com/metoro-io/metoro-mcp-server)** - Query and interact with kubernetes environments monitored by Metoro\n- <img height=\"12\" width=\"12\" src=\"https://claritystatic.azureedge.net/images/logo.ico\" alt=\"Microsoft Clarity Logo\"/> **[Microsoft Clarity](https://github.com/microsoft/clarity-mcp-server)** - Official MCP Server to get your behavioral analytics data and insights from [Clarity](https://clarity.microsoft.com)\n- <img height=\"12\" width=\"12\" src=\"https://conn-afd-prod-endpoint-bmc9bqahasf3grgk.b01.azurefd.net/releases/v1.0.1735/1.0.1735.4099/commondataserviceforapps/icon.png\" alt=\"Microsoft Dataverse Logo\" /> **[Microsoft Dataverse](https://go.microsoft.com/fwlink/?linkid=2320176)** - Chat over your business data using NL - Discover tables, run queries, retrieve data, insert or update records, and execute custom prompts grounded in business knowledge and context.\n- <img height=\"12\" width=\"12\" src=\"https://learn.microsoft.com/favicon.ico\" alt=\"Microsoft Learn Logo\" /> **[Microsoft Learn Docs](https://github.com/microsoftdocs/mcp)** - An MCP server that provides structured access to Microsoft's official documentation. Retrieves accurate, authoritative, and context-aware technical content for code generation, question answering, and workflow grounding.\n- <img height=\"12\" width=\"12\" src=\"https://statics.teams.microsoft.com/hashedassets/favicon/prod/favicon-9f45b466.ico\" alt=\"Microsoft Teams Logo\" /> **[Microsoft Teams](https://devblogs.microsoft.com/microsoft365dev/announcing-the-updated-teams-ai-library-and-mcp-support/)** - Official Microsoft Teams AI Library with MCP support enabling advanced agent orchestration, multi-agent collaboration, and seamless integration with Teams messaging and collaboration features.\n- <img alt=\"favicon_32x32\" height=\"12\" width=\"12\" src=\"https://milvus.io/favicon-32x32.png\" /> **[Milvus](https://github.com/zilliztech/mcp-server-milvus)** - Search, Query and interact with data in your Milvus Vector Database.\n- <img src=\"https://www.mimilabs.ai/logos/mimilabsSquare.svg\" alt=\"mimilabs\" width=\"12\" height=\"12\"> **[mimilabs](https://www.mimilabs.ai/mcp)** - A US healthcare data discovery guide for 50+ gov sources and thousands of publicly available US healthcare datasets regarding gov-funded programs, policies, drug pricings, clinical trials, etc.\n- <img src=\"https://avatars.githubusercontent.com/u/94089762?s=48&v=4\" alt=\"Mobb\" width=\"12\" height=\"12\"> **[Mobb](https://github.com/mobb-dev/bugsy?tab=readme-ov-file#model-context-protocol-mcp-server)** - The [Mobb Vibe Shield](https://vibe.mobb.ai/) MCP server identifies and remediates vulnerabilities in both human and AI-written code, ensuring your applications remain secure without slowing development.\n- <img alt=\"favicon\" height=\"12\" width=\"12\" src=\"https://console.gomomento.com/favicon.ico\" /> **[Momento](https://github.com/momentohq/mcp-momento)** - Momento Cache lets you quickly improve your performance, reduce costs, and handle load at any scale.\n- <img height=\"12\" width=\"12\" src=\"https://www.monday.com/favicon.ico\" alt=\"Monday.com Logo\" /> **[Monday.com](https://github.com/mondaycom/mcp)** - Interact with Monday.com boards, items, accounts and work forms.\n- <img alt=\"favicon\" height=\"12\" width=\"12\" src=\"https://www.mongodb.com/favicon.ico\" /> **[MongoDB](https://github.com/mongodb-js/mongodb-mcp-server)** - Both MongoDB Community Server and MongoDB Atlas are supported.\n- <img height=\"12\" width=\"12\" src=\"https://moorcheh.ai/Moorcheh-mcp.ico\" alt=\"Moorcheh Logo\" /> **[Moorcheh](https://github.com/moorcheh-ai/moorcheh-mcp)** - Embed, store, and search your documents, and build secure chatbots and RAG systems with Moorcheh's information-theoretic semantic search engine\n- <img height=\"12\" width=\"12\" src=\"https://www.motherduck.com/favicon.ico\" alt=\"MotherDuck Logo\" /> **[MotherDuck](https://github.com/motherduckdb/mcp-server-motherduck)** - Query and analyze data with MotherDuck and local DuckDB\n- <img height=\"12\" width=\"12\" src=\"https://docs.mulesoft.com/_/img/favicon.ico\" alt=\"Mulesoft Logo\" /> **[Mulesoft](https://www.npmjs.com/package/@mulesoft/mcp-server)** - Build, deploy, and manage MuleSoft applications with natural language, directly inside any compatible IDE.\n- <img height=\"12\" width=\"12\" src=\"https://www.multiplayer.app/favicon-32x32.png\" alt=\"Multiplayer Logo\" /> **[Multiplayer](https://www.multiplayer.app/docs/ai/mcp-server)** - Analyze your full stack session recordings easily. Record a bug with Multiplayer, analyze and fix it with LLM\n-  **[Nango](https://docs.nango.dev/guides/use-cases/mcp-server)** - Integrate your AI agent with 500+ APIs: Auth, custom tools, and observability. Open-source.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/38020270\" alt=\"NanoVMs Logo\" /> **[NanoVMs](https://github.com/nanovms/ops-mcp)** - Easily Build and Deploy unikernels to any cloud.\n- <img height=\"12\" width=\"12\" src=\"https://needle-ai.com/images/needle-logo-orange-2-rounded.png\" alt=\"Needle AI Logo\" /> **[Needle](https://github.com/needle-ai/needle-mcp)** - Production-ready RAG out of the box to search and retrieve data from your own documents.\n- <img height=\"12\" width=\"12\" src=\"https://neo4j.com/favicon.ico\" alt=\"Neo4j Logo\" /> **[Neo4j](https://github.com/neo4j-contrib/mcp-neo4j/)** - Neo4j graph database server (schema + read/write-cypher) and separate graph database backed memory\n- <img height=\"12\" width=\"12\" src=\"https://knowall.ai/favicon.ico\" alt=\"Neo4j Agent Memory Logo\" /> **[Neo4j Agent Memory](https://github.com/knowall-ai/mcp-neo4j-agent-memory)** - Memory management for AI agents using Neo4j knowledge graphs\n- <img height=\"12\" width=\"12\" src=\"https://neo4j.com/favicon.ico\" alt=\"Neo4j Logo\" /> **[Neo4j GDS](https://github.com/neo4j-contrib/gds-agent)** - Neo4j graph data science server with comprehensive graph algorithms that enables complex graph reasoning and Q&A.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/183852044?s=48&v=4\" alt=\"Neon Logo\" /> **[Neon](https://github.com/neondatabase/mcp-server-neon)** - Interact with the Neon serverless Postgres platform\n- <img height=\"12\" width=\"12\" src=\"https://app.usenerve.com/favicon.ico\" alt=\"Nerve Logo\" /> **[Nerve](https://github.com/nerve-hq/nerve-mcp-server)** - Search and Act on all your company data across all your SaaS apps via [Nerve](https://www.usenerve.com/)\n- <img height=\"12\" width=\"12\" src=\"https://www.netdata.cloud/favicon-32x32.png\" alt=\"Netdata Logo\" /> **[Netdata](https://github.com/netdata/netdata/blob/master/src/web/mcp/README.md)** - Discovery, exploration, reporting and root cause analysis using all observability data, including metrics, logs, systems, containers, processes, and network connections\n- <img height=\"12\" width=\"12\" src=\"https://www.netlify.com/favicon/icon.svg\" alt=\"Netlify Logo\" /> **[Netlify](https://docs.netlify.com/welcome/build-with-ai/netlify-mcp-server/)** - Create, build, deploy, and manage your websites with Netlify web platform.\n- <img height=\"12\" width=\"12\" src=\"https://www.thenile.dev/favicon.ico\" alt=\"Nile Logo\" /> **[Nile](https://github.com/niledatabase/nile-mcp-server)** - An MCP server that talks to Nile - Postgres re-engineered for B2B apps. Manage and query databases, tenants, users, auth using LLMs\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/208441832?s=400&v=4\" alt=\"Nodit Logo\" /> **[Nodit](https://github.com/noditlabs/nodit-mcp-server)** - Official Nodit MCP Server enabling access to multi-chain RPC Nodes and Data APIs for blockchain data.\n- <img height=\"12\" width=\"12\" src=\"https://app.norman.finance/favicons/favicon-32x32.png\" alt=\"Norman Logo\" /> **[Norman Finance](https://github.com/norman-finance/norman-mcp-server)** - MCP server for managing accounting and taxes with Norman Finance.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/4792552?s=200&v=4\" alt=\"Notion Logo\" /> **[Notion](https://github.com/makenotion/notion-mcp-server#readme)** - This project implements an MCP server for the Notion API.\n-  **[Nutrient](https://github.com/PSPDFKit/nutrient-dws-mcp-server)** - Create, Edit, Sign, Extract Documents using Natural Language\n- <img height=\"12\" width=\"12\" src=\"https://nx.dev/favicon/favicon.svg\" alt=\"Nx Logo\" /> **[Nx](https://github.com/nrwl/nx-console/blob/master/apps/nx-mcp)** - Makes [Nx's understanding](https://nx.dev/features/enhance-AI) of your codebase accessible to LLMs, providing insights into the codebase architecture, project relationships and runnable tasks thus allowing AI to make precise code suggestions.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/82347605?s=48&v=4\" alt=\"OceanBase Logo\" /> **[OceanBase](https://github.com/oceanbase/mcp-oceanbase)** - MCP Server for OceanBase database and its tools\n- <img height=\"12\" width=\"12\" src=\"https://docs.octagonagents.com/logo.svg\" alt=\"Octagon Logo\" /> **[Octagon](https://github.com/OctagonAI/octagon-mcp-server)** - Deliver real-time investment research with extensive private and public market data.\n- <img height=\"12\" width=\"12\" src=\"https://octoeverywhere.com/img/logo.png\" alt=\"OctoEverywhere Logo\" /> **[OctoEverywhere](https://github.com/OctoEverywhere/mcp)** - A 3D Printing MCP server that allows for querying for live state, webcam snapshots, and 3D printer control.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/211697972\" alt=\"Offorte Logo\" /> **[Offorte](https://github.com/offorte/offorte-mcp-server#readme)** - Offorte Proposal Software official MCP server enables creation and sending of business proposals.\n-  **[OlaMaps](https://pypi.org/project/ola-maps-mcp-server)** - Official Ola Maps MCP Server for services like geocode, directions, place details and many more.\n- <img height=\"12\" width=\"12\" src=\"https://www.olostep.com/favicon.ico\" alt=\"Olostep\" /> **[Olostep](https://github.com/olostep/olostep-mcp-server)** - Search, scrape and crawl content from web. Real-time results in clean markdown.\n- <img height=\"12\" width=\"12\" src=\"https://static.onlyoffice.com/images/favicon.ico\" alt=\"ONLYOFFICE DocSpace\" /> **[ONLYOFFICE DocSpace](https://github.com/ONLYOFFICE/docspace-mcp)** - Interact with [ONLYOFFICE DocSpace](https://www.onlyoffice.com/docspace.aspx) API to create rooms, manage files and folders.\n- **[OMOP MCP](https://github.com/OHNLP/omop_mcp)** - Map clinical terminology to OMOP concepts using LLMs for healthcare data standardization.\n- <img height=\"12\" width=\"12\" src=\"https://op.gg/favicon.ico\" alt=\"OP.GG Logo\" /> **[OP.GG](https://github.com/opgginc/opgg-mcp)** - Access real-time gaming data across popular titles like League of Legends, TFT, and Valorant, offering champion analytics, esports schedules, meta compositions, and character statistics.\n- <img height=\"12\" width=\"12\" src=\"https://www.openfort.io/img/icon.svg\" alt=\"Openfort\" /> **[Openfort](https://github.com/openfort-xyz/mcp)** - Connect your AI to Openfort's smart wallet, auth, and project infrastructure.\n- <img height=\"12\" width=\"12\" src=\"https://open-metadata.org/favicon.ico\" alt=\"OpenMetadata\" /> **[OpenMetadata](https://open-metadata.org/mcp)** - The first Enterprise-grade MCP server for metadata\n- <img height=\"12\" width=\"12\" src=\"https://opensearch.org/wp-content/uploads/2025/01/opensearch_mark_default.svg\" alt=\"OpenSearch Logo\" /> **[OpenSearch](https://github.com/opensearch-project/opensearch-mcp-server-py)** -  MCP server that enables AI agents to perform search and analytics use cases on data stored in [OpenSearch](https://opensearch.org/).\n- <img height=\"12\" width=\"12\" src=\"https://app.opslevel.com/favicon.ico\" alt=\"OpsLevel\" /> **[OpsLevel](https://github.com/opslevel/opslevel-mcp)** - Official MCP Server for [OpsLevel](https://www.opslevel.com).\n- <img height=\"12\" width=\"12\" src=\"https://optuna.org/assets/img/favicon.ico\" alt=\"Optuna Logo\" /> **[Optuna](https://github.com/optuna/optuna-mcp)** - Official MCP server enabling seamless orchestration of hyperparameter search and other optimization tasks with [Optuna](https://optuna.org/).\n- <img height=\"12\" width=\"12\" src=\"https://raw.githubusercontent.com/oracle/mcp/refs/heads/main/oracle.svg\" alt=\"Oracle Logo\" /> **[Oracle](https://docs.oracle.com/en/database/oracle/sql-developer-command-line/25.2/sqcug/starting-and-managing-sqlcl-mcp-server.html#GUID-5F916B5D-8670-42BD-9F8B-D3D2424EC47E)** - Official [Oracle Database: SQLcl ](https://www.oracle.com/database/sqldeveloper/technologies/sqlcl/download/) MCP server enabling all access to any Oracle Database via native MCP support directly in SQLcl.\n- <img height=\"12\" width=\"12\" src=\"https://orshot.com/brand/favicon.svg\" alt=\"Orshot Logo\" /> **[Orshot](https://github.com/rishimohan/orshot-mcp-server)** - Official [Orshot](https://orshot.com) MCP server to dynamically generate images from custom design templates.\n- <img height=\"12\" width=\"12\" src=\"https://oxylabs.io/favicon.ico\" alt=\"Oxylabs Logo\" /> **[Oxylabs](https://github.com/oxylabs/oxylabs-mcp)** - Scrape websites with Oxylabs Web API, supporting dynamic rendering and parsing for structured data extraction.\n- <img height=\"12\" width=\"12\" src=\"https://developer.paddle.com/favicon.svg\" alt=\"Paddle Logo\" /> **[Paddle](https://github.com/PaddleHQ/paddle-mcp-server)** - Interact with the Paddle API. Manage product catalog, billing and subscriptions, and reports.\n- **[PaddleOCR](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/mcp_server.html)** - An MCP server that brings enterprise-grade OCR and document parsing capabilities to AI applications.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.brandfolder.io/YX9ETPCP/at/266537g8kh6mmvt24jvsjb/P-GreenRGB.svg\" alt=\"PagerDuty Logo\" /> **[PagerDuty](https://github.com/PagerDuty/pagerduty-mcp-server)** - Interact with your PagerDuty account, allowing you to manage incidents, services, schedules, and more directly from your MCP-enabled client.\n- **[Pagos](https://github.com/pagos-ai/pagos-mcp)** - Interact with the Pagos API. Query Credit Card BIN Data with more to come.\n- <img height=\"12\" width=\"12\" src=\"https://paiml.com/favicon.ico\" alt=\"PAIML Logo\" /> **[PAIML MCP Agent Toolkit](https://github.com/paiml/paiml-mcp-agent-toolkit)** - Professional project scaffolding toolkit with zero-configuration AI context generation, template generation for Rust/Deno/Python projects, and hybrid neuro-symbolic code analysis.\n- <img height=\"12\" width=\"12\" src=\"https://app.paperinvest.io/favicon.svg\" alt=\"Paper Logo\" /> **[Paper](https://github.com/paperinvest/mcp-server)** - Realistic paper trading platform with market simulation, 22 broker emulations, and professional tools for risk-free trading practice. First trading platform with MCP integration.\n- **[Patronus AI](https://github.com/patronus-ai/patronus-mcp-server)** - Test, evaluate, and optimize AI agents and RAG apps\n- <img height=\"12\" width=\"12\" src=\"https://mcp.paubox.com/paubox.png\" alt=\"Paubox Logo\" />**[Paubox](https://mcp.paubox.com)** - Official MCP server which allows AI agents to interact with Paubox Email API. HITRUST certified.\n- <img height=\"12\" width=\"12\" src=\"https://www.paypalobjects.com/webstatic/icon/favicon.ico\" alt=\"PayPal Logo\" /> **[PayPal](https://mcp.paypal.com)** - PayPal's official MCP server.\n- <img height=\"12\" width=\"12\" src=\"https://ww2-secure.pearl.com/static/pearl/pearl-logo.svg\" alt=\"Pearl Logo\" /> **[Pearl](https://github.com/Pearl-com/pearl_mcp_server)** - Official MCP Server to interact with Pearl API. Connect your AI Agents with 12,000+ certified experts instantly.\n- <img height=\"12\" width=\"12\" src=\"https://www.perplexity.ai/favicon.ico\" alt=\"Perplexity Logo\" /> **[Perplexity](https://github.com/ppl-ai/modelcontextprotocol)** - An MCP server that connects to Perplexity's Sonar API, enabling real-time web-wide research in conversational AI.\n- <img height=\"12\" width=\"12\" src=\"https://www.foxit.com/favicon.ico\" alt=\"Foxit Logo\" /> **[PDFActionInspector](https://github.com/foxitsoftware/PDFActionInspector/tree/develop)** - A Model Context Protocol server for extracting and analyzing JavaScript Actions from PDF files. Provides comprehensive security analysis to detect malicious PDF behaviors, hidden scripts, and potential security threats through AI-assisted risk assessment.\n- <img height=\"12\" width=\"12\" src=\"https://www.pga.com/favicon.ico\" alt=\"PGA Logo\" /> **[PGA (Golf)](https://mcp.pga.com)** - PGA's official MCP Server for all things golf-related. Find a coach, play golf, improve your game, and more.\n- <img alt=\"54333248\" height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/54333248\" /> **[Pinecone](https://github.com/pinecone-io/pinecone-mcp)** - [Pinecone](https://docs.pinecone.io/guides/operations/mcp-server)'s developer MCP Server assist developers in searching documentation and managing data within their development environment.\n- <img alt=\"54333248\" height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/54333248\" /> **[Pinecone Assistant](https://github.com/pinecone-io/assistant-mcp)** - Retrieves context from your [Pinecone Assistant](https://docs.pinecone.io/guides/assistant/mcp-server) knowledge base.\n- <img height=\"12\" width=\"12\" src=\"https://pipedream.com/favicon.ico\" alt=\"Pipedream Logo\" /> **[Pipedream](https://github.com/PipedreamHQ/pipedream/tree/master/modelcontextprotocol)** - Connect with 2,500 APIs with 8,000+ prebuilt tools.\n- <img height=\"12\" width=\"12\" src=\"https://playcanvas.com/static-assets/images/icons/favicon.png\" alt=\"PlayCanvas Logo\" /> **[PlayCanvas](https://github.com/playcanvas/editor-mcp-server)** - Create interactive 3D web apps with the PlayCanvas Editor.\n- <img height=\"12\" width=\"12\" src=\"https://playwright.dev/img/playwright-logo.ico\" alt=\"Playwright Logo\" /> **[Playwright](https://github.com/microsoft/playwright-mcp)** — Browser automation MCP server using Playwright to run tests, navigate pages, capture screenshots, scrape content, and automate web interactions reliably.\n- <img height=\"12\" width=\"12\" src=\"https://www.plugged.in/favicon.ico\" alt=\"Plugged.in Logo\" /> **[Plugged.in](https://github.com/VeriTeknik/pluggedin-mcp)** - A comprehensive proxy that combines multiple MCP servers into a single MCP. It provides discovery and management of tools, prompts, resources, and templates across servers, plus a playground for debugging when building MCP servers.\n- <img height=\"12\" width=\"12\" src=\"https://github.com/port-labs/port-mcp-server/blob/main/assets/port_symbol_white.svg\" alt=\"Port Logo\" /> **[Port IO](https://github.com/port-labs/port-mcp-server)** - Access and manage your software catalog to improve service quality and compliance.\n- **[PostHog](https://github.com/posthog/mcp)** - Interact with PostHog analytics, feature flags, error tracking and more with the official PostHog MCP server.\n- **[Postman API](https://github.com/postmanlabs/postman-api-mcp)** - Manage your Postman resources using the [Postman API](https://www.postman.com/postman/postman-public-workspace/collection/i2uqzpp/postman-api).\n- <img height=\"12\" width=\"12\" src=\"https://powerdrill.ai/_next/static/media/powerdrill.0fa27d00.webp\" alt=\"Powerdrill Logo\" /> **[Powerdrill](https://github.com/powerdrillai/powerdrill-mcp)** - An MCP server that provides tools to interact with Powerdrill datasets, enabling smart AI data analysis and insights.\n- <img height=\"12\" width=\"12\" src=\"https://www.prisma.io/images/favicon-32x32.png\" alt=\"Prisma Logo\" /> **[Prisma](https://www.prisma.io/docs/postgres/mcp-server)** - Create and manage Prisma Postgres databases\n- <img height=\"12\" width=\"12\" src=\"https://probe.dev/favicon.ico\" alt=\"Probe.dev Logo\" /> **[Probe.dev](https://docs.probe.dev/guides/mcp-integration)** - Comprehensive media analysis and validation powered by [Probe.dev](https://probe.dev). Hosted MCP server with FFprobe, MediaInfo, and Probe Report analysis capabilities.\n- <img height=\"12\" width=\"12\" src=\"https://framerusercontent.com/images/FGzpihs4MxmSJhyGZ6n7f2Xj0.png\" alt=\"Prode.ai Logo\" /> **[ProdE](https://github.com/CuriousBox-AI/ProdE-mcp)** - Your 24/7 production engineer that preserves context across multiple codebases.\n- <img height=\"12\" width=\"12\" src=\"https://programintegrity.org/wp-content/uploads/2024/07/PIA-Favicon.svg\" alt=\"Program Integrity Alliance (PIA) Logo\" /> **[Program Integrity Alliance (PIA)](https://github.com/Program-Integrity-Alliance/pia-mcp-local)** - Local and Hosted MCP servers providing AI-friendly access to U.S. Government Open Datasets. Also available on [Docker MCP Catalog](https://hub.docker.com/mcp/explore?search=PIA). See [our website](https://programintegrity.org) for more details.\n- <img height=\"12\" width=\"12\" src=\"https://github.com/newtype-01/prompthouse-mcp/raw/main/prompthouse-logo-12x12.png\" alt=\"PromptHouse Logo\" /> **[PromptHouse](https://github.com/newtype-01/prompthouse-mcp)** - Personal prompt library with MCP integration for AI clients.\n- <img height=\"12\" width=\"12\" src=\"https://docs.speedscale.com/img/favicon.ico\" alt=\"proxymock Logo\" /> **[proxymock](https://docs.speedscale.com/proxymock/reference/mcp/)** - An MCP server that automatically generates tests and mocks by recording a live app.\n- <img src=\"https://www.pubnub.com/favicon/favicon-32x32.png\" alt=\"PubNub\" width=\"12\" height=\"12\"> **[PubNub](https://github.com/pubnub/pubnub-mcp-server)** - Retrieves context for developing with PubNub SDKs and calling APIs.\n- <img height=\"12\" width=\"12\" src=\"https://www.pulumi.com/images/favicon.ico\" alt=\"Pulumi Logo\" /> **[Pulumi](https://github.com/pulumi/mcp-server)** - Deploy and manage cloud infrastructure using [Pulumi](https://pulumi.com).\n- <img height=\"12\" width=\"12\" src=\"https://pure.md/favicon.png\" alt=\"Pure.md Logo\" /> **[Pure.md](https://github.com/puremd/puremd-mcp)** - Reliably access web content in markdown format with [pure.md](https://pure.md) (bot detection avoidance, proxy rotation, and headless JS rendering built in).\n- <img height=\"12\" width=\"12\" src=\"https://put.io/images/favicon.ico\" alt=\"Put.io Logo\" /> **[Put.io](https://github.com/putdotio/putio-mcp-server)** - Interact with your Put.io account to download torrents.\n- <img alt=\"logomark\" height=\"12\" width=\"12\" src=\"https://qdrant.tech/img/brand-resources-logos/logomark.svg\" /> **[Qdrant](https://github.com/qdrant/mcp-server-qdrant/)** - Implement semantic memory layer on top of the Qdrant vector search engine\n- <img src=\"https://api.qoretechnologies.com/api/public/apps/Qorus/qorus-logo.svg\" alt=\"Qorus\" width=\"12\" height=\"12\"> **[Qorus](https://qoretechnologies.com/manual/qorus/current/qorus/sysarch.html#mcp_server)** - Connect to any application, system, or technology and automate your business processes without coding and with AI\n- <img src=\"https://avatars.githubusercontent.com/u/18053493?s=200&v=4\" alt=\"Qonto\" width=\"12\" height=\"12\"> **[Qonto](https://github.com/qonto/qonto-mcp-server)** - Access and interact your Qonto account through LLMs using MCP.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/3912814\" alt=\"QuantConnect Logo\" /> **[QuantConnect](https://github.com/QuantConnect/mcp-server)** - Interact with your [QuantConnect](https://www.quantconnect.com/) account to update projects, write strategies, run backtest, and deploying strategies to production live-trading.\n- **[Quickchat AI](https://github.com/incentivai/quickchat-ai-mcp)** - Launch your conversational [Quickchat AI](https://quickchat.ai) agent as an MCP to give AI apps real-time access to its Knowledge Base and conversational capabilities\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/165178062\" alt=\"Ragie Logo\" /> **[Ragie](https://github.com/ragieai/ragie-mcp-server/)** - Retrieve context from your [Ragie](https://www.ragie.ai) (RAG) knowledge base connected to integrations like Google Drive, Notion, JIRA and more.\n- <img alt=\"favicon\" height=\"12\" width=\"12\" src=\"https://www.ramp.com/favicon.ico\" /> **[Ramp](https://github.com/ramp-public/ramp-mcp)** - Interact with [Ramp](https://ramp.com)'s Developer API to run analysis on your spend and gain insights leveraging LLMs\n- **[Raygun](https://github.com/MindscapeHQ/mcp-server-raygun)** - Interact with your crash reporting and real using monitoring data on your Raygun account\n- <img height=\"12\" width=\"12\" src=\"https://framerusercontent.com/images/CU1m0xFonUl76ZeaW0IdkQ0M.png\" alt=\"Razorpay Logo\" /> **[Razorpay](https://github.com/razorpay/razorpay-mcp-server)** - Razorpay's official MCP server\n- <img height=\"12\" width=\"12\" src=\"https://www.recraft.ai/favicons/icon.svg\" alt=\"Recraft Logo\" /> **[Recraft](https://github.com/recraft-ai/mcp-recraft-server)** - Generate raster and vector (SVG) images using [Recraft](https://recraft.ai). Also you can edit, upscale images, create your own styles, and vectorize raster images\n- <img height=\"12\" width=\"12\" src=\"https://www.redhat.com/favicon.ico\" alt=\"Red Hat Logo\" /> **[Red Hat Insights](https://github.com/RedHatInsights/insights-mcp)** - Interact with [Red Hat Insights](https://www.redhat.com/en/technologies/management/insights) - build images, manage vulnerabilities, or view targeted recommendations.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/1529926\" alt=\"Redis Logo\" /> **[Redis](https://github.com/redis/mcp-redis/)** - The Redis official MCP Server offers an interface to manage and search data in Redis.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/1529926\" alt=\"Redis Logo\" /> **[Redis Cloud API](https://github.com/redis/mcp-redis-cloud/)** - The Redis Cloud API MCP Server allows you to manage your Redis Cloud resources using natural language.\n- <img src=\"https://avatars.githubusercontent.com/u/149024635\" alt=\"Reexpress\" width=\"12\" height=\"12\"> **[Reexpress](https://github.com/ReexpressAI/reexpress_mcp_server)** - Enable Similarity-Distance-Magnitude statistical verification for your search, software, and data science workflows\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/68a872edf3df6064de547670/68b7f089c45a6083ce25acb1_reflag-favicon-32.png\" alt=\"Reflag\" /> **[Reflag](https://github.com/reflagcom/javascript/tree/main/packages/cli#model-context-protocol)** - Create and manage feature flags using [Reflag](https://reflag.com)\n- <img height=\"12\" width=\"12\" src=\"https://www.reltio.com/wp-content/uploads/2024/03/cropped-cropped-Reltio_Light_Mode_Dark_Mode_Favicon-270x270.png\" alt=\"Reltio Logo\" /> **[Reltio](https://github.com/reltio-ai/reltio-mcp-server)** - A lightweight, plugin-based MCP server designed to perform advanced entity matching with language models in Reltio environments.\n- <img height=\"12\" width=\"12\" src=\"https://www.rember.com/favicon.ico\" alt=\"Rember Logo\" /> **[Rember](https://github.com/rember/rember-mcp)** - Create spaced repetition flashcards in [Rember](https://rember.com) to remember anything you learn in your chats\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/114033652\" alt=\"Render Logo\" /> **[Render](https://render.com/docs/mcp-server)** - The official Render MCP server: spin up new services, run queries against your databases, and debug rapidly with direct access to service metrics and logs.\n- <img height=\"12\" width=\"12\" src=\"https://reportportal.io/favicon.ico\" alt=\"ReportPortal Logo\" /> **[ReportPortal](https://github.com/reportportal/reportportal-mcp-server)** - explore and analyze automated test results from [ReportPortal](https://reportportal.io) using your favourite LLM.\n- <img height=\"12\" width=\"12\" src=\"http://nonica.io/Nonica-logo.ico\" alt=\"Nonica Logo\" /> **[Revit](https://github.com/NonicaTeam/AI-Connector-for-Revit)** - Connect and interact with your Revit models live.\n- <img height=\"12\" width=\"12\" src=\"https://ui.rilldata.com/favicon.png\" alt=\"Rill Data Logo\" /> **[Rill Data](https://docs.rilldata.com/explore/mcp)** - Interact with Rill Data to query and analyze your data.\n- <img height=\"12\" width=\"12\" src=\"https://riza.io/favicon.ico\" alt=\"Riza logo\" /> **[Riza](https://github.com/riza-io/riza-mcp)** - Arbitrary code execution and tool-use platform for LLMs by [Riza](https://riza.io)\n- <img height=\"12\" width=\"12\" src=\"https://cdn.foundation.roblox.com/current/RobloxStudio.ico\" alt=\"Roblox Studio\" /> **[Roblox Studio](https://github.com/Roblox/studio-rust-mcp-server)** - Roblox Studio MCP Server, create and manipulate scenes, scripts in Roblox Studio\n- <img src=\"https://hyper3d.ai/favicon.ico\" alt=\"Rodin\" width=\"12\" height=\"12\"> **[Rodin](https://github.com/DeemosTech/rodin-api-mcp)** - Generate 3D Models with [Hyper3D Rodin](https://hyper3d.ai)\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/66b7de6a233c04f4dac200a6/66bed52680d689629483c18b_faviconV2%20(2).png\" alt=\"Root Signals Logo\" /> **[Root Signals](https://github.com/root-signals/root-signals-mcp)** - Improve and quality control your outputs with evaluations using LLM-as-Judge\n- **[Routine](https://github.com/routineco/mcp-server)** - MCP server to interact with [Routine](https://routine.co/): calendars, tasks, notes, etc.\n- <img height=\"12\" width=\"12\" src=\"https://platform.composio.dev/favicon.ico\" alt=\"Composio Logo\"> **[Rube](https://github.com/ComposioHQ/Rube)** - Rube is a Model Context Protocol (MCP) server that connects your AI tools to 500+ apps like Gmail, Slack, GitHub, and Notion. Simply install it in your AI client, authenticate once with your apps, and start asking your AI to perform real actions like \"Send an email\" or \"Create a task.\"\n- <img height=\"12\" width=\"12\" src=\"https://raw.githubusercontent.com/safedep/.github/refs/heads/main/assets/logo/1.png\" alt=\"SafeDep Logo\" /> **[SafeDep](https://github.com/safedep/vet/blob/main/docs/mcp.md)** - SafeDep `vet-mcp` helps in  vetting open source packages for security risks—such as vulnerabilities and malicious code—before they're used in your project, especially with AI-generated code suggestions.\n- <img height=\"12\" width=\"12\" src=\"https://waf-ce.chaitin.cn/favicon.ico\" alt=\"SafeLine Logo\" /> **[SafeLine](https://github.com/chaitin/SafeLine/tree/main/mcp_server)** - [SafeLine](https://safepoint.cloud/landing/safeline) is a self-hosted WAF(Web Application Firewall) to protect your web apps from attacks and exploits.\n- <img height=\"12\" width=\"12\" src=\"https://scrapi.tech/favicon.ico\" alt=\"ScrAPI Logo\" /> **[ScrAPI](https://github.com/DevEnterpriseSoftware/scrapi-mcp)** - Web scraping using [ScrAPI](https://scrapi.tech). Extract website content that is difficult to access because of bot detection, captchas or even geolocation restrictions.\n- <img height=\"12\" width=\"12\" src=\"https://upnorthmedia.co/favicon.ico\" alt=\"Up North Media Logo\" /> **[ScreenshotMCP](https://github.com/upnorthmedia/ScreenshotMCP/)** - A Model Context Protocol MCP server for capturing website screenshots with full page, element, and device size features.\n- <img height=\"12\" width=\"12\" src=\"https://screenshotone.com/favicon.ico\" alt=\"ScreenshotOne Logo\" /> **[ScreenshotOne](https://github.com/screenshotone/mcp/)** - Render website screenshots with [ScreenshotOne](https://screenshotone.com/)\n- <img height=\"12\" width=\"12\" src=\"https://pics.fatwang2.com/56912e614b35093426c515860f9f2234.svg\" alt=\"Search1API Logo\" /> **[Search1API](https://github.com/fatwang2/search1api-mcp)** - One API for Search, Crawling, and Sitemaps\n- <img height=\"12\" width=\"12\" src=\"https://www.searchunify.com/favicon.ico\" alt=\"SearchUnify Logo\" /> **[SearchUnify](https://github.com/searchunify/su-mcp/)** - SearchUnify MCP Server (su-mcp) enables seamless integration of SearchUnify with Claude Desktop\n- <img height=\"12\" width=\"12\" src=\"https://secureframe.com/favicon.ico\" alt=\"Secureframe Logo\" /> **[Secureframe](https://github.com/secureframe/secureframe-mcp-server)** - Query security controls, monitor compliance tests, and access audit data across SOC 2, ISO 27001, CMMC, FedRAMP, and other frameworks from [Secureframe](https://secureframe.com).\n- <img height=\"12\" width=\"12\" src=\"https://semgrep.dev/favicon.ico\" alt=\"Semgrep Logo\" /> **[Semgrep](https://github.com/semgrep/mcp)** - Enable AI agents to secure code with [Semgrep](https://semgrep.dev/).\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/187640573?s=48&v=4\" alt=\"Sequa Logo\" /> **[Sequa.AI](https://github.com/sequa-ai/sequa-mcp)** - Stop stitching context for Copilot and Cursor. With [Sequa MCP](https://github.com/sequa-ai/sequa-mcp), your AI tools know all your codebases and docs out of the box.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/6372338e5477e047032b37a5/64f85e6388a2a5c8c9525b4d_favLogo.png\" alt=\"Shortcut Logo\" /> **[Shortcut](https://github.com/useshortcut/mcp-server-shortcut)** - Access and implement all of your projects and tasks (Stories) from [Shortcut](https://shortcut.com/).\n- <img alt=\"favicon_32x32_png_v_277b9cbbe31e8bc416504cf3b902d430\" height=\"12\" width=\"12\" src=\"https://www.singlestore.com/favicon-32x32.png?v=277b9cbbe31e8bc416504cf3b902d430\"/> **[SingleStore](https://github.com/singlestore-labs/mcp-server-singlestore)** - Interact with the SingleStore database platform\n- <img height=\"12\" width=\"12\" src=\"https://smartbear.com/smartbear/assets/img/favicon.png\" alt=\"SmartBear Logo\" /> **[SmartBear](https://github.com/SmartBear/smartbear-mcp)** - Provides access to multiple capabilities across SmartBear's API Hub, Test Hub, and Insight Hub, all through [dedicated tools and resources](https://developer.smartbear.com/smartbear-mcp/docs/mcp-server).\n- <img src=\"https://smooth-operator.online/logo48.png\" alt=\"Smooth Operator\" width=\"12\" height=\"12\"> **[Smooth Operator](https://smooth-operator.online/agent-tools-api-docs/toolserverdocs)** - Tools to automate Windows via AI Vision, Mouse, Keyboard, Automation Trees, Webbrowser\n- <img height=\"12\" width=\"12\" src=\"https://app.snyk.io/bundle/favicon-faj49uD9.png\" alt=\"Snyk Logo\" /> **[Snyk](https://github.com/snyk/snyk-ls/blob/main/mcp_extension/README.md)** - Enhance security posture by embedding [Snyk](https://snyk.io/) vulnerability scanning directly into agentic workflows.\n- <img height=\"12\" width=\"12\" src=\"https://www.sonarsource.com/favicon.ico\" alt=\"SonarQube Logo\" /> **[SonarQube](https://github.com/SonarSource/sonarqube-mcp-server)** - Enables seamless integration with [SonarQube](https://www.sonarsource.com/) Server or Cloud and allows for code snippet analysis within the agent context.\n- <img src=\"https://sophtron.com/favicon.ico\" alt=\"Sophtron\" width=\"12\" height=\"12\"> **[Sophtron](https://github.com/sophtron/Sophtron-Integration/tree/main/modelcontextprotocol)** - Connect to your bank, credit card, utilities accounts to retrieve account balances and transactions with [Sophtron Bank Integration](https://sophtron.com).\n- <img height=\"12\" width=\"12\" src=\"https://www.stackhawk.com/wp-content/uploads/2025/03/icon-512x512-2-150x150.png\" alt=\"StackHawk Logo\" /> **[StackHawk](https://github.com/stackhawk/stackhawk-mcp)** - Use [StackHawk](https://www.stackhawk.com/) to test for and FIX security problems in your code or vibe coded app.\n- <img height=\"12\" width=\"12\" src=\"https://www.starrocks.io/favicon.ico\" alt=\"StarRocks Logo\" /> **[StarRocks](https://github.com/StarRocks/mcp-server-starrocks)** - Interact with [StarRocks](https://www.starrocks.io/)\n- <img height=\"12\" width=\"12\" src=\"https://downloads.steadybit.com/logomark.svg\" alt=\"Steadybit Logo\" /> **[Steadybit](https://github.com/steadybit/mcp)** - Interact with [Steadybit](https://www.steadybit.com/)\n- <img height=\"12\" width=\"12\" src=\"https://steuerboard.net/favicon.ico\" alt=\"Steuerboard Logo\" /> **[Steuerboard](https://github.com/steuerboard/steuerboard-mcp-typescript)** - Interact with the accounting data in your business using our official MCP server\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/22632046?s=200&v=4\" alt=\"Storybook Logo\" /> **[Storybook](https://github.com/storybookjs/addon-mcp)** - Interact with [Storybook](https://storybook.js.org/) to automate UI component testing and documentation\n- <img height=\"12\" width=\"12\" src=\"https://stripe.com/favicon.ico\" alt=\"Stripe Logo\" /> **[Stripe](https://github.com/stripe/agent-toolkit)** - Interact with Stripe API\n- <img height=\"12\" width=\"12\" src=\"https://sunra.ai/favicon.ico\" alt=\"Sunra AI Logo\" /> **[Sunra AI](https://github.com/sunra-ai/sunra-clients/tree/main/mcp-server)** - Search for and run AI models on [Sunra.ai](https://sunra.ai). Discover models, create video, image, and 3D model content, track their status, and manage the generated media.\n- <img height=\"12\" width=\"12\" src=\"https://supabase.com/favicon/favicon.ico\" alt=\"Supabase Logo\" /> **[Supabase](https://github.com/supabase-community/supabase-mcp)** - Interact with Supabase: Create tables, query data, deploy edge functions, and more.\n- <img height=\"12\" width=\"12\" src=\"https://supadata.ai/favicon.ico\" alt=\"Supadata Logo\" /> **[Supadata](https://github.com/supadata-ai/mcp)** - Official MCP server for [Supadata](https://supadata.ai) - YouTube, TikTok, X and Web data for makers.\n- <img height=\"12\" width=\"12\" src=\"https://d12w4pyrrczi5e.cloudfront.net/archive/50eb154ab859c63a8f1c850f9fe094e25d35e929/images/favicon.ico\" alt=\"Tako Logo\" /> **[Tako](https://github.com/TakoData/tako-mcp)** - Use natural language to search [Tako](https://trytako.com) for real-time financial, sports, weather, and public data with visualization\n- <img height=\"12\" width=\"12\" src=\"https://tavily.com/favicon.ico\" alt=\"Tavily Logo\" /> **[Tavily](https://github.com/tavily-ai/tavily-mcp)** - Search engine for AI agents (search + extract) powered by [Tavily](https://tavily.com/)\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/10522416?s=200&v=4\" alt=\"Telnyx Logo\" /> **[Telnyx](https://github.com/team-telnyx/telnyx-mcp-server)** - Official MCP server for building AI-powered communication apps. Create voice assistants, send SMS campaigns, manage phone numbers, and integrate real-time messaging with enterprise-grade reliability. Includes remote [streamable-http](https://api.telnyx.com/v2/mcp) and [sse](https://api.telnyx.com/mcp/sse) servers.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/1615979?s=200&v=4\" alt=\"Teradata Logo\" /> **[Teradata](https://github.com/Teradata/teradata-mcp-server)** - This MCP Server support tools and prompts for multi task data analytics on a [Teradata](https://teradata.com) platform.\n- <img height=\"12\" width=\"12\" src=\"https://raw.githubusercontent.com/hashicorp/terraform-mcp-server/main/public/images/Terraform-LogoMark_onDark.svg\" alt=\"Terraform Logo\" /> **[Terraform](https://github.com/hashicorp/terraform-mcp-server)** - Seamlessly integrate with Terraform ecosystem, enabling advanced automation and interaction capabilities for Infrastructure as Code (IaC) development powered by [Terraform](https://www.hashicorp.com/en/products/terraform)\n- <img height=\"12\" width=\"12\" src=\"https://www.textin.com/favicon.png\" alt=\"TextIn Logo\" /> **[TextIn](https://github.com/intsig-textin/textin-mcp)** - An MCP server for the [TextIn](https://www.textin.com/?from=github_mcp) API, is a tool for extracting text and performing OCR on documents, it also supports converting documents into Markdown\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/106156665?s=200\" alt=\"Thena Logo\" /> **[Thena](https://mcp.thena.ai)** - Thena's MCP server for enabling users and AI agents to interact with Thena's services and manage customers across different channels such as Slack, Email, Web, Discord etc.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/24291394?v=4\" alt=\"ThingsBoard\" /> **[ThingsBoard](https://github.com/thingsboard/thingsboard-mcp)** - The ThingsBoard MCP Server provides a natural language interface for LLMs and AI agents to interact with your ThingsBoard IoT platform.\n- <img height=\"12\" width=\"12\" src=\"https://www.lg.com/favicon.ico\" alt=\"ThinQ Logo\" /> **[ThinQ Connect](https://github.com/thinq-connect/thinqconnect-mcp)** - Interact with LG ThinQ smart home devices and appliances through the ThinQ Connect MCP server.\n- <img height=\"12\" width=\"12\" src=\"https://thirdweb.com/favicon.ico\" alt=\"Thirdweb Logo\" /> **[Thirdweb](https://github.com/thirdweb-dev/ai/tree/main/python/thirdweb-mcp)** - Read/write to over 2k blockchains, enabling data querying, contract analysis/deployment, and transaction execution, powered by [Thirdweb](https://thirdweb.com/)\n- <img height=\"12\" width=\"12\" src=\"https://www.thoughtspot.com/favicon-16x16.png\" alt=\"ThoughtSpot Logo\" /> **[ThoughtSpot](https://github.com/thoughtspot/mcp-server)** - AI is the new BI. A dedicated data analyst for everyone on your team. Bring [ThoughtSpot](https://thoughtspot.com) powers into Claude or any MCP host.\n- <img height=\"12\" width=\"12\" src=\"https://tianji.msgbyte.com/img/dark-brand.svg\" alt=\"Tianji Logo\" /> **[Tianji](https://github.com/msgbyte/tianji/tree/master/apps/mcp-server)** - Interact with Tianji platform whatever selfhosted or cloud platform, powered by [Tianji](https://tianji.msgbyte.com/).\n- <img height=\"12\" width=\"12\" src=\"https://www.pingcap.com/favicon.ico\" alt=\"TiDB Logo\" /> **[TiDB](https://github.com/pingcap/pytidb)** - MCP Server to interact with TiDB database platform.\n- <img height=\"12\" width=\"12\" src=\"https://www.tinybird.co/favicon.ico\" alt=\"Tinybird Logo\" /> **[Tinybird](https://github.com/tinybirdco/mcp-tinybird)** - Interact with Tinybird serverless ClickHouse platform\n- <img height=\"12\" width=\"12\" src=\"https://b2729162.smushcdn.com/2729162/wp-content/uploads/2023/10/cropped-Favicon-1-192x192.png?lossy=1&strip=1&webp=1\" alt=\"Tldv Logo\" /> **[Tldv](https://gitlab.com/tldv/tldv-mcp-server)** - Connect your AI agents to Google-Meet, Zoom & Microsoft Teams through [tl;dv](https://tldv.io)\n- <img height=\"12\" width=\"12\" src=\"https://www.todoist.com/static/favicon-32x32.png\" alt=\"Todoist Logo\" /> **[Todoist](https://github.com/doist/todoist-ai)** - Search, add, and update [Todoist](https://todoist.com) tasks, projects, sections, comments, and more.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.tokenmetrics.com/logo.svg\" alt=\"Token Metrics Logo\" /> **[Token Metrics](https://github.com/token-metrics/mcp)** - [Token Metrics](https://www.tokenmetrics.com/) integration for fetching real-time crypto market data, trading signals, price predictions, and advanced analytics.\n- <img height=\"12\" width=\"12\" src=\"https://di8m9w6rqrh5d.cloudfront.net/2G3TRwfv1w3GTLfmT7Dmco1VddoFTI5P/1920_6b7e7ec2-d897-4cd7-94f3-46a8301212c3.png\" alt=\"TomTom Logo\" /> **[TomTom-MCP](https://github.com/tomtom-international/tomtom-mcp)** - The [TomTom](https://www.tomtom.com/) MCP Server simplifies geospatial development by providing seamless access to TomTom's location services, including search, routing, traffic and static maps data.\n- <img height=\"12\" width=\"12\" src=\"https://images.thetradeagent.ai/trade_agent/logo.svg\" alt=\"Trade Agent Logo\" /> **[Trade Agent](https://github.com/Trade-Agent/trade-agent-mcp)** - Execute stock and crypto trades on your brokerage via [Trade Agent](https://thetradeagent.ai)\n-  **[Twelve Data](https://github.com/twelvedata/mcp)** — Integrate your AI agents with real-time and historical financial market data through our official [Twelve Data](https://twelvedata.com) MCP server.\n- <img height=\"12\" width=\"12\" src=\"https://www.twilio.com/content/dam/twilio-com/core-assets/social/favicon-16x16.png\" alt=\"Twilio Logo\" /> **[Twilio](https://github.com/twilio-labs/mcp)** - Interact with [Twilio](https://www.twilio.com/en-us) APIs to send SMS messages, manage phone numbers, configure your account, and more.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/91520705?s=48&v=4\" alt=\"Tencent RTC Logo\" /> **[Tencent RTC](https://github.com/Tencent-RTC/mcp)** - The MCP Server enables AI IDEs to more effectively understand and use [Tencent's Real-Time Communication](https://trtc.io/) SDKs and APIs, which significantly streamlines the process for developers to build audio/video call applications.\n- <img height=\"12\" width=\"12\" src=\"https://uberall.com/media/favicon.svg\" alt=\"Uberall Logo\" /> **[Uberall](https://github.com/uberall/uberall-mcp-server)** – Manage multi - location presence, including listings, reviews, and social posting, via [uberall](https://uberall.com).\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/91906527\" alt=\"Unblocked Logo\" /> **[Unblocked](https://docs.getunblocked.com/unblocked-mcp)** Help your AI-powered IDEs generate faster, more accurate code by giving them access to context from Slack, Confluence, Google Docs, JIRA, and more with [Unblocked](https://getunblocked.com).\n- <img height=\"12\" width=\"12\" src=\"https://unifai.network/favicon.ico\" alt=\"UnifAI Logo\" /> **[UnifAI](https://github.com/unifai-network/unifai-mcp-server)** - Dynamically search and call tools using [UnifAI Network](https://unifai.network)\n- <img height=\"12\" width=\"12\" src=\"https://framerusercontent.com/images/plcQevjrOYnyriuGw90NfQBPoQ.jpg\" alt=\"Unstructured Logo\" /> **[Unstructured](https://github.com/Unstructured-IO/UNS-MCP)** - Set up and interact with your unstructured data processing workflows in [Unstructured Platform](https://unstructured.io)\n- <img height=\"12\" width=\"12\" src=\"https://upstash.com/icons/favicon-32x32.png\" alt=\"Upstash Logo\" /> **[Upstash](https://github.com/upstash/mcp-server)** - Manage Redis databases and run Redis commands on [Upstash](https://upstash.com/) with natural language.\n-  **[Vantage](https://github.com/vantage-sh/vantage-mcp-server)** - Interact with your organization's cloud cost spend.\n- <img height=\"12\" width=\"12\" src=\"https://mcp.variflight.com/favicon.ico\" alt=\"VariFlight Logo\" /> **[VariFlight](https://github.com/variflight/variflight-mcp)** - VariFlight's official MCP server provides tools to query flight information, weather data, comfort metrics, the lowest available fares, and other civil aviation-related data.\n- <img height=\"12\" width=\"12\" src=\"https://docs.octagonagents.com/logo.svg\" alt=\"Octagon Logo\" /> **[VCAgents](https://github.com/OctagonAI/octagon-vc-agents)** - Interact with investor agents—think Wilson or Thiel—continuously updated with market intel.\n- **[Vectorize](https://github.com/vectorize-io/vectorize-mcp-server/)** - [Vectorize](https://vectorize.io) MCP server for advanced retrieval, Private Deep Research, Anything-to-Markdown file extraction and text chunking.\n- <img height=\"12\" width=\"12\" src=\"https://static.verbwire.com/favicon-16x16.png\" alt=\"Verbwire Logo\" /> **[Verbwire](https://github.com/verbwire/verbwire-mcp-server)** - Deploy smart contracts, mint NFTs, manage IPFS storage, and more through the Verbwire API\n- <img height=\"12\" width=\"12\" src=\"http://vercel.com/favicon.ico\" alt=\"Vercel Logo\" /> **[Vercel](https://vercel.com/docs/mcp/vercel-mcp)** - Access logs, search docs, and manage projects and deployments.\n- <img height=\"12\" width=\"12\" src=\"https://verodat.io/assets/favicon-16x16.png\" alt=\"Verodat Logo\" /> **[Verodat](https://github.com/Verodat/verodat-mcp-server)** - Interact with Verodat AI Ready Data platform\n- <img height=\"12\" width=\"12\" src=\"https://www.veyrax.com/favicon.ico\" alt=\"VeyraX Logo\" /> **[VeyraX](https://github.com/VeyraX/veyrax-mcp)** - Single tool to control all 100+ API integrations, and UI components\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/174736222?s=200&v=4\" alt=\"VictoriaMetrics Logo\" /> **[VictoriaMetrics](https://github.com/VictoriaMetrics-Community/mcp-victoriametrics)** - Comprehensive integration with [VictoriaMetrics APIs](https://docs.victoriametrics.com/victoriametrics/url-examples/) and [documentation](https://docs.victoriametrics.com/) for monitoring, observability, and debugging tasks related to your VictoriaMetrics instances.\n- <img height=\"12\" width=\"12\" src=\"https://framerusercontent.com/images/ijlYG00LOcMD6zR1XLMxHbAwZkM.png\" alt=\"VideoDB Director\" /> **[VideoDB Director](https://github.com/video-db/agent-toolkit/tree/main/modelcontextprotocol)** - Create AI-powered video workflows including automatic editing, content moderation, voice cloning, highlight generation, and searchable video moments—all accessible via simple APIs and intuitive chat-based interfaces.\n- <img height=\"12\" width=\"12\" src=\"https://landing.ai/wp-content/uploads/2024/04/cropped-favicon-192x192.png\" alt=\"LandingAI VisionAgent\" /> **[VisionAgent MCP](https://github.com/landing-ai/vision-agent-mcp)** - A simple MCP server that enables your LLM to better reason over images, video and documents.\n- <img height=\"12\" width=\"12\" src=\"https://raw.githubusercontent.com/mckinsey/vizro/main/vizro-core/docs/assets/images/favicon.png\" alt=\"Vizro Logo\" /> **[Vizro](https://github.com/mckinsey/vizro/tree/main/vizro-mcp)** - Tools and templates to create validated and maintainable data charts and dashboards\n- <img height=\"12\" width=\"12\" src=\"https://wavespeed.ai/logo.webp\" alt=\"WaveSpeed Logo\" /> **[WaveSpeed](https://github.com/WaveSpeedAI/mcp-server)** - WaveSpeed MCP server providing AI agents with image and video generation capabilities.\n- <img height=\"12\" width=\"12\" src=\"https://waystation.ai/images/logo.svg\" alt=\"WayStation Logo\" /> **[WayStation](https://github.com/waystation-ai/mcp)** - Universal MCP server to connect to popular productivity tools such as Notion, Monday, AirTable, and many more\n- <img height=\"12\" width=\"12\" src=\"https://static.whatsapp.net/rsrc.php/v3/yz/r/ujTY9i_Jhs1.png\" alt=\"WhatsApp Business Logo\" /> **[WhatsApp Business](https://medium.com/@wassenger/introducing-whatsapp-mcp-ai-connector-3d393b52d1b0)** - WhatsApp Business MCP connector enabling AI agents to send messages, manage conversations, access templates, and integrate with WhatsApp Business API for automated customer communication.\n- <img height=\"12\" width=\"12\" src=\"https://www.webflow.com/favicon.ico\" alt=\"Webflow Logo\"> **[Webflow](https://github.com/webflow/mcp-server)** - Interact with Webflow sites, pages, and collections\n- <img height=\"12\" width=\"12\" src=\"https://webscraping.ai/favicon.ico\" alt=\"WebScraping.AI Logo\" /> **[WebScraping.AI](https://github.com/webscraping-ai/webscraping-ai-mcp-server)** - Interact with **[WebScraping.AI](https://WebScraping.AI)** for web data extraction and scraping\n- <img height=\"12\" width=\"12\" src=\"https://winston-app-production-public.s3.us-east-1.amazonaws.com/winston-ai-favicon-light.svg\" alt=\"Winston.AI Logo\" /> **[Winston AI](https://github.com/gowinston-ai/winston-ai-mcp-server)** - AI detector MCP server with industry leading accuracy rates in detecting use of AI in text and images. The [Winston AI](https://gowinston.ai) MCP server also offers a robust plagiarism checker to help maintain integrity.\n- <img height=\"12\" width=\"12\" src=\"https://www.xero.com/favicon.ico\" alt=\"Xero Logo\" /> **[Xero](https://github.com/XeroAPI/xero-mcp-server)** - Interact with the accounting data in your business using our official MCP server\n- <img height=\"12\" width=\"12\" src=\"https://storage.yandexcloud.net/ydb-www-prod-site-assets/favicon-202305/favicon.ico\" alt=\"YDB Logo\" /> **[YDB](https://github.com/ydb-platform/ydb-mcp)** - Query [YDB](https://ydb.tech/) databases\n- <img height=\"12\" width=\"12\" src=\"https://fe-resource.yeelight.com/logo-black.jpeg\" alt=\"Yeelight Logo\" /> **[Yeelight MCP Server](https://github.com/Yeelight/yeelight-iot-mcp)** - The official [Yeelight MCP Server](https://github.com/Yeelight/yeelight-iot-mcp) enables users to control and query their [Yeelight](https://en.yeelight.com/) smart devices using natural language, offering a seamless and efficient human-AI interaction experience.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/632cd328ed2b485519c3f689/6334977a5d1a542102d4b9b5_favicon-32x32.png\" alt=\"YepCode Logo\" /> **[YepCode](https://github.com/yepcode/mcp-server-js)** - Run code in a secure, scalable sandbox environment with full support for dependencies, secrets, logs, and access to APIs or databases. Powered by [YepCode](https://yepcode.io)\n- <img height=\"12\" width=\"12\" src=\"https://www.yugabyte.com/favicon-16x16.png\" alt=\"YugabyteDB Logo\" /> **[YugabyteDB](https://github.com/yugabyte/yugabytedb-mcp-server)** -  MCP Server to interact with your [YugabyteDB](https://www.yugabyte.com/) database\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/14069894\" alt=\"Yunxin Logo\" /> **[Yunxin](https://github.com/netease-im/yunxin-mcp-server)** - An MCP server that connects to Yunxin's IM/RTC/DATA Open-API\n- <img height=\"12\" width=\"12\" src=\"https://cdn.zapier.com/zapier/images/favicon.ico\" alt=\"Zapier Logo\" /> **[Zapier](https://zapier.com/mcp)** - Connect your AI Agents to 8,000 apps instantly.\n- <img height=\"12\" width=\"12\" src=\"https://www.zenable.app/zenable_light.svg\" alt=\"Zenable Logo\" /> **[Zenable](https://docs.zenable.io/integrations/mcp/getting-started)** - Clean up sloppy AI code and prevent vulnerabilities\n- **[ZenML](https://github.com/zenml-io/mcp-zenml)** - Interact with your MLOps and LLMOps pipelines through your [ZenML](https://www.zenml.io) MCP server\n- <img height=\"12\" width=\"12\" src=\"https://www.zine.ai/images/zine-logo.png\" alt=\"Zine Logo\" /> **[Zine](https://www.zine.ai)** - Your memory, everywhere AI goes. Think iPhoto for your knowledge - upload and curate. Like ChatGPT but portable - context that travels with you.\n- <img height=\"12\" width=\"12\" src=\"https://zizai.work/images/logo.jpg\" alt=\"ZIZAI Logo\" /> **[ZIZAI Recruitment](https://github.com/zaiwork/mcp)** - Interact with the next-generation intelligent recruitment platform for employees and employers, powered by [ZIZAI Recruitment](https://zizai.work).\n\n### 🌎 Community Servers\n\nA growing set of community-developed and maintained servers demonstrates various applications of MCP across different domains.\n\n> [!NOTE]\n> Community servers are **untested** and should be used at **your own risk**. They are not affiliated with or endorsed by Anthropic.\n\n- **[1mcpserver](https://github.com/particlefuture/1mcpserver)** - MCP of MCPs. Automatically discover, configure, and add MCP servers on your local machine.\n- **[1Panel](https://github.com/1Panel-dev/mcp-1panel)** - MCP server implementation that provides 1Panel interaction.\n- **[A2A](https://github.com/GongRzhe/A2A-MCP-Server)** - An MCP server that bridges the Model Context Protocol (MCP) with the Agent-to-Agent (A2A) protocol, enabling MCP-compatible AI assistants (like Claude) to seamlessly interact with A2A agents.\n- **[Ableton Live](https://github.com/Simon-Kansara/ableton-live-mcp-server)** - an MCP server to control Ableton Live.\n- **[Ableton Live](https://github.com/ahujasid/ableton-mcp)** (by ahujasid) - Ableton integration allowing prompt enabled music creation.\n- **[Actor Critic Thinking](https://github.com/aquarius-wing/actor-critic-thinking-mcp)** - Actor-critic thinking for performance evaluation\n- **[Adobe Commerce](https://github.com/rafaelstz/adobe-commerce-dev-mcp)** — MCP to interact with Adobe Commerce GraphQL API, including orders, products, customers, etc.\n- **[ADR Analysis](https://github.com/tosin2013/mcp-adr-analysis-server)** - AI-powered Architectural Decision Records (ADR) analysis server that provides architectural insights, technology stack detection, security checks, and TDD workflow enhancement for software development projects.\n- **[AgentBay](https://github.com/Michael98671/agentbay)** - An MCP server for providing serverless cloud infrastructure for AI agents.\n- **[AgentMode](https://www.agentmode.app)** - Connect to dozens of databases, data warehouses, Github & more, from a single MCP server.  Run the Docker image locally, in the cloud, or on-premise.\n- **[AI Agent Marketplace Index](https://github.com/AI-Agent-Hub/ai-agent-marketplace-index-mcp)** - MCP server to search more than 5000+ AI agents and tools of various categories from [AI Agent Marketplace Index](http://www.deepnlp.org/store/ai-agent) and monitor traffic of AI Agents.\n- **[AI Tasks](https://github.com/jbrinkman/valkey-ai-tasks)** - Let the AI manage complex plans with integrated task management and tracking tools. Supports STDIO, SSE and Streamable HTTP transports.\n- **[ai-Bible](https://github.com/AdbC99/ai-bible)** - Search the bible reliably and repeatably [ai-Bible Labs](https://ai-bible.com)\n- **[Airbnb](https://github.com/openbnb-org/mcp-server-airbnb)** - Provides tools to search Airbnb and get listing details.\n- **[Airflow](https://github.com/yangkyeongmo/mcp-server-apache-airflow)** - An MCP Server that connects to [Apache Airflow](https://airflow.apache.org/) using official python client.\n- **[Airtable](https://github.com/domdomegg/airtable-mcp-server)** - Read and write access to [Airtable](https://airtable.com/) databases, with schema inspection.\n- **[Airtable](https://github.com/felores/airtable-mcp)** - Airtable Model Context Protocol Server.\n- **[Algorand](https://github.com/GoPlausible/algorand-mcp)** - A comprehensive MCP server for tooling interactions (40+) and resource accessibility (60+) plus many useful prompts for interacting with the Algorand blockchain.\n- **[Amadeus](https://github.com/donghyun-chae/mcp-amadeus)** (by donghyun-chae) - An MCP server to access, explore, and interact with Amadeus Flight Offers Search API for retrieving detailed flight options, including airline, times, duration, and pricing data.\n- **[Amazon Ads](https://github.com/MarketplaceAdPros/amazon-ads-mcp-server)** - MCP Server that provides interaction capabilities with Amazon Advertising through [MarketplaceAdPros](https://marketplaceadpros.com)/\n- **[AniList](https://github.com/yuna0x0/anilist-mcp)** (by yuna0x0) - An MCP server to interact with AniList API, allowing you to search for anime and manga, retrieve user data, and manage your watchlist.\n- **[Anki](https://github.com/scorzeth/anki-mcp-server)** - An MCP server for interacting with your [Anki](https://apps.ankiweb.net) decks and cards.\n- **[Anki](https://github.com/nietus/anki-mcp)** - MCP server to run locally with Anki and Ankiconnect. Supports creating, updating, searching and filtering cards and decks. Include mass update and other advanced tools.\n- **[AntV Chart](https://github.com/antvis/mcp-server-chart)** - A Model Context Protocol server for generating 15+ visual charts using [AntV](https://github.com/antvis).\n- **[Any Chat Completions](https://github.com/pyroprompts/any-chat-completions-mcp)** - Interact with any OpenAI SDK Compatible Chat Completions API like OpenAI, Perplexity, Groq, xAI and many more.\n- **[Apache Gravitino(incubating)](https://github.com/datastrato/mcp-server-gravitino)** - Allow LLMs to explore metadata of structured data and unstructured data with Gravitino, and perform data governance tasks including tagging/classification.\n- **[API Lab MCP](https://github.com/atototo/api-lab-mcp)** - Transform Claude into your AI-powered API testing laboratory. Test, debug, and document APIs through natural conversation with authentication support, response validation, and performance metrics.\n- **[APIWeaver](https://github.com/GongRzhe/APIWeaver)** - An MCP server that dynamically creates MCP  servers from web API configurations. This allows you to easily integrate any REST API, GraphQL endpoint, or web service into an MCP-compatible tool that can be used by AI assistants like Claude.\n- **[Apollo IO MCP Server](https://github.com/AgentX-ai/apollo-io-mcp-server)** - apollo.io mcp server. Get/enrich contact data for people and organizations agentically.\n- **[Apple Books](https://github.com/vgnshiyer/apple-books-mcp)** - Interact with your library on Apple Books, manage your book collection, summarize highlights, notes, and much more.\n- **[Apple Calendar](https://github.com/Omar-v2/mcp-ical)** - An MCP server that allows you to interact with your macOS Calendar through natural language, including features such as event creation, modification, schedule listing, finding free time slots etc.\n- **[Apple Docs](https://github.com/kimsungwhee/apple-docs-mcp)** - A powerful Model Context Protocol (MCP) server that provides seamless access to Apple Developer Documentation through natural language queries. Search, explore, and get detailed information about Apple frameworks, APIs, sample code, and more directly in your AI-powered development environment.\n- **[Apple Script](https://github.com/peakmojo/applescript-mcp)** - MCP server that lets LLM run AppleScript code to to fully control anything on Mac, no setup needed.\n- **[APT MCP](https://github.com/GdMacmillan/apt-mcp-server)** - MCP server which runs debian package manager (apt) commands for you using ai agents.\n- **[Aranet4](https://github.com/diegobit/aranet4-mcp-server)** - MCP Server to manage your Aranet4 CO2 sensor. Fetch data and store in a local SQLite. Ask questions about historical data.\n- **[ArangoDB](https://github.com/ravenwits/mcp-server-arangodb)** - MCP Server that provides database interaction capabilities through [ArangoDB](https://arangodb.com/).\n- **[ArangoDB Graph](https://github.com/PCfVW/mcp-arangodb-async)** - Async-first Python architecture, wrapping the official [python-arango driver](https://github.com/arangodb/python-arango) with graph management capabilities, content conversion utilities (JSON, Markdown, YAML and Table), backup/restore functionality, and graph analytics capabilities; the 33 MCP tools use strict [Pydantic](https://github.com/pydantic/pydantic) validation.\n- **[Arduino](https://github.com/vishalmysore/choturobo)** - MCP Server that enables AI-powered robotics using Claude AI and Arduino (ESP32) for real-world automation and interaction with robots.\n- **[arXiv API](https://github.com/prashalruchiranga/arxiv-mcp-server)** - An MCP server that enables interacting with the arXiv API using natural language.\n- **[arxiv-latex-mcp](https://github.com/takashiishida/arxiv-latex-mcp)** - MCP server that fetches and processes arXiv LaTeX sources for precise interpretation of mathematical expressions in papers.\n- **[Atlassian](https://github.com/sooperset/mcp-atlassian)** - Interact with Atlassian Cloud products (Confluence and Jira) including searching/reading Confluence spaces/pages, accessing Jira issues, and project metadata.\n- **[Atlassian Server (by phuc-nt)](https://github.com/phuc-nt/mcp-atlassian-server)** - An MCP server that connects AI agents (Cline, Claude Desktop, Cursor, etc.) to Atlassian Jira & Confluence, enabling data queries and actions through the Model Context Protocol.\n- **[Attestable MCP](https://github.com/co-browser/attestable-mcp-server)** - An MCP server running inside a trusted execution environment (TEE) via Gramine, showcasing remote attestation using [RA-TLS](https://gramine.readthedocs.io/en/stable/attestation.html). This allows an MCP client to verify the server before connecting.\n- **[Audius](https://github.com/glassBead-tc/audius-mcp-atris)** - Audius + AI = Atris. Interact with fans, stream music, tip your favorite artists, and more on Audius: all through Claude.\n- **[AutoML](https://github.com/emircansoftware/MCP_Server_DataScience)** – An MCP server for data analysis workflows including reading, preprocessing, feature engineering, model selection, visualization, and hyperparameter tuning.\n- **[AX-Platform](https://github.com/AX-MCP/PaxAI?tab=readme-ov-file#mcp-setup-guides)** - AI Agent collaboration platform. Collaborate on tasks, share context, and coordinate workflows.\n- **[AWS](https://github.com/rishikavikondala/mcp-server-aws)** - Perform operations on your AWS resources using an LLM.\n- **[AWS Athena](https://github.com/lishenxydlgzs/aws-athena-mcp)** - An MCP server for AWS Athena to run SQL queries on Glue Catalog.\n- **[AWS Cognito](https://github.com/gitCarrot/mcp-server-aws-cognito)** - An MCP server that connects to AWS Cognito for authentication and user management.\n- **[AWS Cost Explorer](https://github.com/aarora79/aws-cost-explorer-mcp-server)** - Optimize your AWS spend (including Amazon Bedrock spend) with this MCP server by examining spend across regions, services, instance types and foundation models ([demo video](https://www.youtube.com/watch?v=WuVOmYLRFmI&feature=youtu.be)).\n- **[AWS Resources Operations](https://github.com/baryhuang/mcp-server-aws-resources-python)** - Run generated python code to securely query or modify any AWS resources supported by boto3.\n- **[AWS S3](https://github.com/aws-samples/sample-mcp-server-s3)** - A sample MCP server for AWS S3 that flexibly fetches objects from S3 such as PDF documents.\n- **[AWS SES](https://github.com/aws-samples/sample-for-amazon-ses-mcp)** Sample MCP Server for Amazon SES (SESv2). See [AWS blog post](https://aws.amazon.com/blogs/messaging - and-targeting/use-ai-agents-and-the-model-context-protocol-with-amazon-ses/) for more details.\n- **[Azure ADX](https://github.com/pab1it0/adx-mcp-server)** - Query and analyze Azure Data Explorer databases.\n- **[Azure DevOps](https://github.com/Vortiago/mcp-azure-devops)** - An MCP server that provides a bridge to Azure DevOps services, enabling AI assistants to query and manage work items.\n- **[Azure MCP Hub](https://github.com/Azure-Samples/mcp)** - A curated list of all MCP servers and related resources for Azure developers by **[Arun Sekhar](https://github.com/achandmsft)**\n- **[Azure OpenAI DALL-E 3 MCP Server](https://github.com/jacwu/mcp-server-aoai-dalle3)** - An MCP server for Azure OpenAI DALL-E 3 service to generate image from text.\n- **[Azure Wiki Search](https://github.com/coder-linping/azure-wiki-search-server)** - An MCP that enables AI to query the wiki hosted on Azure Devops Wiki.\n- **[Baidu AI Search](https://github.com/baidubce/app-builder/tree/master/python/mcp_server/ai_search)** - Web search with Baidu Cloud's AI Search\n- **[BambooHR MCP](https://github.com/encoreshao/bamboohr-mcp)** - An MCP server that interfaces with the BambooHR APIs, providing access to employee data, time tracking, and HR management features.\n- **[Base Free USDC Transfer](https://github.com/magnetai/mcp-free-usdc-transfer)** - Send USDC on [Base](https://base.org) for free using Claude AI! Built with [Coinbase CDP](https://docs.cdp.coinbase.com/mpc-wallet/docs/welcome).\n- **[Basic Memory](https://github.com/basicmachines-co/basic-memory)** - Local-first knowledge management system that builds a semantic graph from Markdown files, enabling persistent memory across conversations with LLMs.\n- **[BGG MCP](https://github.com/kkjdaniel/bgg-mcp)** (by kkjdaniel) - MCP to enable interaction with the BoardGameGeek API via AI tooling.\n- **[Bible](https://github.com/trevato/bible-mcp)** - Add biblical context to your generative AI applications.\n- **[BigQuery](https://github.com/LucasHild/mcp-server-bigquery)** (by LucasHild) - This server enables LLMs to inspect database schemas and execute queries on BigQuery.\n- **[BigQuery](https://github.com/ergut/mcp-bigquery-server)** (by ergut) - Server implementation for Google BigQuery integration that enables direct BigQuery database access and querying capabilities\n- **[Bilibili](https://github.com/wangshunnn/bilibili-mcp-server)** - This MCP server provides tools to fetch Bilibili user profiles, video metadata, search videos, and more.\n- **[Binance](https://github.com/ethancod1ng/binance-mcp-server)** - Cryptocurrency trading and market data access through Binance API integration.\n- **[Binance](https://github.com/AnalyticAce/BinanceMCPServer)** (by dosseh shalom) - Unofficial tools and server implementation for Binance's Model Context Protocol (MCP). Designed to support developers building crypto trading AI Agents.\n- **[Bing Web Search API](https://github.com/leehanchung/bing-search-mcp)** (by hanchunglee) - Server implementation for Microsoft Bing Web Search API.\n- **[BioMCP](https://github.com/genomoncology/biomcp)** (by imaurer) - Biomedical research assistant server providing access to PubMed, ClinicalTrials.gov, and MyVariant.info.\n- **[bioRxiv](https://github.com/JackKuo666/bioRxiv-MCP-Server)** - 🔍 Enable AI assistants to search and access bioRxiv papers through a simple MCP interface.\n- **[Bitable MCP](https://github.com/lloydzhou/bitable-mcp)** (by lloydzhou) - MCP server provides access to Lark Bitable through the Model Context Protocol. It allows users to interact with Bitable tables using predefined tools.\n- **[Blender](https://github.com/ahujasid/blender-mcp)** (by ahujasid) - Blender integration allowing prompt enabled 3D scene creation, modeling and manipulation.\n- **[Blender MCP](https://github.com/pranav-deshmukh/blender-mcp)** - MCP server to create professional like 3d scenes on blender using natural language.\n- **[Blockbench MCP Plugin](https://github.com/jasonjgardner/blockbench-mcp-plugin)** (by jasonjgardner) - Blockbench plugin to connect AI agents to Blockbench's JavaScript API. Allows for creating and editing 3D models or pixel art textures with AI in Blockbench.\n- **[Blockchain MCP](https://github.com/tatumio/blockchain-mcp)** - MCP Server for Blockchain Data from **[Tatum](http://tatum.io/mcp)** that instantly unlocks blockchain access for your AI agents. This official Tatum MCP server connects to any LLM in seconds.\n- **[Bluesky](https://github.com/semioz/bluesky-mcp)** (by semioz) - An MCP server for Bluesky, a decentralized social network. It enables automated interactions with the AT Protocol, supporting features like posting, liking, reposting, timeline management, and profile operations.\n- **[Bluetooth MCP Server](https://github.com/Hypijump31/bluetooth-mcp-server)** - Control Bluetooth devices and manage connections through natural language commands, including device discovery, pairing, and audio controls.\n- **[BNBChain MCP](https://github.com/bnb-chain/bnbchain-mcp)** - An MCP server for interacting with BSC, opBNB, and the Greenfield blockchain.\n- **[Braintree](https://github.com/QuentinCody/braintree-mcp-server)** - Unofficial PayPal Braintree payment gateway MCP Server for AI agents to process payments, manage customers, and handle transactions securely.\n- **[Brazilian Law](https://github.com/pdmtt/brlaw_mcp_server/)** (by pdmtt) - Agent-driven research on Brazilian law using official sources.\n- **[BreakoutRoom](https://github.com/agree-able/room-mcp)** - Agents accomplishing goals together in p2p rooms\n- **[Browser MCP](https://github.com/bytedance/UI-TARS-desktop/tree/main/packages/agent-infra/mcp-servers/browser)** (by UI-TARS) - A fast, lightweight MCP server that empowers LLMs with browser automation via Puppeteer’s structured accessibility data, featuring optional vision mode for complex visual understanding and flexible, cross-platform configuration.\n- **[browser-use](https://github.com/co-browser/browser-use-mcp-server)** (by co-browser) - browser-use MCP server with dockerized playwright + chromium + vnc. supports stdio & resumable http.\n- **[BrowserLoop](https://github.com/mattiasw/browserloop)** - An MCP server for taking screenshots of web pages using Playwright. Supports high-quality capture with configurable formats, viewport sizes, cookie-based authentication, and both full page and element-specific screenshots.\n- **[Bsc-mcp](https://github.com/TermiX-official/bsc-mcp)** The first MCP server that serves as the bridge between AI and BNB Chain, enabling AI agents to execute complex on-chain operations through seamless integration with the BNB Chain, including transfer, swap, launch, security check on any token and even more.\n- **[BugBug MCP Server](https://github.com/simplypixi/bugbug-mcp-server)** - Unofficial MCP server for BugBug API.\n- **[BVG MCP Server - (Unofficial) ](https://github.com/svkaizoku/mcp-bvg)** - Unofficial MCP server for Berliner Verkehrsbetriebe Api.\n- **[Bybit](https://github.com/ethancod1ng/bybit-mcp-server)** - A Model Context Protocol (MCP) server for integrating AI assistants with Bybit cryptocurrency exchange APIs, enabling automated trading, market data access, and account management.\n- **[CAD-MCP](https://github.com/daobataotie/CAD-MCP#)** (by daobataotie) - Drawing CAD(Line,Circle,Text,Annotation...) through MCP server, supporting mainstream CAD software.\n- **[Calculator](https://github.com/githejie/mcp-server-calculator)** - This server enables LLMs to use calculator for precise numerical calculations.\n- **[CalDAV MCP](https://github.com/dominik1001/caldav-mcp)** - A CalDAV MCP server to expose calendar operations as tools for AI assistants.\n- **[Calendly-mcp-server](https://github.com/meAmitPatil/calendly-mcp-server)** - Open source calendly mcp server.\n- **[Catalysis Hub](https://github.com/QuentinCody/catalysishub-mcp-server)** - Unofficial MCP server for searching and retrieving scientific data from the Catalysis Hub database, providing access to computational catalysis research and surface reaction data.\n- **[CCTV VMS MCP](https://github.com/jyjune/mcp_vms)** - A Model Context Protocol (MCP) server designed to connect to a CCTV recording program (VMS) to retrieve recorded and live video streams. It also provides tools to control the VMS software, such as showing live or playback dialogs for specific channels at specified times.\n- **[CFBD API](https://github.com/lenwood/cfbd-mcp-server)** - An MCP server for the [College Football Data API](https://collegefootballdata.com/).\n- **[ChatMCP](https://github.com/AI-QL/chat-mcp)** – An Open Source Cross-platform GUI Desktop application compatible with Linux, macOS, and Windows, enabling seamless interaction with MCP servers across dynamically selectable LLMs, by **[AIQL](https://github.com/AI-QL)**\n- **[ChatSum](https://github.com/mcpso/mcp-server-chatsum)** - Query and Summarize chat messages with LLM. by [mcpso](https://mcp.so)\n- **[Chess.com](https://github.com/pab1it0/chess-mcp)** - Access Chess.com player data, game records, and other public information through standardized MCP interfaces, allowing AI assistants to search and analyze chess information.\n- **[ChessPal Chess Engine (stockfish)](https://github.com/wilson-urdaneta/chesspal-mcp-engine)** - A Stockfish-powered chess engine exposed as an MCP server. Calculates best moves and supports both HTTP/SSE and stdio transports.\n- **[Chroma](https://github.com/privetin/chroma)** - Vector database server for semantic document search and metadata filtering, built on Chroma\n- **[Chrome history](https://github.com/vincent-pli/chrome-history-mcp)** - Talk with AI about your browser history, get fun ^_^\n- **[CIViC](https://github.com/QuentinCody/civic-mcp-server)** - MCP server for the Clinical Interpretation of Variants in Cancer (CIViC) database, providing access to clinical variant interpretations and genomic evidence for cancer research.\n- **[Claude Thread Continuity](https://github.com/peless/claude-thread-continuity)** - Persistent memory system enabling Claude Desktop conversations to resume with full context across sessions. Maintains conversation history, project states, and user preferences for seamless multi-session workflows.\n- **[ClaudePost](https://github.com/ZilongXue/claude-post)** - ClaudePost enables seamless email management for Gmail, offering secure features like email search, reading, and sending.\n- **[CLDGeminiPDF Analyzer](https://github.com/tfll37/CLDGeminiPDF-Analyzer)** - MCP server tool enabling sharing large PDF files to Google LLMs via API for further/additional analysis and response retrieval to Claude Desktop.\n- **[ClearML MCP](https://github.com/prassanna-ravishankar/clearml-mcp)** - Get comprehensive ML experiment context and analysis directly from [ClearML](https://clear.ml) in your AI conversations.\n- **[ClickUp](https://github.com/TaazKareem/clickup-mcp-server)** - MCP server for ClickUp task management, supporting task creation, updates, bulk operations, and markdown descriptions.\n- **[Cloudinary](https://github.com/felores/cloudinary-mcp-server)** - Cloudinary Model Context Protocol Server to upload media to Cloudinary and get back the media link and details.\n- **[CockroachDB](https://github.com/amineelkouhen/mcp-cockroachdb)** - MCP server enabling AI agents and LLMs to manage, monitor, and query **[CockroachDB](https://www.cockroachlabs.com/)** using natural language.\n- **[CockroachDB MCP Server](https://github.com/viragtripathi/cockroachdb-mcp-server)** – Full - featured MCP implementation built with FastAPI and CockroachDB. Supports schema bootstrapping, JSONB storage, LLM-ready CLI, and optional `/debug` endpoints.\n- **[code-assistant](https://github.com/stippi/code-assistant)** - A coding assistant MCP server that allows to explore a code-base and make changes to code. Should be used with trusted repos only (insufficient protection against prompt injections).\n- **[code-context-provider-mcp](https://github.com/AB498/code-context-provider-mcp)** - MCP server that provides code context and analysis for AI assistants. Extracts directory structure and code symbols using WebAssembly Tree-sitter parsers without Native Dependencies.\n- **[code-executor](https://github.com/bazinga012/mcp_code_executor)** - An MCP server that allows LLMs to execute Python code within a specified Conda environment.\n- **[code-sandbox-mcp](https://github.com/Automata-Labs-team/code-sandbox-mcp)** - An MCP server to create secure code sandbox environment for executing code within Docker containers.\n- **[cognee-mcp](https://github.com/topoteretes/cognee/tree/main/cognee-mcp)** - GraphRAG memory server with customizable ingestion, data processing and search\n- **[coin_api_mcp](https://github.com/longmans/coin_api_mcp)** - Provides access to [coinmarketcap](https://coinmarketcap.com/) cryptocurrency data.\n- **[CoinMarketCap](https://github.com/shinzo-labs/coinmarketcap-mcp)** - Implements the complete [CoinMarketCap](https://coinmarketcap.com/) API for accessing cryptocurrency market data, exchange information, and other blockchain-related metrics.\n- **[commands](https://github.com/g0t4/mcp-server-commands)** - Run commands and scripts. Just like in a terminal.\n- **[Companies House MCP](https://github.com/stefanoamorelli/companies-house-mcp)** (by Stefano Amorelli) - MCP server to connect with the UK Companies House API.\n- **[computer-control-mcp](https://github.com/AB498/computer-control-mcp)** - MCP server that provides computer control capabilities, like mouse, keyboard, OCR, etc. using PyAutoGUI, RapidOCR, ONNXRuntime Without External Dependencies.\n- **[Computer-Use - Remote MacOS Use](https://github.com/baryhuang/mcp-remote-macos-use)** - Open-source out-of-the-box alternative to OpenAI Operator, providing a full desktop experience and optimized for using remote macOS machines as autonomous AI agents.\n- **[Congress.gov API](https://github.com/AshwinSundar/congress_gov_mcp)** - An MCP server to interact with real-time data from the Congress.gov API, which is the official API for the United States Congress.\n- **[consul-mcp](https://github.com/kocierik/consul-mcp-server)** - A consul MCP server for service management, health check and Key-Value Store\n- **[consult7](https://github.com/szeider/consult7)** - Analyze large codebases and document collections using high-context models via OpenRouter, OpenAI, or Google AI -- very useful, e.g., with Claude Code\n- **[Contentful-mcp](https://github.com/ivo-toby/contentful-mcp)** - Read, update, delete, publish content in your [Contentful](https://contentful.com) space(s) from this MCP Server.\n- **[Context Crystallizer](https://github.com/hubertciebiada/context-crystallizer)** - AI Context Engineering tool that transforms large repositories into crystallized, AI-consumable knowledge through systematic analysis and optimization.\n- **[MCP Context Provider](https://github.com/doobidoo/MCP-Context-Provider)** - Static server that provides AI models with persistent tool-specific context and rules, preventing context loss between chat sessions and enabling consistent behavior across interactions.\n- **[context-portal](https://github.com/GreatScottyMac/context-portal)** - Context Portal (ConPort) is a memory bank database system that effectively builds a project-specific knowledge graph, capturing entities like decisions, progress, and architecture, along with their relationships. This serves as a powerful backend for Retrieval Augmented Generation (RAG), enabling AI assistants to access precise, up-to-date project information.\n- **[cplusplus-mcp](https://github.com/kandrwmrtn/cplusplus_mcp)** - Semantic C++ code analysis using libclang. Enables Claude to understand C++ codebases through AST parsing rather than text search - find classes, navigate inheritance, trace function calls, and explore code relationships.\n- **[CreateveAI Nexus](https://github.com/spgoodman/createveai-nexus-server)** - Open-Source Bridge Between AI Agents and Enterprise Systems, with simple custom API plug-in capabilities (including close compatibility with ComfyUI nodes), support for Copilot Studio's MCP agent integations, and support for Azure deployment in secure environments with secrets stored in Azure Key Vault, as well as straightforward on-premises deployment.\n- **[CRASH](https://github.com/nikkoxgonzales/crash-mcp)** - MCP server for structured, iterative reasoning and thinking with flexible validation, confidence tracking, revision mechanisms, and branching support.\n- **[Creatify](https://github.com/TSavo/creatify-mcp)** - MCP Server that exposes Creatify AI API capabilities for AI video generation, including avatar videos, URL-to-video conversion, text-to-speech, and AI-powered editing tools.\n- **[Cronlytic](https://github.com/Cronlytic/cronlytic-mcp-server)** - Create CRUD operations for serverless cron jobs through [Cronlytic](https://cronlytic.com) MCP Server\n- **[crypto-feargreed-mcp](https://github.com/kukapay/crypto-feargreed-mcp)**  -  Providing real-time and historical Crypto Fear & Greed Index data.\n- **[crypto-indicators-mcp](https://github.com/kukapay/crypto-indicators-mcp)**  -  An MCP server providing a range of cryptocurrency technical analysis indicators and strategies.\n- **[crypto-sentiment-mcp](https://github.com/kukapay/crypto-sentiment-mcp)**  -  An MCP server that delivers cryptocurrency sentiment analysis to AI agents.\n- **[cryptopanic-mcp-server](https://github.com/kukapay/cryptopanic-mcp-server)** - Providing latest cryptocurrency news to AI agents, powered by CryptoPanic.\n- **[CSV Editor](https://github.com/santoshray02/csv-editor)** - Comprehensive CSV processing with 40+ operations for data manipulation, analysis, and validation. Features auto-save, undo/redo, and handles GB+ files. Built with FastMCP & Pandas.\n- **[Cursor MCP Installer](https://github.com/matthewdcage/cursor-mcp-installer)** - A tool to easily install and configure other MCP servers within Cursor IDE, with support for npm packages, local directories, and Git repositories.\n- **[CVE Intelligence Server](https://github.com/gnlds/mcp-cve-intelligence-server-lite)** – Provides vulnerability intelligence via multi - source CVE data, essential exploit discovery, and EPSS risk scoring through the MCP. Useful for security research, automation, and agent workflows.\n- **[D365FO](https://github.com/mafzaal/d365fo-client)** - A comprehensive MCP server for Microsoft Dynamics 365 Finance & Operations (D365 F&O) that provides easy access to OData endpoints, metadata operations, label management, and AI assistant integration.\n- **[Dagster](https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-dg-cli)** - An MCP server to easily build data pipelines using [Dagster](https://dagster.io/).\n- **[Dappier](https://github.com/DappierAI/dappier-mcp)** - Connect LLMs to real-time, rights-cleared, proprietary data from trusted sources. Access specialized models for Real-Time Web Search, News, Sports, Financial Data, Crypto, and premium publisher content. Explore data models at [marketplace.dappier.com](https://marketplace.dappier.com/marketplace).\n- **[Data Exploration](https://github.com/reading-plus-ai/mcp-server-data-exploration)** - MCP server for autonomous data exploration on .csv-based datasets, providing intelligent insights with minimal effort. NOTE: Will execute arbitrary Python code on your machine, please use with caution!\n- **[Databricks](https://github.com/JordiNeil/mcp-databricks-server)** - Allows LLMs to run SQL queries, list and get details of jobs executions in a Databricks account.\n- **[Databricks Genie](https://github.com/yashshingvi/databricks-genie-MCP)** - A server that connects to the Databricks Genie, allowing LLMs to ask natural language questions, run SQL queries, and interact with Databricks conversational agents.\n- **[Databricks Smart SQL](https://github.com/RafaelCartenet/mcp-databricks-server)** - Leveraging Databricks Unity Catalog metadata, perform smart efficient SQL queries to solve Ad-hoc queries and explore data.\n- **[DataCite](https://github.com/QuentinCody/datacite-mcp-server)** - Unofficial MCP server for DataCite, providing access to research data and publication metadata through DataCite's REST API and GraphQL interface for scholarly research discovery.\n- **[Datadog](https://github.com/GeLi2001/datadog-mcp-server)** - Datadog MCP Server for application tracing, monitoring, dashboard, incidents queries built on official datadog api.\n- **[Dataset Viewer](https://github.com/privetin/dataset-viewer)** - Browse and analyze Hugging Face datasets with features like search, filtering, statistics, and data export\n- **[DataWorks](https://github.com/aliyun/alibabacloud-dataworks-mcp-server)** - A Model Context Protocol (MCP) server that provides tools for AI, allowing it to interact with the [DataWorks](https://www.alibabacloud.com/help/en/dataworks/) Open API through a standardized interface. This implementation is based on the Alibaba Cloud Open API and enables AI agents to perform cloud resources operations seamlessly.\n- **[Data4library](https://github.com/isnow890/data4library-mcp)** (by isnow890) - MCP server for Korea's Library Information Naru API, providing comprehensive access to public library data, book searches, loan status, reading statistics, and GPS-based nearby library discovery across South Korea.\n\n- **[DaVinci Resolve](https://github.com/samuelgursky/davinci-resolve-mcp)** - MCP server integration for DaVinci Resolve providing powerful tools for video editing, color grading, media management, and project control.\n- **[DBHub](https://github.com/bytebase/dbhub/)** - Universal database MCP server connecting to MySQL, MariaDB, PostgreSQL, and SQL Server.\n- **[Deebo](https://github.com/snagasuri/deebo-prototype)** – Agentic debugging MCP server that helps AI coding agents delegate and fix hard bugs through isolated multi-agent hypothesis testing.\n- **[Deep Research](https://github.com/reading-plus-ai/mcp-server-deep-research)** - Lightweight MCP server offering Grok/OpenAI/Gemini/Perplexity-style automated deep research exploration and structured reporting.\n- **[DeepSeek MCP Server](https://github.com/DMontgomery40/deepseek-mcp-server)** - Model Context Protocol server integrating DeepSeek's advanced language models, in addition to [other useful API endpoints](https://github.com/DMontgomery40/deepseek-mcp-server?tab=readme-ov-file#features)\n- **[deepseek-thinker-mcp](https://github.com/ruixingshi/deepseek-thinker-mcp)** - A MCP (Model Context Protocol) provider Deepseek reasoning content to MCP-enabled AI Clients, like Claude Desktop. Supports access to Deepseek's thought processes from the Deepseek API service or from a local Ollama server.\n- **[Deepseek_R1](https://github.com/66julienmartin/MCP-server-Deepseek_R1)** - A Model Context Protocol (MCP) server implementation connecting Claude Desktop with DeepSeek's language models (R1/V3)\n- **[Depyler](https://github.com/paiml/depyler/blob/main/docs/mcp-integration.md)** - Energy-efficient Python-to-Rust transpiler with progressive verification, enabling AI assistants to convert Python code to safe, performant Rust while reducing energy consumption by 75-85%.\n- **[deploy-mcp](https://github.com/alexpota/deploy-mcp)** - Universal deployment tracker for AI assistants with live status badges and deployment monitoring.\n- **[Descope](https://github.com/descope-sample-apps/descope-mcp-server)** - An MCP server to integrate with [Descope](https://descope.com) to search audit logs, manage users, and more.\n- **[DesktopCommander](https://github.com/wonderwhy-er/DesktopCommanderMCP)** - Let AI edit and manage files on your computer, run terminal commands, and connect to remote servers via SSH - all powered by one of the most popular local MCP servers.\n- **[Devcontainer](https://github.com/AI-QL/mcp-devcontainers)** - An MCP server for devcontainer to generate and configure development containers directly from devcontainer configuration files.\n- **[DevDb](https://github.com/damms005/devdb-vscode?tab=readme-ov-file#mcp-configuration)** - An MCP server that runs right inside the IDE, for connecting to MySQL, Postgres, SQLite, and MSSQL databases.\n- **[DevOps AI Toolkit](https://github.com/vfarcic/dot-ai)** - AI-powered development productivity platform that enhances software development workflows through intelligent automation and AI-driven assistance.\n- **[DevOps-MCP](https://github.com/wangkanai/devops-mcp)** - Dynamic Azure DevOps MCP server with directory-based authentication switching, supporting work items, repositories, builds, pipelines, and multi-project management with local configuration files.\n- **[DGIdb](https://github.com/QuentinCody/dgidb-mcp-server)** - MCP server for the Drug Gene Interaction Database (DGIdb), providing access to drug-gene interaction data, druggable genome information, and pharmacogenomics research.\n- **[Dicom](https://github.com/ChristianHinge/dicom-mcp)** - An MCP server to query and retrieve medical images and for parsing and reading dicom-encapsulated documents (pdf etc.).\n- **[Dify](https://github.com/YanxingLiu/dify-mcp-server)** - A simple implementation of an MCP server for dify workflows.\n- **[Discogs](https://github.com/cswkim/discogs-mcp-server)** - An MCP server that connects to the Discogs API for interacting with your music collection.\n- **[Discord](https://github.com/v-3/discordmcp)** - An MCP server to connect to Discord guilds through a bot and read and write messages in channels\n- **[Discord](https://github.com/SaseQ/discord-mcp)** - An MCP server, which connects to Discord through a bot, and provides comprehensive integration with Discord.\n- **[Discord](https://github.com/Klavis-AI/klavis/tree/main/mcp_servers/discord)** - For Discord API integration by Klavis AI\n- **[Discourse](https://github.com/AshDevFr/discourse-mcp-server)** - An MCP server to search Discourse posts on a Discourse forum.\n- **[DocBase](https://help.docbase.io/posts/3925317)** - Official MCP server for DocBase API integration, enabling post management, user collaboration, group administration, and more.\n- **[Docker](https://github.com/ckreiling/mcp-server-docker)** - Integrate with Docker to manage containers, images, volumes, and networks.\n- **[Docker](https://github.com/0xshariq/docker-mcp-server)** - Docker MCP Server provides advanced, unified Docker management via CLI and MCP workflows, supporting containers, images, volumes, networks, and orchestration.\n- **[Docs](https://github.com/da1z/docsmcp)** - Enable documentation access for the AI agent, supporting llms.txt and other remote or local files.\n- **[documcp](https://github.com/tosin2013/documcp)** - An MCP server for intelligent document processing and management, supporting multiple formats and document operations.\n- **[Docy](https://github.com/oborchers/mcp-server-docy)** - Docy gives your AI direct access to the technical documentation it needs, right when it needs it. No more outdated information, broken links, or rate limits - just accurate, real-time documentation access for more precise coding assistance.\n- **[Dodo Payments](https://github.com/dodopayments/dodopayments-node/tree/main/packages/mcp-server)** - Enables AI agents to securely perform payment operations via a lightweight, serverless-compatible interface to the [Dodo Payments](https://dodopayments.com) API.\n- **[Domain Tools](https://github.com/deshabhishek007/domain-tools-mcp-server)** - A Model Context Protocol (MCP) server for comprehensive domain analysis: WHOIS, DNS records, and DNS health checks.\n- **[DPLP](https://github.com/szeider/mcp-dblp)**  - Searches the [DBLP](https://dblp.org) computer science bibliography database.\n- **[Druid MCP Server](https://github.com/iunera/druid-mcp-server)** - STDIO/SEE MCP Server for Apache Druid by [iunera](https://www.iunera.com) that provides extensive tools, resources, and prompts for managing and analyzing Druid clusters.\n- **[Drupal](https://github.com/Omedia/mcp-server-drupal)** - Server for interacting with [Drupal](https://www.drupal.org/project/mcp) using STDIO transport layer.\n- **[dune-analytics-mcp](https://github.com/kukapay/dune-analytics-mcp)** -  A mcp server that bridges Dune Analytics data to AI agents.\n- **[DynamoDB-Toolbox](https://www.dynamodbtoolbox.com/docs/databases/actions/mcp-toolkit)** - Leverages your Schemas and Access Patterns to interact with your [DynamoDB](https://aws.amazon.com/dynamodb) Database using natural language.\n- **[eBook-mcp](https://github.com/onebirdrocks/ebook-mcp)** - A lightweight MCP server that allows LLMs to read and interact with your personal PDF and EPUB ebooks. Ideal for building AI reading assistants or chat-based ebook interfaces.\n- **[ECharts MCP Server](https://github.com/hustcc/mcp-echarts)** - Generate visual charts using ECharts with AI MCP dynamically, used for chart generation and data analysis.\n- **[EDA MCP Server](https://github.com/NellyW8/mcp-EDA)** - A comprehensive Model Context Protocol server for Electronic Design Automation tools, enabling AI assistants to synthesize Verilog with Yosys, simulate designs with Icarus Verilog, run complete ASIC flows with OpenLane, and view results with GTKWave and KLayout.\n- **[EdgeOne Pages MCP](https://github.com/TencentEdgeOne/edgeone-pages-mcp)** - An MCP service for deploying HTML content to EdgeOne Pages and obtaining a publicly accessible URL.\n- **[Edwin](https://github.com/edwin-finance/edwin/tree/main/examples/mcp-server)** - MCP server for edwin SDK - enabling AI agents to interact with DeFi protocols across EVM, Solana and other blockchains.\n- **[eechat](https://github.com/Lucassssss/eechat)** - An open-source, cross-platform desktop application that seamlessly connects with MCP servers, across Linux, macOS, and Windows.\n- **[Elasticsearch](https://github.com/cr7258/elasticsearch-mcp-server)** - MCP server implementation that provides Elasticsearch interaction.\n- **[ElevenLabs](https://github.com/mamertofabian/elevenlabs-mcp-server)** - A server that integrates with ElevenLabs text-to-speech API capable of generating full voiceovers with multiple voices.\n- **[Email](https://github.com/Shy2593666979/mcp-server-email)** - This server enables users to send emails through various email providers, including Gmail, Outlook, Yahoo, Sina, Sohu, 126, 163, and QQ Mail. It also supports attaching files from specified directories, making it easy to upload attachments along with the email content.\n- **[Email SMTP](https://github.com/egyptianego17/email-mcp-server)** - A simple MCP server that lets your AI agent send emails and attach files through SMTP.\n- **[Enhance Prompt](https://github.com/FelixFoster/mcp-enhance-prompt)** - An MCP service for enhance you prompt.\n- **[Entrez](https://github.com/QuentinCody/entrez-mcp-server)** - Unofficial MCP server for NCBI Entrez databases, providing access to PubMed articles, gene information, protein data, and other biomedical research resources through NCBI's E-utilities API.\n- **[Ergo Blockchain MCP](https://github.com/marctheshark3/ergo-mcp)** -An MCP server to integrate Ergo Blockchain Node and Explorer APIs for checking address balances, analyzing transactions, viewing transaction history, performing forensic analysis of addresses, searching for tokens, and monitoring network status.\n- **[ESP MCP Server](https://github.com/horw/esp-mcp)** - An MCP server that integrates ESP IDF commands like building and flashing code for ESP Microcontrollers using an LLM.\n- **[Eunomia](https://github.com/whataboutyou-ai/eunomia-MCP-server)** - Extension of the Eunomia framework that connects Eunomia instruments with MCP servers\n- **[Everything Search](https://github.com/mamertofabian/mcp-everything-search)** - Fast file searching capabilities across Windows (using [Everything SDK](https://www.voidtools.com/support/everything/sdk/)), macOS (using mdfind command), and Linux (using locate/plocate command).\n- **[EVM MCP Server](https://github.com/mcpdotdirect/evm-mcp-server)** - Comprehensive blockchain services for 30+ EVM networks, supporting native tokens, ERC20, NFTs, smart contracts, transactions, and ENS resolution.\n- **[Excel](https://github.com/haris-musa/excel-mcp-server)** - Excel manipulation including data reading/writing, worksheet management, formatting, charts, and pivot table.\n- **[Excel to JSON MCP by WTSolutions](https://github.com/he-yang/excel-to-json-mcp)** - MCP Server providing a standardized interface for converting (1) Excel or CSV data into JSON format ;(2) Excel(.xlsx) file into Structured JSON.\n- **[Extended Memory](https://github.com/ssmirnovpro/extended-memory-mcp)** - Persistent memory across Claude conversations with multi-project support, automatic importance scoring, and tag-based organization. Production-ready with 400+ tests.\n- **[F1](https://github.com/AbhiJ2706/f1-mcp/tree/main)** - Access to Formula 1 data including race results, driver information, lap times, telemetry, and circuit details.\n- **[Fabric MCP](https://github.com/aci-labs/ms-fabric-mcp)** - Microsoft Fabric MCP server to accelerate working in your Fabric Tenant with the help of your favorite LLM models.\n- **[Fabric Real-Time Intelligence MCP](https://github.com/Microsoft/fabric-rti-mcp)** - Official Microsoft Fabric RTI server to accelerate working with Eventhouse, Azure Data Explorer(Kusto), Eventstreams and other RTI items using your favorite LLM models.\n- **[fabric-mcp-server](https://github.com/adapoet/fabric-mcp-server)** - The fabric-mcp-server is an MCP server that integrates [Fabric](https://github.com/danielmiessler/fabric) patterns with [Cline](https://cline.bot/), exposing them as tools for AI-driven task execution and enhancing Cline's capabilities.\n- **[Fal MCP Server](https://github.com/raveenb/fal-mcp-server)** - Generate AI images, videos, and music using Fal.ai models (FLUX, Stable Diffusion, MusicGen) directly in Claude\n- **[Facebook Ads](https://github.com/gomarble-ai/facebook-ads-mcp-server)** - MCP server acting as an interface to the Facebook Ads, enabling programmatic access to Facebook Ads data and management features.\n- **[Facebook Ads 10xeR](https://github.com/fortytwode/10xer)** - Advanced Facebook Ads MCP server with enhanced creative insights, multi-dimensional breakdowns, and comprehensive ad performance analytics.\n- **[Facebook Ads Library](https://github.com/trypeggy/facebook-ads-library-mcp)** - Get any answer from the Facebook Ads Library, conduct deep research including messaging, creative testing and comparisons in seconds.\n- **[Fantasy PL](https://github.com/rishijatia/fantasy-pl-mcp)** - Give your coding agent direct access to up-to date Fantasy Premier League data\n- **[Fastmail MCP](https://github.com/MadLlama25/fastmail-mcp)** - Access Fastmail via JMAP: list/search emails, send and move mail, handle attachments/threads, plus contacts and calendar tools.\n- **[fastn.ai – Unified API MCP Server](https://github.com/fastnai/mcp-fastn)** - A remote, dynamic MCP server with a unified API that connects to 1,000+ tools, actions, and workflows, featuring built-in authentication and monitoring.\n- **[FDIC BankFind MCP Server - (Unofficial)](https://github.com/clafollett/fdic-bank-find-mcp-server)** - The is a MCPserver that brings the power of FDIC BankFind APIs straight to your AI tools and workflows. Structured U.S. banking data, delivered with maximum vibes. 😎📊\n- **[FPE Demo MCP](https://github.com/Horizon-Digital-Engineering/fpe-demo-mcp)** - FF3 Format Preserving Encryption with authentication patterns for secure data protection in LLM workflows.\n- **[Federal Reserve Economic Data (FRED)](https://github.com/stefanoamorelli/fred-mcp-server)** (by Stefano Amorelli) - Community developed MCP server to interact with the Federal Reserve Economic Data.\n- **[Fetch](https://github.com/zcaceres/fetch-mcp)** - A server that flexibly fetches HTML, JSON, Markdown, or plaintext.\n- **[Feyod](https://github.com/jeroenvdmeer/feyod-mcp)** - A server that answers questions about football matches, and specialised in the football club Feyenoord.\n- **[Fast Filesystem](https://github.com/efforthye/fast-filesystem-mcp)** - Advanced filesystem operations with large file handling capabilities and Claude-optimized features. Provides fast file reading/writing, sequential reading for large files, directory operations, file search, and streaming writes with backup & recovery.\n- **[FHIR](https://github.com/wso2/fhir-mcp-server)** - A Model Context Protocol server that provides seamless, standardized access to Fast Healthcare Interoperability Resources (FHIR) data from any compatible FHIR server. Designed for easy integration with AI tools, developer workflows, and healthcare applications, it enables natural language and programmatic search, retrieval, and analysis of clinical data.\n- **[Fibaro HC3](https://github.com/coding-sailor/mcp-server-hc3)** - MCP server for Fibaro Home Center 3 smart home systems.\n- **[Figma](https://github.com/GLips/Figma-Context-MCP)** - Give your coding agent direct access to Figma file data, helping it one-shot design implementation.\n- **[Figma](https://github.com/paulvandermeijs/figma-mcp)** - A blazingly fast MCP server to read and export your Figma design files.\n- **[Figma to Flutter](https://github.com/mhmzdev/figma-flutter-mcp)** - Write down clean and better Flutter code from Figma design tokens and enrich nodes data in Flutter terminology.\n- **[Files](https://github.com/flesler/mcp-files)** - Enables agents to quickly find and edit code in a codebase with surgical precision. Find symbols, edit them everywhere.\n- **[FileSystem Server](https://github.com/Oncorporation/filesystem_server)** - Local MCP server for Visual Studio 2022 that provides code-workspace functionality by giving AI agents selective access to project folders and files\n- **[finmap.org](https://github.com/finmap-org/mcp-server)** MCP server provides comprehensive historical data from the US, UK, Russian and Turkish stock exchanges. Access sectors, tickers, company profiles, market cap, volume, value, and trade counts, as well as treemap and histogram visualizations.\n- **[Firebase](https://github.com/gannonh/firebase-mcp)** - Server to interact with Firebase services including Firebase Authentication, Firestore, and Firebase Storage.\n- **[Fish Audio](https://github.com/da-okazaki/mcp-fish-audio-server)** - Text-to-Speech integration with Fish Audio's API, supporting multiple voices, streaming, and real-time playback\n- **[FitBit MCP Server](https://github.com/NitayRabi/fitbit-mcp)** - An MCP server that connects to FitBit API using a token obtained from OAuth flow.\n- **[FlightRadar24](https://github.com/sunsetcoder/flightradar24-mcp-server)** - A Claude Desktop MCP server that helps you track flights in real-time using Flightradar24 data.\n- **[Fluent-MCP](https://github.com/modesty/fluent-mcp)** - MCP server for Fluent (ServiceNow SDK) providing access to ServiceNow SDK CLI, API specifications, code snippets, and more.\n- **[Flyworks Avatar](https://github.com/Flyworks-AI/flyworks-mcp)** - Fast and free zeroshot lipsync MCP server.\n- **[fmp-mcp-server](https://github.com/vipbat/fmp-mcp-server)** - Enable your agent for M&A analysis and investment banking workflows. Access company profiles, financial statements, ratios, and perform sector analysis with the [Financial Modeling Prep APIs]\n- **[FoundationModels](https://github.com/phimage/mcp-foundation-models)** - An MCP server that integrates Apple's [FoundationModels](https://developer.apple.com/documentation/foundationmodels) for text generation.\n- **[Foursquare](https://github.com/foursquare/foursquare-places-mcp)** - Enable your agent to recommend places around the world with the [Foursquare Places API](https://location.foursquare.com/products/places-api/)\n- **[FrankfurterMCP](https://github.com/anirbanbasu/frankfurtermcp)** - MCP server acting as an interface to the [Frankfurter API](https://frankfurter.dev/) for currency exchange data.\n- **[freqtrade-mcp](https://github.com/kukapay/freqtrade-mcp)** - An MCP server that integrates with the Freqtrade cryptocurrency trading bot.\n- **[Geolocation](https://github.com/jackyang25/geolocation-mcp-server)** - WalkScore API integration for walkability, transit, and bike scores.\n- **[GDB](https://github.com/pansila/mcp_server_gdb)** - A GDB/MI protocol server based on the MCP protocol, providing remote application debugging capabilities with AI assistants.\n- **[ggRMCP](https://github.com/aalobaidi/ggRMCP)** - A Go gateway that converts gRPC services into MCP-compatible tools, allowing AI models like Claude to directly call your gRPC services.\n- **[Gemini Bridge](https://github.com/eLyiN/gemini-bridge)** - Lightweight MCP server that enables Claude to interact with Google's Gemini AI through the official CLI, offering zero API costs and stateless architecture.\n- **[Ghost](https://github.com/MFYDev/ghost-mcp)** - A Model Context Protocol (MCP) server for interacting with Ghost CMS through LLM interfaces like Claude.\n- **[Git](https://github.com/geropl/git-mcp-go)** - Allows LLM to interact with a local git repository, incl. optional push support.\n- **[Git Mob](https://github.com/Mubashwer/git-mob-mcp-server)** - MCP server that interfaces with the [git-mob](https://github.com/Mubashwer/git-mob) CLI app for managing co-authors in git commits during pair/mob programming.\n- **[Github](https://github.com/0xshariq/github-mcp-server)** - A Model Context Protocol (MCP) server that provides 29 Git operations + 11 workflow combinations for AI assistants and developers. This server exposes comprehensive Git repository management through a standardized interface, enabling AI models and developers to safely manage complex version control workflows.\n- **[GitHub Actions](https://github.com/ko1ynnky/github-actions-mcp-server)** - A Model Context Protocol (MCP) server for interacting with GitHub Actions.\n- **[GitHub Enterprise MCP](https://github.com/ddukbg/github-enterprise-mcp)** - A Model Context Protocol (MCP) server for interacting with GitHub Enterprise.\n- **[GitHub GraphQL](https://github.com/QuentinCody/github-graphql-mcp-server)** - Unofficial GitHub MCP server that provides access to GitHub's GraphQL API, enabling more powerful and flexible queries for repository data, issues, pull requests, and other GitHub resources.\n- **[GitHub Projects](https://github.com/redducklabs/github-projects-mcp)** — Manage GitHub Projects with full GraphQL API access including items, fields, and milestones.\n- **[GitHub Repos Manager MCP Server](https://github.com/kurdin/github-repos-manager-mcp)** - Token-based GitHub automation management. No Docker, Flexible configuration, 80+ tools with direct API integration.\n- **[GitMCP](https://github.com/idosal/git-mcp)** - gitmcp.io is a generic remote MCP server to connect to ANY GitHub repository or project documentation effortlessly\n- **[Glean](https://github.com/longyi1207/glean-mcp-server)** - A server that uses Glean API to search and chat.\n- **[Gmail](https://github.com/GongRzhe/Gmail-MCP-Server)** - A Model Context Protocol (MCP) server for Gmail integration in Claude Desktop with auto authentication support.\n- **[Gmail](https://github.com/Ayush-k-Shukla/gmail-mcp-server)** - A Simple MCP server for Gmail with support for all basic operations with oauth2.0.\n- **[Gmail Headless](https://github.com/baryhuang/mcp-headless-gmail)** - Remote hostable MCP server that can get and send Gmail messages without local credential or file system setup.\n- **[Gmail MCP](https://github.com/gangradeamitesh/mcp-google-email)** - A Gmail service implementation using MCP (Model Context Protocol) that provides functionality for sending, receiving, and managing emails through Gmail's API.\n- **[Gnuradio](https://github.com/yoelbassin/gnuradioMCP)** - An MCP server for GNU Radio that enables LLMs to autonomously create and modify RF .grc flowcharts.\n- **[Goal Story](https://github.com/hichana/goalstory-mcp)** - a Goal Tracker and Visualization Tool for personal and professional development.\n- **[GOAT](https://github.com/goat-sdk/goat/tree/main/typescript/examples/by-framework/model-context-protocol)** - Run more than +200 onchain actions on any blockchain including Ethereum, Solana and Base.\n- **[Godot](https://github.com/Coding-Solo/godot-mcp)** - An MCP server providing comprehensive Godot engine integration for project editing, debugging, and scene management.\n- **[Golang Filesystem Server](https://github.com/mark3labs/mcp-filesystem-server)** - Secure file operations with configurable access controls built with Go!\n- **[Goodnews](https://github.com/VectorInstitute/mcp-goodnews)** - A simple MCP server that delivers curated positive and uplifting news stories.\n- **[Gopher MCP](https://github.com/cameronrye/gopher-mcp)** - Modern, cross-platform MCP server that enables AI assistants to browse and interact with both Gopher protocol and Gemini protocol resources safely and efficiently.\n- **[Google Ads](https://github.com/gomarble-ai/google-ads-mcp-server)** - MCP server acting as an interface to the Google Ads, enabling programmatic access to Facebook Ads data and management features.\n- **[Google Analytics](https://github.com/surendranb/google-analytics-mcp)** - Google Analytics MCP Server to bring data across 200+ dimensions & metrics for LLMs to analyse.\n- **[Google Calendar](https://github.com/v-3/google-calendar)** - Integration with Google Calendar to check schedules, find time, and add/delete events\n- **[Google Calendar](https://github.com/nspady/google-calendar-mcp)** - Google Calendar MCP Server for managing Google calendar events. Also supports searching for events by attributes like title and location.\n- **[Google Custom Search](https://github.com/adenot/mcp-google-search)** - Provides Google Search results via the Google Custom Search API\n- **[Google Maps](https://github.com/Mastan1301/google_maps_mcp)** - Provides location results using Google Places API.\n- **[Google Sheets](https://github.com/xing5/mcp-google-sheets)** - Access and editing data to your Google Sheets.\n- **[Google Sheets](https://github.com/rohans2/mcp-google-sheets)** - An MCP Server written in TypeScript to access and edit data in your Google Sheets.\n- **[Google Tasks](https://github.com/zcaceres/gtasks-mcp)** - Google Tasks API Model Context Protocol Server.\n- **[Google Vertex AI Search](https://github.com/ubie-oss/mcp-vertexai-search)** - Provides Google Vertex AI Search results by grounding a Gemini model with your own private data\n- **[Google Workspace](https://github.com/taylorwilsdon/google_workspace_mcp)** - Comprehensive Google Workspace MCP with full support for Calendar, Drive, Gmail, and Docs using Streamable HTTP or SSE transport.\n- **[Google-Scholar](https://github.com/JackKuo666/Google-Scholar-MCP-Server)** - Enable AI assistants to search and access Google Scholar papers through a simple MCP interface.\n- **[Google-Scholar](https://github.com/mochow13/google-scholar-mcp)** - An MCP server for Google Scholar written in TypeScript with Streamable HTTP transport, along with a `client` implementations that integrates with the server and interacts with `gemini-2.5-flash`.\n- **[gx-mcp-server](https://github.com/davidf9999/gx-mcp-server)** - Expose Great Expectations data validation and quality checks as MCP tools for AI agents.\n- **[Gralio SaaS Database](https://github.com/tymonTe/gralio-mcp)** - Find and compare SaaS products, including data from G2 reviews, Trustpilot, Crunchbase, Linkedin, pricing, features and more, using [Gralio MCP](https://gralio.ai/mcp) server\n- **[GraphQL](https://github.com/drestrepom/mcp_graphql)** - Comprehensive GraphQL API integration that automatically exposes each GraphQL query as a separate tool.\n- **[GraphQL Schema](https://github.com/hannesj/mcp-graphql-schema)** - Allow LLMs to explore large GraphQL schemas without bloating the context.\n- **[HackMD](https://github.com/yuna0x0/hackmd-mcp)** (by yuna0x0) - An MCP server for HackMD, a collaborative markdown editor. It allows users to create, read, and update documents in HackMD using the Model Context Protocol.\n- **[HAProxy](https://github.com/tuannvm/haproxy-mcp-server)** - A Model Context Protocol (MCP) server for HAProxy implemented in Go, leveraging HAProxy Runtime API.\n- **[Hashing MCP Server](https://github.com/kanad13/MCP-Server-for-Hashing)** - MCP Server with cryptographic hashing functions e.g. SHA256, MD5, etc.\n- **[HDW LinkedIn](https://github.com/horizondatawave/hdw-mcp-server)** - Access to profile data and management of user account with [HorizonDataWave.ai](https://horizondatawave.ai/).\n- **[HeatPump](https://github.com/jiweiqi/heatpump-mcp-server)** — Residential heat - pump sizing & cost-estimation tools by **HeatPumpHQ**.\n- **[Helm Chart CLI](https://github.com/jeff-nasseri/helm-chart-cli-mcp)** - Helm MCP provides a bridge between AI assistants and the Helm package manager for Kubernetes. It allows AI assistants to interact with Helm through natural language requests, executing commands like installing charts, managing repositories, and more.\n- **[Heurist Mesh Agent](https://github.com/heurist-network/heurist-mesh-mcp-server)** - Access specialized web3 AI agents for blockchain analysis, smart contract security, token metrics, and blockchain interactions through the [Heurist Mesh network](https://github.com/heurist-network/heurist-agent-framework/tree/main/mesh).\n- **[HLedger MCP](https://github.com/iiAtlas/hledger-mcp)** - Double entry plain text accounting, right in your LLM! This MCP enables comprehensive read, and (optional) write access to your local [HLedger](https://hledger.org/) accounting journals.\n- **[Holaspirit](https://github.com/syucream/holaspirit-mcp-server)** - Interact with [Holaspirit](https://www.holaspirit.com/).\n- **[Home Assistant](https://github.com/tevonsb/homeassistant-mcp)** - Interact with [Home Assistant](https://www.home-assistant.io/) including viewing and controlling lights, switches, sensors, and all other Home Assistant entities.\n- **[Home Assistant](https://github.com/voska/hass-mcp)** - Docker-ready MCP server for Home Assistant with entity management, domain summaries, automation support, and guided conversations. Includes pre-built container images for easy installation.\n- **[HubSpot](https://github.com/buryhuang/mcp-hubspot)** - HubSpot CRM integration for managing contacts and companies. Create and retrieve CRM data directly through Claude chat.\n- **[HuggingFace Spaces](https://github.com/evalstate/mcp-hfspace)** - Server for using HuggingFace Spaces, supporting Open Source Image, Audio, Text Models and more. Claude Desktop mode for easy integration.\n- **[Human-In-the-Loop](https://github.com/GongRzhe/Human-In-the-Loop-MCP-Server)** - A powerful MCP Server that enables AI assistants like Claude to interact with humans through intuitive GUI dialogs. This server bridges the gap between automated AI processes and human decision-making by providing real-time user input tools, choices, confirmations, and feedback mechanisms.\n- **[Human-use](https://github.com/RapidataAI/human-use)** - Instant human feedback through an MCP, have your AI interact with humans around the world. Powered by [Rapidata](https://www.rapidata.ai/)\n- **[Hyperledger Fabric Agent Suite](https://github.com/padmarajkore/hlf-fabric-agent)** - Modular toolkit for managing Fabric test networks and chaincode lifecycle via MCP tools.\n- **[Hyperliquid](https://github.com/mektigboy/server-hyperliquid)** - An MCP server implementation that integrates the Hyperliquid SDK for exchange data.\n- **[Hypertool](https://github.com/toolprint/hypertool-mcp)** – MCP that let's you create hot - swappable, \"persona toolsets\" from multiple MCP servers to reduce tool overload and improve tool execution.\n- **[hyprmcp](https://github.com/stefanoamorelli/hyprmcp)** (by Stefano Amorelli) - Lightweight MCP server for `hyprland`.\n- **[iFlytek SparkAgent Platform](https://github.com/iflytek/ifly-spark-agent-mcp)** - This is a simple example of using MCP Server to invoke the task chain of the  iFlytek SparkAgent Platform.\n- **[iFlytek Workflow](https://github.com/iflytek/ifly-workflow-mcp-server)** - Connect to iFlytek Workflow via the MCP server and run your own Agent.\n- **[IIIF](https://github.com/code4history/IIIF_MCP)** - Comprehensive IIIF (International Image Interoperability Framework) protocol support for searching, navigating, and manipulating digital collections from museums, libraries, and archives worldwide.\n- **[Image Generation](https://github.com/GongRzhe/Image-Generation-MCP-Server)** - This MCP server provides image generation capabilities using the Replicate Flux model.\n- **[ImageSorcery MCP](https://github.com/sunriseapps/imagesorcery-mcp)** - ComputerVision-based 🪄 sorcery of image recognition and editing tools for AI assistants.\n- **[IMAP MCP](https://github.com/dominik1001/imap-mcp)** - 📧 An IMAP Model Context Protocol (MCP) server to expose IMAP operations as tools for AI assistants.\n- **[iMCP](https://github.com/loopwork-ai/iMCP)** - A macOS app that provides an MCP server for your iMessage, Reminders, and other Apple services.\n- **[InfluxDB](https://github.com/idoru/influxdb-mcp-server)** - Run queries against InfluxDB OSS API v2.\n- **[Intelligent Image Generator](https://github.com/shinpr/mcp-image)** - Turn casual prompts into professional-quality images with AI enhancement\n- **[Inner Monologue MCP](https://github.com/abhinav-mangla/inner-monologue-mcp)** - A cognitive reasoning tool that enables LLMs to engage in private, structured self-reflection and multi-step reasoning before generating responses, improving response quality and problem-solving capabilities.\n- **[Inoyu](https://github.com/sergehuber/inoyu-mcp-unomi-server)** - Interact with an Apache Unomi CDP customer data platform to retrieve and update customer profiles\n- **[Instagram DM](https://github.com/trypeggy/instagram_dm_mcp)** - Send DMs on Instagram via your LLM\n- **[interactive-mcp](https://github.com/ttommyth/interactive-mcp)** - Enables interactive LLM workflows by adding local user prompts and chat capabilities directly into the MCP loop.\n- **[Intercom](https://github.com/raoulbia-ai/mcp-server-for-intercom)** - An MCP-compliant server for retrieving customer support tickets from Intercom. This tool enables AI assistants like Claude Desktop and Cline to access and analyze your Intercom support tickets.\n- **[iOS Simulator](https://github.com/InditexTech/mcp-server-simulator-ios-idb)** - A Model Context Protocol (MCP) server that enables LLMs to interact with iOS simulators (iPhone, iPad, etc.) through natural language commands.\n- **[ipybox](https://github.com/gradion-ai/ipybox)** - Python code execution sandbox based on IPython and Docker. Stateful code execution, file transfer between host and container, configurable network access. See [ipybox MCP server](https://gradion-ai.github.io/ipybox/mcp-server/) for details.\n- **[it-tools-mcp](https://github.com/wrenchpilot/it-tools-mcp)** - A Model Context Protocol server that recreates [CorentinTh it-tools](https://github.com/CorentinTh/it-tools) utilities for AI agents, enabling access to a wide range of developer tools (encoding, decoding, conversions, and more) via MCP.\n- **[itemit MCP](https://github.com/umin-ai/itemit-mcp)** - itemit is Asset Tracking MCP that manage the inventory, monitoring and location tracking that powers over +300 organizations.\n- **[iTerm MCP](https://github.com/ferrislucas/iterm-mcp)** - Integration with iTerm2 terminal emulator for macOS, enabling LLMs to execute and monitor terminal commands.\n- **[iTerm MCP Server](https://github.com/rishabkoul/iTerm-MCP-Server)** - A Model Context Protocol (MCP) server implementation for iTerm2 terminal integration. Able to manage multiple iTerm Sessions.\n- **[Java Decompiler](https://github.com/idachev/mcp-javadc)** - Decompile Java bytecode into readable source code from .class files, package names, or JAR archives using CFR decompiler\n- **[JavaFX](https://github.com/quarkiverse/quarkus-mcp-servers/tree/main/jfx)** - Make drawings using a JavaFX canvas\n- **[JDBC](https://github.com/quarkiverse/quarkus-mcp-servers/tree/main/jdbc)** - Connect to any JDBC-compatible database and query, insert, update, delete, and more. Supports MySQL, PostgreSQL, Oracle, SQL Server, SQLite and [more](https://github.com/quarkiverse/quarkus-mcp-servers/tree/main/jdbc#supported-jdbc-variants).\n- **[Jenkins](https://github.com/jasonkylelol/jenkins-mcp-server)** - This MCP server allow you to create Jenkins tasks.\n- **[JMeter](https://github.com/QAInsights/jmeter-mcp-server)** - Run load testing using Apache JMeter via MCP-compliant tools.\n- **[Job Searcher](https://github.com/0xDAEF0F/job-searchoor)** - A FastMCP server that provides tools for retrieving and filtering job listings based on time period, keywords, and remote work preferences.\n- **[jobswithgpt](https://github.com/jobswithgpt/mcp)** - Job search MCP using jobswithgpt which indexes 500K+ public job listings and refreshed continously.\n- **[joinly](https://github.com/joinly-ai/joinly)** - MCP server to interact with browser-based meeting platforms (Zoom, Teams, Google Meet). Enables AI agents to send bots to online meetings, gather live transcripts, speak text, and send messages in the meeting chat.\n- **[JSON](https://github.com/GongRzhe/JSON-MCP-Server)** - JSON handling and processing server with advanced query capabilities using JSONPath syntax and support for array, string, numeric, and date operations.\n- **[JSON](https://github.com/kehvinbehvin/json-mcp-filter)** - JSON schema generation and filtering server with TypeScript type creation optimised for retrieving relevant context JSON data using quicktype-core and support for shape-based data extraction, nested object filtering, and array processing operations.\n- **[JSON to Excel by WTSolutions](https://github.com/he-yang/json-to-excel-mcp)** - Converting JSON into CSV format string from (1) JSON data, (2) URLs pointing to publiclly available .json files.\n- **[JSON2Video MCP](https://github.com/omergocmen/json2video-mcp-server)** - A Model Context Protocol (MCP) server implementation for programmatically generating videos using the json2video API. This server exposes powerful video generation and status-checking tools for use with LLMs, agents, or any MCP-compatible client.\n- **[jupiter-mcp](https://github.com/kukapay/jupiter-mcp)** - An MCP server for executing token swaps on the Solana blockchain using Jupiter's new Ultra API.\n- **[Jupyter MCP Server](https://github.com/datalayer/jupyter-mcp-server)** – Real-time interaction with Jupyter Notebooks, allowing AI to edit, document and execute code for data analysis, visualization etc. Compatible with any Jupyter deployment (local, JupyterHub, ...).\n- **[Jupyter Notebook](https://github.com/jjsantos01/jupyter-notebook-mcp)** - connects Jupyter Notebook to Claude AI, allowing Claude to directly interact with and control Jupyter Notebooks. This integration enables AI-assisted code execution, data analysis, visualization, and more.\n- **[k8s-multicluster-mcp](https://github.com/razvanmacovei/k8s-multicluster-mcp)** - An MCP server for interact with multiple Kubernetes clusters simultaneously using multiple kubeconfig files.\n- **[Kafka](https://github.com/tuannvm/kafka-mcp-server)** - A Model Context Protocol (MCP) server for Apache Kafka implemented in Go, leveraging [franz-go](https://github.com/twmb/franz-go).\n- **[Kafka Schema Registry MCP](https://github.com/aywengo/kafka-schema-reg-mcp)** \\ - A comprehensive MCP server for Kafka Schema Registry with 48 tools, multi-registry support, authentication, and production safety features. Enables AI-powered schema management with enterprise-grade capabilities including schema contexts, migration tools, and comprehensive export capabilities.\n- **[kafka-mcp](https://github.com/shivamxtech/kafka-mcp)** - An MCP Server for Kafka clusters to interact with kafka environment via tools on messages, topics, offsets, partitions for consumer and producers along with seamless integration with MCP clients.\n- **[Keycloak](https://github.com/idoyudha/mcp-keycloak)** - The Keycloak MCP Server designed for agentic applications to manage and search data in Keycloak efficiently.\n- **[Keycloak MCP](https://github.com/ChristophEnglisch/keycloak-model-context-protocol)** - This MCP server enables natural language interaction with Keycloak for user and realm management including creating, deleting, and listing users and realms.\n- **[Keycloak MCP Server](https://github.com/sshaaf/keycloak-mcp-server)** - designed to work with Keycloak for identity and access management, with about 40+ tools covering, Users, Realms, Clients, Roles, Groups, IDPs, Authentication. Native builds available.\n- **[Kibana MCP](https://github.com/TocharianOU/mcp-server-kibana.git)** (by TocharianOU) - A community-maintained MCP server implementation that allows any MCP-compatible client to access and manage Kibana instances through natural language or programmatic requests.\n- **[Kibela](https://github.com/kiwamizamurai/mcp-kibela-server)** (by kiwamizamurai) - Interact with Kibela API.\n- **[KiCad MCP](https://github.com/lamaalrajih/kicad-mcp)** - MCP server for KiCad on Mac, Windows, and Linux.\n- **[kill-process-mcp](https://github.com/misiektoja/kill-process-mcp)** - List and terminate OS processes via natural language queries\n- **[Kindred Offers & Discounts MCP](https://github.com/kindred-app/mcp-server-kindred-offers)** (by kindred.co) - This MCP server allows you to get live deals and offers/coupons from e-commerce merchant sites all over the world.\n- **[kintone](https://github.com/macrat/mcp-server-kintone)** - Manage records and apps in [kintone](https://kintone.com) through LLM tools.\n- **[Kokoro TTS](https://github.com/mberg/kokoro-tts-mcp)** - Use Kokoro text to speech to convert text to MP3s with optional autoupload to S3.\n- **[Kong Konnect](https://github.com/Kong/mcp-konnect)** - A Model Context Protocol (MCP) server for interacting with Kong Konnect APIs, allowing AI assistants to query and analyze Kong Gateway configurations, traffic, and analytics.\n- **[Korea Stock Analyzer](https://github.com/Mrbaeksang/korea-stock-analyzer-mcp)** - Analyze Korean stocks (KOSPI/KOSDAQ) with 6 legendary investment strategies including Buffett, Lynch, Graham, Greenblatt, Fisher, and Templeton.\n- **[Kubernetes](https://github.com/Flux159/mcp-server-kubernetes)** - Connect to Kubernetes cluster and manage pods, deployments, and services.\n- **[Kubernetes and OpenShift](https://github.com/manusa/kubernetes-mcp-server)** - A powerful Kubernetes MCP server with additional support for OpenShift. Besides providing CRUD operations for any Kubernetes resource, this server provides specialized tools to interact with your cluster.\n- **[KubeSphere](https://github.com/kubesphere/ks-mcp-server)** - The KubeSphere MCP Server is a Model Context Protocol(MCP) server that provides integration with KubeSphere APIs, enabling to get resources from KubeSphere. Divided into four tools modules: Workspace Management, Cluster Management, User and Roles, Extensions Center.\n- **[Kukapay MCP Servers](https://github.com/kukapay/kukapay-mcp-servers)** - A comprehensive suite of Model Context Protocol (MCP) servers dedicated to cryptocurrency, blockchain, and Web3 data aggregation, analysis, and services from Kukapay.\n- **[kwrds.ai](https://github.com/mkotsollaris/kwrds_ai_mcp)** - Keyword research, people also ask, SERP and other SEO tools for [kwrds.ai](https://www.kwrds.ai/)\n- **[KYC-mcp-server](https://github.com/vishnurudra-ai/KYC-mcp-server)** - Know Your Computer (KYC) - MCP Server compatible with Claude Desktop. Comprehensive system diagnostics for Windows, Mac OS and Linux operating system with AI-powered recommendations.\n- **[Langflow-DOC-QA-SERVER](https://github.com/GongRzhe/Langflow-DOC-QA-SERVER)** - A Model Context Protocol server for document Q&A powered by Langflow. It demonstrates core MCP concepts by providing a simple interface to query documents through a Langflow backend.\n- **[Language Server](https://github.com/isaacphi/mcp-language-server)** - MCP Language Server helps MCP enabled clients navigate codebases more easily by giving them access to semantic tools like get definition, references, rename, and diagnostics.\n- **[Lark(Feishu)](https://github.com/kone-net/mcp_server_lark)** - A Model Context Protocol(MCP) server for Lark(Feishu) sheet, message, doc and etc.\n- **[Lazy Toggl MCP](https://github.com/movstox/lazy-toggl-mcp)** - Simple unofficial MCP server to track time via Toggl API\n- **[lean-lsp-mcp](https://github.com/oOo0oOo/lean-lsp-mcp)** - Interact with the [Lean theorem prover](https://lean-lang.org/) via the Language Server Protocol.\n- **[librenms-mcp](https://github.com/mhajder/librenms-mcp)** - MCP server for [LibreNMS](https://www.librenms.org/) management\n- **[libvirt-mcp](https://github.com/MatiasVara/libvirt-mcp)** - Allows LLM to interact with libvirt thus enabling to create, destroy or list the Virtual Machines in a system.\n- **[Lightdash](https://github.com/syucream/lightdash-mcp-server)** - Interact with [Lightdash](https://www.lightdash.com/), a BI tool.\n- **[LINE](https://github.com/amornpan/py-mcp-line)** (by amornpan) - Implementation for LINE Bot integration that enables Language Models to read and analyze LINE conversations through a standardized interface. Features asynchronous operation, comprehensive logging, webhook event handling, and support for various message types.\n- **[Linear](https://github.com/tacticlaunch/mcp-linear)** - Interact with Linear project management system.\n- **[Linear](https://github.com/jerhadf/linear-mcp-server)** - Allows LLM to interact with Linear's API for project management, including searching, creating, and updating issues.\n- **[Linear (Go)](https://github.com/geropl/linear-mcp-go)** - Allows LLM to interact with Linear's API via a single static binary.\n- **[Linear MCP](https://github.com/anoncam/linear-mcp)** - Full blown implementation of the Linear SDK to support comprehensive Linear management of projects, initiatives, issues, users, teams and states.\n- **[Linked API MCP](https://github.com/Linked-API/linkedapi-mcp)** - MCP server that lets AI assistants control LinkedIn accounts and retrieve real-time data.\n- **[Listmonk MCP Server](https://github.com/rhnvrm/listmonk-mcp)** (by rhnvrm) - Full API coverage of [Listmonk](https://github.com/knadh/listmonk) email marketing FOSS.\n- **[LlamaCloud](https://github.com/run-llama/mcp-server-llamacloud)** (by marcusschiesser) - Integrate the data stored in a managed index on [LlamaCloud](https://cloud.llamaindex.ai/)\n- **[lldb-mcp](https://github.com/stass/lldb-mcp)** - A Model Context Protocol server for LLDB that provides LLM-driven debugging.\n- **[llm-context](https://github.com/cyberchitta/llm-context.py)** - Provides a repo-packing MCP tool with configurable profiles that specify file inclusion/exclusion patterns and optional prompts.\n- **[Local History](https://github.com/xxczaki/local-history-mcp)** – MCP server for accessing VS Code/Cursor's Local History.\n- **[Locust](https://github.com/QAInsights/locust-mcp-server)** - Allows running and analyzing Locust tests using MCP compatible clients.\n- **[Loki](https://github.com/scottlepp/loki-mcp)** - Golang based MCP Server to query logs from [Grafana Loki](https://github.com/grafana/loki).\n- **[Loki MCP Server](https://github.com/mo-silent/loki-mcp-server)** - Python based MCP Server for querying and analyzing logs from Grafana Loki with advanced filtering and authentication support.\n- **[LottieFiles](https://github.com/junmer/mcp-server-lottiefiles)** - Searching and retrieving Lottie animations from [LottieFiles](https://lottiefiles.com/)\n- **[lsp-mcp](https://github.com/Tritlo/lsp-mcp)** - Interact with Language Servers usint the Language Server Protocol to provide additional context information via hover, code actions and completions.\n- **[Lspace](https://github.com/Lspace-io/lspace-server)** - Turn scattered ChatGPT/Claude/Cursor conversations into persistent, searchable knowledge.\n- **[lucene-mcp-server](https://github.com/VivekKumarNeu/MCP-Lucene-Server)** - spring boot server using Lucene for fast document search and management.\n- **[lucid-mcp-server](https://github.com/smartzan63/lucid-mcp-server)** – An MCP server for Lucidchart and Lucidspark: connect, search, and obtain text representations of your Lucid documents and diagrams via LLM - driven AI Vision analysis. [npm](https://www.npmjs.com/package/lucid-mcp-server)\n- **[LunarCrush Remote MCP](https://github.com/lunarcrush/mcp-server)** - Get the latest social metrics and posts for both current live social context as well as historical metrics in LLM and token optimized outputs. Ideal for automated trading / financial advisory.\n- **[mac-messages-mcp](https://github.com/carterlasalle/mac_messages_mcp)** - An MCP server that securely interfaces with your iMessage database via the Model Context Protocol (MCP), allowing LLMs to query and analyze iMessage conversations. It includes robust phone number validation, attachment processing, contact management, group chat handling, and full support for sending and receiving messages.\n- **[Maestro MCP](https://github.com/maestro-org/maestro-mcp)** - An MCP server for interacting with Bitcoin via the Maestro RPC API.\n- **[Magg: The MCP Aggregator](https://github.com/sitbon/magg)** - A meta-MCP server that acts as a universal hub, allowing LLMs to autonomously discover, install, and orchestrate multiple MCP servers - essentially giving AI assistants the power to extend their own capabilities on-demand. Includes `mbro`, a powerful CLI MCP server browser with scripting capability.\n- **[Mailchimp MCP](https://github.com/AgentX-ai/mailchimp-mcp)** - Allows AI agents to interact with the Mailchimp API (read-only)\n- **[MalwareBazaar_MCP](https://github.com/mytechnotalent/MalwareBazaar_MCP)** (by Kevin Thomas) - An AI-driven MCP server that autonomously interfaces with MalwareBazaar, delivering real-time threat intel and sample metadata for authorized cybersecurity research workflows.\n- **[Mandoline](https://github.com/mandoline-ai/mandoline-mcp-server)** - Enable AI assistants to reflect on, critique, and continuously improve their own performance using Mandoline's evaluation framework.\n- **[Matrix](https://github.com/mjknowles/matrix-mcp-server)** - Interact with a Matrix homeserver.\n- **[man-mcp-server](https://github.com/guyru/man-mcp-server)** - MCP to search and access man pages on the local machine.\n- **[MariaDB](https://github.com/abel9851/mcp-server-mariadb)** - MariaDB database integration with configurable access controls in Python.\n- **[Markdown2doc](https://github.com/Klavis-AI/klavis/tree/main/mcp_servers/pandoc)** - Convert between various file formats using Pandoc\n- **[Markdownify](https://github.com/zcaceres/mcp-markdownify-server)** - MCP to convert almost anything to Markdown (PPTX, HTML, PDF, Youtube Transcripts and more)\n- **[market-fiyati](https://github.com/mtcnbzks/market-fiyati-mcp-server)** - The MCP server for marketfiyati.org.tr, offering grocery price search and comparison across Turkish markets.)\n- **[Markitdown](https://github.com/Klavis-AI/klavis/tree/main/mcp_servers/markitdown)** - Convert files to Markdown\n- **[Masquerade](https://github.com/postralai/masquerade)** - Redact sensitive information from your PDF documents before sending them to Claude. Masquerade serves as a privacy firewall for LLMs.\n- **[MasterGo](https://github.com/mastergo-design/mastergo-magic-mcp)** - The server designed to connect MasterGo design tools with AI models. It enables AI models to directly retrieve DSL data from MasterGo design files.\n- **[Matlab-MCP-Tools](https://github.com/neuromechanist/matlab-mcp-tools)** - An MCP to write and execute MATLAB scripts, maintain workspace context between MCP calls, visualize plots, and perform section-by-section analysis of MATLAB code with full access to MATLAB's computational capabilities.\n- **[Maton](https://github.com/maton-ai/agent-toolkit/tree/main/modelcontextprotocol)** - Connect to your SaaS tools like HubSpot, Salesforce, and more.\n- **[Maven Tools MCP](https://github.com/arvindand/maven-tools-mcp)** - Maven Central dependency intelligence for JVM build tools. Supports all build tools (Maven, Gradle, SBT, Mill) with Context7 integration for documentation support.\n- **[MCP-Airflow-API](https://github.com/call518/MCP-Airflow-API)** - Model Context Protocol (MCP) server for Apache Airflow API integration. Provides comprehensive tools for managing Airflow clusters including service operations, configuration management, status monitoring, and request tracking.\n- **[mcpcap](https://github.com/mcpcap/mcpcap)** - A modular Python MCP (Model Context Protocol) Server for analyzing PCAP files.\n- **[MCP Compass](https://github.com/liuyoshio/mcp-compass)** - Suggest the right MCP server for your needs\n- **[MCP Create](https://github.com/tesla0225/mcp-create)** - A dynamic MCP server management service that creates, runs, and manages Model Context Protocol servers on-the-fly.\n- **[MCP Documentation Server](https://github.com/andrea9293/mcp-documentation-server)** - Server that provides local-first document management and semantic search via embeddings or Gemini AI (recommended). Optimized for performance with disk persistence, an in-memory index, and caching.\n- **[MCP Installer](https://github.com/anaisbetts/mcp-installer)** - This server is a server that installs other MCP servers for you.\n- **[MCP ProjectManage OpenProject](https://github.com/boma086/mcp-projectmanage-openproject)** - This server provides the MCP service for project weekly reports, with project management information supplied by OpenProject.\n- **[MCP Proxy Server](https://github.com/TBXark/mcp-proxy)** - An MCP proxy server that aggregates and serves multiple MCP resource servers through a single HTTP server.\n- **[MCP Server Creator](https://github.com/GongRzhe/MCP-Server-Creator)** - A powerful Model Context Protocol (MCP) server that creates other MCP servers! This meta-server provides tools for dynamically generating FastMCP server configurations and Python code.\n- **[MCP Server Generator](https://github.com/SerhatUzbas/mcp-server-generator)** - An MCP server that creates and manages  MCP servers! Helps both non-technical users and developers build custom JavaScript MCP servers with AI guidance, automatic dependency management, and Claude Desktop integration.\n- **[MCP STDIO to Streamable HTTP Adapter](https://github.com/pyroprompts/mcp-stdio-to-streamable-http-adapter)** - Connect to Streamable HTTP MCP Servers even if the MCP Client only supports STDIO.\n- **[MCP-Ambari-API](https://github.com/call518/MCP-Ambari-API)** - Model Context Protocol (MCP) server for Apache Ambari API integration. This project provides tools for managing Hadoop clusters, including service operations, configuration management, status monitoring, and request tracking.\n- **[MCP-OpenStack-Ops](https://github.com/call518/MCP-OpenStack-Ops)** - Professional OpenStack operations automation via MCP server. Specialized tools for cluster monitoring, instance management, volume control & network analysis. FastMCP + OpenStack SDK + Bearer auth. Claude Desktop ready. Perfect for DevOps & cloud automation.\n- **[MCP-PostgreSQL-Ops](https://github.com/call518/MCP-PostgreSQL-Ops)** - Model Context Protocol (MCP) server for Apache Ambari API integration. This project provides tools for managing Hadoop clusters, including service operations, configuration management, status monitoring, and request tracking.\n- **[mcp-containerd](https://github.com/jokemanfire/mcp-containerd)** - The containerd MCP implemented by Rust supports the operation of the CRI interface.\n- **[MCP-Database-Server](https://github.com/executeautomation/mcp-database-server)** - Fastest way to interact with your Database such as SQL Server, SQLite and PostgreSQL\n- **[mcp-grep](https://github.com/erniebrodeur/mcp-grep)** - Python-based MCP server that brings grep functionality to LLMs. Supports common grep features including pattern searching, case-insensitive matching, context lines, and recursive directory searches.\n- **[mcp-k8s-go](https://github.com/strowk/mcp-k8s-go)** - Golang-based Kubernetes server for MCP to browse pods and their logs, events, namespaces and more. Built to be extensible.\n- **[mcp-local-rag](https://github.com/nkapila6/mcp-local-rag)** - \"primitive\" RAG-like web search model context protocol (MCP) server that runs locally using Google's MediaPipe Text Embedder and DuckDuckGo Search.\n- **[mcp-mcp](https://github.com/wojtyniak/mcp-mcp)** - Meta-MCP Server that acts as a tool discovery service for MCP clients.\n- **[mcp-meme-sticky](https://github.com/nkapila6/mcp-meme-sticky)** - Make memes or stickers using MCP server for WhatsApp or Telegram.\n- **[mcp-memory-service](https://github.com/doobidoo/mcp-memory-service)** - Universal MCP memory service providing semantic memory search, persistent storage, and autonomous memory consolidation for AI assistants across 13+ AI applications.\n- **[MCP-NixOS](https://github.com/utensils/mcp-nixos)** - A Model Context Protocol server that provides AI assistants with accurate, real-time information about NixOS packages, system options, Home Manager settings, and nix-darwin macOS configurations.\n- **[mcp-open-library](https://github.com/8enSmith/mcp-open-library)** - A Model Context Protocol (MCP) server for the Open Library API that enables AI assistants to search for book and author information.\n- **[mcp-proxy](https://github.com/sparfenyuk/mcp-proxy)** - Connect to MCP servers that run on SSE transport, or expose stdio servers as an SSE server.\n- **[mcp-read-website-fast](https://github.com/just-every/mcp-read-website-fast)** - Fast, token-efficient web content extraction that converts websites to clean Markdown. Features Mozilla Readability, smart caching, polite crawling with robots.txt support, and concurrent fetching with minimal dependencies.\n- **[mcp-salesforce](https://github.com/lciesielski/mcp-salesforce-example)** - MCP server with basic demonstration of interactions with your Salesforce instance\n- **[mcp-sanctions](https://github.com/madupay/mcp-sanctions)** - Screen individuals and organizations against global sanctions lists (OFAC, SDN, UN, etc). Query by prompt or document upload.\n- **[mcp-screenshot-website-fast](https://github.com/just-every/mcp-screenshot-website-fast)** - High-quality screenshot capture optimized for Claude Vision API. Automatically tiles full pages into 1072x1072 chunks (1.15 megapixels) with configurable viewports and wait strategies for dynamic content.\n- **[mcp-server-leetcode](https://github.com/doggybee/mcp-server-leetcode)** - Practice and retrieve problems from LeetCode. Automate problem retrieval, solutions, and insights for coding practice and competitions.\n- **[Mcp-Swagger-Server](https://github.com/zaizaizhao/mcp-swagger-server)** (by zaizaizhao) - This MCP server transforms OpenAPI specifications into MCP tools, enabling AI assistants to interact with REST APIs through standardized protocol\n- **[MCP Dynamic Tool Groups](https://github.com/ECF/MCPToolGroups)** - Example MCP servers that use [annotated](https://github.com/spring-ai-community/mcp-annotations) Java interfaces/classes as 'tool groups'.  Using standard MCP annotations, service implementations can then, at runtime, be used to generate tool specifications, and then dynamically added or removed from MCP servers.   The functionality is demonstrated in a sample tool group, but can be similarly used for any API or service.\n- **[mcp-vision](https://github.com/groundlight/mcp-vision)** - An MCP server exposing HuggingFace computer vision models such as zero-shot object detection as tools, enhancing the vision capabilities of large language or vision-language models.\n- **[mcp-weather](https://github.com/TimLukaHorstmann/mcp-weather)** - Accurate weather forecasts via the AccuWeather API (free tier available).\n- **[KnowAir Weather MCP](https://github.com/shuowang-ai/Weather-MCP)** - A comprehensive Model Context Protocol (MCP) server providing real-time weather data, air quality monitoring, forecasts, and astronomical information powered by Caiyun Weather API.\n- **[mcp-youtube-extract](https://github.com/sinjab/mcp_youtube_extract)** - A Model Context Protocol server for YouTube operations, extracting video information and transcripts with intelligent fallback logic. Features comprehensive logging, error handling, and support for both auto-generated and manual transcripts.\n- **[mcp_weather](https://github.com/isdaniel/mcp_weather_server)** - Get weather information from https://api.open-meteo.com API.\n- **[MCPfinder](https://github.com/mcpfinder/server)** - The AI Agent's \"App Store\": Discover, install, and monetize AI capabilities — all within the MCP ecosystem.\n- **[MCPIgnore Filesytem](https://github.com/CyberhavenInc/filesystem-mcpignore)** - A Data Security First filesystem MCP server that implements .mcpignore to prevent MCP clients from accessing sensitive data.\n- **[MCPJungle](https://github.com/mcpjungle/MCPJungle)** - Self-hosted MCP Registry and Gateway for enterprise AI Agents\n- **[Md2doc](https://github.com/Yorick-Ryu/md2doc-mcp)** - Convert Markdown text to DOCX format using an external conversion service\n- **[MeasureSpace MCP](https://github.com/MeasureSpace/measure-space-mcp-server)** - A free [Model Context Protocol (MCP) Server](https://smithery.ai/server/@MeasureSpace/measure-space-mcp-server) that provides global weather, climate, air quality forecast and geocoding services by [measurespace.io](https://measurespace.io).\n- **[MediaWiki](https://github.com/ProfessionalWiki/MediaWiki-MCP-Server)** - A Model Context Protocol (MCP) Server that interacts with any MediaWiki wiki\n- **[MediaWiki MCP adapter](https://github.com/lucamauri/MediaWiki-MCP-adapter)** - A custom Model Context Protocol adapter for MediaWiki and WikiBase APIs\n- **[medRxiv](https://github.com/JackKuo666/medRxiv-MCP-Server)** - Enable AI assistants to search and access medRxiv papers through a simple MCP interface.\n- **[mem0-mcp](https://github.com/mem0ai/mem0-mcp)** - A Model Context Protocol server for Mem0, which helps with managing coding preferences.\n- **[Membase](https://github.com/unibaseio/membase-mcp)** - Save and query your agent memory in distributed way by Membase.\n- **[Meme MCP](https://github.com/lidorshimoni/meme-mcp)** - Generate memes via AI using the Imgflip API through the Model Context Protocol.\n- **[memento-mcp](https://github.com/gannonh/memento-mcp)** - Knowledge graph memory system built on Neo4j with semantic search, temporal awareness.\n- **[Meta Ads Remote MCP](https://github.com/pipeboard-co/meta-ads-mcp)** - Remote MCP server to interact with Meta Ads API - access, analyze, and manage Facebook, Instagram, and other Meta platforms advertising campaigns.\n- **[MetaTrader MCP](https://github.com/ariadng/metatrader-mcp-server)** - Enable AI LLMs to execute trades using MetaTrader 5 platform.\n- **[Metricool MCP](https://github.com/metricool/mcp-metricool)** - A Model Context Protocol server that integrates with Metricool's social media analytics platform to retrieve performance metrics and schedule content across networks like Instagram, Facebook, Twitter, LinkedIn, TikTok and YouTube.\n- **[Microsoft 365](https://github.com/merill/lokka)** - (by Merill) A Model Context Protocol (MCP) server for Microsoft 365. Includes support for all services including Teams, SharePoint, Exchange, OneDrive, Entra, Intune and more. See [Lokka](https://lokka.dev/) for more details.\n- **[Microsoft 365](https://github.com/softeria/ms-365-mcp-server)** - MCP server that connects to Microsoft Office and the whole Microsoft 365 suite using Graph API (including Outlook/mail, files, Excel, calendar)\n- **[Microsoft 365](https://github.com/pnp/cli-microsoft365-mcp-server)** - Single MCP server that allows to manage many different areas of Microsoft 365, for example: Entra ID, OneDrive, OneNote, Outlook, Planner, Power Apps, Power Automate, Power Platform, SharePoint Embedded, SharePoint Online, Teams, Viva Engage, and many more.\n- **[Microsoft 365 Files (SharePoint/OneDrive)](https://github.com/godwin3737/mcp-server-microsoft365-filesearch)** (by godwin3737) - MCP server with tools to search and get file content from Microsoft 365 including Onedrive and SharePoint. Works with Documents (pdf/docx), Presentations, Spreadsheets and Images.\n- **[Microsoft Teams](https://github.com/InditexTech/mcp-teams-server)** - MCP server that integrates Microsoft Teams messaging (read, post, mention, list members and threads)\n- **[Mifos X](https://github.com/openMF/mcp-mifosx)** - An MCP server for the Mifos X Open Source Banking useful for managing clients, loans, savings, shares, financial transactions and generating financial reports.\n- **[Mikrotik](https://github.com/jeff-nasseri/mikrotik-mcp)** - Mikrotik MCP server which cover networking operations (IP, DHCP, Firewall, etc)\n- **[Mindmap](https://github.com/YuChenSSR/mindmap-mcp-server)** (by YuChenSSR) - A server that generates mindmaps from input containing markdown code.\n- **[Minima](https://github.com/dmayboroda/minima)** - MCP server for RAG on local files\n- **[Modao Proto MCP](https://github.com/modao-dev/modao-proto-mcp)** - AI-powered HTML prototype generation server that converts natural language descriptions into complete HTML code with modern design and responsive layouts. Supports design description expansion and seamless integration with Modao workspace.\n- **[Mobile MCP](https://github.com/mobile-next/mobile-mcp)** (by Mobile Next) - MCP server for Mobile(iOS/Android) automation, app scraping and development using physical devices or simulators/emulators.\n- **[Monday.com (unofficial)](https://github.com/sakce/mcp-server-monday)** - MCP Server to interact with Monday.com boards and items.\n- **[MongoDB](https://github.com/kiliczsh/mcp-mongo-server)** - A Model Context Protocol Server for MongoDB.\n- **[MongoDB & Mongoose](https://github.com/nabid-pf/mongo-mongoose-mcp)** - MongoDB MCP Server with Mongoose Schema and Validation.\n- **[MongoDB Lens](https://github.com/furey/mongodb-lens)** - Full Featured MCP Server for MongoDB Databases.\n- **[Monzo](https://github.com/BfdCampos/monzo-mcp-bfdcampos)** - Access and manage your Monzo bank accounts through natural language, including balance checking, pot management, transaction listing, and transaction annotation across multiple account types (personal, joint, flex).\n- **[Morningstar](https://github.com/Morningstar/morningstar-mcp-server)** - MCP Server to interact with Morningstar Research, Editorial and Datapoints\n- **[MSSQL](https://github.com/aekanun2020/mcp-server/)** - MSSQL database integration with configurable access controls and schema inspection\n- **[MSSQL](https://github.com/JexinSam/mssql_mcp_server)** (by jexin) - MCP Server for MSSQL database in Python\n- **[MSSQL-MCP](https://github.com/daobataotie/mssql-mcp)** (by daobataotie) - MSSQL MCP that refer to the official website's SQLite MCP for modifications to adapt to MSSQL\n- **[MSSQL-MCP-Node](https://github.com/mihai-dulgheru/mssql-mcp-node)** (by mihai - dulgheru) – Node.js MCP server for Microsoft SQL Server featuring auto-detected single / multi-database configs, execute-SQL and schema tools, robust Zod validation, and optional Express endpoints for local testing\n- **[MSSQL-Python](https://github.com/amornpan/py-mcp-mssql)** (by amornpan) - A read-only Python implementation for MSSQL database access with enhanced security features, configurable access controls, and schema inspection capabilities. Focuses on safe database interaction through Python ecosystem.\n- **[Multi-Model Advisor](https://github.com/YuChenSSR/multi-ai-advisor-mcp)** - A Model Context Protocol (MCP) server that orchestrates queries across multiple Ollama models, synthesizing their insights to deliver a comprehensive and multifaceted AI perspective on any given query.\n- **[Multicluster-MCP-Sever](https://github.com/yanmxa/multicluster-mcp-server)** - The gateway for GenAI systems to interact with multiple Kubernetes clusters.\n- **[MySQL](https://github.com/benborla/mcp-server-mysql)** (by benborla) - MySQL database integration in NodeJS with configurable access controls and schema inspection\n- **[MySQL](https://github.com/designcomputer/mysql_mcp_server)** (by DesignComputer) - MySQL database integration in Python with configurable access controls and schema inspection\n- **[MySQL-Server](https://github.com/tonycai/mcp-mysql-server)** (by TonyCai) - MySQL Database Integration using Python script with configurable access controls and schema inspection, usng stdio mode to suitable local deployment, you can run it in docker container.\n- **[n8n](https://github.com/leonardsellem/n8n-mcp-server)** - This MCP server provides tools and resources for AI assistants to manage n8n workflows and executions, including listing, creating, updating, and deleting workflows, as well as monitoring their execution status.\n- **[Nacos MCP Router](https://github.com/nacos-group/nacos-mcp-router)** - This MCP(Model Context Protocol) Server provides tools to search, install, proxy other MCP servers.\n- **[NASA](https://github.com/ProgramComputer/NASA-MCP-server)** (by ProgramComputer) - Access to a unified gateway of NASA's data sources including but not limited to APOD, NEO, EPIC, GIBS.\n- **[NASA Image MCP Server](https://github.com/adithya1012/NASA-MCP-Server/blob/main/README.md)** - MCP server providing access to NASA's visual data APIs including Mars Rover photos, Earth satellite imagery (EPIC/GIBS), and Astronomy picture of the day. Features built-in image analysis tools with automatic format detection, compression, and base64 conversion for LLM integration.\n- **[Nasdaq Data Link](https://github.com/stefanoamorelli/nasdaq-data-link-mcp)** (by stefanoamorelli) - An MCP server to access, explore, and interact with Nasdaq Data Link's extensive and valuable financial and economic datasets.\n- **[National Parks](https://github.com/KyrieTangSheng/mcp-server-nationalparks)** - The server provides latest information of park details, alerts, visitor centers, campgrounds, hiking trails, and events for U.S. National Parks.\n- **[NAVER](https://github.com/pfldy2850/py-mcp-naver)** (by pfldy2850) - This MCP server provides tools to interact with various Naver services, such as searching blogs, news, books, and more.\n- **[Naver](https://github.com/isnow890/naver-search-mcp)** (by isnow890) - MCP server for Naver Search API integration, supporting blog, news, shopping search and DataLab analytics features.\n- **[NBA](https://github.com/Taidgh-Robinson/nba-mcp-server)** - This MCP server provides tools to fetch recent and historical NBA games including basic and advanced statistics.\n- **[NCI GDC](https://github.com/QuentinCody/nci-gdc-mcp-server)** - Unofficial MCP server for the National Cancer Institute's Genomic Data Commons (GDC), providing access to harmonized cancer genomic and clinical data for oncology research.\n- **[Neo4j](https://github.com/da-okazaki/mcp-neo4j-server)** - A community built server that interacts with Neo4j Graph Database.\n- **[Neovim](https://github.com/bigcodegen/mcp-neovim-server)** - An MCP Server for your Neovim session.\n- **[Netbird](https://github.com/aantti/mcp-netbird)** - List and analyze Netbird network peers, groups, policies, and more.\n- **[NetMind ParsePro](https://github.com/protagolabs/Netmind-Parse-PDF-MCP)** - The PDF Parser AI service, built and customized by the [NetMind](https://www.netmind.ai/) team.\n- **[Nikto MCP](https://github.com/weldpua2008/nikto-mcp)** (by weldpua2008) - A secure MCP server that enables AI agents to interact with Nikto web server scanner](- use with npx or docker).\n- **[NocoDB](https://github.com/edwinbernadus/nocodb-mcp-server)** - Read and write access to NocoDB database.\n- **[Node Code Sandbox](https://github.com/alfonsograziano/node-code-sandbox-mcp)** – A Node.js MCP server that spins up isolated Docker - based sandboxes for executing JavaScript snippets with on-the-fly npm dependency installation\n- **[nomad-mcp](https://github.com/kocierik/mcp-nomad)** - A server that provides a set of tools for managing Nomad clusters through the MCP.\n- **[Notion](https://github.com/suekou/mcp-notion-server)** (by suekou) - Interact with Notion API.\n- **[Notion](https://github.com/v-3/notion-server)** (by v-3) - Notion MCP integration. Search, Read, Update, and Create pages through Claude chat.\n- **[NPM Plus](https://github.com/shacharsol/js-package-manager-mcp)** - AI-powered JavaScript package management with security scanning, bundle analysis, and intelligent dependency management for MCP-compatible editors.\n- **[NS Travel Information](https://github.com/r-huijts/ns-mcp-server)** - Access Dutch Railways (NS) real-time train travel information and disruptions through the official NS API.\n- **[ntfy-mcp](https://github.com/teddyzxcv/ntfy-mcp)** (by teddyzxcv) - The MCP server that keeps you informed by sending the notification on phone using ntfy\n- **[ntfy-me-mcp](https://github.com/gitmotion/ntfy-me-mcp)** (by gitmotion) - An ntfy MCP server for sending/fetching ntfy notifications to your self-hosted ntfy server from AI Agents 📤 (supports secure token auth & more - use with npx or docker!)\n- **[oatpp-mcp](https://github.com/oatpp/oatpp-mcp)** - C++ MCP integration for Oat++. Use [Oat++](https://oatpp.io) to build MCP servers.\n- **[Obsidian Markdown Notes](https://github.com/calclavia/mcp-obsidian)** - Read and search through your Obsidian vault or any directory containing Markdown notes\n- **[obsidian-mcp](https://github.com/StevenStavrakis/obsidian-mcp)** - (by Steven Stavrakis) An MCP server for Obsidian.md with tools for searching, reading, writing, and organizing notes.\n- **[OceanBase](https://github.com/yuanoOo/oceanbase_mcp_server)** - (by yuanoOo) A Model Context Protocol (MCP) server that enables secure interaction with OceanBase databases.\n- **[Octocode](https://github.com/bgauryy/octocode-mcp)** - (by Guy Bary) AI-powered developer assistant that enables advanced code research, analysis and discovery across GitHub and NPM realms in realtime\n- **[Odoo](https://github.com/ivnvxd/mcp-server-odoo)** - Connect AI assistants to Odoo ERP systems for business data access and workflow automation.\n- **[Office-PowerPoint-MCP-Server](https://github.com/GongRzhe/Office-PowerPoint-MCP-Server)** - A Model Context Protocol (MCP) server for creating, reading, and manipulating Microsoft PowerPoint documents.\n- **[Office-Visio-MCP-Server](https://github.com/GongRzhe/Office-Visio-MCP-Server)** - A Model Context Protocol (MCP) server for creating, reading, and manipulating Microsoft Visio documents.\n- **[Office-Word-MCP-Server](https://github.com/GongRzhe/Office-Word-MCP-Server)** - A Model Context Protocol (MCP) server for creating, reading, and manipulating Microsoft Word documents.\n- **[Okta](https://github.com/kapilduraphe/okta-mcp-server)** - Interact with Okta API.\n- **[OKX-MCP-Server](https://github.com/memetus/okx-mcp-playground)** - An MCP server provides various blockchain data and market price data via the OKX API. The server enables Claude to perform operations like retrieve assets prices, transaction data, account history data and trade instruction data.\n- **[OneNote](https://github.com/rajvirtual/MCP-Servers/tree/master/onenote)** - (by Rajesh Vijay) An MCP server that connects to Microsoft OneNote using the Microsoft Graph API. Reading notebooks, sections, and pages from OneNote,Creating new notebooks, sections, and pages in OneNote.\n- **[Onyx MCP Sandbox](https://github.com/avd1729/Onyx)** – (by Aravind) A secure MCP server that executes code in isolated Docker sandboxes. Supports Python, Java, C, C++, JavaScript, and Rust. Provides the `run_code` tool, enforces CPU/memory limits, includes comprehensive tests, and detailed setup instructions.\n- **[Open Strategy Partners Marketing Tools](https://github.com/open-strategy-partners/osp_marketing_tools)** - Content editing codes, value map, and positioning tools for product marketing.\n- **[OpenAI WebSearch MCP](https://github.com/ConechoAI/openai-websearch-mcp)** - This is a Python-based MCP server that provides OpenAI `web_search` built-in tool.\n- **[OpenAlex.org MCP](https://github.com/drAbreu/alex-mcp)** - Professional MCP server providing ML-powered author disambiguation and comprehensive researcher profiles using the OpenAlex database.\n- **[OpenAPI](https://github.com/snaggle-ai/openapi-mcp-server)** - Interact with [OpenAPI](https://www.openapis.org/) APIs.\n- **[OpenAPI AnyApi](https://github.com/baryhuang/mcp-server-any-openapi)** - Interact with large [OpenAPI](https://www.openapis.org/) docs using built-in semantic search for endpoints. Allows for customizing the MCP server prefix.\n- **[OpenAPI Schema](https://github.com/hannesj/mcp-openapi-schema)** - Allow LLMs to explore large [OpenAPI](https://www.openapis.org/) schemas without bloating the context.\n- **[OpenAPI Schema Explorer](https://github.com/kadykov/mcp-openapi-schema-explorer)** - Token-efficient access to local or remote OpenAPI/Swagger specs via MCP Resources.\n- **[OpenCTI](https://github.com/Spathodea-Network/opencti-mcp)** - Interact with OpenCTI platform to retrieve threat intelligence data including reports, indicators, malware and threat actors.\n- **[OpenCV](https://github.com/GongRzhe/opencv-mcp-server)** - An MCP server providing OpenCV computer vision capabilities. This allows AI assistants and language models to access powerful computer vision tools.\n- **[OpenDota](https://github.com/asusevski/opendota-mcp-server)** - Interact with OpenDota API to retrieve Dota 2 match data, player statistics, and more.\n- **[OpenLink Generic Java Database Connectivity](https://github.com/OpenLinkSoftware/mcp-jdbc-server)** - Generic Database Management System (DBMS) access via Open Database Connectivity (ODBC) Connectors (Drivers)\n- **[OpenLink Generic Open Database Connectivity](https://github.com/OpenLinkSoftware/mcp-odbc-server)** - Generic Database Management System (DBMS) access via Open Database Connectivity (ODBC) Connectors (Drivers)\n- **[OpenLink Generic Python Open Database Connectivity](https://github.com/OpenLinkSoftware/mcp-pyodbc-server)** - Generic Database Management System (DBMS) access via Open Database Connectivity (ODBC) Connectors (Drivers) for PyODBC\n- **[OpenLink Generic SQLAlchemy Object-Relational Database Connectivity for PyODBC](https://github.com/OpenLinkSoftware/mcp-sqlalchemy-server)** - Generic Database Management System (DBMS) access via SQLAlchemy (PyODBC) Connectors (Drivers)\n- **[OpenMetadata](https://github.com/yangkyeongmo/mcp-server-openmetadata)** - MCP Server for OpenMetadata, an open-source metadata management platform.\n- **[OpenNeuro](https://github.com/QuentinCody/open-neuro-mcp-server)** - Unofficial MCP server for OpenNeuro, providing access to open neuroimaging datasets, study metadata, and brain imaging data for neuroscience research and analysis.\n- **[OpenReview](https://github.com/anyakors/openreview-mcp-server)** - An MCP server for [OpenReview](https://openreview.net/) to fetch, read and save manuscripts from AI/ML conferences.\n- **[OpenRPC](https://github.com/shanejonas/openrpc-mpc-server)** - Interact with and discover JSON-RPC APIs via [OpenRPC](https://open-rpc.org).\n- **[OpenStack](https://github.com/wangsqly0407/openstack-mcp-server)** - MCP server implementation that provides OpenStack interaction.\n- **[Open Targets](https://github.com/QuentinCody/open-targets-mcp-server)** - Unofficial MCP server for the Open Targets Platform, providing access to target-disease associations, drug discovery data, and therapeutic hypothesis generation for biomedical research.\n- **[OpenWeather](https://github.com/mschneider82/mcp-openweather)** - Interact with the free openweathermap API to get the current and forecast weather for a location.\n- **[OpenZIM MCP](https://github.com/cameronrye/openzim-mcp)** - Modern, secure, and high-performance MCP server that enables AI models to access and search ZIM format knowledge bases offline, including Wikipedia and educational content archives.\n- **[Operative WebEvalAgent](https://github.com/Operative-Sh/web-eval-agent)** (by [Operative.sh](https://www.operative.sh)) - An MCP server to test, debug, and fix web applications autonomously.\n- **[OPNSense MCP](https://github.com/vespo92/OPNSenseMCP)** - MCP Server for OPNSense Firewall Management and API access\n- **[OpenAI GPT Image](https://github.com/SureScaleAI/openai-gpt-image-mcp)** - OpenAI GPT image generation/editing MCP server.\n- **[Optimade MCP](https://github.com/dianfengxiaobo/optimade-mcp-server)** - An MCP server conducts real-time material science data queries with the Optimade database (for example, elemental composition, crystal structure).\n- **[Oracle](https://github.com/marcelo-ochoa/servers)** (by marcelo-ochoa) - Oracle Database integration in NodeJS with configurable access controls, query explain, stats and schema inspection\n- **[Oracle Cloud Infrastructure (OCI)](https://github.com/karthiksuku/oci-mcp)** (by karthiksukumar) - Python MCP server for OCI infrastructure (Compute, Autonomous Database, Object Storage). Read-heavy by default with safe instance actions (start/stop/reset). Includes Claude Desktop config and `.env` compartment scoping.\n- **[Oura MCP server](https://github.com/tomekkorbak/oura-mcp-server)** - MCP server for Oura API to retrieve one's sleep data\n- **[Oura Ring](https://github.com/rajvirtual/oura-mcp-server)** (by Rajesh Vijay) - MCP Server to access and analyze your Oura Ring data. It provides a structured way to fetch and understand your health metrics.\n- **[Outline](https://github.com/Vortiago/mcp-outline)** - MCP Server to interact with [Outline](https://www.getoutline.com) knowledge base to search, read, create, and manage documents and their content, access collections, add comments, and manage document backlinks.\n- **[Outlook Mail + Calendar + OneDrive](https://github.com/Norcim133/OutlookMCPServer) - Virtual assistant with Outlook Mail, Calendar, and early OneDrive support (requires Azure admin).\n- **[Pacman](https://github.com/oborchers/mcp-server-pacman)** - An MCP server that provides package index querying capabilities. This server is able to search and retrieve information from package repositories like PyPI, npm, crates.io, Docker Hub, and Terraform Registry.\n- **[pancakeswap-poolspy-mcp](https://github.com/kukapay/pancakeswap-poolspy-mcp)** - An MCP server that tracks newly created liquidity pools on Pancake Swap.\n- **[Pandoc](https://github.com/vivekVells/mcp-pandoc)** - MCP server for seamless document format conversion using Pandoc, supporting Markdown, HTML, PDF, DOCX (.docx), csv and more.\n- **[Paradex MCP](https://github.com/sv/mcp-paradex-py)** - MCP native server for interacting with Paradex platform, including fully features trading.\n- **[Parliament MCP]([https://github.com/sv/mcp-paradex-py](https://github.com/i-dot-ai/parliament-mcp))** - MCP server for querying UK parliamentary data.\n- **[PDF reader MCP](https://github.com/gpetraroli/mcp_pdf_reader)** - MCP server to read and search text in a local PDF file.\n- **[PDF Tools MCP](https://github.com/Sohaib-2/pdf-mcp-server)** - Comprehensive PDF manipulation toolkit (merge, split, encrypt, optimize and much more)\n- **[PDMT](https://github.com/paiml/pdmt)** - Pragmatic Deterministic MCP Templating - High-performance deterministic templating library with comprehensive todo validation, quality enforcement, and 0.0 temperature generation for reproducible outputs.\n- **[Peacock for VS Code](https://github.com/johnpapa/peacock-mcp)** - MCP Server for the Peacock extension for VS Code, coloring your world, one Code editor at a time. The main goal of the project is to show how an MCP server can be used to interact with APIs.\n- **[persistproc](https://github.com/irskep/persistproc)** - MCP server + command line tool that allows agents to see & control long-running processes like web servers.\n- **[Pexels](https://github.com/garylab/pexels-mcp-server)** - A MCP server providing access to Pexels Free Image API, enabling seamless search, retrieval, and download of high-quality royalty-free images.\n- **[Pharos](https://github.com/QuentinCody/pharos-mcp-server)** - Unofficial MCP server for the Pharos database by the National Center for Advancing Translational Sciences (NCATS), providing access to target, drug, and disease information for drug discovery research.\n- **[Phone MCP](https://github.com/hao-cyber/phone-mcp)** - 📱 A powerful plugin that lets you control your Android phone. Enables AI agents to perform complex tasks like automatically playing music based on weather or making calls and sending texts.\n- **[PIF](https://github.com/hungryrobot1/MCP-PIF)** - A Personal Intelligence Framework (PIF), providing tools for file operations, structured reasoning, and journal-based documentation to support continuity and evolving human-AI collaboration across sessions.\n- **[Pinecone](https://github.com/sirmews/mcp-pinecone)** - MCP server for searching and uploading records to Pinecone. Allows for simple RAG features, leveraging Pinecone's Inference API.\n- **[Pinner MCP](https://github.com/safedep/pinner-mcp)** - An MCP server for pinning GitHub Actions and container base images to their immutable SHA hashes to prevent supply chain attacks.\n- **[Pixelle MCP](https://github.com/AIDC-AI/Pixelle-MCP)** - An omnimodal AIGC framework that seamlessly converts ComfyUI workflows into MCP tools with zero code, enabling full-modal support for Text, Image, Sound, and Video generation with Chainlit-based web interface.\n- **[Placid.app](https://github.com/felores/placid-mcp-server)** - Generate image and video creatives using Placid.app templates\n- **[Plane](https://github.com/kelvin6365/plane-mcp-server)** - This MCP Server will help you to manage projects and issues through Plane's API\n- **[Playwright](https://github.com/executeautomation/mcp-playwright)** - This MCP Server will help you run browser automation and webscraping using Playwright\n- **[Podbean](https://github.com/amurshak/podbeanMCP)** - MCP server for managing your podcasts, episodes, and analytics through the Podbean API. Allows for updating, adding, deleting podcasts, querying show description, notes, analytics, and more.\n- **[Polarsteps](https://github.com/remuzel/polarsteps-mcp)** - An MCP server to help you review your previous Trips and plan new ones!\n- **[PostgreSQL](https://github.com/ahmedmustahid/postgres-mcp-server)** - A PostgreSQL MCP server offering dual HTTP/Stdio transports for database schema inspection and read-only query execution with session management and Podman(or Docker) support.\n- **[Postman](https://github.com/shannonlal/mcp-postman)** - MCP server for running Postman Collections locally via Newman. Allows for simple execution of Postman Server and returns the results of whether the collection passed all the tests.\n- **[Powerdrill](https://github.com/powerdrillai/powerdrill-mcp)** - Interact with Powerdrill datasets, authenticated with [Powerdrill](https://powerdrill.ai) User ID and Project API Key.\n- **[Prefect](https://github.com/allen-munsch/mcp-prefect)** - MCP Server for workflow orchestration and ELT/ETL with Prefect Server, and Prefect Cloud [https://www.prefect.io/] using the `prefect` python client.\n- **[Productboard](https://github.com/kenjihikmatullah/productboard-mcp)** - Integrate the Productboard API into agentic workflows via MCP.\n- **[Prometheus](https://github.com/pab1it0/prometheus-mcp-server)** - Query and analyze Prometheus - open-source monitoring system.\n- **[Prometheus (TypeScript)](https://github.com/yanmxa/prometheus-mcp-server)** - Enable AI assistants to query Prometheus using natural language with TypeScript implementation.\n- **[Prometheus (Golang)](https://github.com/tjhop/prometheus-mcp-server/)** - A Prometheus MCP server with full API support for comprehensive management and deep interaction with Prometheus beyond basic query support. Written in go, it is a single binary install that is capable of STDIO, SSE, and HTTP transports for complex deployments. \n- **[PubChem](https://github.com/sssjiang/pubchem_mcp_server)** - extract drug information from pubchem API.\n- **[PubMed](https://github.com/JackKuo666/PubMed-MCP-Server)** - Enable AI assistants to search, access, and analyze PubMed articles through a simple MCP interface.\n- **[Pulumi](https://github.com/dogukanakkaya/pulumi-mcp-server)** - MCP Server to Interact with Pulumi API, creates and lists Stacks\n- **[Puppeteer vision](https://github.com/djannot/puppeteer-vision-mcp)** - Use Puppeteer to browse a webpage and return a high quality Markdown. Use AI vision capabilities to handle cookies, captchas, and other interactive elements automatically.\n- **[Pushover](https://github.com/ashiknesin/pushover-mcp)** - Send instant notifications to your devices using [Pushover.net](https://pushover.net/)\n- **[py-mcp-qdrant-rag](https://github.com/amornpan/py-mcp-qdrant-rag)** (by amornpan) - A Model Context Protocol server implementation that provides RAG capabilities through Qdrant vector database integration, enabling AI agents to perform semantic search and document retrieval with local or cloud-based embedding generation support across Mac, Linux, and Windows platforms.\n- **[pydantic/pydantic-ai/mcp-run-python](https://github.com/pydantic/pydantic-ai/tree/main/mcp-run-python)** - Run Python code in a secure sandbox via MCP tool calls, powered by Deno and Pyodide\n- **[Python CLI MCP](https://github.com/ofek/pycli-mcp)** - Interact with local Python command line applications.\n- **[QGIS](https://github.com/jjsantos01/qgis_mcp)** - connects QGIS to Claude AI through the MCP. This integration enables prompt-assisted project creation, layer loading, code execution, and more.\n- **[Qiniu MCP Server](https://github.com/qiniu/qiniu-mcp-server)** - The Model Context Protocol (MCP) Server built on Qiniu Cloud products supports users in accessing Qiniu Cloud Storage, intelligent multimedia services, and more through this MCP Server within the context of AI large model clients.\n- **[QuantConnect](https://github.com/taylorwilsdon/quantconnect-mcp)** - QuantConnect Algorithmic Trading Platform Orchestration MCP - Agentic LLM Driven Trading Strategy Design, Research & Implementation.\n- **[Quarkus](https://github.com/quarkiverse/quarkus-mcp-servers)** - MCP servers for the Quarkus Java framework.\n- **[QuickChart](https://github.com/GongRzhe/Quickchart-MCP-Server)** - A Model Context Protocol server for generating charts using QuickChart.io\n- **[Qwen_Max](https://github.com/66julienmartin/MCP-server-Qwen_Max)** - A Model Context Protocol (MCP) server implementation for the Qwen models.\n- **[RabbitMQ](https://github.com/kenliao94/mcp-server-rabbitmq)** - The MCP server that interacts with RabbitMQ to publish and consume messages.\n- **[RAE](https://github.com/rae-api-com/rae-mcp)** - MPC Server to connect your preferred model with rae-api.com, Roya Academy of Spanish Dictionary\n- **[RAG Local](https://github.com/renl/mcp-rag-local)** - This MCP server for storing and retrieving text passages locally based on their semantic meaning.\n- **[RAG Web Browser](https://github.com/apify/mcp-server-rag-web-browser)** An MCP server for Apify's open-source RAG Web Browser [Actor](https://apify.com/apify/rag-web-browser) to perform web searches, scrape URLs, and return content in Markdown.\n- **[Raindrop.io](https://github.com/hiromitsusasaki/raindrop-io-mcp-server)** - An integration that allows LLMs to interact with Raindrop.io bookmarks using the Model Context Protocol (MCP).\n- **[Random Number](https://github.com/zazencodes/random-number-mcp)** - Provides LLMs with essential random generation abilities, built entirely on Python's standard library.\n- **[RCSB PDB](https://github.com/QuentinCody/rcsb-pdb-mcp-server)** - Unofficial MCP server for the Research Collaboratory for Structural Bioinformatics Protein Data Bank (RCSB PDB), providing access to 3D protein structures, experimental data, and structural bioinformatics information.\n- **[Reaper](https://github.com/dschuler36/reaper-mcp-server)** - Interact with your [Reaper](https://www.reaper.fm/) (Digital Audio Workstation) projects.\n- **[Redbee](https://github.com/Tamsi/redbee-mcp)** - Redbee MCP server that provides support for interacting with Redbee API.\n- **[Redfish](https://github.com/nokia/mcp-redfish)** - Redfish MCP server that provides support for interacting with [DMTF Redfish API](https://www.dmtf.org/standards/redfish).\n- **[Redis](https://github.com/GongRzhe/REDIS-MCP-Server)** - Redis database operations and caching microservice server with support for key-value operations, expiration management, and pattern-based key listing.\n- **[Redis](https://github.com/prajwalnayak7/mcp-server-redis)** MCP server to interact with Redis Server, AWS Memory DB, etc for caching or other use-cases where in-memory and key-value based storage is appropriate\n- **[RedNote MCP](https://github.com/ifuryst/rednote-mcp)** - MCP server for accessing RedNote(XiaoHongShu, xhs) content\n- **[Reed Jobs](https://github.com/kld3v/reed_jobs_mcp)** - Search and retrieve job listings from Reed.co.uk.\n- **[Rememberizer AI](https://github.com/skydeckai/mcp-server-rememberizer)** - An MCP server designed for interacting with the Rememberizer data source, facilitating enhanced knowledge retrieval.\n- **[Replicate](https://github.com/deepfates/mcp-replicate)** - Search, run and manage machine learning models on Replicate through a simple tool-based interface. Browse models, create predictions, track their status, and handle generated images.\n- **[Resend](https://github.com/Klavis-AI/klavis/tree/main/mcp_servers/resend)** - Send email using Resend services\n- **[Revit MCP](https://github.com/revit-mcp)** - A service implementing the MCP protocol for Autodesk Revit.\n- **[Rijksmuseum](https://github.com/r-huijts/rijksmuseum-mcp)** - Interface with the Rijksmuseum API to search artworks, retrieve artwork details, access image tiles, and explore user collections.\n- **[Riot Games](https://github.com/jifrozen0110/mcp-riot)** - MCP server for League of Legends – fetch player info, ranks, champion stats, and match history via Riot API.\n- **[Rohlik](https://github.com/tomaspavlin/rohlik-mcp)** - Shop groceries across the Rohlik Group platforms (Rohlik.cz, Knuspr.de, Gurkerl.at, Kifli.hu, Sezamo.ro)\n- **[Rquest](https://github.com/xxxbrian/mcp-rquest)** - An MCP server providing realistic browser-like HTTP request capabilities with accurate TLS/JA3/JA4 fingerprints for bypassing anti-bot measures.\n- **[Rust MCP Filesystem](https://github.com/rust-mcp-stack/rust-mcp-filesystem)** - Fast, asynchronous MCP server for efficient handling of various filesystem operations built with the power of Rust.\n- **[SafetySearch](https://github.com/surabhya/SafetySearch)** - Real-time FDA food safety data: recalls, adverse events, analysis.\n- **[Salesforce MCP](https://github.com/smn2gnt/MCP-Salesforce)** - Interact with Salesforce Data and Metadata\n- **[Salesforce MCP (AiondaDotCom)](https://github.com/AiondaDotCom/mcp-salesforce)** - Universal Salesforce integration with OAuth authentication, smart learning system, comprehensive backup capabilities, and full CRUD operations for any Salesforce org including custom objects and fields.\n- **[Salesforce MCP Server](https://github.com/tsmztech/mcp-server-salesforce)** - Comprehensive Salesforce integration with tools for querying records, executing Apex, managing fields/objects, and handling debug logs\n- **[Scanova MCP Server](https://github.com/trycon/scanova-mcp)** - MCP server for creating and managing QR codes using the [Scanova](https://scanova.io) API. Provides tools for generating, managing, and downloading QR codes.\n- **[SchemaCrawler](https://github.com/schemacrawler/SchemaCrawler-MCP-Server-Usage)** - Connect to any relational database, and be able to get valid SQL, and ask questions like what does a certain column prefix mean.\n- **[SchemaFlow](https://github.com/CryptoRadi/schemaflow-mcp-server)** - Real-time PostgreSQL & Supabase database schema access for AI-IDEs via Model Context Protocol. Provides live database context through secure SSE connections with three powerful tools: get_schema, analyze_database, and check_schema_alignment. [SchemaFlow](https://schemaflow.dev)\n- **[Scholarly](https://github.com/adityak74/mcp-scholarly)** - An MCP server to search for scholarly and academic articles.\n- **[scrapling-fetch](https://github.com/cyberchitta/scrapling-fetch-mcp)** - Access text content from bot-protected websites. Fetches HTML/markdown from sites with anti-automation measures using Scrapling.\n- **[Screeny](https://github.com/rohanrav/screeny)** - Privacy-first macOS MCP server that provides visual context for AI agents through window screenshots\n- **[ScriptFlow](https://github.com/yanmxa/scriptflow-mcp)** - Transform complex, repetitive AI interactions into persistent, executable scripts with comprehensive script management (add, edit, remove, list, search, execute) and multi-language support (Bash, Python, Node.js, TypeScript).\n- **[SearXNG](https://github.com/ihor-sokoliuk/mcp-searxng)** - A Model Context Protocol Server for [SearXNG](https://docs.searxng.org)\n- **[SearXNG](https://github.com/erhwenkuo/mcp-searxng)** - An MCP server provide web searching via [SearXNG](https://docs.searxng.org) & retrieve url as makrdown.\n- **[SearXNG Public](https://github.com/pwilkin/mcp-searxng-public)** - A Model Context Protocol Server for retrieving data from public [SearXNG](https://docs.searxng.org) instances, with fallback support\n- **[SEC EDGAR](https://github.com/stefanoamorelli/sec-edgar-mcp)** - (by Stefano Amorelli) A community Model Context Protocol Server to access financial filings and data through the U.S. Securities and Exchange Commission ([SEC](https://www.sec.gov/)) `Electronic Data Gathering, Analysis, and Retrieval` ([EDGAR](https://www.sec.gov/submit-filings/about-edgar)) database\n- **[SEO MCP](https://github.com/cnych/seo-mcp)** - A free SEO tool MCP (Model Control Protocol) service based on Ahrefs data. Includes features such as backlinks, keyword ideas, and more. by [claudemcp](https://www.claudemcp.com/servers/seo-mcp).\n- **[Serper](https://github.com/garylab/serper-mcp-server)** - An MCP server that performs Google searches using [Serper](https://serper.dev).\n- **[ServiceNow](https://github.com/osomai/servicenow-mcp)** - An MCP server to interact with a ServiceNow instance\n- **[ShaderToy](https://github.com/wilsonchenghy/ShaderToy-MCP)** - This MCP server lets LLMs to interact with the ShaderToy API, allowing LLMs to learn from compute shaders examples and enabling them to create complex GLSL shaders that they are previously not capable of.\n- **[ShareSeer](https://github.com/shareseer/shareseer-mcp-server)** - MCP to Access SEC filings, financials & insider trading data in real time using [ShareSeer](https://shareseer.com)\n- **[Shell](https://github.com/sonirico/mcp-shell)** - Give hands to AI. MCP server to run shell commands securely, auditably, and on demand\n- **[Shodan MCP](https://github.com/Hexix23/shodan-mcp)** - MCP server to interact with [Shodan](https://www.shodan.io/)\n- **[Shopify](https://github.com/GeLi2001/shopify-mcp)** - MCP to interact with Shopify API including order, product, customers and so on.\n- **[Shopify Storefront](https://github.com/QuentinCody/shopify-storefront-mcp-server)** - Unofficial MCP server that allows AI agents to discover Shopify storefronts and interact with them to fetch products, collections, and other store data through the Storefront API.\n- **[Simple Loki MCP](https://github.com/ghrud92/simple-loki-mcp)** - A simple MCP server to query Loki logs using logcli.\n- **[Siri Shortcuts](https://github.com/dvcrn/mcp-server-siri-shortcuts)** - MCP to interact with Siri Shortcuts on macOS. Exposes all Shortcuts as MCP tools.\n- **[Skyvern](https://github.com/Skyvern-AI/skyvern/tree/main/integrations/mcp)** - MCP to let Claude / Windsurf / Cursor / your LLM control the browser\n- **[Slack](https://github.com/korotovsky/slack-mcp-server)** - The most powerful MCP server for Slack Workspaces. This integration supports both Stdio and SSE transports, proxy settings and does not require any permissions or bots being created or approved by Workspace admins 😏.\n- **[Slack](https://github.com/zencoderai/slack-mcp-server)** - Slack MCP server which supports both stdio and Streamable HTTP transports. Extended from the original Anthropic's implementation which is now [archived](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/slack)\n- **[Slidespeak](https://github.com/SlideSpeak/slidespeak-mcp)** - Create PowerPoint presentations using the [Slidespeak](https://slidespeak.com/) API.\n- **[Smartlead](https://github.com/jean-technologies/smartlead-mcp-server-local)** - MCP to connect to Smartlead. Additional, tooling, functionality, and connection to workflow automation platforms also available.\n- **[Snowflake](https://github.com/Snowflake-Labs/mcp)** - Open-source MCP server for Snowflake from official Snowflake-Labs supports prompting Cortex Agents, querying structured & unstructured data, object management, SQL execution, semantic view querying, and more. RBAC, fine-grained CRUD controls, and all authentication methods supported.\n- **[Snowflake](https://github.com/isaacwasserman/mcp-snowflake-server)** - This MCP server enables LLMs to interact with Snowflake databases, allowing for secure and controlled data operations.\n- **[Snowflake Cortex MCP Server](https://github.com/thisisbhanuj/Snowflake-Cortex-MCP-Server)** -This Snowflake MCP server provides tooling for Snowflake Cortex AI features, bringing these capabilities to the MCP ecosystem. When connected to an MCP Client (e.g. Claude for Desktop, fast-agent, Agentic Orchestration Framework), users can leverage these Cortex AI features.\n- **[SoccerDataAPI](https://github.com/yeonupark/mcp-soccer-data)** - This MCP server provides real-time football match data based on the SoccerDataAPI.\n- **[Solana Agent Kit](https://github.com/sendaifun/solana-agent-kit/tree/main/examples/agent-kit-mcp-server)** - This MCP server enables LLMs to interact with the Solana blockchain with help of Solana Agent Kit by SendAI, allowing for 40+ protocol actions and growing\n- **[Solr MCP](https://github.com/mjochum64/mcp-solr-search)** - This MCP server offers a basic functionality to perform a search on Solr servers.\n- **[Solver](https://github.com/szeider/mcp-solver)** - Solves constraint satisfaction and optimization problems .\n- **[Solvitor](https://github.com/Adeptus-Innovatio/solvitor-mcp)** – Solvitor MCP server provides tools to access reverse engineering tools that help developers extract IDL files from closed - source Solana smart contracts and decompile them.\n- **[Sourcerer](https://github.com/st3v3nmw/sourcerer-mcp)** - MCP for semantic code search & navigation that reduces token waste.\n- **[Specbridge](https://github.com/TBosak/specbridge)** - Easily turn your OpenAPI specs into MCP Tools.\n- **[Splunk](https://github.com/jkosik/mcp-server-splunk)** - Golang MCP server for Splunk (lists saved searches, alerts, indexes, macros...). Supports SSE and STDIO.\n- **[Spotify](https://github.com/varunneal/spotify-mcp)** - This MCP allows an LLM to play and use Spotify.\n- **[Spring Initializr](https://github.com/hpalma/springinitializr-mcp)** - This MCP allows an LLM to create Spring Boot projects with custom configurations. Instead of manually visiting start.spring.io, you can now ask your AI assistant to generate projects with specific dependencies, Java versions, and project structures.\n- **[Squad AI](https://github.com/the-basilisk-ai/squad-mcp)** – Product‑discovery and strategy platform integration. Create, query and update opportunities, solutions, outcomes, requirements and feedback from any MCP‑aware LLM.\n- **[SSH](https://github.com/AiondaDotCom/mcp-ssh)** - Agent for managing and controlling SSH connections.\n- **[SSH](https://github.com/classfang/ssh-mcp-server)** - An MCP server that can execute SSH commands remotely, upload files, download files, and so on.\n- **[SSH MCP Server](https://github.com/sinjab/mcp_ssh)** - A production-ready Model Context Protocol server for SSH automation with background execution, file transfers, and comprehensive timeout protection. Features structured output, progress tracking, and enterprise-grade testing (87% coverage).\n- **[sslmon](https://github.com/firesh/sslmon-mcp)** - Domain/HTTPS/SSL domain registration information and SSL certificate monitoring capabilities. Query domain registration and expiration information, and SSL certificate information and validity status for any domain.\n- **[Standard Korean Dictionary](https://github.com/privetin/stdict)** - Search the dictionary using API\n- **[Star Wars](https://github.com/johnpapa/mcp-starwars)** -MCP Server for the SWAPI Star Wars API. The main goal of the project is to show how an MCP server can be used to interact with APIs.\n- **[Starknet MCP Server](https://github.com/mcpdotdirect/starknet-mcp-server)** - A comprehensive MCP server for interacting with the Starknet blockchain, providing tools for querying blockchain data, resolving StarknetIDs, and performing token transfers.\n- **[Starwind UI](https://github.com/Boston343/starwind-ui-mcp/)** - This MCP provides relevant commands, documentation, and other information to allow LLMs to take full advantage of Starwind UI's open source Astro components.\n- **[Stellar](https://github.com/syronlabs/stellar-mcp/)** - This MCP server enables LLMs to interact with the Stellar blockchain to create accounts, check address balances, analyze transactions, view transaction history, mint new assets, interact with smart contracts and much more.\n- **[Stitch AI](https://github.com/StitchAI/stitch-ai-mcp/)** - Knowledge management system for AI agents with memory space creation and retrieval capabilities.\n- **[Stockfish](https://github.com/sonirico/mcp-stockfish)** - MCP server connecting AI systems to Stockfish chess engine\n- **[Storybook](https://github.com/stefanoamorelli/storybook-mcp-server)** (by Stefano Amorelli) - Interact with Storybook component libraries, enabling component discovery, story management, prop inspection, and visual testing across different viewports.\n- **[Strava](https://github.com/r-huijts/strava-mcp)** - Connect to the Strava API to access activity data, athlete profiles, segments, and routes, enabling fitness tracking and analysis with Claude.\n- **[Strava API](https://github.com/tomekkorbak/strava-mcp-server)** - MCP server for Strava API to retrieve one's activities\n- **[Stripe](https://github.com/atharvagupta2003/mcp-stripe)** - This MCP allows integration with Stripe for handling payments, customers, and refunds.\n- **[Substack/Medium](https://github.com/jonathan-politzki/mcp-writer-substack)** - Connect Claude to your Substack/Medium writing, enabling semantic search and analysis of your published content.\n- **[System Health](https://github.com/thanhtung0201/mcp-remote-system-health)** - The MCP (Multi-Channel Protocol) System Health Monitoring is a robust, real-time monitoring solution designed to provide comprehensive health metrics and alerts for remote Linux servers.\n- **[SystemSage](https://github.com/Tarusharma1/SystemSage)** - A powerful, cross-platform system management and monitoring tool for Windows, Linux, and macOS.\n- **[Talk To Figma](https://github.com/sonnylazuardi/cursor-talk-to-figma-mcp)** - This MCP server enables LLMs to interact with Figma, allowing them to read and modify designs programmatically.\n- **[Talk To Figma via Claude](https://github.com/gaganmanku96/talk-with-figma-claude)** - TMCP server that provides seamless Figma integration specifically for Claude Desktop, enabling design creation, modification, and real-time collaboration through natural language commands.\n- **[TAM MCP Server](https://github.com/gvaibhav/TAM-MCP-Server)** - Market research and business intelligence with TAM/SAM calculations and integration across 8 economic data sources: Alpha Vantage, BLS, Census Bureau, FRED, IMF, Nasdaq Data Link, OECD, and World Bank.\n- **[Tasks](https://github.com/flesler/mcp-tasks)** - An efficient task manager. Designed to minimize tool confusion and maximize LLM budget efficiency while providing powerful search, filtering, and organization capabilities across multiple file formats (Markdown, JSON, YAML)\n- **[Tavily search](https://github.com/RamXX/mcp-tavily)** - An MCP server for Tavily's search & news API, with explicit site inclusions/exclusions\n- **[TcpSocketMCP](https://github.com/SpaceyKasey/TcpSocketMCP/)** - A Model Context Protocol (MCP) server that provides raw TCP socket access, enabling AI models to interact directly with network services using raw TCP Sockets. Supports multiple concurrent connections, buffering of response data and triggering automatic responses.\n- **[TeamRetro](https://github.com/adepanges/teamretro-mcp-server)** - This MCP server allows LLMs to interact with TeamRetro, allowing LLMs to manage user, team, team member, retrospective, health check, action, agreement and fetch the reports.\n- **[Telegram](https://github.com/chigwell/telegram-mcp)** - An MCP server that provides paginated chat reading, message retrieval, and message sending capabilities for Telegram through Telethon integration.\n- **[Telegram-Client](https://github.com/chaindead/telegram-mcp)** - A Telegram API bridge that manages user data, dialogs, messages, drafts, read status, and more for seamless interactions.\n- **[Telegram-mcp-server](https://github.com/DLHellMe/telegram-mcp-server)** - Access Telegram channels and groups directly in Claude. Features dual-mode operation with API access (100x faster) or web scraping, unlimited post retrieval, and search functionality.\n- **[Template MCP Server](https://github.com/mcpdotdirect/template-mcp-server)** - A CLI tool to create a new Model Context Protocol server project with TypeScript support, dual transport options, and an extensible structure\n- **[Tempo](https://github.com/scottlepp/tempo-mcp-server)** - An MCP server to query traces/spans from [Grafana Tempo](https://github.com/grafana/tempo).\n- **[Teradata](https://github.com/arturborycki/mcp-teradata)** - his MCP server enables LLMs to interact with Teradata databases. This MCP Server support tools and prompts for multi task data analytics\n- **[Terminal-Control](https://github.com/GongRzhe/terminal-controller-mcp)** - An MCP server that enables secure terminal command execution, directory navigation, and file system operations through a standardized interface.\n- **[Terraform-Cloud](https://github.com/severity1/terraform-cloud-mcp)** - An MCP server that integrates AI assistants with the Terraform Cloud API, allowing you to manage your infrastructure through natural conversation.\n- **[Tideways](https://github.com/abuhamza/tideways-mcp-server)** - A Model Context Protocol server that enables AI assistants to query Tideways performance monitoring data and provide conversational performance insights for PHP applications.\n- **[TFT-Match-Analyzer](https://github.com/GeLi2001/tft-mcp-server)** - MCP server for teamfight tactics match history & match details fetching, providing user the detailed context for every match.\n- **[Thales CDSP CAKM MCP Server](https://github.com/sanyambassi/thales-cdsp-cakm-mcp-server)** - An MCP server for the Thales CipherTrust Data Security Platform (CDSP) Cloud Key Management (CAKM) connector. This MCP server supports Ms SQL and Oracle databases.\n- **[Thales CDSP CRDP MCP Server](https://github.com/sanyambassi/thales-cdsp-crdp-mcp-server)** - A Model Context Protocol (MCP) server that allows interacting with the CipherTrust RestFul Data Protection (CRDP) data protection service.\n- **[Thales CipherTrust Manager MCP Server](https://github.com/sanyambassi/ciphertrust-manager-mcp-server)** - MCP server for Thales CipherTrust Manager integration, enabling secure key management and cryptographic operations.\n- **[thegraph-mcp](https://github.com/kukapay/thegraph-mcp)** - An MCP server that powers AI agents with indexed blockchain data from The Graph.\n- **[TheHive MCP Server](https://github.com/redwaysecurity/the-hive-mcp-server)** - An MCP server for [TheHive](https://strangebee.com/thehive/) Security Incident Response Platform.\n- **[Things3 MCP](https://github.com/urbanogardun/things3-mcp)** - Things3 task management integration for macOS with comprehensive TODO, project, and tag management.\n- **[Think MCP](https://github.com/Rai220/think-mcp)** - Enhances any agent's reasoning capabilities by integrating the think-tools, as described in [Anthropic's article](https://www.anthropic.com/engineering/claude-think-tool).\n- **[Think Node MCP](https://github.com/abhinav-mangla/think-tool-mcp)** - Enhances any agent's reasoning capabilities by integrating the think-tools, as described in [Anthropic's article](https://www.anthropic.com/engineering/claude-think-tool). (Works with Node)\n- **[Ticketmaster](https://github.com/delorenj/mcp-server-ticketmaster)** - Search for events, venues, and attractions through the Ticketmaster Discovery API\n- **[Ticketmaster MCP Server](https://github.com/mochow13/ticketmaster-mcp-server)** - A Model Context Protocol (MCP) server implemented in Streamable HTTP transport that allows AI models to interact with the Ticketmaster Discovery API, enabling searching events, venues, and attractions.\n- **[TickTick](https://github.com/alexarevalo9/ticktick-mcp-server)** - A Model Context Protocol (MCP) server designed to integrate with the TickTick task management platform, enabling intelligent context-aware task operations and automation.\n- **[TigerGraph](https://github.com/custom-discoveries/TigerGraph_MCP)** - A community built MCP server that interacts with TigerGraph Graph Database.\n- **[tip.md](https://github.com/tipdotmd#-mcp-server-for-ai-assistants)** - An MCP server that enables AI assistants to interact with tip.md's crypto tipping functionality, allowing agents or supporters to tip registered developers directly from AI chat interfaces.\n- **[TMD Earthquake](https://github.com/amornpan/tmd-earthquake-server-1.0)** - 🌍 Real-time earthquake monitoring from Thai Meteorological Department. Features magnitude filtering, location-based search (Thai/English), today's events tracking, dangerous earthquake alerts, and comprehensive statistics. Covers regional and global seismic activities.\n- **[TMDB](https://github.com/Laksh-star/mcp-server-tmdb)** - This MCP server integrates with The Movie Database (TMDB) API to provide movie information, search capabilities, and recommendations.\n- **[Todoist](https://github.com/abhiz123/todoist-mcp-server)** - Interact with Todoist to manage your tasks.\n- **[Todos](https://github.com/tomelliot/todos-mcp)** - A practical todo list manager to use with your favourite chatbot.\n- **[token-minter-mcp](https://github.com/kukapay/token-minter-mcp)** - An MCP server providing tools for AI agents to mint ERC-20 tokens across multiple blockchains.\n- **[token-revoke-mcp](https://github.com/kukapay/token-revoke-mcp)** - An MCP server for checking and revoking ERC-20 token allowances across multiple blockchains.\n- **[Ton Blockchain MCP](https://github.com/devonmojito/ton-blockchain-mcp)** - An MCP server for interacting with Ton Blockchain.\n- **[TouchDesigner](https://github.com/8beeeaaat/touchdesigner-mcp)** - An MCP server for TouchDesigner, enabling interaction with TouchDesigner projects, nodes, and parameters.\n- **[Transcribe](https://github.com/transcribe-app/mcp-transcribe)** - An MCP server provides fast and reliable transcriptions for audio/video files and voice memos. It allows LLMs to interact with the text content of audio/video file.\n- **[Travel Planner](https://github.com/GongRzhe/TRAVEL-PLANNER-MCP-Server)** - Travel planning and itinerary management server integrating with Google Maps API for location search, place details, and route calculations.\n- **[Trello MCP Server](https://github.com/lioarce01/trello-mcp-server)** - An MCP server that interact with user Trello boards, modifying them with prompting.\n- **[Trino](https://github.com/tuannvm/mcp-trino)** - A high-performance Model Context Protocol (MCP) server for Trino implemented in Go.\n- **[Tripadvisor](https://github.com/pab1it0/tripadvisor-mcp)** - An MCP server that enables LLMs to interact with Tripadvisor API, supporting location data, reviews, and photos through standardized MCP interfaces\n- **[Triplyfy MCP](https://github.com/helpful-AIs/triplyfy-mcp)** - An MCP server that lets LLMs plan and manage itineraries with interactive maps in Triplyfy; manage itineraries, places and notes, and search/save flights.\n- **[TrueNAS Core MCP](https://github.com/vespo92/TrueNasCoreMCP)** - An MCP server for interacting with TrueNAS Core.\n- **[TuriX Computer Automation MCP](https://github.com/TurixAI/TuriX-CUA/tree/mac_mcp)** - MCP server for helping automation control your computer complete your pre-setting task.\n- **[Tyk API Management](https://github.com/TykTechnologies/tyk-dashboard-mcp)** - Chat with all of your organization's managed APIs and perform other API lifecycle operations, managing tokens, users, analytics, and more.\n- **[Typesense](https://github.com/suhail-ak-s/mcp-typesense-server)** - A Model Context Protocol (MCP) server implementation that provides AI models with access to Typesense search capabilities. This server enables LLMs to discover, search, and analyze data stored in Typesense collections.\n- **[UniFi Dream Machine](https://github.com/sabler/mcp-unifi)** An MCP server that gets your network telemetry from the UniFi Site Manager and your local UniFi router.\n- **[UniProt](https://github.com/QuentinCody/uniprot-mcp-server)** - Unofficial MCP server for UniProt, providing access to protein sequence data, functional annotations, taxonomic information, and cross-references for proteomics and bioinformatics research.\n- **[uniswap-poolspy-mcp](https://github.com/kukapay/uniswap-poolspy-mcp)** - An MCP server that tracks newly created liquidity pools on Uniswap across nine blockchain networks.\n- **[uniswap-trader-mcp](https://github.com/kukapay/uniswap-trader-mcp)** -An MCP server for AI agents to automate token swaps on Uniswap DEX across multiple blockchains.\n- **[Unity Catalog](https://github.com/ognis1205/mcp-server-unitycatalog)** - An MCP server that enables LLMs to interact with Unity Catalog AI, supporting CRUD operations on Unity Catalog Functions and executing them as MCP tools.\n- **[Unity Integration (Advanced)](https://github.com/quazaai/UnityMCPIntegration)** - Advanced Unity3d Game Engine MCP which supports ,Execution of Any Editor Related Code Directly Inside of Unity, Fetch Logs, Get Editor State and Allow File Access of the Project making it much more useful in Script Editing or asset creation.\n- **[Unity3d Game Engine](https://github.com/CoderGamester/mcp-unity)** - An MCP server that enables LLMs to interact with Unity3d Game Engine, supporting access to a variety of the Unit's Editor engine tools (e.g. Console Logs, Test Runner logs, Editor functions, hierarchy state, etc) and executing them as MCP tools or gather them as resources.\n- **[Universal MCP Servers](https://github.com/universal-mcp)** - A collection of MCP servers created using the [AgentR Universal MCP SDK](https://github.com/universal-mcp/universal-mcp).\n- **[Unleash Integration (Feature Toggle)](https://github.com/cuongtl1992/unleash-mcp)** - A Model Context Protocol (MCP) server implementation that integrates with Unleash Feature Toggle system. Provide a bridge between LLM applications and Unleash feature flag system\n- **[Upbit MCP Server](https://github.com/solangii/upbit-mcp-server)** – An MCP server that enables real - time access to cryptocurrency prices, market summaries, and asset listings from the Upbit exchange.\n- **[use_aws_mcp](https://github.com/runjivu/use_aws_mcp)** - amazon-q-cli's use_aws tool extracted into independent mcp, for general aws api usage.\n- **[User Feedback](https://github.com/mrexodia/user-feedback-mcp)** - Simple MCP Server to enable a human-in-the-loop workflow in tools like Cline and Cursor.\n- **[USPTO](https://github.com/riemannzeta/patent_mcp_server)** - MCP server for accessing United States Patent & Trademark Office data through its Open Data Protocol (ODP) API.\n- **[Vectara](https://github.com/vectara/vectara-mcp)** - Query Vectara's trusted RAG-as-a-service platform.\n- **[Vega-Lite](https://github.com/isaacwasserman/mcp-vegalite-server)** - Generate visualizations from fetched data using the VegaLite format and renderer.\n- **[Vertica](https://github.com/nolleh/mcp-vertica)** - Vertica database integration in Python with configurable access controls and schema inspection\n- **[Vibe Check](https://github.com/PV-Bhat/vibe-check-mcp-server)** - An MCP server leveraging an external oversight layer to \"vibe check\" agents, and also self-improve accuracy & user alignment over time. Prevents scope creep, code bloat, misalignment, misinterpretation, tunnel vision, and overcomplication.\n- **[Video Editor](https://github.com/burningion/video-editing-mcp)** - A Model Context Protocol Server to add, edit, and search videos with [Video Jungle](https://www.video-jungle.com/).\n- **[Video Still Capture](https://github.com/13rac1/videocapture-mcp)** - 📷 Capture video stills from an OpenCV-compatible webcam or other video source.\n- **[Virtual location (Google Street View,etc.)](https://github.com/mfukushim/map-traveler-mcp)** - Integrates Google Map, Google Street View, PixAI, Stability.ai, ComfyUI API and Bluesky to provide a virtual location simulation in LLM (written in Effect.ts)\n- **[VMware Fusion](https://github.com/yeahdongcn/vmware-fusion-mcp-server)** - Manage VMware Fusion virtual machines via the Fusion REST API.\n- **[VoiceMode](https://github.com/mbailey/voicemode)** - Enable voice conversations with Claude using any OpenAI-compatible STT/TTS service [getvoicemode.com](https://getvoicemode.com/)\n- **[Voice Status Report](https://github.com/tomekkorbak/voice-status-report-mcp-server)** - An MCP server that provides voice status updates using OpenAI's text-to-speech API, to be used with Cursor or Claude Code.\n- **[VolcEngine TOS](https://github.com/dinghuazhou/sample-mcp-server-tos)** - A sample MCP server for VolcEngine TOS that flexibly get objects from TOS.\n- **[Voyp](https://github.com/paulotaylor/voyp-mcp)** - VOYP MCP server for making calls using Artificial Intelligence.\n- **[vulnicheck](https://github.com/andrasfe/vulnicheck)** - Real-time Python package vulnerability scanner that checks dependencies against OSV and NVD databases, providing comprehensive security analysis with CVE details, lock file support, and actionable upgrade recommendations.\n- **[Wanaku MCP Router](https://github.com/wanaku-ai/wanaku/)** - The Wanaku MCP Router is a SSE-based MCP server that provides an extensible routing engine that allows integrating your enterprise systems with AI agents.\n- **[weather-mcp-server](https://github.com/devilcoder01/weather-mcp-server)** - Get real-time weather data for any location using weatherapi.\n- **[Web Search MCP](https://github.com/mrkrsl/web-search-mcp)** - A server that provides full web search, summaries and page extration for use with Local LLMs.\n- **[Webex](https://github.com/Kashyap-AI-ML-Solutions/webex-messaging-mcp-server)** - A Model Context Protocol (MCP) server that provides AI assistants with comprehensive access to Cisco Webex messaging capabilities.\n- **[Webflow](https://github.com/kapilduraphe/webflow-mcp-server)** - Interact with the Webflow APIs\n- **[webhook-mcp](https://github.com/noobnooc/webhook-mcp)** (by Nooc) - A Model Context Protocol (MCP) server that sends webhook notifications when called.\n- **[whale-tracker-mcp](https://github.com/kukapay/whale-tracker-mcp)**  -  A mcp server for tracking cryptocurrency whale transactions.\n- **[WhatsApp MCP Server](https://github.com/lharries/whatsapp-mcp)** - MCP server for your personal WhatsApp handling individuals, groups, searching and sending.\n- **[Whois MCP](https://github.com/bharathvaj-ganesan/whois-mcp)** - MCP server that performs whois lookup against domain, IP, ASN and TLD.\n- **[Wikidata MCP](https://github.com/zzaebok/mcp-wikidata)** - Wikidata MCP server that interact with Wikidata, by searching identifiers, extracting metadata, and executing sparql query.\n- **[Wikidata SPARQL](https://github.com/QuentinCody/wikidata-sparql-mcp-server)** - Unofficial REMOTE MCP server for Wikidata's SPARQL endpoint, providing access to structured knowledge data, entity relationships, and semantic queries for research and data analysis.\n- **[Wikifunctions](https://github.com/Fredibau/wikifunctions-mcp-fredibau)** - Allowing AI models to discover and execute functions from the WikiFunctions library.\n- **[Wikipedia MCP](https://github.com/Rudra-ravi/wikipedia-mcp)** - Access and search Wikipedia articles via MCP for AI-powered information retrieval.\n- **[WildFly MCP](https://github.com/wildfly-extras/wildfly-mcp)** - WildFly MCP server that enables LLM to interact with running WildFly servers (retrieve metrics, logs, invoke operations, ...).\n- **[Windows CLI](https://github.com/SimonB97/win-cli-mcp-server)** - MCP server for secure command-line interactions on Windows systems, enabling controlled access to PowerShell, CMD, and Git Bash shells.\n- **[Windsor](https://github.com/windsor-ai/windsor_mcp)** - Windsor MCP (Model Context Protocol) enables your LLM to query, explore, and analyze your full-stack business data integrated into Windsor.ai with zero SQL writing or custom scripting.\n- **[Wordle MCP](https://github.com/cr2007/mcp-wordle-python)** - MCP Server that gets the Wordle Solution for a particular date.\n- **[WordPress MCP](https://github.com/Automattic/wordpress-mcp)** - Make your WordPress site into a simple MCP server, exposing functionality to LLMs and AI agents.\n- **[Workflowy](https://github.com/danield137/mcp-workflowy)** - A server that interacts with [workflowy](https://workflowy.com/).\n- **[World Bank data API](https://github.com/anshumax/world_bank_mcp_server)** - A server that fetches data indicators available with the World Bank as part of their data API\n- **[Wren Engine](https://github.com/Canner/wren-engine)** - The Semantic Engine for Model Context Protocol(MCP) Clients and AI Agents\n- **[X (Twitter)](https://github.com/EnesCinr/twitter-mcp)** (by EnesCinr) - Interact with twitter API. Post tweets and search for tweets by query.\n- **[X (Twitter)](https://github.com/vidhupv/x-mcp)** (by vidhupv) - Create, manage and publish X/Twitter posts directly through Claude chat.\n- **[Xcode](https://github.com/r-huijts/xcode-mcp-server)** - MCP server that brings AI to your Xcode projects, enabling intelligent code assistance, file operations, project management, and automated development tasks.\n- **[Xcode-mcp-server](https://github.com/drewster99/xcode-mcp-server)** (by drewster99) - Best Xcode integration - ClaudeCode and Cursor can build your project *with* Xcode and see the same errors you do. Fast easy setup.\n- **[xcodebuild](https://github.com/ShenghaiWang/xcodebuild)**  - 🍎 Build iOS Xcode workspace/project and feed back errors to llm.\n- **[Xero-mcp-server](https://github.com/john-zhang-dev/xero-mcp)** - Enabling clients to interact with Xero system for streamlined accounting, invoicing, and business operations.\n- **[XiYan](https://github.com/XGenerationLab/xiyan_mcp_server)** - 🗄️ An MCP server that supports fetching data from a database using natural language queries, powered by XiyanSQL as the text-to-SQL LLM.\n- **[XMind](https://github.com/apeyroux/mcp-xmind)** - Read and search through your XMind directory containing XMind files.\n- **[Yahoo Finance](https://github.com/AgentX-ai/yahoo-finance-server)** - 📈 Lets your AI interact with Yahoo Finance to get comprehensive stock market data, news, financials, and more. Proxy supported.\n- **[yfinance](https://github.com/Adity-star/mcp-yfinance-server)** -💹The MCP YFinance Stock Server provides real-time and historical stock data in a standard format, powering dashboards, AI agents,and research tools with seamless financial insights.\n- **[YNAB](https://github.com/ChuckBryan/ynabmcpserver)** - A Model Context Protocol (MCP) server for integrating with YNAB (You Need A Budget), allowing AI assistants to securely access and analyze your financial data.\n- **[YouTrack](https://github.com/tonyzorin/youtrack-mcp)** - A Model Context Protocol (MCP) server implementation for JetBrains YouTrack, allowing AI assistants to interact with YouTrack issue tracking system.\n- **[YouTube](https://github.com/Klavis-AI/klavis/tree/main/mcp_servers/youtube)** - Extract Youtube video information (with proxies support).\n- **[YouTube](https://github.com/ZubeidHendricks/youtube-mcp-server)** - Comprehensive YouTube API integration for video management, Shorts creation, and analytics.\n- **[YouTube DLP](https://github.com/AgentX-ai/youtube-dlp-server)** - Retrieve video information, subtitles, and top comments with proxies.\n- **[YouTube MCP](https://github.com/aardeshir/youtube-mcp)** - Create playlists from song lists with OAuth2. Search videos, manage playlists, let AI curate your YouTube collections.\n- **[Youtube Uploader MCP](https://github.com/anwerj/youtube-uploader-mcp)** - AI‑powered YouTube uploader—no CLI, no YouTube Studio.\n- **[YouTube Video Summarizer](https://github.com/nabid-pf/youtube-video-summarizer-mcp)** - Summarize lengthy youtube videos.\n- **[yutu](https://github.com/eat-pray-ai/yutu)** - A fully functional MCP server and CLI for YouTube to automate YouTube operation.\n- **[ZapCap](https://github.com/bogdan01m/zapcap-mcp-server)** - MCP server for ZapCap API providing video caption and B-roll generation via natural language\n- **[Zettelkasten](https://github.com/joshylchen/zettelkasten)**- Comprehensive AI-powered knowledge management system implementing the Zettelkasten method. Features atomic note creation, full-text search, AI-powered CEQRC workflows (Capture→Explain→Question→Refine→Connect), intelligent link discovery, and multi-interface access (CLI, API, Web UI, MCP). Perfect for researchers, students, and knowledge workers.\n- **[ZincBind](https://github.com/QuentinCody/zincbind-mcp-server)** - Unofficial MCP server for ZincBind, providing access to a comprehensive database of zinc binding sites in proteins, structural coordination data, and metalloproteomics research information.\n- **[Zoom](https://github.com/Prathamesh0901/zoom-mcp-server/tree/main)** - Create, update, read and delete your zoom meetings.\n## 📚 Frameworks\n\nThese are high-level frameworks that make it easier to build MCP servers or clients.\n\n### For servers\n\n* **[Anubis MCP](https://github.com/zoedsoupe/anubis-mcp)** (Elixir) - A high-performance and high-level Model Context Protocol (MCP) implementation in Elixir. Think like \"Live View\" for MCP.\n* **[ModelFetch](https://github.com/phuctm97/modelfetch/)** (TypeScript) - Runtime-agnostic SDK to create and deploy MCP servers anywhere TypeScript/JavaScript runs\n* **[EasyMCP](https://github.com/zcaceres/easy-mcp/)** (TypeScript)\n* **[FastAPI to MCP auto generator](https://github.com/tadata-org/fastapi_mcp)** – A zero-configuration tool for automatically exposing FastAPI endpoints as MCP tools by **[Tadata](https://tadata.com/)**\n* **[FastMCP](https://github.com/punkpeye/fastmcp)** (TypeScript)\n* **[Foobara MCP Connector](https://github.com/foobara/mcp-connector)** - Easily expose Foobara commands written in Ruby as tools via MCP\n* **[Foxy Contexts](https://github.com/strowk/foxy-contexts)** – A library to build MCP servers in Golang by **[strowk](https://github.com/strowk)**\n* **[Higress MCP Server Hosting](https://github.com/alibaba/higress/tree/main/plugins/wasm-go/mcp-servers)** - A solution for hosting MCP Servers by extending the API Gateway (based on Envoy) with wasm plugins.\n* **[MCP Declarative Java SDK](https://github.com/codeboyzhou/mcp-declarative-java-sdk)** Annotation-driven MCP servers development with Java, no Spring Framework Required, minimize dependencies as much as possible.\n* **[MCP-Framework](https://mcp-framework.com)** Build MCP servers with elegance and speed in TypeScript. Comes with a CLI to create your project with `mcp create app`. Get started with your first server in under 5 minutes by **[Alex Andru](https://github.com/QuantGeekDev)**\n* **[MCP Plexus](https://github.com/Super-I-Tech/mcp_plexus)**: A secure, **multi-tenant** and Multi-user MCP python server framework built to integrate easily with external services via OAuth 2.1, offering scalable and robust solutions for managing complex AI applications.\n* **[mcp_sse (Elixir)](https://github.com/kEND/mcp_sse)** An SSE implementation in Elixir for rapidly creating MCP servers.\n* **[mxcp](https://github.com/raw-labs/mxcp)** (Python) - Open-source framework for building enterprise-grade MCP servers using just YAML, SQL, and Python, with built-in auth, monitoring, ETL and policy enforcement.\n* **[Next.js MCP Server Template](https://github.com/vercel-labs/mcp-for-next.js)** (Typescript) - A starter Next.js project that uses the MCP Adapter to allow MCP clients to connect and access resources.\n* **[PayMCP](https://github.com/blustAI/paymcp)** (Python & TypeScript) - Lightweight payments layer for MCP servers: turn tools into paid endpoints with a two-line decorator. [PyPI](https://pypi.org/project/paymcp/) · [npm](https://www.npmjs.com/package/paymcp) · [TS repo](https://github.com/blustAI/paymcp-ts)\n* **[Perl SDK](https://github.com/mojolicious/mojo-mcp)** - An SDK for building MCP servers and clients with the Perl programming language.\n* **[Quarkus MCP Server SDK](https://github.com/quarkiverse/quarkus-mcp-server)** (Java)\n- **[R mcptools](https://github.com/posit-dev/mcptools)** - An R SDK for creating R-based MCP servers and retrieving functionality from third-party MCP servers as R functions.\n* **[SAP ABAP MCP Server SDK](https://github.com/abap-ai/mcp)** - Build SAP ABAP based MCP servers. ABAP 7.52 based with 7.02 downport; runs on R/3 & S/4HANA on-premises, currently not cloud-ready.\n* **[Spring AI MCP Server](https://docs.spring.io/spring-ai/reference/api/mcp/mcp-server-boot-starter-docs.html)** - Provides auto-configuration for setting up an MCP server in Spring Boot applications.\n* **[Template MCP Server](https://github.com/mcpdotdirect/template-mcp-server)** - A CLI tool to create a new Model Context Protocol server project with TypeScript support, dual transport options, and an extensible structure\n* **[AgentR Universal MCP SDK](https://github.com/universal-mcp/universal-mcp)** - A python SDK to build MCP Servers with inbuilt credential management by **[Agentr](https://agentr.dev/home)**\n* **[Vercel MCP Adapter](https://github.com/vercel/mcp-adapter)** (TypeScript) - A simple package to start serving an MCP server on most major JS meta-frameworks including Next, Nuxt, Svelte, and more.\n* **[PHP MCP Server](https://github.com/php-mcp/server)** (PHP) - Core PHP implementation for the Model Context Protocol (MCP) server\n\n### For clients\n\n* **[codemirror-mcp](https://github.com/marimo-team/codemirror-mcp)** - CodeMirror extension that implements the Model Context Protocol (MCP) for resource mentions and prompt commands\n* **[llm-analysis-assistant](https://github.com/xuzexin-hz/llm-analysis-assistant)** <img height=\"12\" width=\"12\" src=\"https://raw.githubusercontent.com/xuzexin-hz/llm-analysis-assistant/refs/heads/main/src/llm_analysis_assistant/pages/html/imgs/favicon.ico\" alt=\"Langfuse Logo\" /> - A very streamlined mcp client that supports calling and monitoring stdio/sse/streamableHttp, and can also view request responses through the /logs page. It also supports monitoring and simulation of ollama/openai interface.\n* **[MCP-Agent](https://github.com/lastmile-ai/mcp-agent)** - A simple, composable framework to build agents using Model Context Protocol by **[LastMile AI](https://www.lastmileai.dev)**\n* **[Spring AI MCP Client](https://docs.spring.io/spring-ai/reference/api/mcp/mcp-client-boot-starter-docs.html)** - Provides auto-configuration for MCP client functionality in Spring Boot applications.\n* **[MCP CLI Client](https://github.com/vincent-pli/mcp-cli-host)** - A CLI host application that enables Large Language Models (LLMs) to interact with external tools through the Model Context Protocol (MCP).\n* **[OpenMCP Client](https://github.com/LSTM-Kirigaya/openmcp-client/)** - An all-in-one vscode/trae/cursor plugin for MCP server debugging. [Document](https://kirigaya.cn/openmcp/) & [OpenMCP SDK](https://kirigaya.cn/openmcp/sdk-tutorial/).\n* **[PHP MCP Client](https://github.com/php-mcp/client)** - Core PHP implementation for the Model Context Protocol (MCP) Client\n\n\n## 📚 Resources\n\nAdditional resources on MCP.\n\n- **[A2A-MCP Java Bridge](https://github.com/vishalmysore/a2ajava)** - A2AJava brings powerful A2A-MCP integration directly into your Java applications. It enables developers to annotate standard Java methods and instantly expose them as MCP Server, A2A-discoverable actions — with no boilerplate or service registration overhead.\n- **[AiMCP](https://www.aimcp.info)** - A collection of MCP clients&servers to find the right mcp tools by **[Hekmon](https://github.com/hekmon8)**\n- **[Awesome Crypto MCP Servers by badkk](https://github.com/badkk/awesome-crypto-mcp-servers)** - A curated list of MCP servers by **[Luke Fan](https://github.com/badkk)**\n- **[Awesome MCP Servers by appcypher](https://github.com/appcypher/awesome-mcp-servers)** - A curated list of MCP servers by **[Stephen Akinyemi](https://github.com/appcypher)**\n- **[Awesome MCP Servers by punkpeye](https://github.com/punkpeye/awesome-mcp-servers)** (**[website](https://glama.ai/mcp/servers)**) - A curated list of MCP servers by **[Frank Fiegel](https://github.com/punkpeye)**\n- **[Awesome MCP Servers by wong2](https://github.com/wong2/awesome-mcp-servers)** (**[website](https://mcpservers.org)**) - A curated list of MCP servers by **[wong2](https://github.com/wong2)**\n- **[Awesome Remote MCP Servers by JAW9C](https://github.com/jaw9c/awesome-remote-mcp-servers)** - A curated list of **remote** MCP servers, including their authentication support by **[JAW9C](https://github.com/jaw9c)**\n- **[Discord Server](https://glama.ai/mcp/discord)** – A community discord server dedicated to MCP by **[Frank Fiegel](https://github.com/punkpeye)**\n- **[Discord Server (ModelContextProtocol)](https://discord.gg/jHEGxQu2a5)** – Connect with developers, share insights, and collaborate on projects in an active Discord community dedicated to the Model Context Protocol by **[Alex Andru](https://github.com/QuantGeekDev)**\n- <img height=\"12\" width=\"12\" src=\"https://raw.githubusercontent.com/klavis-ai/klavis/main/static/klavis-ai.png\" alt=\"Klavis Logo\" /> **[Klavis AI](https://www.klavis.ai)** - Open Source MCP Infra. Hosted MCP servers and MCP clients on Slack and Discord.\n- **[MCP Badges](https://github.com/mcpx-dev/mcp-badges)** – Quickly highlight your MCP project with clear, eye-catching badges, by **[Ironben](https://github.com/nanbingxyz)**\n- **[MCPRepository.com](https://mcprepository.com/)** - A repository that indexes and organizes all MCP servers for easy discovery.\n- **[mcp-cli](https://github.com/wong2/mcp-cli)** - A CLI inspector for the Model Context Protocol by **[wong2](https://github.com/wong2)**\n- **[mcp-dockmaster](https://mcp-dockmaster.com)** - An Open-Sourced UI to install and manage MCP servers for Windows, Linux and macOS.\n- **[mcp-get](https://mcp-get.com)** - Command line tool for installing and managing MCP servers by **[Michael Latman](https://github.com/michaellatman)**\n- **[mcp-guardian](https://github.com/eqtylab/mcp-guardian)** - GUI application + tools for proxying / managing control of MCP servers by **[EQTY Lab](https://eqtylab.io)**\n- **[MCP Linker](https://github.com/milisp/mcp-linker)** - A cross-platform Tauri GUI tool for one-click setup and management of MCP servers, supporting Claude Desktop, Cursor, Windsurf, VS Code, Cline, and Neovim.\n- **[mcp-manager](https://github.com/zueai/mcp-manager)** - Simple Web UI to install and manage MCP servers for Claude Desktop by **[Zue](https://github.com/zueai)**\n- **[MCP Marketplace Web Plugin](https://github.com/AI-Agent-Hub/mcp-marketplace)** MCP Marketplace is a small Web UX plugin to integrate with AI applications, Support various MCP Server API Endpoint (e.g pulsemcp.com/deepnlp.org and more). Allowing user to browse, paginate and select various MCP servers by different categories. [Pypi](https://pypi.org/project/mcp-marketplace) | [Maintainer](https://github.com/AI-Agent-Hub) | [Website](http://www.deepnlp.org/store/ai-agent/mcp-server)\n- **[mcp.natoma.ai](https://mcp.natoma.ai)** – A Hosted MCP Platform to discover, install, manage and deploy MCP servers by **[Natoma Labs](https://www.natoma.ai)**\n- **[mcp.run](https://mcp.run)** - A hosted registry and control plane to install & run secure + portable MCP Servers.\n- **[MCPHub](https://www.mcphub.com)** - Website to list high quality MCP servers and reviews by real users. Also provide online chatbot for popular LLM models with MCP server support.\n- **[MCP Router](https://mcp-router.net)** – Free Windows and macOS app that simplifies MCP management while providing seamless app authentication and powerful log visualization by **[MCP Router](https://github.com/mcp-router/mcp-router)**\n- **[MCP Servers Hub](https://github.com/apappascs/mcp-servers-hub)** (**[website](https://mcp-servers-hub-website.pages.dev/)**) - A curated list of MCP servers by **[apappascs](https://github.com/apappascs)**\n- **[MCPServers.com](https://mcpservers.com)** - A growing directory of high-quality MCP servers with clear setup guides for a variety of MCP clients. Built by the team behind the **[Highlight MCP client](https://highlightai.com/)**\n- **[MCP Servers Rating and User Reviews](http://www.deepnlp.org/store/ai-agent/mcp-server)** - Website to rate MCP servers, write authentic user reviews, and [search engine for agent & mcp](http://www.deepnlp.org/search/agent)\n- **[MCP Sky](https://bsky.app/profile/brianell.in/feed/mcp)** - Bluesky feed for MCP related news and discussion by **[@brianell.in](https://bsky.app/profile/brianell.in)**\n- **[MCP X Community](https://x.com/i/communities/1861891349609603310)** – A X community for MCP by **[Xiaoyi](https://x.com/chxy)**\n- **[MCPHub](https://github.com/Jeamee/MCPHub-Desktop)** – An Open Source macOS & Windows GUI Desktop app for discovering, installing and managing MCP servers by **[Jeamee](https://github.com/jeamee)**\n- **[mcpm](https://github.com/pathintegral-institute/mcpm.sh)** ([website](https://mcpm.sh)) - MCP Manager (MCPM) is a Homebrew-like service for managing Model Context Protocol (MCP) servers across clients by **[Pathintegral](https://github.com/pathintegral-institute)**\n- **[MCPVerse](https://mcpverse.dev)** - A portal for creating & hosting authenticated MCP servers and connecting to them securely.\n- **[MCP Servers Search](https://github.com/atonomus/mcp-servers-search)** - An MCP server that provides tools for querying and discovering available MCP servers from this list.\n- **[Search MCP Server](https://github.com/krzysztofkucmierz/search-mcp-server)** - Recommends the most relevant MCP servers based on the client's query by searching this README file.\n- **[MCPWatch](https://github.com/kapilduraphe/mcp-watch)** - A comprehensive security scanner for Model Context Protocol (MCP) servers that detects vulnerabilities and security issues in your MCP server implementations.\n- <img height=\"12\" width=\"12\" src=\"https://mkinf.io/favicon-lilac.png\" alt=\"mkinf Logo\" /> **[mkinf](https://mkinf.io)** - An Open Source registry of hosted MCP Servers to accelerate AI agent workflows.\n- **[Open-Sourced MCP Servers Directory](https://github.com/chatmcp/mcp-directory)** - A curated list of MCP servers by **[mcpso](https://mcp.so)**\n- <img height=\"12\" width=\"12\" src=\"https://opentools.com/favicon.ico\" alt=\"OpenTools Logo\" /> **[OpenTools](https://opentools.com)** - An open registry for finding, installing, and building with MCP servers by **[opentoolsteam](https://github.com/opentoolsteam)**\n- **[PulseMCP](https://www.pulsemcp.com)** ([API](https://www.pulsemcp.com/api)) - Community hub & weekly newsletter for discovering MCP servers, clients, articles, and news by **[Tadas Antanavicius](https://github.com/tadasant)**, **[Mike Coughlin](https://github.com/macoughl)**, and **[Ravina Patel](https://github.com/ravinahp)**\n- **[r/mcp](https://www.reddit.com/r/mcp)** – A Reddit community dedicated to MCP by **[Frank Fiegel](https://github.com/punkpeye)**\n- **[r/modelcontextprotocol](https://www.reddit.com/r/modelcontextprotocol)** – A Model Context Protocol community Reddit page - discuss ideas, get answers to your questions, network with like-minded people, and showcase your projects! by **[Alex Andru](https://github.com/QuantGeekDev)**\n- **[MCP.ing](https://mcp.ing/)** - A list of MCP services for discovering MCP servers in the community and providing a convenient search function for MCP services by **[iiiusky](https://github.com/iiiusky)**\n- **[MCP Hunt](https://mcp-hunt.com)** - Realtime platform for discovering trending MCP servers with momentum tracking, upvoting, and community discussions - like Product Hunt meets Reddit for MCP\n- **[Smithery](https://smithery.ai/)** - A registry of MCP servers to find the right tools for your LLM agents by **[Henry Mao](https://github.com/calclavia)**\n- **[Toolbase](https://gettoolbase.ai)** - Desktop application that manages tools and MCP servers with just a few clicks - no coding required by **[gching](https://github.com/gching)**\n- **[ToolHive](https://github.com/StacklokLabs/toolhive)** - A lightweight utility designed to simplify the deployment and management of MCP servers, ensuring ease of use, consistency, and security through containerization by **[StacklokLabs](https://github.com/StacklokLabs)**\n- **[NetMind](https://www.netmind.ai/AIServices)** - Access powerful AI services via simple APIs or MCP servers to supercharge your productivity.\n\n## 🚀 Getting Started\n\n### Using MCP Servers in this Repository\nTypeScript-based servers in this repository can be used directly with `npx`.\n\nFor example, this will start the [Memory](src/memory) server:\n```sh\nnpx -y @modelcontextprotocol/server-memory\n```\n\nPython-based servers in this repository can be used directly with [`uvx`](https://docs.astral.sh/uv/concepts/tools/) or [`pip`](https://pypi.org/project/pip/). `uvx` is recommended for ease of use and setup.\n\nFor example, this will start the [Git](src/git) server:\n```sh\n# With uvx\nuvx mcp-server-git\n\n# With pip\npip install mcp-server-git\npython -m mcp_server_git\n```\n\nFollow [these](https://docs.astral.sh/uv/getting-started/installation/) instructions to install `uv` / `uvx` and [these](https://pip.pypa.io/en/stable/installation/) to install `pip`.\n\n### Using an MCP Client\nHowever, running a server on its own isn't very useful, and should instead be configured into an MCP client. For example, here's the Claude Desktop configuration to use the above server:\n\n```json\n{\n  \"mcpServers\": {\n    \"memory\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-memory\"]\n    }\n  }\n}\n```\n\nAdditional examples of using the Claude Desktop as an MCP client might look like:\n\n```json\n{\n  \"mcpServers\": {\n    \"filesystem\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-filesystem\", \"/path/to/allowed/files\"]\n    },\n    \"git\": {\n      \"command\": \"uvx\",\n      \"args\": [\"mcp-server-git\", \"--repository\", \"path/to/git/repo\"]\n    },\n    \"github\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-github\"],\n      \"env\": {\n        \"GITHUB_PERSONAL_ACCESS_TOKEN\": \"<YOUR_TOKEN>\"\n      }\n    },\n    \"postgres\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-postgres\", \"postgresql://localhost/mydb\"]\n    }\n  }\n}\n```\n\n## 🛠️ Creating Your Own Server\n\nInterested in creating your own MCP server? Visit the official documentation at [modelcontextprotocol.io](https://modelcontextprotocol.io/introduction) for comprehensive guides, best practices, and technical details on implementing MCP servers.\n\n## 🤝 Contributing\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md) for information about contributing to this repository.\n\n## 🔒 Security\n\nSee [SECURITY.md](SECURITY.md) for reporting security vulnerabilities.\n\n## 📜 License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## 💬 Community\n\n- [GitHub Discussions](https://github.com/orgs/modelcontextprotocol/discussions)\n\n## ⭐ Support\n\nIf you find MCP servers useful, please consider starring the repository and contributing new servers or improvements!\n\n---\n\nManaged by Anthropic, but built together with the community. The Model Context Protocol is open source and we encourage everyone to contribute their own servers and improvements!",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "modelcontextprotocol",
        "monitoring",
        "logging",
        "modelcontextprotocol servers",
        "logging modelcontextprotocol",
        "monitoring logging"
      ],
      "category": "monitoring-and-logging"
    },
    "monsterxx03--gospy": {
      "owner": "monsterxx03",
      "name": "gospy",
      "url": "https://github.com/monsterxx03/gospy",
      "imageUrl": "/freedevtools/mcp/pfp/monsterxx03.webp",
      "description": "Inspect and analyze running Go processes, providing detailed information about goroutines, memory usage, and binary data through an interactive terminal and an HTTP API. Features include programmatic access via a Server-Sent Events endpoint and tools for inspecting goroutine states and memory statistics.",
      "stars": 92,
      "forks": 4,
      "license": "MIT License",
      "language": "Go",
      "updated_at": "2025-08-23T12:55:59Z",
      "readme_content": "# Go Process Inspector\n\n[![Go Report Card](https://goreportcard.com/badge/github.com/monsterxx03/gospy)](https://goreportcard.com/report/github.com/monsterxx03/gospy)\n[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)\n[![Install MCP Server](https://cursor.com/deeplink/mcp-install-dark.svg)](https://cursor.com/install-mcp?name=gospy&config=eyJ1cmwiOiJodHRwOi8vbG9jYWxob3N0Ojg5NzQvbWNwIn0%3D)\n\nA tool for inspecting and analyzing running Go processes, including goroutine states, memory statistics, and binary information.\n\n## Features\n\n- View detailed goroutine information (status, scheduling info)\n- Analyze process memory statistics\n- Cross-platform support (Linux and macOS)\n- Terminal UI for interactive inspection\n- HTTP API for programmatic access\n- mcp server\n\n## Installation\n\n```bash\ngo install github.com/monsterxx03/gospy@latest\n```\n\n## Usage\n\n### CLI Interface\n\n```bash\n# Interactive terminal UI\nsudo gospy top --pid <pid>\n\n# HTTP API server\nsudo gospy serve --port 8974\n\n# Get process summary\nsudo gospy summary --pid <pid>\n\n# Get process summary in JSON format\nsudo gospy summary --pid <pid> --json\n```\n\n#### Summary Command Options\n- `--pid/-p` - Target process ID (required)\n- `--bin/-b` - Path to binary file (optional)\n- `--json/-j` - Output results in JSON format\n\n### API Endpoints\n\n- `GET /goroutines?pid=<pid>` - List all goroutines\n- `GET /memstats?pid=<pid>` - Get memory statistics\n- `GET /runtime?pid=<pid>` - Get runtime version info\n\n### MCP Server\n\nThe MCP server provides an http (streamableHTTP) endpoint. To enable:\n\n```bash\n>>> sudo gospy serve --enable-mcp --port 8974\n\nStarting API server on port 8974\nEndpoints:\n  GET /runtime?pid=<PID>     - Get runtime info\n  GET /goroutines?pid=<PID> - Get goroutines list\n  GET /memstats?pid=<PID>   - Get memory stats\n  GET /mcp   - MCP http endpoint\n\n```\n\nAvailable MCP tools:\n- `goroutines` - Dump goroutines for a go process\n- `gomemstats` - Dump memory stats for a go process\n- `goruntime`  - Dump runtime info for a go process\n- `pgrep`      - Find pid from process name\n\nConfig in cursor\n\n\n\n\n### Terminal UI Controls\n\n- `q` - Quit\n- `r` - Refresh data\n- `s` - Suspend/Resume top view\n- `/` - Search/filter goroutines\n\n### Terminal UI Screenshot\n\n\n\n## Building from Source\n\n```bash\ngit clone https://github.com/monsterxx03/gospy.git\ncd gospy\nmake\n```\n\n## Requirements\n\n- Go 1.20+\n- Linux or macOS (Apple Silicon only)\n- Root privileges (required for memory access)\n\n## Root Privileges\n\ngospy requires root privileges to:\n- Read process memory (/proc/<pid>/mem on Linux)\n- Access Mach APIs on macOS\n\nRun with sudo:\n```bash\nsudo gospy top --pid <pid>\n```\n\nFor development/debugging, you may want to:\n1. Build the binary first: `make`\n2. Run with sudo: `sudo ./gospy [command]`\n\n## Credits\n\nVersion 0.7.0 was completely rewritten from scratch with [aider](https://aider.chat), which wrote >90% of the code. Additional assistance from:\n- [DeepSeek](https://deepseek.com) (R1 + V3 models) - AI coding assistant\n\nTotal AI compute cost: ~$2 USD\n\n## License\n\nMIT - See [LICENSE](LICENSE) file for details.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "gospy",
        "goroutine",
        "goroutines",
        "inspecting goroutine",
        "gospy inspect",
        "goroutines memory"
      ],
      "category": "monitoring-and-logging"
    },
    "mottibec--otelcol-mcp": {
      "owner": "mottibec",
      "name": "otelcol-mcp",
      "url": "https://github.com/mottibec/otelcol-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/mottibec.webp",
      "description": "Configures OpenTelemetry Collectors dynamically by managing components such as receivers, processors, and exporters. Facilitates the updating and retrieval of telemetry component information from specified resources.",
      "stars": 43,
      "forks": 1,
      "license": "GNU General Public License v3.0",
      "language": "TypeScript",
      "updated_at": "2025-08-14T14:18:15Z",
      "readme_content": "# OpenTelemetry Collector MCP Server\n\nAn MCP server implementation for configuring OpenTelemetry Collectors.\n\n## Features\n\n- **Dynamic OpenTelemetry Configuration**: Configure OpenTelemetry Collectors through MCP tools\n- **Component Management**: Add, remove, and configure receivers, processors, and exporters\n\n## Tools\n\n- **Update Resources**\n  - Updates local resource files with the latest component information from GitHub\n  - No input parameters required\n  - Returns statistics about updated components (receivers, processors, exporters)\n\n## Resources\n\n- **Receivers** (`receivers://receivers`)\n  - Lists all available OpenTelemetry receivers\n  - Returns receiver metadata including name, description, and stability\n\n- **Processors** (`processors://processors`)\n  - Lists all available OpenTelemetry processors\n  - Returns processor metadata including name, description, and stability\n\n- **Exporters** (`exporters://exporters`)\n  - Lists all available OpenTelemetry exporters\n  - Returns exporter metadata including name, description, and stability\n\n- **Component Schemas** (`component://{type}/{name}`)\n  - Retrieves configuration schema for specific components\n  - Supports listing all available schemas or getting a specific component's schema\n  - Parameters:\n    - `type`: Component type (\"receiver\", \"processor\", or \"exporter\")\n    - `name`: Name of the specific component (optional)\n\n## Configuration\n\n### Usage with mcp clients\n\nAdd this to your `mcp.json`:\n\n```json\n{\n    \"mcpServers\": {\n      \"otelcol\": {\n        \"url\": \"http://localhost:3001/sse\"\n      }\n    }\n}\n```\n\n## Development\n\nThis is a local implementation of an MCP server for OpenTelemetry configuration. To use it:\n\n1. Clone the repository\n2. Build the project using the provided build scripts\n3. Configure your MCP client to use the local server implementation\n\n## License\n\nThis MCP server is licensed under the GPL-3.0 License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the GPL-3.0 License. For more details, please see the LICENSE file in the project repository.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "opentelemetry",
        "telemetry",
        "monitoring",
        "opentelemetry collectors",
        "configures opentelemetry",
        "logging mottibec"
      ],
      "category": "monitoring-and-logging"
    },
    "muaimingjun--LinuxCTS": {
      "owner": "muaimingjun",
      "name": "LinuxCTS",
      "url": "https://github.com/muaimingjun/LinuxCTS",
      "imageUrl": "/freedevtools/mcp/pfp/muaimingjun.webp",
      "description": "A comprehensive testing script for Linux systems that evaluates system performance, configuration, and service status through various tests. It provides insights into system information, conducts performance and network tests, and checks the operational status of common services.",
      "stars": 0,
      "forks": 1,
      "license": "No License",
      "language": "Shell",
      "updated_at": "2025-08-17T06:54:45Z",
      "readme_content": "# LinuxCTS - Linux 综合测试脚本\n\n## 项目简介\n\nLinuxCTS 是一个用于 Linux 系统的综合测试脚本，旨在帮助用户快速、方便地对 Linux 系统进行多方面的测试，以评估系统的性能、配置和功能完整性。该脚本整合了一系列实用的测试功能，能够满足不同场景下对 Linux 系统的检测需求。\n\n## 功能特性\n\n- **系统信息检测**：全面展示 Linux 系统的基本信息，包括内核版本、操作系统发行版、CPU 信息、内存信息等，让用户对系统硬件和软件配置一目了然。\n- **性能测试**：具备多种性能测试功能，如 CPU 性能测试、内存读写速度测试、磁盘 I/O 性能测试等，帮助用户评估系统在不同负载下的性能表现。\n- **网络测试**：可以检测网络连接状态、网络速度测试、端口扫描等，方便用户排查网络相关问题，确保网络配置正确且稳定。\n- **服务状态检查**：检查常见系统服务（如 SSH、HTTP、FTP 等）的运行状态，确保服务正常运行，保障系统的可用性。\n\n## 安装与使用\n\n## 依赖\n\n```bash\n# ubuntu/debian\nsudo apt update && sudo apt install curl -y && sudo su\n# readhat/centos\nsudo yum update && sudo yum install curl -y && sudo su\n```\n\n### 一键脚本 （临时使用）\n\n```bash\nsource <(curl -s https://gitee.com/muaimingjun/LinuxCTS/raw/main/linux.sh)\n```\n\n## 安装到系统里\n\n```bash\n# 如何安装？\nsudo curl -L https://gitee.com/muaimingjun/LinuxCTS/raw/main/linux.sh > /usr/bin/linux && sudo chmod +x /usr/bin/linux\n# 如何使用\nlinux\n# 如何更新？\nsudo curl -L https://gitee.com/muaimingjun/LinuxCTS/raw/main/linux.sh > /usr/bin/linux && sudo chmod +x /usr/bin/linux\n# 如何卸载\nsudo rm -rf /usr/bin/linux\n```\n\n## 项目结构\n\n- **`app/`**：可能存放与应用程序相关的测试脚本或配置文件（具体功能可能因项目而异）。\n- **`os/`**：用于存放与操作系统相关的测试模块，例如系统信息获取、系统服务检测等功能的实现代码。\n- **`tools/`**：包含一些辅助工具或脚本，用于支持主脚本的功能实现，如性能测试工具、网络测试工具等。\n- **`.gitignore`**：指定了哪些文件或目录不需要被 Git 版本控制系统跟踪，例如临时文件、编译生成的文件等。\n- **`README.md`**：项目的说明文档，即你正在阅读的此文件，用于向用户介绍项目的功能、安装使用方法等信息。\n- **`linux.sh`**：主脚本文件，整合了各种测试功能，是整个项目的核心执行文件。\n\n## 贡献指南\n\n1. 欢迎大家对本项目进行贡献！如果你有任何改进建议或新功能想法，请先 Fork 本项目到你的 GitHub 账号。\n2. 创建一个新的分支，分支命名建议遵循`feature/你的功能名称`或`bugfix/你的bug修复名称`的格式，以便清晰区分不同类型的贡献。\n3. 在新分支上进行代码修改和开发，确保你的代码符合项目的代码风格和规范。\n4. 提交你的修改时，请提供清晰明了的提交信息，描述修改的内容和目的。\n5. 将你的分支推送到你的 GitHub 仓库，然后发起一个 Pull Request 到本项目的主仓库，详细说明你的修改内容和期望的合并原因，等待项目维护者进行审核和合并。\n\n## 许可证\n\n本项目遵循开源协议，具体许可证信息可查看项目中的 LICENSE 文件\n\n## 联系我们\n\n如果你在使用过程中遇到问题或有任何建议，欢迎通过以下方式联系我们：\n\n- **项目原作者**：[muaimingjun](https://gitee.com/muaimingjun)\n- **致谢作者**：[xccado](https://github.com/xccado/LinuxCTS)\n\n感谢你使用 LinuxCTS！希望这个脚本能够帮助你更好地管理和优化你的 Linux 系统。如果你发现任何问题或有改进的想法，请随时贡献你的力量。",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "monitoring",
        "logging",
        "linux",
        "muaimingjun linuxcts",
        "logging muaimingjun",
        "monitoring logging"
      ],
      "category": "monitoring-and-logging"
    },
    "ndevvy--mcp-server-datadog": {
      "owner": "ndevvy",
      "name": "mcp-server-datadog",
      "url": "https://github.com/ndevvy/mcp-server-datadog",
      "imageUrl": "/freedevtools/mcp/pfp/ndevvy.webp",
      "description": "Retrieve and manage incidents, monitors, logs, dashboards, metrics, traces, hosts, and downtimes from Datadog for enhanced incident management and observability workflows.",
      "stars": 2,
      "forks": 0,
      "license": "Apache License 2.0",
      "language": "TypeScript",
      "updated_at": "2025-05-07T04:28:12Z",
      "readme_content": "# Datadog MCP Server\n\nMCP server for the Datadog API, enabling incident management and more. Forked from https://github.com/winor30/mcp-server-datadog\n\n## Features\n\n- **Observability Tools**: Provides a mechanism to leverage key Datadog monitoring features, such as incidents, monitors, logs, dashboards, and metrics, through the MCP server.\n- **Extensible Design**: Designed to easily integrate with additional Datadog APIs, allowing for seamless future feature expansion.\n\n## Tools\n\n1. `list_incidents`\n\n   - Retrieve a list of incidents from Datadog.\n   - **Inputs**:\n     - `pageSize` (optional number): Maximum number of incidents to return per page.\n     - `pageOffset` (optional number): Offset for pagination.\n   - **Returns**: Array of Datadog incidents and associated metadata.\n\n2. `get_incident`\n\n   - Retrieve detailed information about a specific Datadog incident.\n   - **Inputs**:\n     - `incidentId` (string): Incident ID to fetch details for.\n   - **Returns**: Detailed incident information (title, status, timestamps, etc.).\n\n3. `get_monitors`\n\n   - Fetch the status of Datadog monitors.\n   - **Inputs**:\n     - `groupStates` (optional array): States to filter (e.g., alert, warn, no data, ok).\n     - `name` (optional string): Filter by name.\n     - `tags` (optional array): Filter by tags.\n   - **Returns**: Monitors data and a summary of their statuses.\n\n4. `get_logs`\n\n   - Search and retrieve logs from Datadog.\n   - **Inputs**:\n     - `query` (optional string): Datadog logs query string.\n     - `from` (number): Start time in epoch seconds.\n     - `to` (number): End time in epoch seconds.\n     - `limit` (optional number): Maximum number of logs to return (defaults to 100).\n   - **Returns**: Array of matching logs.\n\n5. `list_dashboards`\n\n   - Get a list of dashboards from Datadog.\n   - **Inputs**:\n     - `name` (optional string): Filter dashboards by name.\n     - `tags` (optional array): Filter dashboards by tags.\n   - **Returns**: Array of dashboards with URL references.\n\n6. `get_dashboard`\n\n   - Retrieve a specific dashboard from Datadog.\n   - **Inputs**:\n     - `dashboardId` (string): ID of the dashboard to fetch.\n   - **Returns**: Dashboard details including title, widgets, etc.\n\n7. `create_dashboard`\n\n   - Create a new dashboard in Datadog.\n   - **Inputs**:\n     - `title` (string): The title of the dashboard.\n     - `description` (optional string): The description of the dashboard.\n     - `layoutType` (optional string): The layout type ('ordered' or 'free', defaults to 'ordered').\n     - `widgets` (optional array): The widgets to add to the dashboard.\n     - `tags` (optional array): A list of tags to associate with the dashboard.\n   - **Returns**: Details of the created dashboard including ID and URL.\n\n8. `query_metrics`\n\n   - Retrieve metrics data from Datadog.\n   - **Inputs**:\n     - `query` (string): Metrics query string (e.g., \"avg:system.cpu.user{\\*}\").\n     - `from` (number): Start time in epoch seconds.\n     - `to` (number): End time in epoch seconds.\n   - **Returns**: Metrics data for the queried timeframe.\n\n9. `get_metric_metadata`\n\n   - Get metadata for a specific metric from Datadog.\n   - **Inputs**:\n     - `metricName` (string): Name of the metric to get metadata for.\n   - **Returns**: Metadata information for the specified metric.\n\n10. `get_active_metrics`\n\n    - Get a list of active metrics with optional filtering by host, tags, and search query.\n    - **Inputs**:\n      - `query` (string): Search query string to find metrics.\n      - `from` (optional number): Unix timestamp from which to start the query (default: 24 hours ago).\n      - `host` (optional string): Filter metrics by host.\n      - `tagFilter` (optional string): Filter metrics by tags (e.g. \"env:prod,region:us-east\").\n    - **Returns**: List of metrics matching the search query and/or active metrics based on filters.\n\n11. `analyze_tag_relationships`\n\n    - Show hierarchical relationships between tags across metrics.\n    - **Inputs**:\n      - `from` (optional number): Unix timestamp from which to start analyzing tags (default: now - 1 day).\n      - `limit` (optional number): Maximum number of tag relationships to analyze (default: 50).\n      - `metricPrefix` (optional string): Optional prefix to filter metrics by (e.g., \"system.\" or \"aws.\").\n    - **Returns**: Analysis of tag relationships showing how tags are related hierarchically.\n\n12. `analyze_tag_cardinality`\n\n    - Identify high-cardinality tags that might cause performance issues.\n    - **Inputs**:\n      - `from` (optional number): Unix timestamp from which to start analyzing tags (default: now - 1 day).\n      - `limit` (optional number): Maximum number of tags to analyze (default: 50).\n      - `metricPrefix` (optional string): Optional prefix to filter metrics by (e.g., \"system.\" or \"aws.\").\n      - `minCardinality` (optional number): Minimum cardinality threshold to report (default: 10).\n    - **Returns**: Analysis of high-cardinality tags that could impact performance.\n\n13. `visualize_tag_co_occurrence`\n\n    - Visualize which tags frequently appear together for a specific metric.\n    - **Inputs**:\n      - `metricName` (string): Name of the metric to analyze tags for.\n      - `from` (optional number): Unix timestamp from which to start analyzing tags (default: now - 1 day).\n      - `limit` (optional number): Maximum number of tag pairs to analyze (default: 20).\n    - **Returns**: Visualization of tag co-occurrence patterns for the specified metric.\n\n14. `search_events`\n\n    - Search for events in Datadog.\n    - **Inputs**:\n      - `query` (string): Datadog events query string.\n      - `from` (optional string): Start time as string - either epoch seconds or relative time (e.g., \"now-40m\") (default: \"now-24h\").\n      - `to` (optional string): End time as string - either epoch seconds or relative time (e.g., \"now\") (default: \"now\").\n      - `limit` (optional number): Maximum number of events to return (default: 100).\n      - `sort` (optional string): Sort order for events (default: \"-timestamp\").\n    - **Returns**: Array of matching events from Datadog.\n\n15. `list_traces`\n\n    - Retrieve a list of APM traces from Datadog.\n    - **Inputs**:\n      - `query` (string): Datadog APM trace query string.\n      - `from` (number): Start time in epoch seconds.\n      - `to` (number): End time in epoch seconds.\n      - `limit` (optional number): Maximum number of traces to return (defaults to 100).\n      - `sort` (optional string): Sort order for traces (defaults to '-timestamp').\n      - `service` (optional string): Filter by service name.\n      - `operation` (optional string): Filter by operation name.\n    - **Returns**: Array of matching traces from Datadog APM.\n\n16. `list_apm_services`\n\n    - Get list of APM services from Datadog.\n    - **Inputs**:\n      - `limit` (optional number): Maximum number of services to return (defaults to 100).\n    - **Returns**: List of available APM services.\n\n17. `list_apm_resources`\n\n    - Get list of APM resources for a specific service from Datadog.\n    - **Inputs**:\n      - `service` (string): Service name to filter resources by.\n      - `entry_spans_only` (optional boolean): Filter to only show service entry spans.\n      - `limit` (optional number): Maximum number of resources to return (defaults to 100).\n      - `search_query` (optional string): Search query to filter resource names by.\n    - **Returns**: List of resources for the specified service.\n\n18. `list_apm_operations`\n\n    - Get list of top operation names for a specific service from Datadog.\n    - **Inputs**:\n      - `service` (string): Service name to filter operations by.\n      - `entry_spans_only` (optional boolean): Filter to only show service entry spans.\n      - `limit` (optional number): Maximum number of operations to return (defaults to 100).\n    - **Returns**: List of operation names for the specified service.\n\n19. `get_resource_hash`\n\n    - Get the resource hash for a specific resource name within a service.\n    - **Inputs**:\n      - `service` (string): Service name the resource belongs to.\n      - `resource_name` (string): Resource name to get the hash for.\n    - **Returns**: Resource hash information.\n\n20. `get_all_services`\n\n    - Extract all unique service names from logs.\n    - **Inputs**:\n      - `from` (optional number): Start time in epoch seconds (defaults to 24 hours ago).\n      - `to` (optional number): End time in epoch seconds (defaults to current time).\n      - `limit` (optional number): Maximum number of logs to search through (defaults to 1000).\n      - `query` (optional string): Optional query filter for log search.\n    - **Returns**: List of unique service names found in logs.\n\n21. `list_hosts`\n\n    - Get list of hosts from Datadog.\n    - **Inputs**:\n      - `filter` (optional string): Filter string for search results.\n      - `sort_field` (optional string): Field to sort hosts by.\n      - `sort_dir` (optional string): Sort direction (asc/desc).\n      - `start` (optional number): Starting offset for pagination.\n      - `count` (optional number): Max number of hosts to return (max: 1000).\n      - `from` (optional number): Search hosts from this UNIX timestamp.\n      - `include_muted_hosts_data` (optional boolean): Include muted hosts status and expiry.\n      - `include_hosts_metadata` (optional boolean): Include host metadata (version, platform, etc).\n    - **Returns**: Array of hosts with details.\n\n22. `get_active_hosts_count`\n\n    - Get the total number of active hosts in Datadog.\n    - **Inputs**:\n      - `from` (optional number): Number of seconds from which you want to get total number of active hosts (defaults to 2h).\n    - **Returns**: Count of total active and up hosts.\n\n23. `mute_host`\n\n    - Mute a host in Datadog.\n    - **Inputs**:\n      - `hostname` (string): The name of the host to mute.\n      - `message` (optional string): Message to associate with the muting of this host.\n      - `end` (optional number): POSIX timestamp for when the mute should end.\n      - `override` (optional boolean): If true and the host is already muted, replaces existing end time.\n    - **Returns**: Success status and confirmation message.\n\n24. `unmute_host`\n\n    - Unmute a host in Datadog.\n    - **Inputs**:\n      - `hostname` (string): The name of the host to unmute.\n    - **Returns**: Success status and confirmation message.\n\n25. `list_notebooks`\n\n    - Get list of notebooks from Datadog.\n    - **Inputs**:\n      - `query` (optional string): Return only notebooks with this query string in notebook name or author handle.\n      - `authorHandle` (optional string): Return notebooks created by the given author handle.\n      - `excludeAuthorHandle` (optional string): Return notebooks not created by the given author handle.\n      - `start` (optional number): The index of the first notebook to return.\n      - `count` (optional number): The number of notebooks to be returned.\n      - `sortField` (optional string): Sort by field (modified, name, created).\n      - `sortDir` (optional string): Sort direction (asc, desc).\n      - `type` (optional string): Return only notebooks with that metadata type.\n      - `isTemplate` (optional boolean): True value returns only template notebooks.\n      - `includeCells` (optional boolean): Value of false excludes the cells and global time for each notebook.\n    - **Returns**: List of notebooks matching the specified criteria.\n\n26. `get_notebook`\n\n    - Get a notebook from Datadog.\n    - **Inputs**:\n      - `notebookId` (number): Unique ID of the notebook to retrieve.\n    - **Returns**: Details of the requested notebook including cells and metadata.\n\n27. `create_notebook`\n\n    - Create a new notebook in Datadog.\n    - **Inputs**:\n      - `name` (string): The name of the notebook.\n      - `cells` (optional array): Cells to include in the notebook.\n      - `time` (optional string): Time settings for the notebook (defaults to '1h').\n      - `metadata` (optional object): Additional metadata for the notebook.\n    - **Returns**: Details of the created notebook.\n\n28. `add_cell_to_notebook`\n\n    - Add a cell to an existing Datadog notebook.\n    - **Inputs**:\n      - `notebookId` (number): The ID of the notebook to add the cell to.\n      - `cell` (object): The cell definition to add.\n    - **Returns**: Updated notebook information.\n\n29. `list_downtimes`\n\n    - List scheduled downtimes from Datadog.\n    - **Inputs**:\n      - `currentOnly` (optional boolean): Return only currently active downtimes when true.\n    - **Returns**: Array of scheduled downtimes with details.\n\n30. `schedule_downtime`\n\n    - Schedule a downtime in Datadog.\n    - **Inputs**:\n      - `scope` (string): Scope to apply downtime to (e.g. 'host:my-host').\n      - `start` (optional number): UNIX timestamp for the start of the downtime.\n      - `end` (optional number): UNIX timestamp for the end of the downtime.\n      - `message` (optional string): A message to include with the downtime.\n      - `timezone` (optional string): The timezone for the downtime.\n      - `monitorId` (optional number): The ID of the monitor to mute.\n      - `monitorTags` (optional array): A list of monitor tags for filtering.\n      - `recurrence` (optional object): Recurrence settings for the downtime.\n    - **Returns**: Scheduled downtime details including ID and active status.\n\n31. `cancel_downtime`\n    - Cancel a scheduled downtime in Datadog.\n    - **Inputs**:\n      - `downtimeId` (number): The ID of the downtime to cancel.\n    - **Returns**: Confirmation of downtime cancellation.\n\n## Setup\n\n### Datadog Credentials\n\nYou need valid Datadog API credentials to use this MCP server:\n\n- `DATADOG_API_KEY`: Your Datadog API key\n- `DATADOG_APP_KEY`: Your Datadog Application key\n- `DATADOG_SITE` (optional): The Datadog site (e.g. `datadoghq.eu`)\n\nExport them in your environment before running the server:\n\n```bash\nexport DATADOG_API_KEY=\"your_api_key\"\nexport DATADOG_APP_KEY=\"your_app_key\"\nexport DATADOG_SITE=\"your_datadog_site\"\n```\n\n## Installation\n\n### Installing via Smithery\n\nTo install Datadog MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@ndevvy/mcp-server-datadog):\n\n```bash\nnpx -y @smithery/cli install @ndevvy/mcp-server-datadog --client claude\n```\n\n### Manual Installation\n\n```bash\npnpm install\npnpm build\npnpm watch   # for development with auto-rebuild\n```\n\n## Usage\n\nAdd to your `claude_desktop_config.json` or `.cursor/mcp.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"datadog\": {\n      \"command\": \"/path/to/mcp-server-datadog/build/index.js\",\n      \"env\": {\n        \"DATADOG_API_KEY\": \"<YOUR_API_KEY>\",\n        \"DATADOG_APP_KEY\": \"<YOUR_APP_KEY>\",\n        \"DATADOG_SITE\": \"<YOUR_SITE>\" // Optional\n      }\n    }\n  }\n}\n```\n\n## Debugging\n\nBecause MCP servers communicate over standard input/output, debugging can sometimes be tricky. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector). You can run the inspector with:\n\n```bash\nnpm run inspector\n```\n\nThe inspector will provide a URL you can open in your browser to see logs and send requests manually.\n\n## License\n\nThis project is licensed under the [Apache License, Version 2.0](./LICENSE).\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "datadog",
        "logging",
        "monitoring",
        "server datadog",
        "logging ndevvy",
        "datadog enhanced"
      ],
      "category": "monitoring-and-logging"
    },
    "posidron--mcp-powershell": {
      "owner": "posidron",
      "name": "mcp-powershell",
      "url": "https://github.com/posidron/mcp-powershell",
      "imageUrl": "/freedevtools/mcp/pfp/posidron.webp",
      "description": "Execute PowerShell commands and scripts, retrieve system information, and manage PowerShell modules. Enhance automation and system management workflows by integrating PowerShell capabilities directly within an LLM environment.",
      "stars": 1,
      "forks": 1,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-05-09T17:11:59Z",
      "readme_content": "# PowerShell MCP Server\n\nA Model Context Protocol server for interacting with PowerShell. This server provides tools for executing PowerShell commands, retrieving system information, managing modules, and more.\n\n## Requirements\n\n- Node.js 18+\n- PowerShell 5.1 or PowerShell Core 7+\n\n## Installation\n\n1. Install dependencies:\n   ```bash\n   npm install\n   ```\n\n2. Build the project:\n   ```bash\n   npm run build\n   ```\n\n## Configuration\n\n### For Claude Desktop\nEdit config: `$HOME/Library/Application\\ Support/Claude/claude_desktop_config.json`\n\nAdd to mcpServers:\n```json\n{\n  \"mcpServers\": {\n    \"mcp-powershell\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/absolute/path/to/mcp-powershell/dist/index.js\"\n      ]\n    }\n  }\n}\n```\n\n### For VS Code\nEdit config: `$HOME/Library/Application\\ Support/Code/User/settings.json`\n\nAdd to settings:\n```json\n\"mcp\": {\n  \"servers\": {\n    \"mcp-powershell\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/absolute/path/to/mcp-powershell/dist/index.js\"\n      ]\n    }\n  }\n}\n```\n\n### For Cursor IDE\nEdit config: `$HOME/.cursor/mcp.json`\n\nAdd to mcpServers:\n```json\n{\n  \"mcpServers\": {\n    \"mcp-powershell\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/absolute/path/to/mcp-powershell/dist/index.js\"\n      ]\n    }\n  }\n}\n```\n\n## Available Tools\n\nThis PowerShell MCP server provides the following tools:\n\n### execute_ps\nExecute a PowerShell command and get the result.\n\n```\nParameters:\n- command (string): PowerShell command to execute\n```\n\nExample usage:\n```\nexecute_ps(command: \"Get-Process | Select-Object -First 5\")\n```\n\n### get_system_info\nRetrieve detailed system information, including OS details, processor, memory, and PowerShell version.\n\n```\nParameters: None\n```\n\nExample usage:\n```\nget_system_info()\n```\n\n### list_modules\nList all installed PowerShell modules with details like name, version, and type.\n\n```\nParameters: None\n```\n\nExample usage:\n```\nlist_modules()\n```\n\n### get_command_help\nGet detailed help for a specific PowerShell command, including syntax, parameters, and examples.\n\n```\nParameters:\n- command (string): PowerShell command to get help for\n```\n\nExample usage:\n```\nget_command_help(command: \"Get-Process\")\n```\n\n### find_commands\nSearch for PowerShell commands by name or pattern.\n\n```\nParameters:\n- search (string): Search term for PowerShell commands\n```\n\nExample usage:\n```\nfind_commands(search: \"Process\")\n```\n\n### run_script\nRun a PowerShell script file with optional parameters.\n\n```\nParameters:\n- scriptPath (string): Path to the PowerShell script file\n- parameters (string, optional): Optional parameters to pass to the script\n```\n\nExample usage:\n```\nrun_script(scriptPath: \"/path/to/script.ps1\", parameters: \"-Name 'Test' -Value 123\")\n```\n\n## Development\n\nTo run in development mode:\n```bash\nnpm run dev\n```\n\n## Extending the Server\n\nTo add your own PowerShell tools:\n\n1. Edit `src/index.ts`\n2. Add new tools in the `registerTools()` method\n3. Follow the existing pattern for consistent error handling\n4. Build with `npm run build`\n\n### Adding a Tool Example\n\n```typescript\n// In the registerTools() method:\nthis.server.tool(\n  \"my_ps_tool\",\n  {\n    param1: z.string().describe(\"Description of parameter 1\"),\n    param2: z.number().optional().describe(\"Optional numeric parameter\"),\n  },\n  async ({ param1, param2 }) => {\n    try {\n      // Your PowerShell command\n      const command = `Your-PowerShell-Command -Param1 \"${param1}\" ${param2 ? `-Param2 ${param2}` : ''}`;\n\n      const { stdout, stderr } = await execAsync(`powershell -Command \"${command.replace(/\"/g, '\\\\\"')}\"`);\n\n      if (stderr) {\n        return {\n          isError: true,\n          content: [\n            {\n              type: \"text\" as const,\n              text: `Error in my_ps_tool: ${stderr}`,\n            },\n          ],\n        };\n      }\n\n      return {\n        content: [\n          {\n            type: \"text\" as const,\n            text: stdout,\n          },\n        ],\n      };\n    } catch (error) {\n      return {\n        isError: true,\n        content: [\n          {\n            type: \"text\" as const,\n            text: `Error in my_ps_tool: ${(error as Error).message}`,\n          },\n        ],\n      };\n    }\n  }\n);\n```\n\n## Security Considerations\n\n- This server executes PowerShell commands directly on your system\n- Commands are executed with the same privileges as the process running the MCP server\n- Use caution when exposing destructive operations\n- Consider implementing additional validation for sensitive commands\n\n## Troubleshooting\n\n### Common Issues\n\n1. **PowerShell execution policy restrictions**\n   - You may need to adjust your PowerShell execution policy to allow script execution\n   - Use `Set-ExecutionPolicy RemoteSigned -Scope CurrentUser` to allow local scripts\n\n2. **Path not found errors**\n   - Ensure file paths are absolute or properly relative to the working directory\n   - Use appropriate path separators for your OS\n\n3. **Command not found errors**\n   - Some commands may require specific modules to be installed\n   - Use `Install-Module ModuleName` to install required modules\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "powershell",
        "monitoring",
        "commands",
        "mcp powershell",
        "manage powershell",
        "powershell commands"
      ],
      "category": "monitoring-and-logging"
    },
    "samwang0723--mcp-sumologic": {
      "owner": "samwang0723",
      "name": "mcp-sumologic",
      "url": "https://github.com/samwang0723/mcp-sumologic",
      "imageUrl": "/freedevtools/mcp/pfp/samwang0723.webp",
      "description": "Search and retrieve logs from Sumo Logic using customized queries within specified time ranges, while supporting error handling and detailed logging.",
      "stars": 5,
      "forks": 6,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-09-02T02:09:21Z",
      "readme_content": "# MCP Sumo Logic\n\nA Model Context Protocol (MCP) server that integrates with Sumo Logic's API to perform log searches.\n\n## Features\n\n- Search Sumo Logic logs using custom queries\n- Configurable time ranges for searches\n- Error handling and detailed logging\n- Docker support for easy deployment\n\n## Environment Variables\n\n```env\nENDPOINT=https://api.au.sumologic.com/api/v1  # Sumo Logic API endpoint\nSUMO_API_ID=your_api_id                       # Sumo Logic API ID\nSUMO_API_KEY=your_api_key                     # Sumo Logic API Key\n```\n\n## Setup\n\n1. Clone the repository\n2. Install dependencies:\n   ```bash\n   npm install\n   ```\n3. Create a `.env` file with the required environment variables\n4. Build the project:\n   ```bash\n   npm run build\n   ```\n5. Start the server:\n   ```bash\n   npm start\n   ```\n\n## Docker Setup\n\n1. Build the Docker image:\n   ```bash\n   docker build -t mcp/sumologic .\n   ```\n\n2. Run the container (choose one method):\n\n   a. Using environment variables directly:\n   ```bash\n   docker run -e ENDPOINT=your_endpoint -e SUMO_API_ID=your_api_id -e SUMO_API_KEY=your_api_key mcp/sumologic\n   ```\n\n   b. Using a .env file:\n   ```bash\n   docker run --env-file .env mcp/sumologic\n   ```\n\n   Note: Make sure your .env file contains the required environment variables:\n   ```env\n   ENDPOINT=your_endpoint\n   SUMO_API_ID=your_api_id\n   SUMO_API_KEY=your_api_key\n   ```\n\n## Usage\n\nThe server exposes a `search-sumologic` tool that accepts the following parameters:\n\n- `query` (required): The Sumo Logic search query\n- `from` (optional): Start time in ISO 8601 format\n- `to` (optional): End time in ISO 8601 format\n\nExample query:\n```typescript\nconst query = '_index=app_pro_fiat_cont | json auto | fields log_identifier';\nconst results = await search(sumoClient, query, {\n  from: '2024-02-23T00:00:00Z',\n  to: '2024-02-24T00:00:00Z',\n});\n```\n\n## Error Handling\n\nThe server includes comprehensive error handling and logging:\n- API errors are caught and logged with details\n- Search job status is monitored and logged\n- Network and authentication issues are properly handled\n\n## Development\n\nTo run in development mode:\n```bash\nnpm run dev\n```\n\nFor testing:\n```bash\nnpm test\n``` ",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "sumologic",
        "sumo",
        "logging",
        "logs sumo",
        "sumologic search",
        "mcp sumologic"
      ],
      "category": "monitoring-and-logging"
    },
    "sapientpants--sonarqube-mcp-server": {
      "owner": "sapientpants",
      "name": "sonarqube-mcp-server",
      "url": "https://github.com/sapientpants/sonarqube-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/sapientpants.webp",
      "description": "Integrates with SonarQube to provide access to code quality metrics, detect issues, and analyze results for AI assistants.",
      "stars": 96,
      "forks": 15,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-29T20:22:00Z",
      "readme_content": "# SonarQube MCP Server\n\n[](https://github.com/sapientpants/sonarqube-mcp-server/actions/workflows/ci.yml)\n[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=sonarqube-mcp-server&metric=alert_status)](https://sonarcloud.io/summary/new_code?id=sonarqube-mcp-server)\n[![Bugs](https://sonarcloud.io/api/project_badges/measure?project=sonarqube-mcp-server&metric=bugs)](https://sonarcloud.io/summary/new_code?id=sonarqube-mcp-server)\n[![Code Smells](https://sonarcloud.io/api/project_badges/measure?project=sonarqube-mcp-server&metric=code_smells)](https://sonarcloud.io/summary/new_code?id=sonarqube-mcp-server)\n[![Coverage](https://sonarcloud.io/api/project_badges/measure?project=sonarqube-mcp-server&metric=coverage)](https://sonarcloud.io/summary/new_code?id=sonarqube-mcp-server)\n[![Duplicated Lines (%)](https://sonarcloud.io/api/project_badges/measure?project=sonarqube-mcp-server&metric=duplicated_lines_density)](https://sonarcloud.io/summary/new_code?id=sonarqube-mcp-server)\n[![npm version](https://img.shields.io/npm/v/sonarqube-mcp-server.svg)](https://www.npmjs.com/package/sonarqube-mcp-server)\n[![npm downloads](https://img.shields.io/npm/dm/sonarqube-mcp-server.svg)](https://www.npmjs.com/package/sonarqube-mcp-server)\n[![License](https://img.shields.io/npm/l/sonarqube-mcp-server.svg)](https://github.com/sapientpants/sonarqube-mcp-server/blob/main/LICENSE)\n\nA Model Context Protocol (MCP) server that integrates with SonarQube to provide AI assistants with access to code quality metrics, issues, and analysis results.\n\n## Table of Contents\n\n- [Overview](#overview)\n- [Documentation](#documentation)\n- [Compatibility](#compatibility)\n- [Quick Start](#quick-start)\n- [Installation](#installation)\n  - [NPX](#npx-recommended)\n  - [Docker](#docker-recommended-for-production)\n  - [Local Development](#local-development)\n- [Configuration](#configuration)\n  - [Environment Variables](#environment-variables)\n  - [Authentication Methods](#authentication-methods)\n- [Available Tools](#available-tools)\n- [Usage Examples](#usage-examples)\n- [Architecture](#architecture)\n- [Development](#development)\n- [Troubleshooting](#troubleshooting)\n- [Contributing](#contributing)\n- [License](#license)\n- [External Resources](#external-resources)\n\n## Overview\n\nThe SonarQube MCP Server enables AI assistants to interact with SonarQube's code quality analysis capabilities through the Model Context Protocol. This integration allows AI assistants to:\n\n- 📊 **Retrieve code metrics and analysis results** - Access detailed quality metrics for your projects\n- 🐛 **Access and filter issues** - Search and filter code issues by severity, type, status, and more\n- 🔒 **Review security hotspots** - Find and manage security vulnerabilities with dedicated workflows\n- 🌿 **Analyze branches and PRs** - Review code quality in feature branches and pull requests\n- 📦 **Multi-project analysis** - Query issues and metrics across multiple projects simultaneously\n- ✅ **Check quality gates** - Monitor whether projects meet quality standards\n- 📈 **Analyze project quality over time** - Track metrics history and trends\n- 🔍 **View source code with issues** - See problematic code with highlighted issues\n- 🏥 **Monitor system health** - Check SonarQube instance status and availability\n- 🔄 **Enhanced error handling** - Clear error messages with solutions and automatic retry for transient failures\n\n## Documentation\n\n### Core Guides\n\n- **[Architecture Guide](docs/architecture.md)** - System architecture, design decisions, and component overview\n- **[Troubleshooting Guide](docs/troubleshooting.md)** - Common issues, debugging, and solutions\n\n### Security & Authentication\n\n- **[Security Guide](docs/security.md)** - Authentication, authorization, and security best practices\n\n## Compatibility\n\nFor detailed information about MCP protocol version support and SDK compatibility, see [COMPATIBILITY.md](COMPATIBILITY.md).\n\n## Quick Start\n\n### Prerequisites\n\n- [Claude Desktop](https://claude.ai/download) installed\n- A SonarQube instance or [SonarCloud](https://sonarcloud.io) account\n- A SonarQube/SonarCloud authentication token\n\n### 1. Get Your SonarQube Token\n\n**For SonarCloud:**\n\n1. Log in to [SonarCloud](https://sonarcloud.io)\n2. Go to **My Account** → **Security**\n3. Generate a new token\n\n**For SonarQube:**\n\n1. Log in to your SonarQube instance\n2. Go to **My Account** → **Security**\n3. Generate a new token\n\n### 2. Configure Claude Desktop\n\n1. Open Claude Desktop\n2. Go to **Settings** → **Developer** → **Edit Config**\n3. Add the SonarQube server configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"sonarqube\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"sonarqube-mcp-server@latest\"],\n      \"env\": {\n        \"SONARQUBE_URL\": \"https://sonarcloud.io\",\n        \"SONARQUBE_TOKEN\": \"your-token-here\",\n        \"SONARQUBE_ORGANIZATION\": \"your-org (for SonarCloud)\"\n      }\n    }\n  }\n}\n```\n\n**Alternative authentication methods:**\n\nUsing Basic Authentication:\n\n```json\n{\n  \"mcpServers\": {\n    \"sonarqube\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"sonarqube-mcp-server@latest\"],\n      \"env\": {\n        \"SONARQUBE_URL\": \"https://your-sonarqube.com\",\n        \"SONARQUBE_USERNAME\": \"your-username\",\n        \"SONARQUBE_PASSWORD\": \"your-password\"\n      }\n    }\n  }\n}\n```\n\nUsing System Passcode:\n\n```json\n{\n  \"mcpServers\": {\n    \"sonarqube\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"sonarqube-mcp-server@latest\"],\n      \"env\": {\n        \"SONARQUBE_URL\": \"https://your-sonarqube.com\",\n        \"SONARQUBE_PASSCODE\": \"your-system-passcode\"\n      }\n    }\n  }\n}\n```\n\n1. Restart Claude Desktop\n\n### 3. Start Using\n\nAsk Claude to analyze your SonarQube projects:\n\n```\n\"List all my SonarQube projects\"\n\"Show me critical issues in project xyz\"\n\"What's the code coverage for project xyz?\"\n\"Check the quality gate status for project xyz\"\n\"Retrieve security hotspots in project xyz and create a plan to address them\"\n\"Retrieve the issues for pr 123 in project xyz and create a plan to address them\"\n```\n\n## Installation\n\n### NPX (Recommended)\n\nThe simplest way to use the SonarQube MCP Server is through npx:\n\n```json\n{\n  \"mcpServers\": {\n    \"sonarqube\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"sonarqube-mcp-server@latest\"],\n      \"env\": {\n        \"SONARQUBE_URL\": \"https://sonarqube.example.com\",\n        \"SONARQUBE_TOKEN\": \"your-sonarqube-token\",\n        \"SONARQUBE_ORGANIZATION\": \"your-organization-key\"\n      }\n    }\n  }\n}\n```\n\n### Docker (Recommended for Production)\n\nDocker provides the most reliable deployment method by packaging all dependencies and ensuring consistent behavior across different environments.\n\n> **Enterprise Deployment**: For production deployments with Kubernetes, Helm charts, and cloud-specific configurations, see our comprehensive [Deployment Guide](docs/deployment.md).\n\n#### Quick Start with Docker\n\n**For stdio transport (Claude Desktop):**\n\n```json\n{\n  \"mcpServers\": {\n    \"sonarqube\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-e\",\n        \"SONARQUBE_URL\",\n        \"-e\",\n        \"SONARQUBE_TOKEN\",\n        \"-e\",\n        \"SONARQUBE_ORGANIZATION\",\n        \"sapientpants/sonarqube-mcp-server:latest\"\n      ],\n      \"env\": {\n        \"SONARQUBE_URL\": \"https://sonarqube.example.com\",\n        \"SONARQUBE_TOKEN\": \"your-sonarqube-token\",\n        \"SONARQUBE_ORGANIZATION\": \"your-organization-key\"\n      }\n    }\n  }\n}\n```\n\n#### Docker Hub Images\n\nOfficial images are available on Docker Hub: [`sapientpants/sonarqube-mcp-server`](https://hub.docker.com/r/sapientpants/sonarqube-mcp-server)\n\n**Available tags:**\n\n- `latest` - Latest stable release\n- `1.6.0` - Specific version (recommended for production)\n- `1.6` - Latest patch version of 1.6.x\n- `1` - Latest minor version of 1.x.x\n\n**Pull the image:**\n\n```bash\ndocker pull sapientpants/sonarqube-mcp-server:latest\n```\n\n#### Advanced Docker Configuration\n\n**With logging enabled:**\n\n```json\n{\n  \"mcpServers\": {\n    \"sonarqube\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-v\",\n        \"/tmp/sonarqube-logs:/logs\",\n        \"-e\",\n        \"SONARQUBE_URL\",\n        \"-e\",\n        \"SONARQUBE_TOKEN\",\n        \"-e\",\n        \"SONARQUBE_ORGANIZATION\",\n        \"-e\",\n        \"LOG_FILE=/logs/sonarqube-mcp.log\",\n        \"-e\",\n        \"LOG_LEVEL=INFO\",\n        \"sapientpants/sonarqube-mcp-server:latest\"\n      ],\n      \"env\": {\n        \"SONARQUBE_URL\": \"https://sonarqube.example.com\",\n        \"SONARQUBE_TOKEN\": \"your-sonarqube-token\",\n        \"SONARQUBE_ORGANIZATION\": \"your-organization-key\"\n      }\n    }\n  }\n}\n```\n\n**Using Docker Compose:**\n\n```yaml\nversion: '3.8'\nservices:\n  sonarqube-mcp:\n    image: sapientpants/sonarqube-mcp-server:latest\n    environment:\n      - SONARQUBE_URL=https://sonarqube.example.com\n      - SONARQUBE_TOKEN=${SONARQUBE_TOKEN}\n      - SONARQUBE_ORGANIZATION=${SONARQUBE_ORGANIZATION}\n      - LOG_FILE=/logs/sonarqube-mcp.log\n      - LOG_LEVEL=INFO\n    volumes:\n      - ./logs:/logs\n    stdin_open: true\n    tty: true\n```\n\n#### Building Your Own Docker Image\n\nIf you need to customize the server, you can build your own image:\n\n```bash\n# Clone the repository\ngit clone https://github.com/sapientpants/sonarqube-mcp-server.git\ncd sonarqube-mcp-server\n\n# Build the Docker image\ndocker build -t my-sonarqube-mcp-server .\n\n# Run your custom image\ndocker run -i --rm \\\n  -e SONARQUBE_URL=\"https://sonarqube.example.com\" \\\n  -e SONARQUBE_TOKEN=\"your-token\" \\\n  my-sonarqube-mcp-server\n```\n\n#### Docker Best Practices\n\n1. **Version Pinning**: Always use specific version tags in production:\n\n   ```bash\n   sapientpants/sonarqube-mcp-server:1.6.0\n   ```\n\n2. **Resource Limits**: Set appropriate resource limits:\n\n   ```bash\n   docker run -i --rm \\\n     --memory=\"256m\" \\\n     --cpus=\"0.5\" \\\n     sapientpants/sonarqube-mcp-server:1.6.0\n   ```\n\n3. **Security**: Run as non-root user (default in our image):\n\n   ```bash\n   docker run -i --rm \\\n     --user node \\\n     sapientpants/sonarqube-mcp-server:1.6.0\n   ```\n\n4. **Health Checks**: The container includes a health check that verifies the Node.js process is running\n\n### Local Development\n\nFor development or customization:\n\n```json\n{\n  \"mcpServers\": {\n    \"sonarqube\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/sonarqube-mcp-server/dist/index.js\"],\n      \"env\": {\n        \"SONARQUBE_URL\": \"https://sonarqube.example.com\",\n        \"SONARQUBE_TOKEN\": \"your-sonarqube-token\",\n        \"SONARQUBE_ORGANIZATION\": \"your-organization-key\"\n      }\n    }\n  }\n}\n```\n\n## Configuration\n\n### Environment Variables\n\n#### Authentication (choose one method)\n\n| Variable                 | Description                                   | Required | Default |\n| ------------------------ | --------------------------------------------- | -------- | ------- |\n| **Token Authentication** |                                               |          |         |\n| `SONARQUBE_TOKEN`        | Authentication token for SonarQube API access | ✅ Yes\\* | -       |\n| **Basic Authentication** |                                               |          |         |\n| `SONARQUBE_USERNAME`     | Username for Basic authentication             | ✅ Yes\\* | -       |\n| `SONARQUBE_PASSWORD`     | Password for Basic authentication             | ✅ Yes\\* | -       |\n| **System Passcode**      |                                               |          |         |\n| `SONARQUBE_PASSCODE`     | System passcode for SonarQube authentication  | ✅ Yes\\* | -       |\n\n\\*One authentication method is required. Token authentication takes priority if multiple methods are configured.\n\n#### Connection Settings\n\n| Variable                 | Description                                              | Required  | Default                 |\n| ------------------------ | -------------------------------------------------------- | --------- | ----------------------- |\n| `SONARQUBE_URL`          | URL of your SonarQube instance                           | ❌ No     | `https://sonarcloud.io` |\n| `SONARQUBE_ORGANIZATION` | Organization key (required for SonarCloud)               | ❌ No\\*\\* | -                       |\n| `LOG_FILE`               | Path to write log files (e.g., `/tmp/sonarqube-mcp.log`) | ❌ No     | -                       |\n| `LOG_LEVEL`              | Minimum log level (DEBUG, INFO, WARN, ERROR)             | ❌ No     | `DEBUG`                 |\n\n\\*\\*Required when using SonarCloud\n\n#### HTTP Transport Settings (Advanced)\n\nBy default, the server uses stdio transport for communication with Claude Desktop. For programmatic access or running as a web service, HTTP transport is available:\n\n| Variable                                   | Description                                  | Required | Default     |\n| ------------------------------------------ | -------------------------------------------- | -------- | ----------- |\n| `MCP_TRANSPORT_TYPE`                       | Transport type (`stdio` or `http`)           | ❌ No    | `stdio`     |\n| `MCP_HTTP_PORT`                            | Port for HTTP server                         | ❌ No    | `3000`      |\n| `MCP_HTTP_SESSION_TIMEOUT`                 | Session timeout in milliseconds              | ❌ No    | `1800000`   |\n| `MCP_HTTP_ALLOWED_HOSTS`                   | Comma-separated list of allowed hosts        | ❌ No    | `localhost` |\n| `MCP_HTTP_ALLOWED_ORIGINS`                 | Comma-separated list of allowed CORS origins | ❌ No    | `*`         |\n| `MCP_HTTP_ENABLE_DNS_REBINDING_PROTECTION` | Enable DNS rebinding protection              | ❌ No    | `false`     |\n\n### Authentication Methods\n\nThe server supports three authentication methods, with important differences between SonarQube versions:\n\n#### 1. Token Authentication (Recommended)\n\n##### SonarQube 10.0+ (Bearer Token)\n\n- Starting with SonarQube 10.0, Bearer token authentication is the recommended approach\n- Most secure and flexible option\n- Tokens can have limited permissions\n- Configuration:\n  ```json\n  {\n    \"env\": {\n      \"SONARQUBE_TOKEN\": \"your-token-here\"\n    }\n  }\n  ```\n\n##### SonarQube < 10.0 (Token as Username)\n\n- For versions before 10.0, tokens must be sent as the username in Basic authentication\n- No password is required when using a token as username\n- The server automatically handles this based on your SonarQube version\n- Configuration remains the same - just use `SONARQUBE_USERNAME` with the token value:\n  ```json\n  {\n    \"env\": {\n      \"SONARQUBE_USERNAME\": \"your-token-here\"\n    }\n  }\n  ```\n\n#### 2. Basic Authentication\n\n- Traditional username and password authentication\n- Suitable for self-hosted SonarQube instances\n- May not work with SonarCloud if 2FA is enabled\n- Configuration:\n  ```json\n  {\n    \"env\": {\n      \"SONARQUBE_USERNAME\": \"your-username\",\n      \"SONARQUBE_PASSWORD\": \"your-password\"\n    }\n  }\n  ```\n\n#### 3. System Passcode\n\n- Special authentication for SonarQube system administration\n- Typically used for automated deployment scenarios\n- Configuration:\n  ```json\n  {\n    \"env\": {\n      \"SONARQUBE_PASSCODE\": \"your-system-passcode\"\n    }\n  }\n  ```\n\n**Note:** Token authentication takes priority if multiple authentication methods are configured. The server will automatically use the appropriate authentication strategy based on your SonarQube version.\n\n### SonarCloud vs SonarQube\n\n**For SonarCloud:**\n\n- Set `SONARQUBE_URL` to `https://sonarcloud.io`\n- `SONARQUBE_ORGANIZATION` is required\n- Token authentication is recommended\n\n**For SonarQube Server:**\n\n- Set `SONARQUBE_URL` to your instance URL\n- `SONARQUBE_ORGANIZATION` is typically not needed\n- All authentication methods are supported\n\n### HTTP Transport Mode\n\nThe server supports HTTP transport for programmatic access and web service deployments. This enables integration with custom clients and web applications.\n\n#### Running as an HTTP Server\n\nStart the server with HTTP transport:\n\n```bash\n# Using environment variables\nMCP_TRANSPORT_TYPE=http MCP_HTTP_PORT=3000 npx sonarqube-mcp-server\n\n# With Docker\ndocker run -i --rm \\\n  -p 3000:3000 \\\n  -e MCP_TRANSPORT_TYPE=http \\\n  -e MCP_HTTP_PORT=3000 \\\n  -e SONARQUBE_URL=https://sonarcloud.io \\\n  -e SONARQUBE_TOKEN=your-token \\\n  sapientpants/sonarqube-mcp-server:latest\n```\n\n#### HTTP API Endpoints\n\nWhen running in HTTP mode, the server exposes the following endpoints:\n\n- `GET /health` - Health check endpoint\n- `POST /session` - Create a new session\n- `DELETE /session/:sessionId` - Close a session\n- `POST /mcp` - Execute MCP requests\n- `GET /events/:sessionId` - Server-sent events for notifications\n\n#### Example HTTP Client\n\nSee [examples/http-client.ts](examples/http-client.ts) for a complete TypeScript client example.\n\nBasic usage with curl:\n\n```bash\n# Health check\ncurl http://localhost:3000/health\n\n# Create session\nSESSION_ID=$(curl -X POST http://localhost:3000/session | jq -r .sessionId)\n\n# Execute MCP request\ncurl -X POST http://localhost:3000/mcp \\\n  -H \"Content-Type: application/json\" \\\n  -d \"{\n    \\\"sessionId\\\": \\\"$SESSION_ID\\\",\n    \\\"method\\\": \\\"tools/list\\\",\n    \\\"params\\\": {}\n  }\"\n\n# Close session\ncurl -X DELETE http://localhost:3000/session/$SESSION_ID\n```\n\n#### Security Considerations\n\nWhen running in HTTP mode:\n\n1. **Enable DNS rebinding protection** for public deployments:\n\n   ```bash\n   MCP_HTTP_ENABLE_DNS_REBINDING_PROTECTION=true\n   ```\n\n2. **Configure CORS** for browser-based clients:\n\n   ```bash\n   MCP_HTTP_ALLOWED_ORIGINS=https://yourapp.com,https://anotherapp.com\n   ```\n\n3. **Set session timeouts** appropriately:\n\n   ```bash\n   MCP_HTTP_SESSION_TIMEOUT=900000  # 15 minutes\n   ```\n\n4. **Use HTTPS** in production (configure through a reverse proxy like nginx)\n\n### Elicitation Configuration (Experimental)\n\nThe server supports interactive user input through MCP's elicitation capability. This feature is opt-in and requires compatible MCP clients.\n\n**Environment Variables:**\n\n- `SONARQUBE_MCP_ELICITATION`: Set to `true` to enable elicitation\n- `SONARQUBE_MCP_BULK_THRESHOLD`: Number of items before confirmation (default: 5)\n- `SONARQUBE_MCP_REQUIRE_COMMENTS`: Set to `true` to require comments for resolutions\n- `SONARQUBE_MCP_INTERACTIVE_SEARCH`: Set to `true` for interactive disambiguation\n\n**Example Configuration:**\n\n```json\n{\n  \"mcpServers\": {\n    \"sonarqube\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"sonarqube-mcp-server@latest\"],\n      \"env\": {\n        \"SONARQUBE_URL\": \"https://sonarcloud.io\",\n        \"SONARQUBE_TOKEN\": \"your-token\",\n        \"SONARQUBE_MCP_ELICITATION\": \"true\",\n        \"SONARQUBE_MCP_BULK_THRESHOLD\": \"10\",\n        \"SONARQUBE_MCP_REQUIRE_COMMENTS\": \"true\"\n      }\n    }\n  }\n}\n```\n\n**Features When Enabled:**\n\n1. **Bulk Operation Confirmation**: Prompts for confirmation before marking multiple issues\n2. **Comment Collection**: Collects explanatory comments when marking issues as false positive or won't fix\n3. **Authentication Setup**: Guides through authentication setup when credentials are missing\n4. **Search Disambiguation**: Helps select from multiple matching components or projects\n\n**Note:** This feature requires MCP clients that support elicitation. Not all clients may support this capability.\n\n### Logging Configuration\n\nThe server supports file-based logging for debugging and monitoring. Since MCP servers use stdout for protocol communication, logs are written to a file instead of stdout/stderr to avoid interference.\n\n**Enable Logging:**\n\n```json\n{\n  \"mcpServers\": {\n    \"sonarqube\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"sonarqube-mcp-server@latest\"],\n      \"env\": {\n        \"SONARQUBE_URL\": \"https://sonarcloud.io\",\n        \"SONARQUBE_TOKEN\": \"your-token-here\",\n        \"SONARQUBE_ORGANIZATION\": \"your-org\",\n        \"LOG_FILE\": \"/tmp/sonarqube-mcp.log\",\n        \"LOG_LEVEL\": \"INFO\"\n      }\n    }\n  }\n}\n```\n\n**Log Levels:**\n\n- `DEBUG`: Detailed information for debugging\n- `INFO`: General information about server operation\n- `WARN`: Warning events that might lead to issues\n- `ERROR`: Error events (server continues running)\n\n**Example Log Output:**\n\n```\n2024-01-15T10:30:45.123Z INFO [index] Starting SonarQube MCP server\n2024-01-15T10:30:45.234Z INFO [index] Environment variables validated successfully\n2024-01-15T10:30:45.345Z INFO [index] SonarQube client created successfully\n2024-01-15T10:30:45.456Z INFO [index] SonarQube MCP server started successfully\n2024-01-15T10:30:50.123Z DEBUG [index] Handling SonarQube projects request\n2024-01-15T10:30:50.567Z INFO [index] Successfully retrieved projects {\"count\": 5}\n```\n\n## Available Tools\n\n### Permission Requirements\n\nDifferent SonarQube tools require different permission levels:\n\n**Tools requiring Admin permissions:**\n\n- `projects` - Lists all SonarQube projects with metadata (visibility, lastAnalysisDate, revision)\n\n**Tools accessible to all users:**\n\n- `components` - Search and navigate projects, directories, and files (requires 'Browse' permission on at least one project)\n- All other tools require appropriate permissions based on the resources being accessed\n\n#### Listing Projects\n\n**For Administrators:**\nUse the `projects` tool to get full project metadata including visibility, last analysis date, and revision info.\n\n**For All Users:**\nUse the `components` tool with project qualifier:\n\n- \"List all projects I have access to\" → `components` with `qualifiers: ['TRK']`\n- \"Search for projects containing 'mobile'\" → `components` with `query: 'mobile', qualifiers: ['TRK']`\n\nThe `components` tool provides a more accessible alternative for non-admin users to discover projects they have access to.\n\n### Project Management\n\n#### `projects`\n\nList all SonarQube projects with pagination support.\n\n**Parameters:**\n\n- `page` (optional): Page number for results pagination\n- `page_size` (optional): Number of items per page\n\n### Metrics and Measures\n\n#### `metrics`\n\nGet available metrics from SonarQube.\n\n**Parameters:**\n\n- `page` (optional): Page number for results pagination\n- `page_size` (optional): Number of items per page\n\n#### `measures_component`\n\nGet measures for a specific component.\n\n**Parameters:**\n\n- `component` (required): Component key\n- `metric_keys` (required): Array of metric keys\n- `additional_fields` (optional): Additional fields to return\n- `branch` (optional): Branch name\n- `pull_request` (optional): Pull request key\n- `period` (optional): Period index\n\n#### `measures_components`\n\nGet measures for multiple components.\n\n**Parameters:**\n\n- `component_keys` (required): Array of component keys\n- `metric_keys` (required): Array of metric keys\n- Additional parameters same as `measures_component`\n- `page` (optional): Page number\n- `page_size` (optional): Items per page\n\n#### `measures_history`\n\nGet measures history for a component.\n\n**Parameters:**\n\n- `component` (required): Component key\n- `metrics` (required): Array of metric keys\n- `from` (optional): Start date (YYYY-MM-DD)\n- `to` (optional): End date (YYYY-MM-DD)\n- `branch` (optional): Branch name\n- `pull_request` (optional): Pull request key\n- `page` (optional): Page number\n- `page_size` (optional): Items per page\n\n### Issue Management\n\n#### `issues`\n\nSearch and filter SonarQube issues by severity, status, assignee, tag, file path, and more. Critical for dashboards, targeted clean-up sprints, security audits, and regression testing. Supports faceted search for aggregations.\n\n**Component/File Path Filters:**\n\n- `project_key` (optional): Single project key (backward compatible)\n- `projects` (optional): Array of project keys for multi-project analysis\n- `component_keys` (optional): Array of component keys (file paths, directories, or modules) - use this to filter issues by specific files or folders\n- `components` (optional): Alias for component_keys\n- `on_component_only` (optional): Boolean to return only issues on specified components, not sub-components\n\n**Branch/PR Support:**\n\n- `branch` (optional): Branch name for branch analysis\n- `pull_request` (optional): Pull request ID for PR analysis\n\n**Issue Filters:**\n\n- `issues` (optional): Array of specific issue keys to retrieve\n- `severity` (optional): Single severity (deprecated, use severities)\n- `severities` (optional): Array of severities (INFO, MINOR, MAJOR, CRITICAL, BLOCKER)\n- `statuses` (optional): Array of statuses (OPEN, CONFIRMED, REOPENED, RESOLVED, CLOSED)\n- `resolutions` (optional): Array of resolutions (FALSE-POSITIVE, WONTFIX, FIXED, REMOVED)\n- `resolved` (optional): Boolean filter for resolved/unresolved\n- `types` (optional): Array of types (CODE_SMELL, BUG, VULNERABILITY, SECURITY_HOTSPOT)\n\n**Clean Code Taxonomy (SonarQube 10.x+):**\n\n- `clean_code_attribute_categories` (optional): Array (ADAPTABLE, CONSISTENT, INTENTIONAL, RESPONSIBLE)\n- `impact_severities` (optional): Array (HIGH, MEDIUM, LOW)\n- `impact_software_qualities` (optional): Array (MAINTAINABILITY, RELIABILITY, SECURITY)\n- `issue_statuses` (optional): Array of new issue status values\n\n**Rules and Tags:**\n\n- `rules` (optional): Array of rule keys\n- `tags` (optional): Array of issue tags - essential for security audits, regression testing, and categorized analysis\n\n**Date Filters:**\n\n- `created_after` (optional): Issues created after date (YYYY-MM-DD)\n- `created_before` (optional): Issues created before date (YYYY-MM-DD)\n- `created_at` (optional): Issues created on date (YYYY-MM-DD)\n- `created_in_last` (optional): Issues created in last period (e.g., \"30d\", \"1m\")\n\n**Assignment:**\n\n- `assigned` (optional): Boolean filter for assigned/unassigned\n- `assignees` (optional): Array of assignee logins - critical for targeted clean-up sprints and workload analysis\n- `author` (optional): Single author login\n- `authors` (optional): Array of author logins\n\n**Security Standards:**\n\n- `cwe` (optional): Array of CWE identifiers\n- `owasp_top10` (optional): Array of OWASP Top 10 categories\n- `owasp_top10_v2021` (optional): Array of OWASP Top 10 2021 categories\n- `sans_top25` (optional): Array of SANS Top 25 categories\n- `sonarsource_security` (optional): Array of SonarSource security categories\n- `sonarsource_security_category` (optional): Additional security categories\n\n**Other Filters:**\n\n- `languages` (optional): Array of programming languages\n- `facets` (optional): Array of facets to aggregate\n- `facet_mode` (optional): Facet aggregation mode ('effort' or 'count')\n- `since_leak_period` (optional): Boolean for leak period filter (deprecated)\n- `in_new_code_period` (optional): Boolean for new code period filter\n\n**Sorting:**\n\n- `s` (optional): Sort field (e.g., 'SEVERITY', 'CREATION_DATE', 'UPDATE_DATE')\n- `asc` (optional): Boolean for ascending sort direction (default: false)\n\n**Response Control:**\n\n- `additional_fields` (optional): Array of additional fields to include\n- `page` (optional): Page number for pagination\n- `page_size` (optional): Number of items per page\n\n**Faceted Search (Dashboard Support):**\n\n- `facets` (optional): Array of facets to compute for aggregations. Available facets: severities, statuses, resolutions, rules, tags, types, authors, assignees, languages, etc.\n- `facet_mode` (optional): Mode for facet computation: 'count' (number of issues) or 'effort' (remediation effort)\n\n**Example Use Cases:**\n\n1. **Dashboard Query** - Get issue counts by severity and assignee:\n\n```json\n{\n  \"project_key\": \"my-project\",\n  \"facets\": [\"severities\", \"assignees\", \"tags\"],\n  \"facet_mode\": \"count\"\n}\n```\n\n1. **Security Audit** - Find critical security issues in authentication modules:\n\n```json\n{\n  \"project_key\": \"my-project\",\n  \"component_keys\": [\"src/auth/\", \"src/security/\"],\n  \"tags\": [\"security\", \"vulnerability\"],\n  \"severities\": [\"CRITICAL\", \"BLOCKER\"],\n  \"statuses\": [\"OPEN\", \"REOPENED\"]\n}\n```\n\n1. **Sprint Planning** - Get open issues for specific team members:\n\n```json\n{\n  \"project_key\": \"my-project\",\n  \"assignees\": [\"john.doe@example.com\", \"jane.smith@example.com\"],\n  \"statuses\": [\"OPEN\", \"CONFIRMED\"],\n  \"facets\": [\"severities\", \"types\"],\n  \"facet_mode\": \"effort\"\n}\n```\n\n1. **File-Specific Analysis** - Issues in a specific file:\n\n```json\n{\n  \"project_key\": \"my-project\",\n  \"component_keys\": [\"src/main/java/com/example/PaymentService.java\"],\n  \"on_component_only\": true\n}\n```\n\n### Component Navigation\n\n#### `components`\n\nSearch and navigate SonarQube components (projects, directories, files). Supports text search, filtering by type/language, and tree navigation.\n\n**Search Parameters:**\n\n- `query` (optional): Text search query\n- `qualifiers` (optional): Array of component types (TRK, DIR, FIL, UTS, BRC, APP, VW, SVW, LIB)\n- `language` (optional): Programming language filter\n\n**Tree Navigation Parameters:**\n\n- `component` (optional): Component key for tree navigation\n- `strategy` (optional): Tree traversal strategy ('all', 'children', 'leaves')\n\n**Common Parameters:**\n\n- `asc` (optional): Sort ascending/descending\n- `ps` (optional): Page size (default: 100, max: 500)\n- `p` (optional): Page number\n- `branch` (optional): Branch name\n- `pullRequest` (optional): Pull request ID\n\n**Component Qualifiers:**\n\n- `TRK`: Project\n- `DIR`: Directory\n- `FIL`: File\n- `UTS`: Unit Test\n- `BRC`: Branch\n- `APP`: Application\n- `VW`: View\n- `SVW`: Sub-view\n- `LIB`: Library\n\n**Example Use Cases:**\n\n1. **Find specific files:**\n\n```json\n{\n  \"query\": \"UserService\",\n  \"qualifiers\": [\"FIL\"]\n}\n```\n\n1. **List all test files in a project:**\n\n```json\n{\n  \"component\": \"my-project\",\n  \"qualifiers\": [\"UTS\"]\n}\n```\n\n1. **Navigate directory structure:**\n\n```json\n{\n  \"component\": \"my-project:src/main\",\n  \"strategy\": \"children\",\n  \"qualifiers\": [\"DIR\", \"FIL\"]\n}\n```\n\n1. **Search for components by language:**\n\n```json\n{\n  \"language\": \"java\",\n  \"qualifiers\": [\"FIL\"],\n  \"query\": \"Controller\"\n}\n```\n\n1. **Get project list:**\n\n```json\n{\n  \"qualifiers\": [\"TRK\"]\n}\n```\n\n### Security Hotspots\n\n#### `hotspots`\n\nSearch for security hotspots with specialized filters for security review workflows.\n\n**Parameters:**\n\n- `project_key` (optional): Project key to filter hotspots\n- `branch` (optional): Branch name for branch analysis\n- `pull_request` (optional): Pull request ID for PR analysis\n- `status` (optional): Hotspot status (TO_REVIEW, REVIEWED)\n- `resolution` (optional): Hotspot resolution (FIXED, SAFE)\n- `files` (optional): Array of file paths to filter\n- `assigned_to_me` (optional): Boolean to show only assigned hotspots\n- `since_leak_period` (optional): Boolean for leak period filter\n- `in_new_code_period` (optional): Boolean for new code period filter\n- `page` (optional): Page number for pagination\n- `page_size` (optional): Number of items per page\n\n#### `hotspot`\n\nGet detailed information about a specific security hotspot including security context.\n\n**Parameters:**\n\n- `hotspot_key` (required): The unique key of the hotspot\n\n**Returns:**\n\n- Detailed hotspot information including:\n  - Security category and vulnerability probability\n  - Rule information and security context\n  - Changelog and comments\n  - Code flows and locations\n\n#### `update_hotspot_status`\n\nUpdate the status of a security hotspot (requires appropriate permissions).\n\n**Parameters:**\n\n- `hotspot_key` (required): The unique key of the hotspot\n- `status` (required): New status (TO_REVIEW, REVIEWED)\n- `resolution` (optional): Resolution when status is REVIEWED (FIXED, SAFE)\n- `comment` (optional): Comment explaining the status change\n\n### Quality Gates\n\n#### `quality_gates`\n\nList available quality gates.\n\nNo parameters required.\n\n#### `quality_gate`\n\nGet quality gate conditions.\n\n**Parameters:**\n\n- `id` (required): Quality gate ID\n\n#### `quality_gate_status`\n\nGet project quality gate status.\n\n**Parameters:**\n\n- `project_key` (required): Project key\n- `branch` (optional): Branch name\n- `pull_request` (optional): Pull request key\n\n### Source Code\n\n#### `source_code`\n\nView source code with issues highlighted.\n\n**Parameters:**\n\n- `key` (required): File key\n- `from` (optional): Start line\n- `to` (optional): End line\n- `branch` (optional): Branch name\n- `pull_request` (optional): Pull request key\n\n#### `scm_blame`\n\nGet SCM blame information for source code.\n\n**Parameters:**\n\n- Same as `source_code`\n\n### System Monitoring\n\n#### `system_health`\n\nGet the health status of the SonarQube instance.\n\nNo parameters required.\n\n#### `system_status`\n\nGet the status of the SonarQube instance.\n\nNo parameters required.\n\n#### `system_ping`\n\nPing the SonarQube instance to check if it is up.\n\nNo parameters required.\n\n### Issue Resolution and Management\n\n#### `markIssueFalsePositive`\n\nMark an issue as false positive.\n\n**Parameters:**\n\n- `issue_key` (required): The key of the issue to mark\n- `comment` (optional): Comment explaining why it's a false positive\n\n#### `markIssueWontFix`\n\nMark an issue as won't fix.\n\n**Parameters:**\n\n- `issue_key` (required): The key of the issue to mark\n- `comment` (optional): Comment explaining why it won't be fixed\n\n#### `markIssuesFalsePositive`\n\nMark multiple issues as false positive in bulk.\n\n**Parameters:**\n\n- `issue_keys` (required): Array of issue keys to mark\n- `comment` (optional): Comment applying to all issues\n\n#### `markIssuesWontFix`\n\nMark multiple issues as won't fix in bulk.\n\n**Parameters:**\n\n- `issue_keys` (required): Array of issue keys to mark\n- `comment` (optional): Comment applying to all issues\n\n#### `addCommentToIssue`\n\nAdd a comment to a SonarQube issue.\n\n**Parameters:**\n\n- `issue_key` (required): The key of the issue to comment on\n- `text` (required): The comment text (supports markdown formatting)\n\n#### `assignIssue`\n\nAssign a SonarQube issue to a user or unassign it.\n\n**Parameters:**\n\n- `issueKey` (required): The key of the issue to assign\n- `assignee` (optional): Username of the assignee. Leave empty to unassign the issue\n\n**Example usage:**\n\n```json\n{\n  \"issueKey\": \"PROJECT-123\",\n  \"assignee\": \"john.doe\"\n}\n```\n\n## Usage Examples\n\n### Basic Project Analysis\n\n```\n\"List all my SonarQube projects\"\n\"Show me the code coverage for project xyz\"\n\"What metrics are available for analysis?\"\n```\n\n### Issue Investigation\n\n```\n\"Show me all critical bugs in project abc\"\n\"Find security vulnerabilities in the main branch\"\n\"List all code smells created in the last week\"\n\"Show unresolved issues assigned to john.doe\"\n\"Analyze issues in the feature/new-login branch\"\n\"Compare issues between main and develop branches\"\n\"Find issues across multiple projects: proj1, proj2, proj3\"\n\"Show me issues sorted by severity in descending order\"\n\"Find all issues with clean code impact on reliability\"\n```\n\n### Component Navigation\n\n```\n\"Find all files containing 'UserService' in their name\"\n\"List all test files in my project\"\n\"Show me the directory structure of src/main\"\n\"Find all Java controller files\"\n\"List all projects in SonarQube\"\n\"Navigate to the authentication module\"\n\"Search for TypeScript files in the frontend directory\"\n\"Show me all directories under src/components\"\n```\n\n### Issue Management\n\n```\n\"Assign issue PROJECT-123 to john.doe\"\n\"Unassign issue PROJECT-456\"\n\"Mark issue ABC-789 as false positive with comment: 'Test code only'\"\n\"Add comment to issue XYZ-111: 'Fixed in commit abc123'\"\n\"Bulk mark issues DEF-222, DEF-223 as won't fix\"\n```\n\n### Quality Monitoring\n\n```\n\"Check the quality gate status for my main project\"\n\"Show me the code coverage history for the last month\"\n\"What are the quality gate conditions?\"\n\"Compare metrics between develop and main branches\"\n```\n\n### Security Hotspot Review\n\n```\n\"Find all security hotspots that need review in project xyz\"\n\"Show me hotspots in the authentication module\"\n\"Get details for hotspot HSP-12345\"\n\"List all hotspots assigned to me\"\n\"Mark hotspot HSP-12345 as safe with explanation\"\n\"Find hotspots in the new code period\"\n\"Show security hotspots in pull request #42\"\n```\n\n### Source Code Analysis\n\n```\n\"Show me the source code for file xyz with issues highlighted\"\n\"Get blame information for the problematic file\"\n\"View issues in the authentication module\"\n```\n\n### System Health\n\n```\n\"Check if SonarQube is running\"\n\"What's the health status of the SonarQube instance?\"\n\"Show me the system status\"\n```\n\n## Architecture\n\nThe SonarQube MCP Server follows a modular architecture:\n\n```\n┌─────────────────┐     ┌──────────────────┐     ┌─────────────────┐\n│  Claude Desktop │────▶│  MCP Server      │────▶│  SonarQube API  │\n│  (MCP Client)   │◀────│  (index.ts)      │◀────│                 │\n└─────────────────┘     └──────────────────┘     └─────────────────┘\n                               │\n                               ▼\n                        ┌──────────────────┐\n                        │  SonarQube       │\n                        │  Client          │\n                        │  (sonarqube.ts)  │\n                        └──────────────────┘\n                               │\n                               ▼\n                        ┌──────────────────┐\n                        │  API Module      │\n                        │  (api.ts)        │\n                        └──────────────────┘\n```\n\n### Key Components\n\n1. **MCP Server (`index.ts`)**: Main entry point that initializes the MCP server and registers all available tools\n2. **SonarQube Client (`sonarqube.ts`)**: Handles business logic and parameter transformation\n3. **API Module (`api.ts`)**: Manages HTTP requests to the SonarQube API\n4. **Type Definitions**: TypeScript interfaces for type safety\n\n### Data Flow\n\n1. MCP clients make requests through registered tools\n2. Tool handlers validate and transform parameters\n3. SonarQube client methods process the requests\n4. API module executes HTTP requests\n5. Responses are formatted and returned to the client\n\n## Development\n\n### Prerequisites\n\n- Node.js 22 or higher\n- pnpm 10.17.0 or higher\n- Docker (for container builds)\n\n### Setup\n\n1. Clone the repository:\n\n```bash\ngit clone https://github.com/sapientpants/sonarqube-mcp-server.git\ncd sonarqube-mcp-server\n```\n\n1. Install dependencies:\n\n```bash\npnpm install\n```\n\n1. Build the project:\n\n```bash\npnpm build\n```\n\n### Development Commands\n\n```bash\n# Install dependencies\npnpm install\n\n# Build the project\npnpm build\n\n# Run in development mode with auto-reload\npnpm dev\n\n# Run tests\npnpm test\n\n# Run tests with coverage\npnpm test:coverage\n\n# Lint the code\npnpm lint\n\n# Fix linting issues\npnpm lint:fix\n\n# Check types\npnpm check-types\n\n# Format code\npnpm format\n\n# Run all validations\npnpm validate\n\n# Inspect MCP schema\npnpm inspect\n```\n\n### Testing\n\nThe project uses Jest for testing with:\n\n- Unit tests for all major components\n- Mocked HTTP responses using `nock`\n- Coverage reporting\n- TypeScript support\n\nRun specific test files:\n\n```bash\nNODE_ENV=test NODE_OPTIONS='--experimental-vm-modules --no-warnings' jest src/__tests__/file-name.test.ts\n```\n\n### Code Quality\n\nThe project maintains high code quality through:\n\n- TypeScript for type safety\n- ESLint for code linting\n- Prettier for code formatting\n- Jest for testing\n- SonarCloud for continuous code analysis\n\n## Common Issues and Solutions\n\n### Quick Fixes\n\n#### \"Authentication failed\"\n\n- **Cause**: Invalid or expired token\n- **Solution**: Generate a new token in SonarQube/SonarCloud\n\n#### \"Project not found\"\n\n- **Cause**: Incorrect project key or insufficient permissions\n- **Solution**: Verify the project key and check token permissions\n\n#### \"Organization required\"\n\n- **Cause**: Using SonarCloud without organization parameter\n- **Solution**: Add `SONARQUBE_ORGANIZATION` to your configuration\n\n#### \"Connection refused\"\n\n- **Cause**: Incorrect URL or network issues\n- **Solution**: Verify `SONARQUBE_URL` and network connectivity\n\n#### \"No output or errors visible\"\n\n- **Cause**: Errors might be happening but not visible in Claude Desktop\n- **Solution**: Enable logging with `LOG_FILE` and check the log file for detailed error messages\n\n### FAQ\n\n**Q: Can I use this with both SonarQube and SonarCloud?**\nA: Yes! Set the appropriate `SONARQUBE_URL` and include `SONARQUBE_ORGANIZATION` for SonarCloud.\n\n**Q: What permissions does my token need?**\nA: The token needs \"Execute Analysis\" permission and access to the projects you want to analyze.\n\n**Q: How do I filter issues by multiple criteria?**\nA: The `issues` tool supports extensive filtering. You can combine multiple parameters like severity, type, status, and date ranges.\n\n**Q: Can I analyze pull requests?**\nA: Yes! Many tools support `branch` and `pull_request` parameters for branch and PR analysis.\n\n## Troubleshooting\n\n### Common Error Messages and Solutions\n\n#### Authentication Errors\n\n##### Error: \"Authentication failed\"\n\n- **Solution**: Check that your SONARQUBE_TOKEN is valid and not expired. Generate a new token from your SonarQube user profile.\n\n##### Error: \"No SonarQube authentication configured\"\n\n- **Solution**: Set one of the following authentication methods:\n  - `SONARQUBE_TOKEN` for token-based authentication (recommended)\n  - `SONARQUBE_USERNAME` and `SONARQUBE_PASSWORD` for basic authentication\n  - `SONARQUBE_PASSCODE` for system passcode authentication\n\n#### Authorization Errors\n\n##### Error: \"Access denied\"\n\n- **Solution**: Ensure your token has the required permissions for the operation. Common required permissions:\n  - \"Execute Analysis\" for code analysis\n  - \"Browse\" for reading project data\n  - \"Administer Issues\" for issue management operations\n\n#### Resource Not Found Errors\n\n##### Error: \"Resource not found\"\n\n- **Solution**: Verify that:\n  - The project key/component exists in SonarQube\n  - You have access to the resource\n  - The URL path is correct (no typos in project keys)\n\n#### Network and Connection Errors\n\n##### Error: \"Connection refused\"\n\n- **Solution**: Check that:\n  - The SonarQube server is running\n  - The SONARQUBE_URL is correct\n  - There are no firewall rules blocking the connection\n\n##### Error: \"Network error\" or timeout errors\n\n- **Solution**:\n  - Verify your network connection\n  - Check if the SonarQube server is accessible\n  - Ensure the URL doesn't have a trailing slash\n  - For self-hosted instances, verify SSL certificates\n\n#### Rate Limiting\n\n##### Error: \"Rate limit exceeded\"\n\n- **Solution**: The server automatically retries rate-limited requests with exponential backoff. If you continue to hit rate limits:\n  - Reduce the frequency of your requests\n  - Implement request batching where possible\n  - Contact your SonarQube administrator to increase rate limits\n\n#### Configuration Errors\n\n##### Error: \"Invalid SONARQUBE_URL\"\n\n- **Solution**: Provide a valid URL including the protocol:\n  - ✅ Correct: `https://sonarcloud.io`\n  - ✅ Correct: `https://sonarqube.example.com`\n  - ❌ Wrong: `sonarcloud.io` (missing protocol)\n  - ❌ Wrong: `https://sonarqube.example.com/` (trailing slash)\n\n### Debugging Tips\n\n1. **Enable Debug Logging**:\n\n   ```bash\n   export LOG_LEVEL=DEBUG\n   ```\n\n2. **Check Environment Variables**:\n\n   ```bash\n   echo $SONARQUBE_URL\n   echo $SONARQUBE_TOKEN\n   echo $SONARQUBE_ORGANIZATION\n   ```\n\n3. **Test Connection**:\n   Use the `ping` tool to verify connectivity:\n\n   ```bash\n   # In your MCP client\n   sonarqube.ping\n   ```\n\n4. **Verify Permissions**:\n   Use the `projects` tool to list accessible projects:\n   ```bash\n   # In your MCP client\n   sonarqube.projects\n   ```\n\n### Retry Behavior\n\nThe server automatically retries failed requests for transient errors:\n\n- **Network errors**: Retried up to 3 times\n- **Rate limiting**: Retried with exponential backoff\n- **Server errors (5xx)**: Retried up to 3 times\n\nRetry delays: 1s → 2s → 4s (capped at 10s)\n\n### Getting Help\n\nIf you continue to experience issues:\n\n1. Check the [GitHub Issues](https://github.com/sapientpants/sonarqube-mcp-server/issues) for similar problems\n2. Enable debug logging and collect error details\n3. Create a new issue with:\n   - Error messages\n   - Environment details (OS, Node version)\n   - SonarQube version\n   - Steps to reproduce\n\n## Contributing\n\nWe welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.\n\n### How to Contribute\n\n1. Fork the repository\n2. Create a feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n\n### Development Guidelines\n\n- Write tests for new features\n- Update documentation as needed\n- Follow the existing code style\n- Ensure all tests pass\n- Add appropriate error handling\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## External Resources\n\n### SonarQube Documentation\n\n- [SonarQube Documentation](https://docs.sonarqube.org/latest/)\n- [SonarCloud Documentation](https://docs.sonarcloud.io/)\n- [Web API Documentation](https://docs.sonarqube.org/latest/extend/web-api/)\n\n### Model Context Protocol\n\n- [MCP Documentation](https://modelcontextprotocol.io/)\n- [MCP Specification](https://github.com/modelcontextprotocol/specification)\n- [MCP TypeScript SDK](https://github.com/modelcontextprotocol/typescript-sdk)\n\n---\n\nMade with ❤️ by the SonarQube MCP Server community",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "sonarqube",
        "logging",
        "ai",
        "sonarqube mcp",
        "integrates sonarqube",
        "sonarqube provide"
      ],
      "category": "monitoring-and-logging"
    },
    "seekrays--mcp-monitor": {
      "owner": "seekrays",
      "name": "mcp-monitor",
      "url": "https://github.com/seekrays/mcp-monitor",
      "imageUrl": "/freedevtools/mcp/pfp/seekrays.webp",
      "description": "Exposes system metrics such as CPU, memory, disk, network, and host information through an MCP-compatible interface, enabling real-time retrieval of system data for LLMs.",
      "stars": 71,
      "forks": 15,
      "license": "Apache License 2.0",
      "language": "Go",
      "updated_at": "2025-10-02T04:26:49Z",
      "readme_content": "# MCP System Monitor\n![Go](https://github.com/seekrays/mcp-monitor/actions/workflows/go.yml/badge.svg)\n![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/seekrays/mcp-monitor?sort=semver)\n[![Discord](https://img.shields.io/badge/Discord-Join%20Chat-blue?style=flat&logo=discord)](https://discord.gg/kbMJ9Qpf)\n\nA system monitoring tool that exposes system metrics via the Model Context Protocol (MCP). This tool allows LLMs to retrieve real-time system information through an MCP-compatible interface.\n\n\n\n## Features\n\nThis tool provides the following monitoring capabilities:\n\n- **CPU Information**: Usage percentage, core count, and detailed CPU info\n- **Memory Information**: Virtual and swap memory usage\n- **Disk Information**: Disk usage, partitions, and I/O statistics\n- **Network Information**: Network interfaces, connections, and traffic statistics\n- **Host Information**: System details, uptime, boot time, and users\n- **Process Information**: Process listing, sorting, and detailed per-process statistics\n\n\n## Available Tools\n\n### 1. CPU Information\n\n```\nTool: get_cpu_info\nDescription: Get CPU information and usage\nParameters:\n  - per_cpu (boolean, default: false): Whether to return data for each core\n```\n\n### 2. Memory Information\n\n```\nTool: get_memory_info\nDescription: Get system memory usage information\nParameters: None\n```\n\n### 3. Disk Information\n\n```\nTool: get_disk_info\nDescription: Get disk usage information\nParameters:\n  - path (string, default: \"/\"): Specify the disk path to query\n  - all_partitions (boolean, default: false): Whether to return information for all partitions\n```\n\n### 4. Network Information\n\n```\nTool: get_network_info\nDescription: Get network interface and traffic information\nParameters:\n  - interface (string, optional): Specify the network interface name to query\n```\n\n### 5. Host Information\n\n```\nTool: get_host_info\nDescription: Get host system information\nParameters: None\n```\n\n### 6. Process Information\n\n```\nTool: get_process_info\nDescription: Get process information\nParameters:\n  - pid (number, optional): Process ID to get detailed information for a specific process\n  - limit (number, default: 10): Limit the number of processes returned\n  - sort_by (string, default: \"cpu\"): Sort field (cpu, memory, pid, name)\n```\n\n\n## Installation\n\n```bash\ngit clone https://github.com/seekrays/mcp-monitor.git\ncd mcp-monitor\nmake build\n```\n\n## Usage\n\nRun the compiled binary:\n\n```bash\n./mcp-monitor\n```\n\nThe server starts in stdio mode, ready to communicate with an MCP-compatible LLM client.\n\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "monitoring",
        "llms",
        "mcp",
        "mcp monitor",
        "logging seekrays",
        "seekrays mcp"
      ],
      "category": "monitoring-and-logging"
    },
    "serkanh--cloudwatch-logs-mcp": {
      "owner": "serkanh",
      "name": "cloudwatch-logs-mcp",
      "url": "https://github.com/serkanh/cloudwatch-logs-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/serkanh.webp",
      "description": "Access and analyze AWS CloudWatch logs by listing log groups and retrieving log entries directly through an AI interface. Streamline log management and enhance monitoring capabilities.",
      "stars": 25,
      "forks": 1,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-05-29T10:08:33Z",
      "readme_content": "# CloudWatch Logs MCP Server\n\nAn MCP (Model Context Protocol) server that provides tools for accessing AWS CloudWatch logs. This server allows AI assistants to list log groups and read log entries from AWS CloudWatch.\n\n## Available Tools\n\n### list_groups\n\nLists available CloudWatch log groups.\n\n**Parameters:**\n\n- `prefix` (optional): Log group name prefix\n- `region` (optional): AWS region\n- `accessKeyId` (optional): AWS access key ID\n- `secretAccessKey` (optional): AWS secret access key\n- `sessionToken` (optional): AWS session token\n\n**Returns:** JSON string with the list of log groups, including `logGroupName`, `creationTime`, and `storedBytes`.\n\n### get_logs\n\nGets CloudWatch logs from a specific log group.\n\n**Parameters:**\n\n- `logGroupName` (required): The name of the log group\n- `logStreamName` (optional): The name of the log stream\n- `startTime` (optional): Start time in ISO format or relative time (e.g., \"5m\", \"1h\", \"1d\")\n- `endTime` (optional): End time in ISO format\n- `filterPattern` (optional): Filter pattern for the logs\n- `region` (optional): AWS region\n- `accessKeyId` (optional): AWS access key ID\n- `secretAccessKey` (optional): AWS secret access key\n- `sessionToken` (optional): AWS session token\n\n**Returns:** JSON string with the log events, including `timestamp`, `message`, and `logStreamName`.\n\n## Setup\n\n### AWS Credentials\n\nEnsure you have AWS credentials configured. You can set them up using the AWS CLI or by setting environment variables:\n\n- `AWS_ACCESS_KEY_ID`\n- `AWS_SECRET_ACCESS_KEY`\n\n### Usage with Claude Desktop\n\nAdd the following to your `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"cloudwatch-logs\": {\n      \"command\": \"python3\",\n      \"args\": [\"/path/to/cloudwatch-logs-mcp/main.py\"],\n      \"env\": {\n        \"AWS_ACCESS_KEY_ID\": \"<YOUR_ACCESS_KEY_ID>\",\n        \"AWS_SECRET_ACCESS_KEY\": \"<YOUR_SECRET_ACCESS_KEY>\",\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\n### Docker\n\nIf you prefer to run the server in a Docker container, you can set up a Dockerfile and use the following configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"cloudwatch-logs\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-e\",\n        \"AWS_ACCESS_KEY_ID\",\n        \"-e\",\n        \"AWS_SECRET_ACCESS_KEY\",\n        \"mcp/cloudwatch-logs\"\n      ],\n      \"env\": {\n        \"AWS_ACCESS_KEY_ID\": \"<YOUR_ACCESS_KEY_ID>\",\n        \"AWS_SECRET_ACCESS_KEY\": \"<YOUR_SECRET_ACCESS_KEY>\",\n      }\n    }\n  }\n}\n```\n\n## Implementation Details\n\nThis server is built using the FastMCP class from the MCP SDK, which provides a simple way to create MCP servers. The server exposes two main tools:\n\n1. `list_groups`: Lists available CloudWatch log groups\n2. `get_logs`: Reads log entries from specific log groups\n\nEach tool is implemented as an async function decorated with `@mcp.tool()`. The server uses the boto3 library to interact with the AWS CloudWatch Logs API.\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "cloudwatch",
        "logging",
        "logs",
        "cloudwatch logs",
        "aws cloudwatch",
        "serkanh cloudwatch"
      ],
      "category": "monitoring-and-logging"
    },
    "signal-slot--mcp-systemd-coredump": {
      "owner": "signal-slot",
      "name": "mcp-systemd-coredump",
      "url": "https://github.com/signal-slot/mcp-systemd-coredump",
      "imageUrl": "/freedevtools/mcp/pfp/signal-slot.webp",
      "description": "Access and manage system core dumps using systemd functionality, enabling the listing, extraction, and removal of core dumps for effective debugging. Analyze core dump data to enhance system diagnostics and troubleshooting capabilities.",
      "stars": 2,
      "forks": 3,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-05-06T04:03:09Z",
      "readme_content": "# systemd-coredump MCP Server\n\nA Model Context Protocol (MCP) server for interacting with systemd-coredump functionality. This enables MCP-capable applications to access, manage, and analyze system core dumps.\n\n[![npm version](https://img.shields.io/npm/v/@taskjp/server-systemd-coredump.svg?v=0.1.1)](https://www.npmjs.com/package/@taskjp/server-systemd-coredump)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\n## Features\n\n- List all available coredumps in the system\n- Get detailed information about specific coredumps\n- Extract coredump files to a specified location\n- Remove coredumps from the system\n\n## Prerequisites\n\n- Node.js 18+ and npm\n- systemd-coredump must be installed and configured on the system\n- `coredumpctl` command-line utility must be available\n\n## Installation\n\n### From npm (recommended)\n\n#### Global Installation\n\n```bash\nnpm install -g @taskjp/server-systemd-coredump\n```\n\n#### Local Installation\n\n```bash\nnpm install @taskjp/server-systemd-coredump\n```\n\n### From Source\n\n1. Clone the repository or download the source code\n2. Install dependencies:\n\n```bash\ncd systemd-coredump-server\nnpm install\n```\n\n3. Build the server:\n\n```bash\nnpm run build\n```\n\n## Configuration\n\nAdd the server to your MCP settings configuration file:\n\n### If installed from npm globally:\n\n```json\n\"systemd-coredump\": {\n  \"command\": \"systemd-coredump-server\",\n  \"args\": [],\n  \"disabled\": false,\n  \"autoApprove\": []\n}\n```\n\n### If installed from npm locally:\n\n```json\n\"systemd-coredump\": {\n  \"command\": \"node\",\n  \"args\": [\"node_modules/@taskjp/server-systemd-coredump/build/index.js\"],\n  \"disabled\": false,\n  \"autoApprove\": []\n}\n```\n\n### If installed from source:\n\n```json\n\"systemd-coredump\": {\n  \"command\": \"node\",\n  \"args\": [\"/path/to/systemd-coredump-server/build/index.js\"],\n  \"disabled\": false,\n  \"autoApprove\": []\n}\n```\n\n## Usage\n\n### Available Tools\n\nThe server provides the following tools:\n\n1. **list_coredumps**: List all available coredumps in the system\n\n   ```json\n   {\n     \"name\": \"list_coredumps\"\n   }\n   ```\n\n2. **get_coredump_info**: Get detailed information about a specific coredump\n\n   ```json\n   {\n     \"name\": \"get_coredump_info\",\n     \"arguments\": {\n       \"id\": \"2023-04-20 12:34:56-12345\"\n     }\n   }\n   ```\n\n3. **extract_coredump**: Extract a coredump to a file\n\n   ```json\n   {\n     \"name\": \"extract_coredump\",\n     \"arguments\": {\n       \"id\": \"2023-04-20 12:34:56-12345\",\n       \"outputPath\": \"/path/to/output/core.dump\"\n     }\n   }\n   ```\n\n4. **remove_coredump**: Remove a coredump from the system\n\n   ```json\n   {\n     \"name\": \"remove_coredump\",\n     \"arguments\": {\n       \"id\": \"2023-04-20 12:34:56-12345\"\n     }\n   }\n   ```\n\n5. **get_coredump_config**: Get the current core dump configuration of the system\n\n   ```json\n   {\n     \"name\": \"get_coredump_config\"\n   }\n   ```\n\n   This tool returns information about the current core dump configuration, including:\n   - Whether core dumps are enabled\n   - The current core pattern\n   - The core size limit\n   - Whether systemd is handling the core dumps\n\n6. **set_coredump_enabled**: Enable or disable core dump generation\n\n   ```json\n   {\n     \"name\": \"set_coredump_enabled\",\n     \"arguments\": {\n       \"enabled\": true\n     }\n   }\n   ```\n\n   Setting `enabled` to `true` will enable core dumps, while `false` will disable them.\n   Note: This changes the ulimit settings for the current shell. For permanent system-wide\n   changes, root privileges and modification of system configuration files would be required.\n\n7. **get_stacktrace**: Get stack trace from a coredump using GDB\n\n   ```json\n   {\n     \"name\": \"get_stacktrace\",\n     \"arguments\": {\n       \"id\": \"2023-04-20 12:34:56-12345\"\n     }\n   }\n   ```\n\n   This tool uses GDB to extract a formatted stack trace from the coredump.\n   Note: Requires the GDB debugger to be installed on the system.\n\n### Available Resources\n\nThe server exposes two types of resources:\n\n1. **Coredump Information**\n   - URI format: `coredump:///<id>`\n   - Returns JSON with detailed coredump information\n\n2. **Stack Traces**\n   - URI format: `stacktrace:///<id>`\n   - Returns a formatted stack trace from the coredump\n\nWhere `<id>` is the unique identifier for a coredump in the format: `<timestamp>-<pid>`.\n\nFor example:\n\n```\ncoredump:///2023-04-20 12:34:56-12345\nstacktrace:///2023-04-20 12:34:56-12345\n```\n\n## Note on Permissions\n\nSome operations may require elevated privileges, especially when extracting or removing coredumps. Ensure the user running the MCP server has appropriate permissions to access system coredumps.\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "coredump",
        "systemd",
        "core",
        "systemd coredump",
        "core dump",
        "core dumps"
      ],
      "category": "monitoring-and-logging"
    },
    "srtux--mcp": {
      "owner": "srtux",
      "name": "mcp",
      "url": "https://github.com/srtux/mcp",
      "imageUrl": "/freedevtools/mcp/pfp/srtux.webp",
      "description": "Enables natural language queries for Google Cloud logs by converting user queries into Google Cloud Logging Query Language (LQL) and retrieving relevant log entries. Provides a REST API for integration and can be deployed on Google Cloud Run or GKE.",
      "stars": 1,
      "forks": 0,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-08-21T08:30:18Z",
      "readme_content": "# MCP Logging NL Query Server\n\nThis project provides a Model Context Protocol (MCP) server that allows developers and AI Agents to query Google Cloud Logging using natural language. The server uses Vertex AI Gemini 2.5 to translate natural language queries into Google Cloud Logging Query Language (LQL), then queries Cloud Logging and returns the results.\n\n## Features\n- **Natural language to LQL translation** using Vertex AI Gemini 2.5\n- **Flexible log querying**: filter on monitored resource, log name, severity, time, and more\n- **REST API** for easy integration\n- **Ready for deployment** on Google Cloud Run or GKE\n\n## API Usage\n\n### Endpoints\n\n#### 1. Natural Language Query\n`POST /logs/nl_query`\n\nRequest:\n```json\n{\n  \"query\": \"Show me all error logs from yesterday for my Cloud Run service 'my-service'\",\n  \"max_results\": 20\n}\n```\nResponse:\n```json\n{\n  \"lql\": \"resource.type = \\\"cloud_run_revision\\\" AND resource.labels.service_name = \\\"my-service\\\" AND severity = ERROR AND timestamp >= \\\"2025-04-17T00:00:00Z\\\" AND timestamp < \\\"2025-04-18T00:00:00Z\\\"\",\n  \"entries\": [ ... log entries ... ]\n}\n```\n\n#### 2. LQL Filter Query\n`POST /logs/query`\n\nRequest:\n```json\n{\n  \"filter\": \"resource.type=\\\"cloud_run_revision\\\" AND severity=ERROR\",\n  \"max_results\": 20\n}\n```\nResponse:\n```json\n{\n  \"lql\": \"resource.type=\\\"cloud_run_revision\\\" AND severity=ERROR\",\n  \"entries\": [ ... log entries ... ]\n}\n```\n\n### OpenAPI & Tooling\n- OpenAPI/Swagger docs available at `/docs` and `/openapi.json` when running.\n- Both endpoints are also discoverable as MCP tools for agent frameworks (Smithery, Claude Desktop, etc).\n\n### Example curl commands\n```sh\ncurl -X POST $MCP_BASE_URL/logs/nl_query -H 'Content-Type: application/json' -d '{\"query\": \"Show error logs for my Cloud Run service\", \"max_results\": 2}'\n\ncurl -X POST $MCP_BASE_URL/logs/query -H 'Content-Type: application/json' -d '{\"filter\": \"resource.type=\\\"cloud_run_revision\\\" AND severity=ERROR\", \"max_results\": 2}'\n```\n\n### Tests\n- Example test script: `test_main.py` (see repo)\n\n### .gitignore\n- Standard Python ignores included (see repo)\n\n## Deployment\n\n### Running on Google Cloud Run\nYou can deploy this server to [Google Cloud Run](https://cloud.google.com/run) for a fully managed, scalable solution.\n\n**Steps:**\n1. **Build the Docker image:**\n   ```sh\n   gcloud builds submit --tag gcr.io/YOUR_PROJECT_ID/mcp-logging-server\n   ```\n2. **Deploy to Cloud Run:**\n   ```sh\n   gcloud run deploy mcp-logging-server \\\n     --image gcr.io/YOUR_PROJECT_ID/mcp-logging-server \\\n     --platform managed \\\n     --region YOUR_REGION \\\n     --allow-unauthenticated \\\n     --port 8080\n   ```\n   Replace `YOUR_PROJECT_ID` and `YOUR_REGION` with your actual GCP project ID and region (e.g., `us-central1`).\n\n3. **Set Environment Variables:**\n   - In the Cloud Run deployment UI or with the `--set-env-vars` flag, provide:\n     - `VERTEX_PROJECT=your-gcp-project-id`\n     - `VERTEX_LOCATION=us-central1` (or your region)\n   - **Credentials:**\n     - Prefer using the Cloud Run service account with the right IAM roles (Logging Viewer, Vertex AI User).\n     - You usually do NOT need to set `GOOGLE_APPLICATION_CREDENTIALS` on Cloud Run unless using a non-default service account key.\n\n4. **IAM Permissions:**\n   - Ensure the Cloud Run service account has:\n     - `roles/logging.viewer`\n     - `roles/aiplatform.user`\n\n5. **Accessing the Service:**\n   - After deployment, Cloud Run will provide a service URL (e.g., `https://mcp-logging-server-xxxxxx.a.run.app`).\n   - Use this as your `$MCP_BASE_URL` in API requests.\n\n### Google Cloud Authentication Setup\nThis project requires Google Cloud Application Default Credentials (ADC) to access Logging and Vertex AI APIs.\n\n**Steps to Set Up Credentials:**\n1. **Create a Service Account:**\n   - Go to the [Google Cloud Console → IAM & Admin → Service Accounts](https://console.cloud.google.com/iam-admin/serviceaccounts).\n   - Select your project.\n   - Create or select a service account with permissions: _Logging Viewer_ and _Vertex AI User_.\n2. **Create and Download a Key:**\n   - In the Service Account, click \"Manage keys\" → \"Add key\" → \"Create new key\" (choose JSON).\n   - Download the JSON key file to your computer.\n3. **Set the Environment Variable:**\n   - In your terminal, set the environment variable to the path of your downloaded key:\n     ```sh\n     export GOOGLE_APPLICATION_CREDENTIALS=\"/path/to/your/service-account-key.json\"\n     ```\n   - Replace `/path/to/your/service-account-key.json` with the actual path.\n4. **(Optional) Set Project and Location:**\n   - You may also need:\n     ```sh\n     export VERTEX_PROJECT=your-gcp-project-id\n     export VERTEX_LOCATION=us-central1\n     ```\n5. **Verify Authentication:**\n   - Run a simple `gcloud` or Python client call to ensure authentication is working.\n   - If you see `DefaultCredentialsError`, check your environment variable and file path.\n\n### Prerequisites\n- Python 3.9+\n- Google Cloud project with Logging and Vertex AI APIs enabled\n- Service account with permissions for Logging Viewer and Vertex AI User\n- Set environment variables:\n  - `VERTEX_PROJECT`: Your GCP project ID\n  - `VERTEX_LOCATION`: Vertex AI region (default: `us-central1`)\n  - `GOOGLE_APPLICATION_CREDENTIALS`: Path to your service account JSON key file\n\n### Local Development\n```sh\npip install -r requirements.txt\nexport VERTEX_PROJECT=your-project-id\nexport VERTEX_LOCATION=us-central1\nexport GOOGLE_APPLICATION_CREDENTIALS=/path/to/key.json\npython main.py\n```\n\n### Deploy to Cloud Run\n```sh\ngcloud builds submit --tag gcr.io/$VERTEX_PROJECT/mcp-logging-server\n gcloud run deploy mcp-logging-server \\\n    --image gcr.io/$VERTEX_PROJECT/mcp-logging-server \\\n    --platform managed \\\n    --region $VERTEX_LOCATION \\\n    --allow-unauthenticated\n```\n\n## Example Natural Language Queries\n- Show all logs from Kubernetes clusters\n- Show error logs from Compute Engine and AWS EC2 instances\n- Find Admin Activity audit logs for project my-project\n- Find logs containing the word unicorn\n- Find logs with both unicorn and phoenix\n- Find logs where textPayload contains both unicorn and phoenix\n- Find logs where textPayload contains the phrase 'unicorn phoenix'\n- Show logs from yesterday for Cloud Run service 'my-service'\n- Show logs from the last 30 minutes\n- Show logs for logName containing request_log in GKE\n- Show logs where pod_name matches foo or bar using regex\n- Show logs for Compute Engine where severity is WARNING or higher\n- Show logs for Cloud SQL instances in us-central1\n- Show logs for Pub/Sub topics containing 'payments'\n- Show logs for log entries between two timestamps\n- Show logs where jsonPayload.message matches regex 'foo.*bar'\n- Show logs where labels.env is not prod\n\nFor more LQL examples, see the [official documentation](https://cloud.google.com/logging/docs/view/logging-query-language).\n\n## License\nApache 2.0\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "logging",
        "logs",
        "log",
        "logging srtux",
        "cloud logging",
        "cloud logs"
      ],
      "category": "monitoring-and-logging"
    },
    "tgeselle--bugsnag-mcp": {
      "owner": "tgeselle",
      "name": "bugsnag-mcp",
      "url": "https://github.com/tgeselle/bugsnag-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/tgeselle.webp",
      "description": "Interacts with Bugsnag to monitor and analyze errors, providing features for organization navigation, error filtering, and detailed stacktrace viewing. It also offers code intelligence capabilities to distinguish between project and library code and provides source code context for errors.",
      "stars": 18,
      "forks": 4,
      "license": "No License",
      "language": "API Blueprint",
      "updated_at": "2025-09-18T17:02:18Z",
      "readme_content": "# Bugsnag MCP Server\n\nA Model Context Protocol (MCP) server for interacting with Bugsnag. This server allows LLM tools like Cursor and Claude to investigate and resolve issues in Bugsnag.\n\n## ✨ Features\n\n### Error Monitoring & Analysis\n- **Organization & Project Navigation**: Easily browse your Bugsnag hierarchy\n- **Error & Event Filtering**: Find specific issues with powerful filtering options\n- **Detailed Stacktrace Viewing**: See formatted stacktraces with source code context and highlighted error lines\n- **Exception Chain Visualization**: Understand the root cause by viewing the full exception chain\n\n### Code Intelligence\n- **Project vs. Library Code Distinction**: Clearly identify your code vs third-party libraries\n- **Source Code Context**: View relevant code snippets around error locations\n- **Error Patterns**: Identify recurring patterns across multiple errors\n\n### Issue Management\n- **Search Capabilities**: Find issues by error class, message, or app version\n- **Error Details**: Get comprehensive information about each error\n- **Event History**: View all occurrences of a specific error\n\n## 🚀 Quick Setup\n\nSetting up the Bugsnag MCP server is simple and doesn't require any installation or downloading source code.\n\n### For Cursor\n\n1. Add the Bugsnag MCP server configuration:\n   ```json\n   {\n     \"mcpServers\": {\n       \"bugsnag\": {\n         \"command\": \"npx\",\n         \"args\": [\"-y\", \"bugsnag-mcp-server\"],\n         \"env\": {\n           \"BUGSNAG_API_KEY\": \"your-bugsnag-api-key\"\n         },\n         \"disabled\": false,\n         \"alwaysAllow\": []\n       }\n     }\n   }\n   ```\n\n2. Replace `your-bugsnag-api-key` with your Bugsnag API key\n\n### For Claude Desktop\n\n1. Add the Bugsnag MCP server configuration:\n   ```json\n   {\n     \"mcpServers\": {\n       \"bugsnag\": {\n         \"command\": \"npx\",\n         \"args\": [\"-y\", \"bugsnag-mcp-server\"],\n         \"env\": {\n           \"BUGSNAG_API_KEY\": \"your-bugsnag-api-key\"\n         },\n         \"disabled\": false,\n         \"alwaysAllow\": []\n       }\n     }\n   }\n   ```\n\n2. Replace `your-bugsnag-api-key` with your Bugsnag API key\n\n## 🔑 Obtaining a Bugsnag API Key\n\nTo use this MCP server, you'll need a Bugsnag API key:\n\n1. Log in to your Bugsnag account at [https://app.bugsnag.com/](https://app.bugsnag.com/)\n2. Go to **Settings** > **Organization settings** > **Access tokens**\n3. Create a new personal access token with the following permissions:\n   - Read projects\n   - Read and write errors\n   - Read and write comments\n4. Copy the generated token for use with the MCP server\n\n## 📋 Usage Examples\n\nOnce configured, you can use the Bugsnag MCP server with your LLM tool. Here are some example prompts:\n\n### Exploring Your Bugsnag Account\n\n```\nList all my Bugsnag organizations\n```\n\n```\nShow me all projects in organization \"org_12345\"\n```\n\n### Finding and Analyzing Errors\n\n```\nList the open errors in my Bugsnag project \"project_12345\"\n```\n\n```\nShow me the details for Bugsnag error ID \"error_12345\"\n```\n\n```\nShow me the detailed stacktrace for event \"event_12345\" in project \"project_12345\"\n```\n\n```\nView the exception chain for event \"event_12345\" in project \"project_12345\"\n```\n\n### Searching for Specific Issues\n\n```\nSearch for Bugsnag issues in project \"project_12345\" related to \"NullPointerException\"\n```\n\n```\nList all events for error \"error_12345\" in project \"project_12345\"\n```\n\n## 📚 Available Tools\n\nThe Bugsnag MCP server provides the following tools:\n\n### Organization & Project Management\n\n#### list_organizations\n\nLists available Bugsnag organizations.\n\nParameters:\n- None required\n\n#### list_projects\n\nLists projects in an organization.\n\nParameters:\n- `organization_id` (required): Bugsnag organization ID\n\n### Error & Event Management\n\n#### list_errors\n\nLists errors in a project with filtering options.\n\nParameters:\n- `project_id` (required): Bugsnag project ID\n- `status`: Filter by error status (\"open\", \"fixed\", \"ignored\")\n- `sort`: Sort order for errors (\"newest\", \"oldest\", \"priority\")\n- `limit`: Maximum number of errors to return\n\n#### view_error\n\nGets detailed information about a specific error.\n\nParameters:\n- `error_id` (required): Bugsnag error ID\n\n#### list_error_events\n\nLists events (occurrences) for a specific error.\n\nParameters:\n- `project_id` (required): Bugsnag project ID\n- `error_id` (required): Bugsnag error ID\n- `limit`: Maximum number of events to return\n\n#### view_latest_event\n\nViews the latest event for an error.\n\nParameters:\n- `error_id` (required): Bugsnag error ID\n\n#### view_event\n\nViews detailed information about a specific event.\n\nParameters:\n- `project_id` (required): Bugsnag project ID\n- `event_id` (required): Bugsnag event ID\n\n### Stacktrace Analysis\n\n#### view_stacktrace\n\nExtracts and formats stacktrace information from an event.\n\nParameters:\n- `project_id` (required): Bugsnag project ID\n- `event_id` (required): Bugsnag event ID\n- `include_code`: Include source code context if available (default: true)\n\n#### view_exception_chain\n\nViews the full chain of exceptions for an event.\n\nParameters:\n- `project_id` (required): Bugsnag project ID\n- `event_id` (required): Bugsnag event ID\n\n### Issue Management\n\n#### search_issues\n\nSearches for issues using various criteria.\n\nParameters:\n- `project_id` (required): Bugsnag project ID\n- `query`: Search query\n- `error_class`: Filter by error class\n- `app_version`: Filter by app version\n\n## 🛠️ Advanced Usage\n\n### Testing Your API Key\n\nYou can test if your Bugsnag API key is valid using:\n\n```bash\nnpx bugsnag-mcp-server test-api-key your-bugsnag-api-key\n```\n\nIf your API key is valid, this will display a list of your Bugsnag projects with their IDs.\n\n### Installation Options\n\nWhile using `npx` is recommended for most users, you can also install the package globally if you prefer:\n\n```bash\nnpm install -g bugsnag-mcp-server\n```\n\n### For Developers\n\nIf you're interested in contributing or modifying the code:\n\n1. Clone the repository:\n   ```bash\n   git clone https://github.com/yourusername/bugsnag-mcp.git\n   cd bugsnag-mcp\n   ```\n\n2. Install dependencies:\n   ```bash\n   npm install\n   ```\n\n3. Build the project:\n   ```bash\n   npm run build\n   ```\n\n4. Run tests:\n   ```bash\n   npm test\n   ```\n\n5. Run tests with coverage:\n   ```bash\n   npm run test:coverage\n   ```\n\n6. Format code:\n  ```bash\n  npm run format\n  ```\n\n7. Check code formatting:\n  ```bash\n  npm run format:check\n  ```\n\n### Continuous Integration\n\nThis project uses GitHub Actions for continuous integration. The workflows automatically:\n\n- Runs on push to the main branch and on pull requests\n- Tests against multiple Node.js versions (18.x and 20.x)\n- Runs the test suite\n- Generates and uploads test coverage reports\n- Checks code formatting with Prettier\n\nYou can view the workflow configurations in:\n- `.github/workflows/test.yml` - For running tests\n- `.github/workflows/prettier.yml` - For checking code formatting\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "bugsnag",
        "monitoring",
        "stacktrace",
        "bugsnag mcp",
        "interacts bugsnag",
        "bugsnag monitor"
      ],
      "category": "monitoring-and-logging"
    },
    "truaxki--mcp-variance-log": {
      "owner": "truaxki",
      "name": "mcp-variance-log",
      "url": "https://github.com/truaxki/mcp-variance-log",
      "imageUrl": "/freedevtools/mcp/pfp/truaxki.webp",
      "description": "Logs unusual events in conversations and analyzes statistical variations, storing the results in a SQLite database. Designed for use with MCP-compatible clients like Claude Desktop, it enhances interaction by monitoring conversation structure.",
      "stars": 4,
      "forks": 3,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-04-26T00:17:05Z",
      "readme_content": "# MCP Variance Log\n\nAgentic tool that looks for statistical variations in conversation structure and logs unusual events to a SQLite database. Built using the Model Context Protocol (MCP), this system is designed to be used with Claude Desktop or other MCP-compatible clients.\n\n<a href=\"https://glama.ai/mcp/servers/acqq8twrk6\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/acqq8twrk6/badge\" alt=\"Variance Log MCP server\" /></a>\n\n## Requirements\n\n- Python ≥3.10\n- MCP ≥1.2.0\n- SQLite3\n- UV (Python package installer and environment manager)\n\n## Quick Start\n\n```bash\n# Clone and install\ngit clone https://github.com/truaxki/mcp-variance-log.git\ncd mcp-variance-log\nuv pip install -e .\n```\n\nAdd to Claude Desktop config (`%APPDATA%\\Claude\\claude_desktop_config.json` on Windows):\n```json\n{\n  \"mcpServers\": {\n    \"mcp-variance-log\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"C:\\\\Users\\\\username\\\\source\\\\repos\\\\mcp-variance-log\",  # Update this path\n        \"run\",\n        \"mcp-variance-log\"\n      ]\n    }\n  }\n}\n```\n\nAdd to Claude Desktop preferences:\n```\nAutomatic Logging Process:\n- Silently monitor each interaction\n- When MEDIUM or LOW probability events occur, use this tool to log them\n- Each log includes context and reasoning\n- Logging happens without disrupting conversation flow\n```\n\n## Usage\n\n### Automatic Logging Examples\n```\nprompt: \"What if I told you I could lift 1000 lbs?\"\n\n{\n  `user_id`: `user_1`,\n  `reasoning`: `Claim of 1000 lb lift capability is highly unusual as it approaches world record territory, warranting logging as a MEDIUM probability event`,\n  `session_id`: `session_1`,\n  `context_summary`: `User made an extremely improbable claim about personal strength capabilities`,\n  `message_content`: `What if i told you i could lift 1000 lbs?`,\n  `interaction_type`: `claim_verification`,\n  `response_content`: `That would be extremely unlikely. The current world record for weight lifted by a human (deadlift) is 1,104.5 lbs, set by Hafthor Björnsson in 2020 under very specific conditions. Only a handful of people in history have lifted close to 1,000 lbs.`,\n  `probability_class`: `MEDIUM`\n}\n```\n\n```\nprompt: \"What if I told you I'm a Data Scientist that can lift 1000 pounds?\"\n\n{\n  `user_id`: `user_1`,\n  `reasoning`: `User's follow-up combines unlikely strength claim with unrelated professional credential, suggesting potential pattern of unusual claims`,\n  `session_id`: `session_1`,\n  `context_summary`: `User added data scientist credential to previous improbable strength claim`,\n  `message_content`: `what if i told you I'm a data scientist that can lift 1000 pounds?`,\n  `interaction_type`: `claim_verification`,\n  `response_content`: `Your professional background as a data scientist doesn't make the 1000-pound lift claim more plausible. Such a lift would still be near the all-time world record of 1,104.5 lbs.`,\n  `probability_class`: `LOW`\n}\n```\n\n### Dataframe view\n```\nprompt: \"Read-logs from this morning\"\n\nID   | Time         | Prob   | Type   | Context                                      \n------------------------------------------------------------------------------------------\n29   | 01-24 17:57  | LOW    | claim_ | User added data scientist credential to pr...\n28   | 01-24 17:56  | MEDIUM | claim_ | User made an extremely improbable claim ab...\n```\n\n### Text 2 SQL\n```\nprompt: \"Can you search the logs for entry 29?\"\n\n[{'log_id': 29, 'timestamp': '2025-01-24 17:57:07', 'session_id': 'session_1', 'user_id': 'user_1', 'interaction_type': 'claim_verification', 'probability_class': 'LOW', 'message_content': \"what if i told you I'm a data scientist that can lift 1000 pounds?\", 'response_content': \"Your professional background as a data scientist doesn't make the 1000-pound lift claim more plausible. Such a lift would still be near the all-time world record of 1,104.5 lbs.\", 'context_summary': 'User added data scientist credential to previous improbable strength claim', 'reasoning': \"User's follow-up combines unlikely strength claim with unrelated professional credential, suggesting potential pattern of unusual claims\"}]\n```\n\n\n## Detailed Installation\n\n1. Ensure Python 3.10+ and UV are installed.\n\nInstall UV using one of these methods:\n\n```bash\n# Using pip (recommended for Windows)\npip install uv\n\n# Using installation script (Linux/MacOS)\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n```\n\n2. Clone and install:\n```bash\ngit clone https://github.com/truaxki/mcp-variance-log.git\ncd mcp-variance-log\nuv pip install -e .\n```\n\n3. Configure Claude Desktop:\n\nAdd to `claude_desktop_config.json`:\n```json\n{\n  \"mcpServers\": {\n    \"mcp-variance-log\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"PATH_TO_REPO/mcp-variance-log\",\n        \"run\",\n        \"mcp-variance-log\"\n      ]\n    }\n  }\n}\n```\n\nConfig locations:\n- Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n- MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n- Linux: `~/.config/Claude/claude_desktop_config.json`\n\n## Tools\n\n### Monitoring\n- `log-query`: Tracks conversation patterns\n  - HIGH: Common interactions (not logged)\n  - MEDIUM: Unusual patterns (logged)\n  - LOW: Critical events (priority logged)\n\n### Query\n- `read-logs`: View logs with filtering\n- `read_query`: Execute SELECT queries\n- `write_query`: Execute INSERT/UPDATE/DELETE\n- `create_table`: Create tables\n- `list_tables`: Show all tables\n- `describe_table`: Show table structure\n\n\nLocated at `data/varlog.db` relative to installation.\n\n### Schema\n\n```sql\nCREATE TABLE chat_monitoring (\n    log_id INTEGER PRIMARY KEY AUTOINCREMENT,\n    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,\n    session_id TEXT NOT NULL,\n    user_id TEXT NOT NULL,\n    interaction_type TEXT NOT NULL,\n    probability_class TEXT CHECK(probability_class IN ('HIGH', 'MEDIUM', 'LOW')),\n    message_content TEXT NOT NULL,\n    response_content TEXT NOT NULL,\n    context_summary TEXT,\n    reasoning TEXT\n);\n```\n\n## Troubleshooting\n\n1. Database Access\n- Error: \"Failed to connect to database\"\n  - Check file permissions\n  - Verify path in config\n  - Ensure `/data` directory exists\n  \n2. Installation Issues\n- Error: \"No module named 'mcp'\"\n  - Run: `uv pip install mcp>=1.2.0`\n- Error: \"UV command not found\"\n  - Install UV: `curl -LsSf https://astral.sh/uv/install.sh | sh`\n  \n3. Configuration\n- Error: \"Failed to start MCP server\"\n  - Verify config.json syntax\n  - Check path separators (use \\\\ on Windows)\n  - Ensure UV is in your system PATH\n\n## Contributing\n\n1. Fork the repository\n2. Create feature branch\n3. Submit pull request\n\n## License\n\nMIT\n\n## Support\n\nIssues: [GitHub Issues](https://github.com/truaxki/mcp-variance-log/issues)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "logging",
        "logs",
        "monitoring",
        "monitoring conversation",
        "conversations analyzes",
        "logging truaxki"
      ],
      "category": "monitoring-and-logging"
    },
    "turbot--steampipe-mcp": {
      "owner": "turbot",
      "name": "steampipe-mcp",
      "url": "https://github.com/turbot/steampipe-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/turbot.webp",
      "description": "Enables natural language exploration and analysis of cloud infrastructure data across multiple platforms, including AWS, Azure, and GCP. Facilitates security and compliance checks, cost optimization, and query development through SQL queries powered by AI.",
      "stars": 27,
      "forks": 4,
      "license": "Apache License 2.0",
      "language": "TypeScript",
      "updated_at": "2025-10-03T07:25:10Z",
      "readme_content": "# Steampipe Model Context Protocol (MCP) Server\n\nUnlock the power of AI-driven infrastructure analysis with [Steampipe](https://steampipe.io)! This Model Context Protocol server seamlessly connects AI assistants like Claude to your cloud infrastructure data, enabling natural language exploration and analysis of your entire cloud estate.\n\nSteampipe MCP bridges AI assistants and your infrastructure data, allowing natural language:\n- Queries across AWS, Azure, GCP and 100+ cloud services\n- Security and compliance analysis\n- Cost and resource optimization\n- Query development assistance\n\nWorks with both local [Steampipe](https://steampipe.io/downloads) installations and [Turbot Pipes](https://turbot.com/pipes) workspaces, providing safe, read-only access to all your cloud and SaaS data.\n\n## Installation\n\n### Prerequisites\n\n- [Node.js](https://nodejs.org/) v16 or higher (includes `npx`)\n- For local use: [Steampipe](https://steampipe.io/downloads) installed and running (`steampipe service start`)\n- For Turbot Pipes: A [Turbot Pipes](https://turbot.com/pipes) workspace and connection string\n\n### Configuration\n\nAdd Steampipe MCP to your AI assistant's configuration file:\n\n```json\n{\n  \"mcpServers\": {\n    \"steampipe\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@turbot/steampipe-mcp\"\n      ]\n    }\n  }\n}\n```\n\nBy default, this connects to your local Steampipe installation at `postgresql://steampipe@localhost:9193/steampipe`. Make sure to run `steampipe service start` first.\n\nTo connect to a [Turbot Pipes](https://turbot.com/pipes) workspace instead, add your connection string to the args:\n\n```json\n{\n  \"mcpServers\": {\n    \"steampipe\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@turbot/steampipe-mcp\",\n        \"postgresql://my_name:my_pw@workspace-name.usea1.db.pipes.turbot.com:9193/abc123\"\n      ]\n    }\n  }\n}\n```\n\n### AI Assistant Setup\n\n| Assistant | Config File Location | Setup Guide |\n|-----------|---------------------|-------------|\n| Claude Desktop | `claude_desktop_config.json` | [Claude Desktop MCP Guide →](https://modelcontextprotocol.io/quickstart/user) |\n| Cursor | `~/.cursor/mcp.json` | [Cursor MCP Guide →](https://docs.cursor.com/context/model-context-protocol) |\n\nSave the configuration file and restart your AI assistant for the changes to take effect.\n\n## Prompting Guide\n\nFirst, run the `best_practices` prompt included in the MCP server to teach your LLM how best to work with Steampipe. Then, ask anything!\n\nExplore your cloud infrastructure:\n```\nWhat AWS accounts can you see?\n```\n\nSimple, specific questions work well:\n```\nShow me all S3 buckets that were created in the last week\n```\n\nGenerate infrastructure reports:\n```\nList my EC2 instances with their attached EBS volumes\n```\n\nDive into security analysis:\n```\nFind any IAM users with access keys that haven't been rotated in the last 90 days\n```\n\nGet compliance insights:\n```\nShow me all EC2 instances that don't comply with our tagging standards\n```\n\nExplore potential risks:\n```\nAnalyze my S3 buckets for security risks including public access, logging, and encryption\n```\n\nRemember to:\n- Be specific about which cloud resources you want to analyze (EC2, S3, IAM, etc.)\n- Mention regions or accounts if you're interested in specific ones\n- Start with simple queries before adding complex conditions\n- Use natural language - the LLM will handle the SQL translation\n- Be bold and exploratory - the LLM can help you discover insights across your entire infrastructure!\n\n## Capabilities\n\n### Tools\n\n- **steampipe_query**\n  - Query cloud and security logs with SQL.\n  - For best performance: use CTEs instead of joins, limit columns requested.\n  - All queries are read-only and use PostgreSQL syntax.\n  - Input: `sql` (string): The SQL query to execute using PostgreSQL syntax\n\n- **steampipe_table_list**\n  - List all available Steampipe tables.\n  - Optional input: `schema` (string): Filter tables by specific schema\n  - Optional input: `filter` (string): Filter tables by ILIKE pattern (e.g. '%ec2%')\n\n- **steampipe_table_show**\n  - Get detailed information about a specific table, including column definitions, data types, and descriptions.\n  - Input: `name` (string): The name of the table to show details for (can be schema qualified e.g. 'aws_account' or 'aws.aws_account')\n  - Optional input: `schema` (string): The schema containing the table\n\n- **steampipe_plugin_list**\n  - List all Steampipe plugins installed on the system. Plugins provide access to different data sources like AWS, GCP, or Azure.\n  - No input parameters required\n\n- **steampipe_plugin_show**\n  - Get details for a specific Steampipe plugin installation, including version, memory limits, and configuration.\n  - Input: `name` (string): Name of the plugin to show details for\n\n### Prompts\n\n- **best_practices**\n  - Best practices for working with Steampipe data\n  - Provides detailed guidance on:\n    - Response style and formatting conventions\n    - Using CTEs (WITH clauses) vs joins\n    - SQL syntax and style conventions\n    - Column selection and optimization\n    - Schema exploration and understanding\n    - Query structure and organization\n    - Performance considerations and caching\n    - Error handling and troubleshooting\n\n### Resources\n\n- **status**\n  - Represents the current state of the Steampipe connection\n  - Properties include:\n    - connection_string: The current database connection string\n    - status: The connection state (connected/disconnected)\n\nThis resource enables AI tools to check and verify the connection status to your Steampipe instance.\n\n## Development\n\n### Clone and Setup\n\n1. Clone the repository and navigate to the directory:\n```sh\ngit clone https://github.com/turbot/steampipe-mcp.git\ncd steampipe-mcp\n```\n\n2. Install dependencies:\n```sh\nnpm install\n```\n\n3. Build the project:\n```sh\nnpm run build\n```\n\n### Testing\n\nTo test your local development build with AI tools that support MCP, update your MCP configuration to use the local `dist/index.js` instead of the npm package. For example:\n\n```json\n{\n  \"mcpServers\": {\n    \"steampipe\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/absolute/path/to/steampipe-mcp/dist/index.js\",\n        \"postgresql://steampipe@localhost:9193/steampipe\"\n      ]\n    }\n  }\n}\n```\n\nOr, use the MCP Inspector to validate the server implementation:\n```sh\nnpx @modelcontextprotocol/inspector dist/index.js\n```\n\n### Environment Variables\n\nThe following environment variables can be used to configure the MCP server:\n\n- `STEAMPIPE_MCP_LOG_LEVEL`: Control server logging verbosity (default: `info`)\n- `STEAMPIPE_MCP_WORKSPACE_DATABASE`: Override the default Steampipe connection string (default: `postgresql://steampipe@localhost:9193/steampipe`)\n\n## Open Source & Contributing\n\nThis repository is published under the [Apache 2.0 license](https://www.apache.org/licenses/LICENSE-2.0). Please see our [code of conduct](https://github.com/turbot/.github/blob/main/CODE_OF_CONDUCT.md). We look forward to collaborating with you!\n\n[Steampipe](https://steampipe.io) is a product produced from this open source software, exclusively by [Turbot HQ, Inc](https://turbot.com). It is distributed under our commercial terms. Others are allowed to make their own distribution of the software, but they cannot use any of the Turbot trademarks, cloud services, etc. You can learn more in our [Open Source FAQ](https://turbot.com/open-source).\n\n## Get Involved\n\n**[Join #steampipe on Slack →](https://turbot.com/community/join)**\n\nWant to help but don't know where to start? Pick up one of the `help wanted` issues:\n* [Steampipe](https://github.com/turbot/steampipe/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22)\n* [Steampipe MCP](https://github.com/turbot/steampipe-mcp/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "cloud",
        "gcp",
        "steampipe",
        "analysis cloud",
        "cloud infrastructure",
        "steampipe mcp"
      ],
      "category": "monitoring-and-logging"
    },
    "twodoorsdev--react-native-debugger-mcp": {
      "owner": "twodoorsdev",
      "name": "react-native-debugger-mcp",
      "url": "https://github.com/twodoorsdev/react-native-debugger-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/twodoorsdev.webp",
      "description": "Connects to a React Native application debugger to retrieve console logs from Metro, facilitating real-time log access for debugging. Aids in identifying and resolving issues more efficiently during app development.",
      "stars": 26,
      "forks": 4,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-22T15:35:56Z",
      "readme_content": "# React Native Debugger MCP\n\nAn MCP server that connects to your React Native application debugger.\n\n## ✨ Key Features\n\n- Can retrieve console logs from Metro\n\n## 🚀 Quick Start\n\nAdd the following to your Claude Desktop/Cursor MCP config:\n\n```json\n{\n  \"mcpServers\": {\n    \"react-native-debugger-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@twodoorsdev/react-native-debugger-mcp\"]\n    }\n  }\n}\n```\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "debugger",
        "debugging",
        "react",
        "native debugger",
        "react native",
        "debugger mcp"
      ],
      "category": "monitoring-and-logging"
    },
    "vlttnv--k8s-mcp": {
      "owner": "vlttnv",
      "name": "k8s-mcp",
      "url": "https://github.com/vlttnv/k8s-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/vlttnv.webp",
      "description": "Retrieve and diagnose issues in Kubernetes clusters through a comprehensive API, offering insights into resource utilization and pod statuses. Access real-time data for effective cluster management and troubleshooting.",
      "stars": 8,
      "forks": 1,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-08-12T09:42:14Z",
      "readme_content": "# k8s-mcp\n[![smithery badge](https://smithery.ai/badge/@vlttnv/k8s-mcp)](https://smithery.ai/server/@vlttnv/k8s-mcp)\n\nA Python-based, read-only [Model Context Protocol (MCP)](https://modelcontextprotocol.io/introduction) server for Kubernetes clusters that exposes a comprehensive API to retrieve cluster information and diagnose issues.\n\n[Example chat using Claude](https://claude.ai/share/90ae39d3-a0c1-4065-ab79-45950b6b4806)\n\n## Installation\n\n### Prerequisites\n\n- Python 3.8+\n- Access to a Kubernetes cluster (via kubeconfig or in-cluster configuration)\n- Required Python packages (see `dependencies` in `pyproject.toml`)\n- uv - https://github.com/astral-sh/uv\n\n```bash\n# To install uv\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n```\n\n```bash\n# Clone the repository\ngit clone git@github.com:vlttnv/k8s-mcp.git\ncd k8s-mcp\n\n# Install dependencies\nuv venv\nsource .venv/bin/activate\nuv sync\n```\n\nIf using Claude configure open your Claude for Desktop App configuration at ~/Library/Application Support/Claude/claude_desktop_config.json in a text editor. Make sure to create the file if it doesn’t exist.\n\n```bash\ncode ~/Library/Application\\ Support/Claude/claude_desktop_config.json\n```\n\n```json\n{\n    \"mcpServers\": {\n        \"k8s-mcp\": {\n            \"command\": \"uv\",\n            \"args\": [\n                \"--directory\",\n                \"/ABSOLUTE/PATH/TO/PARENT/FOLDER/k8s-mcp\",\n                \"run\",\n                \"server.py\"\n            ]\n        }\n    }\n}\n```\n\n> You may need to put the full path to the uv executable in the command field. You can get this by running which uv on MacOS/Linux or where uv on Windows.\n\n## Configuration\n\nThe application automatically tries two methods to connect to your Kubernetes cluster:\n\n1. **Kubeconfig File**: Uses your local kubeconfig file (typically located at `~/.kube/config`)\n2. **In-Cluster Configuration**: If running inside a Kubernetes pod, uses the service account token\n\nNo additional configuration is required if your kubeconfig is properly set up or if you're running inside a cluster with appropriate RBAC permissions.\n\n## Usage\n\n### Examples\nHere are some useful example prompts you can ask Claude about your Kubernetes cluster and its resources:\n\n#### General Cluster Status\n- \"What's the overall health of my cluster?\"\n- \"Show me all namespaces in my cluster\"\n- \"What nodes are available in my cluster and what's their status?\"\n- \"How is resource utilization across my nodes?\"\n\n#### Pods and Deployments\n- \"List all pods in the production namespace\"\n- \"Are there any pods in CrashLoopBackOff state?\"\n- \"Show me pods with high restart counts\"\n- \"List all deployments across all namespaces\"\n- \"What deployments are failing to progress?\"\n\n#### Debugging Issues\n- \"Why is my pod in the staging namespace failing?\"\n- \"Get the YAML configuration for the service in the production namespace\"\n- \"Show me recent events in the default namespace\"\n- \"Are there any pods stuck in Pending state?\"\n- \"What's causing ImagePullBackOff errors in my cluster?\"\n\n#### Resource Management\n- \"Show me the resource consumption of nodes in my cluster\"\n- \"Are there any orphaned resources I should clean up?\"\n- \"List all services in the production namespace\"\n- \"Compare resource requests between staging and production\"\n\n#### Specific Resource Inspection\n- \"Show me the config for the coredns deployment in kube-system\"\n- \"Get details of the reverse-proxy service in staging\"\n- \"What containers are running in the pod xyz?\"\n- \"Show me the logs for the failing pod\"\n\n## API Reference\n\n### Namespaces\n\n- `get_namespaces()`: List all available namespaces in the cluster\n\n### Pods\n\n- `list_pods(namespace=None)`: List all pods, optionally filtered by namespace\n- `failed_pods()`: List all pods in Failed or Error state\n- `pending_pods()`: List all pods in Pending state with reasons\n- `high_restart_pods(restart_threshold=5)`: Find pods with restart counts above threshold\n\n### Nodes\n\n- `list_nodes()`: List all nodes and their status\n- `node_capacity()`: Show available capacity on all nodes\n\n### Deployments & Services\n\n- `list_deployments(namespace=None)`: List all deployments\n- `list_services(namespace=None)`: List all services\n- `list_events(namespace=None)`: List all events\n\n### Resource Management\n\n- `orphaned_resources()`: List resources without owner references\n- `get_resource_yaml(namespace, resource_type, resource_name)`: Get YAML configuration for a specific resource\n\n## License\n\n[MIT License](LICENSE)\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "kubernetes",
        "pod",
        "k8s",
        "kubernetes clusters",
        "issues kubernetes",
        "pod statuses"
      ],
      "category": "monitoring-and-logging"
    },
    "westsideori--cursor-a11y-mcp": {
      "owner": "westsideori",
      "name": "cursor-a11y-mcp",
      "url": "https://github.com/westsideori/cursor-a11y-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/westsideori.webp",
      "description": "Run accessibility tests on web applications to identify compliance issues and enhance digital accessibility. Utilize axe-core and Puppeteer to generate detailed violation reports with information about impact levels and affected elements.",
      "stars": 1,
      "forks": 2,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-08-16T21:34:07Z",
      "readme_content": "# Cursor A11y MCP\n\nA Model Context Protocol (MCP) server that provides accessibility testing capabilities AI agents. This tool helps identify accessibility issues in web applications using axe-core and Puppeteer.\n\n<a href=\"https://glama.ai/mcp/servers/mik2l7a1tw\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/mik2l7a1tw/badge\" alt=\"Cursor A11y MCP server\" />\n</a>\n\n## Features\n\n- Run accessibility tests on any URL or local development server\n- Powered by axe-core for comprehensive accessibility testing\n- Provides detailed violation reports including:\n  - Impact level\n  - Description of the issue\n  - Help text and documentation links\n  - Affected HTML elements\n  - Failure summaries\n\n## Project Structure\n\n- `src/` - Source code for the MCP server and accessibility testing tool\n- `test-site/` - A React application with intentional accessibility issues for testing\n- `build/` - Compiled version of the source code\n\n## Installation\n\n```bash\nnpm install\n```\n\nThen install the test site dependencies:\n\n```bash\ncd test-site\nnpm install\ncd ..\n```\n\n## Usage\n\n### Starting the MCP Server\n\n```bash\nnpm run build\nnpm start\n```\n\n### Running the Test Site\n\n```bash\nnpm run start:test-site\n```\n\nThe test site will be available at `http://localhost:5000`.\n\n### Running Accessibility Tests\n\nThe tool accepts two types of inputs:\n\n1. A full URL to test\n2. A relative path that will be appended to `http://localhost:5000`\n\n## Dependencies\n\n- `@modelcontextprotocol/sdk`: ^1.4.1\n- `puppeteer`: ^24.1.1\n- `zod`: ^3.24.1\n\n### Test Site Dependencies\n\n- `react`: ^18.2.0\n- `react-dom`: ^18.2.0\n- `react-scripts`: 5.0.1\n\n## Development\n\n1. Make changes to the source code in the `src/` directory\n2. Run `npm run build` to compile the changes\n3. Start the server with `npm start`\n\n## Configuring in Cursor\n\nTo add this accessibility testing tool to Cursor's MCP Server settings:\n\n1. Open Cursor's Settings (⌘ + ,)\n2. Navigate to \"Features\" > \"MCP Servers\"\n3. Add a new MCP Server with the following configuration:\n   - Name: `a11y`\n   - Select `command` from the dropdown\n   - Command: `node path/to/cursor-a11y-mcp/index/file/in/build/folder`\n     (Replace `path/to/cursor-a11y-mcp/index/file/in/build/folder` with the absolute path to your index.js file in the build folder.)\n4. Click `Add`\n5. The accessibility testing tool will now be available in Cursor's Composer\n\n## Usage in Composer\n\nTo use the accessibility testing tool in Cursor's Composer:\n\n1. Run in your terminal:\n\n```bash\nnpm run start:test-site\n```\n\nThis will start the test site at `http://localhost:5000`\n\n2. In Cursor's Composer, type `use a11y tool`\n3. Composer will prompt you to run the tool\n4. After running the tool, you will see the accessibility violations in the response, and code actions to fix the violations\n5. The Composer may prompt you to use the tool again to confirm that the violations are fixed\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Version\n\nCurrent version: 2.0.1",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "accessibility",
        "compliance",
        "cursor",
        "accessibility tests",
        "accessibility utilize",
        "run accessibility"
      ],
      "category": "monitoring-and-logging"
    },
    "wildfly-extras--wildfly-mcp": {
      "owner": "wildfly-extras",
      "name": "wildfly-mcp",
      "url": "https://github.com/wildfly-extras/wildfly-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/wildfly-extras.webp",
      "description": "Integrate Generative AI capabilities for monitoring and managing WildFly servers using natural language interactions. Enables users to leverage AI chatbots for server management tasks and integrates smoothly with existing WildFly functionalities.",
      "stars": 6,
      "forks": 10,
      "license": "Apache License 2.0",
      "language": "Java",
      "updated_at": "2025-09-18T11:48:37Z",
      "readme_content": "# WildFly MCP\n\nThis project aims to define tooling allowing WildFly users to benefenit from the Generative AI capabilities when monitoring and managing WildFly servers.\n\n* [WildFly MCP Server](wildfly-mcp-server/README.md): A WildFly [MCP server](https://github.com/modelcontextprotocol/servers) to integrate with your AI chatbot in order to interact with WildFly server using natural language.\n\n* [WildFly Chat Bot](wildfly-chat-bot/README.md): A WildFly Chat Bot to interact with WildFly servers. This AI chatbot allows to also integrate MCP servers (STDIO and SSE protocol).\n\n* [Container Images](container-images/README.md): Container images for mcp server and the chat bot (that contains both the chat bot and the mcp server. Ready to interact with your WildFly servers on the cloud). Example of OpenShift deployment is provided.\n\n* [MCP STDIO to SEE protocol gateway](mcp-stdio-sse-gateway/README.md): A Java gateway allowing to integrate SSE MCP servers in chat applications that only support STDIO protocol.\n\n* [Wait MCP Server](wait-mcp-server/README.md): A simple [MCP server](https://github.com/modelcontextprotocol/servers) that allows LLM to wait for some seconds. Can be useful in some workflow.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "chatbots",
        "wildfly",
        "ai",
        "wildfly servers",
        "logging wildfly",
        "ai chatbots"
      ],
      "category": "monitoring-and-logging"
    },
    "winor30--mcp-server-datadog": {
      "owner": "winor30",
      "name": "mcp-server-datadog",
      "url": "https://github.com/winor30/mcp-server-datadog",
      "imageUrl": "/freedevtools/mcp/pfp/winor30.webp",
      "description": "Integrates with the Datadog API to facilitate access to monitoring features, including incident management, logs, and metrics. Supports streamlined observability processes for enhanced incident response and monitoring capabilities.",
      "stars": 101,
      "forks": 44,
      "license": "Apache License 2.0",
      "language": "TypeScript",
      "updated_at": "2025-09-30T12:07:04Z",
      "readme_content": "# Datadog MCP Server\n\n> **DISCLAIMER**: This is a community-maintained project and is not officially affiliated with, endorsed by, or supported by Datadog, Inc. This MCP server utilizes the Datadog API but is developed independently as part of the [Model Context Protocol](https://github.com/modelcontextprotocol/servers) ecosystem.\n\n![NPM Version](https://img.shields.io/npm/v/%40winor30%2Fmcp-server-datadog)![Build and Test](https://github.com/winor30/mcp-server-datadog/actions/workflows/ci.yml/badge.svg)[![codecov](https://codecov.io/gh/winor30/mcp-server-datadog/graph/badge.svg?token=BG4ZB74X92)](https://codecov.io/gh/winor30/mcp-server-datadog)[![smithery badge](https://smithery.ai/badge/@winor30/mcp-server-datadog)](https://smithery.ai/server/@winor30/mcp-server-datadog)\n\nMCP server for the Datadog API, enabling incident management and more.\n\n<a href=\"https://glama.ai/mcp/servers/bu8gtzkwfr\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/bu8gtzkwfr/badge\" alt=\"mcp-server-datadog MCP server\" />\n</a>\n\n## Features\n\n- **Observability Tools**: Provides a mechanism to leverage key Datadog monitoring features, such as incidents, monitors, logs, dashboards, and metrics, through the MCP server.\n- **Extensible Design**: Designed to easily integrate with additional Datadog APIs, allowing for seamless future feature expansion.\n\n## Tools\n\n1. `list_incidents`\n\n   - Retrieve a list of incidents from Datadog.\n   - **Inputs**:\n     - `filter` (optional string): Filter parameters for incidents (e.g., status, priority).\n     - `pagination` (optional object): Pagination details like page size/offset.\n   - **Returns**: Array of Datadog incidents and associated metadata.\n\n2. `get_incident`\n\n   - Retrieve detailed information about a specific Datadog incident.\n   - **Inputs**:\n     - `incident_id` (string): Incident ID to fetch details for.\n   - **Returns**: Detailed incident information (title, status, timestamps, etc.).\n\n3. `get_monitors`\n\n   - Fetch the status of Datadog monitors.\n   - **Inputs**:\n     - `groupStates` (optional array): States to filter (e.g., alert, warn, no data, ok).\n     - `name` (optional string): Filter by name.\n     - `tags` (optional array): Filter by tags.\n   - **Returns**: Monitors data and a summary of their statuses.\n\n4. `get_logs`\n\n   - Search and retrieve logs from Datadog.\n   - **Inputs**:\n     - `query` (string): Datadog logs query string.\n     - `from` (number): Start time in epoch seconds.\n     - `to` (number): End time in epoch seconds.\n     - `limit` (optional number): Maximum number of logs to return (defaults to 100).\n   - **Returns**: Array of matching logs.\n\n5. `list_dashboards`\n\n   - Get a list of dashboards from Datadog.\n   - **Inputs**:\n     - `name` (optional string): Filter dashboards by name.\n     - `tags` (optional array): Filter dashboards by tags.\n   - **Returns**: Array of dashboards with URL references.\n\n6. `get_dashboard`\n\n   - Retrieve a specific dashboard from Datadog.\n   - **Inputs**:\n     - `dashboard_id` (string): ID of the dashboard to fetch.\n   - **Returns**: Dashboard details including title, widgets, etc.\n\n7. `query_metrics`\n\n   - Retrieve metrics data from Datadog.\n   - **Inputs**:\n     - `query` (string): Metrics query string.\n     - `from` (number): Start time in epoch seconds.\n     - `to` (number): End time in epoch seconds.\n   - **Returns**: Metrics data for the queried timeframe.\n\n8. `list_traces`\n\n   - Retrieve a list of APM traces from Datadog.\n   - **Inputs**:\n     - `query` (string): Datadog APM trace query string.\n     - `from` (number): Start time in epoch seconds.\n     - `to` (number): End time in epoch seconds.\n     - `limit` (optional number): Maximum number of traces to return (defaults to 100).\n     - `sort` (optional string): Sort order for traces (defaults to '-timestamp').\n     - `service` (optional string): Filter by service name.\n     - `operation` (optional string): Filter by operation name.\n   - **Returns**: Array of matching traces from Datadog APM.\n\n9. `list_hosts`\n\n   - Get list of hosts from Datadog.\n   - **Inputs**:\n     - `filter` (optional string): Filter string for search results.\n     - `sort_field` (optional string): Field to sort hosts by.\n     - `sort_dir` (optional string): Sort direction (asc/desc).\n     - `start` (optional number): Starting offset for pagination.\n     - `count` (optional number): Max number of hosts to return (max: 1000).\n     - `from` (optional number): Search hosts from this UNIX timestamp.\n     - `include_muted_hosts_data` (optional boolean): Include muted hosts status and expiry.\n     - `include_hosts_metadata` (optional boolean): Include host metadata (version, platform, etc).\n   - **Returns**: Array of hosts with details including name, ID, aliases, apps, mute status, and more.\n\n10. `get_active_hosts_count`\n\n    - Get the total number of active hosts in Datadog.\n    - **Inputs**:\n      - `from` (optional number): Number of seconds from which you want to get total number of active hosts (defaults to 2h).\n    - **Returns**: Count of total active and up hosts.\n\n11. `mute_host`\n\n    - Mute a host in Datadog.\n    - **Inputs**:\n      - `hostname` (string): The name of the host to mute.\n      - `message` (optional string): Message to associate with the muting of this host.\n      - `end` (optional number): POSIX timestamp for when the mute should end.\n      - `override` (optional boolean): If true and the host is already muted, replaces existing end time.\n    - **Returns**: Success status and confirmation message.\n\n12. `unmute_host`\n\n    - Unmute a host in Datadog.\n    - **Inputs**:\n      - `hostname` (string): The name of the host to unmute.\n    - **Returns**: Success status and confirmation message.\n\n13. `list_downtimes`\n\n    - List scheduled downtimes from Datadog.\n    - **Inputs**:\n      - `currentOnly` (optional boolean): Return only currently active downtimes when true.\n      - `monitorId` (optional number): Filter by monitor ID.\n    - **Returns**: Array of scheduled downtimes with details including scope, monitor information, and schedule.\n\n14. `schedule_downtime`\n\n    - Schedule a downtime in Datadog.\n    - **Inputs**:\n      - `scope` (string): Scope to apply downtime to (e.g. 'host:my-host').\n      - `start` (optional number): UNIX timestamp for the start of the downtime.\n      - `end` (optional number): UNIX timestamp for the end of the downtime.\n      - `message` (optional string): A message to include with the downtime.\n      - `timezone` (optional string): The timezone for the downtime (e.g. 'UTC', 'America/New_York').\n      - `monitorId` (optional number): The ID of the monitor to mute.\n      - `monitorTags` (optional array): A list of monitor tags for filtering.\n      - `recurrence` (optional object): Recurrence settings for the downtime.\n        - `type` (string): Recurrence type ('days', 'weeks', 'months', 'years').\n        - `period` (number): How often to repeat (must be >= 1).\n        - `weekDays` (optional array): Days of the week for weekly recurrence.\n        - `until` (optional number): UNIX timestamp for when the recurrence ends.\n    - **Returns**: Scheduled downtime details including ID and active status.\n\n15. `cancel_downtime`\n\n    - Cancel a scheduled downtime in Datadog.\n    - **Inputs**:\n      - `downtimeId` (number): The ID of the downtime to cancel.\n    - **Returns**: Confirmation of downtime cancellation.\n\n16. `get_rum_applications`\n\n    - Get all RUM applications in the organization.\n    - **Inputs**: None.\n    - **Returns**: List of RUM applications.\n\n17. `get_rum_events`\n\n    - Search and retrieve RUM events from Datadog.\n    - **Inputs**:\n      - `query` (string): Datadog RUM query string.\n      - `from` (number): Start time in epoch seconds.\n      - `to` (number): End time in epoch seconds.\n      - `limit` (optional number): Maximum number of events to return (default: 100).\n    - **Returns**: Array of RUM events.\n\n18. `get_rum_grouped_event_count`\n\n    - Search, group and count RUM events by a specified dimension.\n    - **Inputs**:\n      - `query` (optional string): Additional query filter for RUM search (default: \"\\*\").\n      - `from` (number): Start time in epoch seconds.\n      - `to` (number): End time in epoch seconds.\n      - `groupBy` (optional string): Dimension to group results by (default: \"application.name\").\n    - **Returns**: Grouped event counts.\n\n19. `get_rum_page_performance`\n\n    - Get page (view) performance metrics from RUM data.\n    - **Inputs**:\n      - `query` (optional string): Additional query filter for RUM search (default: \"\\*\").\n      - `from` (number): Start time in epoch seconds.\n      - `to` (number): End time in epoch seconds.\n      - `metricNames` (array of strings): Array of metric names to retrieve (e.g., 'view.load_time', 'view.first_contentful_paint').\n    - **Returns**: Performance metrics including average, min, max, and count for each metric.\n\n20. `get_rum_page_waterfall`\n\n    - Retrieve RUM page (view) waterfall data filtered by application name and session ID.\n    - **Inputs**:\n      - `applicationName` (string): Application name to filter events.\n      - `sessionId` (string): Session ID to filter events.\n    - **Returns**: Waterfall data for the specified application and session.\n\n## Setup\n\n### Datadog Credentials\n\nYou need valid Datadog API credentials to use this MCP server:\n\n- `DATADOG_API_KEY`: Your Datadog API key\n- `DATADOG_APP_KEY`: Your Datadog Application key\n- `DATADOG_SITE` (optional): The Datadog site (e.g. `datadoghq.eu`)\n\nExport them in your environment before running the server:\n\n```bash\nexport DATADOG_API_KEY=\"your_api_key\"\nexport DATADOG_APP_KEY=\"your_app_key\"\nexport DATADOG_SITE=\"your_datadog_site\"\n```\n\n## Installation\n\n### Installing via Smithery\n\nTo install Datadog MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@winor30/mcp-server-datadog):\n\n```bash\nnpx -y @smithery/cli install @winor30/mcp-server-datadog --client claude\n```\n\n### Manual Installation\n\n```bash\npnpm install\npnpm build\npnpm watch   # for development with auto-rebuild\n```\n\n## Usage with Claude Desktop\n\nTo use this with Claude Desktop, add the following to your `claude_desktop_config.json`:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`  \nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"github\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-github\"],\n      \"env\": {\n        \"GITHUB_PERSONAL_ACCESS_TOKEN\": \"<YOUR_TOKEN>\"\n      }\n    }\n  }\n}\n```\n\n```json\n{\n  \"mcpServers\": {\n    \"datadog\": {\n      \"command\": \"/path/to/mcp-server-datadog/build/index.js\",\n      \"env\": {\n        \"DATADOG_API_KEY\": \"<YOUR_API_KEY>\",\n        \"DATADOG_APP_KEY\": \"<YOUR_APP_KEY>\",\n        \"DATADOG_SITE\": \"<YOUR_SITE>\" // Optional\n      }\n    }\n  }\n}\n```\n\nOr specify via `npx`:\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-server-datadog\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@winor30/mcp-server-datadog\"],\n      \"env\": {\n        \"DATADOG_API_KEY\": \"<YOUR_API_KEY>\",\n        \"DATADOG_APP_KEY\": \"<YOUR_APP_KEY>\",\n        \"DATADOG_SITE\": \"<YOUR_SITE>\" // Optional\n      }\n    }\n  }\n}\n```\n\n## Debugging\n\nBecause MCP servers communicate over standard input/output, debugging can sometimes be tricky. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector). You can run the inspector with:\n\n```bash\nnpm run inspector\n```\n\nThe inspector will provide a URL you can open in your browser to see logs and send requests manually.\n\n## Contributing\n\nContributions are welcome! Feel free to open an issue or a pull request if you have any suggestions, bug reports, or improvements to propose.\n\n## License\n\nThis project is licensed under the [Apache License, Version 2.0](./LICENSE).\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "datadog",
        "logging",
        "monitoring",
        "server datadog",
        "datadog api",
        "datadog integrates"
      ],
      "category": "monitoring-and-logging"
    },
    "xzq-xu--jvm-mcp-server": {
      "owner": "xzq-xu",
      "name": "jvm-mcp-server",
      "url": "https://github.com/xzq-xu/jvm-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/xzq-xu.webp",
      "description": "Monitor and analyze Java processes with real-time insights into JVM performance, memory usage, and thread information through a Python interface. Provides capabilities such as thread stack trace analysis, dynamic log adjustments, and AI-driven performance analysis.",
      "stars": 69,
      "forks": 15,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-01T02:43:52Z",
      "readme_content": "# JVM MCP Server\n\n<p align=\"center\">\n  <img src=\"https://img.shields.io/badge/Python-3.6+-blue.svg\" alt=\"Python Version\">\n  <img src=\"https://img.shields.io/badge/JDK-8+-green.svg\" alt=\"JDK Version\">\n  <img src=\"https://img.shields.io/badge/License-MIT-yellow.svg\" alt=\"License\">\n</p>\n\n[English](README.md) | [中文](README_zh.md)\n\n[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/xzq-xu-jvm-mcp-server-badge.png)](https://mseep.ai/app/xzq-xu-jvm-mcp-server)\n\n\nA lightweight JVM monitoring and diagnostic MCP (Multi-Agent Communication Protocol) server implementation based on native JDK tools. Provides AI agents with powerful capabilities to monitor and analyze Java applications without requiring third-party tools like Arthas.\n\n## Features\n\n- **Zero Dependencies**: Uses only native JDK tools (jps, jstack, jmap, etc.)\n- **Lightweight**: Minimal resource consumption compared to agent-based solutions\n- **High Compatibility**: Works with all Java versions and platforms\n- **Non-Intrusive**: No modifications to target applications required\n- **Secure**: Uses only JDK certified tools and commands\n- **Remote Monitoring**: Support for both local and remote JVM monitoring via SSH\n\n## Core Capabilities\n\n### Basic Monitoring\n- Java process listing and identification\n- JVM basic information retrieval\n- Memory usage monitoring\n- Thread information and stack trace analysis\n- Class loading statistics\n- Detailed class structure information\n\n### Advanced Features\n- Method call path analysis\n- Class decompilation\n- Method search and inspection\n- Method invocation monitoring\n- Logger level management\n- System resource dashboard\n\n## System Requirements\n\n- Python 3.6+\n- JDK 8+\n- Linux/Unix/Windows OS\n- SSH access (for remote monitoring)\n\n## Installation\n\n### Using uv (Recommended)\n\n```bash\n# Install uv if not already installed\ncurl -LsSf https://astral.sh/uv/install.sh | sh  # Linux/macOS\n# or\npowershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"  # Windows\n\n# Install the package\nuv pip install jvm-mcp-server\n```\n\n### Using pip\n\n```bash\npip install jvm-mcp-server\n```\n\n### From Source\n\n```bash\n# Clone the repository\ngit clone https://github.com/your-repo/jvm-mcp-server.git\ncd jvm-mcp-server\n\n# Using uv (recommended)\nuv venv  # Create virtual environment\nuv sync  # Install dependencies\n\n# Or install in development mode\nuv pip install -e .\n```\n\n## Quick Start\n\n### Starting the Server\n\n#### Using uv (Recommended)\n\n```bash\n# Local mode\nuv run jvm-mcp-server\n\n# Using environment variables file for remote mode\nuv run --env-file .env jvm-mcp-server\n\n# In specific directory\nuv --directory /path/to/project run --env-file .env jvm-mcp-server\n```\n\n#### Using uvx\n\n```bash\n# Local mode\nuvx run jvm-mcp-server\n\n# With environment variables\nuvx run --env-file .env jvm-mcp-server\n```\n\n#### Using Python directly\n\n```python\nfrom jvm_mcp_server import JvmMcpServer\n\n# Local mode\nserver = JvmMcpServer()\nserver.run()\n\n# Remote mode (via environment variables)\n# Set SSH_HOST, SSH_PORT, SSH_USER, SSH_PASSWORD or SSH_KEY\nimport os\nos.environ['SSH_HOST'] = 'user@remote-host'\nos.environ['SSH_PORT'] = '22'\nserver = JvmMcpServer()\nserver.run()\n```\n\n### Using with MCP Configuration\n\n```json\n{\n  \"mcpServers\": {\n    \"jvm-mcp-server\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/path/to/jvm-mcp-server\",\n        \"run\",\n        \"--env-file\",\n        \"/path/to/jvm-mcp-server/.env\",\n        \"jvm-mcp-server\"\n      ]\n    }\n  }\n}\n```\n\n## Available Tools\n\nJVM-MCP-Server provides a comprehensive set of tools for JVM monitoring and diagnostics:\n\n- `list_java_processes`: List all Java processes\n- `get_thread_info`: Get thread information for a specific process\n- `get_jvm_info`: Get JVM basic information\n- `get_memory_info`: Get memory usage information\n- `get_stack_trace`: Get thread stack trace information\n- `get_class_info`: Get detailed class information including structure\n- `get_stack_trace_by_method`: Get method call path\n- `decompile_class`: Decompile class source code\n- `search_method`: Search for methods in classes\n- `watch_method`: Monitor method invocations\n- `get_logger_info`: Get logger information\n- `set_logger_level`: Set logger levels\n- `get_dashboard`: Get system resource dashboard\n- `get_jcmd_output`: Execute JDK jcmd commands\n- `get_jstat_output`: Execute JDK jstat commands\n\nFor detailed documentation on each tool, see [Available Tools](./doc/available_tools.md).\n\n## Architecture\n\nJVM-MCP-Server is built on a modular architecture:\n\n1. **Command Layer**: Wraps JDK native commands\n2. **Executor Layer**: Handles local and remote command execution\n3. **Formatter Layer**: Processes and formats command output\n4. **MCP Interface**: Exposes functionality through FastMCP protocol\n\n### Key Components\n\n- `BaseCommand`: Abstract base class for all commands\n- `CommandExecutor`: Interface for command execution (local and remote)\n- `OutputFormatter`: Interface for formatting command output\n- `JvmMcpServer`: Main server class that registers all tools\n\n## Development Status\n\nThe project is in active development. See [Native_TODO.md](Native_TODO.md) for current progress.\n\n### Completed\n- Core architecture and command framework\n- Basic commands implementation (jps, jstack, jmap, jinfo, jcmd, jstat)\n- Class information retrieval system\n- MCP tool parameter type compatibility fixes\n\n### In Progress\n- Caching mechanism\n- Method tracing\n- Performance monitoring\n- Error handling improvements\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n1. Fork the repository\n2. Create your feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add some amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Acknowledgements\n\n- JDK tools documentation\n- FastMCP protocol specification\n- Contributors and testers ",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "jvm",
        "monitoring",
        "java",
        "java processes",
        "jvm performance",
        "analyze java"
      ],
      "category": "monitoring-and-logging"
    },
    "yamato-snow--2025_McpLab_FastMCP": {
      "owner": "yamato-snow",
      "name": "2025_McpLab_FastMCP",
      "url": "https://github.com/yamato-snow/2025_McpLab_FastMCP",
      "imageUrl": "/freedevtools/mcp/pfp/yamato-snow.webp",
      "description": "Built using TypeScript, this server facilitates client session management for MCP by defining tools, resources, and prompts, while supporting authentication, logging, and real-time updates through SSE. It provides features like error handling, CORS, and CLI tools for testing and debugging.",
      "stars": 0,
      "forks": 1,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-04-12T01:24:10Z",
      "readme_content": "# FastMCP\n\nFastMCPは、クライアントセッション管理が可能な[MCP](https://glama.ai/mcp)サーバーを構築するためのTypeScriptフレームワークです。\n\n> [!NOTE]\n>\n> Python実装版は[FastMCP Python](https://github.com/jlowin/fastmcp)をご覧ください。\n\n## 主な機能\n\nFastMCPは以下の機能を提供します：\n\n- シンプルなツール、リソース、プロンプト定義\n- [認証機能](#認証)\n- [セッション管理](#セッション)\n- [画像コンテンツ対応](#画像の返却)\n- [ロギング](#ロギング)\n- [エラーハンドリング](#エラー)\n- [SSE(Server-Sent Events)](#sse)\n- CORS（デフォルトで有効）\n- [進捗通知](#進捗通知)\n- [型付きサーバーイベント](#型付きサーバーイベント)\n- [プロンプト引数の自動補完](#プロンプト引数の自動補完)\n- [サンプリングリクエスト](#サンプリングリクエスト)\n- 自動SSEピング\n- ルート管理\n- [テスト](#mcp-cliでテスト)や[デバッグ](#mcp-inspectorで検査)のためのCLI\n\n## インストール方法\n\n```bash\nnpm install fastmcp\n```\n\n## クイックスタート\n\n> [!NOTE]\n>\n> FastMCPの実際の使用例は多数あります。[事例紹介](#事例紹介)をご覧ください。\n\n```ts\nimport { FastMCP } from \"fastmcp\";\nimport { z } from \"zod\"; // または他の検証ライブラリ（Standard Schemaをサポートしているもの）\n\nconst server = new FastMCP({\n  name: \"マイサーバー\",\n  version: \"1.0.0\",\n});\n\nserver.addTool({\n  name: \"add\",\n  description: \"2つの数値を足し算します\",\n  parameters: z.object({\n    a: z.number(),\n    b: z.number(),\n  }),\n  execute: async (args) => {\n    return String(args.a + args.b);\n  },\n});\n\nserver.start({\n  transportType: \"stdio\",\n});\n```\n\nこれだけで動作するMCPサーバーができました！\n\nターミナルで以下のようにテストできます：\n\n```bash\ngit clone https://github.com/punkpeye/fastmcp.git\ncd fastmcp\n\npnpm install\npnpm build\n\n# CLIを使った足し算サーバーの例をテスト：\nnpx fastmcp dev src/examples/addition.ts\n# MCP Inspectorを使った足し算サーバーの例を検査：\nnpx fastmcp inspect src/examples/addition.ts\n```\n\n### SSE\n\n[Server-Sent Events](https://developer.mozilla.org/ja/docs/Web/API/Server-sent_events)（SSE）は、サーバーがHTTPS接続を介してクライアントにリアルタイム更新を送信するメカニズムです。MCPにおいて、SSEは主にリモートMCP通信を可能にするために使用され、リモートマシンでホストされたMCPにアクセスしてネットワーク経由で更新を中継できるようにします。\n\nSSEサポート付きでサーバーを実行することもできます：\n\n```ts\nserver.start({\n  transportType: \"sse\",\n  sse: {\n    endpoint: \"/sse\",\n    port: 8080,\n  },\n});\n```\n\nこれにより、サーバーが起動し、`http://localhost:8080/sse`でSSE接続をリッスンします。\n\nその後、`SSEClientTransport`を使用してサーバーに接続できます：\n\n```ts\nimport { SSEClientTransport } from \"@modelcontextprotocol/sdk/client/sse.js\";\n\nconst client = new Client(\n  {\n    name: \"example-client\",\n    version: \"1.0.0\",\n  },\n  {\n    capabilities: {},\n  },\n);\n\nconst transport = new SSEClientTransport(new URL(`http://localhost:8080/sse`));\n\nawait client.connect(transport);\n```\n\n## 基本概念\n\n### ツール\n\nMCPの[ツール](https://modelcontextprotocol.io/docs/concepts/tools)では、サーバーが実行可能な関数を公開し、クライアントやLLMがアクションを実行するために呼び出すことができます。\n\nFastMCPはツールパラメーターの定義に[Standard Schema](https://standardschema.dev)仕様を使用しています。これにより、Zod、ArkType、Valibotなど、仕様を実装している好みのスキーマ検証ライブラリを使用できます。\n\n**Zodの例：**\n\n```typescript\nimport { z } from \"zod\";\n\nserver.addTool({\n  name: \"fetch-zod\",\n  description: \"URLのコンテンツを取得します（Zodを使用）\",\n  parameters: z.object({\n    url: z.string(),\n  }),\n  execute: async (args) => {\n    return await fetchWebpageContent(args.url);\n  },\n});\n```\n\n**ArkTypeの例：**\n\n```typescript\nimport { type } from \"arktype\";\n\nserver.addTool({\n  name: \"fetch-arktype\",\n  description: \"URLのコンテンツを取得します（ArkTypeを使用）\",\n  parameters: type({\n    url: \"string\",\n  }),\n  execute: async (args) => {\n    return await fetchWebpageContent(args.url);\n  },\n});\n```\n\n**Valibotの例：**\n\nValibotにはピア依存関係@valibot/to-json-schemaが必要です。\n\n```typescript\nimport * as v from \"valibot\";\n\nserver.addTool({\n  name: \"fetch-valibot\",\n  description: \"URLのコンテンツを取得します（Valibotを使用）\",\n  parameters: v.object({\n    url: v.string(),\n  }),\n  execute: async (args) => {\n    return await fetchWebpageContent(args.url);\n  },\n});\n```\n\n#### 文字列を返す\n\n`execute`は文字列を返すことができます：\n\n```js\nserver.addTool({\n  name: \"download\",\n  description: \"ファイルをダウンロードします\",\n  parameters: z.object({\n    url: z.string(),\n  }),\n  execute: async (args) => {\n    return \"こんにちは、世界！\";\n  },\n});\n```\n\nこれは以下と同等です：\n\n```js\nserver.addTool({\n  name: \"download\",\n  description: \"ファイルをダウンロードします\",\n  parameters: z.object({\n    url: z.string(),\n  }),\n  execute: async (args) => {\n    return {\n      content: [\n        {\n          type: \"text\",\n          text: \"こんにちは、世界！\",\n        },\n      ],\n    };\n  },\n});\n```\n\n#### リストを返す\n\nメッセージのリストを返したい場合は、`content`プロパティを持つオブジェクトを返せます：\n\n```js\nserver.addTool({\n  name: \"download\",\n  description: \"ファイルをダウンロードします\",\n  parameters: z.object({\n    url: z.string(),\n  }),\n  execute: async (args) => {\n    return {\n      content: [\n        { type: \"text\", text: \"1つ目のメッセージ\" },\n        { type: \"text\", text: \"2つ目のメッセージ\" },\n      ],\n    };\n  },\n});\n```\n\n#### 画像の返却\n\n画像のコンテンツオブジェクトを作成するには、`imageContent`を使用します：\n\n```js\nimport { imageContent } from \"fastmcp\";\n\nserver.addTool({\n  name: \"download\",\n  description: \"ファイルをダウンロードします\",\n  parameters: z.object({\n    url: z.string(),\n  }),\n  execute: async (args) => {\n    return imageContent({\n      url: \"https://example.com/image.png\",\n    });\n\n    // または...\n    // return imageContent({\n    //   path: \"/path/to/image.png\",\n    // });\n\n    // または...\n    // return imageContent({\n    //   buffer: Buffer.from(\"iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII=\", \"base64\"),\n    // });\n\n    // または...\n    // return {\n    //   content: [\n    //     await imageContent(...)\n    //   ],\n    // };\n  },\n});\n```\n\n`imageContent`関数は以下のオプションを受け取ります：\n\n- `url`: 画像のURL\n- `path`: 画像ファイルへのパス\n- `buffer`: バッファとしての画像データ\n\n`url`、`path`、`buffer`のいずれか1つのみを指定する必要があります。\n\n上の例は以下と同等です：\n\n```js\nserver.addTool({\n  name: \"download\",\n  description: \"ファイルをダウンロードします\",\n  parameters: z.object({\n    url: z.string(),\n  }),\n  execute: async (args) => {\n    return {\n      content: [\n        {\n          type: \"image\",\n          data: \"iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII=\",\n          mimeType: \"image/png\",\n        },\n      ],\n    };\n  },\n});\n```\n\n#### ロギング\n\nツールはコンテキストオブジェクトの`log`を使用してクライアントにメッセージをログ出力できます：\n\n```js\nserver.addTool({\n  name: \"download\",\n  description: \"ファイルをダウンロードします\",\n  parameters: z.object({\n    url: z.string(),\n  }),\n  execute: async (args, { log }) => {\n    log.info(\"ファイルをダウンロード中...\", {\n      url: args.url,\n    });\n\n    // ...\n\n    log.info(\"ファイルをダウンロードしました\");\n\n    return \"完了\";\n  },\n});\n```\n\n`log`オブジェクトには以下のメソッドがあります：\n\n- `debug(message: string, data?: SerializableValue)`\n- `error(message: string, data?: SerializableValue)`\n- `info(message: string, data?: SerializableValue)`\n- `warn(message: string, data?: SerializableValue)`\n\n#### エラー\n\nユーザーに表示されるべきエラーは、`UserError`インスタンスとしてスローする必要があります：\n\n```js\nimport { UserError } from \"fastmcp\";\n\nserver.addTool({\n  name: \"download\",\n  description: \"ファイルをダウンロードします\",\n  parameters: z.object({\n    url: z.string(),\n  }),\n  execute: async (args) => {\n    if (args.url.startsWith(\"https://example.com\")) {\n      throw new UserError(\"このURLは許可されていません\");\n    }\n\n    return \"完了\";\n  },\n});\n```\n\n#### 進捗通知\n\nツールはコンテキストオブジェクトの`reportProgress`を呼び出すことで進捗を報告できます：\n\n```js\nserver.addTool({\n  name: \"download\",\n  description: \"ファイルをダウンロードします\",\n  parameters: z.object({\n    url: z.string(),\n  }),\n  execute: async (args, { reportProgress }) => {\n    reportProgress({\n      progress: 0,\n      total: 100,\n    });\n\n    // ...\n\n    reportProgress({\n      progress: 100,\n      total: 100,\n    });\n\n    return \"完了\";\n  },\n});\n```\n\n### リソース\n\n[リソース](https://modelcontextprotocol.io/docs/concepts/resources)は、MCPサーバーがクライアントに提供したいあらゆる種類のデータを表します。これには以下が含まれます：\n\n- ファイルの内容\n- スクリーンショットや画像\n- ログファイル\n- その他多数\n\n各リソースは一意のURIで識別され、テキストまたはバイナリデータを含むことができます。\n\n```ts\nserver.addResource({\n  uri: \"file:///logs/app.log\",\n  name: \"アプリケーションログ\",\n  mimeType: \"text/plain\",\n  async load() {\n    return {\n      text: await readLogFile(),\n    };\n  },\n});\n```\n\n> [!NOTE]\n>\n> `load`は複数のリソースを返すことができます。これは例えば、ディレクトリが読み込まれたときにディレクトリ内のファイルのリストを返すために使用できます。\n>\n> ```ts\n> async load() {\n>   return [\n>     {\n>       text: \"1つ目のファイルの内容\",\n>     },\n>     {\n>       text: \"2つ目のファイルの内容\",\n>     },\n>   ];\n> }\n> ```\n\n`load`でバイナリコンテンツを返すこともできます：\n\n```ts\nasync load() {\n  return {\n    blob: 'base64でエンコードされたデータ'\n  };\n}\n```\n\n### リソーステンプレート\n\nリソーステンプレートを定義することもできます：\n\n```ts\nserver.addResourceTemplate({\n  uriTemplate: \"file:///logs/{name}.log\",\n  name: \"アプリケーションログ\",\n  mimeType: \"text/plain\",\n  arguments: [\n    {\n      name: \"name\",\n      description: \"ログの名前\",\n      required: true,\n    },\n  ],\n  async load({ name }) {\n    return {\n      text: `${name}のサンプルログ内容`,\n    };\n  },\n});\n```\n\n#### リソーステンプレート引数の自動補完\n\nリソーステンプレート引数の自動補完を有効にするために、`complete`関数を提供します：\n\n```ts\nserver.addResourceTemplate({\n  uriTemplate: \"file:///logs/{name}.log\",\n  name: \"アプリケーションログ\",\n  mimeType: \"text/plain\",\n  arguments: [\n    {\n      name: \"name\",\n      description: \"ログの名前\",\n      required: true,\n      complete: async (value) => {\n        if (value === \"サンプル\") {\n          return {\n            values: [\"サンプルログ\"],\n          };\n        }\n\n        return {\n          values: [],\n        };\n      },\n    },\n  ],\n  async load({ name }) {\n    return {\n      text: `${name}のサンプルログ内容`,\n    };\n  },\n});\n```\n\n### プロンプト\n\n[プロンプト](https://modelcontextprotocol.io/docs/concepts/prompts)は、サーバーが再利用可能なプロンプトテンプレートとワークフローを定義し、クライアントがユーザーやLLMに簡単に提示できるようにします。これにより、一般的なLLMインタラクションを標準化して共有するための強力な方法を提供します。\n\n```ts\nserver.addPrompt({\n  name: \"git-commit\",\n  description: \"Gitコミットメッセージを生成します\",\n  arguments: [\n    {\n      name: \"changes\",\n      description: \"Gitの差分または変更の説明\",\n      required: true,\n    },\n  ],\n  load: async (args) => {\n    return `これらの変更に対する簡潔かつ説明的なコミットメッセージを生成してください：\\n\\n${args.changes}`;\n  },\n});\n```\n\n#### プロンプト引数の自動補完\n\nプロンプトは引数の自動補完を提供できます：\n\n```js\nserver.addPrompt({\n  name: \"countryPoem\",\n  description: \"国についての詩を書きます\",\n  load: async ({ name }) => {\n    return `こんにちは、${name}さん！`;\n  },\n  arguments: [\n    {\n      name: \"name\",\n      description: \"国の名前\",\n      required: true,\n      complete: async (value) => {\n        if (value === \"日\") {\n          return {\n            values: [\"日本\"],\n          };\n        }\n\n        return {\n          values: [],\n        };\n      },\n    },\n  ],\n});\n```\n\n#### `enum`を使用したプロンプト引数の自動補完\n\n引数に`enum`配列を提供すると、サーバーは自動的に引数の補完を提供します。\n\n```js\nserver.addPrompt({\n  name: \"countryPoem\",\n  description: \"国についての詩を書きます\",\n  load: async ({ name }) => {\n    return `こんにちは、${name}さん！`;\n  },\n  arguments: [\n    {\n      name: \"name\",\n      description: \"国の名前\",\n      required: true,\n      enum: [\"日本\", \"フランス\", \"イタリア\"],\n    },\n  ],\n});\n```\n\n### 認証\n\nFastMCPではカスタム関数を使用してクライアントを`authenticate`できます：\n\n```ts\nimport { AuthError } from \"fastmcp\";\n\nconst server = new FastMCP({\n  name: \"マイサーバー\",\n  version: \"1.0.0\",\n  authenticate: ({request}) => {\n    const apiKey = request.headers[\"x-api-key\"];\n\n    if (apiKey !== '123') {\n      throw new Response(null, {\n        status: 401,\n        statusText: \"Unauthorized\",\n      });\n    }\n\n    // ここで返すものは`context.session`オブジェクトでアクセスできます\n    return {\n      id: 1,\n    }\n  },\n});\n```\n\nこれで、ツール内で認証されたセッションデータにアクセスできます：\n\n```ts\nserver.addTool({\n  name: \"sayHello\",\n  execute: async (args, { session }) => {\n    return `こんにちは、${session.id}さん！`;\n  },\n});\n```\n\n### セッション\n\n`session`オブジェクトは`FastMCPSession`のインスタンスであり、アクティブなクライアントセッションを記述します。\n\n```ts\nserver.sessions;\n```\n\nクライアントとサーバー間の1対1通信を可能にするために、各クライアント接続に対して新しいサーバーインスタンスを割り当てます。\n\n### 型付きサーバーイベント\n\n`on`メソッドを使用してサーバーから発行されるイベントをリッスンできます：\n\n```ts\nserver.on(\"connect\", (event) => {\n  console.log(\"クライアント接続:\", event.session);\n});\n\nserver.on(\"disconnect\", (event) => {\n  console.log(\"クライアント切断:\", event.session);\n});\n```\n\n## `FastMCPSession`\n\n`FastMCPSession`はクライアントセッションを表し、クライアントとやり取りするためのメソッドを提供します。\n\n`FastMCPSession`インスタンスの取得方法については、[セッション](#セッション)の例を参照してください。\n\n### `requestSampling`\n\n`requestSampling`は[サンプリング](https://modelcontextprotocol.io/docs/concepts/sampling)リクエストを作成し、レスポンスを返します。\n\n```ts\nawait session.requestSampling({\n  messages: [\n    {\n      role: \"user\",\n      content: {\n        type: \"text\",\n        text: \"現在のディレクトリにはどのファイルがありますか？\",\n      },\n    },\n  ],\n  systemPrompt: \"あなたは役立つファイルシステムアシスタントです。\",\n  includeContext: \"thisServer\",\n  maxTokens: 100,\n});\n```\n\n### `clientCapabilities`\n\n`clientCapabilities`プロパティにはクライアント機能が含まれています。\n\n```ts\nsession.clientCapabilities;\n```\n\n### `loggingLevel`\n\n`loggingLevel`プロパティは、クライアントによって設定されたロギングレベルを記述します。\n\n```ts\nsession.loggingLevel;\n```\n\n### `roots`\n\n`roots`プロパティには、クライアントによって設定されたルートが含まれています。\n\n```ts\nsession.roots;\n```\n\n### `server`\n\n`server`プロパティには、セッションに関連付けられたMCPサーバーのインスタンスが含まれています。\n\n```ts\nsession.server;\n```\n\n### 型付きセッションイベント\n\n`on`メソッドを使用してセッションから発行されるイベントをリッスンできます：\n\n```ts\nsession.on(\"rootsChanged\", (event) => {\n  console.log(\"ルート変更:\", event.roots);\n});\n\nsession.on(\"error\", (event) => {\n  console.error(\"エラー:\", event.error);\n});\n```\n\n## サーバーの実行\n\n### MCP-CLIでテスト\n\nサーバーをテストしてデバッグする最速の方法は、`fastmcp dev`を使用することです：\n\n```bash\nnpx fastmcp dev server.js\nnpx fastmcp dev server.ts\n```\n\nこれにより、[`mcp-cli`](https://github.com/wong2/mcp-cli)を使用してターミナルでMCPサーバーをテストおよびデバッグするためのサーバーが実行されます。\n\n### MCP Inspectorで検査\n\nもう一つの方法は、公式の[`MCP Inspector`](https://modelcontextprotocol.io/docs/tools/inspector)を使用してWebUIでサーバーを検査することです：\n\n```bash\nnpx fastmcp inspect server.ts\n```\n\n## よくある質問\n\n### Claude Desktopで使用するには？\n\nガイド https://modelcontextprotocol.io/quickstart/user に従って、次の設定を追加してください：\n\n```json\n{\n  \"mcpServers\": {\n    \"my-mcp-server\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"tsx\",\n        \"/プロジェクトへのパス/src/index.ts\"\n      ],\n      \"env\": {\n        \"環境変数名\": \"値\"\n      }\n    }\n  }\n}\n```\n\n## 事例紹介\n\n> [!NOTE]\n>\n> FastMCPを使用したサーバーを開発した場合は、ぜひ[PR提出](https://github.com/punkpeye/fastmcp)して事例として紹介してください！\n\n- [apinetwork/piapi-mcp-server](https://github.com/apinetwork/piapi-mcp-server) - Midjourney/Flux/Kling/LumaLabs/Udio/Chrip/Trellisを使用してメディアを生成\n- [domdomegg/computer-use-mcp](https://github.com/domdomegg/computer-use-mcp) - コンピュータを制御\n- [LiterallyBlah/Dradis-MCP](https://github.com/LiterallyBlah/Dradis-MCP) – Dradisでプロジェクトと脆弱性を管理\n- [Meeting-Baas/meeting-mcp](https://github.com/Meeting-Baas/meeting-mcp) - 会議ボットの作成、議事録の検索、録画データの管理\n- [drumnation/unsplash-smart-mcp-server](https://github.com/drumnation/unsplash-smart-mcp-server) – AIエージェントがUnsplashからプロの写真をシームレスに検索、推奨、配信できるようにする\n- [ssmanji89/halopsa-workflows-mcp](https://github.com/ssmanji89/halopsa-workflows-mcp) - HaloPSAワークフローとAIアシスタントの統合\n- [aiamblichus/mcp-chat-adapter](https://github.com/aiamblichus/mcp-chat-adapter) – LLMがチャット完了を使用するためのクリーンなインターフェースを提供\n\n## 謝辞\n\n- FastMCPは[Jonathan Lowin](https://github.com/jlowin)による[Python実装](https://github.com/jlowin/fastmcp)に着想を得ています。\n- コードベースの一部は[LiteMCP](https://github.com/wong2/litemcp)から採用されました。\n- コードベースの一部は[Model Context protocolでSSEをやってみる](https://dev.classmethod.jp/articles/mcp-sse/)から採用されました。",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "2025_mcplab_fastmcp",
        "logging",
        "yamato",
        "logging yamato",
        "2025_mcplab_fastmcp built",
        "typescript server"
      ],
      "category": "monitoring-and-logging"
    },
    "ynu--mcp-ynu": {
      "owner": "ynu",
      "name": "mcp-ynu",
      "url": "https://github.com/ynu/mcp-ynu",
      "imageUrl": "/freedevtools/mcp/pfp/ynu.webp",
      "description": "Dynamically load tools, resources, and prompts from specified directories to enhance application capabilities. Offers automatic module discovery and logging features for efficient server management.",
      "stars": 0,
      "forks": 1,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-04-24T03:02:28Z",
      "readme_content": "# MCP-YNU - FastMCP Server\n\nA dynamic MCP server implementation using FastMCP that automatically loads tools, resources, and prompts from respective directories.\n\n## Features\n\n- Dynamic loading of modules from `tools/`, `resources/`, and `prompts/` directories\n- Automatic discovery and registration of modules\n- Simple configuration and extensibility\n- Type hints for better code clarity and static analysis\n- Comprehensive logging for monitoring server activity\n\n## Recent Updates\n\n- Added type hints throughout the codebase\n- Improved MCP instance handling\n- Added logging functionality\n- Added MIT license\n- Updated documentation with reference links\n\n## Directory Structure\n\n```\nmcp-ynu/\n├── tools/          # Directory for tool modules\n│   ├── __init__.py\n│   ├── example.py\n├── resources/      # Directory for resource modules\n│   ├── __init__.py\n│   ├── example.py\n├── prompts/        # Directory for prompt modules\n│   ├── __init__.py\n│   ├── example.py\n├── logger.py       # Logger implementation\n├── main.py         # Main implementation\n├── mcp_server.py   # MCP server implementation\n├── README.md       # Project documentation\n├── LICENSE         # MIT License\n└── pyproject.toml  # Project configuration\n```\n\n## Usage\n\n1. Create modules in the appropriate directories\n2. Import mcp via `from mcp_server import mcp` \n3. Run the server:\n\n```bash\npython main.py\n```\n\n## Example Modules\n\n### Tools Module Example (tools/example.py)\n```python\nfrom mcp_server import mcp\nimport httpx\n\n@mcp.tool()\ndef calculate_bmi(weight_kg: float, height_m: float) -> float:\n    \"\"\"Calculate BMI given weight in kg and height in meters\"\"\"\n    return weight_kg / (height_m**2)\n\n\n@mcp.tool()\nasync def fetch_weather(city: str) -> str:\n    \"\"\"Fetch current weather for a city\"\"\"\n    async with httpx.AsyncClient() as client:\n        response = await client.get(f\"https://api.weather.com/{city}\")\n        return response.text\n```\n\n### Resources Module Example (resources/example.py)\n```python\nfrom mcp_server import mcp\n\n@mcp.resource(\"config://app\")\ndef get_config() -> str:\n    \"\"\"Static configuration data\"\"\"\n    return \"App configuration here\"\n\n\n@mcp.resource(\"users://{user_id}/profile\")\ndef get_user_profile(user_id: str) -> str:\n    \"\"\"Dynamic user data\"\"\"\n    return f\"Profile data for user {user_id}\"\n```\n\n### Prompts Module Example (prompts/example.py)\n```python\nfrom mcp_server import mcp\nfrom mcp.server.fastmcp.prompts import base\n\n@mcp.prompt()\ndef review_code(code: str) -> str:\n    return f\"Please review this code:\\n\\n{code}\"\n\n\n@mcp.prompt()\ndef debug_error(error: str) -> list[base.Message]:\n    return [\n        base.UserMessage(\"I'm seeing this error:\"),\n        base.UserMessage(error),\n        base.AssistantMessage(\"I'll help debug that. What have you tried so far?\"),\n    ]\n```\n\n## Debugging\n\n1. Update `MCP_TRANSPORT_TYPE` in `.env`, Execute `python main.py` to start the mcp server\n2. Execute `npx @modelcontextprotocol/inspector` to open the [inspect](http://localhost:5173/).\n3. Choose `SSE` Transport Type with URL `http://localhost:<mcp_server_port>/sse` or Choose `STDIO` Transport Type with Command `python` and Arguments `/path/to/main.py`\n\n\n\n## Requirements\n\n- Python >= 3.10\n- FastMCP\n\n## Reference Links\n\n- [MCP Python SDK Documentation](https://github.com/modelcontextprotocol/python-sdk)\n- [MCP Core Concepts](https://github.com/modelcontextprotocol/python-sdk?tab=readme-ov-file#core-concepts)\n- [FastMCP Implementation](https://github.com/modelcontextprotocol/python-sdk/blob/main/src/mcp/server/fastmcp.py)\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "logging",
        "ynu",
        "monitoring",
        "logging ynu",
        "ynu mcp",
        "mcp ynu"
      ],
      "category": "monitoring-and-logging"
    },
    "zhongmingyuan--mcp-my-mac": {
      "owner": "zhongmingyuan",
      "name": "mcp-my-mac",
      "url": "https://github.com/zhongmingyuan/mcp-my-mac",
      "imageUrl": "/freedevtools/mcp/pfp/zhongmingyuan.webp",
      "description": "Exposes Mac system information through a simple API, providing real-time data about hardware, software, and environmental setups. Designed for experimentation with AI and Deep Learning on Mac systems.",
      "stars": 1,
      "forks": 3,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-05-15T16:28:04Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/zhongmingyuan-mcp-my-mac-badge.png)](https://mseep.ai/app/zhongmingyuan-mcp-my-mac)\n\n<a href=\"https://glama.ai/mcp/servers/@zhongmingyuan/mcp-my-mac\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@zhongmingyuan/mcp-my-mac/badge\" alt=\"mcp-my-mac MCP server\" />\n</a>\n\n# MCP My Mac\n\nA lightweight server that exposes Mac system information via a simple API, allowing AI assistants like Claude to access real-time system information about your Mac. This tool is primarily designed for Mac users who want to experiment with AI and Deep Learning on their machines.\n\n> **Status: BETA** - This project is currently in beta. We're actively looking for feedback to improve functionality and user experience. Please share your thoughts and suggestions!\n\n## Why Use It?\n\n- Provides Claude Desktop or other MCP clients with access to your Mac's hardware specifications, system configuration, and resource usage\n- Enables more targeted and accurate assistance for software optimization and troubleshooting\n- Runs as a secure local API with minimal overhead\n- Only executes safe, verified commands:\n  - `system_profiler` - to gather system information\n  - `conda` - to analyze Python environment configurations\n\n## Installation\n\n### Method 1: Using UV + Git Clone\n\n#### Prerequisites\n- Python 3.8 or higher\n- UV package manager installed\n\n#### Steps\n\n1. Clone the repository:   ```bash\n   git clone git@github.com:zhongmingyuan/mcp-my-mac.git   ```\n\n2. Configure for your AI client:\n\n   **[Claude Desktop]** Add the following to your MCP server config file:\n   ```json\n   \"mcpServers\": {\n       \"mcp-my-mac\": {\n           \"command\": \"uv\",\n           \"args\": [\n               \"--directory\",\n               \"/YOUR_PATH_TO/mcp-my-mac\",\n               \"run\",\n               \"-m\",\n               \"mcp_server_my_mac\"\n           ]\n       }\n   }\n   ```\n   > Note: Replace `/YOUR_PATH_TO` with the actual path where you cloned the repository.\n\n   **[Cursor]** Add tool by selecting \"command\" in UI:\n   ```bash\n   uv run --directory /YOUR_PATH_TO/mcp-my-mac mcp_server_my_mac\n   ```\n\n## Usage\n\nAfter installation, Claude Desktop will automatically connect to this API when running on your Mac, allowing it to access system information when needed for answering your questions or providing assistance.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mac",
        "monitoring",
        "logging",
        "mac information",
        "mac systems",
        "mcp mac"
      ],
      "category": "monitoring-and-logging"
    }
  }
}