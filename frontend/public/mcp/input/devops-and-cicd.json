{
  "category": "devops-and-cicd",
  "categoryDisplay": "DevOps and CI/CD",
  "description": "",
  "totalRepositories": 41,
  "repositories": {
    "10164367--sonic-buildimage": {
      "owner": "10164367",
      "name": "sonic-buildimage",
      "url": "https://github.com/10164367/sonic-buildimage",
      "imageUrl": "/freedevtools/mcp/pfp/10164367.webp",
      "description": "SONiC Buildimage is a server that helps create installation images for network switches, making it easier to deploy and customize software for different hardware. It supports various tools for debugging and managing network device images efficiently.",
      "stars": 0,
      "forks": 0,
      "license": "Other",
      "language": "",
      "updated_at": "2022-01-21T03:21:56Z",
      "readme_content": "*static analysis*:\n\n[](https://lgtm.com/projects/g/Azure/sonic-buildimage/alerts/)\n[](https://lgtm.com/projects/g/Azure/sonic-buildimage/context:python)\n\n\n*master builds*:\n\n[![Barefoot](https://dev.azure.com/mssonic/build/_apis/build/status/barefoot/Azure.sonic-buildimage.official.barefoot?branchName=master&label=Barefoot)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=146&branchName=master)\n[![Broadcom](https://dev.azure.com/mssonic/build/_apis/build/status/broadcom/Azure.sonic-buildimage.official.broadcom?branchName=master&label=Broadcom)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=138&branchName=master)\n[![Centec](https://dev.azure.com/mssonic/build/_apis/build/status/centec/Azure.sonic-buildimage.official.centec?branchName=master&label=Centec)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=143&branchName=master)\n[![Centec(arm64)](https://dev.azure.com/mssonic/build/_apis/build/status/centec/Azure.sonic-buildimage.official.centec-arm64?branchName=master&label=Centec-arm64)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=140&branchName=master)\n[![Innovium](https://dev.azure.com/mssonic/build/_apis/build/status/innovium/Azure.sonic-buildimage.official.innovium?branchName=master&label=Innovium)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=148&branchName=master)\n[![Mellanox](https://dev.azure.com/mssonic/build/_apis/build/status/mellanox/Azure.sonic-buildimage.official.mellanox?branchName=master&label=Mellanox)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=139&branchName=master)\n[![Marvell(armhf)](https://dev.azure.com/mssonic/build/_apis/build/status/marvell/Azure.sonic-buildimage.official.marvell-armhf?branchName=master&label=Marvell-armhf)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=141&branchName=master)\n[![Nephos](https://dev.azure.com/mssonic/build/_apis/build/status/nephos/Azure.sonic-buildimage.official.nephos?branchName=master&label=Nephos)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=149&branchName=master)\n[![P4](https://sonic-jenkins.westus2.cloudapp.azure.com/job/p4/job/buildimage-p4-all/badge/icon?subject=P4)](https://sonic-jenkins.westus2.cloudapp.azure.com/job/p4/job/buildimage-p4-all)\n[![VS](https://dev.azure.com/mssonic/build/_apis/build/status/vs/Azure.sonic-buildimage.official.vs?branchName=master&label=VS)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=142&branchName=master)\n\n*202012 builds*:\n\n[![Barefoot](https://dev.azure.com/mssonic/build/_apis/build/status/barefoot/Azure.sonic-buildimage.official.barefoot?branchName=202012&label=Barefoot)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=146&branchName=202012)\n[![Broadcom](https://dev.azure.com/mssonic/build/_apis/build/status/broadcom/Azure.sonic-buildimage.official.broadcom?branchName=202012&label=Broadcom)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=138&branchName=202012)\n[![Centec](https://dev.azure.com/mssonic/build/_apis/build/status/centec/Azure.sonic-buildimage.official.centec?branchName=202012&label=Centec)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=143&branchName=202012)\n[![Centec(arm64)](https://dev.azure.com/mssonic/build/_apis/build/status/centec/Azure.sonic-buildimage.official.centec-arm64?branchName=202012&label=Centec-arm64)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=140&branchName=202012)\n[![Innovium](https://dev.azure.com/mssonic/build/_apis/build/status/innovium/Azure.sonic-buildimage.official.innovium?branchName=202012&label=Innovium)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=148&branchName=202012)\n[![Marvell(armhf)](https://dev.azure.com/mssonic/build/_apis/build/status/marvell/Azure.sonic-buildimage.official.marvell-armhf?branchName=202012&label=Marvell-armhf)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=141&branchName=202012)\n[![Mellanox](https://dev.azure.com/mssonic/build/_apis/build/status/mellanox/Azure.sonic-buildimage.official.mellanox?branchName=202012&label=Mellanox)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=139&branchName=202012)\n[![Nephos](https://dev.azure.com/mssonic/build/_apis/build/status/nephos/Azure.sonic-buildimage.official.nephos?branchName=202012&label=Nephos)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=149&branchName=202012)\n[![VS](https://dev.azure.com/mssonic/build/_apis/build/status/vs/Azure.sonic-buildimage.official.vs?branchName=202012&label=VS)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=142&branchName=202012)\n\n*201911 builds*:\n\n[![Barefoot](https://dev.azure.com/mssonic/build/_apis/build/status/barefoot/Azure.sonic-buildimage.official.barefoot?branchName=201911&label=Barefoot)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=146&branchName=201911)\n[![Broadcom](https://dev.azure.com/mssonic/build/_apis/build/status/broadcom/Azure.sonic-buildimage.official.broadcom?branchName=201911&label=Broadcom)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=138&branchName=201911)\n[![Innovium](https://dev.azure.com/mssonic/build/_apis/build/status/innovium/Azure.sonic-buildimage.official.innovium?branchName=201911&label=Innovium)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=148&branchName=201911)\n[![Mellanox](https://dev.azure.com/mssonic/build/_apis/build/status/mellanox/Azure.sonic-buildimage.official.mellanox?branchName=201911&label=Mellanox)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=139&branchName=201911)\n[![Nephos](https://dev.azure.com/mssonic/build/_apis/build/status/nephos/Azure.sonic-buildimage.official.nephos?branchName=201911&label=Nephos)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=149&branchName=201911)\n[![VS](https://dev.azure.com/mssonic/build/_apis/build/status/vs/Azure.sonic-buildimage.official.vs?branchName=201911&label=VS)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=142&branchName=201911)\n\n*201811 builds*:\n\n[![Broadcom](https://dev.azure.com/mssonic/build/_apis/build/status/broadcom/Azure.sonic-buildimage.official.broadcom?branchName=201811&label=Broadcom)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=138&branchName=201811)\n[![Mellanox](https://dev.azure.com/mssonic/build/_apis/build/status/mellanox/Azure.sonic-buildimage.official.mellanox?branchName=201811&label=Mellanox)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=139&branchName=201811)\n[![Innovium](https://dev.azure.com/mssonic/build/_apis/build/status/innovium/Azure.sonic-buildimage.official.innovium?branchName=201811&label=Innovium)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=148&branchName=201811)\n[![Nephos](https://dev.azure.com/mssonic/build/_apis/build/status/nephos/Azure.sonic-buildimage.official.nephos?branchName=201811&label=Nephos)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=149&branchName=201811)\n[![VS](https://dev.azure.com/mssonic/build/_apis/build/status/vs/Azure.sonic-buildimage.official.vs?branchName=201811&label=VS)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=142&branchName=201811)\n\n*201807 builds*:\n\n[![Broadcom](https://sonic-jenkins.westus2.cloudapp.azure.com/job/broadcom/job/buildimage-brcm-201807/badge/icon?subject=Broadcom)](https://sonic-jenkins.westus2.cloudapp.azure.com/job/broadcom/job/buildimage-brcm-201807/)\n[![Barefoot](https://sonic-jenkins.westus2.cloudapp.azure.com/job/barefoot/job/buildimage-bf-201807/badge/icon?subject=Barefoot)](https://sonic-jenkins.westus2.cloudapp.azure.com/job/barefoot/job/buildimage-bf-201807/)\n\n*201803 builds*:\n\n[![Broadcom](https://sonic-jenkins.westus2.cloudapp.azure.com/job/broadcom/job/buildimage-brcm-201803/badge/icon?subject=Broadcom)](https://sonic-jenkins.westus2.cloudapp.azure.com/job/broadcom/job/buildimage-brcm-201803/)\n[![Nephos](https://sonic-jenkins.westus2.cloudapp.azure.com/job/nephos/job/buildimage-nephos-201803/badge/icon?subject=Nephos)](https://sonic-jenkins.westus2.cloudapp.azure.com/job/nephos/job/buildimage-nephos-201803/)\n[![Marvell](https://sonic-jenkins.westus2.cloudapp.azure.com/job/marvell/job/buildimage-mrvl-201803/badge/icon?subject=Marvell)](https://sonic-jenkins.westus2.cloudapp.azure.com/job/marvell/job/buildimage-mrvl-201803/)\n[![Mellanox](https://sonic-jenkins.westus2.cloudapp.azure.com/job/mellanox/job/buildimage-mlnx-201803/badge/icon?subject=Mellanox)](https://sonic-jenkins.westus2.cloudapp.azure.com/job/mellanox/job/buildimage-mlnx-201803/)\n\n# sonic-buildimage\n\n## Build SONiC Switch Images\n\n# Description\n\nFollowing is the instruction on how to build an [(ONIE)](https://github.com/opencomputeproject/onie) compatible network operating system (NOS) installer image for network switches, and also how to build docker images running inside the NOS. Note that SONiC image are build per ASIC platform. Switches using the same ASIC platform share a common image. For a list of supported switches and ASIC, please refer to this [list](https://github.com/Azure/SONiC/wiki/Supported-Devices-and-Platforms)\n\n# Hardware\n\nAny server can be a build image server as long as it has:\n\n  * Multiple cores to increase build speed\n  * Plenty of RAM (less than 8 GiB is likely to cause issues)\n  * 300G of free disk space\n\nA good choice of OS for building SONiC is currently Ubuntu 20.04.\n\n## Prerequisites\n\n * Install pip and jinja in host build machine, execute below commands if j2/j2cli is not available:\n\n```\nsudo apt install -y python3-pip\nsudo pip3 install j2cli\n```\n\n * Install [Docker](https://docs.docker.com/engine/install/) and configure your system to allow running the 'docker' command without 'sudo':\n    * Add current user to the docker group: `sudo gpasswd -a ${USER} docker`\n    * Log out and log back in so that your group membership is re-evaluated\n\n## Clone or fetch the code repository with all git submodules\nTo clone the code repository recursively, assuming git version 1.9 or newer:\n\n    git clone https://github.com/Azure/sonic-buildimage.git\n\n## Usage\n\nTo build SONiC installer image and docker images, run the following commands:\n\n    # Ensure the 'overlay' module is loaded on your development system\n    sudo modprobe overlay\n\n    # Enter the source directory\n    cd sonic-buildimage\n\n    # (Optional) Checkout a specific branch. By default, it uses master branch. For example, to checkout the branch 201911, use \"git checkout 201911\"\n    git checkout [branch_name]\n\n    # Execute make init once after cloning the repo, or after fetching remote repo with submodule updates\n    make init\n\n    # Execute make configure once to configure ASIC\n    make configure PLATFORM=[ASIC_VENDOR]\n\n    # Build SONiC image with 4 jobs in parallel.\n    # Note: You can set this higher, but 4 is a good number for most cases\n    # and is well-tested.\n    make SONIC_BUILD_JOBS=4 all\n\n The supported ASIC vendors are:\n\n- PLATFORM=broadcom\n- PLATFORM=marvell\n- PLATFORM=mellanox\n- PLATFORM=cavium\n- PLATFORM=centec\n- PLATFORM=nephos\n- PLATFORM=innovium\n- PLATFORM=p4\n- PLATFORM=vs\n\n## Usage for ARM Architecture\nTo build Arm32 bit for (ARMHF) platform\n    ARM build has dependency in docker version 18,\n    if docker version is 19, downgrade to 18 as below\n    sudo apt-get install --allow-downgrades  -y docker-ce=5:18.09.0~3-0~ubuntu-xenial\n    sudo apt-get install --allow-downgrades  -y docker-ce-cli=5:18.09.0~3-0~ubuntu-xenial\n\n    # Execute make configure once to configure ASIC and ARCH\n\n    make configure PLATFORM=[ASIC_VENDOR] PLATFORM_ARCH=armhf\n\n    make target/sonic-[ASIC_VENDER]-armhf.bin\n\n    # example:\n\n    make configure PLATFORM=marvell-armhf PLATFORM_ARCH=armhf\n\n    make target/sonic-marvell-armhf.bin\n\n\n\nTo build Arm64 bit for platform\n\n    # Execute make configure once to configure ASIC and ARCH\n\n    make configure PLATFORM=[ASIC_VENDOR] PLATFORM_ARCH=arm64\n\n    # example:\n\n    make configure PLATFORM=marvell-arm64 PLATFORM_ARCH=arm64\n\n\n **NOTE**:\n\n- Recommend reserving at least 100G free space to build one platform with a single job. The build process will use more disk if you are setting `SONIC_BUILD_JOBS` to more than 1.\n- If Docker's workspace folder, `/var/lib/docker`, resides on a partition without sufficient free space, you may encounter an error like the following during a Docker container build job:\n\n    `/usr/bin/tar: /path/to/sonic-buildimage/<some_file>: Cannot write: No space left on device`\n\n    The solution is to [move the directory](https://linuxconfig.org/how-to-move-docker-s-default-var-lib-docker-to-another-directory-on-ubuntu-debian-linux) to a partition with more free space.\n- Use `http_proxy=[your_proxy] https_proxy=[your_proxy] no_proxy=[your_no_proxy] make` to enable http(s) proxy in the build process.\n- Add your user account to `docker` group and use your user account to make. `root` or `sudo` are not supported.\n\nThe SONiC installer contains all docker images needed. SONiC uses one image for all devices of a same ASIC vendor.\n\nFor Broadcom ASIC, we build ONIE and EOS image. EOS image is used for Arista devices, ONIE image is used for all other Broadcom ASIC based devices.\n\n    make configure PLATFORM=broadcom\n    # build debian stretch required targets\n    BLDENV=stretch make stretch\n    # build ONIE image\n    make target/sonic-broadcom.bin\n    # build EOS image\n    make target/sonic-aboot-broadcom.swi\n\nYou may find the rules/config file useful. It contains configuration options for the build process, like adding more verbosity or showing dependencies, username and password for base image etc.\n\nEvery docker image is built and saved to target/ directory.\nSo, for instance, to build only docker-database, execute:\n\n    make target/docker-database.gz\n\nSame goes for debian packages, which are under target/debs/:\n\n    make target/debs/swss_1.0.0_amd64.deb\n\nEvery target has a clean target, so in order to clean swss, execute:\n\n    make target/debs/swss_1.0.0_amd64.deb-clean\n\nIt is recommended to use clean targets to clean all packages that are built together, like dev packages for instance. In order to be more familiar with build process and make some changes to it, it is recommended to read this short [Documentation](README.buildsystem.md).\n\n## Build debug dockers and debug SONiC installer image:\nSONiC build system supports building dockers and ONIE-image with debug tools and debug symbols, to help with live & core debugging. For details refer to [(SONiC Buildimage Guide)](https://github.com/Azure/sonic-buildimage/blob/master/README.buildsystem.md).\n\n## SAI Version\nPlease refer to [SONiC roadmap](https://github.com/Azure/SONiC/wiki/Sonic-Roadmap-Planning) on the SAI version for each SONiC release.\n\n## Notes:\n- If you are running make for the first time, a sonic-slave-${USER} docker image will be built automatically.\nThis may take a while, but it is a one-time action, so please be patient.\n\n- The root user account is disabled. However, the created user can `sudo`.\n\n- The target directory is `./target`, containing the NOS installer image and docker images.\n  - sonic-generic.bin: SONiC switch installer image (ONIE compatible)\n  - sonic-aboot.bin: SONiC switch installer image (Aboot compatible)\n  - docker-base.gz: base docker image where other docker images are built from, only used in build process (gzip tar archive)\n  - docker-database.gz: docker image for in-memory key-value store, used as inter-process communication (gzip tar archive)\n  - docker-fpm.gz: docker image for quagga with fpm module enabled (gzip tar archive)\n  - docker-orchagent.gz: docker image for SWitch State Service (SWSS) (gzip tar archive)\n  - docker-syncd-brcm.gz: docker image for the daemon to sync database and Broadcom switch ASIC (gzip tar archive)\n  - docker-syncd-cavm.gz: docker image for the daemon to sync database and Cavium switch ASIC (gzip tar archive)\n  - docker-syncd-mlnx.gz: docker image for the daemon to sync database and Mellanox switch ASIC (gzip tar archive)\n  - docker-syncd-nephos.gz: docker image for the daemon to sync database and Nephos switch ASIC (gzip tar archive)\n  - docker-syncd-invm.gz: docker image for the daemon to sync database and Innovium switch ASIC (gzip tar archive)\n  - docker-sonic-p4.gz: docker image for all-in-one for p4 software switch (gzip tar archive)\n  - docker-sonic-vs.gz: docker image for all-in-one for software virtual switch (gzip tar archive)\n  - docker-sonic-mgmt.gz: docker image for [managing, configuring and monitoring SONiC](https://github.com/Azure/sonic-mgmt) (gzip tar archive)\n\n## Contribution Guide\n\nAll contributors must sign a contribution license agreement before contributions can be accepted.  Contact [sonic-cla-agreements@microsoft.com](mailto:sonic-cla-agreements@microsoft.com).\n\n## GitHub Workflow\n\nWe're following basic GitHub Flow. If you have no idea what we're talking about, check out [GitHub's official guide](https://guides.github.com/introduction/flow/). Note that merge is only performed by the repository maintainer.\n\nGuide for performing commits:\n\n* Isolate each commit to one component/bugfix/issue/feature\n* Use a standard commit message format:\n\n>     [component/folder touched]: Description intent of your changes\n>\n>     [List of changes]\n>\n> \t  Signed-off-by: Your Name your@email.com\n\nFor example:\n\n>     swss-common: Stabilize the ConsumerTable\n>\n>     * Fixing autoreconf\n>     * Fixing unit-tests by adding checkers and initialize the DB before start\n>     * Adding the ability to select from multiple channels\n>     * Health-Monitor - The idea of the patch is that if something went wrong with the notification channel,\n>       we will have the option to know about it (Query the LLEN table length).\n>\n>       Signed-off-by: user@dev.null\n\n\n* Each developer should fork this repository and [add the team as a Contributor](https://help.github.com/articles/adding-collaborators-to-a-personal-repository)\n* Push your changes to your private fork and do \"pull-request\" to this repository\n* Use a pull request to do code review\n* Use issues to keep track of what is going on\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "buildimage",
        "devops",
        "sonic",
        "sonic buildimage",
        "buildimage sonic",
        "devops cicd"
      ],
      "category": "devops-and-cicd"
    },
    "1Panel-dev--mcp-1panel": {
      "owner": "1Panel-dev",
      "name": "mcp-1panel",
      "url": "https://github.com/1Panel-dev/mcp-1panel",
      "imageUrl": "/freedevtools/mcp/pfp/1Panel-dev.webp",
      "description": "The 1Panel MCP Server allows users to connect and manage their 1Panel environment, enabling efficient interaction with various tools and applications in real-time.",
      "stars": 142,
      "forks": 21,
      "license": "GNU General Public License v3.0",
      "language": "Go",
      "updated_at": "2025-10-01T14:30:13Z",
      "readme_content": "[<a href=\"/README.md\">English</a>] | [<a href=\"/docs/README.zh-Hans.md\">中文(简体)</a>]\n\n# 1Panel MCP Server\n\n**1Panel MCP Server** is an implementation of the Model Context Protocol (MCP) server for [1Panel](https://github.com/1Panel-dev/1Panel).\n\n## Installation Methods\n\n### Method 1: Download from Release Page (Recommended)\n\n1. Visit the [Releases Page](https://github.com/1Panel-dev/mcp-1panel/releases) and download the executable file corresponding to your system.\n\n2. Example installation (for amd64):\n\n```bash\nchmod +x mcp-1panel-linux-amd64\nmv mcp-1panel-linux-amd64 /usr/local/bin/mcp-1panel\n```\n\n### Method 2: Build from Source\n\nMake sure Go 1.23 or later is installed locally. Then run:\n\n1. Clone the repository:\n\n```bash\ngit clone https://github.com/1Panel-dev/mcp-1panel.git\ncd mcp-1panel\n```\n\n2. Build the executable:\n\n```bash\nmake build\n```\n\n> Move ./build/mcp-1panel to a directory included in your system's PATH.\n\n### Method 3: Install via go install\n\nMake sure Go 1.23 or later is installed locally. Then run:\n\n```bash\ngo install github.com/1Panel-dev/mcp-1panel@latest\n```\n\n### Method 4: Install via Docker\n\nMake sure Docker is correctly installed and configured on your machine.\n\nThe official image supports the following architectures:\n\n- amd64\n- arm64\n- arm/v7\n- s390x\n- ppc64le\n\n## Usage\n\n1Panel MCP Server supports two running modes: `stdio` and `sse`.\n\n### stdio Mode\n\n#### Using Local Binary\n\nIn the configuration file of Cursor or Windsurf, add:\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-1panel\": {\n      \"command\": \"mcp-1panel\",\n      \"env\": {\n        \"PANEL_ACCESS_TOKEN\": \"<your 1Panel access token>\",\n        \"PANEL_HOST\": \"such as http://localhost:8080\"\n      }\n    }\n  }\n}\n```\n\n#### Running in Docker\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-1panel\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-e\",\n        \"PANEL_HOST\",\n        \"-e\",\n        \"PANEL_ACCESS_TOKEN\",\n        \"1panel/1panel-mcp-server\"\n      ],\n      \"env\": {\n        \"PANEL_HOST\": \"such as http://localhost:8080\",\n        \"PANEL_ACCESS_TOKEN\": \"<your 1Panel access token>\"\n      }\n    }\n  }\n}\n```\n\n### sse Mode\n\n1. Start the MCP Server:\n\n```bash\nmcp-1panel -host http://localhost:8080 -token <your 1Panel access token> -transport sse -addr http://localhost:8000\n```\n\n2. Configure in Cursor or Windsurf:\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-1panel\": {\n      \"url\": \"http://localhost:8000/sse\"\n    }\n  }\n}\n```\n\n#### Command Line Options\n\n- `-token`: 1Panel access token\n- `-host`: 1Panel access address\n- `-transport`: Transport type (stdio or sse, default: stdio)\n- `-addr`: Start SSE server address (default: http://localhost:8000)\n\n## Available Tools\n\nThe server provides various tools for interacting with 1Panel:\n\n| Tool                        | Category     | Description               |\n|-----------------------------|--------------|---------------------------|\n| **get_dashboard_info**      | System       | List dashboard status     |\n| **get_system_info**         | System       | Get system information    |\n| **list_websites**           | Website      | List all websites         |\n| **create_website**          | Website      | Create a website          |\n| **list_ssls**               | Certificate  | List all certificates     |\n| **create_ssl**              | Certificate  | Create a certificate      |\n| **list_installed_apps**     | Application  | List installed apps       |\n| **install_openresty**       | Application  | Install OpenResty         |\n| **install_mysql**           | Application  | Install MySQL             |\n| **list_databases**          | Database     | List all databases        |\n| **create_database**         | Database     | Create a database         |\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "1panel",
        "mcp",
        "devops",
        "mcp 1panel",
        "1panel dev",
        "1panel mcp"
      ],
      "category": "devops-and-cicd"
    },
    "AgentsWorkingTogether--mcp-sleep": {
      "owner": "AgentsWorkingTogether",
      "name": "mcp-sleep",
      "url": "https://github.com/AgentsWorkingTogether/mcp-sleep",
      "imageUrl": "/freedevtools/mcp/pfp/AgentsWorkingTogether.webp",
      "description": "Pause execution for a specified duration to control the flow of agents. Useful for introducing timed delays, ensuring tasks are executed in a desired sequence, especially in workflows that require waiting periods between actions.",
      "stars": 1,
      "forks": 1,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-05-08T19:34:15Z",
      "readme_content": "# Sleep MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@AgentsWorkingTogether/mcp-sleep)](https://smithery.ai/server/@AgentsWorkingTogether/mcp-sleep)\n\nThis MCP server attempts to pause execution for a specified duration to control the flow of your agents. Enhance your automation by introducing timed delays, ensuring tasks are executed in the desired sequence. Ideal for managing workflows that require waiting periods between actions.\n\n\n<a href=\"https://glama.ai/mcp/servers/@AgentsWorkingTogether/mcp-sleep\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@AgentsWorkingTogether/mcp-sleep/badge\" alt=\"Sleep MCP Server\" />\n</a>\n\n## Setup\n\n### Installation\n\n#### Using MCP package managers\n\n**Smithery**\n\nTo install Sleep MCP for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@AgentsWorkingTogether/mcp-sleep):\n\n```bash\nnpx @smithery/cli install @AgentsWorkingTogether/mcp-sleep --client claude\n```\n\n**mcp-get**\n\nYou can install the Sleep MCP server using [mcp-get](https://github.com/michaellatman/mcp-get):\n\n```bash\nnpx @michaellatman/mcp-get@latest install mcp-sleep\n```\n\n### Prerequisites\n\nMCP is still very new and evolving, we recommend following the [MCP documentation](https://modelcontextprotocol.io/quickstart#prerequisites) to get the MCP basics up and running.\n\nYou'll need:\n- [Claude Desktop](https://claude.ai/)\n- [uv](https://docs.astral.sh/uv/getting-started/installation/)\n\n### Configuration\n\n#### 1. Configure Claude Desktop\n\nCreate the following file depending on your OS:\n\nOn MacOS: `~/Library/Application\\ Support/Claude/claude_desktop_config.json`\n\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\nPaste this template in the file\n\n```json\n{\n    \"mcpServers\": {\n        \"mcp-sleep\": {\n            \"command\": \"uvx\",\n            \"args\": [\n                \"mcp-sleep\"\n            ],\n        }\n    }\n}\n```\nOptionally, it replace `<MCP_SLEEP_TIMEOUT>` with your timeout ( maximum time allowed to wait, default 60 seconds ):\n\n```json\n{\n    \"mcpServers\": {\n        \"mcp-sleep\": {\n            \"command\": \"uvx\",\n            \"args\": [\n                \"mcp-sleep\"\n            ],\n            \"env\": {\n                \"MCP_SLEEP_TIMEOUT\": \"<MCP_SLEEP_TIMEOUT>\"\n            }\n        }\n    }\n}\n```\n\n#### 2. Restart Claude Desktop\n\n\n#### SSE mode\n\nAlternatively, you can run the MCP server in SSE mode by running the following command:\n\n```bash\nuvx mcp-sleep --transport sse\n```\n\nThis mode is useful to integrate with an MCP client that supports SSE (like a web app).\n\n\n## Tools\n\n1. `sleep`\n   - Pause execution for a specified duration to control the flow of your agents.\n   - Inputs:\n     - `seconds` (number, max timeout config value): Seconds it will take me to tell you to continue\n   - Returns: You will receive the sentence after {seconds} \"You can continue to do your task after you've been waiting {seconds} seconds\". If you enter a waiting time greater than the maximum time the result will be \"My configuration does not allow me to make you wait more than {ctx.sleep.config.timeout} seconds\"\n\n\n### Usage with Claude Desktop\nTo use this with Claude Desktop, add the following to your `claude_desktop_config.json`:\n\n#### Docker\n```json\n{\n  \"mcpServers\": {\n    \"mcp-sleep\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-e\",\n        \"MCP_SLEEP_TIMEOUT\",\n        \"mcp/sleep\"\n      ],\n      \"env\": {\n        \"MCP_SLEEP_TIMEOUT\": \"<MCP_SLEEP_TIMEOUT>\"\n      }\n    }\n  }\n}\n```\n\n\n## Development\n\n### Config\nIf you are working locally add two environment variables to a `.env` file in the root of the repository:\n\n```sh\nMCP_SLEEP_TIMEOUT=\n```\n\nFor local development, update your Claude Desktop configuration:\n\n```json\n{\n  \"mcpServers\": {\n      \"mcp-sleep_local\": {\n          \"command\": \"uv\",\n          \"args\": [\n              \"run\",\n              \"--directory\",\n              \"/path/to/your/mcp-sleep\",\n              \"run\",\n              \"mcp-sleep\"\n          ]\n      }\n  }\n}\n```\n\n<details>\n  <summary>Published Servers Configuration</summary>\n\n  ```json\n  \"mcpServers\": {\n    \"mcp-sleep\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"mcp-sleep\"\n      ]\n    }\n  }\n  ```\n</details>\n\n### Building and Publishing\n\nTo prepare the package for distribution:\n\n1. Sync dependencies and update lockfile:\n```bash\nuv sync\n```\n\n2. Build package distributions:\n```bash\nuv build\n```\n\nThis will create source and wheel distributions in the `dist/` directory.\n\n3. Publish to PyPI:\n```bash\nuv publish\n```\n\nNote: You'll need to set PyPI credentials via environment variables or command flags:\n- Token: `--token` or `UV_PUBLISH_TOKEN`\n- Or username/password: `--username`/`UV_PUBLISH_USERNAME` and `--password`/`UV_PUBLISH_PASSWORD`\n\nDocker build:\n\n```bash\ndocker build -t mcp/sleep -f Dockerfile .\n```\n\n\n### Debugging\n\nSince MCP servers run over stdio, debugging can be challenging. For the best debugging\nexperience, we strongly recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector).\n\n\nYou can launch the MCP Inspector via [`npm`](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm) with this command:\n\n```bash\nnpx @modelcontextprotocol/inspector uv --directory /path/to/your/mcp-sleep run mcp-sleep\n```\n\nUpon launching, the Inspector will display a URL that you can access in your browser to begin debugging.\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "agentsworkingtogether",
        "devops",
        "agents",
        "agentsworkingtogether mcp",
        "cicd agentsworkingtogether",
        "devops cicd"
      ],
      "category": "devops-and-cicd"
    },
    "Bigsy--shadow-cljs-mcp": {
      "owner": "Bigsy",
      "name": "shadow-cljs-mcp",
      "url": "https://github.com/Bigsy/shadow-cljs-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/Bigsy.webp",
      "description": "Monitors shadow-cljs builds and provides real-time updates on build status, errors, and metrics after editing ClojureScript files. Integrates seamlessly with development environments for enhanced workflow efficiency.",
      "stars": 1,
      "forks": 4,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-04-15T19:46:36Z",
      "readme_content": "# shadow-cljs-mcp\n\n[![npm version](https://badge.fury.io/js/shadow-cljs-mcp.svg)](https://badge.fury.io/js/shadow-cljs-mcp)\n\nA Model Context Protocol (MCP) server that monitors shadow-cljs builds and provides real-time build status updates.\n\n## Installation\n\nAdd the following to your Cline/Cursor/Claude whatever settings:\n```json\n{\n  \"mcpServers\": {\n    \"shadow-cljs-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"shadow-cljs-mcp\"\n      ],\n      \"disabled\": false,\n      \"autoApprove\": [],\n      \"timeout\": 60\n    }\n  }\n}\n```\nWith optional server location\n```json\n{\n  \"mcpServers\": {\n    \"shadow-cljs-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"shadow-cljs-mcp\",\n        \"--host\",\n        \"localhost\",\n        \"--port\",\n        \"9630\"\n      ],\n      \"disabled\": false,\n      \"autoApprove\": [],\n      \"timeout\": 60\n    }\n  }\n}\n```\n\nThe `--host` and `--port` arguments are optional. If not provided, the server will default to connecting to `localhost:9630`.\n\n## Overview\n\nThis MCP server connects to a running shadow-cljs instance and tracks build progress, failures, and completions. It provides an MCP tool that LLMs can use to verify build status after making changes to ClojureScript files.\n\n## LLM Integration\n\n### Adding to Your LLM Notes\n\nAdd the following to your LLM's notes file (e.g., CLAUDE.md, cursorrules.md):\n\n```markdown\nAfter any edits to ClojureScript files, use the shadow-cljs-mcp server's get_last_build_status tool to verify the build succeeded:\n\n<use_mcp_tool>\n<server_name>shadow-cljs-mcp</server_name>\n<tool_name>get_last_build_status</tool_name>\n<arguments>\n{}\n</arguments>\n</use_mcp_tool>\n\nThis will show:\n- Build status (completed/failed)\n- Which files were compiled\n- Any errors or warnings\n- Build duration and metrics\n```\n\n## Example Tool Response\n\nSuccessful build:\n```json\n{\n  \"status\": \"completed\",\n  \"resources\": 317,\n  \"compiled\": 1,\n  \"warnings\": 0,\n  \"duration\": 0.609,\n  \"compiledFiles\": [\n    \"path/to/your/file.cljs (505ms)\"\n  ]\n}\n```\n\nFailed build:\n```json\n{\n  \"status\": \"failed\",\n  \"message\": \"Build failed\",\n  \"details\": {\n    // Error information\n  }\n}\n```\n\n## Usage Notes\n\n- LLMs should call get_last_build_status after each ClojureScript file edit\n- Compilation errors will be shown in detail for easy debugging\n- Successful builds show which files were compiled and how long they took\n- Make sure shadow-cljs is running before starting this server\n\n## Requirements\n- Running shadow-cljs instance (defaults to localhost:9630 if not configured otherwise)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "clojurescript",
        "cljs",
        "devops",
        "shadow cljs",
        "cljs builds",
        "devops cicd"
      ],
      "category": "devops-and-cicd"
    },
    "CircleCI-Public--mcp-server-circleci": {
      "owner": "CircleCI-Public",
      "name": "mcp-server-circleci",
      "url": "https://github.com/CircleCI-Public/mcp-server-circleci",
      "imageUrl": "/freedevtools/mcp/pfp/CircleCI-Public.webp",
      "description": "Facilitates natural language interactions with CircleCI functionality, enabling retrieval of build logs, analysis of failures, and management of CI/CD processes directly from IDEs. Integrates CircleCI commands into the development workflow for enhanced efficiency.",
      "stars": 65,
      "forks": 37,
      "license": "Other",
      "language": "TypeScript",
      "updated_at": "2025-10-01T15:32:33Z",
      "readme_content": "# CircleCI MCP Server\n\n[![GitHub](https://img.shields.io/github/license/CircleCI-Public/mcp-server-circleci)](https://github.com/CircleCI-Public/mcp-server-circleci/blob/main/LICENSE)\n[![CircleCI](https://dl.circleci.com/status-badge/img/gh/CircleCI-Public/mcp-server-circleci/tree/main.svg?style=svg)](https://dl.circleci.com/status-badge/redirect/gh/CircleCI-Public/mcp-server-circleci/tree/main)\n[![npm](https://img.shields.io/npm/v/@circleci/mcp-server-circleci?logo=npm)](https://www.npmjs.com/package/@circleci/mcp-server-circleci)\n\nModel Context Protocol (MCP) is a [new, standardized protocol](https://modelcontextprotocol.io/introduction) for managing context between large language models (LLMs) and external systems. In this repository, we provide an MCP Server for [CircleCI](https://circleci.com).\n\nThis lets you use Cursor IDE, Windsurf, Copilot, or any MCP supported Client, to use natural language to accomplish things with CircleCI, e.g.:\n\n- `Find the latest failed pipeline on my branch and get logs`\n  https://github.com/CircleCI-Public/mcp-server-circleci/wiki#circleci-mcp-server-with-cursor-ide\n\nhttps://github.com/user-attachments/assets/3c765985-8827-442a-a8dc-5069e01edb74\n\n## Requirements\n\n- CircleCI Personal API Token - you can generate one through the CircleCI. [Learn more](https://circleci.com/docs/managing-api-tokens/) or [click here](https://app.circleci.com/settings/user/tokens) for quick access.\n\nFor NPX installation:\n\n- pnpm package manager - [Learn more](https://pnpm.io/installation)\n- Node.js >= v18.0.0\n\nFor Docker installation:\n\n- Docker - [Learn more](https://docs.docker.com/get-docker/)\n\n## Installation\n\n### Cursor\n\n#### Using NPX in a local MCP Server\n\nAdd the following to your cursor MCP config:\n\n```json\n{\n  \"mcpServers\": {\n    \"circleci-mcp-server\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@circleci/mcp-server-circleci@latest\"],\n      \"env\": {\n        \"CIRCLECI_TOKEN\": \"your-circleci-token\",\n        \"CIRCLECI_BASE_URL\": \"https://circleci.com\" // Optional - required for on-prem customers only\n      }\n    }\n  }\n}\n```\n\n\n#### Using Docker in a local MCP Server\n\nAdd the following to your cursor MCP config:\n\n```json\n{\n  \"mcpServers\": {\n    \"circleci-mcp-server\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"-i\",\n        \"-e\",\n        \"CIRCLECI_TOKEN\",\n        \"-e\",\n        \"CIRCLECI_BASE_URL\",\n        \"circleci:mcp-server-circleci\"\n      ],\n      \"env\": {\n        \"CIRCLECI_TOKEN\": \"your-circleci-token\",\n        \"CIRCLECI_BASE_URL\": \"https://circleci.com\" // Optional - required for on-prem customers only\n      }\n    }\n  }\n}\n```\n\n#### Using a Self-Managed Remote MCP Server\n\nAdd the following to your cursor MCP config:\n\n```json\n{\n  \"inputs\": [\n    {\n      \"type\": \"promptString\",\n      \"id\": \"circleci-token\", \n      \"description\": \"CircleCI API Token\",\n      \"password\": true\n    }\n  ],\n  \"servers\": {\n    \"circleci-mcp-server-remote\": {\n      \"url\": \"http://your-circleci-remote-mcp-server-endpoint:8000/mcp\"\n    }\n  }\n}\n```\n\n### VS Code\n\n#### Using NPX in a local MCP Server\n\nTo install CircleCI MCP Server for VS Code in `.vscode/mcp.json`:\n\n```json\n{\n  // 💡 Inputs are prompted on first server start, then stored securely by VS Code.\n  \"inputs\": [\n    {\n      \"type\": \"promptString\",\n      \"id\": \"circleci-token\",\n      \"description\": \"CircleCI API Token\",\n      \"password\": true\n    },\n    {\n      \"type\": \"promptString\",\n      \"id\": \"circleci-base-url\",\n      \"description\": \"CircleCI Base URL\",\n      \"default\": \"https://circleci.com\"\n    }\n  ],\n  \"servers\": {\n    // https://github.com/ppl-ai/modelcontextprotocol/\n    \"circleci-mcp-server\": {\n      \"type\": \"stdio\",\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@circleci/mcp-server-circleci@latest\"],\n      \"env\": {\n        \"CIRCLECI_TOKEN\": \"${input:circleci-token}\",\n        \"CIRCLECI_BASE_URL\": \"${input:circleci-base-url}\"\n      }\n    }\n  }\n}\n```\n\n#### Using Docker in a local MCP Server\n\nTo install CircleCI MCP Server for VS Code in `.vscode/mcp.json` using Docker:\n\n```json\n{\n  // 💡 Inputs are prompted on first server start, then stored securely by VS Code.\n  \"inputs\": [\n    {\n      \"type\": \"promptString\",\n      \"id\": \"circleci-token\",\n      \"description\": \"CircleCI API Token\",\n      \"password\": true\n    },\n    {\n      \"type\": \"promptString\",\n      \"id\": \"circleci-base-url\",\n      \"description\": \"CircleCI Base URL\",\n      \"default\": \"https://circleci.com\"\n    }\n  ],\n  \"servers\": {\n    // https://github.com/ppl-ai/modelcontextprotocol/\n    \"circleci-mcp-server\": {\n      \"type\": \"stdio\",\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"-i\",\n        \"-e\",\n        \"CIRCLECI_TOKEN\",\n        \"-e\",\n        \"CIRCLECI_BASE_URL\",\n        \"circleci:mcp-server-circleci\"\n      ],\n      \"env\": {\n        \"CIRCLECI_TOKEN\": \"${input:circleci-token}\",\n        \"CIRCLECI_BASE_URL\": \"${input:circleci-base-url}\"\n      }\n    }\n  }\n}\n```\n\n#### Using a Self-Managed Remote MCP Server\n\nTo install CircleCI MCP Server for VS Code in `.vscode/mcp.json` using a self-managed remote MCP server:\n\n```json\n{\n  \"servers\": {\n    \"circleci-mcp-server-remote\": {\n      \"type\": \"sse\",\n      \"url\": \"http://your-circleci-remote-mcp-server-endpoint:8000/mcp\"\n    }\n  }\n}\n```\n\n### Claude Desktop\n\n#### Using NPX in a local MCP Server\n\nAdd the following to your claude_desktop_config.json:\n\n```json\n{\n  \"mcpServers\": {\n    \"circleci-mcp-server\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@circleci/mcp-server-circleci@latest\"],\n      \"env\": {\n        \"CIRCLECI_TOKEN\": \"your-circleci-token\",\n        \"CIRCLECI_BASE_URL\": \"https://circleci.com\" // Optional - required for on-prem customers only\n      }\n    }\n  }\n}\n```\nTo locate this file:\n\nmacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n\n\nWindows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n\n[Claude Desktop setup](https://modelcontextprotocol.io/quickstart/user)\n\n\n#### Using Docker in a local MCP Server\n\nAdd the following to your claude_desktop_config.json:\n\n```json\n{\n  \"mcpServers\": {\n    \"circleci-mcp-server\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"-i\",\n        \"-e\",\n        \"CIRCLECI_TOKEN\",\n        \"-e\",\n        \"CIRCLECI_BASE_URL\",\n        \"circleci:mcp-server-circleci\"\n      ],\n      \"env\": {\n        \"CIRCLECI_TOKEN\": \"your-circleci-token\",\n        \"CIRCLECI_BASE_URL\": \"https://circleci.com\" // Optional - required for on-prem customers only\n      }\n    }\n  }\n}\n```\n\nTo find/create this file, first open your claude desktop settings. Then click on \"Developer\" in the left-hand bar of the Settings pane, and then click on \"Edit Config\"\n\nThis will create a configuration file at:\n\n- macOS: ~/Library/Application Support/Claude/claude_desktop_config.json\n- Windows: %APPDATA%\\Claude\\claude_desktop_config.json\n\nSee the guide below for more information on using MCP servers with Claude Desktop:\nhttps://modelcontextprotocol.io/quickstart/user\n\n#### Using a Self-Managed Remote MCP Server\n\nCreate a wrapper script first\n\nCreate a script file such as 'circleci-remote-mcp.sh':\n\n```bash\n#!/bin/bash\nexport CIRCLECI_TOKEN=\"your-circleci-token\"\nnpx mcp-remote http://your-circleci-remote-mcp-server-endpoint:8000/mcp --allow-http \n```\n\nMake it executable:\n\n```bash\nchmod +x circleci-remote-mcp.sh\n```\n\nThen add the following to your claude_desktop_config.json:\n\n```json\n{\n  \"mcpServers\": {\n    \"circleci-remote-mcp-server\": {\n      \"command\": \"/full/path/to/circleci-remote-mcp.sh\"\n    }\n  }\n}\n```\n\nTo find/create this file, first open your Claude Desktop settings. Then click on \"Developer\" in the left-hand bar of the Settings pane, and then click on \"Edit Config\"\n\nThis will create a configuration file at:\n\n- macOS: ~/Library/Application Support/Claude/claude_desktop_config.json\n- Windows: %APPDATA%\\Claude\\claude_desktop_config.json\n\nSee the guide below for more information on using MCP servers with Claude Desktop:\nhttps://modelcontextprotocol.io/quickstart/user\n\n### Claude Code\n\n#### Using NPX in a local MCP Server\n\nAfter installing Claude Code, run the following command:\n\n```bash\nclaude mcp add circleci-mcp-server -e CIRCLECI_TOKEN=your-circleci-token -- npx -y @circleci/mcp-server-circleci@latest\n```\n\n#### Using Docker in a local MCP Server\n\nAfter installing Claude Code, run the following command:\n\n```bash\nclaude mcp add circleci-mcp-server -e CIRCLECI_TOKEN=your-circleci-token -e CIRCLECI_BASE_URL=https://circleci.com -- docker run --rm -i -e CIRCLECI_TOKEN -e CIRCLECI_BASE_URL circleci:mcp-server-circleci\n```\n\nSee the guide below for more information on using MCP servers with Claude Code:\nhttps://docs.anthropic.com/en/docs/agents-and-tools/claude-code/tutorials#set-up-model-context-protocol-mcp\n\n#### Using Self-Managed Remote MCP Server\n\nAfter installing Claude Code, run the following command:\n\n```bash\nclaude mcp add circleci-mcp-server -e CIRCLECI_TOKEN=your-circleci-token -- npx mcp-remote http://your-circleci-remote-mcp-server-endpoint:8000/mcp --allow-http\n```\n\nSee the guide below for more information on using MCP servers with Claude Code:\nhttps://docs.anthropic.com/en/docs/agents-and-tools/claude-code/tutorials#set-up-model-context-protocol-mcp\n\n### Windsurf\n\n#### Using NPX in a local MCP Server\n\nAdd the following to your windsurf mcp_config.json:\n\n```json\n{\n  \"mcpServers\": {\n    \"circleci-mcp-server\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@circleci/mcp-server-circleci@latest\"],\n      \"env\": {\n        \"CIRCLECI_TOKEN\": \"your-circleci-token\",\n        \"CIRCLECI_BASE_URL\": \"https://circleci.com\" // Optional - required for on-prem customers only\n      }\n    }\n  }\n}\n```\n\n#### Using Docker in a local MCP Server\n\nAdd the following to your windsurf mcp_config.json:\n\n```json\n{\n  \"mcpServers\": {\n    \"circleci-mcp-server\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"-i\",\n        \"-e\",\n        \"CIRCLECI_TOKEN\",\n        \"-e\",\n        \"CIRCLECI_BASE_URL\",\n        \"circleci:mcp-server-circleci\"\n      ],\n      \"env\": {\n        \"CIRCLECI_TOKEN\": \"your-circleci-token\",\n        \"CIRCLECI_BASE_URL\": \"https://circleci.com\" // Optional - required for on-prem customers only\n      }\n    }\n  }\n}\n```\n\n#### Using Self-Managed Remote MCP Server\n\nAdd the following to your windsurf mcp_config.json:\n\n```json\n{\n  \"mcpServers\": {\n    \"circleci\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"mcp-remote\",\n        \"http://your-circleci-remote-mcp-server-endpoint:8000/mcp\",\n        \"--allow-http\"\n      ],\n      \"disabled\": false,\n      \"alwaysAllow\": []\n    }\n  }\n}\n```\n\nSee the guide below for more information on using MCP servers with windsurf:\nhttps://docs.windsurf.com/windsurf/mcp\n\n### Installing via Smithery\n\nTo install CircleCI MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@CircleCI-Public/mcp-server-circleci):\n\n```bash\nnpx -y @smithery/cli install @CircleCI-Public/mcp-server-circleci --client claude\n```\n\n### Amazon Q Developer CLi\n\nMCP client configuration in Amazon Q Developer is stored in JSON format, in a file named mcp.json.\n\nAmazon Q Developer CLI supports two levels of MCP configuration:\n\nGlobal Configuration: ~/.aws/amazonq/mcp.json - Applies to all workspaces\n\nWorkspace Configuration: .amazonq/mcp.json - Specific to the current workspace\n\nBoth files are optional; neither, one, or both can exist. If both files exist, Amazon Q Developer reads MCP configuration from both and combines them, taking the union of their contents. If there is a conflict (i.e., a server defined in the global config is also present in the workspace config), a warning is displayed and only the server entry in the workspace config is used.\n\n#### Using NPX in a local MCP Server\n\nEdit your global configuration file ~/.aws/amazonq/mcp.json or create a new one in the current workspace .amazonq/mcp.json with the following content:\n\n```json\n{\n  \"mcpServers\": {\n    \"circleci-local\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@circleci/mcp-server-circleci@latest\"\n      ],\n      \"env\": {\n        \"CIRCLECI_TOKEN\": \"YOUR_CIRCLECI_TOKEN\",\n        \"CIRCLECI_BASE_URL\": \"https://circleci.com\" // Optional - required for on-prem customers only\n      },\n      \"timeout\": 60000\n    }\n  }\n}\n```\n\n#### Using a Self-Managed Remote MCP Server\n\nCreate a wrapper script first\n\nCreate a script file such as 'circleci-remote-mcp.sh':\n\n```bash\n#!/bin/bash\nexport CIRCLECI_TOKEN=\"your-circleci-token\"\nnpx mcp-remote http://your-circleci-remote-mcp-server-endpoint:8000/mcp --allow-http\n```\n\nMake it executable:\n\n```bash\nchmod +x circleci-remote-mcp.sh\n```\n\nThen add it:\n\n```bash\nq mcp add --name circleci --command \"/full/path/to/circleci-remote-mcp.sh\"\n```\n\n### Amazon Q Developer in the IDE\n\n#### Using NPX in a local MCP Server\n\nEdit your global configuration file ~/.aws/amazonq/mcp.json or create a new one in the current workspace .amazonq/mcp.json with the following content:\n\n```json\n{\n  \"mcpServers\": {\n    \"circleci-local\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@circleci/mcp-server-circleci@latest\"\n      ],\n      \"env\": {\n        \"CIRCLECI_TOKEN\": \"YOUR_CIRCLECI_TOKEN\",\n        \"CIRCLECI_BASE_URL\": \"https://circleci.com\" // Optional - required for on-prem customers only\n      },\n      \"timeout\": 60000\n    }\n  }\n}\n```\n\n#### Using a Self-Managed Remote MCP Server\n\nCreate a wrapper script first\n\nCreate a script file such as 'circleci-remote-mcp.sh':\n\n```bash\n#!/bin/bash\nnpx mcp-remote http://your-circleci-remote-mcp-server-endpoint:8000/mcp --allow-http\n```\n\nMake it executable:\n\n```bash\nchmod +x circleci-remote-mcp.sh\n```\n\nThen add it to the Q Developer in your IDE:\n\nAccess the MCP configuration UI (https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/mcp-ide.html#mcp-ide-configuration-access-ui).\n\nChoose the plus (+) symbol.\n\nSelect the scope: global or local.\n\nIf you select global scope, the MCP server configuration is stored in ~/.aws/amazonq/mcp.json and available across all your projects. If you select local scope, the configuration is stored in .amazonq/mcp.json within your current project.\n\nIn the Name field, enter the name of the CircleCI remote MCP server (e.g. circleci-remote-mcp).\n\nSelect the transport protocol (stdio).\n\nIn the Command field, enter the shell command created previously that the MCP server will run when it initializes (e.g. /full/path/to/circleci-remote-mcp.sh).\n\nClick the Save button.\n\n# Features\n\n## Supported Tools\n\n- `get_build_failure_logs`\n\n  Retrieves detailed failure logs from CircleCI builds. This tool can be used in three ways:\n\n  1. Using Project Slug and Branch (Recommended Workflow):\n\n     - First, list your available projects:\n       - Use the list_followed_projects tool to get your projects\n       - Example: \"List my CircleCI projects\"\n       - Then choose the project, which has a projectSlug associated with it\n       - Example: \"Lets use my-project\"\n     - Then ask to retrieve the build failure logs for a specific branch:\n       - Example: \"Get build failures for my-project on the main branch\"\n\n  2. Using CircleCI URLs:\n\n     - Provide a failed job URL or pipeline URL directly\n     - Example: \"Get logs from https://app.circleci.com/pipelines/github/org/repo/123\"\n\n  3. Using Local Project Context:\n     - Works from your local workspace by providing:\n       - Workspace root path\n       - Git remote URL\n       - Branch name\n     - Example: \"Find the latest failed pipeline on my current branch\"\n\n  The tool returns formatted logs including:\n\n  - Job names\n  - Step-by-step execution details\n  - Failure messages and context\n\n  This is particularly useful for:\n\n  - Debugging failed builds\n  - Analyzing test failures\n  - Investigating deployment issues\n  - Quick access to build logs without leaving your IDE\n\n- `find_flaky_tests`\n\n  Identifies flaky tests in your CircleCI project by analyzing test execution history. This leverages the flaky test detection feature described here: https://circleci.com/blog/introducing-test-insights-with-flaky-test-detection/#flaky-test-detection\n\n  This tool can be used in three ways:\n\n  1. Using Project Slug (Recommended Workflow):\n\n     - First, list your available projects:\n       - Use the list_followed_projects tool to get your projects\n       - Example: \"List my CircleCI projects\"\n       - Then choose the project, which has a projectSlug associated with it\n       - Example: \"Lets use my-project\"\n     - Then ask to retrieve the flaky tests:\n       - Example: \"Get flaky tests for my-project\"\n\n  2. Using CircleCI Project URL:\n\n     - Provide the project URL directly from CircleCI\n     - Example: \"Find flaky tests in https://app.circleci.com/pipelines/github/org/repo\"\n\n  3. Using Local Project Context:\n     - Works from your local workspace by providing:\n       - Workspace root path\n       - Git remote URL\n     - Example: \"Find flaky tests in my current project\"\n\n  The tool can be used in two ways:\n  1. Using text output mode (default):\n     - This will return the flaky tests and their details in a text format\n  2. Using file output mode: (requires the `FILE_OUTPUT_DIRECTORY` environment variable to be set)\n     - This will create a directory with the flaky tests and their details\n\n  The tool returns detailed information about flaky tests, including:\n\n  - Test names and file locations\n  - Failure messages and contexts\n\n  This helps you:\n\n  - Identify unreliable tests in your test suite\n  - Get detailed context about test failures\n  - Make data-driven decisions about test improvements\n\n- `get_latest_pipeline_status`\n\n  Retrieves the status of the latest pipeline for a given branch. This tool can be used in three ways:\n\n  1. Using Project Slug and Branch (Recommended Workflow):\n\n     - First, list your available projects:\n       - Use the list_followed_projects tool to get your projects\n       - Example: \"List my CircleCI projects\"\n       - Then choose the project, which has a projectSlug associated with it\n       - Example: \"Lets use my-project\"\n     - Then ask to retrieve the latest pipeline status for a specific branch:\n       - Example: \"Get the status of the latest pipeline for my-project on the main branch\"\n\n  2. Using CircleCI Project URL:\n\n     - Provide the project URL directly from CircleCI\n     - Example: \"Get the status of the latest pipeline for https://app.circleci.com/pipelines/github/org/repo\"\n\n  3. Using Local Project Context:\n     - Works from your local workspace by providing:\n       - Workspace root path\n       - Git remote URL\n       - Branch name\n     - Example: \"Get the status of the latest pipeline for my current project\"\n\n  The tool returns a formatted status of the latest pipeline:\n\n  - Workflow names and their current status\n  - Duration of each workflow\n  - Creation and completion timestamps\n  - Overall pipeline health\n\n  Example output:\n\n  ```\n  ---\n  Workflow: build\n  Status: success\n  Duration: 5 minutes\n  Created: 4/20/2025, 10:15:30 AM\n  Stopped: 4/20/2025, 10:20:45 AM\n  ---\n  Workflow: test\n  Status: running\n  Duration: unknown\n  Created: 4/20/2025, 10:21:00 AM\n  Stopped: in progress\n  ```\n\n  This is particularly useful for:\n\n  - Checking the status of the latest pipeline\n  - Getting the status of the latest pipeline for a specific branch\n  - Quickly checking the status of the latest pipeline without leaving your IDE\n\n- `get_job_test_results`\n\n  Retrieves test metadata for CircleCI jobs, allowing you to analyze test results without leaving your IDE. This tool can be used in three ways:\n\n  1. Using Project Slug and Branch (Recommended Workflow):\n\n     - First, list your available projects:\n       - Use the list_followed_projects tool to get your projects\n       - Example: \"List my CircleCI projects\"\n       - Then choose the project, which has a projectSlug associated with it\n       - Example: \"Lets use my-project\"\n     - Then ask to retrieve the test results for a specific branch:\n       - Example: \"Get test results for my-project on the main branch\"\n\n  2. Using CircleCI URL:\n\n     - Provide a CircleCI URL in any of these formats:\n       - Job URL: \"https://app.circleci.com/pipelines/github/org/repo/123/workflows/abc-def/jobs/789\"\n       - Workflow URL: \"https://app.circleci.com/pipelines/github/org/repo/123/workflows/abc-def\"\n       - Pipeline URL: \"https://app.circleci.com/pipelines/github/org/repo/123\"\n     - Example: \"Get test results for https://app.circleci.com/pipelines/github/org/repo/123/workflows/abc-def\"\n\n  3. Using Local Project Context:\n     - Works from your local workspace by providing:\n       - Workspace root path\n       - Git remote URL\n       - Branch name\n     - Example: \"Get test results for my current project on the main branch\"\n\n  The tool returns detailed test result information:\n\n  - Summary of all tests (total, successful, failed)\n  - Detailed information about failed tests including:\n    - Test name and class\n    - File location\n    - Error messages\n    - Runtime duration\n  - List of successful tests with timing information\n  - Filter by tests result\n\n  This is particularly useful for:\n\n  - Quickly analyzing test failures without visiting the CircleCI web UI\n  - Identifying patterns in test failures\n  - Finding slow tests that might need optimization\n  - Checking test coverage across your project\n  - Troubleshooting flaky tests\n\n  Note: The tool requires that test metadata is properly configured in your CircleCI config. For more information on setting up test metadata collection, see:\n  https://circleci.com/docs/collect-test-data/\n\n- `config_helper`\n\n  Assists with CircleCI configuration tasks by providing guidance and validation. This tool helps you:\n\n  1. Validate CircleCI Config:\n     - Checks your .circleci/config.yml for syntax and semantic errors\n     - Example: \"Validate my CircleCI config\"\n\n  The tool provides:\n\n  - Detailed validation results\n  - Configuration recommendations\n\n  This helps you:\n\n  - Catch configuration errors before pushing\n  - Learn CircleCI configuration best practices\n  - Troubleshoot configuration issues\n  - Implement CircleCI features correctly\n\n- `create_prompt_template`\n\n  Helps generate structured prompt templates for AI-enabled applications based on feature requirements. This tool:\n\n  1. Converts Feature Requirements to Structured Prompts:\n     - Transforms user requirements into optimized prompt templates\n     - Example: \"Create a prompt template for generating bedtime stories by age and topic\"\n\n  The tool provides:\n\n  - A structured prompt template\n  - A context schema defining required input parameters\n\n  This helps you:\n\n  - Create effective prompts for AI applications\n  - Standardize input parameters for consistent results\n  - Build robust AI-powered features\n\n- `recommend_prompt_template_tests`\n\n  Generates test cases for prompt templates to ensure they produce expected results. This tool:\n\n  1. Provides Test Cases for Prompt Templates:\n     - Creates diverse test scenarios based on your prompt template and context schema\n     - Example: \"Generate tests for my bedtime story prompt template\"\n\n  The tool provides:\n\n  - An array of recommended test cases\n  - Various parameter combinations to test template robustness\n\n  This helps you:\n\n  - Validate prompt template functionality\n  - Ensure consistent AI responses across inputs\n  - Identify edge cases and potential issues\n  - Improve overall AI application quality\n\n- `list_followed_projects`\n\n  Lists all projects that the user is following on CircleCI. This tool:\n\n  1. Retrieves and Displays Projects:\n     - Shows all projects the user has access to and is following\n     - Provides the project name and projectSlug for each entry\n     - Example: \"List my CircleCI projects\"\n\n  The tool returns a formatted list of projects, example output:\n\n  ```\n  Projects followed:\n  1. my-project (projectSlug: gh/organization/my-project)\n  2. another-project (projectSlug: gh/organization/another-project)\n  ```\n\n  This is particularly useful for:\n\n  - Identifying which CircleCI projects are available to you\n  - Obtaining the projectSlug needed for other CircleCI tools\n  - Selecting a project for subsequent operations\n\n  Note: The projectSlug (not the project name) is required for many other CircleCI tools, and will be used for those tool calls after a project is selected.\n\n- `run_pipeline`\n\n  Triggers a pipeline to run. This tool can be used in three ways:\n\n  1. Using Project Slug and Branch (Recommended Workflow):\n\n     - First, list your available projects:\n       - Use the list_followed_projects tool to get your projects\n       - Example: \"List my CircleCI projects\"\n       - Then choose the project, which has a projectSlug associated with it\n       - Example: \"Lets use my-project\"\n     - Then ask to run the pipeline for a specific branch:\n       - Example: \"Run the pipeline for my-project on the main branch\"\n\n  2. Using CircleCI URL:\n\n     - Provide a CircleCI URL in any of these formats:\n       - Job URL: \"https://app.circleci.com/pipelines/github/org/repo/123/workflows/abc-def/jobs/789\"\n       - Workflow URL: \"https://app.circleci.com/pipelines/github/org/repo/123/workflows/abc-def\"\n       - Pipeline URL: \"https://app.circleci.com/pipelines/github/org/repo/123\"\n       - Project URL with branch: \"https://app.circleci.com/projects/github/org/repo?branch=main\"\n     - Example: \"Run the pipeline for https://app.circleci.com/pipelines/github/org/repo/123/workflows/abc-def\"\n\n  3. Using Local Project Context:\n     - Works from your local workspace by providing:\n       - Workspace root path\n       - Git remote URL\n       - Branch name\n     - Example: \"Run the pipeline for my current project on the main branch\"\n\n  The tool returns a link to monitor the pipeline execution.\n\n  This is particularly useful for:\n\n  - Quickly running pipelines without visiting the CircleCI web UI\n  - Running pipelines from a specific branch\n\n- `run_rollback_pipeline`\n\n  This tool allows for triggering a rollback for a project.\n  It requires the following parameters;\n\n  - `project_id` - The ID of the CircleCI project (UUID)\n  - `environmentName` - The environment name\n  - `componentName` - The component name\n  - `currentVersion` - The current version\n  - `targetVersion` - The target version\n  - `namespace` - The namespace of the component\n  - `reason` - The reason for the rollback (optional)\n  - `parameters` - The extra parameters for the rollback pipeline (optional)\n\n  If not all the parameters are provided right away, the toll will make use of other tools to try and retrieve all the required info.\n  The rollback can be performed in two different way, depending on whether a rollback pipeline definition has been configured for the project:\n\n  - Pipeline Rollback: will trigger the rollback pipeline.\n  - Workflow Rerun: will trigger the rerun of a previous workflow.\n\n  A typical interaction with this tool will follow this pattern:\n\n  1. Project Selection - Retrieve list of followed projects and prompt user to select one\n  2. Environment Selection - List available environments and select target (auto-select if only one exists)\n  3. Component Selection - List available components and select target (auto-select if only one exists)\n  4. Version Selection - Display available versions, user selects non-live version for rollback\n  5. Rollback Mode Detection - Check if rollback pipeline is configured for the selected project\n  6. Execute Rollback - Two options available:\n    - Pipeline Rollback: Prompt for optional reason, execute rollback pipeline\n    - Workflow Rerun**: Rerun workflow using selected version's workflow ID\n  7. Confirmation - Summarize rollback request and confirm before execution\n\n- `rerun_workflow`\n\n  Reruns a workflow from its start or from the failed job.\n\n  The tool returns the ID of the newly-created workflow, and a link to monitor the new workflow.\n\n  This is particularly useful for:\n\n  - Quickly rerunning a workflow from its start or from the failed job without visiting the CircleCI web UI\n\n- `analyze_diff`\n\n  Analyzes git diffs against cursor rules to identify rule violations.\n\n  This tool can be used by providing:\n\n  1. Git Diff Content:\n\n     - Staged changes: `git diff --cached`\n     - Unstaged changes: `git diff`\n     - All changes: `git diff HEAD`\n     - Example: \"Analyze my staged changes against the cursor rules\"\n\n  2. Repository Rules:\n     - Rules from `.cursorrules` file in your repository root\n     - Rules from `.cursor/rules` directory\n     - Multiple rule files combined with `---` separator\n     - Example: \"Check my diff against the TypeScript coding standards\"\n\n  The tool provides:\n\n  - Detailed violation reports with confidence scores\n  - Specific explanations for each rule violation\n\n  Example usage scenarios:\n\n  - \"Analyze my staged changes for any rule violations\"\n  - \"Check my unstaged changes against rules\"\n\n  This is particularly useful for:\n\n  - Pre-commit code quality checks\n  - Ensuring consistency with team coding standards\n  - Catching rule violations before code review\n\n  The tool integrates with your existing cursor rules setup and provides immediate feedback on code quality, helping you catch issues early in the development process.\n\n- `list_component_versions`\n\n  Lists all versions for a specific CircleCI component in an environment. This tool retrieves version history including deployment status, commit information, and timestamps for a component.\n  The tool will prompt the user to select the component and environment from a list if not provided.\n\n  Example output:\n\n  ```\n  Versions for the component: {\n    \"items\": [\n      {\n        \"name\": \"v1.2.0\",\n        \"namespace\": \"production\",\n        \"environment_id\": \"env-456def\",\n        \"is_live\": true,\n        \"pipeline_id\": \"12345678-1234-1234-1234-123456789abc\",\n        \"workflow_id\": \"87654321-4321-4321-4321-cba987654321\",\n        \"job_id\": \"11111111-1111-1111-1111-111111111111\",\n        \"job_number\": 42,\n        \"last_deployed_at\": \"2023-01-01T00:00:00Z\"\n      },\n      {\n        \"name\": \"v1.1.0\",\n        \"namespace\": \"production\", \n        \"environment_id\": \"env-456def\",\n        \"is_live\": false,\n        \"pipeline_id\": \"22222222-2222-2222-2222-222222222222\",\n        \"workflow_id\": \"33333333-3333-3333-3333-333333333333\",\n        \"job_id\": \"44444444-4444-4444-4444-444444444444\",\n        \"job_number\": 38,\n        \"last_deployed_at\": \"2023-01-03T00:00:00Z\"\n      }\n    ]\n  }\n  ```\n\n  This is useful for:\n\n  - Identifying which versions were deployed for a component\n  - Finding the currently live version in an environment\n  - Selecting target versions for rollback operations\n  - Getting deployment details like pipeline, workflow, and job information\n  - Listing all environments\n  - Listing all components\n\n- `download_usage_api_data`\n\n  Downloads usage data from the CircleCI Usage API for a given organization. Accepts flexible, natural language date input (e.g., \"March 2025\" or \"last month\"). Cloud-only feature.\n\n  This tool can be used in one of two ways:\n\n  1) Start a new export job for a date range (max 32 days) by providing:\n  - orgId: Organization ID\n  - startDate: Start date (YYYY-MM-DD or natural language)\n  - endDate: End date (YYYY-MM-DD or natural language)\n  - outputDir: Directory to save the CSV file\n\n  2) Check/download an existing export job by providing:\n  - orgId: Organization ID\n  - jobId: Usage export job ID\n  - outputDir: Directory to save the CSV file\n\n  The tool provides:\n  - A csv containing the CircleCI Usage API data from the specified time frame\n\n  This is useful for:\n  - Downloading detailed CircleCI usage data for reporting or analysis\n  - Feeding usage data into the `find_underused_resource_classes` tool\n\n  Example usage scenarios:\n- Scenario 1:\n  1. \"Download usage data for org abc123 from June into ~/Downloads\"\n  2. \"Check status\"\n\n- Scenario 2:\n  1. \"Download usage data for org abc123 for last month to my Downloads folder\"\n  2. \"Check usage download status\"\n  3. \"Check status again\"\n\n- Scenario 3:\n  1. \"Check my usage export job usage-job-9f2d7c and download it if ready\"\n\n- `find_underused_resource_classes`\n\n  Analyzes a CircleCI usage data CSV file to find jobs/resource classes with average or max CPU/RAM usage below a given threshold (default 40%).\n\n  This tool can be used by providing:\n  - A csv containing CircleCI Usage API data, which can be obtained by using the `download_usage_api_data` tool.\n\n  The tool provides:\n  - A markdown list of all jobs that are below the threshold, delineated by project and workflow.\n\n  This is useful for:\n  - Finding jobs that are using less than half of the compute provided to them on average\n  - Generating a list of low hanging cost optimizations\n\n  Example usage scenarios:\n  - Scenario 1:\n    1. \"Find underused resource classes in the file you just downloaded\"\n  - Scenario 2:\n    1. \"Find underused resource classes in ~/Downloads/usage-data-2025-06-01_2025-06-30.csv\"\n  - Scenario 3:\n    1. \"Analyze /Users/you/Projects/acme/usage-data-job-9f2d7c.csv with threshold 30\"\n\n## Troubleshooting\n\n### Quick Fixes\n\n**Most Common Issues:**\n\n1. **Clear package caches:**\n   ```bash\n   npx clear-npx-cache\n   npm cache clean --force\n   ```\n\n2. **Force latest version:** Add `@latest` to your config:\n   ```json\n   \"args\": [\"-y\", \"@circleci/mcp-server-circleci@latest\"]\n   ```\n\n3. **Restart your IDE completely** (not just reload window)\n\n## Authentication Issues\n\n* **Invalid token errors:** Verify your `CIRCLECI_TOKEN` in Personal API Tokens\n* **Permission errors:** Ensure token has read access to your projects\n* **Environment variables not loading:** Test with `echo $CIRCLECI_TOKEN` (Mac/Linux) or `echo %CIRCLECI_TOKEN%` (Windows)\n\n## Connection and Network Issues\n\n* **Base URL:** Confirm `CIRCLECI_BASE_URL` is `https://circleci.com`\n* **Corporate networks:** Configure npm proxy settings if behind firewall\n* **Firewall blocking:** Check if security software blocks package downloads\n\n## System Requirements\n\n* **Node.js version:** Ensure ≥ 18.0.0 with `node --version`\n* **Update Node.js:** Consider latest LTS if experiencing compatibility issues\n* **Package manager:** Verify npm/pnpm is working: `npm --version`\n\n## IDE-Specific Issues\n\n* **Config file location:** Double-check path for your OS\n* **Syntax errors:** Validate JSON syntax in config file\n* **Console logs:** Check IDE developer console for specific errors\n* **Try different IDE:** Test config in another supported editor to isolate issue\n\n## Process Issues\n\n* **Hanging processes:** Kill existing MCP processes:\n  ```bash\n  # Mac/Linux: \n  pkill -f \"mcp-server-circleci\"\n  \n  # Windows: \n  taskkill /f /im node.exe\n\n* **Port conflicts:** Restart IDE if connection seems blocked\n\n## Advanced Debugging\n\n* **Test package directly:** `npx @circleci/mcp-server-circleci@latest --help`\n* **Verbose logging:** `DEBUG=* npx @circleci/mcp-server-circleci@latest`\n* **Docker fallback:** Try Docker installation if npx fails consistently\n\n## Still Need Help?\n\n1. Check GitHub issues for similar problems\n2. Include your OS, Node version, and IDE when reporting issues\n3. Share relevant error messages from IDE console\n\n# Development\n\n## Getting Started\n\n1. Clone the repository:\n\n   ```bash\n   git clone https://github.com/CircleCI-Public/mcp-server-circleci.git\n   cd mcp-server-circleci\n   ```\n\n2. Install dependencies:\n\n   ```bash\n   pnpm install\n   ```\n\n3. Build the project:\n   ```bash\n   pnpm build\n   ```\n\n## Building Docker Container\n\nYou can build the Docker container locally using:\n\n```bash\ndocker build -t circleci:mcp-server-circleci .\n```\n\nThis will create a Docker image tagged as `circleci:mcp-server-circleci` that you can use with any MCP client.\n\nTo run the container locally:\n\n```bash\ndocker run --rm -i -e CIRCLECI_TOKEN=your-circleci-token -e CIRCLECI_BASE_URL=https://circleci.com circleci:mcp-server-circleci\n```\n\nTo run the container as a self-managed remote MCP server you need to add the environment variable `start=remote` to the docker run command. You can also define the port to use with the environment variable `port=<port>` or else the default port `8000` will be used:\n\n```bash\ndocker run --rm -i -e CIRCLECI_TOKEN=your-circleci-token -e CIRCLECI_BASE_URL=https://circleci.com circleci:mcp-server-circleci -e start=remote -e port=8000\n```\n\n## Development with MCP Inspector\n\nThe easiest way to iterate on the MCP Server is using the MCP inspector. You can learn more about the MCP inspector at https://modelcontextprotocol.io/docs/tools/inspector\n\n1. Start the development server:\n\n   ```bash\n   pnpm watch # Keep this running in one terminal\n   ```\n\n2. In a separate terminal, launch the inspector:\n\n   ```bash\n   pnpm inspector\n   ```\n\n3. Configure the environment:\n   - Add your `CIRCLECI_TOKEN` to the Environment Variables section in the inspector UI\n   - The token needs read access to your CircleCI projects\n   - Optionally you can set your CircleCI Base URL. Defaults to `https//circleci.com`\n\n## Testing\n\n- Run the test suite:\n\n  ```bash\n  pnpm test\n  ```\n\n- Run tests in watch mode during development:\n  ```bash\n  pnpm test:watch\n  ```\n\nFor more detailed contribution guidelines, see [CONTRIBUTING.md](CONTRIBUTING.md)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "circleci",
        "devops",
        "cicd",
        "devops cicd",
        "circleci commands",
        "circleci functionality"
      ],
      "category": "devops-and-cicd"
    },
    "DefangLabs--defang": {
      "owner": "DefangLabs",
      "name": "defang",
      "url": "https://github.com/DefangLabs/defang",
      "imageUrl": "/freedevtools/mcp/pfp/DefangLabs.webp",
      "description": "Facilitates secure code building and release management by automating dependency handling, formatting, and versioning processes. Ensures projects maintain updated dependencies and supports streamlined continuous integration workflows.",
      "stars": 144,
      "forks": 19,
      "license": "MIT License",
      "language": "Go",
      "updated_at": "2025-10-03T21:43:10Z",
      "readme_content": "[![Go package](https://github.com/DefangLabs/defang/actions/workflows/go.yml/badge.svg?branch=main)](https://github.com/DefangLabs/defang/actions/workflows/go.yml)\n![Discord](https://img.shields.io/discord/1233224785450897561)\n![GitHub Release](https://img.shields.io/github/v/release/DefangLabs/defang)\n\n### ![Defang](https://raw.githubusercontent.com/DefangLabs/defang-assets/main/Logos/Element_Wordmark_Slogan/JPG/Dark_Colour_Glow.jpg)\n\n## Develop Once, Deploy Anywhere.\n\nTake your app from Docker Compose to a secure and scalable deployment on your favorite cloud in minutes.\n\n## Defang CLI\n\nThe Defang Command-Line Interface [(CLI)](https://docs.defang.io/docs/getting-started) is designed for developers who prefer to manage their workflows directly from the terminal. It offers full access to Defang’s capabilities, allowing you to build, test, and deploy applications efficiently to the cloud.\n\n## Defang MCP Server\n\nThe Defang Model Context Protocol [(MCP)](https://docs.defang.io/docs/concepts/mcp) Server is tailored for developers who work primarily within integrated development environments (IDEs). It enables seamless cloud deployment from supported editors such as Cursor, Windsurf, VS Code, VS Code Insiders and Claude delivering a fully integrated experience without leaving your development environment.\n\n## This repo includes:\n\n- Public releases of the Defang CLI; [click here](https://github.com/DefangLabs/defang/releases/latest/) for the latest version\n- Built-in support for MCP Server — the Defang MCP Server makes cloud deployment as easy as a single prompt. [Learn more](https://docs.defang.io/docs/concepts/mcp)\n- [Samples](https://github.com/DefangLabs/samples) in Golang, Python, and Node.js that show how to accomplish various tasks and deploy them to the DOP using a Docker Compose file using the Defang CLI.\n- Samples that show how to deploy an app using the [Defang Pulumi Provider](https://github.com/DefangLabs/pulumi-defang).\n\n## Getting started\n\n- Read our [Getting Started](https://docs.defang.io/docs/getting-started) page\n- Follow the installation instructions from the [Installing](https://docs.defang.io/docs/getting-started/installing) page\n- Take a look at our [Samples folder](https://github.com/DefangLabs/defang/tree/main/samples) for example projects in various programming languages.\n- Try the AI integration by running `defang generate`\n- Start your new service with `defang compose up`\n\n## Installing\n\nInstall the Defang CLI from one of the following sources:\n\n- Using the [Homebrew](https://brew.sh) package manager [DefangLabs/defang tap](https://github.com/DefangLabs/homebrew-defang):\n\n  ```\n  brew install DefangLabs/defang/defang\n  ```\n\n- Using a shell script:\n\n  ```\n  eval \"$(curl -fsSL s.defang.io/install)\"\n  ```\n\n- Using [Go](https://go.dev):\n\n  ```\n  go install github.com/DefangLabs/defang/src/cmd/cli@latest\n  ```\n\n- Using the [Nix package manager](https://nixos.org):\n\n  - with Nix-Env:\n    ```\n    nix-env -if https://github.com/DefangLabs/defang/archive/main.tar.gz\n    ```\n  - or with Flakes:\n    ```\n    nix profile install github:DefangLabs/defang#defang-bin --refresh\n    ```\n\n- Using [winget](https://learn.microsoft.com/en-us/windows/package-manager/winget/):\n\n  ```\n  winget install defang\n  ```\n\n- Using a PowerShell script:\n\n  ```\n  iwr https://s.defang.io/defang_win_amd64.zip -OutFile defang.zip\n  Expand-Archive defang.zip . -Force\n  ```\n\n- Using the [official image from Docker Hub](https://hub.docker.com/r/defangio/defang-cli):\n\n  ```\n  docker run -it defangio/defang-cli help\n  ```\n\n- or download the [latest binary](https://github.com/DefangLabs/defang/releases/latest/) of the Defang CLI.\n\n## Support\n\n- File any issues [here](https://github.com/DefangLabs/defang/issues)\n\n## Command completion\n\nThe Defang CLI supports command completion for Bash, Zsh, Fish, and Powershell. To get the shell script for command completion, run the following command:\n\n```\ndefang completion [bash|zsh|fish|powershell]\n```\n\nIf you're using Bash, you can add the following to your `~/.bashrc` file:\n\n```\nsource <(defang completion bash)\n```\n\nIf you're using Zsh, you can add the following to your `~/.zshrc` file:\n\n```\nsource <(defang completion zsh)\n```\n\nor pipe the output to a file called `_defang` in the directory with the completions.\n\nIf you're using Fish, you can add the following to your `~/.config/fish/config.fish` file:\n\n```\ndefang completion fish | source\n```\n\nIf you're using Powershell, you can add the following to your `$HOME\\Documents\\PowerShell\\Microsoft.PowerShell_profile.ps1` file:\n\n```\nInvoke-Expression -Command (defang completion powershell | Out-String)\n```\n\n## Environment Variables\n\nThe Defang CLI recognizes the following environment variables:\n\n- `COMPOSE_PROJECT_NAME` - The name of the project to use; overrides the name in the `compose.yaml` file\n- `DEFANG_ACCESS_TOKEN` - The access token to use for authentication; if not specified, uses token from `defang login`\n- `DEFANG_BUILD_CONTEXT_LIMIT` - The maximum size of the build context when building container images; defaults to `100MiB`\n- `DEFANG_CD_BUCKET` - The S3 bucket to use for the BYOC CD pipeline; defaults to `defang-cd-bucket-…`\n- `DEFANG_CD_IMAGE` - The image to use for the Continuous Deployment (CD) pipeline; defaults to `public.ecr.aws/defang-io/cd:public-beta`\n- `DEFANG_DEBUG` - set this to `1` or `true` to enable debug logging\n- `DEFANG_DISABLE_ANALYTICS` - If set to `true`, disables sending analytics to Defang; defaults to `false`\n- `DEFANG_EDITOR` - The editor to launch after new project generation; defaults to `code` (VS Code)\n- `DEFANG_FABRIC` - The address of the Defang Fabric to use; defaults to `fabric-prod1.defang.dev`\n- `DEFANG_JSON` - If set to `true`, outputs JSON instead of human-readable output; defaults to `false`\n- `DEFANG_HIDE_HINTS` - If set to `true`, hides hints in the CLI output; defaults to `false`\n- `DEFANG_HIDE_UPDATE` - If set to `true`, hides the update notification; defaults to `false`\n- `DEFANG_ISSUER` - The OAuth2 issuer to use for authentication; defaults to `https://auth.defang.io`\n- `DEFANG_MODEL_ID` - The model ID of the LLM to use for the generate/debug AI integration (Pro users only)\n- `DEFANG_NO_CACHE` - If set to `true`, disables pull-through caching of container images; defaults to `false`\n- `DEFANG_ORG` - The name of the organization to use; defaults to the user's GitHub name\n- `DEFANG_PREFIX` - The prefix to use for all BYOC resources; defaults to `Defang`\n- `DEFANG_PROVIDER` - The name of the cloud provider to use, `auto` (default), `aws`, `digitalocean`, `gcp`, or `defang`\n- `DEFANG_PULUMI_BACKEND` - The Pulumi backend URL or `\"pulumi-cloud\"`; defaults to a self-hosted backend\n- `DEFANG_PULUMI_DIR` - Run Pulumi from this folder, instead of spawning a cloud task; requires `--debug` (BYOC only)\n- `DEFANG_PULUMI_VERSION` - Override the version of the Pulumi image to use (`aws` provider only)\n- `NO_COLOR` - If set to any value, disables color output; by default, color output is enabled depending on the terminal\n- `PULUMI_ACCESS_TOKEN` - The Pulumi access token to use for authentication to Pulumi Cloud; see `DEFANG_PULUMI_BACKEND`\n- `PULUMI_CONFIG_PASSPHRASE` - Passphrase used to generate a unique key for your stack, and configuration and encrypted state values\n- `TZ` - The timezone to use for log timestamps: an IANA TZ name like `UTC` or `Europe/Amsterdam`; defaults to `Local`\n- `XDG_STATE_HOME` - The directory to use for storing state; defaults to `~/.local/state`\n\nEnvironment variables will be loaded from a `.defangrc` file in the current directory, if it exists. This file follows\nthe same format as a `.env` file: `KEY=VALUE` pairs on each line, lines starting with `#` are treated as comments and ignored.\n\n## Development\n\nAt Defang we use the [Nix package manager](https://nixos.org) for our dev environment, in conjunction with [DirEnv](https://direnv.net).\n\nTo get started quickly, install Nix and DirEnv, then create a `.envrc` file to automatically load the Defang developer environment:\n\n```sh\necho use flake >> .envrc\ndirenv allow\n```\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "defanglabs",
        "devops",
        "defang",
        "devops cicd",
        "cicd defanglabs",
        "defanglabs defang"
      ],
      "category": "devops-and-cicd"
    },
    "F4biox--hello-github-actions": {
      "owner": "F4biox",
      "name": "hello-github-actions",
      "url": "https://github.com/F4biox/hello-github-actions",
      "imageUrl": "/freedevtools/mcp/pfp/null.webp",
      "description": "Guide users through creating their first GitHub Action and integrating it into a workflow file. The server provides a structured approach for hands-on learning with practical examples.",
      "stars": 0,
      "forks": 0,
      "license": "Unknown",
      "language": "Unknown",
      "updated_at": "",
      "readme_content": "",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "github",
        "devops",
        "workflow",
        "github actions",
        "github action",
        "creating github"
      ],
      "category": "devops-and-cicd"
    },
    "Flux159--mcp-server-kubernetes": {
      "owner": "Flux159",
      "name": "mcp-server-kubernetes",
      "url": "https://github.com/Flux159/mcp-server-kubernetes",
      "imageUrl": "/freedevtools/mcp/pfp/Flux159.webp",
      "description": "Interact with Kubernetes clusters using kubectl for managing and orchestrating containerized applications, deployments, and services.",
      "stars": 1108,
      "forks": 180,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-04T08:36:38Z",
      "readme_content": "# MCP Server Kubernetes\n\n[![CI](https://github.com/Flux159/mcp-server-kubernetes/actions/workflows/ci.yml/badge.svg)](https://github.com/yourusername/mcp-server-kubernetes/actions/workflows/ci.yml)\n[![Language](https://img.shields.io/github/languages/top/Flux159/mcp-server-kubernetes)](https://github.com/yourusername/mcp-server-kubernetes)\n[![Bun](https://img.shields.io/badge/runtime-bun-orange)](https://bun.sh)\n[![Kubernetes](https://img.shields.io/badge/kubernetes-%23326ce5.svg?style=flat&logo=kubernetes&logoColor=white)](https://kubernetes.io/)\n[![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?style=flat&logo=docker&logoColor=white)](https://www.docker.com/)\n[![Stars](https://img.shields.io/github/stars/Flux159/mcp-server-kubernetes)](https://github.com/Flux159/mcp-server-kubernetes/stargazers)\n[![Issues](https://img.shields.io/github/issues/Flux159/mcp-server-kubernetes)](https://github.com/Flux159/mcp-server-kubernetes/issues)\n[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](https://github.com/Flux159/mcp-server-kubernetes/pulls)\n[![Last Commit](https://img.shields.io/github/last-commit/Flux159/mcp-server-kubernetes)](https://github.com/Flux159/mcp-server-kubernetes/commits/main)\n[![Trust Score](https://archestra.ai/mcp-catalog/api/badge/quality/Flux159/mcp-server-kubernetes)](https://archestra.ai/mcp-catalog/flux159__mcp-server-kubernetes)\n[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/Flux159/mcp-server-kubernetes)\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/Flux159/mcp-server-kubernetes/refs/heads/main/icon.png\" width=\"200\">\n</p>\n\nMCP Server that can connect to a Kubernetes cluster and manage it. Supports loading kubeconfig from multiple sources in priority order.\n\nhttps://github.com/user-attachments/assets/f25f8f4e-4d04-479b-9ae0-5dac452dd2ed\n\n<a href=\"https://glama.ai/mcp/servers/w71ieamqrt\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/w71ieamqrt/badge\" /></a>\n\n## Installation & Usage\n\n### Prerequisites\n\nBefore using this MCP server with any tool, make sure you have:\n\n1. kubectl installed and in your PATH\n2. A valid kubeconfig file with contexts configured\n3. Access to a Kubernetes cluster configured for kubectl (e.g. minikube, Rancher Desktop, GKE, etc.)\n4. Helm v3 installed and in your PATH (no Tiller required). Optional if you don't plan to use Helm.\n\nYou can verify your connection by running `kubectl get pods` in a terminal to ensure you can connect to your cluster without credential issues.\n\nBy default, the server loads kubeconfig from `~/.kube/config`. For additional authentication options (environment variables, custom paths, etc.), see [ADVANCED_README.md](ADVANCED_README.md).\n\n### Claude Code\n\nAdd the MCP server to Claude Code using the built-in command:\n\n```bash\nclaude mcp add kubernetes -- npx mcp-server-kubernetes\n```\n\nThis will automatically configure the server in your Claude Code MCP settings.\n\n### Claude Desktop\n\nAdd the following configuration to your Claude Desktop config file:\n\n```json\n{\n  \"mcpServers\": {\n    \"kubernetes\": {\n      \"command\": \"npx\",\n      \"args\": [\"mcp-server-kubernetes\"]\n    }\n  }\n}\n```\n\n### Claude Desktop Connector via mcpb\n\nMCP Server Kubernetes is also available as a [mcpb](https://github.com/anthropics/mcpb) (formerly dxt) extension. In Claude Desktop, go to Settings (`Cmd+,` on Mac) -> Extensions -> Browse Extensions and scroll to find mcp-server-kubernetes in the modal. Install it & it will install & utilize kubectl via command line & your kubeconfig.\n\nTo manually install, you can also get the .mcpb by going to the latest [Release](https://github.com/Flux159/mcp-server-kubernetes/releases) and downloading it.\n\n### VS Code\n\n[![Install Kubernetes MCP in VS Code](https://img.shields.io/badge/Install%20Kubernetes%20MCP%20in%20VS%20Code-blue?logo=visualstudiocode)](vscode:mcp/install?%7B%22name%22%3A%20%22kubernetes%22%2C%20%22type%22%3A%20%22stdio%22%2C%20%22command%22%3A%20%22npx%22%2C%20%22args%22%3A%20%5B%22mcp-server-kubernetes%22%5D%7D)\n\nFor VS Code integration, you can use the MCP server with extensions that support the Model Context Protocol:\n\n1. Install a compatible MCP extension (such as Claude Dev or similar MCP clients)\n2. Configure the extension to use this server:\n\n```json\n{\n  \"mcpServers\": {\n    \"kubernetes\": {\n      \"command\": \"npx\",\n      \"args\": [\"mcp-server-kubernetes\"],\n      \"description\": \"Kubernetes cluster management and operations\"\n    }\n  }\n}\n```\n\n### Cursor\n\nCursor supports MCP servers through its AI integration. Add the server to your Cursor MCP configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"kubernetes\": {\n      \"command\": \"npx\",\n      \"args\": [\"mcp-server-kubernetes\"]\n    }\n  }\n}\n```\n\nThe server will automatically connect to your current kubectl context. You can verify the connection by asking the AI assistant to list your pods or create a test deployment.\n\n## Usage with mcp-chat\n\n[mcp-chat](https://github.com/Flux159/mcp-chat) is a CLI chat client for MCP servers. You can use it to interact with the Kubernetes server.\n\n```shell\nnpx mcp-chat --server \"npx mcp-server-kubernetes\"\n```\n\nAlternatively, pass it your existing Claude Desktop configuration file from above (Linux should pass the correct path to config):\n\nMac:\n\n```shell\nnpx mcp-chat --config \"~/Library/Application Support/Claude/claude_desktop_config.json\"\n```\n\nWindows:\n\n```shell\nnpx mcp-chat --config \"%APPDATA%\\Claude\\claude_desktop_config.json\"\n```\n\n## Features\n\n- [x] Connect to a Kubernetes cluster\n- [x] Unified kubectl API for managing resources\n  - Get or list resources with `kubectl_get`\n  - Describe resources with `kubectl_describe`\n  - List resources with `kubectl_get`\n  - Create resources with `kubectl_create`\n  - Apply YAML manifests with `kubectl_apply`\n  - Delete resources with `kubectl_delete`\n  - Get logs with `kubectl_logs`\n  - Manage kubectl contexts with `kubectl_context`\n  - Explain Kubernetes resources with `explain_resource`\n  - List API resources with `list_api_resources`\n  - Scale resources with `kubectl_scale`\n  - Update field(s) of a resource with `kubectl_patch`\n  - Manage deployment rollouts with `kubectl_rollout`\n  - Execute any kubectl command with `kubectl_generic`\n  - Verify connection with `ping`\n- [x] Advanced operations\n  - Scale deployments with `kubectl_scale` (replaces legacy `scale_deployment`)\n  - Port forward to pods and services with `port_forward`\n  - Run Helm operations\n    - Install, upgrade, and uninstall charts\n    - Support for custom values, repositories, and versions\n    - Template-based installation (`helm_template_apply`) to bypass authentication issues\n    - Template-based uninstallation (`helm_template_uninstall`) to bypass authentication issues\n  - Pod cleanup operations\n    - Clean up problematic pods (`cleanup_pods`) in states: Evicted, ContainerStatusUnknown, Completed, Error, ImagePullBackOff, CrashLoopBackOff\n  - Node management operations\n    - Cordoning, draining, and uncordoning nodes (`node_management`) for maintenance and scaling operations\n- [x] Troubleshooting Prompt (`k8s-diagnose`)\n  - Guides through a systematic Kubernetes troubleshooting flow for pods based on a keyword and optional namespace.\n- [x] Non-destructive mode for read and create/update-only access to clusters\n- [x] Secrets masking for security (masks sensitive data in `kubectl get secrets` commands, does not affect logs)\n\n## Prompts\n\nThe MCP Kubernetes server includes specialized prompts to assist with common diagnostic operations.\n\n### /k8s-diagnose Prompt\n\nThis prompt provides a systematic troubleshooting flow for Kubernetes pods. It accepts a `keyword` to identify relevant pods and an optional `namespace` to narrow the search.\nThe prompt's output will guide you through an autonomous troubleshooting flow, providing instructions for identifying issues, collecting evidence, and suggesting remediation steps.\n\n## Local Development\n\nMake sure that you have [bun installed](https://bun.sh/docs/installation). Clone the repo & install dependencies:\n\n```bash\ngit clone https://github.com/Flux159/mcp-server-kubernetes.git\ncd mcp-server-kubernetes\nbun install\n```\n\n### Development Workflow\n\n1. Start the server in development mode (watches for file changes):\n\n```bash\nbun run dev\n```\n\n2. Run unit tests:\n\n```bash\nbun run test\n```\n\n3. Build the project:\n\n```bash\nbun run build\n```\n\n4. Local Testing with [Inspector](https://github.com/modelcontextprotocol/inspector)\n\n```bash\nnpx @modelcontextprotocol/inspector node dist/index.js\n# Follow further instructions on terminal for Inspector link\n```\n\n5. Local testing with Claude Desktop\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-server-kubernetes\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/your/mcp-server-kubernetes/dist/index.js\"]\n    }\n  }\n}\n```\n\n6. Local testing with [mcp-chat](https://github.com/Flux159/mcp-chat)\n\n```bash\nbun run chat\n```\n\n## Contributing\n\nSee the [CONTRIBUTING.md](CONTRIBUTING.md) file for details.\n\n## Advanced\n\n### Non-Destructive Mode\n\nYou can run the server in a non-destructive mode that disables all destructive operations (delete pods, delete deployments, delete namespaces, etc.):\n\n```shell\nALLOW_ONLY_NON_DESTRUCTIVE_TOOLS=true npx mcp-server-kubernetes\n```\n\nFor Claude Desktop configuration with non-destructive mode:\n\n```json\n{\n  \"mcpServers\": {\n    \"kubernetes-readonly\": {\n      \"command\": \"npx\",\n      \"args\": [\"mcp-server-kubernetes\"],\n      \"env\": {\n        \"ALLOW_ONLY_NON_DESTRUCTIVE_TOOLS\": \"true\"\n      }\n    }\n  }\n}\n```\n\n### Commands Available in Non-Destructive Mode\n\nAll read-only and resource creation/update operations remain available:\n\n- Resource Information: `kubectl_get`, `kubectl_describe`, `kubectl_logs`, `explain_resource`, `list_api_resources`\n- Resource Creation/Modification: `kubectl_apply`, `kubectl_create`, `kubectl_scale`, `kubectl_patch`, `kubectl_rollout`\n- Helm Operations: `install_helm_chart`, `upgrade_helm_chart`, `helm_template_apply`, `helm_template_uninstall`\n- Connectivity: `port_forward`, `stop_port_forward`\n- Context Management: `kubectl_context`\n\n### Commands Disabled in Non-Destructive Mode\n\nThe following destructive operations are disabled:\n\n- `kubectl_delete`: Deleting any Kubernetes resources\n- `uninstall_helm_chart`: Uninstalling Helm charts\n- `cleanup`: Cleanup of managed resources\n- `cleanup_pods`: Cleaning up problematic pods\n- `node_management`: Node management operations (can drain nodes)\n- `kubectl_generic`: General kubectl command access (may include destructive operations)\n\nFor additional advanced features, see the [ADVANCED_README.md](ADVANCED_README.md) and also the [docs](https://github.com/Flux159/mcp-server-kubernetes/tree/main/docs) folder for specific information on `helm_install`, `helm_template_apply`, node management & pod cleanup.\n\n## Architecture\n\nSee this [DeepWiki link](https://deepwiki.com/Flux159/mcp-server-kubernetes) for a more indepth architecture overview created by Devin.\n\nThis section describes the high-level architecture of the MCP Kubernetes server.\n\n### Request Flow\n\nThe sequence diagram below illustrates how requests flow through the system:\n\n```mermaid\nsequenceDiagram\n    participant Client\n    participant Transport as Transport Layer\n    participant Server as MCP Server\n    participant Filter as Tool Filter\n    participant Handler as Request Handler\n    participant K8sManager as KubernetesManager\n    participant K8s as Kubernetes API\n\n    Note over Transport: StdioTransport or<br>SSE Transport\n\n    Client->>Transport: Send Request\n    Transport->>Server: Forward Request\n\n    alt Tools Request\n        Server->>Filter: Filter available tools\n        Note over Filter: Remove destructive tools<br>if in non-destructive mode\n        Filter->>Handler: Route to tools handler\n\n        alt kubectl operations\n            Handler->>K8sManager: Execute kubectl operation\n            K8sManager->>K8s: Make API call\n        else Helm operations\n            Handler->>K8sManager: Execute Helm operation\n            K8sManager->>K8s: Make API call\n        else Port Forward operations\n            Handler->>K8sManager: Set up port forwarding\n            K8sManager->>K8s: Make API call\n        end\n\n        K8s-->>K8sManager: Return result\n        K8sManager-->>Handler: Process response\n        Handler-->>Server: Return tool result\n    else Resource Request\n        Server->>Handler: Route to resource handler\n        Handler->>K8sManager: Get resource data\n        K8sManager->>K8s: Query API\n        K8s-->>K8sManager: Return data\n        K8sManager-->>Handler: Format response\n        Handler-->>Server: Return resource data\n    end\n\n    Server-->>Transport: Send Response\n    Transport-->>Client: Return Final Response\n```\n\nSee this [DeepWiki link](https://deepwiki.com/Flux159/mcp-server-kubernetes) for a more indepth architecture overview created by Devin.\n\n## Publishing new release\n\nGo to the [releases page](https://github.com/Flux159/mcp-server-kubernetes/releases), click on \"Draft New Release\", click \"Choose a tag\" and create a new tag by typing out a new version number using \"v{major}.{minor}.{patch}\" semver format. Then, write a release title \"Release v{major}.{minor}.{patch}\" and description / changelog if necessary and click \"Publish Release\".\n\nThis will create a new tag which will trigger a new release build via the cd.yml workflow. Once successful, the new release will be published to [npm](https://www.npmjs.com/package/mcp-server-kubernetes). Note that there is no need to update the package.json version manually, as the workflow will automatically update the version number in the package.json file & push a commit to main.\n\n## Not planned\n\nAdding clusters to kubectx.\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=Flux159/mcp-server-kubernetes&type=Date)](https://www.star-history.com/#Flux159/mcp-server-kubernetes&Date)\n\n## 🖊️ Cite\n\nIf you find this repo useful, please cite:\n\n```\n@software{Patel_MCP_Server_Kubernetes_2024,\nauthor = {Patel, Paras and Sonwalkar, Suyog},\nmonth = jul,\ntitle = {{MCP Server Kubernetes}},\nurl = {https://github.com/Flux159/mcp-server-kubernetes},\nversion = {2.5.0},\nyear = {2024}\n}\n```\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "kubernetes",
        "kubectl",
        "devops",
        "kubernetes clusters",
        "server kubernetes",
        "interact kubernetes"
      ],
      "category": "devops-and-cicd"
    },
    "PatrickKalkman--encoding-devops": {
      "owner": "PatrickKalkman",
      "name": "encoding-devops",
      "url": "https://github.com/PatrickKalkman/encoding-devops",
      "imageUrl": "/freedevtools/mcp/pfp/PatrickKalkman.webp",
      "description": "Streamlines video encoding workflows using AI for real-time analysis, error translation, and automated email drafts for issue management. Provides continuous monitoring of encoding jobs to ensure efficient operations.",
      "stars": 1,
      "forks": 4,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-03-24T23:26:21Z",
      "readme_content": "# 🎬 Encoding DevOps MCP Server: AI-Powered Video Encoding Assistant\n\n[![GitHub stars](https://img.shields.io/github/stars/PatrickKalkman/encoding-devops)](https://github.com/PatrickKalkman/encoding-devops/stargazers)\n[![GitHub contributors](https://img.shields.io/github/contributors/PatrickKalkman/encoding-devops)](https://github.com/PatrickKalkman/encoding-devops/graphs/contributors)\n[![GitHub last commit](https://img.shields.io/github/last-commit/PatrickKalkman/encoding-devops)](https://github.com/PatrickKalkman/encoding-devops)\n[![open issues](https://img.shields.io/github/issues/PatrickKalkman/encoding-devops)](https://github.com/PatrickKalkman/encoding-devops/issues)\n[![Python Version](https://img.shields.io/badge/python-3.9%2B-blue)](https://www.python.org/downloads/)\n[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](https://makeapullrequest.com)\n\nEver been woken up at 3 AM by a failed encoding job? Say goodbye to those late-night troubleshooting sessions! This Model Context Protocol (MCP) server connects Anthropic's Claude directly to your encoding workflow, making video encoding issues a breeze to handle.\n\n## ✨ What's Cool About This?\n\n- **Smart Error Translation**: Turns cryptic \"moov atom not found\" messages into plain English\n- **Real-time Analysis**: Connects directly to your encoding workflow and database\n- **Human-Friendly Responses**: Generates clear, actionable solutions for your team\n- **Auto-Email Draft**: Creates professional client communications with context\n- **Always On Guard**: Monitors your encoding jobs 24/7\n- **Keeps You in Control**: Suggests actions but lets you make the final call\n\n## 🚀 Getting Started\n\n### You'll Need\n\n- Python 3.11 or higher\n- Claude Desktop\n- Your encoding workflow API credentials\n- OMDB API key (optional, for movie metadata)\n\n### Quick Setup\n\n1. **Install the package using UV**:\n```bash\ncurl -LsSf https://astral.sh/uv/install.sh | sh\nuv pip install encoding-devops\n```\n\n2. **Set up your environment**:\n```bash\n# Copy the example config\ncp .env.example .env\n\n# Add your API keys\nnano .env\n```\n\n3. **Register with Claude Desktop**:\n```bash\nuv run mcp install ./src/encoding_devops/main.py\n```\n\n## 💡 How to Use It\n\n```bash\n# Start the MCP server\nuv run mcp dev ./src/encoding_devops/main.py\n\n# In Claude Desktop, you can now ask things like:\n\"What's wrong with job XYZ-123?\"\n\"Draft an email about the failed encoding job\"\n\"Check the encoding cluster status\"\n```\n\n## 🔧 Under the Hood\n\nThe MCP server uses three main components to help you:\n\n1. **Resources**: Email templates, error guides, and documentation\n2. **Tools**: Job status checks, log analysis, and email drafting\n3. **Prompts**: Instructions that help Claude understand encoding issues\n\n## 🤝 Want to Help?\n\nWe'd love your input! Here's how you can contribute:\n\n1. Fork it\n2. Create your feature branch (`git checkout -b feature/awesome-feature`)\n3. Commit your changes (`git commit -m 'Add awesome feature'`)\n4. Push to the branch (`git push origin feature/awesome-feature`)\n5. Open a Pull Request\n\n## 📋 Coming Soon\n\n- Integration with more encoding workflow systems\n- Advanced log analysis patterns\n- Automated health checks\n- Slack notifications\n- Custom email templates\n\n## 📝 License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## 🙌 Thanks To\n\n- Anthropic team for the MCP framework\n- All our contributors\n- The DevOps community for feedback and suggestions\n\n---\n\n💤 Built by a developer who wanted to sleep through the night. If this helps you too, give us a star!\n\n*Read the full story behind this project in my [Medium article about using MCP to handle encoding fires](https://medium.com/p/dedab6dc182b).*",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "devops",
        "encoding",
        "workflows",
        "encoding devops",
        "encoding workflows",
        "devops streamlines"
      ],
      "category": "devops-and-cicd"
    },
    "ProgrammerAgua--jenkins-mcp-server": {
      "owner": "ProgrammerAgua",
      "name": "jenkins-mcp-server",
      "url": "https://github.com/ProgrammerAgua/jenkins-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/ProgrammerAgua.webp",
      "description": "Manage Jenkins jobs through a unified API interface, facilitating job creation, triggering builds, retrieving job information, and updating configurations.",
      "stars": 0,
      "forks": 3,
      "license": "Apache License 2.0",
      "language": "Java",
      "updated_at": "2025-04-09T02:51:56Z",
      "readme_content": "English | [中文](README.zh-CN.md)\n# Jenkins API MCP Server\n\nThis is a MCP Server service based on Spring AI for Jenkins Rest API calls, providing common operation interfaces for Jenkins jobs.\n\n## Features\n\n- Job Management: Create, delete, enable/disable, rename jobs\n- Job Building: Trigger builds, build with parameters, stop builds\n- Job Information: Get job info, build info, build logs\n- Job Configuration: Get and update job configurations\n\n## Technology Stack\n\n- Spring Boot 3.3.6\n- Jenkins REST API Client\n- Spring AI MCP Server\n\n## Quick Start\n\n### Requirements\n\n- JDK 17+\n- Maven 3.6+\n- Jenkins server (with \"Remote Access API\" enabled)\n\n### Build Project\n\nClone the repository and navigate to the project directory:\n\n```bash\ngit clone [repository-url]\ncd jenkins-mcp-server\n```\n\nBefore running the project, you need to package it using Maven:\n\n```bash\nmvn package\n```\nAfter a successful build, a file named `mcp-jenkins-server-0.0.1-SNAPSHOT.jar` will be generated in the `/target` directory. Use the full path to this file in your `mcp.json` configuration:\n\n```bash\n{your_path}\\\\mcp-jenkins-server-0.0.1-SNAPSHOT.jar\n ```\n\n### mcp.json Configuration\n```yaml\n{\n  \"mcpServers\": {\n    \"jenkins-mcp\": {\n      \"command\": \"java\",\n      \"args\": [\n        \"-jar\",\n        \"{your_path}\\\\mcp-jenkins-server-0.0.1-SNAPSHOT.jar\"\n      ],\n      \"env\": {\n        \"JENKINS_API_SERVER_URI\": \"jenkins-uri\",\n        \"JENKINS_API_USERNAME\": \"username\", \n        \"JENKINS_API_TOKEN\": \"password/token\"\n      }\n    }\n  }\n}\n```\n\n## API Documentation\n### Job Management\n- createJob : Create a new Jenkins job\n- deleteJob : Delete an existing Jenkins job\n- enableJob : Enable a disabled Jenkins job\n- disableJob : Disable an enabled Jenkins job\n- renameJob : Rename an existing Jenkins job\n### Job Building\n- buildJob : Trigger a build for a Jenkins job\n- buildJobWithParams : Trigger a build with parameters\n- killJob : Stop a running build\n### Job Information\n- getJobInfo : Get detailed information about a job\n- getBuildInfo : Get information about a specific build\n- getBuildLog : Get the console output of a build\n- getLastBuildNumber : Get the last build number\n- getLastBuildTimestamp : Get the timestamp of the last build\n### Job Configuration\n- getJobConfig : Get the configuration XML of a job\n- updateJobConfig : Update the configuration of a job",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "devops",
        "jenkins",
        "mcp",
        "devops cicd",
        "manage jenkins",
        "jenkins jobs"
      ],
      "category": "devops-and-cicd"
    },
    "QAInsights--k6-mcp-server": {
      "owner": "QAInsights",
      "name": "k6-mcp-server",
      "url": "https://github.com/QAInsights/k6-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/QAInsights.webp",
      "description": "Run load tests using k6 with custom configurations and obtain real-time execution output. Integrates with the Model Context Protocol to streamline load testing processes and enhance performance insights.",
      "stars": 15,
      "forks": 8,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-11T16:28:07Z",
      "readme_content": "# 🚀 ⚡️ k6-mcp-server\n\nA Model Context Protocol (MCP) server implementation for running k6 load tests.\n\n## ✨ Features\n\n- Simple integration with Model Context Protocol framework\n- Support for custom test durations and virtual users (VUs)\n- Easy-to-use API for running k6 load tests\n- Configurable through environment variables\n- Real-time test execution output\n\n## 🔧 Prerequisites\n\nBefore you begin, ensure you have the following installed:\n\n- Python 3.12 or higher\n- k6 load testing tool ([Installation guide](https://grafana.com/docs/k6/latest/set-up/install-k6/))\n- uv package manager ([Installation guide](https://github.com/astral-sh/uv))\n\n## 📦 Installation\n\n1. Clone the repository:\n\n```bash\ngit clone https://github.com/qainsights/k6-mcp-server.git\n```\n\n2. Install the required dependencies:\n\n```bash\nuv pip install -r requirements.txt\n```\n\n3. Set up environment variables (optional):\n   Create a `.env` file in the project root:\n\n```bash\nK6_BIN=/path/to/k6  # Optional: defaults to 'k6' in system PATH\n```\n\n## 🚀 Getting Started\n\n1. Create a k6 test script (e.g., `test.js`):\n\n```javascript\nimport http from \"k6/http\";\nimport { sleep } from \"k6\";\n\nexport default function () {\n  http.get(\"http://test.k6.io\");\n  sleep(1);\n}\n```\n\n2. Configure the MCP server using the below specs in your favorite MCP client (Claude Desktop, Cursor, Windsurf and more):\n\n```json\n{\n  \"mcpServers\": {\n    \"k6\": {\n      \"command\": \"/path/to/bin/uv\",\n      \"args\": [\n        \"--directory\",\n        \"/path/to/k6-mcp-server\",\n        \"run\",\n        \"k6_server.py\"\n      ]\n    }\n  }\n}\n\n```\n3. Now ask the LLM to run the test e.g. `run k6 test for hello.js`. The k6 mcp server will leverage either one of the below tools to start the test.\n\n- `execute_k6_test`: Run a test with default options (30s duration, 10 VUs)\n- `execute_k6_test_with_options`: Run a test with custom duration and VUs\n\n\n\n\n## 📝 API Reference\n\n### Execute K6 Test\n\n```python\nexecute_k6_test(\n    script_file: str,\n    duration: str = \"30s\",  # Optional\n    vus: int = 10          # Optional\n)\n```\n\n### Execute K6 Test with Custom Options\n\n```python\nexecute_k6_test_with_options(\n    script_file: str,\n    duration: str,\n    vus: int\n)\n```\n\n## ✨ Use cases\n\n- LLM powered results analysis\n- Effective debugging of load tests\n\n## 🤝 Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## 📄 License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "devops",
        "k6",
        "testing",
        "load testing",
        "load tests",
        "devops cicd"
      ],
      "category": "devops-and-cicd"
    },
    "Shengwenhao-manbo--k8s-mcp": {
      "owner": "Shengwenhao-manbo",
      "name": "k8s-mcp",
      "url": "https://github.com/Shengwenhao-manbo/k8s-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/Shengwenhao-manbo.webp",
      "description": "Manage and interact with Kubernetes clusters through a Model Context Protocol server utilizing SSE transport for API calls. Simplifies Kubernetes operations integration into LLM applications with secure management capabilities.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-04-18T02:10:33Z",
      "readme_content": "# k8s-mcp\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "kubernetes",
        "devops",
        "k8s",
        "kubernetes operations",
        "interact kubernetes",
        "simplifies kubernetes"
      ],
      "category": "devops-and-cicd"
    },
    "TBXark--mcp-proxy": {
      "owner": "TBXark",
      "name": "mcp-proxy",
      "url": "https://github.com/TBXark/mcp-proxy",
      "imageUrl": "/freedevtools/mcp/pfp/TBXark.webp",
      "description": "Aggregates multiple MCP resource servers through a single HTTP endpoint, enabling unified access to various MCP clients. Supports real-time updates with SSE and offers flexible configuration options for different client types.",
      "stars": 548,
      "forks": 69,
      "license": "MIT License",
      "language": "Go",
      "updated_at": "2025-10-03T08:57:06Z",
      "readme_content": "# MCP Proxy Server\n\nAn MCP proxy that aggregates multiple MCP servers behind a single HTTP entrypoint.\n\n## Features\n\n- Proxy multiple MCP clients: aggregate tools, prompts, and resources from many servers.\n- SSE and streamable HTTP: serve via Server‑Sent Events or streamable HTTP.\n- Flexible config: supports `stdio`, `sse`, and `streamable-http` client types.\n\n## Documentation\n\n- Configuration: [docs/configuration.md](docs/CONFIGURATION.md)\n- Usage: [docs/usage.md](docs/USAGE.md)\n- Deployment: [docs/deployment.md](docs/DEPLOYMENT.md)\n- Claude config converter: https://tbxark.github.io/mcp-proxy\n\n## Quick Start\n\n### Build from source\n\n```bash\ngit clone https://github.com/TBXark/mcp-proxy.git\ncd mcp-proxy\nmake build\n./build/mcp-proxy --config path/to/config.json\n```\n\n### Install via Go\n\n```bash\ngo install github.com/TBXark/mcp-proxy@latest\n```\n\n### Docker\n\nThe image includes support for launching MCP servers via `npx` and `uvx`.\n\n```bash\ndocker run -d -p 9090:9090 -v /path/to/config.json:/config/config.json ghcr.io/tbxark/mcp-proxy:latest\n# or provide a remote config\ndocker run -d -p 9090:9090 ghcr.io/tbxark/mcp-proxy:latest --config https://example.com/config.json\n```\n\nMore deployment options (including docker‑compose) are in [docs/deployment.md](docs/DEPLOYMENT.md).\n\n## Configuration\n\nSee full configuration reference and examples in [docs/configuration.md](docs/CONFIGURATION.md).\nAn online Claude config converter is available at: https://tbxark.github.io/mcp-proxy\n\n\n## Usage\n\nCommand‑line flags, endpoints, and auth examples are documented in [docs/usage.md](docs/USAGE.md).\n\n## Thanks\n\n- This project was inspired by the [adamwattis/mcp-proxy-server](https://github.com/adamwattis/mcp-proxy-server) project\n- If you have any questions about deployment, you can refer to  [《在 Docker 沙箱中运行 MCP Server》](https://miantiao.me/posts/guide-to-running-mcp-server-in-a-sandbox/)([@ccbikai](https://github.com/ccbikai))\n\n## License\n\nThis project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "devops",
        "mcp",
        "tbxark",
        "mcp proxy",
        "devops cicd",
        "mcp clients"
      ],
      "category": "devops-and-cicd"
    },
    "TaichiHo--k8s-interactive-mcp": {
      "owner": "TaichiHo",
      "name": "k8s-interactive-mcp",
      "url": "https://github.com/TaichiHo/k8s-interactive-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/TaichiHo.webp",
      "description": "Run Kubernetes commands using a specified kubeconfig path and provide interpretations of those commands. This server supports custom kubeconfig paths, automatic kubectl installation checks, and includes error handling features.",
      "stars": 4,
      "forks": 4,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-07-04T07:37:07Z",
      "readme_content": "# k8s-interactive-mcp\n\nA MCP server that can run Kubernetes commands with a given kubeconfig path and provide interpretation of the commands.\n\n<a href=\"https://glama.ai/mcp/servers/gwvs0s78be\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/gwvs0s78be/badge\" alt=\"k8s-interactive-mcp MCP server\" /></a>\n\n## Result\n\n\n\n## Features\n\n- Run kubectl commands through MCP tools\n- Flexible command line piping\n- Automatic kubectl installation check\n- Support for custom kubeconfig paths\n- Error handling and helpful messages\n\n## Usage\n\n1. Install dependencies:\n```bash\nnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n```bash\nnpm run watch\n```\n\n## Installation\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"k8s-interactive\": {\n      \"command\": \"/path/to/k8s-interactive/build/index.js\"\n    }\n  }\n}\n```\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "kubeconfig",
        "kubernetes",
        "kubectl",
        "kubernetes commands",
        "run kubernetes",
        "kubeconfig path"
      ],
      "category": "devops-and-cicd"
    },
    "Tiberriver256--mcp-server-azure-devops": {
      "owner": "Tiberriver256",
      "name": "mcp-server-azure-devops",
      "url": "https://github.com/Tiberriver256/mcp-server-azure-devops",
      "imageUrl": "/freedevtools/mcp/pfp/Tiberriver256.webp",
      "description": "Interact with Azure DevOps APIs to manage projects, work items, and repositories using natural language commands. Facilitate secure execution of common DevOps workflows and access repository content through standardized URIs.",
      "stars": 298,
      "forks": 88,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-30T12:06:23Z",
      "readme_content": "# ℹ️ DISCUSSION: [Microsoft launched an official ADO MCP Server! 🎉🎉🎉](https://github.com/Tiberriver256/mcp-server-azure-devops/discussions/237)\n\n# Azure DevOps MCP Server\n\nA Model Context Protocol (MCP) server implementation for Azure DevOps, allowing AI assistants to interact with Azure DevOps APIs through a standardized protocol.\n\n## Overview\n\nThis server implements the [Model Context Protocol (MCP)](https://modelcontextprotocol.io/) for Azure DevOps, enabling AI assistants like Claude to interact with Azure DevOps resources securely. The server acts as a bridge between AI models and Azure DevOps APIs, providing a standardized way to:\n\n- Access and manage projects, work items, repositories, and more\n- Create and update work items, branches, and pull requests\n- Execute common DevOps workflows through natural language\n- Access repository content via standardized resource URIs\n- Safely authenticate and interact with Azure DevOps resources\n\n## Server Structure\n\nThe server is structured around the Model Context Protocol (MCP) for communicating with AI assistants. It provides tools for interacting with Azure DevOps resources including:\n\n- Projects\n- Work Items\n- Repositories\n- Pull Requests\n- Branches\n- Pipelines\n\n### Core Components\n\n- **AzureDevOpsServer**: Main server class that initializes the MCP server and registers tools\n- **Feature Modules**: Organized by feature area (work-items, projects, repositories, etc.)\n- **Request Handlers**: Each feature module provides request identification and handling functions\n- **Tool Handlers**: Modular functions for each Azure DevOps operation\n- **Configuration**: Environment-based configuration for organization URL, PAT, etc.\n\nThe server uses a feature-based architecture where each feature area (like work-items, projects, repositories) is encapsulated in its own module. This makes the codebase more maintainable and easier to extend with new features.\n\n## Getting Started\n\n### Prerequisites\n\n- Node.js (v16+)\n- npm or yarn\n- Azure DevOps account with appropriate access\n- Authentication credentials (see [Authentication Guide](docs/authentication.md) for details):\n  - Personal Access Token (PAT), or\n  - Azure Identity credentials, or\n  - Azure CLI login\n\n### Running with NPX\n\n### Usage with Claude Desktop/Cursor AI\n\nTo integrate with Claude Desktop or Cursor AI, add one of the following configurations to your configuration file.\n\n#### Azure Identity Authentication\n\nBe sure you are logged in to Azure CLI with `az login` then add the following:\n\n```json\n{\n  \"mcpServers\": {\n    \"azureDevOps\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@tiberriver256/mcp-server-azure-devops\"],\n      \"env\": {\n        \"AZURE_DEVOPS_ORG_URL\": \"https://dev.azure.com/your-organization\",\n        \"AZURE_DEVOPS_AUTH_METHOD\": \"azure-identity\",\n        \"AZURE_DEVOPS_DEFAULT_PROJECT\": \"your-project-name\"\n      }\n    }\n  }\n}\n```\n\n#### Personal Access Token (PAT) Authentication\n\n```json\n{\n  \"mcpServers\": {\n    \"azureDevOps\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@tiberriver256/mcp-server-azure-devops\"],\n      \"env\": {\n        \"AZURE_DEVOPS_ORG_URL\": \"https://dev.azure.com/your-organization\",\n        \"AZURE_DEVOPS_AUTH_METHOD\": \"pat\",\n        \"AZURE_DEVOPS_PAT\": \"<YOUR_PAT>\",\n        \"AZURE_DEVOPS_DEFAULT_PROJECT\": \"your-project-name\"\n      }\n    }\n  }\n}\n```\n\nFor detailed configuration instructions and more authentication options, see the [Authentication Guide](docs/authentication.md).\n\n## Authentication Methods\n\nThis server supports multiple authentication methods for connecting to Azure DevOps APIs. For detailed setup instructions, configuration examples, and troubleshooting tips, see the [Authentication Guide](docs/authentication.md).\n\n### Supported Authentication Methods\n\n1. **Personal Access Token (PAT)** - Simple token-based authentication\n2. **Azure Identity (DefaultAzureCredential)** - Flexible authentication using the Azure Identity SDK\n3. **Azure CLI** - Authentication using your Azure CLI login\n\nExample configuration files for each authentication method are available in the [examples directory](docs/examples/).\n\n## Environment Variables\n\nFor a complete list of environment variables and their descriptions, see the [Authentication Guide](docs/authentication.md#configuration-reference).\n\nKey environment variables include:\n\n| Variable                       | Description                                                                        | Required                     | Default          |\n| ------------------------------ | ---------------------------------------------------------------------------------- | ---------------------------- | ---------------- |\n| `AZURE_DEVOPS_AUTH_METHOD`     | Authentication method (`pat`, `azure-identity`, or `azure-cli`) - case-insensitive | No                           | `azure-identity` |\n| `AZURE_DEVOPS_ORG_URL`         | Full URL to your Azure DevOps organization                                         | Yes                          | -                |\n| `AZURE_DEVOPS_PAT`             | Personal Access Token (for PAT auth)                                               | Only with PAT auth           | -                |\n| `AZURE_DEVOPS_DEFAULT_PROJECT` | Default project if none specified                                                  | No                           | -                |\n| `AZURE_DEVOPS_API_VERSION`     | API version to use                                                                 | No                           | Latest           |\n| `AZURE_TENANT_ID`              | Azure AD tenant ID (for service principals)                                        | Only with service principals | -                |\n| `AZURE_CLIENT_ID`              | Azure AD application ID (for service principals)                                   | Only with service principals | -                |\n| `AZURE_CLIENT_SECRET`          | Azure AD client secret (for service principals)                                    | Only with service principals | -                |\n| `LOG_LEVEL`                    | Logging level (debug, info, warn, error)                                           | No                           | info             |\n\n## Troubleshooting Authentication\n\nFor detailed troubleshooting information for each authentication method, see the [Authentication Guide](docs/authentication.md#troubleshooting-authentication-issues).\n\nCommon issues include:\n\n- Invalid or expired credentials\n- Insufficient permissions\n- Network connectivity problems\n- Configuration errors\n\n## Authentication Implementation Details\n\nFor technical details about how authentication is implemented in the Azure DevOps MCP server, see the [Authentication Guide](docs/authentication.md) and the source code in the `src/auth` directory.\n\n## Available Tools\n\nThe Azure DevOps MCP server provides a variety of tools for interacting with Azure DevOps resources. For detailed documentation on each tool, please refer to the corresponding documentation.\n\n### User Tools\n\n- `get_me`: Get details of the authenticated user (id, displayName, email)\n\n### Organization Tools\n\n- `list_organizations`: List all accessible organizations\n\n### Project Tools\n\n- `list_projects`: List all projects in an organization\n- `get_project`: Get details of a specific project\n- `get_project_details`: Get comprehensive details of a project including process, work item types, and teams\n\n### Repository Tools\n\n- `list_repositories`: List all repositories in a project\n- `get_repository`: Get details of a specific repository\n- `get_repository_details`: Get detailed information about a repository including statistics and refs\n- `get_file_content`: Get content of a file or directory from a repository\n\n### Work Item Tools\n\n- `get_work_item`: Retrieve a work item by ID\n- `create_work_item`: Create a new work item\n- `update_work_item`: Update an existing work item\n- `list_work_items`: List work items in a project\n- `manage_work_item_link`: Add, remove, or update links between work items\n\n### Search Tools\n\n- `search_code`: Search for code across repositories in a project\n- `search_wiki`: Search for content across wiki pages in a project\n- `search_work_items`: Search for work items across projects in Azure DevOps\n\n### Pipelines Tools\n\n- `list_pipelines`: List pipelines in a project\n- `get_pipeline`: Get details of a specific pipeline\n- `trigger_pipeline`: Trigger a pipeline run with customizable parameters\n\n### Wiki Tools\n\n- `get_wikis`: List all wikis in a project\n- `get_wiki_page`: Get content of a specific wiki page as plain text\n\n### Pull Request Tools\n\n- [`create_pull_request`](docs/tools/pull-requests.md#create_pull_request) - Create a new pull request\n- [`list_pull_requests`](docs/tools/pull-requests.md#list_pull_requests) - List pull requests in a repository\n- [`add_pull_request_comment`](docs/tools/pull-requests.md#add_pull_request_comment) - Add a comment to a pull request\n- [`get_pull_request_comments`](docs/tools/pull-requests.md#get_pull_request_comments) - Get comments from a pull request\n- [`update_pull_request`](docs/tools/pull-requests.md#update_pull_request) - Update an existing pull request (title, description, status, draft state, reviewers, work items)\n\nFor comprehensive documentation on all tools, see the [Tools Documentation](docs/tools/).\n\n## Contributing\n\nContributions are welcome! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for contribution guidelines.\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=tiberriver256/mcp-server-azure-devops&type=Date)](https://www.star-history.com/#tiberriver256/mcp-server-azure-devops&Date)\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "devops",
        "azure",
        "repositories",
        "azure devops",
        "devops cicd",
        "devops apis"
      ],
      "category": "devops-and-cicd"
    },
    "Tsuchijo--sandbox-mcp": {
      "owner": "Tsuchijo",
      "name": "sandbox-mcp",
      "url": "https://github.com/Tsuchijo/sandbox-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/Tsuchijo.webp",
      "description": "Isolated Docker environments for executing code in various programming languages, managing package installations, and running commands within containers.",
      "stars": 11,
      "forks": 4,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-08-08T02:58:03Z",
      "readme_content": "# Sandbox MCP Server\n\nAn MCP server that provides isolated Docker environments for code execution. This server allows you to:\n- Create containers with any Docker image\n- Write and execute code in multiple programming languages\n- Install packages and set up development environments\n- Run commands in isolated containers\n\n## Prerequisites\n\n- Python 3.9 or higher\n- Docker installed and running\n- uv package manager (recommended)\n- Docker MCP server (recommended)\n\n## Installation\n\n1. Clone this repository:\n```bash\ngit clone <your-repo-url>\ncd sandbox_server\n```\n\n2. Create and activate a virtual environment with uv:\n```bash\nuv venv\nsource .venv/bin/activate  # On Unix/MacOS\n# Or on Windows:\n# .venv\\Scripts\\activate\n```\n\n3. Install dependencies:\n```bash\nuv pip install .\n```\n\n## Integration with Claude Desktop\n\n1. Open Claude Desktop's configuration file:\n- macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n- Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n\n2. Add the sandbox server configuration:\n```json\n{\n    \"mcpServers\": {\n        \"sandbox\": {\n            \"command\": \"uv\",\n            \"args\": [\n                \"--directory\",\n                \"/absolute/path/to/sandbox_server\",\n                \"run\",\n                \"sandbox_server.py\"\n            ],\n            \"env\": {\n                \"PYTHONPATH\": \"/absolute/path/to/sandbox_server\"\n            }\n        }\n    }\n}\n```\n\nReplace `/absolute/path/to/sandbox_server` with the actual path to your project directory.\n\n3. Restart Claude Desktop\n\n## Usage Examples\n\n### Basic Usage\n\nOnce connected to Claude Desktop, you can:\n\n1. Create a Python container:\n```\nCould you create a Python container and write a simple hello world program?\n```\n\n2. Run code in different languages:\n```\nCould you create a C program that calculates the fibonacci sequence and run it?\n```\n\n3. Install packages and use them:\n```\nCould you create a Python script that uses numpy to generate and plot some random data?\n```\n\n### Saving and Reproducing Environments\n\nThe server provides several ways to save and reproduce your development environments:\n\n#### Creating Persistent Containers\n\nWhen creating a container, you can make it persistent:\n```\nCould you create a persistent Python container with numpy and pandas installed?\n```\n\nThis will create a container that:\n- Stays running after Claude Desktop closes\n- Can be accessed directly through Docker\n- Preserves all installed packages and files\n\nThe server will provide instructions for:\n- Accessing the container directly (`docker exec`)\n- Stopping and starting the container\n- Removing it when no longer needed\n\n#### Saving Container State\n\nAfter setting up your environment, you can save it as a Docker image:\n```\nCould you save the current container state as an image named 'my-ds-env:v1'?\n```\n\nThis will:\n1. Create a new Docker image with all your:\n   - Installed packages\n   - Created files\n   - Configuration changes\n2. Provide instructions for reusing the environment\n\nYou can then share this image or use it as a starting point for new containers:\n```\nCould you create a new container using the my-ds-env:v1 image?\n```\n\n#### Generating Dockerfiles\n\nTo make your environment fully reproducible, you can generate a Dockerfile:\n```\nCould you export a Dockerfile that recreates this environment?\n```\n\nThe generated Dockerfile will include:\n- Base image specification\n- Created files\n- Template for additional setup steps\n\nYou can use this Dockerfile to:\n1. Share your environment setup with others\n2. Version control your development environment\n3. Modify and customize the build process\n4. Deploy to different systems\n\n#### Recommended Workflow\n\nFor reproducible development environments:\n\n1. Create a persistent container:\n```\nCreate a persistent Python container for data science work\n```\n\n2. Install needed packages and set up the environment:\n```\nInstall numpy, pandas, and scikit-learn in the container\n```\n\n3. Test your setup:\n```\nCreate and run a test script to verify the environment\n```\n\n4. Save the state:\n```\nSave this container as 'ds-workspace:v1'\n```\n\n5. Export a Dockerfile:\n```\nGenerate a Dockerfile for this environment\n```\n\nThis gives you multiple options for recreating your environment:\n- Use the saved Docker image directly\n- Build from the Dockerfile with modifications\n- Access the original container if needed\n\n## Security Notes\n\n- All code executes in isolated Docker containers\n- Containers are automatically removed after use\n- File systems are isolated between containers\n- Host system access is restricted\n\n## Project Structure\n\n```\nsandbox_server/\n├── sandbox_server.py     # Main server implementation\n├── pyproject.toml        # Project configuration\n└── README.md            # This file\n```\n\n## Available Tools\n\nThe server provides three main tools:\n\n1. `create_container_environment`: Creates a new Docker container with specified image\n2. `create_file_in_container`: Creates a file in a container\n3. `execute_command_in_container`: Runs commands in a container\n4. `save_container_state`: Saves the container state to a persistent container\n5. `export_dockerfile`: exports a docker file to create a persistant environment\n6. `exit_container`: closes a container to cleanup environment when finished\n\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "docker",
        "devops",
        "containers",
        "docker environments",
        "isolated docker",
        "commands containers"
      ],
      "category": "devops-and-cicd"
    },
    "ZephyrDeng--pprof-analyzer-mcp": {
      "owner": "ZephyrDeng",
      "name": "pprof-analyzer-mcp",
      "url": "https://github.com/ZephyrDeng/pprof-analyzer-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/ZephyrDeng.webp",
      "description": "Analyze Go pprof performance profiles to identify bottlenecks and optimize applications by generating flame graphs and detailed reports for CPU and memory usage visualization.",
      "stars": 35,
      "forks": 4,
      "license": "MIT License",
      "language": "Go",
      "updated_at": "2025-09-29T12:29:00Z",
      "readme_content": "[简体中文](README_zh-CN.md) | English\n\n# Pprof Analyzer MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@ZephyrDeng/pprof-analyzer-mcp)](https://smithery.ai/server/@ZephyrDeng/pprof-analyzer-mcp)\n![](https://badge.mcpx.dev?type=server&features=tools 'MCP server with tools')\n[![Build Status](https://github.com/ZephyrDeng/pprof-analyzer-mcp/actions/workflows/release.yml/badge.svg)](https://github.com/ZephyrDeng/pprof-analyzer-mcp/actions)\n[![License](https://img.shields.io/badge/license-MIT-blue)]()\n[![Go Version](https://img.shields.io/github/go-mod/go-version/ZephyrDeng/pprof-analyzer-mcp)](https://golang.org)\n[![GoDoc](https://pkg.go.dev/badge/github.com/ZephyrDeng/pprof-analyzer-mcp)](https://pkg.go.dev/github.com/ZephyrDeng/pprof-analyzer-mcp)\n\nThis is a Model Context Protocol (MCP) server implemented in Go, providing a tool to analyze Go pprof performance profiles.\n\n## Features\n\n*   **`analyze_pprof` Tool:**\n    *   Analyzes the specified Go pprof file and returns serialized analysis results (e.g., Top N list or flame graph JSON).\n    *   Supported Profile Types:\n        *   `cpu`: Analyzes CPU time consumption during code execution to find hot spots.\n        *   `heap`: Analyzes the current memory usage (heap allocations) to find objects and functions with high memory consumption. Enhanced with object count, allocation site, and type information.\n        *   `goroutine`: Displays stack traces of all current goroutines, used for diagnosing deadlocks, leaks, or excessive goroutine usage.\n        *   `allocs`: Analyzes memory allocations (including freed ones) during program execution to locate code with frequent allocations. Provides detailed allocation site and object count information.\n        *   `mutex`: Analyzes contention on mutexes to find locks causing blocking. (*Not yet implemented*)\n        *   `block`: Analyzes operations causing goroutine blocking (e.g., channel waits, system calls). (*Not yet implemented*)\n    *   Supported Output Formats: `text`, `markdown`, `json` (Top N list), `flamegraph-json` (hierarchical flame graph data, default).\n        *   `text`, `markdown`: Human-readable text or Markdown format.\n        *   `json`: Outputs Top N results in structured JSON format (implemented for `cpu`, `heap`, `goroutine`, `allocs`).\n        *   `flamegraph-json`: Outputs hierarchical flame graph data in JSON format, compatible with d3-flame-graph (implemented for `cpu`, `heap`, `allocs`, default format). Output is compact.\n    *   Configurable number of Top N results (`top_n`, defaults to 5, effective for `text`, `markdown`, `json` formats).\n*   **`generate_flamegraph` Tool:**\n    *   Uses `go tool pprof` to generate a flame graph (SVG format) for the specified pprof file, saves it to the specified path, and returns the path and SVG content.\n    *   Supported Profile Types: `cpu`, `heap`, `allocs`, `goroutine`, `mutex`, `block`.\n    *   Requires the user to specify the output SVG file path.\n    *   **Important:** This feature depends on [Graphviz](#dependencies) being installed.\n*   **`open_interactive_pprof` Tool (macOS Only):**\n    *   Attempts to launch the `go tool pprof` interactive web UI in the background for the specified pprof file. Uses port `:8081` by default if `http_address` is not provided.\n    *   Returns the Process ID (PID) of the background `pprof` process upon successful launch.\n    *   **macOS Only:** This tool will only work on macOS.\n    *   **Dependencies:** Requires the `go` command to be available in the system's PATH.\n    *   **Limitations:** Errors from the background `pprof` process are not captured by the server. Temporary files downloaded from remote URLs are not automatically cleaned up until the process is terminated (either manually via `disconnect_pprof_session` or when the MCP server exits).\n*   **`detect_memory_leaks` Tool:**\n    *   Compares two heap profile snapshots to identify potential memory leaks.\n    *   Analyzes memory growth by object type and allocation site.\n    *   Provides detailed statistics on memory growth, including absolute and percentage changes.\n    *   Configurable growth threshold and result limit.\n    *   Helps identify memory leaks by comparing profiles taken at different points in time.\n*   **`disconnect_pprof_session` Tool:**\n    *   Attempts to terminate a background `pprof` process previously started by `open_interactive_pprof`, using its PID.\n    *   Sends an Interrupt signal first, then a Kill signal if Interrupt fails.\n\n## Installation (As a Library/Tool)\n\nYou can install this package directly using `go install`:\n\n```bash\ngo install github.com/ZephyrDeng/pprof-analyzer-mcp@latest\n```\nThis will install the `pprof-analyzer-mcp` executable to your `$GOPATH/bin` or `$HOME/go/bin` directory. Ensure this directory is in your system's PATH to run the command directly.\n\n## Building from Source\n\nEnsure you have a Go environment installed (Go 1.18 or higher recommended).\n\nIn the project root directory (`pprof-analyzer-mcp`), run:\n\n```bash\ngo build\n```\n\nThis will generate an executable file named `pprof-analyzer-mcp` (or `pprof-analyzer-mcp.exe` on Windows) in the current directory.\n\n### Using `go install` (Recommended)\n\nYou can also use `go install` to install the executable into your `$GOPATH/bin` or `$HOME/go/bin` directory. This allows you to run `pprof-analyzer-mcp` directly from the command line (if the directory is added to your system's PATH environment variable).\n\n```bash\n# Installs the executable using the module path defined in go.mod\ngo install .\n# Or directly using the GitHub path (recommended after publishing)\n# go install github.com/ZephyrDeng/pprof-analyzer-mcp@latest\n```\n\n## Running with Docker\n\nUsing Docker is a convenient way to run the server, as it bundles the necessary Graphviz dependency.\n\n1.  **Build the Docker Image:**\n    In the project root directory (where the `Dockerfile` is located), run:\n    ```bash\n    docker build -t pprof-analyzer-mcp .\n    ```\n\n2.  **Run the Docker Container:**\n    ```bash\n    docker run -i --rm pprof-analyzer-mcp\n    ```\n    *   The `-i` flag keeps STDIN open, which is required for the stdio transport used by this MCP server.\n    *   The `--rm` flag automatically removes the container when it exits.\n\n3.  **Configure MCP Client for Docker:**\n    To connect your MCP client (like Roo Cline) to the server running inside Docker, update your `.roo/mcp.json`:\n    ```json\n    {\n      \"mcpServers\": {\n        \"pprof-analyzer-docker\": {\n          \"command\": \"docker run -i --rm pprof-analyzer-mcp\"\n        }\n      }\n    }\n    ```\n    Make sure the `pprof-analyzer-mcp` image has been built locally before the client tries to run this command.\n\n\n## Releasing (Automated via GitHub Actions)\n\nThis project uses [GoReleaser](https://goreleaser.com/) and GitHub Actions to automate the release process. Releases are triggered automatically when a Git tag matching the pattern `v*` (e.g., `v0.1.0`, `v1.2.3`) is pushed to the repository.\n\n**Release Steps:**\n\n1.  **Make Changes:** Develop new features or fix bugs.\n2.  **Commit Changes:** Commit your changes using [Conventional Commits](https://www.conventionalcommits.org/) format (e.g., `feat: ...`, `fix: ...`). This is important for automatic changelog generation.\n    ```bash\n    git add .\n    git commit -m \"feat: Add awesome new feature\"\n    # or\n    git commit -m \"fix: Resolve issue #42\"\n    ```\n3.  **Push Changes:** Push your commits to the main branch on GitHub.\n    ```bash\n    git push origin main\n    ```\n4.  **Create and Push Tag:** When ready to release, create a new Git tag and push it to GitHub.\n    ```bash\n    # Example: Create tag v0.1.0\n    git tag v0.1.0\n\n    # Push the tag to GitHub\n    git push origin v0.1.0\n    ```\n5.  **Automatic Release:** Pushing the tag will trigger the `GoReleaser` GitHub Action defined in `.github/workflows/release.yml`. This action will:\n    *   Build binaries for Linux, macOS, and Windows (amd64 & arm64).\n    *   Generate a changelog based on Conventional Commits since the last tag.\n    *   Create a new GitHub Release with the changelog and attach the built binaries and checksums as assets.\n\nYou can view the release workflow progress in the \"Actions\" tab of the GitHub repository.\n\n## Configuring the MCP Client\n\nThis server uses the `stdio` transport protocol. You need to configure it in your MCP client (e.g., Roo Cline extension for VS Code).\n\nTypically, this involves adding the following configuration to the `.roo/mcp.json` file in your project root:\n\n```json\n{\n  \"mcpServers\": {\n    \"pprof-analyzer\": {\n      \"command\": \"pprof-analyzer-mcp\"\n    }\n  }\n}\n```\n\n**Note:** Adjust the `command` value based on your build method (`go build` or `go install`) and the actual location of the executable. Ensure the MCP client can find and execute this command.\n\nAfter configuration, reload or restart your MCP client, and it should automatically connect to the `PprofAnalyzer` server.\n\n## Dependencies\n\n*   **Graphviz**: The `generate_flamegraph` tool requires Graphviz to generate SVG flame graphs (the `go tool pprof` command calls `dot` when generating SVG). Ensure Graphviz is installed on your system and the `dot` command is available in your system's PATH environment variable.\n\n    **Installing Graphviz:**\n    *   **macOS (using Homebrew):**\n        ```bash\n        brew install graphviz\n        ```\n    *   **Debian/Ubuntu:**\n        ```bash\n        sudo apt-get update && sudo apt-get install graphviz\n        ```\n    *   **CentOS/Fedora:**\n        ```bash\n        sudo yum install graphviz\n        # or\n        sudo dnf install graphviz\n        ```\n    *   **Windows (using Chocolatey):**\n        ```bash\n        choco install graphviz\n        ```\n    *   **Other Systems:** Refer to the [Graphviz official download page](https://graphviz.org/download/).\n\n## Usage Examples (via MCP Client)\n\nOnce the server is connected, you can call the `analyze_pprof` and `generate_flamegraph` tools using `file://`, `http://`, or `https://` URIs for the profile file.\n\n**Example: Analyze CPU Profile (Text format, Top 5)**\n\n```json\n{\n  \"tool_name\": \"analyze_pprof\",\n  \"arguments\": {\n    \"profile_uri\": \"file:///path/to/your/cpu.pprof\",\n    \"profile_type\": \"cpu\"\n  }\n}\n```\n\n**Example: Analyze Heap Profile (Markdown format, Top 10)**\n\n```json\n{\n  \"tool_name\": \"analyze_pprof\",\n  \"arguments\": {\n    \"profile_uri\": \"file:///path/to/your/heap.pprof\",\n    \"profile_type\": \"heap\",\n    \"top_n\": 10,\n    \"output_format\": \"markdown\"\n  }\n}\n```\n\n**Example: Analyze Goroutine Profile (Text format, Top 5)**\n\n```json\n{\n  \"tool_name\": \"analyze_pprof\",\n  \"arguments\": {\n    \"profile_uri\": \"file:///path/to/your/goroutine.pprof\",\n    \"profile_type\": \"goroutine\"\n  }\n}\n```\n\n**Example: Generate Flame Graph for CPU Profile**\n\n```json\n{\n  \"tool_name\": \"generate_flamegraph\",\n  \"arguments\": {\n    \"profile_uri\": \"file:///path/to/your/cpu.pprof\",\n    \"profile_type\": \"cpu\",\n    \"output_svg_path\": \"/path/to/save/cpu_flamegraph.svg\"\n  }\n}\n```\n\n**Example: Generate Flame Graph for Heap Profile (inuse_space)**\n\n```json\n{\n  \"tool_name\": \"generate_flamegraph\",\n  \"arguments\": {\n    \"profile_uri\": \"file:///path/to/your/heap.pprof\",\n    \"profile_type\": \"heap\",\n    \"output_svg_path\": \"/path/to/save/heap_flamegraph.svg\"\n  }\n}\n```\n\n**Example: Analyze CPU Profile (JSON format, Top 3)**\n\n```json\n{\n  \"tool_name\": \"analyze_pprof\",\n  \"arguments\": {\n    \"profile_uri\": \"file:///path/to/your/cpu.pprof\",\n    \"profile_type\": \"cpu\",\n    \"top_n\": 3,\n    \"output_format\": \"json\"\n  }\n}\n```\n\n**Example: Analyze CPU Profile (Default Flame Graph JSON format)**\n\n```json\n{\n  \"tool_name\": \"analyze_pprof\",\n  \"arguments\": {\n    \"profile_uri\": \"file:///path/to/your/cpu.pprof\",\n    \"profile_type\": \"cpu\"\n    // output_format defaults to \"flamegraph-json\"\n  }\n}\n```\n\n**Example: Analyze Heap Profile (Explicitly Flame Graph JSON format)**\n\n```json\n{\n  \"tool_name\": \"analyze_pprof\",\n  \"arguments\": {\n    \"profile_uri\": \"file:///path/to/your/heap.pprof\",\n    \"profile_type\": \"heap\",\n    \"output_format\": \"flamegraph-json\"\n  }\n}\n```\n\n**Example: Analyze Remote CPU Profile (from HTTP URL)**\n\n```json\n{\n  \"tool_name\": \"analyze_pprof\",\n  \"arguments\": {\n    \"profile_uri\": \"https://example.com/profiles/cpu.pprof\",\n    \"profile_type\": \"cpu\"\n  }\n}\n```\n\n**Example: Analyze Online CPU Profile (from GitHub Raw URL)**\n\n```json\n{\n  \"tool_name\": \"analyze_pprof\",\n  \"arguments\": {\n    \"profile_uri\": \"https://raw.githubusercontent.com/google/pprof/refs/heads/main/profile/testdata/gobench.cpu\",\n    \"profile_type\": \"cpu\",\n    \"top_n\": 5\n  }\n}\n```\n\n**Example: Generate Flame Graph for Online Heap Profile (from GitHub Raw URL)**\n\n```json\n{\n  \"tool_name\": \"generate_flamegraph\",\n  \"arguments\": {\n    \"profile_uri\": \"https://raw.githubusercontent.com/google/pprof/refs/heads/main/profile/testdata/gobench.heap\",\n    \"profile_type\": \"heap\",\n    \"output_svg_path\": \"./online_heap_flamegraph.svg\"\n  }\n}\n```\n\n**Example: Open Interactive Pprof UI for Online CPU Profile (macOS Only)**\n\n```json\n{\n  \"tool_name\": \"open_interactive_pprof\",\n  \"arguments\": {\n    \"profile_uri\": \"https://raw.githubusercontent.com/google/pprof/refs/heads/main/profile/testdata/gobench.cpu\"\n    // Optional: \"http_address\": \":8082\" // Example of overriding the default port\n  }\n}\n```\n\n**Example: Detect Memory Leaks Between Two Heap Profiles**\n\n```json\n{\n  \"tool_name\": \"detect_memory_leaks\",\n  \"arguments\": {\n    \"old_profile_uri\": \"file:///path/to/your/heap_before.pprof\",\n    \"new_profile_uri\": \"file:///path/to/your/heap_after.pprof\",\n    \"threshold\": 0.05,  // 5% growth threshold\n    \"limit\": 15         // Show top 15 potential leaks\n  }\n}\n```\n\n**Example: Disconnect a Pprof Session**\n\n```json\n{\n  \"tool_name\": \"disconnect_pprof_session\",\n  \"arguments\": {\n    \"pid\": 12345 // Replace 12345 with the actual PID returned by open_interactive_pprof\n  }\n}\n```\n\n## Future Improvements (TODO)\n\n*   Implement full analysis logic for `mutex`, `block` profiles.\n*   Implement `json` output format for `mutex`, `block` profile types.\n*   Set appropriate MIME types in MCP results based on `output_format`.\n*   Add more robust error handling and logging level control.\n*   ~~Consider supporting remote pprof file URIs (e.g., `http://`, `https://`).~~ (Done)\n*   ~~Implement full analysis logic for `allocs` profiles.~~ (Done)\n*   ~~Implement `json` output format for `allocs` profile type.~~ (Done)\n*   ~~Add memory leak detection capabilities.~~ (Done)\n*   Add time-series analysis for memory profiles to track growth over multiple snapshots.\n*   Implement differential flame graphs to visualize changes between profiles.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "pprof",
        "performance",
        "bottlenecks",
        "pprof performance",
        "performance profiles",
        "pprof analyzer"
      ],
      "category": "devops-and-cicd"
    },
    "abhijeetka--mcp-k8s-server": {
      "owner": "abhijeetka",
      "name": "mcp-k8s-server",
      "url": "https://github.com/abhijeetka/mcp-k8s-server",
      "imageUrl": "/freedevtools/mcp/pfp/abhijeetka.webp",
      "description": "Manage Kubernetes clusters using natural language commands, simplifying complex kubectl operations and providing a conversational interface for Kubernetes resource management.",
      "stars": 9,
      "forks": 3,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-07-10T20:54:18Z",
      "readme_content": "# MCP Kubernetes Server\n\n![](https://badge.mcpx.dev?type=server 'MCP Server')\n[![smithery badge](https://smithery.ai/badge/@abhijeetka/mcp-k8s-server)](https://smithery.ai/server/@abhijeetka/mcp-k8s-server)\n\nThis is an MCP (Model Context Protocol) server for Kubernetes that provides control over Kubernetes clusters through interactions with LLMs.\n\n## Overview\n\nThis client allows you to perform common Kubernetes operations through MCP tools. It wraps `kubectl` commands to provide a simple interface for managing Kubernetes resources. The Model Context Protocol (MCP) enables seamless interaction between language models and Kubernetes operations.\n\n## What is MCP?\n\nModel Context Protocol (MCP) is a framework that enables Language Models to interact with external tools and services in a structured way. It provides:\n- A standardized way to expose functionality to language models\n- Context management for operations\n- Tool discovery and documentation\n- Type-safe interactions between models and tools\n\n## Usage Examples\n\n- Create a new deployment for me with name nginx-app and image nginx:latest in the production namespace with 3 replicas.\n- Update the deployment nginx-app to version 1.19 in the production namespace.\n- Scale the deployment nginx-app to 5 replicas in the production namespace.\n- Get me the pods in the production namespace.\n- Get me all namespaces in the cluster.\n- Get me all nodes in the cluster.\n- Get me all services in the cluster.\n- Get me all deployments in the cluster.\n- Get me all jobs in the cluster.\n- Get me all cronjobs in the cluster.\n- Get me all statefulsets in the cluster.\n- Get me all daemonsets in the cluster.\n- What is the current context.\n- list all contexts.\n- switch to context <context-name>.\n- Get me the logs of pod <pod-name> in the production namespace.\n- Get me the events in the production namespace.\n- annotate pod <pod-name> with key1=value1 in the production namespace.\n- remove annotation key1 from pod <pod-name> in the production namespace.\n- add label key1=value1 to pod <pod-name> in the production namespace.\n- remove label key1 from pod <pod-name> in the production namespace.\n- expose deployment nginx-app in the production namespace on port 80.\n- port-forward pod,deployment,service with name <resource-name> in the production namespace to local port 8080.\n- delete pod, deployment, service, job, cronjob, statefulset, daemonset with name <resource-name> in the production namespace.\n\n## Upcoming Features\n- Create cluster role.\n- delete cluster role.\n- create cluster role binding.\n- delete cluster role binding.\n- create namespace.\n- delete namespace.\n- create service account.\n- delete service account.\n- create role.\n- delete role.\n- create role binding.a\n- delete role binding.\n\n## LLM Integration\n\nThis MCP client is designed to work seamlessly with Large Language Models (LLMs). The functions are decorated with `@mcp.tool()`, making them accessible to LLMs through the Model Context Protocol framework.\n\n### Example LLM Prompts\n\nLLMs can interact with your Kubernetes cluster using natural language. Here are some example prompts:\n\n- \"Create a new nginx deployment with 3 replicas in the production namespace\"\n- \"Scale the nginx-app deployment to 5 replicas\"\n- \"Update the image of nginx-app to version 1.19\"\n\nThe LLM will interpret these natural language requests and call the appropriate MCP functions with the correct parameters.\n\n### Benefits of LLM Integration\n\n1. **Natural Language Interface**: Manage Kubernetes resources using conversational language\n2. **Reduced Command Complexity**: No need to remember exact kubectl syntax\n3. **Error Prevention**: LLMs can validate inputs and provide helpful error messages\n4. **Context Awareness**: LLMs can maintain context across multiple operations\n5. **Structured Interactions**: MCP ensures type-safe and documented interactions between LLMs and tools\n\n## Requirements\n\n- Kubernetes cluster access configured via `kubectl`\n- Python 3.x\n- MCP framework installed and configured\n\n## Security Note\n\nWhen using this client with LLMs, ensure that:\n- Proper access controls are in place for your Kubernetes cluster\n- The MCP server is running in a secure environment\n- API access is properly authenticated and authorized\n\n## Usage with Claude Desktop\n\n```\n{\n    \"mcpServers\": {\n        \"Kubernetes\": {\n            \"command\": \"uv\",\n            \"args\": [\n                \"--directory\",\n                \"~/mcp/mcp-k8s-server\",\n                \"run\",\n                \"kubernetes.py\"\n            ]\n        }\n    }\n}\n```\n\n## Contributing\n\nWe welcome contributions to the MCP Kubernetes Server! If you'd like to contribute:\n\n1. Fork the repository\n2. Create a new branch for your feature (`git checkout -b feature/amazing-feature`)\n3. Make your changes\n4. Write or update tests as needed\n5. Commit your changes (`git commit -m 'Add some amazing feature'`)\n6. Push to your branch (`git push origin feature/amazing-feature`)\n7. Open a Pull Request\n\n\nFor major changes, please open an issue first to discuss what you would like to change.\n### Installing via Smithery\n\nTo install Kubernetes Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@abhijeetka/mcp-k8s-server):\n\n```bash\nnpx -y @smithery/cli install @abhijeetka/mcp-k8s-server --client claude\n```\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "kubernetes",
        "kubectl",
        "devops",
        "kubernetes clusters",
        "manage kubernetes",
        "kubernetes resource"
      ],
      "category": "devops-and-cicd"
    },
    "anaisbetts--mcp-installer": {
      "owner": "anaisbetts",
      "name": "mcp-installer",
      "url": "https://github.com/anaisbetts/mcp-installer",
      "imageUrl": "/freedevtools/mcp/pfp/anaisbetts.webp",
      "description": "Installs other MCP servers hosted on npm or PyPi, enabling users to easily manage and set up various MCP servers through command prompts.",
      "stars": 1432,
      "forks": 184,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-10-03T22:31:55Z",
      "readme_content": "# mcp-installer - A MCP Server to install MCP Servers\n\nThis server is a server that installs other MCP servers for you. Install it, and you can ask Claude to install MCP servers hosted in npm or PyPi for you. Requires `npx` and `uv` to be installed for node and Python servers respectively.\n\n![image](https://github.com/user-attachments/assets/d082e614-b4bc-485c-a7c5-f80680348793)\n\n### How to install:\n\nPut this into your `claude_desktop_config.json` (either at `~/Library/Application Support/Claude` on macOS or `C:\\Users\\NAME\\AppData\\Roaming\\Claude` on Windows):\n\n```json\n  \"mcpServers\": {\n    \"mcp-installer\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"@anaisbetts/mcp-installer\"\n      ]\n    }\n  }\n```\n\n### Example prompts\n\n> Hey Claude, install the MCP server named mcp-server-fetch\n\n> Hey Claude, install the @modelcontextprotocol/server-filesystem package as an MCP server. Use ['/Users/anibetts/Desktop'] for the arguments\n\n> Hi Claude, please install the MCP server at /Users/anibetts/code/mcp-youtube, I'm too lazy to do it myself.\n\n> Install the server @modelcontextprotocol/server-github. Set the environment variable GITHUB_PERSONAL_ACCESS_TOKEN to '1234567890'\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcp",
        "devops",
        "anaisbetts",
        "mcp installer",
        "installs mcp",
        "devops cicd"
      ],
      "category": "devops-and-cicd"
    },
    "andrewhopper--itmcp": {
      "owner": "andrewhopper",
      "name": "itmcp",
      "url": "https://github.com/andrewhopper/itmcp",
      "imageUrl": "/freedevtools/mcp/pfp/andrewhopper.webp",
      "description": "Enables AI assistants to execute network administration and diagnostic commands securely within a Docker container sandbox. Provides controlled access to networking tools and file operations with enterprise-grade security features, including session management and audit logging.",
      "stars": 18,
      "forks": 2,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-07-06T09:48:48Z",
      "readme_content": "# ITMCP\n\nSecure network administration tools for AI assistants through the Model Context Protocol (MCP).\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)\n\n## Overview\n\nITMCP is an MCP server that enables AI assistants to safely execute networking commands inside a Docker container sandbox. It provides a secure interface for running common network diagnostic and administration tools while maintaining strict security controls.\n\nThe project implements the Model Context Protocol (MCP) to expose networking tools as callable functions for AI assistants, allowing them to perform network diagnostics and system administration tasks in a controlled environment.\n\n## Features\n\n- **Docker Isolation**: All commands run in a sandboxed Docker container for enhanced security\n- **Security Controls**: Comprehensive whitelisting of hosts, directories, and commands\n- **Network Diagnostic Tools**: SSH, ping, nslookup, telnet, dig, tcpdump, and more\n- **File Operations**: Secure access to view and analyze files with tools like cat, grep, head, tail\n- **Process Management**: View running processes with ps and top tools\n- **Credential Management**: Secure handling of SSH keys and passwords\n- **MCP Integration**: Full compatibility with the Model Context Protocol\n- **Enterprise-Grade Security**: Session management, audit logging, and access controls\n\n## Installation\n\n### Prerequisites\n\n- Python 3.10 or higher\n- Docker (for containerized execution)\n- MCP library (version 1.0.0 or higher)\n\n### Basic Installation\n\n1. Clone the repository:\n   ```bash\n   git clone https://github.com/yourusername/itmcp.git\n   cd itmcp\n   ```\n\n2. Install dependencies:\n   ```bash\n   pip install -e .\n   ```\n\n### Docker Setup\n\n1. Build the Docker container:\n   ```bash\n   docker build -t itmcp_container .\n   ```\n\n2. Run the container:\n   ```bash\n   docker-compose up -d\n   ```\n\n## Configuration\n\nITMCP uses a YAML-based configuration system and environment variables for setup.\n\n### Environment Variables\n\nCreate a `.env` file in the project root with the following variables:\n\n```\n# Docker configuration\nUSE_DOCKER=true\nDOCKER_CONTAINER=itmcp_container\n\n# SSH credentials configuration\nSSH_CREDENTIALS_PATH=/app/secrets/ssh_credentials.json\nSSH_KEYS_PATH=/app/secrets/keys\n\n# Security whitelists\nALLOWED_HOSTS=localhost,127.0.0.1,example.com\nALLOWED_DIRECTORIES=/tmp,/var/log\nALLOWED_REMOTE_COMMANDS=ls,cat,grep\n```\n\n### Security Whitelists\n\nITMCP implements three key whitelists for security:\n\n1. **Allowed Hosts**: Restricts which hosts can be targeted by network tools\n2. **Allowed Directories**: Limits file system access to specific directories\n3. **Allowed Remote Commands**: Controls which commands can be executed remotely\n\n## Available Tools\n\nITMCP provides the following network administration tools:\n\n| Tool | Description |\n|------|-------------|\n| `ssh_tool` | Connect to a target via SSH |\n| `ping_tool` | Ping a host to check connectivity |\n| `nslookup_tool` | Perform DNS lookup on a hostname or IP address |\n| `telnet_tool` | Test TCP connectivity to a host and port |\n| `dig_tool` | Perform DNS lookup with dig command |\n| `tcpdump_tool` | Capture network packets (limited time) |\n| `ps_tool` | List running processes |\n| `cat_tool` | Display content of a file |\n| `top_tool` | Display system processes (snapshot) |\n| `grep_tool` | Search for patterns in files |\n| `head_tool` | Display the beginning of a file |\n| `tail_tool` | Display the end of a file |\n\n## Security Features\n\nITMCP implements enterprise-grade security features:\n\n### Session Management\n\n- Secure session creation with cryptographic tokens\n- Session expiration and timeout controls\n- Concurrent session limits\n- Session validation and regeneration\n\n### Audit Logging\n\n- Comprehensive command logging\n- User attribution for all actions\n- Success/failure logging\n- Security event flagging\n- Tamper-evident logs\n\n### Access Control\n\n- Command whitelisting\n- Directory restrictions\n- Host restrictions\n- Input validation and sanitization\n\n## Docker Integration\n\nITMCP uses Docker to create a secure sandbox for command execution:\n\n1. All commands are routed through the Docker container\n2. The container has limited access to the host system\n3. Resource limits can be applied to prevent abuse\n4. Network isolation provides an additional security layer\n\n## Usage Examples\n\n### MCP Configuration\n\n#### Claude Desktop Configuration\n\nTo use ITMCP with Claude desktop, add the following to your `config.json` file:\n\n```json\n{\n  \"servers\": [\n    {\n      \"name\": \"itmcp\",\n      \"command\": [\"python\", \"-m\", \"itmcp.server\"],\n      \"environment\": {\n        \"USE_DOCKER\": \"true\",\n        \"DOCKER_CONTAINER\": \"itmcp_container\",\n        \"ALLOWED_HOSTS\": \"localhost,127.0.0.1,yahoo.com,firewall.local\"\n      }\n    }\n  ]\n}\n```\n\n#### Cline Configuration\n\nFor Cline AI, a more detailed configuration is provided in the `mcp-config.json` file included in this repository:\n\n```json\n{\n    \"servers\": [\n        {\n            \"name\": \"itmcp\",\n            \"command\": [\n                \"python\",\n                \"-m\",\n                \"itmcp.server\"\n            ],\n            \"environment\": {\n                \"USE_DOCKER\": \"true\",\n                \"DOCKER_CONTAINER\": \"itmcp_container\",\n                \"ALLOWED_HOSTS\": \"localhost,127.0.0.1,yahoo.com,firewall.local\",\n                \"ALLOWED_DIRECTORIES\": \"/tmp,/var/log\",\n                \"ALLOWED_REMOTE_COMMANDS\": \"ls,cat,grep,ping,ssh,nslookup,dig,telnet,tcpdump,ps,top,head,tail\"\n            },\n            \"description\": \"Secure network administration tools running in a Docker sandbox\",\n            \"tools\": [\n                {\n                    \"name\": \"ssh_tool\",\n                    \"description\": \"Connect to a target via SSH\"\n                },\n                {\n                    \"name\": \"ping_tool\",\n                    \"description\": \"Ping a host to check connectivity\"\n                },\n                {\n                    \"name\": \"nslookup_tool\",\n                    \"description\": \"Perform DNS lookup on a hostname or IP address\"\n                },\n                {\n                    \"name\": \"telnet_tool\",\n                    \"description\": \"Test TCP connectivity to a host and port\"\n                },\n                {\n                    \"name\": \"dig_tool\",\n                    \"description\": \"Perform DNS lookup with dig command\"\n                },\n                {\n                    \"name\": \"tcpdump_tool\",\n                    \"description\": \"Capture network packets (limited time)\"\n                },\n                {\n                    \"name\": \"ps_tool\",\n                    \"description\": \"List running processes\"\n                },\n                {\n                    \"name\": \"cat_tool\",\n                    \"description\": \"Display content of a file\"\n                },\n                {\n                    \"name\": \"top_tool\",\n                    \"description\": \"Display system processes (snapshot)\"\n                },\n                {\n                    \"name\": \"grep_tool\",\n                    \"description\": \"Search for patterns in files\"\n                },\n                {\n                    \"name\": \"head_tool\",\n                    \"description\": \"Display the beginning of a file\"\n                },\n                {\n                    \"name\": \"tail_tool\",\n                    \"description\": \"Display the end of a file\"\n                }\n            ]\n        }\n    ]\n}\n```\n\nTo use this configuration with Cline:\n\n1. Copy the `mcp-config.json` file to your Cline configuration directory\n2. Start Cline with the `--mcp-config` flag pointing to this file\n3. The ITMCP tools will be available for use in your Cline sessions\n\n### Example 1: Ping a Host\n\n```\n# Using the ping_tool to check connectivity to yahoo.com\n<use_mcp_tool>\n<server_name>itmcp</server_name>\n<tool_name>ping_tool</tool_name>\n<arguments>\n{\n  \"target\": \"yahoo.com\",\n  \"count\": 4\n}\n</arguments>\n</use_mcp_tool>\n```\n\n### Example 2: SSH Connection to Firewall\n\n```\n# Using the ssh_tool to connect to a firewall and run a command\n<use_mcp_tool>\n<server_name>itmcp</server_name>\n<tool_name>ssh_tool</tool_name>\n<arguments>\n{\n  \"target\": \"firewall.local\",\n  \"user\": \"admin\",\n  \"command\": \"show interface status\"\n}\n</arguments>\n</use_mcp_tool>\n```\n\n### Example 3: DNS Lookup\n\n```\n# Using the dig_tool to perform a DNS lookup\n<use_mcp_tool>\n<server_name>itmcp</server_name>\n<tool_name>dig_tool</tool_name>\n<arguments>\n{\n  \"target\": \"yahoo.com\",\n  \"type\": \"MX\"\n}\n</arguments>\n</use_mcp_tool>\n```\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n1. Fork the repository\n2. Create your feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add some amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## Author\n\n**Andrew Hopper**\n\n- Email: hopperab@gmail.com\n- Twitter: [x.com/andrewhopper](https://x.com/andrewhopper)\n- Website: [andyhop.316.dev](https://andyhop.316.dev)\n- LinkedIn: [linkedin.com/in/andrewhopper](https://linkedin.com/in/andrewhopper)\n\n## Security Considerations\n\nITMCP is designed with security in mind, but proper configuration is essential:\n\n- Always run in a Docker container for isolation\n- Carefully configure whitelists for hosts, directories, and commands\n- Regularly review audit logs for suspicious activity\n- Keep the system updated with security patches\n- Follow the security best practices in the documentation\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "devops",
        "docker",
        "sandbox",
        "devops cicd",
        "container sandbox",
        "securely docker"
      ],
      "category": "devops-and-cicd"
    },
    "crunchloop--mcp-devcontainers": {
      "owner": "crunchloop",
      "name": "mcp-devcontainers",
      "url": "https://github.com/crunchloop/mcp-devcontainers",
      "imageUrl": "/freedevtools/mcp/pfp/crunchloop.webp",
      "description": "Manage and interact with development containers by starting environments, running user setup commands, and executing shell commands within devcontainers. Simplifies the development workflow through direct control of devcontainers.",
      "stars": 2,
      "forks": 5,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-06-18T19:21:22Z",
      "readme_content": "# mcp-devcontainers\n\nThe MCP Devcontainers is a Model Context Protocol (MCP) server that provides a simple integration with the [devcontainers cli](https://github.com/devcontainers/cli).\n\n<a href=\"https://glama.ai/mcp/servers/@crunchloop/mcp-devcontainers\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@crunchloop/mcp-devcontainers/badge\" alt=\"Devcontainers MCP server\" />\n</a>\n\n## Dependencies\n\nThis server requires **Docker** to be installed and running on your system, as it is used by the [devcontainers cli](https://github.com/devcontainers/cli) to build and manage development containers.\n\n- [Docker installation guide](https://docs.docker.com/get-docker/)\n\nNo other dependencies are required to use the MCP Devcontainers server.\n\n## Usage\n\nMCP servers are configured differently depending on the client that you are using. For reference, this is how you would configure it using Claude Desktop.\n\n```json\n{\n  \"mcpServers\": {\n    \"devcontainers\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@crunchloop/mcp-devcontainers\"\n      ]\n    }\n  }\n}\n```\n\n## MCP Transport\n\nAt the moment, only `stdio` transport has been implemented.\n\n## Tools\n\n- **devcontainer_up** - Start or initialize a devcontainer environment in the specified workspace folder. Use this to ensure the devcontainer is running and ready for development tasks.\n  - `workspaceFolder`: Path to the workspace folder (string, required)\n  - `outputFilePath`: Path to write output logs (string, optional)\n\n- **devcontainer_run_user_commands** - Run the user-defined `postCreateCommand` and `postStartCommand` scripts in the devcontainer for the specified workspace folder. Use this to execute setup or initialization commands after the devcontainer starts.\n  - `workspaceFolder`: Path to the workspace folder (string, required)\n  - `outputFilePath`: Path to write output logs (string, optional)\n\n- **devcontainer_exec** - Execute an arbitrary shell command inside the devcontainer for the specified workspace folder. Use this to run custom commands or scripts within the devcontainer context.\n  - `workspaceFolder`: Path to the workspace folder (string, required)\n  - `command`: Command to execute (string[], required)\n  - `outputFilePath`: Path to write output logs (string, optional)\n\n## License\n\nReleased under the MIT License.  See the [LICENSE](./LICENSE) file for further details.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "devops",
        "devcontainers",
        "containers",
        "devops cicd",
        "devcontainers manage",
        "mcp devcontainers"
      ],
      "category": "devops-and-cicd"
    },
    "cuongdev--mcp-codepipeline-server": {
      "owner": "cuongdev",
      "name": "mcp-codepipeline-server",
      "url": "https://github.com/cuongdev/mcp-codepipeline-server",
      "imageUrl": "/freedevtools/mcp/pfp/cuongdev.webp",
      "description": "Manage AWS CodePipeline pipelines by triggering executions, retrieving metrics, approving actions, and obtaining execution logs through natural language commands in Windsurf. Streamline CI/CD processes with a standardized interface for AWS CodePipeline services.",
      "stars": 4,
      "forks": 4,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-05-14T09:09:27Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/cuongdev-mcp-codepipeline-server-badge.png)](https://mseep.ai/app/cuongdev-mcp-codepipeline-server)\n\n# AWS CodePipeline MCP Server\n\nThis is a Model Context Protocol (MCP) server that integrates with AWS CodePipeline, allowing you to manage your pipelines through Windsurf and Cascade. The server provides a standardized interface for interacting with AWS CodePipeline services.\n\n**Author:** Cuong T Nguyen\n\n## Features\n\n- List all pipelines\n- Get pipeline state and detailed pipeline definitions\n- List pipeline executions\n- Approve or reject manual approval actions\n- Retry failed stages\n- Trigger pipeline executions\n- View pipeline execution logs\n- Stop pipeline executions\n- Tag pipeline resources\n- Create webhooks for automatic pipeline triggering\n- Get pipeline performance metrics\n\n## Prerequisites\n\n- Node.js (v14 or later)\n- AWS account with CodePipeline access\n- AWS credentials with permissions for CodePipeline, CloudWatch, and IAM (for tagging)\n- Windsurf IDE with Cascade AI assistant\n\n## Installation\n\n1. Clone this repository:\n\n```bash\ngit clone https://github.com/cuongdev/mcp-codepipeline-server.git\ncd mcp-codepipeline-server\n```\n\n2. Install dependencies:\n\n```bash\nnpm install\n```\n\n3. Create a `.env` file based on the `.env.example` template:\n\n```bash\ncp .env.example .env\n```\n\n4. Update the `.env` file with your AWS credentials and configuration:\n\n```\nAWS_REGION=us-east-1\nAWS_ACCESS_KEY_ID=your_access_key_id\nAWS_SECRET_ACCESS_KEY=your_secret_access_key\nPORT=3000\n```\n\n> **Note**: For security, never commit your `.env` file to version control.\n\n## Usage\n\n### Build the project\n\n```bash\nnpm run build\n```\n\n### Start the server\n\n```bash\nnpm start\n```\n\nFor development with auto-restart:\n\n```bash\nnpm run dev\n```\n\n## Integration with Windsurf\n\nThis MCP server is designed to work with Windsurf, allowing Cascade to interact with AWS CodePipeline through natural language requests.\n\n### Setup Steps\n\n1. Make sure the server is running:\n\n```bash\nnpm start\n```\n\n2. Add the server configuration to your Windsurf MCP config file at `~/.codeium/windsurf/mcp_config.json`:\n\n```json\n{\n   \"mcpServers\": {\n    \"codepipeline\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"path/to/mcp-codepipeline-server/dist/index.js\"\n      ],\n      \"env\": {\n        \"AWS_REGION\": \"us-east-1\",\n        \"AWS_ACCESS_KEY_ID\": \"your_access_key_id\",\n        \"AWS_SECRET_ACCESS_KEY\": \"your_secret_access_key\"\n      }\n    }\n  }\n}\n```\n\n3. Create the directory if it doesn't exist:\n\n```bash\nmkdir -p ~/.codeium/windsurf\ntouch ~/.codeium/windsurf/mcp_config.json\n```\n\n4. Restart Windsurf to load the new MCP server configuration\n\n### Using with Cascade\n\nOnce configured, you can interact with AWS CodePipeline using natural language in Windsurf. For example:\n\n- \"List all my CodePipeline pipelines\"\n- \"Show me the current state of my 'production-deploy' pipeline\"\n- \"Trigger the 'test-build' pipeline\"\n- \"Get metrics for my 'data-processing' pipeline\"\n- \"Create a webhook for my 'frontend-deploy' pipeline\"\n\nCascade will translate these requests into the appropriate MCP tool calls.\n\n## MCP Tools\n\n### Core Pipeline Management\n\n| Tool Name | Description | Parameters |\n|-----------|-------------|------------|\n| `list_pipelines` | List all CodePipeline pipelines | None |\n| `get_pipeline_state` | Get the state of a specific pipeline | `pipelineName`: Name of the pipeline |\n| `list_pipeline_executions` | List executions for a specific pipeline | `pipelineName`: Name of the pipeline |\n| `trigger_pipeline` | Trigger a pipeline execution | `pipelineName`: Name of the pipeline |\n| `stop_pipeline_execution` | Stop a pipeline execution | `pipelineName`: Name of the pipeline<br>`executionId`: Execution ID<br>`reason`: Optional reason for stopping |\n\n### Pipeline Details and Metrics\n\n| Tool Name | Description | Parameters |\n|-----------|-------------|------------|\n| `get_pipeline_details` | Get the full definition of a pipeline | `pipelineName`: Name of the pipeline |\n| `get_pipeline_execution_logs` | Get logs for a pipeline execution | `pipelineName`: Name of the pipeline<br>`executionId`: Execution ID |\n| `get_pipeline_metrics` | Get performance metrics for a pipeline | `pipelineName`: Name of the pipeline<br>`period`: Optional metric period in seconds<br>`startTime`: Optional start time for metrics<br>`endTime`: Optional end time for metrics |\n\n### Pipeline Actions and Integrations\n\n| Tool Name | Description | Parameters |\n|-----------|-------------|------------|\n| `approve_action` | Approve or reject a manual approval action | `pipelineName`: Name of the pipeline<br>`stageName`: Name of the stage<br>`actionName`: Name of the action<br>`token`: Approval token<br>`approved`: Boolean indicating approval or rejection<br>`comments`: Optional comments |\n| `retry_stage` | Retry a failed stage | `pipelineName`: Name of the pipeline<br>`stageName`: Name of the stage<br>`pipelineExecutionId`: Execution ID |\n| `tag_pipeline_resource` | Add or update tags for a pipeline resource | `pipelineName`: Name of the pipeline<br>`tags`: Array of key-value pairs for tagging |\n| `create_pipeline_webhook` | Create a webhook for a pipeline | `pipelineName`: Name of the pipeline<br>`webhookName`: Name for the webhook<br>`targetAction`: Target action for the webhook<br>`authentication`: Authentication type<br>`authenticationConfiguration`: Optional auth config<br>`filters`: Optional event filters |\n\n## Troubleshooting\n\n### Common Issues\n\n1. **Connection refused error**:\n   - Ensure the server is running on the specified port\n   - Check if the port is blocked by a firewall\n\n2. **AWS credential errors**:\n   - Verify your AWS credentials in the `.env` file\n   - Ensure your IAM user has the necessary permissions\n\n3. **Windsurf not detecting the MCP server**:\n   - Check the `mcp_config.json` file format\n   - Ensure the server URL is correct\n   - Restart Windsurf after making changes\n\n### Logs\n\nThe server logs information to the console. Check these logs for troubleshooting:\n\n```bash\n# Run with more verbose logging\nDEBUG=* npm start\n```\n\n## Examples\n\n### Creating a Webhook for GitHub Integration\n\n```json\n{\n  \"pipelineName\": \"my-pipeline\",\n  \"webhookName\": \"github-webhook\",\n  \"targetAction\": \"Source\",\n  \"authentication\": \"GITHUB_HMAC\",\n  \"authenticationConfiguration\": {\n    \"SecretToken\": \"my-secret-token\"\n  },\n  \"filters\": [\n    {\n      \"jsonPath\": \"$.ref\",\n      \"matchEquals\": \"refs/heads/main\"\n    }\n  ]\n}\n```\n\n### Getting Pipeline Metrics\n\n```json\n{\n  \"pipelineName\": \"my-pipeline\",\n  \"period\": 86400,\n  \"startTime\": \"2025-03-10T00:00:00Z\",\n  \"endTime\": \"2025-03-17T23:59:59Z\"\n}\n```\n\n## License\n\nISC\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "codepipeline",
        "pipelines",
        "devops",
        "aws codepipeline",
        "codepipeline pipelines",
        "codepipeline services"
      ],
      "category": "devops-and-cicd"
    },
    "delorenj--super-win-cli-mcp-server": {
      "owner": "delorenj",
      "name": "super-win-cli-mcp-server",
      "url": "https://github.com/delorenj/super-win-cli-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/delorenj.webp",
      "description": "Provides full access to Windows CLI environments and unrestricted execution of system commands, enabling broad control over the operating system and file system.",
      "stars": 6,
      "forks": 4,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-28T18:40:10Z",
      "readme_content": "# Super Windows CLI MCP Server\n\nAn enhanced fork of the Windows CLI MCP Server with unrestricted system access capabilities.\n\n## Enhancements\n\n- Full system access through SYSTEM service installation\n- Unrestricted command execution\n- Network-level access controls\n- Unlimited process capabilities\n- Auto-recovery and fault tolerance\n- PowerShell telemetry disabled\n\n## Security Notice\n\nThis version removes application-level restrictions in favor of network-level security. It is designed for use in trusted environments where full system access is required.\n\n## Features\n\n- Complete access to Windows shell environments (PowerShell, CMD, Git Bash)\n- No command or argument restrictions\n- Full file system access\n- SYSTEM-level service installation\n- Automatic service recovery\n- Network binding controls\n- Process reuse for performance\n- Extended timeouts for long-running operations\n\n## Installation\n\n1. Build the project:\n```bash\nnpm install\nnpm run build\n```\n\n2. Copy the built files to your Windows machine\n\n3. Run the installation script as administrator:\n```powershell\n.\\install-service.ps1\n```\n\n## Configuration\n\nThe server is configured for maximum capability with these key features:\n\n- No command restrictions\n- Full filesystem access\n- Disabled injection protection\n- Unlimited process resources\n- Network-level access control\n- SYSTEM-level privileges\n\nSee `config.json` for the complete configuration.\n\n## Service Management\n\n### Installation\n```powershell\n.\\install-service.ps1\n```\n\n### Removal\n```powershell\n.\\uninstall-service.ps1\n```\n\n## Network Security\n\nWhile application-level restrictions are removed, the following network-level protections are in place:\n\n- Localhost binding by default\n- Configurable allowed IP ranges\n- Local network restriction\n- Optional VPN integration\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## Acknowledgments\n\nBased on the original [win-cli-mcp-server](https://github.com/SimonB97/win-cli-mcp-server) by SimonB97.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "cli",
        "devops",
        "commands",
        "windows cli",
        "devops cicd",
        "cli environments"
      ],
      "category": "devops-and-cicd"
    },
    "dion-hagan--mcp-server-spinnaker": {
      "owner": "dion-hagan",
      "name": "mcp-server-spinnaker",
      "url": "https://github.com/dion-hagan/mcp-server-spinnaker",
      "imageUrl": "/freedevtools/mcp/pfp/dion-hagan.webp",
      "description": "Integrates AI models with Spinnaker to manage and optimize deployment processes, leveraging contextual information for proactive issue detection and decision-making in CI/CD workflows.",
      "stars": 1,
      "forks": 2,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-07-17T20:27:02Z",
      "readme_content": "# MCP Server for Spinnaker\n\nThis package provides a Model Context Protocol (MCP) server implementation for Spinnaker integrations. It allows AI models to interact with Spinnaker deployments, pipelines, and applications through the standardized MCP interface.\n\n## AI Integration\n\nThis MCP server is a powerful example of how Anthropic's new AI model, Claude, can directly integrate with and enhance software deployment processes using the Model Context Protocol. By following MCP standards, Claude can access rich contextual information about Spinnaker applications, pipelines, and deployments, and actively manage them using well-defined tools.\n\nLet's dive into some of the exciting possibilities this integration enables for AI-driven CI/CD:\n\n1. **Intelligent Deployment Decisions**: With access to comprehensive context about the state of applications and pipelines, AI models like Claude can analyze this information to make intelligent decisions about when and how to deploy. For example, Claude could look at factors like test coverage, code churn, and historical success rates to determine the optimal time and target environment for a deployment.\n\n2. **Proactive Issue Detection and Autonomous Remediation**: AI models can continuously monitor the CI/CD process, spotting potential issues before they cause problems. Imagine Claude detecting that a new version of a dependency has a known vulnerability and automatically creating a pull request to update it, or noticing that a deployment is taking longer than usual and proactively spinning up additional resources to prevent a timeout.\n\n3. **Continuous Process Optimization**: With each deployment, AI models can learn and adapt, continuously optimizing the CI/CD process. Claude could analyze build and deployment logs to identify bottlenecks, then experiment with different configurations to improve speed and reliability. Over time, the entire deployment process becomes more efficient and robust.\n\n4. **Automated Root Cause Analysis and Recovery**: When issues do occur, AI can rapidly diagnose the problem and even attempt to fix it autonomously. Claude could correlate errors across different parts of the system, identify the most likely root cause, and then take corrective actions like rolling back to a previous version or applying a known patch.\n\nAnd these are just a few examples! As the Model Context Protocol evolves and more integrations are built, we can expect AI to take on increasingly sophisticated roles in the DevOps world. Across the entire CI/CD pipeline, AI could provide intelligent insights and recommendations, acting as a virtual assistant for product engineers.\n\nBy empowering AI to work alongside humans in the CI/CD process, MCP integrations like this Spinnaker server showcase how AI can become a proactive, intelligent partner in Developer Productivity infrastructure. It's a significant step towards more efficient, reliable, and autonomous software delivery.\n\n## Installation\n\n```bash\nnpm install @airjesus17/mcp-server-spinnaker\n```\n\nor\n\n```bash\nyarn add @airjesus17/mcp-server-spinnaker\n```\n\n## Usage\n\n```typescript\nimport { SpinnakerMCPServer } from '@airjesus17/mcp-server-spinnaker';\n\n// Initialize the server\nconst server = new SpinnakerMCPServer(\n  'https://your-gate-url',\n  ['app1', 'app2'],  // List of applications to monitor\n  ['prod', 'staging']  // List of environments to monitor\n);\n\n// Start the server\nconst port = 3000;\nserver.listen(port, () => {\n  console.log(`Spinnaker MCP Server is running on port ${port}`);\n});\n```\n\n## Available Tools\n\nThe server provides the following tools for AI models to interact with Spinnaker:\n\n### get-applications\nRetrieves a list of monitored Spinnaker applications and their current state.\n\n```typescript\n// Example response\n{\n  \"success\": true,\n  \"data\": [\n    {\n      \"name\": \"myapp\",\n      \"description\": \"My application\",\n      \"pipelines\": [\n        {\n          \"id\": \"pipeline-1\",\n          \"name\": \"Deploy to Production\",\n          \"status\": \"SUCCEEDED\"\n        }\n      ]\n    }\n  ]\n}\n```\n\n### get-pipelines\nRetrieves all pipelines for a specific application.\n\n```typescript\n// Parameters\n{\n  \"application\": \"myapp\"\n}\n\n// Example response\n{\n  \"success\": true,\n  \"data\": [\n    {\n      \"id\": \"pipeline-1\",\n      \"name\": \"Deploy to Production\",\n      \"status\": \"SUCCEEDED\",\n      \"stages\": [...]\n    }\n  ]\n}\n```\n\n### trigger-pipeline\nTriggers a pipeline execution for a specific application.\n\n```typescript\n// Parameters\n{\n  \"application\": \"myapp\",\n  \"pipelineId\": \"pipeline-1\",\n  \"parameters\": {\n    \"version\": \"1.2.3\",\n    \"environment\": \"production\"\n  }\n}\n\n// Example response\n{\n  \"success\": true,\n  \"data\": {\n    \"ref\": \"01HFGH2J...\",\n    \"status\": \"RUNNING\"\n  }\n}\n```\n\n## Context Updates\n\nThe server automatically maintains context about your Spinnaker deployments. The context includes:\n\n- List of applications and their current state\n- Pipeline status for each application\n- Current deployments across monitored environments\n- Recent pipeline executions\n\nContext is refreshed every 30 seconds by default.\n\n## Environment Variables\n\nThe server can be configured using the following environment variables:\n\n- `GATE_URL`: URL of your Spinnaker Gate service\n- `MCP_PORT`: Port to run the MCP server on (default: 3000)\n- `REFRESH_INTERVAL`: Context refresh interval in seconds (default: 30)\n\n## Types\n\nThe package exports TypeScript types for working with the server:\n\n```typescript\nimport type {\n  SpinnakerApplication,\n  SpinnakerPipeline,\n  SpinnakerDeployment,\n  SpinnakerExecution\n} from '@airjesus17/mcp-server-spinnaker';\n```\n\n## Development\n\nTo contribute to the development:\n\n1. Clone the repository\n2. Install dependencies: `yarn install`\n3. Build the project: `yarn build`\n4. Run tests: `yarn test`\n\n## License\n\nMIT License - see [LICENSE](LICENSE) for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "devops",
        "workflows",
        "deployment",
        "devops cicd",
        "deployment processes",
        "issue detection"
      ],
      "category": "devops-and-cicd"
    },
    "fyp312572116--devops-java-sample": {
      "owner": "fyp312572116",
      "name": "devops-java-sample",
      "url": "https://github.com/fyp312572116/devops-java-sample",
      "imageUrl": "/freedevtools/mcp/pfp/fyp312572116.webp",
      "description": "Streamline development processes by creating and managing CI/CD pipelines using a Jenkins-based system integrated within a SpringBoot demo project.",
      "stars": 0,
      "forks": 0,
      "license": "Apache License 2.0",
      "language": "Java",
      "updated_at": "2024-04-15T08:53:46Z",
      "readme_content": "> **_NOTICE:_**  Give [some historic reasons](https://github.com/kubesphere/devops-java-sample/issues/76), this repo has been archived. Please move forward to [devops-maven-sample](https://github.com/kubesphere/devops-maven-sample) if you want to help us improve the sample project.\n\n\n## Repo Introduction\n\n> English | [中文](README_zh.md)\n\nKubeSphere provides a Jenkins-based DevOps system [with various features](https://kubesphere.io/docs/devops-user-guide/understand-and-manage-devops-projects/overview/#features). This repository is used for a SpringBoot demo for DevOps on KubeSphere. For example, you can find a file of `Jenkinsfile-online` in the root directory, and you can use it to create a pipeline through the **Jenkinsfile in SCM** method.\n\nFor more information about how to use the KubeSphere DevOps system, you can refer to the following list of KubeSphere official documents. \n\n## Document List\n\n- [Create a Pipeline Using a Jenkinsfile](https://kubesphere.io/docs/devops-user-guide/how-to-use/create-a-pipeline-using-jenkinsfile/)\n- [Create a Pipeline Using Graphical Editing Panels](https://kubesphere.io/docs/devops-user-guide/how-to-use/create-a-pipeline-using-graphical-editing-panel/)\n- [Build and Deploy a Maven Project](https://kubesphere.io/docs/devops-user-guide/examples/a-maven-project/)\n- [Source to Image: Publish an App without a Dockerfile](https://kubesphere.io/docs/project-user-guide/image-builder/source-to-image/)\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "devops",
        "jenkins",
        "pipelines",
        "devops cicd",
        "devops java",
        "using jenkins"
      ],
      "category": "devops-and-cicd"
    },
    "izaitsevfb--claude-pytorch-treehugger": {
      "owner": "izaitsevfb",
      "name": "claude-pytorch-treehugger",
      "url": "https://github.com/izaitsevfb/claude-pytorch-treehugger",
      "imageUrl": "/freedevtools/mcp/pfp/izaitsevfb.webp",
      "description": "Access and analyze CI/CD data and job logs, providing tools for log analysis and resource utilization metrics within PyTorch workflows. Integrates with ClickHouse for advanced analytics capabilities.",
      "stars": 2,
      "forks": 2,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-07-01T14:01:33Z",
      "readme_content": "# PyTorch HUD API with MCP Support\n\nA Python library and MCP server for interacting with the PyTorch HUD API, providing access to CI/CD data, job logs, and analytics.\n\n## Overview\n\nThis project provides tools for PyTorch CI/CD analytics including:\n- Data access for workflows, jobs, and test runs\n- Efficient log analysis for large CI logs\n- ClickHouse query integration for analytics\n- Resource utilization metrics\n\n## Usage (for humans)\n\n```bash\n# Install from GitHub repository\npip install git+https://github.com/izaitsevfb/claude-pytorch-treehugger.git\n```\n\n```bash\nclaude mcp add hud pytorch-hud\n```\n\n## Development\n\n```bash\n# Install dependencies (if not installing with pip)\npip install -r requirements.txt\n\n# Start MCP server\npython -m pytorch_hud\n```\n\n## Key Features\n\n### Data Access\n\n- `get_commit_summary`: Basic commit info without jobs\n- `get_job_summary`: Aggregated job status counts\n- `get_filtered_jobs`: Jobs with filtering by status/workflow/name\n- `get_failure_details`: Failed jobs with detailed failure info\n- `get_recent_commit_status`: Status for recent commits with job statistics\n\n### Log Analysis\n\n- `download_log_to_file`: Download logs to local storage\n- `extract_log_patterns`: Find errors, warnings, etc.\n- `extract_test_results`: Parse test execution results\n- `filter_log_sections`: Extract specific log sections\n- `search_logs`: Search across multiple logs\n\n## Development\n\n```bash\n# Run tests\npython -m unittest discover test\n\n# Type checking\nmypy -p pytorch_hud -p test\n\n# Linting\nruff check pytorch_hud/ test/\n```\n\n## Documentation\n\n- [CLAUDE.md](CLAUDE.md): Detailed usage, code style, and implementation notes\n- [mcp-guide.md](mcp-guide.md): General MCP protocol information\n\n## License\n\nMIT",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "treehugger",
        "devops",
        "analytics",
        "devops cicd",
        "pytorch treehugger",
        "job logs"
      ],
      "category": "devops-and-cicd"
    },
    "jfrog--mcp-jfrog": {
      "owner": "jfrog",
      "name": "mcp-jfrog",
      "url": "https://github.com/jfrog/mcp-jfrog",
      "imageUrl": "/freedevtools/mcp/pfp/jfrog.webp",
      "description": "Manages repositories, tracks builds, and oversees the release lifecycle in conjunction with the JFrog Platform API. Provides tools for artifact search through AQL queries and runtime cluster monitoring.",
      "stars": 107,
      "forks": 21,
      "license": "Apache License 2.0",
      "language": "TypeScript",
      "updated_at": "2025-10-03T10:14:52Z",
      "readme_content": "# JFrog MCP Server (🧪 Experimental)\n\n[![smithery badge](https://smithery.ai/badge/@jfrog/mcp-jfrog)](https://smithery.ai/server/@jfrog/mcp-jfrog)\n\nModel Context Protocol (MCP) Server for the JFrog Platform API, enabling repository management, build tracking, release lifecycle management, and more.\n\n\nhttps://github.com/user-attachments/assets/aca3af2b-f294-41c8-8727-799a019a55b5\n\n\n## Disclaimer\nThis is an experimental project intended to demonstrate JFrog's capabilities with MCP. It is not officially supported or verified by JFrog.\n\n> **Update (2025):**  \nJFrog now provides an official, secure, and remotely hosted MCP server for seamless integration with the JFrog Platform.  \nThis managed MCP server is maintained by JFrog and is recommended for production use, offering enhanced security, reliability, and support.\n\nLearn more and get started here:  \n👉 [JFrog MCP Server Documentation](https://jfrog.com/help/r/jfrog-integrations-documentation/jfrog-mcp-server)\n\n## Features\n\n- **Repository Management**: Create and manage local, remote, and virtual repositories\n- **Build Tracking**: List and retrieve build information\n- **Runtime Monitoring**: View runtime clusters and running container images\n- **Mission Control**: View associated JFrog Platform instances\n- **Artifact Search**: Execute powerful AQL queries to search for artifacts and builds\n- **Catalog and Curation**: Access package information, versions, vulnerabilities, and check curation status\n- **Xray**: Access scan artifacts summary, group by severity per artifact\n\n## Tools\n\n<details>\n<summary><strong>Repository Management</strong></summary>\n\n1. `check_jfrog_availability`\n   - Check if JFrog platform is ready and functioning\n   - Returns: Platform readiness status\n\n2. `create_local_repository`\n   - Create a new local repository in Artifactory\n   - Inputs:\n     - `key` (string): Repository key\n     - `rclass` (string): Repository class (must be \"local\")\n     - `packageType` (string): Package type of the repository\n     - `description` (optional string): Repository description\n     - `projectKey` (optional string): Project key to assign the repository to\n     - `environments` (optional string[]): Environments to assign the repository to\n   - Returns: Created repository details\n\n3. `create_remote_repository`\n   - Create a new remote repository in Artifactory to proxy external package registries\n   - Inputs:\n     - `key` (string): Repository key\n     - `rclass` (string): Repository class (must be \"remote\")\n     - `packageType` (string): Package type of the repository\n     - `url` (string): URL to the remote repository\n     - `username` (optional string): Remote repository username\n     - `password` (optional string): Remote repository password\n     - `description` (optional string): Repository description\n     - `projectKey` (optional string): Project key to assign the repository to\n     - `environments` (optional string[]): Environments to assign the repository to\n     - Many other optional parameters for specific repository configurations\n   - Returns: Created repository details\n\n4. `create_virtual_repository`\n   - Create a new virtual repository in Artifactory that aggregates multiple repositories\n   - Inputs:\n     - `key` (string): Repository key\n     - `rclass` (string): Repository class (must be \"virtual\")\n     - `packageType` (string): Package type of the repository\n     - `repositories` (string[]): List of repository keys to include in the virtual repository\n     - `description` (optional string): Repository description\n     - `projectKey` (optional string): Project key to assign the repository to\n     - `environments` (optional string[]): Environments to assign the repository to\n     - Other optional parameters for specific repository configurations\n   - Returns: Created repository details\n\n5. `list_repositories`\n   - List all repositories in Artifactory with optional filtering\n   - Inputs:\n     - `type` (optional string): Filter repositories by type (local, remote, virtual, federated, distribution)\n     - `packageType` (optional string): Filter repositories by package type\n     - `project` (optional string): Filter repositories by project key\n   - Returns: List of repositories matching the filters\n\n6. `set_folder_property`\n   - Set properties on a folder in Artifactory, with optional recursive application\n   - Inputs:\n     - `folderPath` (string): Path to the folder where properties should be set\n     - `properties` (object): Key-value pairs of properties to set\n     - `recursive` (optional boolean): Whether to apply properties recursively to sub-folders\n   - Returns: Operation result\n\n7. `execute_aql_query`\n   - Execute an Artifactory Query Language (AQL) query to search for artifacts, builds, or other entities in JFrog Artifactory\n   - Inputs:\n     - `query` (string): The AQL query to execute. Must follow AQL syntax (e.g., items.find({\"repo\":\"my-repo\"}).include(\"name\",\"path\"))\n     - `domain` (optional string): The primary domain to search in (items, builds, archive.entries, build.promotions, releases)\n     - `transitive` (optional boolean): Whether to search in remote repositories\n     - `limit` (optional number): Maximum number of results to return\n     - `offset` (optional number): Number of results to skip\n     - `include_fields` (optional string[]): Fields to include in the results\n     - `sort_by` (optional string): Field to sort results by\n     - `sort_order` (optional string): Sort order (asc or desc)\n   - Returns: Search results with metadata\n</details>\n\n<details>\n<summary><strong>Build Management</strong></summary>\n\n8. `list_jfrog_builds`\n   - Return a list of all builds in the JFrog platform\n   - Returns: List of builds\n\n9. `get_specific_build`\n   - Get details for a specific build by name\n   - Inputs:\n     - `buildName` (string): Name of the build to retrieve\n     - `project` (optional string): Project key to scope the build search\n   - Returns: Build details\n</details>\n\n<details>\n<summary><strong>Runtime Management</strong></summary>\n\n10. `list_jfrog_runtime_clusters`\n    - Return a list of all runtime clusters in the JFrog platform\n    - Inputs:\n      - `limit` (optional integer): The maximum number of clusters to return\n      - `next_key` (optional string): The next key to use for pagination\n    - Returns: List of runtime clusters\n\n11. `get_jfrog_runtime_specific_cluster`\n    - Return a runtime cluster by ID\n    - Inputs:\n      - `clusterId` (integer): The ID of the cluster to retrieve\n    - Returns: Cluster details\n\n12. `list_jfrog_running_images`\n    - List all running container images across runtime clusters with their security and operational status\n    - Inputs:\n      - `filters` (optional string): Filters to apply\n      - `num_of_rows` (optional integer): Number of rows to return\n      - `page_num` (optional integer): Page number\n      - `statistics` (optional boolean): Whether to include statistics\n      - `timePeriod` (optional string): Time period to query\n    - Returns: List of running images\n</details>\n\n<details>\n<summary><strong>Access Control</strong></summary>\n\n13. `list_jfrog_environments`\n    - Get a list of all environments types in the JFrog platform with their details\n    - Inputs:\n    - Returns: List of environments\n\n14. `list_jfrog_projects`\n    - Get a list of all projects in the JFrog platform with their details\n    - Inputs:\n    - Returns: List of projects\n\n15. `get_specific_project`\n    - Get detailed information about a specific project in the JFrog platform\n    - Inputs:\n      - `project_key` (string): The unique key of the project to retrieve\n    - Returns: Project details\n\n16. `create_project`\n    - Create a new project in the JFrog platform\n    - Inputs:\n      - `project_key` (string): Unique identifier for the project\n      - `display_name` (string): Display name of the project\n      - `description` (string): Description of the project\n      - `admin_privileges` (object): Administrative privileges for the project\n      - `storage_quota_bytes` (number): Storage quota in bytes (-1 for unlimited)\n    - Returns: Created project details\n</details>\n\n<details>\n<summary><strong>Catalog and Curation</strong></summary>\n\n17. `jfrog_get_package_info`\n    - Get publicly available information about a software package\n    - Inputs:\n      - `type` (string): The type of package (pypi, npm, maven, golang, nuget, huggingface, rubygems)\n      - `name` (string): The name of the package, as it appears in the package repository\n      - `version` (optional string): The version of the package (default: \"latest\")\n    - Returns: Package information including description, latest version, license, and URLs\n\n18. `jfrog_get_package_versions`\n    - Get a list of versions of a publicly available package with publication dates\n    - Inputs:\n      - `type` (string): The type of package (pypi, npm, maven, golang, nuget, huggingface, rubygems)\n      - `name` (string): The name of the package, as it appears in the package repository\n    - Returns: List of package versions with publication dates\n\n19. `jfrog_get_package_version_vulnerabilities`\n    - Get a list of known vulnerabilities affecting a specific version of an open source package\n    - Inputs:\n      - `type` (string): The type of package (pypi, npm, maven, golang, nuget, huggingface, rubygems)\n      - `name` (string): The name of the package, as it appears in the package repository\n      - `version` (optional string): The version of the package (default: \"latest\")\n      - `pageSize` (optional number): Number of vulnerabilities to return per page (default: 10)\n      - `pageCount` (optional number): Number of pages to return (default: 1)\n    - Returns: List of vulnerabilities affecting the specified package version\n\n20. `jfrog_get_vulnerability_info`\n    - Get detailed information about a specific vulnerability, including affected packages and versions\n    - Inputs:\n      - `cve_id` (string): The CVE ID or vulnerability identifier to look up\n      - `pageSize` (optional number): Number of vulnerabilities to return per page (default: 10)\n      - `pageCount` (optional number): Number of pages to return (default: 1)\n    - Returns: Detailed vulnerability information and affected packages\n\n21. `jfrog_get_package_curation_status`\n    - Check the curation status of a specific package version\n    - Inputs:\n      - `packageType` (string): The type of package (pypi, npm, maven, golang, nuget, huggingface, rubygems)\n      - `packageName` (string): The name of the package, as it appears in the package repository\n      - `packageVersion` (string): The version of the package, as it appears in the package repository\n    - Returns: Curation status (approved, blocked, or inconclusive)\n</details>\n\n<details>\n<summary><strong>Xray</strong></summary>\n\n22. `jfrog_get_artifacts_summary`\n    - Get artifacts issues summary in a repository or build, categorized and counted by severity (Low, Medium, High, Critical, Unkown)\n    - Inputs:\n      - `paths` (string array): An array of paths to the artifacts from which to create the summary from\n    - Returns: A summary based on vulnerability count per severity for each artifact in the provided array plus the total issues\n</details>\n\n## Setup\n\n### Installing via Smithery\n\nTo install mcp-jfrog for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@jfrog/mcp-jfrog):\n\n```bash\nnpx -y @smithery/cli install @jfrog/mcp-jfrog --client claude\n```\n\n### Prerequisites\n\n- Node.js v18 or higher\n- Docker (if using Docker deployment, [See Docker Deployment](https://github.com/jfrog/mcp-jfrog/blob/main/README.md#docker) )\n- A valid JFrog platform instance with appropriate permissions\n- Access to create and manage access tokens in your JFrog platform instance\n\n## Environment Variables\n\n- `JFROG_ACCESS_TOKEN`: Your JFrog access token (required)\n- `JFROG_URL`: Base URL for your JFrog platform (required)\n- `TRANSPORT`: Transport mode to use, set to 'sse' to enable SSE transport (default: stdio)\n- `PORT`: Port number to use for SSE transport (default: 8080)\n- `CORS_ORIGIN`: CORS origin allowed for SSE connections (default: '*')\n- `LOG_LEVEL`: Logging level: DEBUG, INFO, WARN, ERROR (default: INFO)\n- `MAX_RECONNECT_ATTEMPTS`: Maximum number of reconnection attempts for SSE server (default: 5)\n- `RECONNECT_DELAY_MS`: Base delay in milliseconds between reconnection attempts (default: 2000)\n\n### JFrog Token (`JFROG_ACCESS_TOKEN`)\nTo use this MCP server, you need to create a JFrog Access Token or use an identity token with appropriate permissions:\n\nFor information on how to create a JFrog Token, please refer to the JFrog official documentations:\n\n- [Identity Tokens](https://jfrog.com/help/r/platform-api-key-deprecation-and-the-new-reference-tokens/introducing-jfrog-access-and-identity-tokens)\n\n- [Access Tokens](https://jfrog.com/help/r/jfrog-platform-administration-documentation/access-tokens)\n\n### JFrog URL (`JFROG_URL`)\n\nYour JFrog platform instance URL (e.g. https://acme.jfrog.io)\n\n### SSE Transport Features\n\nThe SSE transport mode includes the following features:\n\n- **Connection Management**: Each SSE connection is tracked with a unique ID, allowing clients to maintain state across reconnection attempts.\n- **Structured Logging**: Detailed logs with timestamps, severity levels, and relevant contextual information.\n- **Connection Resilience**: Automatic reconnection attempts with exponential backoff if the server fails to start.\n- **Health Endpoint**: A `/health` endpoint that returns server status information.\n- **Connection Tracking**: Real-time tracking of active connections with periodic statistics logging.\n- **Performance Metrics**: Execution time tracking for tool operations and HTTP requests.\n\nWhen using SSE mode:\n\n1. Clients should connect to the `/sse` endpoint, optionally providing a `connectionId` query parameter for session tracking.\n2. Client requests should be sent to the `/messages` endpoint with the same `connectionId` as a query parameter.\n3. The server will respond with server-sent events through the established SSE connection.\n\nExample client connection with connection ID:\n```\nGET /sse?connectionId=client123\n```\n\nExample client request:\n```\nPOST /messages?connectionId=client123\nContent-Type: application/json\n\n{\n  \"jsonrpc\": \"2.0\",\n  \"method\": \"listTools\",\n  \"id\": 1\n}\n```\n\n### How to build\n\nClone the repo to your local machine using `git clone` and `cd` into the project directory:\n\n```bash\ngit clone git@github.com:jfrog/mcp-jfrog.git\n\ncd mcp-jfrog\n```\n\nBuild as a Docker image:\n\n```bash\ndocker build -t mcp/jfrog -f Dockerfile .\n```\n\nBuild as an npm module: \n\n```bash\nnpm i && npm run build\n```\n\n\n## Usage\n\n<details>\n<summary><strong>Use with Cursor</strong></summary>\nAdd the following to your `~/.cursor/mcp.json`:\n\n### npm\n\n```json\n{\n  \"mcpServers\": {\n    \"MCP-JFrog\": { \n      \"command\": \"npm\",\n      \"args\": [\n        \"exec\",\n        \"-y\",\n        \"github:jfrog/mcp-jfrog\"\n      ],\n      \"env\": {\n        \"JFROG_ACCESS_TOKEN\": \"ACCESS_TOKEN\",\n        \"JFROG_URL\": \"https://<YOUR_JFROG_INSTANCE_URL>\"\n      }\n    }\n  },\n  \"mcp-local-dev\":{\n      \"command\": \"node\",\n      \"args\": [\n        \"/<ABSOLUT_PATH_TO>/mcp-jfrog/dist/index.js\"\n      ],\n      \"env\": {\n        \"JFROG_ACCESS_TOKEN\": \"<ACCESS_TOKEN>>\",\n        \"JFROG_URL\": \"<JFROG_URL>\"\n      }\n    }\n}\n```\n\n### Docker\n```json\n{\n  \"mcpServers\": { \n    \"jfrog\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"-i\",\n        \"-e\",\n        \"JFROG_ACCESS_TOKEN\",\n        \"-e\",\n        \"JFROG_URL\",\n        \"mcp/jfrog\"\n      ],\n      \"env\": {\n        \"JFROG_ACCESS_TOKEN\": \"<YOUR_TOKEN>\",\n        \"JFROG_URL\": \"https://your-instance.jfrog.io\"\n      },\n      \"serverUrl\": \"http://localhost:8080/sse\"\n    }\n  }\n}\n```\n\n### SSE Transport Mode\n\nTo use the JFrog MCP Server with SSE transport mode (useful for web interfaces like Cursor's webview):\n\n```json\n{\n  \"mcpServers\": { \n    \"jfrog-sse\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"-p\",\n        \"8080:8080\",\n        \"-e\",\n        \"TRANSPORT=sse\",\n        \"-e\",\n        \"PORT=8080\",\n        \"-e\",\n        \"CORS_ORIGIN=*\",\n        \"-e\",\n        \"LOG_LEVEL=INFO\",\n        \"-e\",\n        \"MAX_RECONNECT_ATTEMPTS=5\",\n        \"-e\",\n        \"RECONNECT_DELAY_MS=2000\",\n        \"-e\",\n        \"JFROG_ACCESS_TOKEN\",\n        \"-e\",\n        \"JFROG_URL\",\n        \"mcp/jfrog\"\n      ],\n      \"env\": {\n        \"JFROG_ACCESS_TOKEN\": \"<YOUR_TOKEN>\",\n        \"JFROG_URL\": \"https://your-instance.jfrog.io\",\n        \"serverUrl\": \"http://localhost:8080/sse\"\n      }\n    }\n  }\n}\n```\n\nNote: For SSE mode, you need to add the `serverUrl` parameter pointing to your SSE endpoint, and expose the port used by the server (-p 8080:8080).\n</details>\n\n<details>\n<summary><strong>Use with Claude Desktop</strong></summary>\n\n\nAdd the following to your `claude_desktop_config.json`:\n#### Docker\n\n```json\n{\n  \"mcpServers\": { \n    \"jfrog\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"-i\",\n        \"-e\",\n        \"JFROG_ACCESS_TOKEN\",\n        \"-e\",\n        \"JFROG_URL\",\n        \"mcp/jfrog\"\n      ],\n      \"env\": {\n        \"JFROG_ACCESS_TOKEN\": \"<YOUR_TOKEN>\",\n        \"JFROG_URL\": \"https://your-instance.jfrog.io\" // Your JFrog platform URL\n      },\n      \"serverUrl\": \"http://localhost:8080/sse\"\n    }\n  }\n}\n```\n\n### npm\n\n```json\n{\n\"mcpServers\": {\n    \"MCP-JFrog\": { \n      \"command\": \"npm\",\n      \"args\": [\n        \"exec\",\n        \"-y\",\n        \"github:jfrog/mcp-jfrog\"\n      ],\n      \"env\": {\n        \"JFROG_ACCESS_TOKEN\": \"ACCESS_TOKEN\",\n        \"JFROG_URL\": \"https://<YOUR_JFROG_INSTANCE_URL>\"\n      }\n    }\n  }\n}\n```\n\n### SSE Transport Mode\n\nFor Claude Desktop with SSE transport:\n\n```json\n{\n  \"mcpServers\": { \n    \"jfrog-sse\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"-p\",\n        \"8080:8080\",\n        \"-e\",\n        \"TRANSPORT=sse\",\n        \"-e\",\n        \"PORT=8080\",\n        \"-e\",\n        \"CORS_ORIGIN=*\",\n        \"-e\",\n        \"LOG_LEVEL=INFO\",\n        \"-e\",\n        \"MAX_RECONNECT_ATTEMPTS=5\",\n        \"-e\",\n        \"RECONNECT_DELAY_MS=2000\",\n        \"-e\",\n        \"JFROG_ACCESS_TOKEN\",\n        \"-e\",\n        \"JFROG_URL\",\n        \"mcp/jfrog\"\n      ],\n      \"env\": {\n        \"JFROG_ACCESS_TOKEN\": \"<YOUR_TOKEN>\",\n        \"JFROG_URL\": \"https://your-instance.jfrog.io\",\n        \"serverUrl\": \"http://localhost:8080/sse\"\n      }\n    }\n  }\n}\n```\n```\n</details>\n\n\n## License\n\nThis MCP server is licensed under the Apache License 2.0. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the Apache License 2.0. For more details, please see the LICENSE.md file in the project repository.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "devops",
        "jfrog",
        "repositories",
        "devops cicd",
        "jfrog manages",
        "jfrog platform"
      ],
      "category": "devops-and-cicd"
    },
    "kaznak--shell-command-mcp": {
      "owner": "kaznak",
      "name": "shell-command-mcp",
      "url": "https://github.com/kaznak/shell-command-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/kaznak.webp",
      "description": "Execute shell commands securely within an isolated Docker container environment. It supports both synchronous and asynchronous execution with multiple notification modes, while also integrating Kubernetes tools.",
      "stars": 5,
      "forks": 2,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-06-19T05:00:58Z",
      "readme_content": "# *OBSOLETE*\n\nI recommend using Claude Code by running `claude mcp serve` instead of this MCP server.\nI have created [ai-agent-workspace](https://github.com/kaznak/container-images/tree/main/ai-agent-workspace) as a container to run Claude Code.\nPlease use it as needed.\n\n# Shell Command MCP Server\n\nThis is an MCP (Model Context Protocol) server that allows executing shell commands within a Docker container. It provides a secure and isolated workspace for running commands without giving access to the host Docker daemon.\n\n## Features\n\n- Run shell scripts through a simple MCP interface\n  - synchronous execution\n  - asynchronous execution with 4 different modes\n    - complete: notify when the command is completed\n    - line: notify on each line of output\n    - chunk: notify on each chunk of output\n    - character: notify on each character of output\n- Kubernetes tools included: kubectl, helm, kustomize, hemfile\n- Isolated Docker container environment with non-root user\n  - host-container userid/groupid mapping implemented. this allows the container to run as the same user as the host, ensuring that files created by the container have the same ownership and permissions as those created by the host.\n  - mount a host directory to the container /home/mcp directory for persistence. it become the home directory the AI works in.\n  - if the host directory is empty, the initial files will be copied form the backup in the container.\n\n## Design Philosophy\n\nThis MCP server provides AI with a workspace similar to that of a human.\nAuthorization is limited not by MCP functions, but by container isolation and external authorization restrictions.\n\nIt provides more general tools such as shell script execution, so that they can be used without specialized knowledge of tool use.\n\nThe server implementation is kept as simple as possible to facilitate code auditing.\n\n## Getting Started\n\n### Prerequisites\n\n- Docker\n\n### Usage with Claude for Desktop\n\nAdd the following configuration to your Claude for Desktop configuration file.\n\nMacOS:\n\n```json\n\"shell-command\": {\n  \"command\": \"docker\",\n  \"args\": [\n    \"run\",\n    \"--rm\",\n    \"-i\",\n    \"--mount\",\n    \"type=bind,src=/Users/user-name/MCPHome,dst=/home/mcp\",\n    \"ghcr.io/kaznak/shell-command-mcp:latest\"\n  ]\n}\n```\n\nReplace `/Users/user-name/ClaudeWorks` with the directory you want to make available to the container.\n\nWindows:\n\n```json\n\"shell-command\": {\n   \"command\": \"docker\",\n   \"args\": [\n      \"run\",\n      \"--rm\",\n      \"-i\",\n      \"--mount\",\n      \"type=bind,src=\\\\\\\\wsl.localhost\\\\Ubuntu\\\\home\\\\user-name\\\\MCPHome,dst=/home/mcp\",\n      \"ghcr.io/kaznak/shell-command-mcp:latest\"\n   ]\n}\n```\n\n### Feed some prompts\n\nTo Operate the files in the mounted directory.\n\n## Available MCP Tools\n\n- [execute-bash-script-sync](./src/execute-bash-script-sync.ts)\n- [execute-bash-script-async](./src/execute-bash-script-async.ts)\n\n## Security Considerations\n\n- The MCP server runs as a non-root user within the container\n- The container does not have access to the host Docker daemon\n- User workspace is mounted from the host for persistence\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "docker",
        "kubernetes",
        "devops",
        "kaznak shell",
        "docker container",
        "kubernetes tools"
      ],
      "category": "devops-and-cicd"
    },
    "kjozsa--jenkins-mcp": {
      "owner": "kjozsa",
      "name": "jenkins-mcp",
      "url": "https://github.com/kjozsa/jenkins-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/kjozsa.webp",
      "description": "Manage Jenkins operations efficiently, facilitating build and deployment processes.",
      "stars": 8,
      "forks": 10,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-05-25T14:00:51Z",
      "readme_content": "# Jenkins MCP\n[![smithery badge](https://smithery.ai/badge/@kjozsa/jenkins-mcp)](https://smithery.ai/server/@kjozsa/jenkins-mcp)\nMCP server for managing Jenkins operations.\n\n<a href=\"https://glama.ai/mcp/servers/7j3zk84u5p\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/7j3zk84u5p/badge\" alt=\"Jenkins MCP server\" />\n</a>\n\n## Installation\n### Installing via Smithery\n\nTo install Jenkins MCP for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@kjozsa/jenkins-mcp):\n\n```bash\nnpx -y @smithery/cli install @kjozsa/jenkins-mcp --client claude\n```\n\n### Installing Manually\n```bash\nuvx install jenkins-mcp\n```\n\n## Configuration\nAdd the MCP server using the following JSON configuration snippet:\n\n```json\n{\n  \"mcpServers\": {\n    \"jenkins-mcp\": {\n      \"command\": \"uvx\",\n      \"args\": [\"jenkins-mcp\"],\n      \"env\": {\n        \"JENKINS_URL\": \"https://your-jenkins-server/\",\n        \"JENKINS_USERNAME\": \"your-username\",\n        \"JENKINS_PASSWORD\": \"your-password\",\n        \"JENKINS_USE_API_TOKEN\": \"false\"\n      }\n    }\n  }\n}\n```\n\n## CSRF Crumb Handling\n\nJenkins implements CSRF protection using \"crumbs\" - tokens that must be included with POST requests. This MCP server handles CSRF crumbs in two ways:\n\n1. **Default Mode**: Automatically fetches and includes CSRF crumbs with build requests\n   - Uses session cookies to maintain the web session\n   - Handles all the CSRF protection behind the scenes\n\n2. **API Token Mode**: Uses Jenkins API tokens which are exempt from CSRF protection\n   - Set `JENKINS_USE_API_TOKEN=true`\n   - Set `JENKINS_PASSWORD` to your API token instead of password\n   - Works with Jenkins 2.96+ which doesn't require crumbs for API token auth\n\nYou can generate an API token in Jenkins at: User → Configure → API Token → Add new Token\n\n## Features\n- List Jenkins jobs\n- Trigger builds with optional parameters\n- Check build status\n- CSRF crumb handling for secure API access\n\n## Development\n```bash\n# Install dependencies\nuv pip install -r requirements.txt\n\n# Run in dev mode with Inspector\nmcp dev jenkins_mcp/server.py\n```\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "jenkins",
        "devops",
        "deployment",
        "manage jenkins",
        "jenkins operations",
        "devops cicd"
      ],
      "category": "devops-and-cicd"
    },
    "lanbaoshen--mcp-jenkins": {
      "owner": "lanbaoshen",
      "name": "mcp-jenkins",
      "url": "https://github.com/lanbaoshen/mcp-jenkins",
      "imageUrl": "/freedevtools/mcp/pfp/lanbaoshen.webp",
      "description": "Connects Jenkins with AI language models to automate and manage CI/CD pipelines, facilitating secure interaction with Jenkins tools and simplifying job management and build monitoring.",
      "stars": 48,
      "forks": 18,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-03T08:28:57Z",
      "readme_content": "# MCP Jenkins\n![PyPI Version](https://img.shields.io/pypi/v/mcp-jenkins)\n[![PyPI Downloads](https://static.pepy.tech/badge/mcp-jenkins)](https://pepy.tech/projects/mcp-jenkins)\n[![test](https://github.com/lanbaoshen/mcp-jenkins/actions/workflows/test.yml/badge.svg)](https://github.com/lanbaoshen/mcp-jenkins/actions/workflows/test.yml/badge.svg)\n![License](https://img.shields.io/github/license/lanbaoshen/mcp-jenkins)\n\nThe Model Context Protocol (MCP) is an open-source implementation that bridges Jenkins with AI language models following Anthropic's MCP specification. This project enables secure, contextual AI interactions with Jenkins tools while maintaining data privacy and security.\n\n\n## Cursor Demo\n![cursor demo](https://github.com/user-attachments/assets/ba954a67-e9ca-4d38-b962-19fb8856bdde)\n\n\n## Setup Guide\n\n### Installation\nChoose one of these installation methods:\n```\n# Using uv (recommended)\npip install uv\nuvx mcp-jenkins\n\n# Using pip\npip install mcp-jenkins\n\n# Using Smithery\nnpx -y @smithery/cli@latest install @lanbaoshen/mcp-jenkins --client claude\n```\n\n### Configuration and Usage\n\n#### Cursor\n1. Open Cursor Settings\n2. Navigate to MCP\n3. Click + Add new global MCP server\n\nThis will create or edit the ~/.cursor/mcp.json file with your MCP server configuration.\n```shell\n{\n  \"mcpServers\": {\n    \"mcp-jenkins\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"mcp-jenkins\",\n        \"--jenkins-url=xxx\",\n        \"--jenkins-username=xxx\",\n        \"--jenkins-password=xxx\"\n      ]\n    }\n  }\n}\n```\n\n**Note: You can set your Jenkins token to password too!**\n\n#### VSCode Copilot Chat\n1. Create `.vscode` folder with `mcp.json` file in you workspace for local setup or edit `settings.json` trough settings menù.\n2. Insert the following configuration:\n```json\n{\n    \"servers\": {\n        \"jenkins\": {\n            \"url\": \"http://localhost:3000/sse\",\n            \"type\": \"sse\"\n        }\n    }\n}\n```\n3. Run the Jenkins MCP server with the following command:\n```shell\nuvx mcp-jenkins \\\n  --jenkins-url http://localhost:3000 \\\n  --jenkins-username your_username  \\\n  --jenkins-password your_password_or_token \\\n  --transport sse --port 3000\n```\n\n#### line arguments\n```shell\n# Stdio Mode\nuvx mcp-jenkins --jenkins-url xxx --jenkins-username xxx --jenkins-password xxx --read-only\n\n# SSE Mode\nuvx mcp-jenkins --jenkins-url xxx --jenkins-username xxx --jenkins-password xxx --transport sse --port 9887\n```\n\n#### AutoGen\n<details>\n<summary>Install and exec</summary>\n\nInstall autogen:\n```shell\npip install \"autogen-ext[azure,ollama,openai,mcp]\" autogen-chat\n```\n\nRun python scripts:\n```python\nimport asyncio\n\nfrom autogen_ext.tools.mcp import StdioMcpToolAdapter, StdioServerParams\nfrom autogen_agentchat.agents import AssistantAgent\nfrom autogen_agentchat.ui import Console\nfrom autogen_core import CancellationToken\n\n\nasync def main() -> None:\n    # Create server params for the remote MCP service\n    server_params = StdioServerParams(\n        command='uvx',\n        args=[\n            'mcp-jenkins',\n            '--jenkins-username',\n            'xxx',\n            '--jenkins-password',\n            'xxx',\n            '--jenkins-url',\n            'xxx'\n        ],\n    )\n\n    # Get the translation tool from the server\n    adapter = await StdioMcpToolAdapter.from_server_params(server_params, 'get_all_jobs')\n\n    # Create an agent that can use the translation tool\n    agent = AssistantAgent(\n        name='jenkins_assistant',\n        model_client=[Replace_with_your_model_client],\n        tools=[adapter],\n    )\n\n    # Let the agent translate some text\n    await Console(\n        agent.run_stream(task='Get all jobs', cancellation_token=CancellationToken())\n    )\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n</details>\n\n## Available Tools\n| Tool                      | Description                                                                     |\n|---------------------------|---------------------------------------------------------------------------------|\n| get_all_jobs              | Get all jobs                                                                    |\n| get_job_config            | Get job config                                                                  |\n| search_jobs               | Search job by specific field                                                    |\n| get_running_builds        | Get running builds                                                              |\n| stop_build                | Stop running build                                                              |\n| get_build_info            | Get build info                                                                  |\n| get_build_sourcecode      | Get the pipeline source code of a specific build in Jenkins\n| get_job_info              | Get job info                                                                    |\n| build_job                 | Build a job with param                                                          |\n| get_build_logs            | Get build logs                                                                  |\n| get_all_nodes             | Get nodes                                                                       |\n| get_node_config           | Get the config of node                                                          |\n| get_all_queue_items       | Get all queue items                                                             |\n| get_queue_item            | Get queue item info                                                             |\n| cancel_queue_item         | Cancel queue item                                                               |\n| get_multibranch_jobs      | Get all multibranch pipeline jobs from Jenkins, optionally filtered by patterns |\n| get_multibranch_branches  | Get all branches for a specific multibranch pipeline job                        |\n| scan_multibranch_pipeline | Trigger a scan of a multibranch pipeline to discover new branches               |\n\n\n## Development & Debugging\n```shell\n# Using MCP Inspector\n# For installed package\nnpx @modelcontextprotocol/inspector uvx mcp-jenkins --jenkins-url xxx --jenkins-username xxx --jenkins-password xxx\n\n# For local development version\nnpx @modelcontextprotocol/inspector uv --directory /path/to/your/mcp-jenkins run mcp-jenkins --jenkins-url xxx --jenkins-username xxx --jenkins-password xxx\n```\n\n### Pre-Commit Hook\n```shell\n# Install Dependency\nuv sync --all-extras --dev\npre-commit install\n\n# Manually execute\npre-commit run --all-files\n```\n\n### UT\n```\n# Install Dependency\nuv sync --all-extras --dev\n\n# Execute UT\nuv run pytest --cov=mcp_jenkins\n```\n\n\n## License\nLicensed under MIT - see [LICENSE](LICENSE) file. This is not an official Jenkins product.\n\n\n## MCP-Jenkins in MCP Registries\n- https://mcpreview.com/mcp-servers/lanbaoshen/mcp-jenkins\n- https://smithery.ai/server/@lanbaoshen/mcp-jenkins\n- https://glama.ai/mcp/servers/@lanbaoshen/mcp-jenkins\n- https://mseep.ai/app/lanbaoshen-mcp-jenkins\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=lanbaoshen/mcp-jenkins&type=Date)](https://www.star-history.com/#lanbaoshen/mcp-jenkins&Date)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "jenkins",
        "devops",
        "automate",
        "jenkins tools",
        "jenkins ai",
        "mcp jenkins"
      ],
      "category": "devops-and-cicd"
    },
    "lieee1995--mcp-jenkins-server": {
      "owner": "lieee1995",
      "name": "mcp-jenkins-server",
      "url": "https://github.com/lieee1995/mcp-jenkins-server",
      "imageUrl": "/freedevtools/mcp/pfp/lieee1995.webp",
      "description": "Integrates with a Jenkins server to manage jobs, retrieve build information, and trigger builds. Provides direct access to Jenkins data for enhanced automation and CI/CD processes.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-03-31T07:44:10Z",
      "readme_content": "﻿# MCP Jenkins Server\r\n\r\nA Model Context Protocol (MCP) server that provides Jenkins integration tools.\r\n\r\n## Features\r\n\r\n- Get Jenkins server information\r\n- List and inspect Jenkins jobs\r\n- Get build information and console output\r\n- Manage Jenkins views\r\n- Trigger specific job builds\r\n\r\n## Requirements\r\n\r\n- Python 3.10+\r\n- Jenkins server with API access\r\n- Jenkins API token for authentication\r\n\r\n## Installation\r\n\r\n1. Clone this repository\r\n2. Install dependencies:\r\n   ```bash\r\n   pip install -r requirements.txt\r\n   ```\r\n\r\n## Configuration\r\n\r\nCreate a `.env` file with your Jenkins credentials:\r\n\r\n```ini\r\nJENKINS_URL=https://your-jenkins-server\r\nJENKINS_USER=your-username\r\nJENKINS_TOKEN=your-api-token\r\n```\r\n\r\n## CLI Configuration\r\n\r\nTo add this MCP server to your CLI, use the following configuration:\r\n\r\n```json\r\n{\r\n  \"mcpServers\": {\r\n    \"mcp-jenkins-server\": {\r\n      \"command\": \"uv\",\r\n      \"args\": [\r\n        \"--directory\", \r\n        \"C:\\\\Users\\\\Dean.Li\\\\Documents\\\\Cline\\\\MCP\\\\mcp-jenkins-server\",\r\n        \"run\",\r\n        \"server.py\"\r\n      ],\r\n      \"env\": {\r\n        \"JENKINS_URL\": \"https://your-jenkins-server/\",\r\n        \"JENKINS_USERNAME\": \"your-username\",\r\n        \"JENKINS_PASSWORD\": \"your-password\"\r\n      },\r\n      \"disabled\": false,\r\n      \"autoApprove\": []\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n## Available Tools\r\n\r\nThis MCP server provides the following tools:\r\n\r\n### `get_jenkins_info`\r\nGet Jenkins server information\r\n\r\n### `list_jobs`\r\nList all Jenkins jobs\r\n\r\n### `get_job_info`\r\nGet information about a specific job\r\n- Parameters:\r\n  - `job_name`: Name of the job to inspect\r\n\r\n### `get_build_info`\r\nGet information about a specific build\r\n- Parameters:\r\n  - `job_name`: Name of the job\r\n  - `build_number`: Build number to inspect\r\n\r\n### `get_build_console_output`\r\nGet console output for a specific build\r\n- Parameters:\r\n  - `job_name`: Name of the job\r\n  - `build_number`: Build number to inspect\r\n\r\n### `get_views`\r\nList all Jenkins views\r\n\r\n### `trriger_llm_demo_job_build`\r\nTrigger the \"LLM_Demo\" job build\r\n- Parameters:\r\n  - `user`: User name to pass as build parameter\r\n\r\n## Example Usage\r\n\r\n```python\r\nfrom mcp.client import Client\r\n\r\nclient = Client(\"http://localhost:8000\")  # MCP server URL\r\nresponse = client.call_tool(\"list_jobs\")\r\nprint(response)\r\n```\r\n\r\n## License\r\n\r\nMIT\r\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "jenkins",
        "devops",
        "mcp",
        "devops cicd",
        "integrates jenkins",
        "mcp jenkins"
      ],
      "category": "devops-and-cicd"
    },
    "lumix-labs--swift": {
      "owner": "lumix-labs",
      "name": "swift",
      "url": "https://github.com/lumix-labs/swift",
      "imageUrl": "/freedevtools/mcp/pfp/lumix-labs.webp",
      "description": "Transforms legacy systems to enhance deployment speed and minimize incidents by enabling incremental modernization without extensive rewrites. Facilitates faster deployment cycles from weeks to days while reducing technical debt.",
      "stars": 4,
      "forks": 3,
      "license": "Apache License 2.0",
      "language": "TypeScript",
      "updated_at": "2025-06-23T07:11:41Z",
      "readme_content": "# Swift by Lumix Labs\n[![smithery badge](https://smithery.ai/badge/@lumix-labs/swift)](https://smithery.ai/server/@lumix-labs/swift)\n\n> Ship legacy code 5x faster. No rewrites. No regressions.  \n> Built by ex-Meta, OVO, and Paytm engineers.  \n> Used by growing teams to scale deployment velocity and slash production incidents.\n\nCurrent Version: [v0.x] – Early Access  \nTry it → [https://lumix-labs.github.io/swift](https://lumix-labs.github.io/swift)\n\n## About\n\nSwift by Lumix Labs helps engineering leaders transform legacy systems from innovation bottlenecks to competitive advantages. Deploy faster, reduce incidents, and modernize incrementally without risky rewrites or expensive consultants.\n\n## Key Features\n\n- Accelerate legacy deployment cycles from weeks to days\n- Reduce technical debt costs by up to 40%\n- Zero-disruption implementation\n- Cut legacy system incidents by 60%\n- Analyze repository composition with language and code quality metrics\n- Identify technical debt hotspots for targeted modernization\n\n## Setup Guide for Engineers\n\n### Prerequisites\n\n- [Docker Desktop](https://www.docker.com/products/docker-desktop/)\n- [Claude membership](https://claude.ai/)\n- Git\n\n### Installation Steps\n\n1. Clone the repository:\n   ```bash\n   git clone https://github.com/lumix-labs/swift.git\n   cd swift/mcp-server\n   ```\n\n2. Build the Docker image:\n   ```bash\n   ./build.sh\n   ```\n   This will create a Docker image named `lumix-labs/mcp-server` that you can see in Docker Desktop.\n\n### Connecting Claude to Swift\n\n1. Open Claude Desktop application\n2. Go to Settings → Developer → Edit Config\n3. Add the following configuration block:\n\n   ```json\n   {\n    \"mcpServers\": {\n     \"swift-mcp-server\": {\n       \"command\": \"docker\",\n       \"args\": [\n         \"run\",\n         \"-i\",\n         \"--rm\",\n         \"-v\",\n         \"/path/to/your/repo1:/repo1\",\n         \"-v\",\n         \"/path/to/your/repo2:/repo2\",\n         \"-w\",\n         \"/\",\n         \"lumixlabs/mcp-server\"\n       ]\n     }\n    }\n   }\n   ```\n\n4. Replace the paths in the `-v` arguments with the absolute paths to your local repositories:\n   - The format is: `/your/local/path:/mounted/path`\n   - For simplicity, the right side (mounted path) should be a simple name at the root level\n   - Example:\n     ```\n     \"-v\",\n     \"/Users/username/projects/my-app:/my-app\",\n     ```\n\n5. Save and restart Claude\n\nNow Claude is connected to your MCP server and can access your local repositories!\n\n## Available Tools\n\n- **Repo Analyzer**: Analyzes repository structure showing language distribution and code quality metrics\n- **Security Analyzer**: Scans for vulnerabilities and security issues in your codebase\n- **UUID Generator**: Generates UUIDs in various formats\n\n## Usage Examples\n\nAsk Claude to analyze a repository:\n```\nCan you analyze the repository at /my-repo using repo-analyzer with language analysis and code quality metrics?\n```\n\nScan for security vulnerabilities:\n```\nCan you scan /my-repo for security vulnerabilities focusing on credential detection and OWASP Top 10?\n```\n\nGenerate a UUID:\n```\nCan you generate a UUID for me?\n```\n\n## Contributing\n\nWe welcome contributions to Swift! Here's how you can help:\n\n### Setting Up Development Environment\n\n1. Fork the repository\n2. Clone your fork:\n   ```bash\n   git clone https://github.com/YOUR-USERNAME/swift.git\n   cd swift\n   ```\n\n3. Test locally:\n   ```bash\n   cd mcp-server\n   ./build.sh\n   ```\n\n### Development Workflow\n\n1. Create a feature branch:\n   ```bash\n   git checkout -b feature/your-feature-name\n   ```\n\n2. Make your changes and test locally\n3. Submit a pull request with:\n   - Clear description of changes\n   - Any relevant issue numbers\n   - Testing details\n\n### Project Areas Needing Help\n\n- Tool development (new analyzers or utilities)\n- Documentation improvements\n- Testing and quality assurance\n- Performance optimizations\n\n## Troubleshooting\n\nCommon issues and solutions:\n\n- **Docker build fails**: Ensure Docker Desktop is running and you have sufficient permissions\n- **Claude can't connect to Swift**: Verify your config.json syntax and restart Claude\n- **Repository not found**: Check the path mappings in your Claude configuration\n- **Permission denied errors**: Verify Docker has access to the mapped directories\n\n## Documentation\n\nVisit our [GitHub Pages site](https://lumix-labs.github.io/swift/) for complete documentation and guides.\n\n## 🚀 Get Cracked at Lumix\n\nWant to work on real problems, ship fast, and grow like you're at Meta—without the red tape?\n\nWe don’t do resumes. We do velocity.  \nJoin Swift as a contributor and become a cracked engineer.\n\n### What You Get\n- Contribute to real production systems\n- Mentorship from Ashwani (ex-Meta, Ovo)\n- Ship into prod from day 1\n- Get paid for high-impact work\n- Potential full-time roles\n\n### How to Start\n1. Visit the [issues page](https://github.com/lumix-labs/swift/issues)\n2. Pick one tagged `good-first-crack` or suggest your own\n3. Open a PR or comment on the issue\n4. If it ships, we talk 🚀\n\n🧠 Read more: [https://lumix-labs.github.io/swift/cracked](https://lumix-labs.github.io/swift/cracked)\n\n## 🛠 Contributors\n\nThis project is made better by every contributor.  \nWant your name here? [Get cracked](https://lumix-labs.github.io/swift/cracked) and make your first PR.\n\n- 🧑‍💻 Ashwani Karoriwal - Founder @ Lumix Labs\n\n## License\n\nSee the [LICENSE](LICENSE) file for details.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "devops",
        "deployment",
        "swift",
        "devops cicd",
        "legacy systems",
        "enhance deployment"
      ],
      "category": "devops-and-cicd"
    },
    "mrrobotke--django-migrations-mcp": {
      "owner": "mrrobotke",
      "name": "django-migrations-mcp",
      "url": "https://github.com/mrrobotke/django-migrations-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/mrrobotke.webp",
      "description": "Manage Django migrations in distributed environments through MCP endpoints, simplifying migration processes with validations and safety checks for CI/CD integration.",
      "stars": 5,
      "forks": 2,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-07-17T09:12:29Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/mrrobotke-django-migrations-mcp-badge.png)](https://mseep.ai/app/mrrobotke-django-migrations-mcp)\n\n# Django Migrations MCP Service\n\nA Model Context Protocol (MCP) service for managing Django migrations in distributed environments. This service wraps Django's migration commands and exposes them as MCP endpoints, making it easy to manage migrations across multiple services and integrate with CI/CD pipelines.\n\n## Features\n\n- Check migration status (equivalent to `showmigrations`)\n- Create new migrations with validation (equivalent to `makemigrations`)\n- Apply migrations with safety checks (equivalent to `migrate`)\n- Additional validation and safety checks:\n  - Sequential migration order verification\n  - Conflict detection\n  - Dependency validation\n  - Safety analysis of migration operations\n\n## Installation\n\n### Local Development\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/mrrobotke/django-migrations-mcp.git\ncd django-migrations-mcp\n```\n\n2. Install dependencies:\n```bash\npip install -r requirements.txt\n```\n\n## Configuration\n\nSet the following environment variables:\n\n```bash\nexport DJANGO_SETTINGS_MODULE=\"your_project.settings\"\nexport MCP_SERVICE_PORT=8000  # Optional, defaults to 8000\n```\n\n## Usage\n\n### Running the Service\n\n1. Directly with Python:\n```bash\npython -m migrations_mcp.service\n```\n\n2. Using Docker:\n```bash\ndocker build -t django-migrations-mcp .\ndocker run -e DJANGO_SETTINGS_MODULE=your_project.settings \\\n          -v /path/to/your/django/project:/app/project \\\n          -p 8000:8000 \\\n          django-migrations-mcp\n```\n\n### MCP Endpoints\n\n1. Show Migrations:\n```python\nfrom mcp import MCPClient\n\nclient = MCPClient()\nmigrations = await client.call(\"show_migrations\")\n```\n\n2. Make Migrations:\n```python\nresult = await client.call(\"make_migrations\", {\n    \"app_labels\": [\"myapp\"],  # Optional\n    \"dry_run\": True  # Optional\n})\n```\n\n3. Apply Migrations:\n```python\nresult = await client.call(\"migrate\", {\n    \"app_label\": \"myapp\",  # Optional\n    \"migration_name\": \"0001\",  # Optional\n    \"fake\": False,  # Optional\n    \"plan\": True  # Optional\n})\n```\n\n## CI/CD Integration\n\nExample GitHub Actions workflow:\n\n```yaml\nname: Django Migrations Check\n\non:\n  pull_request:\n    paths:\n      - '*/migrations/*.py'\n      - '*/models.py'\n\njobs:\n  check-migrations:\n    runs-on: ubuntu-latest\n    \n    steps:\n    - uses: actions/checkout@v2\n    \n    - name: Set up Python\n      uses: actions/setup-python@v2\n      with:\n        python-version: '3.11'\n    \n    - name: Install dependencies\n      run: |\n        pip install -r requirements.txt\n    \n    - name: Start MCP service\n      run: |\n        python -m migrations_mcp.service &\n    \n    - name: Check migrations\n      run: |\n        python ci/check_migrations.py\n```\n\nExample check_migrations.py script:\n\n```python\nimport asyncio\nfrom mcp import MCPClient\n\nasync def check_migrations():\n    client = MCPClient()\n    \n    # Check current status\n    migrations = await client.call(\"show_migrations\")\n    \n    # Try making migrations\n    result = await client.call(\"make_migrations\", {\"dry_run\": True})\n    if not result.success:\n        print(f\"Error: {result.message}\")\n        exit(1)\n    \n    print(\"Migration check passed!\")\n\nif __name__ == \"__main__\":\n    asyncio.run(check_migrations())\n```\n\n## Development\n\n### Running Tests\n\n```bash\npytest migrations_mcp/tests/\n```\n\n### Code Style\n\nThe project follows PEP 8 guidelines. Format your code using:\n\n```bash\nblack migrations_mcp/\nisort migrations_mcp/\n```\n\n## License\n\nMIT License. See LICENSE file for details.\n\n## Contributing\n\n1. Fork the repository\n2. Create your feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n\n## Docker Usage\n\nThe project includes a `docker-commands.json` file that provides structured commands for different deployment scenarios. You can use these commands directly or parse them in your scripts.\n\n### Available Docker Configurations\n\n1. **Redis MCP Server**\n```bash\n# Run Redis MCP server\ndocker run -i --rm mcp/redis redis://host.docker.internal:6379\n```\n\n2. **Django Migrations MCP Server**\n```bash\n# Basic setup\ndocker run -d \\\n  --name django-migrations-mcp \\\n  -e DJANGO_SETTINGS_MODULE=your_project.settings \\\n  -e MCP_SERVICE_PORT=8000 \\\n  -v /path/to/your/django/project:/app/project \\\n  -p 8000:8000 \\\n  django-migrations-mcp\n\n# With Redis integration\ndocker run -d \\\n  --name django-migrations-mcp \\\n  -e DJANGO_SETTINGS_MODULE=your_project.settings \\\n  -e MCP_SERVICE_PORT=8000 \\\n  -e REDIS_URL=redis://host.docker.internal:6379 \\\n  -v /path/to/your/django/project:/app/project \\\n  -p 8000:8000 \\\n  --network host \\\n  django-migrations-mcp\n```\n\n3. **Development Environment**\n```bash\n# Using docker-compose\ndocker-compose up -d --build\n```\n\n4. **Testing Environment**\n```bash\n# Run tests in container\ndocker run --rm \\\n  -e DJANGO_SETTINGS_MODULE=your_project.settings \\\n  -e PYTHONPATH=/app \\\n  -v ${PWD}:/app \\\n  django-migrations-mcp \\\n  pytest\n```\n\n5. **Production Environment**\n```bash\n# Production setup with health check\ndocker run -d \\\n  --name django-migrations-mcp \\\n  -e DJANGO_SETTINGS_MODULE=your_project.settings \\\n  -e MCP_SERVICE_PORT=8000 \\\n  -e REDIS_URL=redis://your-redis-host:6379 \\\n  -v /path/to/your/django/project:/app/project \\\n  -p 8000:8000 \\\n  --restart unless-stopped \\\n  --network your-network \\\n  django-migrations-mcp\n```\n\n### Using the Commands Programmatically\n\nYou can parse and use the commands programmatically:\n\n```python\nimport json\nimport subprocess\n\n# Load commands\nwith open('docker-commands.json') as f:\n    commands = json.load(f)\n\n# Run Redis MCP server\nredis_config = commands['mcpServers']['redis']\nsubprocess.run([redis_config['command']] + redis_config['args'])\n\n# Run Django Migrations MCP server\ndjango_config = commands['mcpServers']['djangoMigrations']\nsubprocess.run([django_config['command']] + django_config['args'])\n```\n\n### Network Setup\n\n1. **Development Network**\n```bash\ndocker network create mcp-dev-network\n```\n\n2. **Production Network**\n```bash\ndocker network create --driver overlay --attachable mcp-prod-network\n```\n\n### Using MCP Tools\n\nThe service exposes several endpoints that can be accessed via curl or any HTTP client:\n\n1. **Show Migrations**\n```bash\ncurl -X POST http://localhost:8000/mcp \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"method\": \"show_migrations\"}'\n```\n\n2. **Make Migrations**\n```bash\ncurl -X POST http://localhost:8000/mcp \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"method\": \"make_migrations\", \"params\": {\"apps\": [\"your_app\"]}}'\n```\n\n3. **Apply Migrations**\n```bash\ncurl -X POST http://localhost:8000/mcp \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"method\": \"migrate\", \"params\": {\"app\": \"your_app\"}}'\n``` ",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "migrations",
        "devops",
        "django",
        "django migrations",
        "migrations mcp",
        "migrations distributed"
      ],
      "category": "devops-and-cicd"
    },
    "punprapor--punprapor": {
      "owner": "punprapor",
      "name": "punprapor",
      "url": "https://github.com/punprapor/punprapor",
      "imageUrl": "/freedevtools/mcp/pfp/punprapor.webp",
      "description": "Connect with a community focused on enhancing DevOps skills through practical insights and collaborative opportunities. Engage with like-minded individuals to foster growth in various tech initiatives.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "",
      "updated_at": "2022-03-31T07:58:47Z",
      "readme_content": "- 👋 Hi, I’m Dmitry from Belarus.\n- 👀 I’m interested in DevOps, SEO, Marketing and Project Management.\n- 🌱 I’m currently learning DevOps Fundamentals EPAM course and reaching B1 English level.\n- 💞️ I want to collaborate with people who want to change this world like me.\n- 📫 The better way to reach me - is to send me an email (punprapor@gmail.com), it might be weird, but messengers are overloaded nowadays 🤯. By this nickname you also can find me on Skype, and by the reverse nickname 🙃 (from \"r\" to \"p\") - in Telegram if you want.\n\n<!---\npunprapor/punprapor is a ✨ special ✨ repository because its `README.md` (this file) appears on your GitHub profile.\nYou can click the Preview link to take a look at your changes.\n--->\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "devops",
        "tech",
        "punprapor",
        "devops skills",
        "devops cicd",
        "enhancing devops"
      ],
      "category": "devops-and-cicd"
    },
    "sapientpants--sonarqube-mcp-server": {
      "owner": "sapientpants",
      "name": "sonarqube-mcp-server",
      "url": "https://github.com/sapientpants/sonarqube-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/sapientpants.webp",
      "description": "Integrates with SonarQube to provide access to code quality metrics, detect issues, and analyze results for AI assistants.",
      "stars": 96,
      "forks": 15,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-29T20:22:00Z",
      "readme_content": "# SonarQube MCP Server\n\n[](https://github.com/sapientpants/sonarqube-mcp-server/actions/workflows/ci.yml)\n[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=sonarqube-mcp-server&metric=alert_status)](https://sonarcloud.io/summary/new_code?id=sonarqube-mcp-server)\n[![Bugs](https://sonarcloud.io/api/project_badges/measure?project=sonarqube-mcp-server&metric=bugs)](https://sonarcloud.io/summary/new_code?id=sonarqube-mcp-server)\n[![Code Smells](https://sonarcloud.io/api/project_badges/measure?project=sonarqube-mcp-server&metric=code_smells)](https://sonarcloud.io/summary/new_code?id=sonarqube-mcp-server)\n[![Coverage](https://sonarcloud.io/api/project_badges/measure?project=sonarqube-mcp-server&metric=coverage)](https://sonarcloud.io/summary/new_code?id=sonarqube-mcp-server)\n[![Duplicated Lines (%)](https://sonarcloud.io/api/project_badges/measure?project=sonarqube-mcp-server&metric=duplicated_lines_density)](https://sonarcloud.io/summary/new_code?id=sonarqube-mcp-server)\n[![npm version](https://img.shields.io/npm/v/sonarqube-mcp-server.svg)](https://www.npmjs.com/package/sonarqube-mcp-server)\n[![npm downloads](https://img.shields.io/npm/dm/sonarqube-mcp-server.svg)](https://www.npmjs.com/package/sonarqube-mcp-server)\n[![License](https://img.shields.io/npm/l/sonarqube-mcp-server.svg)](https://github.com/sapientpants/sonarqube-mcp-server/blob/main/LICENSE)\n\nA Model Context Protocol (MCP) server that integrates with SonarQube to provide AI assistants with access to code quality metrics, issues, and analysis results.\n\n## Table of Contents\n\n- [Overview](#overview)\n- [Documentation](#documentation)\n- [Compatibility](#compatibility)\n- [Quick Start](#quick-start)\n- [Installation](#installation)\n  - [NPX](#npx-recommended)\n  - [Docker](#docker-recommended-for-production)\n  - [Local Development](#local-development)\n- [Configuration](#configuration)\n  - [Environment Variables](#environment-variables)\n  - [Authentication Methods](#authentication-methods)\n- [Available Tools](#available-tools)\n- [Usage Examples](#usage-examples)\n- [Architecture](#architecture)\n- [Development](#development)\n- [Troubleshooting](#troubleshooting)\n- [Contributing](#contributing)\n- [License](#license)\n- [External Resources](#external-resources)\n\n## Overview\n\nThe SonarQube MCP Server enables AI assistants to interact with SonarQube's code quality analysis capabilities through the Model Context Protocol. This integration allows AI assistants to:\n\n- 📊 **Retrieve code metrics and analysis results** - Access detailed quality metrics for your projects\n- 🐛 **Access and filter issues** - Search and filter code issues by severity, type, status, and more\n- 🔒 **Review security hotspots** - Find and manage security vulnerabilities with dedicated workflows\n- 🌿 **Analyze branches and PRs** - Review code quality in feature branches and pull requests\n- 📦 **Multi-project analysis** - Query issues and metrics across multiple projects simultaneously\n- ✅ **Check quality gates** - Monitor whether projects meet quality standards\n- 📈 **Analyze project quality over time** - Track metrics history and trends\n- 🔍 **View source code with issues** - See problematic code with highlighted issues\n- 🏥 **Monitor system health** - Check SonarQube instance status and availability\n- 🔄 **Enhanced error handling** - Clear error messages with solutions and automatic retry for transient failures\n\n## Documentation\n\n### Core Guides\n\n- **[Architecture Guide](docs/architecture.md)** - System architecture, design decisions, and component overview\n- **[Troubleshooting Guide](docs/troubleshooting.md)** - Common issues, debugging, and solutions\n\n### Security & Authentication\n\n- **[Security Guide](docs/security.md)** - Authentication, authorization, and security best practices\n\n## Compatibility\n\nFor detailed information about MCP protocol version support and SDK compatibility, see [COMPATIBILITY.md](COMPATIBILITY.md).\n\n## Quick Start\n\n### Prerequisites\n\n- [Claude Desktop](https://claude.ai/download) installed\n- A SonarQube instance or [SonarCloud](https://sonarcloud.io) account\n- A SonarQube/SonarCloud authentication token\n\n### 1. Get Your SonarQube Token\n\n**For SonarCloud:**\n\n1. Log in to [SonarCloud](https://sonarcloud.io)\n2. Go to **My Account** → **Security**\n3. Generate a new token\n\n**For SonarQube:**\n\n1. Log in to your SonarQube instance\n2. Go to **My Account** → **Security**\n3. Generate a new token\n\n### 2. Configure Claude Desktop\n\n1. Open Claude Desktop\n2. Go to **Settings** → **Developer** → **Edit Config**\n3. Add the SonarQube server configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"sonarqube\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"sonarqube-mcp-server@latest\"],\n      \"env\": {\n        \"SONARQUBE_URL\": \"https://sonarcloud.io\",\n        \"SONARQUBE_TOKEN\": \"your-token-here\",\n        \"SONARQUBE_ORGANIZATION\": \"your-org (for SonarCloud)\"\n      }\n    }\n  }\n}\n```\n\n**Alternative authentication methods:**\n\nUsing Basic Authentication:\n\n```json\n{\n  \"mcpServers\": {\n    \"sonarqube\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"sonarqube-mcp-server@latest\"],\n      \"env\": {\n        \"SONARQUBE_URL\": \"https://your-sonarqube.com\",\n        \"SONARQUBE_USERNAME\": \"your-username\",\n        \"SONARQUBE_PASSWORD\": \"your-password\"\n      }\n    }\n  }\n}\n```\n\nUsing System Passcode:\n\n```json\n{\n  \"mcpServers\": {\n    \"sonarqube\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"sonarqube-mcp-server@latest\"],\n      \"env\": {\n        \"SONARQUBE_URL\": \"https://your-sonarqube.com\",\n        \"SONARQUBE_PASSCODE\": \"your-system-passcode\"\n      }\n    }\n  }\n}\n```\n\n1. Restart Claude Desktop\n\n### 3. Start Using\n\nAsk Claude to analyze your SonarQube projects:\n\n```\n\"List all my SonarQube projects\"\n\"Show me critical issues in project xyz\"\n\"What's the code coverage for project xyz?\"\n\"Check the quality gate status for project xyz\"\n\"Retrieve security hotspots in project xyz and create a plan to address them\"\n\"Retrieve the issues for pr 123 in project xyz and create a plan to address them\"\n```\n\n## Installation\n\n### NPX (Recommended)\n\nThe simplest way to use the SonarQube MCP Server is through npx:\n\n```json\n{\n  \"mcpServers\": {\n    \"sonarqube\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"sonarqube-mcp-server@latest\"],\n      \"env\": {\n        \"SONARQUBE_URL\": \"https://sonarqube.example.com\",\n        \"SONARQUBE_TOKEN\": \"your-sonarqube-token\",\n        \"SONARQUBE_ORGANIZATION\": \"your-organization-key\"\n      }\n    }\n  }\n}\n```\n\n### Docker (Recommended for Production)\n\nDocker provides the most reliable deployment method by packaging all dependencies and ensuring consistent behavior across different environments.\n\n> **Enterprise Deployment**: For production deployments with Kubernetes, Helm charts, and cloud-specific configurations, see our comprehensive [Deployment Guide](docs/deployment.md).\n\n#### Quick Start with Docker\n\n**For stdio transport (Claude Desktop):**\n\n```json\n{\n  \"mcpServers\": {\n    \"sonarqube\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-e\",\n        \"SONARQUBE_URL\",\n        \"-e\",\n        \"SONARQUBE_TOKEN\",\n        \"-e\",\n        \"SONARQUBE_ORGANIZATION\",\n        \"sapientpants/sonarqube-mcp-server:latest\"\n      ],\n      \"env\": {\n        \"SONARQUBE_URL\": \"https://sonarqube.example.com\",\n        \"SONARQUBE_TOKEN\": \"your-sonarqube-token\",\n        \"SONARQUBE_ORGANIZATION\": \"your-organization-key\"\n      }\n    }\n  }\n}\n```\n\n#### Docker Hub Images\n\nOfficial images are available on Docker Hub: [`sapientpants/sonarqube-mcp-server`](https://hub.docker.com/r/sapientpants/sonarqube-mcp-server)\n\n**Available tags:**\n\n- `latest` - Latest stable release\n- `1.6.0` - Specific version (recommended for production)\n- `1.6` - Latest patch version of 1.6.x\n- `1` - Latest minor version of 1.x.x\n\n**Pull the image:**\n\n```bash\ndocker pull sapientpants/sonarqube-mcp-server:latest\n```\n\n#### Advanced Docker Configuration\n\n**With logging enabled:**\n\n```json\n{\n  \"mcpServers\": {\n    \"sonarqube\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-v\",\n        \"/tmp/sonarqube-logs:/logs\",\n        \"-e\",\n        \"SONARQUBE_URL\",\n        \"-e\",\n        \"SONARQUBE_TOKEN\",\n        \"-e\",\n        \"SONARQUBE_ORGANIZATION\",\n        \"-e\",\n        \"LOG_FILE=/logs/sonarqube-mcp.log\",\n        \"-e\",\n        \"LOG_LEVEL=INFO\",\n        \"sapientpants/sonarqube-mcp-server:latest\"\n      ],\n      \"env\": {\n        \"SONARQUBE_URL\": \"https://sonarqube.example.com\",\n        \"SONARQUBE_TOKEN\": \"your-sonarqube-token\",\n        \"SONARQUBE_ORGANIZATION\": \"your-organization-key\"\n      }\n    }\n  }\n}\n```\n\n**Using Docker Compose:**\n\n```yaml\nversion: '3.8'\nservices:\n  sonarqube-mcp:\n    image: sapientpants/sonarqube-mcp-server:latest\n    environment:\n      - SONARQUBE_URL=https://sonarqube.example.com\n      - SONARQUBE_TOKEN=${SONARQUBE_TOKEN}\n      - SONARQUBE_ORGANIZATION=${SONARQUBE_ORGANIZATION}\n      - LOG_FILE=/logs/sonarqube-mcp.log\n      - LOG_LEVEL=INFO\n    volumes:\n      - ./logs:/logs\n    stdin_open: true\n    tty: true\n```\n\n#### Building Your Own Docker Image\n\nIf you need to customize the server, you can build your own image:\n\n```bash\n# Clone the repository\ngit clone https://github.com/sapientpants/sonarqube-mcp-server.git\ncd sonarqube-mcp-server\n\n# Build the Docker image\ndocker build -t my-sonarqube-mcp-server .\n\n# Run your custom image\ndocker run -i --rm \\\n  -e SONARQUBE_URL=\"https://sonarqube.example.com\" \\\n  -e SONARQUBE_TOKEN=\"your-token\" \\\n  my-sonarqube-mcp-server\n```\n\n#### Docker Best Practices\n\n1. **Version Pinning**: Always use specific version tags in production:\n\n   ```bash\n   sapientpants/sonarqube-mcp-server:1.6.0\n   ```\n\n2. **Resource Limits**: Set appropriate resource limits:\n\n   ```bash\n   docker run -i --rm \\\n     --memory=\"256m\" \\\n     --cpus=\"0.5\" \\\n     sapientpants/sonarqube-mcp-server:1.6.0\n   ```\n\n3. **Security**: Run as non-root user (default in our image):\n\n   ```bash\n   docker run -i --rm \\\n     --user node \\\n     sapientpants/sonarqube-mcp-server:1.6.0\n   ```\n\n4. **Health Checks**: The container includes a health check that verifies the Node.js process is running\n\n### Local Development\n\nFor development or customization:\n\n```json\n{\n  \"mcpServers\": {\n    \"sonarqube\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/sonarqube-mcp-server/dist/index.js\"],\n      \"env\": {\n        \"SONARQUBE_URL\": \"https://sonarqube.example.com\",\n        \"SONARQUBE_TOKEN\": \"your-sonarqube-token\",\n        \"SONARQUBE_ORGANIZATION\": \"your-organization-key\"\n      }\n    }\n  }\n}\n```\n\n## Configuration\n\n### Environment Variables\n\n#### Authentication (choose one method)\n\n| Variable                 | Description                                   | Required | Default |\n| ------------------------ | --------------------------------------------- | -------- | ------- |\n| **Token Authentication** |                                               |          |         |\n| `SONARQUBE_TOKEN`        | Authentication token for SonarQube API access | ✅ Yes\\* | -       |\n| **Basic Authentication** |                                               |          |         |\n| `SONARQUBE_USERNAME`     | Username for Basic authentication             | ✅ Yes\\* | -       |\n| `SONARQUBE_PASSWORD`     | Password for Basic authentication             | ✅ Yes\\* | -       |\n| **System Passcode**      |                                               |          |         |\n| `SONARQUBE_PASSCODE`     | System passcode for SonarQube authentication  | ✅ Yes\\* | -       |\n\n\\*One authentication method is required. Token authentication takes priority if multiple methods are configured.\n\n#### Connection Settings\n\n| Variable                 | Description                                              | Required  | Default                 |\n| ------------------------ | -------------------------------------------------------- | --------- | ----------------------- |\n| `SONARQUBE_URL`          | URL of your SonarQube instance                           | ❌ No     | `https://sonarcloud.io` |\n| `SONARQUBE_ORGANIZATION` | Organization key (required for SonarCloud)               | ❌ No\\*\\* | -                       |\n| `LOG_FILE`               | Path to write log files (e.g., `/tmp/sonarqube-mcp.log`) | ❌ No     | -                       |\n| `LOG_LEVEL`              | Minimum log level (DEBUG, INFO, WARN, ERROR)             | ❌ No     | `DEBUG`                 |\n\n\\*\\*Required when using SonarCloud\n\n#### HTTP Transport Settings (Advanced)\n\nBy default, the server uses stdio transport for communication with Claude Desktop. For programmatic access or running as a web service, HTTP transport is available:\n\n| Variable                                   | Description                                  | Required | Default     |\n| ------------------------------------------ | -------------------------------------------- | -------- | ----------- |\n| `MCP_TRANSPORT_TYPE`                       | Transport type (`stdio` or `http`)           | ❌ No    | `stdio`     |\n| `MCP_HTTP_PORT`                            | Port for HTTP server                         | ❌ No    | `3000`      |\n| `MCP_HTTP_SESSION_TIMEOUT`                 | Session timeout in milliseconds              | ❌ No    | `1800000`   |\n| `MCP_HTTP_ALLOWED_HOSTS`                   | Comma-separated list of allowed hosts        | ❌ No    | `localhost` |\n| `MCP_HTTP_ALLOWED_ORIGINS`                 | Comma-separated list of allowed CORS origins | ❌ No    | `*`         |\n| `MCP_HTTP_ENABLE_DNS_REBINDING_PROTECTION` | Enable DNS rebinding protection              | ❌ No    | `false`     |\n\n### Authentication Methods\n\nThe server supports three authentication methods, with important differences between SonarQube versions:\n\n#### 1. Token Authentication (Recommended)\n\n##### SonarQube 10.0+ (Bearer Token)\n\n- Starting with SonarQube 10.0, Bearer token authentication is the recommended approach\n- Most secure and flexible option\n- Tokens can have limited permissions\n- Configuration:\n  ```json\n  {\n    \"env\": {\n      \"SONARQUBE_TOKEN\": \"your-token-here\"\n    }\n  }\n  ```\n\n##### SonarQube < 10.0 (Token as Username)\n\n- For versions before 10.0, tokens must be sent as the username in Basic authentication\n- No password is required when using a token as username\n- The server automatically handles this based on your SonarQube version\n- Configuration remains the same - just use `SONARQUBE_USERNAME` with the token value:\n  ```json\n  {\n    \"env\": {\n      \"SONARQUBE_USERNAME\": \"your-token-here\"\n    }\n  }\n  ```\n\n#### 2. Basic Authentication\n\n- Traditional username and password authentication\n- Suitable for self-hosted SonarQube instances\n- May not work with SonarCloud if 2FA is enabled\n- Configuration:\n  ```json\n  {\n    \"env\": {\n      \"SONARQUBE_USERNAME\": \"your-username\",\n      \"SONARQUBE_PASSWORD\": \"your-password\"\n    }\n  }\n  ```\n\n#### 3. System Passcode\n\n- Special authentication for SonarQube system administration\n- Typically used for automated deployment scenarios\n- Configuration:\n  ```json\n  {\n    \"env\": {\n      \"SONARQUBE_PASSCODE\": \"your-system-passcode\"\n    }\n  }\n  ```\n\n**Note:** Token authentication takes priority if multiple authentication methods are configured. The server will automatically use the appropriate authentication strategy based on your SonarQube version.\n\n### SonarCloud vs SonarQube\n\n**For SonarCloud:**\n\n- Set `SONARQUBE_URL` to `https://sonarcloud.io`\n- `SONARQUBE_ORGANIZATION` is required\n- Token authentication is recommended\n\n**For SonarQube Server:**\n\n- Set `SONARQUBE_URL` to your instance URL\n- `SONARQUBE_ORGANIZATION` is typically not needed\n- All authentication methods are supported\n\n### HTTP Transport Mode\n\nThe server supports HTTP transport for programmatic access and web service deployments. This enables integration with custom clients and web applications.\n\n#### Running as an HTTP Server\n\nStart the server with HTTP transport:\n\n```bash\n# Using environment variables\nMCP_TRANSPORT_TYPE=http MCP_HTTP_PORT=3000 npx sonarqube-mcp-server\n\n# With Docker\ndocker run -i --rm \\\n  -p 3000:3000 \\\n  -e MCP_TRANSPORT_TYPE=http \\\n  -e MCP_HTTP_PORT=3000 \\\n  -e SONARQUBE_URL=https://sonarcloud.io \\\n  -e SONARQUBE_TOKEN=your-token \\\n  sapientpants/sonarqube-mcp-server:latest\n```\n\n#### HTTP API Endpoints\n\nWhen running in HTTP mode, the server exposes the following endpoints:\n\n- `GET /health` - Health check endpoint\n- `POST /session` - Create a new session\n- `DELETE /session/:sessionId` - Close a session\n- `POST /mcp` - Execute MCP requests\n- `GET /events/:sessionId` - Server-sent events for notifications\n\n#### Example HTTP Client\n\nSee [examples/http-client.ts](examples/http-client.ts) for a complete TypeScript client example.\n\nBasic usage with curl:\n\n```bash\n# Health check\ncurl http://localhost:3000/health\n\n# Create session\nSESSION_ID=$(curl -X POST http://localhost:3000/session | jq -r .sessionId)\n\n# Execute MCP request\ncurl -X POST http://localhost:3000/mcp \\\n  -H \"Content-Type: application/json\" \\\n  -d \"{\n    \\\"sessionId\\\": \\\"$SESSION_ID\\\",\n    \\\"method\\\": \\\"tools/list\\\",\n    \\\"params\\\": {}\n  }\"\n\n# Close session\ncurl -X DELETE http://localhost:3000/session/$SESSION_ID\n```\n\n#### Security Considerations\n\nWhen running in HTTP mode:\n\n1. **Enable DNS rebinding protection** for public deployments:\n\n   ```bash\n   MCP_HTTP_ENABLE_DNS_REBINDING_PROTECTION=true\n   ```\n\n2. **Configure CORS** for browser-based clients:\n\n   ```bash\n   MCP_HTTP_ALLOWED_ORIGINS=https://yourapp.com,https://anotherapp.com\n   ```\n\n3. **Set session timeouts** appropriately:\n\n   ```bash\n   MCP_HTTP_SESSION_TIMEOUT=900000  # 15 minutes\n   ```\n\n4. **Use HTTPS** in production (configure through a reverse proxy like nginx)\n\n### Elicitation Configuration (Experimental)\n\nThe server supports interactive user input through MCP's elicitation capability. This feature is opt-in and requires compatible MCP clients.\n\n**Environment Variables:**\n\n- `SONARQUBE_MCP_ELICITATION`: Set to `true` to enable elicitation\n- `SONARQUBE_MCP_BULK_THRESHOLD`: Number of items before confirmation (default: 5)\n- `SONARQUBE_MCP_REQUIRE_COMMENTS`: Set to `true` to require comments for resolutions\n- `SONARQUBE_MCP_INTERACTIVE_SEARCH`: Set to `true` for interactive disambiguation\n\n**Example Configuration:**\n\n```json\n{\n  \"mcpServers\": {\n    \"sonarqube\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"sonarqube-mcp-server@latest\"],\n      \"env\": {\n        \"SONARQUBE_URL\": \"https://sonarcloud.io\",\n        \"SONARQUBE_TOKEN\": \"your-token\",\n        \"SONARQUBE_MCP_ELICITATION\": \"true\",\n        \"SONARQUBE_MCP_BULK_THRESHOLD\": \"10\",\n        \"SONARQUBE_MCP_REQUIRE_COMMENTS\": \"true\"\n      }\n    }\n  }\n}\n```\n\n**Features When Enabled:**\n\n1. **Bulk Operation Confirmation**: Prompts for confirmation before marking multiple issues\n2. **Comment Collection**: Collects explanatory comments when marking issues as false positive or won't fix\n3. **Authentication Setup**: Guides through authentication setup when credentials are missing\n4. **Search Disambiguation**: Helps select from multiple matching components or projects\n\n**Note:** This feature requires MCP clients that support elicitation. Not all clients may support this capability.\n\n### Logging Configuration\n\nThe server supports file-based logging for debugging and monitoring. Since MCP servers use stdout for protocol communication, logs are written to a file instead of stdout/stderr to avoid interference.\n\n**Enable Logging:**\n\n```json\n{\n  \"mcpServers\": {\n    \"sonarqube\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"sonarqube-mcp-server@latest\"],\n      \"env\": {\n        \"SONARQUBE_URL\": \"https://sonarcloud.io\",\n        \"SONARQUBE_TOKEN\": \"your-token-here\",\n        \"SONARQUBE_ORGANIZATION\": \"your-org\",\n        \"LOG_FILE\": \"/tmp/sonarqube-mcp.log\",\n        \"LOG_LEVEL\": \"INFO\"\n      }\n    }\n  }\n}\n```\n\n**Log Levels:**\n\n- `DEBUG`: Detailed information for debugging\n- `INFO`: General information about server operation\n- `WARN`: Warning events that might lead to issues\n- `ERROR`: Error events (server continues running)\n\n**Example Log Output:**\n\n```\n2024-01-15T10:30:45.123Z INFO [index] Starting SonarQube MCP server\n2024-01-15T10:30:45.234Z INFO [index] Environment variables validated successfully\n2024-01-15T10:30:45.345Z INFO [index] SonarQube client created successfully\n2024-01-15T10:30:45.456Z INFO [index] SonarQube MCP server started successfully\n2024-01-15T10:30:50.123Z DEBUG [index] Handling SonarQube projects request\n2024-01-15T10:30:50.567Z INFO [index] Successfully retrieved projects {\"count\": 5}\n```\n\n## Available Tools\n\n### Permission Requirements\n\nDifferent SonarQube tools require different permission levels:\n\n**Tools requiring Admin permissions:**\n\n- `projects` - Lists all SonarQube projects with metadata (visibility, lastAnalysisDate, revision)\n\n**Tools accessible to all users:**\n\n- `components` - Search and navigate projects, directories, and files (requires 'Browse' permission on at least one project)\n- All other tools require appropriate permissions based on the resources being accessed\n\n#### Listing Projects\n\n**For Administrators:**\nUse the `projects` tool to get full project metadata including visibility, last analysis date, and revision info.\n\n**For All Users:**\nUse the `components` tool with project qualifier:\n\n- \"List all projects I have access to\" → `components` with `qualifiers: ['TRK']`\n- \"Search for projects containing 'mobile'\" → `components` with `query: 'mobile', qualifiers: ['TRK']`\n\nThe `components` tool provides a more accessible alternative for non-admin users to discover projects they have access to.\n\n### Project Management\n\n#### `projects`\n\nList all SonarQube projects with pagination support.\n\n**Parameters:**\n\n- `page` (optional): Page number for results pagination\n- `page_size` (optional): Number of items per page\n\n### Metrics and Measures\n\n#### `metrics`\n\nGet available metrics from SonarQube.\n\n**Parameters:**\n\n- `page` (optional): Page number for results pagination\n- `page_size` (optional): Number of items per page\n\n#### `measures_component`\n\nGet measures for a specific component.\n\n**Parameters:**\n\n- `component` (required): Component key\n- `metric_keys` (required): Array of metric keys\n- `additional_fields` (optional): Additional fields to return\n- `branch` (optional): Branch name\n- `pull_request` (optional): Pull request key\n- `period` (optional): Period index\n\n#### `measures_components`\n\nGet measures for multiple components.\n\n**Parameters:**\n\n- `component_keys` (required): Array of component keys\n- `metric_keys` (required): Array of metric keys\n- Additional parameters same as `measures_component`\n- `page` (optional): Page number\n- `page_size` (optional): Items per page\n\n#### `measures_history`\n\nGet measures history for a component.\n\n**Parameters:**\n\n- `component` (required): Component key\n- `metrics` (required): Array of metric keys\n- `from` (optional): Start date (YYYY-MM-DD)\n- `to` (optional): End date (YYYY-MM-DD)\n- `branch` (optional): Branch name\n- `pull_request` (optional): Pull request key\n- `page` (optional): Page number\n- `page_size` (optional): Items per page\n\n### Issue Management\n\n#### `issues`\n\nSearch and filter SonarQube issues by severity, status, assignee, tag, file path, and more. Critical for dashboards, targeted clean-up sprints, security audits, and regression testing. Supports faceted search for aggregations.\n\n**Component/File Path Filters:**\n\n- `project_key` (optional): Single project key (backward compatible)\n- `projects` (optional): Array of project keys for multi-project analysis\n- `component_keys` (optional): Array of component keys (file paths, directories, or modules) - use this to filter issues by specific files or folders\n- `components` (optional): Alias for component_keys\n- `on_component_only` (optional): Boolean to return only issues on specified components, not sub-components\n\n**Branch/PR Support:**\n\n- `branch` (optional): Branch name for branch analysis\n- `pull_request` (optional): Pull request ID for PR analysis\n\n**Issue Filters:**\n\n- `issues` (optional): Array of specific issue keys to retrieve\n- `severity` (optional): Single severity (deprecated, use severities)\n- `severities` (optional): Array of severities (INFO, MINOR, MAJOR, CRITICAL, BLOCKER)\n- `statuses` (optional): Array of statuses (OPEN, CONFIRMED, REOPENED, RESOLVED, CLOSED)\n- `resolutions` (optional): Array of resolutions (FALSE-POSITIVE, WONTFIX, FIXED, REMOVED)\n- `resolved` (optional): Boolean filter for resolved/unresolved\n- `types` (optional): Array of types (CODE_SMELL, BUG, VULNERABILITY, SECURITY_HOTSPOT)\n\n**Clean Code Taxonomy (SonarQube 10.x+):**\n\n- `clean_code_attribute_categories` (optional): Array (ADAPTABLE, CONSISTENT, INTENTIONAL, RESPONSIBLE)\n- `impact_severities` (optional): Array (HIGH, MEDIUM, LOW)\n- `impact_software_qualities` (optional): Array (MAINTAINABILITY, RELIABILITY, SECURITY)\n- `issue_statuses` (optional): Array of new issue status values\n\n**Rules and Tags:**\n\n- `rules` (optional): Array of rule keys\n- `tags` (optional): Array of issue tags - essential for security audits, regression testing, and categorized analysis\n\n**Date Filters:**\n\n- `created_after` (optional): Issues created after date (YYYY-MM-DD)\n- `created_before` (optional): Issues created before date (YYYY-MM-DD)\n- `created_at` (optional): Issues created on date (YYYY-MM-DD)\n- `created_in_last` (optional): Issues created in last period (e.g., \"30d\", \"1m\")\n\n**Assignment:**\n\n- `assigned` (optional): Boolean filter for assigned/unassigned\n- `assignees` (optional): Array of assignee logins - critical for targeted clean-up sprints and workload analysis\n- `author` (optional): Single author login\n- `authors` (optional): Array of author logins\n\n**Security Standards:**\n\n- `cwe` (optional): Array of CWE identifiers\n- `owasp_top10` (optional): Array of OWASP Top 10 categories\n- `owasp_top10_v2021` (optional): Array of OWASP Top 10 2021 categories\n- `sans_top25` (optional): Array of SANS Top 25 categories\n- `sonarsource_security` (optional): Array of SonarSource security categories\n- `sonarsource_security_category` (optional): Additional security categories\n\n**Other Filters:**\n\n- `languages` (optional): Array of programming languages\n- `facets` (optional): Array of facets to aggregate\n- `facet_mode` (optional): Facet aggregation mode ('effort' or 'count')\n- `since_leak_period` (optional): Boolean for leak period filter (deprecated)\n- `in_new_code_period` (optional): Boolean for new code period filter\n\n**Sorting:**\n\n- `s` (optional): Sort field (e.g., 'SEVERITY', 'CREATION_DATE', 'UPDATE_DATE')\n- `asc` (optional): Boolean for ascending sort direction (default: false)\n\n**Response Control:**\n\n- `additional_fields` (optional): Array of additional fields to include\n- `page` (optional): Page number for pagination\n- `page_size` (optional): Number of items per page\n\n**Faceted Search (Dashboard Support):**\n\n- `facets` (optional): Array of facets to compute for aggregations. Available facets: severities, statuses, resolutions, rules, tags, types, authors, assignees, languages, etc.\n- `facet_mode` (optional): Mode for facet computation: 'count' (number of issues) or 'effort' (remediation effort)\n\n**Example Use Cases:**\n\n1. **Dashboard Query** - Get issue counts by severity and assignee:\n\n```json\n{\n  \"project_key\": \"my-project\",\n  \"facets\": [\"severities\", \"assignees\", \"tags\"],\n  \"facet_mode\": \"count\"\n}\n```\n\n1. **Security Audit** - Find critical security issues in authentication modules:\n\n```json\n{\n  \"project_key\": \"my-project\",\n  \"component_keys\": [\"src/auth/\", \"src/security/\"],\n  \"tags\": [\"security\", \"vulnerability\"],\n  \"severities\": [\"CRITICAL\", \"BLOCKER\"],\n  \"statuses\": [\"OPEN\", \"REOPENED\"]\n}\n```\n\n1. **Sprint Planning** - Get open issues for specific team members:\n\n```json\n{\n  \"project_key\": \"my-project\",\n  \"assignees\": [\"john.doe@example.com\", \"jane.smith@example.com\"],\n  \"statuses\": [\"OPEN\", \"CONFIRMED\"],\n  \"facets\": [\"severities\", \"types\"],\n  \"facet_mode\": \"effort\"\n}\n```\n\n1. **File-Specific Analysis** - Issues in a specific file:\n\n```json\n{\n  \"project_key\": \"my-project\",\n  \"component_keys\": [\"src/main/java/com/example/PaymentService.java\"],\n  \"on_component_only\": true\n}\n```\n\n### Component Navigation\n\n#### `components`\n\nSearch and navigate SonarQube components (projects, directories, files). Supports text search, filtering by type/language, and tree navigation.\n\n**Search Parameters:**\n\n- `query` (optional): Text search query\n- `qualifiers` (optional): Array of component types (TRK, DIR, FIL, UTS, BRC, APP, VW, SVW, LIB)\n- `language` (optional): Programming language filter\n\n**Tree Navigation Parameters:**\n\n- `component` (optional): Component key for tree navigation\n- `strategy` (optional): Tree traversal strategy ('all', 'children', 'leaves')\n\n**Common Parameters:**\n\n- `asc` (optional): Sort ascending/descending\n- `ps` (optional): Page size (default: 100, max: 500)\n- `p` (optional): Page number\n- `branch` (optional): Branch name\n- `pullRequest` (optional): Pull request ID\n\n**Component Qualifiers:**\n\n- `TRK`: Project\n- `DIR`: Directory\n- `FIL`: File\n- `UTS`: Unit Test\n- `BRC`: Branch\n- `APP`: Application\n- `VW`: View\n- `SVW`: Sub-view\n- `LIB`: Library\n\n**Example Use Cases:**\n\n1. **Find specific files:**\n\n```json\n{\n  \"query\": \"UserService\",\n  \"qualifiers\": [\"FIL\"]\n}\n```\n\n1. **List all test files in a project:**\n\n```json\n{\n  \"component\": \"my-project\",\n  \"qualifiers\": [\"UTS\"]\n}\n```\n\n1. **Navigate directory structure:**\n\n```json\n{\n  \"component\": \"my-project:src/main\",\n  \"strategy\": \"children\",\n  \"qualifiers\": [\"DIR\", \"FIL\"]\n}\n```\n\n1. **Search for components by language:**\n\n```json\n{\n  \"language\": \"java\",\n  \"qualifiers\": [\"FIL\"],\n  \"query\": \"Controller\"\n}\n```\n\n1. **Get project list:**\n\n```json\n{\n  \"qualifiers\": [\"TRK\"]\n}\n```\n\n### Security Hotspots\n\n#### `hotspots`\n\nSearch for security hotspots with specialized filters for security review workflows.\n\n**Parameters:**\n\n- `project_key` (optional): Project key to filter hotspots\n- `branch` (optional): Branch name for branch analysis\n- `pull_request` (optional): Pull request ID for PR analysis\n- `status` (optional): Hotspot status (TO_REVIEW, REVIEWED)\n- `resolution` (optional): Hotspot resolution (FIXED, SAFE)\n- `files` (optional): Array of file paths to filter\n- `assigned_to_me` (optional): Boolean to show only assigned hotspots\n- `since_leak_period` (optional): Boolean for leak period filter\n- `in_new_code_period` (optional): Boolean for new code period filter\n- `page` (optional): Page number for pagination\n- `page_size` (optional): Number of items per page\n\n#### `hotspot`\n\nGet detailed information about a specific security hotspot including security context.\n\n**Parameters:**\n\n- `hotspot_key` (required): The unique key of the hotspot\n\n**Returns:**\n\n- Detailed hotspot information including:\n  - Security category and vulnerability probability\n  - Rule information and security context\n  - Changelog and comments\n  - Code flows and locations\n\n#### `update_hotspot_status`\n\nUpdate the status of a security hotspot (requires appropriate permissions).\n\n**Parameters:**\n\n- `hotspot_key` (required): The unique key of the hotspot\n- `status` (required): New status (TO_REVIEW, REVIEWED)\n- `resolution` (optional): Resolution when status is REVIEWED (FIXED, SAFE)\n- `comment` (optional): Comment explaining the status change\n\n### Quality Gates\n\n#### `quality_gates`\n\nList available quality gates.\n\nNo parameters required.\n\n#### `quality_gate`\n\nGet quality gate conditions.\n\n**Parameters:**\n\n- `id` (required): Quality gate ID\n\n#### `quality_gate_status`\n\nGet project quality gate status.\n\n**Parameters:**\n\n- `project_key` (required): Project key\n- `branch` (optional): Branch name\n- `pull_request` (optional): Pull request key\n\n### Source Code\n\n#### `source_code`\n\nView source code with issues highlighted.\n\n**Parameters:**\n\n- `key` (required): File key\n- `from` (optional): Start line\n- `to` (optional): End line\n- `branch` (optional): Branch name\n- `pull_request` (optional): Pull request key\n\n#### `scm_blame`\n\nGet SCM blame information for source code.\n\n**Parameters:**\n\n- Same as `source_code`\n\n### System Monitoring\n\n#### `system_health`\n\nGet the health status of the SonarQube instance.\n\nNo parameters required.\n\n#### `system_status`\n\nGet the status of the SonarQube instance.\n\nNo parameters required.\n\n#### `system_ping`\n\nPing the SonarQube instance to check if it is up.\n\nNo parameters required.\n\n### Issue Resolution and Management\n\n#### `markIssueFalsePositive`\n\nMark an issue as false positive.\n\n**Parameters:**\n\n- `issue_key` (required): The key of the issue to mark\n- `comment` (optional): Comment explaining why it's a false positive\n\n#### `markIssueWontFix`\n\nMark an issue as won't fix.\n\n**Parameters:**\n\n- `issue_key` (required): The key of the issue to mark\n- `comment` (optional): Comment explaining why it won't be fixed\n\n#### `markIssuesFalsePositive`\n\nMark multiple issues as false positive in bulk.\n\n**Parameters:**\n\n- `issue_keys` (required): Array of issue keys to mark\n- `comment` (optional): Comment applying to all issues\n\n#### `markIssuesWontFix`\n\nMark multiple issues as won't fix in bulk.\n\n**Parameters:**\n\n- `issue_keys` (required): Array of issue keys to mark\n- `comment` (optional): Comment applying to all issues\n\n#### `addCommentToIssue`\n\nAdd a comment to a SonarQube issue.\n\n**Parameters:**\n\n- `issue_key` (required): The key of the issue to comment on\n- `text` (required): The comment text (supports markdown formatting)\n\n#### `assignIssue`\n\nAssign a SonarQube issue to a user or unassign it.\n\n**Parameters:**\n\n- `issueKey` (required): The key of the issue to assign\n- `assignee` (optional): Username of the assignee. Leave empty to unassign the issue\n\n**Example usage:**\n\n```json\n{\n  \"issueKey\": \"PROJECT-123\",\n  \"assignee\": \"john.doe\"\n}\n```\n\n## Usage Examples\n\n### Basic Project Analysis\n\n```\n\"List all my SonarQube projects\"\n\"Show me the code coverage for project xyz\"\n\"What metrics are available for analysis?\"\n```\n\n### Issue Investigation\n\n```\n\"Show me all critical bugs in project abc\"\n\"Find security vulnerabilities in the main branch\"\n\"List all code smells created in the last week\"\n\"Show unresolved issues assigned to john.doe\"\n\"Analyze issues in the feature/new-login branch\"\n\"Compare issues between main and develop branches\"\n\"Find issues across multiple projects: proj1, proj2, proj3\"\n\"Show me issues sorted by severity in descending order\"\n\"Find all issues with clean code impact on reliability\"\n```\n\n### Component Navigation\n\n```\n\"Find all files containing 'UserService' in their name\"\n\"List all test files in my project\"\n\"Show me the directory structure of src/main\"\n\"Find all Java controller files\"\n\"List all projects in SonarQube\"\n\"Navigate to the authentication module\"\n\"Search for TypeScript files in the frontend directory\"\n\"Show me all directories under src/components\"\n```\n\n### Issue Management\n\n```\n\"Assign issue PROJECT-123 to john.doe\"\n\"Unassign issue PROJECT-456\"\n\"Mark issue ABC-789 as false positive with comment: 'Test code only'\"\n\"Add comment to issue XYZ-111: 'Fixed in commit abc123'\"\n\"Bulk mark issues DEF-222, DEF-223 as won't fix\"\n```\n\n### Quality Monitoring\n\n```\n\"Check the quality gate status for my main project\"\n\"Show me the code coverage history for the last month\"\n\"What are the quality gate conditions?\"\n\"Compare metrics between develop and main branches\"\n```\n\n### Security Hotspot Review\n\n```\n\"Find all security hotspots that need review in project xyz\"\n\"Show me hotspots in the authentication module\"\n\"Get details for hotspot HSP-12345\"\n\"List all hotspots assigned to me\"\n\"Mark hotspot HSP-12345 as safe with explanation\"\n\"Find hotspots in the new code period\"\n\"Show security hotspots in pull request #42\"\n```\n\n### Source Code Analysis\n\n```\n\"Show me the source code for file xyz with issues highlighted\"\n\"Get blame information for the problematic file\"\n\"View issues in the authentication module\"\n```\n\n### System Health\n\n```\n\"Check if SonarQube is running\"\n\"What's the health status of the SonarQube instance?\"\n\"Show me the system status\"\n```\n\n## Architecture\n\nThe SonarQube MCP Server follows a modular architecture:\n\n```\n┌─────────────────┐     ┌──────────────────┐     ┌─────────────────┐\n│  Claude Desktop │────▶│  MCP Server      │────▶│  SonarQube API  │\n│  (MCP Client)   │◀────│  (index.ts)      │◀────│                 │\n└─────────────────┘     └──────────────────┘     └─────────────────┘\n                               │\n                               ▼\n                        ┌──────────────────┐\n                        │  SonarQube       │\n                        │  Client          │\n                        │  (sonarqube.ts)  │\n                        └──────────────────┘\n                               │\n                               ▼\n                        ┌──────────────────┐\n                        │  API Module      │\n                        │  (api.ts)        │\n                        └──────────────────┘\n```\n\n### Key Components\n\n1. **MCP Server (`index.ts`)**: Main entry point that initializes the MCP server and registers all available tools\n2. **SonarQube Client (`sonarqube.ts`)**: Handles business logic and parameter transformation\n3. **API Module (`api.ts`)**: Manages HTTP requests to the SonarQube API\n4. **Type Definitions**: TypeScript interfaces for type safety\n\n### Data Flow\n\n1. MCP clients make requests through registered tools\n2. Tool handlers validate and transform parameters\n3. SonarQube client methods process the requests\n4. API module executes HTTP requests\n5. Responses are formatted and returned to the client\n\n## Development\n\n### Prerequisites\n\n- Node.js 22 or higher\n- pnpm 10.17.0 or higher\n- Docker (for container builds)\n\n### Setup\n\n1. Clone the repository:\n\n```bash\ngit clone https://github.com/sapientpants/sonarqube-mcp-server.git\ncd sonarqube-mcp-server\n```\n\n1. Install dependencies:\n\n```bash\npnpm install\n```\n\n1. Build the project:\n\n```bash\npnpm build\n```\n\n### Development Commands\n\n```bash\n# Install dependencies\npnpm install\n\n# Build the project\npnpm build\n\n# Run in development mode with auto-reload\npnpm dev\n\n# Run tests\npnpm test\n\n# Run tests with coverage\npnpm test:coverage\n\n# Lint the code\npnpm lint\n\n# Fix linting issues\npnpm lint:fix\n\n# Check types\npnpm check-types\n\n# Format code\npnpm format\n\n# Run all validations\npnpm validate\n\n# Inspect MCP schema\npnpm inspect\n```\n\n### Testing\n\nThe project uses Jest for testing with:\n\n- Unit tests for all major components\n- Mocked HTTP responses using `nock`\n- Coverage reporting\n- TypeScript support\n\nRun specific test files:\n\n```bash\nNODE_ENV=test NODE_OPTIONS='--experimental-vm-modules --no-warnings' jest src/__tests__/file-name.test.ts\n```\n\n### Code Quality\n\nThe project maintains high code quality through:\n\n- TypeScript for type safety\n- ESLint for code linting\n- Prettier for code formatting\n- Jest for testing\n- SonarCloud for continuous code analysis\n\n## Common Issues and Solutions\n\n### Quick Fixes\n\n#### \"Authentication failed\"\n\n- **Cause**: Invalid or expired token\n- **Solution**: Generate a new token in SonarQube/SonarCloud\n\n#### \"Project not found\"\n\n- **Cause**: Incorrect project key or insufficient permissions\n- **Solution**: Verify the project key and check token permissions\n\n#### \"Organization required\"\n\n- **Cause**: Using SonarCloud without organization parameter\n- **Solution**: Add `SONARQUBE_ORGANIZATION` to your configuration\n\n#### \"Connection refused\"\n\n- **Cause**: Incorrect URL or network issues\n- **Solution**: Verify `SONARQUBE_URL` and network connectivity\n\n#### \"No output or errors visible\"\n\n- **Cause**: Errors might be happening but not visible in Claude Desktop\n- **Solution**: Enable logging with `LOG_FILE` and check the log file for detailed error messages\n\n### FAQ\n\n**Q: Can I use this with both SonarQube and SonarCloud?**\nA: Yes! Set the appropriate `SONARQUBE_URL` and include `SONARQUBE_ORGANIZATION` for SonarCloud.\n\n**Q: What permissions does my token need?**\nA: The token needs \"Execute Analysis\" permission and access to the projects you want to analyze.\n\n**Q: How do I filter issues by multiple criteria?**\nA: The `issues` tool supports extensive filtering. You can combine multiple parameters like severity, type, status, and date ranges.\n\n**Q: Can I analyze pull requests?**\nA: Yes! Many tools support `branch` and `pull_request` parameters for branch and PR analysis.\n\n## Troubleshooting\n\n### Common Error Messages and Solutions\n\n#### Authentication Errors\n\n##### Error: \"Authentication failed\"\n\n- **Solution**: Check that your SONARQUBE_TOKEN is valid and not expired. Generate a new token from your SonarQube user profile.\n\n##### Error: \"No SonarQube authentication configured\"\n\n- **Solution**: Set one of the following authentication methods:\n  - `SONARQUBE_TOKEN` for token-based authentication (recommended)\n  - `SONARQUBE_USERNAME` and `SONARQUBE_PASSWORD` for basic authentication\n  - `SONARQUBE_PASSCODE` for system passcode authentication\n\n#### Authorization Errors\n\n##### Error: \"Access denied\"\n\n- **Solution**: Ensure your token has the required permissions for the operation. Common required permissions:\n  - \"Execute Analysis\" for code analysis\n  - \"Browse\" for reading project data\n  - \"Administer Issues\" for issue management operations\n\n#### Resource Not Found Errors\n\n##### Error: \"Resource not found\"\n\n- **Solution**: Verify that:\n  - The project key/component exists in SonarQube\n  - You have access to the resource\n  - The URL path is correct (no typos in project keys)\n\n#### Network and Connection Errors\n\n##### Error: \"Connection refused\"\n\n- **Solution**: Check that:\n  - The SonarQube server is running\n  - The SONARQUBE_URL is correct\n  - There are no firewall rules blocking the connection\n\n##### Error: \"Network error\" or timeout errors\n\n- **Solution**:\n  - Verify your network connection\n  - Check if the SonarQube server is accessible\n  - Ensure the URL doesn't have a trailing slash\n  - For self-hosted instances, verify SSL certificates\n\n#### Rate Limiting\n\n##### Error: \"Rate limit exceeded\"\n\n- **Solution**: The server automatically retries rate-limited requests with exponential backoff. If you continue to hit rate limits:\n  - Reduce the frequency of your requests\n  - Implement request batching where possible\n  - Contact your SonarQube administrator to increase rate limits\n\n#### Configuration Errors\n\n##### Error: \"Invalid SONARQUBE_URL\"\n\n- **Solution**: Provide a valid URL including the protocol:\n  - ✅ Correct: `https://sonarcloud.io`\n  - ✅ Correct: `https://sonarqube.example.com`\n  - ❌ Wrong: `sonarcloud.io` (missing protocol)\n  - ❌ Wrong: `https://sonarqube.example.com/` (trailing slash)\n\n### Debugging Tips\n\n1. **Enable Debug Logging**:\n\n   ```bash\n   export LOG_LEVEL=DEBUG\n   ```\n\n2. **Check Environment Variables**:\n\n   ```bash\n   echo $SONARQUBE_URL\n   echo $SONARQUBE_TOKEN\n   echo $SONARQUBE_ORGANIZATION\n   ```\n\n3. **Test Connection**:\n   Use the `ping` tool to verify connectivity:\n\n   ```bash\n   # In your MCP client\n   sonarqube.ping\n   ```\n\n4. **Verify Permissions**:\n   Use the `projects` tool to list accessible projects:\n   ```bash\n   # In your MCP client\n   sonarqube.projects\n   ```\n\n### Retry Behavior\n\nThe server automatically retries failed requests for transient errors:\n\n- **Network errors**: Retried up to 3 times\n- **Rate limiting**: Retried with exponential backoff\n- **Server errors (5xx)**: Retried up to 3 times\n\nRetry delays: 1s → 2s → 4s (capped at 10s)\n\n### Getting Help\n\nIf you continue to experience issues:\n\n1. Check the [GitHub Issues](https://github.com/sapientpants/sonarqube-mcp-server/issues) for similar problems\n2. Enable debug logging and collect error details\n3. Create a new issue with:\n   - Error messages\n   - Environment details (OS, Node version)\n   - SonarQube version\n   - Steps to reproduce\n\n## Contributing\n\nWe welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.\n\n### How to Contribute\n\n1. Fork the repository\n2. Create a feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n\n### Development Guidelines\n\n- Write tests for new features\n- Update documentation as needed\n- Follow the existing code style\n- Ensure all tests pass\n- Add appropriate error handling\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## External Resources\n\n### SonarQube Documentation\n\n- [SonarQube Documentation](https://docs.sonarqube.org/latest/)\n- [SonarCloud Documentation](https://docs.sonarcloud.io/)\n- [Web API Documentation](https://docs.sonarqube.org/latest/extend/web-api/)\n\n### Model Context Protocol\n\n- [MCP Documentation](https://modelcontextprotocol.io/)\n- [MCP Specification](https://github.com/modelcontextprotocol/specification)\n- [MCP TypeScript SDK](https://github.com/modelcontextprotocol/typescript-sdk)\n\n---\n\nMade with ❤️ by the SonarQube MCP Server community",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "sonarqube",
        "devops",
        "ai",
        "sonarqube mcp",
        "integrates sonarqube",
        "sonarqube provide"
      ],
      "category": "devops-and-cicd"
    },
    "sparesparrow--mcp-project-orchestrator": {
      "owner": "sparesparrow",
      "name": "mcp-project-orchestrator",
      "url": "https://github.com/sparesparrow/mcp-project-orchestrator",
      "imageUrl": "/freedevtools/mcp/pfp/sparesparrow.webp",
      "description": "Streamlines software project setup using standardized templates and best practices, automatically generating comprehensive documentation and visual diagrams to enhance project architecture and implementation strategy.",
      "stars": 15,
      "forks": 4,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-03T07:46:52Z",
      "readme_content": "# MCP Project Orchestrator\n\n[](https://github.com/yourusername/mcp-project-orchestrator/actions/workflows/ci.yml)\n[![codecov](https://codecov.io/gh/yourusername/mcp-project-orchestrator/branch/main/graph/badge.svg)](https://codecov.io/gh/yourusername/mcp-project-orchestrator)\n[![PyPI version](https://badge.fury.io/py/mcp-project-orchestrator.svg)](https://badge.fury.io/py/mcp-project-orchestrator)\n[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\nA comprehensive project orchestration tool for managing Model Context Protocol (MCP) projects, templates, prompts, and Mermaid diagrams.\n\n## Features\n\n- **Template Management**\n  - Project templates for quick project setup\n  - Component templates for modular development\n  - Variable substitution and validation\n  - Template discovery and versioning\n\n- **Prompt Management**\n  - System and user prompt templates\n  - Variable substitution\n  - Prompt categorization and versioning\n  - Easy prompt discovery and reuse\n\n- **Mermaid Diagram Generation**\n  - Flowchart generation\n  - Sequence diagram generation\n  - Class diagram generation\n  - SVG and PNG rendering\n  - Diagram validation\n\n- **AWS MCP Integration**\n  - AWS service access (S3, EC2, Lambda, CloudFormation, IAM)\n  - AWS best practices enforcement\n  - Cost optimization recommendations\n  - Security and compliance guidance\n  - See [AWS_MCP.md](./docs/AWS_MCP.md) for details\n\n## Installation\n\n```bash\npip install mcp-project-orchestrator\n```\n\nFor AWS integration support:\n\n```bash\npip install mcp-project-orchestrator[aws]\n```\n\nOr with Poetry:\n\n```bash\npoetry add mcp-project-orchestrator\n# Or with AWS support\npoetry add mcp-project-orchestrator -E aws\n```\n\n### Using as a Conan dependency (for ai-servis)\n\nThis repository provides a Conan v2 package exposing the Python environment and CLI. In `ai-servis`'s `conanfile.py` add:\n\n```python\ndef requirements(self):\n    self.requires(\"mcp-project-orchestrator/0.1.0@sparesparrow/stable\")\n```\n\nThen activate the run environment so `mcp-orchestrator` is on `PATH` and the package is on `PYTHONPATH`:\n\n```bash\nconan profile detect --force\nconan create . --user=sparesparrow --channel=stable\nconan install mcp-project-orchestrator/0.1.0@sparesparrow/stable -g VirtualRunEnv\n./conanrun.sh mcp-orchestrator --help\n```\n\n## Quick Start\n\n### Project Templates\n\n```python\nfrom mcp_project_orchestrator.templates import TemplateManager\n\n# Initialize template manager\nmanager = TemplateManager(\"path/to/templates\")\n\n# List available templates\ntemplates = manager.list_templates()\nprint(templates)\n\n# Apply a project template\nmanager.apply_template(\"fastapi-project\", {\n    \"project_name\": \"my-api\",\n    \"project_description\": \"My FastAPI project\",\n    \"author_name\": \"John Doe\",\n    \"author_email\": \"john@example.com\"\n})\n```\n\n### JSON-Driven Project Orchestration\n\nThe setup script reads `config/project_orchestration.json` to enable/disable features and set ports and tool options.\n\nRun the setup:\n\n```bash\nchmod +x scripts/setup_orchestrator.sh\nscripts/setup_orchestrator.sh\n```\n\nEdit `config/project_orchestration.json` to control scaffolding:\n\n```json\n{\n  \"enable\": {\n    \"cursorConfigs\": true,\n    \"pythonMcp\": true,\n    \"tsMcp\": true,\n    \"cppMcp\": true,\n    \"mcpClient\": true,\n    \"backgroundAgent\": true,\n    \"githubActions\": true,\n    \"devcontainer\": true,\n    \"awsTerraform\": true,\n    \"webAndMcp\": true,\n    \"cppConan\": true,\n    \"esp32\": true,\n    \"android\": true\n  }\n}\n```\n\n- Set items to `false` to skip generating those components.\n- Ports and URLs are respected across `.cursor/webhooks`, `.cursor/agents`, `Dockerfile` EXPOSE, and `compose.yaml`.\n\n### Prompt Management\n\n```python\nfrom mcp_project_orchestrator.prompts import PromptManager\n\n# Initialize prompt manager\nmanager = PromptManager(\"path/to/prompts\")\n\n# List available prompts\nprompts = manager.list_prompts()\nprint(prompts)\n\n# Render a prompt with variables\nrendered = manager.render_prompt(\"system-prompt\", {\n    \"name\": \"User\",\n    \"project\": \"MCP\"\n})\nprint(rendered)\n```\n\n### Mermaid Diagrams\n\n```python\nfrom mcp_project_orchestrator.mermaid import MermaidGenerator, MermaidRenderer\n\n# Initialize generators\ngenerator = MermaidGenerator()\nrenderer = MermaidRenderer()\n\n# Generate a flowchart\nflowchart = generator.generate_flowchart(\n    nodes=[\n        (\"A\", \"Start\"),\n        (\"B\", \"Process\"),\n        (\"C\", \"End\")\n    ],\n    edges=[\n        (\"A\", \"B\", \"\"),\n        (\"B\", \"C\", \"\")\n    ]\n)\n\n# Render to SVG\nrenderer.render(flowchart, \"flowchart.svg\")\n```\n\n## Project Structure\n\n```\nmcp-project-orchestrator/\n├── src/\n│   └── mcp_project_orchestrator/\n│       ├── templates/\n│       │   ├── __init__.py\n│       │   ├── base.py\n│       │   ├── project.py\n│       │   ├── component.py\n│       │   └── manager.py\n│       ├── prompts/\n│       │   ├── __init__.py\n│       │   ├── template.py\n│       │   └── manager.py\n│       └── mermaid/\n│           ├── __init__.py\n│           ├── generator.py\n│           └── renderer.py\n├── tests/\n│   ├── __init__.py\n│   ├── conftest.py\n│   ├── test_templates.py\n│   ├── test_prompts.py\n│   └── test_mermaid.py\n├── docs/\n├── examples/\n├── .github/\n│   └── workflows/\n│       └── ci.yml\n├── pyproject.toml\n├── Containerfile\n└── README.md\n```\n\n## Development\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/yourusername/mcp-project-orchestrator.git\ncd mcp-project-orchestrator\n```\n\n2. Install dependencies:\n```bash\npoetry install\n```\n\n3. Run tests:\n```bash\npoetry run pytest\n```\n\n4. Run linting:\n```bash\npoetry run ruff check .\npoetry run mypy src/mcp_project_orchestrator\n```\n\n## Contributing\n\n1. Fork the repository\n2. Create a feature branch\n3. Commit your changes\n4. Push to the branch\n5. Create a Pull Request\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Acknowledgments\n\n- [Model Context Protocol](https://github.com/yourusername/model-context-protocol) - The foundation for this project\n- [Mermaid](https://mermaid-js.github.io/mermaid/) - For diagram generation\n- [Poetry](https://python-poetry.org/) - For dependency management\n- [Ruff](https://github.com/astral-sh/ruff) - For linting\n- [mypy](https://mypy.readthedocs.io/) - For type checking",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "devops",
        "documentation",
        "diagrams",
        "devops cicd",
        "project orchestrator",
        "project architecture"
      ],
      "category": "devops-and-cicd"
    },
    "stefanskiasan--azure-devops-mcp-server": {
      "owner": "stefanskiasan",
      "name": "azure-devops-mcp-server",
      "url": "https://github.com/stefanskiasan/azure-devops-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/stefanskiasan.webp",
      "description": "Integrate with Azure DevOps services to access work items, repositories, and pull requests, enabling streamlined project management and collaboration. Provides functionalities for retrieving and managing Azure DevOps resources efficiently.",
      "stars": 33,
      "forks": 15,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-08-29T21:13:17Z",
      "readme_content": "# Azure DevOps MCP Server for Cline\n[![smithery badge](https://smithery.ai/badge/@stefanskiasan/azure-devops-mcp-server)](https://smithery.ai/server/@stefanskiasan/azure-devops-mcp-server)\n\nThis Model Context Protocol (MCP) server provides integration with Azure DevOps, allowing Cline to interact with Azure DevOps services.\n\n## Prerequisites\n\n- Node.js (v20 LTS or higher)\n- npm (comes with Node.js)\n- A Cline installation\n- Azure DevOps account with access tokens\n\n## Installation\n\n### Installing via Smithery\n\nTo install Azure DevOps Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@stefanskiasan/azure-devops-mcp-server):\n\n```bash\nnpx -y @smithery/cli install @stefanskiasan/azure-devops-mcp-server --client claude\n```\n\n### Manual Installation\n1. Clone this repository:\n```bash\ngit clone https://github.com/stefanskiasan/azure-devops-mcp-server.git\ncd azure-devops-mcp-server\n```\n\n2. Install dependencies:\n```bash\nnpm install\n```\n\n3. Build the server:\n```bash\nnpm run build\n```\n\nNote: The build output (`build/` directory) is not included in version control. You must run the build command after cloning the repository.\n\n## Configuration\n\n### 1. Get Azure DevOps Personal Access Token (PAT)\n\n1. Go to Azure DevOps and sign in\n2. Click on your profile picture in the top right\n3. Select \"Security\"\n4. Click \"New Token\"\n5. Give your token a name and select the required scopes:\n   - `Code (read, write)` - For Pull Request operations\n   - `Work Items (read, write)` - For Work Item management\n   - `Build (read, execute)` - For Pipeline operations\n   - `Wiki (read, write)` - For Wiki operations\n   - `Project and Team (read)` - For Project and Board information\n6. Copy the generated token\n\n### 2. Configure Cline MCP Settings\n\nAdd the server configuration to your Cline MCP settings file:\n\n- For VSCode extension: `%APPDATA%/Code/User/globalStorage/rooveterinaryinc.roo-cline/settings/cline_mcp_settings.json`\n- For Claude desktop app: `%LOCALAPPDATA%/Claude/claude_desktop_config.json`\n\nAdd the following configuration to the `mcpServers` object:\n\n```json\n{\n  \"mcpServers\": {\n    \"azure-devops\": {\n      \"command\": \"node\",\n      \"args\": [\"/absolute/path/to/azure-devops-server/build/index.js\"],\n      \"env\": {\n        \"AZURE_DEVOPS_ORG\": \"your-organization\",\n        \"AZURE_DEVOPS_PAT\": \"your-personal-access-token\",\n        \"AZURE_DEVOPS_PROJECT\": \"your-project-name\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\nReplace the following values:\n- `/absolute/path/to/azure-devops-server`: The absolute path to where you cloned this repository\n- `your-organization`: Your Azure DevOps organization name\n- `your-project-name`: Your Azure DevOps project name\n- `your-personal-access-token`: The PAT you generated in step 1\n\n## Available Tools\n\n### Work Items\n- `get_work_item`: Get a work item by ID\n- `list_work_items`: Query work items using WIQL\n- `create_work_item`: Create a new work item (Bug, Task, User Story)\n- `update_work_item`: Update an existing work item\n\n### Boards\n- `get_boards`: Get available boards in the project\n\n### Pipelines\n- `list_pipelines`: List all pipelines in the project\n- `trigger_pipeline`: Execute a pipeline\n\n### Pull Requests\n- `list_pull_requests`: List pull requests\n- `create_pull_request`: Create a new pull request\n- `update_pull_request`: Update a pull request\n- `get_pull_request`: Get pull request details\n\n### Wiki\n- `get_wikis`: List all wikis in the project\n- `get_wiki_page`: Get a wiki page\n- `create_wiki`: Create a new wiki\n- `update_wiki_page`: Create or update a wiki page\n\n### Projects\n- `list_projects`: List all projects in the Azure DevOps organization\n\n## Verification\n\n1. Restart Cline (or VSCode) after adding the configuration\n2. The Azure DevOps MCP server should now be listed in Cline's capabilities\n3. You can verify the installation using the MCP Inspector:\n```bash\nnpm run inspector\n```\n\n## Troubleshooting\n\n1. If the server isn't connecting:\n   - Check that the path in your MCP settings is correct\n   - Verify your Azure DevOps credentials\n   - Check the Cline logs for any error messages\n\n2. If you get authentication errors:\n   - Verify your PAT hasn't expired\n   - Ensure the PAT has all necessary scopes\n   - Double-check the organization and project names\n\n3. For other issues:\n   - Run the inspector tool to verify the server is working correctly\n   - Check the server logs for any error messages\n\n## Development\n\nTo modify or extend the server:\n\n1. Make your changes in the `src` directory\n2. Run `npm run watch` for development\n3. Build with `npm run build` when ready\n4. Test using the inspector: `npm run inspector`\n\n## License\n\nMIT License - See [LICENSE](LICENSE) for details\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "devops",
        "azure",
        "repositories",
        "azure devops",
        "devops services",
        "devops mcp"
      ],
      "category": "devops-and-cicd"
    },
    "strowk--mcp-k8s-go": {
      "owner": "strowk",
      "name": "mcp-k8s-go",
      "url": "https://github.com/strowk/mcp-k8s-go",
      "imageUrl": "/freedevtools/mcp/pfp/strowk.webp",
      "description": "Connects to Kubernetes for managing contexts, pods, events, and services, and facilitates fetching pod logs across specified namespaces.",
      "stars": 348,
      "forks": 49,
      "license": "MIT License",
      "language": "Go",
      "updated_at": "2025-10-03T16:13:05Z",
      "readme_content": "<h4 align=\"center\">Golang-based MCP server connecting to Kubernetes</h4>\r\n\r\n<h1 align=\"center\">\r\n   \r\n   <br/>\r\n   MCP K8S Go\r\n</h1>\r\n\r\n<p align=\"center\">\r\n  <a href=\"#features\">Features</a> ⚙\r\n  <a href=\"#browse-with-inspector\">Browse With Inspector</a> ⚙\r\n  <a href=\"#use-with-claude\">Use With Claude</a> ⚙\r\n  <a href=\"https://github.com/strowk/mcp-k8s-go/blob/main/CONTRIBUTING.md\">Contributing ↗</a> ⚙\r\n  <a href=\"https://modelcontextprotocol.io\">About MCP ↗</a>\r\n</p>\r\n\r\n<p align=\"center\">\r\n    <a href=\"https://github.com/strowk/mcp-k8s-go/actions/workflows/dependabot/dependabot-updates\"><img src=\"https://github.com/strowk/mcp-k8s-go/actions/workflows/dependabot/dependabot-updates/badge.svg\"></a>\r\n    <a href=\"https://github.com/strowk/mcp-k8s-go/actions/workflows/test.yaml\"><img src=\"https://github.com/strowk/mcp-k8s-go/actions/workflows/test.yaml/badge.svg\"></a>\r\n\t  <a href=\"https://github.com/strowk/mcp-k8s-go/actions/workflows/golangci-lint.yaml\"><img src=\"https://github.com/strowk/mcp-k8s-go/actions/workflows/golangci-lint.yaml/badge.svg\"/></a>\r\n    <br/>\r\n    <a href=\"https://github.com/strowk/mcp-k8s-go/releases/latest\"><img src=\"https://img.shields.io/github/v/release/strowk/mcp-k8s-go?logo=github&color=22ff22\" alt=\"latest release badge\"></a>\r\n    <a href=\"https://goreportcard.com/report/github.com/strowk/mcp-k8s-go\"><img src=\"https://goreportcard.com/badge/github.com/strowk/mcp-k8s-go\" alt=\"Go Reference\"></a>\r\n    <a href=\"https://github.com/strowk/mcp-k8s-go/blob/main/LICENSE\"><img src=\"https://img.shields.io/github/license/strowk/mcp-k8s-go\" alt=\"license badge\"></a>\r\n</p>\r\n\r\n## Features\r\n\r\nMCP 💬 prompt 🗂️ resource 🤖 tool \r\n\r\n- 🗂️🤖 List Kubernetes contexts\r\n- 💬🤖 List Kubernetes namespaces\r\n- 🤖 List, get, create and modify any Kubernetes resources\r\n  - includes custom mappings for resources like pods, services, deployments\r\n- 🤖 List Kubernetes nodes\r\n- 💬 List Kubernetes pods\r\n- 🤖 Get Kubernetes events\r\n- 🤖 Get Kubernetes pod logs\r\n- 🤖 Run command in Kubernetes pod\r\n\r\n## Browse With Inspector\r\n\r\nTo use latest published version with Inspector you can run this:\r\n\r\n```bash\r\nnpx @modelcontextprotocol/inspector npx @strowk/mcp-k8s\r\n```\r\n\r\n## Use With Claude\r\n\r\n<details><summary><b>\r\nDemo Usage\r\n</b></summary>\r\n\r\nFollowing chat with Claude Desktop demonstrates how it looks when selected particular context as a resource and then asked to check pod logs for errors in kube-system namespace:\r\n\r\n\r\n\r\n</details>\r\n\r\nTo use this MCP server with Claude Desktop (or any other client) you might need to choose which way of installation to use.\r\n\r\nYou have multiple options:\r\n\r\n|              | <a href=\"#using-smithery\">Smithery</a> | <a href=\"#using-mcp-get\">mcp-get</a> | <a href=\"#prebuilt-from-npm\">Pre-built NPM</a> | <a href=\"#from-github-releases\">Pre-built in Github</a> | <a href=\"#building-from-source\">From sources</a> | <a href=\"#using-docker\">Using Docker</a> |\r\n| ------------ | -------------------------------------- | ------------------------------------ | ---------------------------------------------- | ------------------------------------------------------- | ------------------------------------------------ | ---------------------------------------- |\r\n| Claude Setup | Auto                                   | Auto                                 | Manual                                         | Manual                                                  | Manual                                           | Manual                                   |\r\n| Prerequisite | Node.js                                | Node.js                              | Node.js                                        | None                                                    | Golang                                           | Docker                                   |\r\n\r\n### Using Smithery\r\n\r\nTo install MCP K8S Go for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@strowk/mcp-k8s):\r\n\r\n```bash\r\nnpx -y @smithery/cli install @strowk/mcp-k8s --client claude\r\n```\r\n\r\n### Using mcp-get\r\n\r\nTo install MCP K8S Go for Claude Desktop automatically via [mcp-get](https://mcp-get.com/packages/%40strowk%2Fmcp-k8s):\r\n\r\n```bash\r\nnpx @michaellatman/mcp-get@latest install @strowk/mcp-k8s\r\n```\r\n\r\n### Manually with prebuilt binaries\r\n\r\n#### Prebuilt from npm\r\n\r\nUse this if you have npm installed and want to use pre-built binaries:\r\n\r\n```bash\r\nnpm install -g @strowk/mcp-k8s\r\n```\r\n\r\nThen check version by running `mcp-k8s --version` and if this printed installed version, you can proceed to add configuration to `claude_desktop_config.json` file:\r\n\r\n```json\r\n{\r\n  \"mcpServers\": {\r\n    \"mcp_k8s\": {\r\n      \"command\": \"mcp-k8s\",\r\n      \"args\": []\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n, or using `npx` with any client:\r\n\r\n```bash\r\nnpx @strowk/mcp-k8s\r\n```\r\n\r\nFor example for Claude:\r\n\r\n```json\r\n{\r\n  \"mcpServers\": {\r\n    \"mcp_k8s\": {\r\n      \"command\": \"npx\",\r\n      \"args\": [\r\n        \"@strowk/mcp-k8s\"\r\n      ]\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n#### From GitHub releases\r\n\r\nHead to [GitHub releases](https://github.com/strowk/mcp-k8s-go/releases) and download the latest release for your platform.\r\n\r\nUnpack the archive, which would contain binary named `mcp-k8s-go`, put that binary somewhere in your PATH and then add the following configuration to the `claude_desktop_config.json` file:\r\n\r\n```json\r\n{\r\n  \"mcpServers\": {\r\n    \"mcp_k8s\": {\r\n      \"command\": \"mcp-k8s-go\",\r\n      \"args\": []\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n### Building from source\r\n\r\nYou would need Golang installed to build this project:\r\n\r\n```bash\r\ngo get github.com/strowk/mcp-k8s-go\r\ngo install github.com/strowk/mcp-k8s-go\r\n```\r\n\r\n, and then add the following configuration to the `claude_desktop_config.json` file:\r\n\r\n```json\r\n{\r\n  \"mcpServers\": {\r\n    \"mcp_k8s_go\": {\r\n      \"command\": \"mcp-k8s-go\",\r\n      \"args\": []\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n### Using Docker\r\n\r\nThis server is built and published to Docker Hub since 0.3.1-beta.2 release with multi-arch images available for linux/amd64 and linux/arm64 architectures.\r\n\r\nYou can use latest tag f.e like this:\r\n\r\n```bash\r\ndocker run -i -v ~/.kube/config:/home/nonroot/.kube/config --rm mcpk8s/server:latest\r\n```\r\n\r\nWindows users might need to replace `~/.kube/config` with `//c/Users/<username>/.kube/config` at least in Git Bash.\r\n\r\nFor Claude:\r\n\r\n```json\r\n{\r\n  \"mcpServers\": {\r\n    \"mcp_k8s_go\": {\r\n      \"command\": \"docker\",\r\n      \"args\": [\r\n        \"run\",\r\n        \"-i\",\r\n        \"-v\",\r\n        \"~/.kube/config:/home/nonroot/.kube/config\",\r\n        \"--rm\",\r\n        \"mcpk8s/server:latest\"\r\n      ]\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n### Environment Variables and Command-line Options\r\n\r\nThe following environment variables are used by the MCP server:\r\n\r\n- `KUBECONFIG`: Path to your Kubernetes configuration file (optional, defaults to ~/.kube/config)\r\n\r\nThe following command-line options are supported:\r\n\r\n- `--allowed-contexts=<ctx1,ctx2,...>`: Comma-separated list of allowed Kubernetes contexts that users can access. If not specified, all contexts are allowed.\r\n- `--readonly`: Disables any tool which can write changes to the cluster\r\n- `--help`: Display help information\r\n- `--version`: Display version information\r\n\r\nFor example if you are configuring Claude Desktop, you can add the following configuration to `claude_desktop_config.json` file:\r\n\r\n```json\r\n{\r\n    \"mcpServers\": {\r\n        \"mcp_k8s\": {\r\n            \"command\": \"mcp-k8s\",\r\n            \"args\": [\r\n                \"--allowed-contexts=dev,prod\",\r\n                \"--readonly\"\r\n            ]\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n, which would allow only `dev` and `prod` contexts to be used and would disable any tool which can write changes to the cluster.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "kubernetes",
        "devops",
        "pods",
        "connects kubernetes",
        "kubernetes managing",
        "pod logs"
      ],
      "category": "devops-and-cicd"
    },
    "vaebe--mcp": {
      "owner": "vaebe",
      "name": "mcp",
      "url": "https://github.com/vaebe/mcp",
      "imageUrl": "/freedevtools/mcp/pfp/vaebe.webp",
      "description": "Retrieve the current time effortlessly, integrating time-fetching capabilities into applications with accurate and reliable time data.",
      "stars": 0,
      "forks": 3,
      "license": "Apache License 2.0",
      "language": "JavaScript",
      "updated_at": "2025-04-16T14:21:57Z",
      "readme_content": "# mcp\n\n## 版本更新\n\n```bash\n# 安装 changesets\nnpm install @changesets/cli --save-dev\n\n# 初始化 changesets\nnpx changeset init\n\n# 生成变更日志\npnpm changelog\n\n# 创建一个新的 changeset\nnpx changeset\n\n# 更新版本号和生成发布日志\nnpx changeset version\n\n# 测试发布\npnpm -r publish --access public --dry-run --no-git-checks\n# 发布\npnpm -r publish --access public --no-git-checks\n\n# 移除版本\nnpm unpublish @vaebe/server-github-search@0.2.0 --force\n```\n\n## 测试 mcp\n\n```bash\nnpx @modelcontextprotocol/inspector node mcp/githubSearch.mjs\n```\n\n## docker 打包测试\n\n```bash\ndocker build -f packages/github-search/Dockerfile -t github-search .\n```",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "devops",
        "mcp",
        "cicd",
        "devops cicd",
        "time fetching",
        "reliable time"
      ],
      "category": "devops-and-cicd"
    },
    "vanisoul--rundeck-mcp-server": {
      "owner": "vanisoul",
      "name": "rundeck-mcp-server",
      "url": "https://github.com/vanisoul/rundeck-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/vanisoul.webp",
      "description": "Enables management of Rundeck operations through AI, facilitating job execution, information retrieval for projects and nodes, and system monitoring without manual CLI interaction. Streamlines Rundeck workflows with an AI interface for efficient tracking and execution of jobs and executions.",
      "stars": 0,
      "forks": 2,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-04-16T04:30:31Z",
      "readme_content": "# Rundeck MCP Server\n\nThis is a Model Context Protocol (MCP) server for interacting with the Rundeck CLI. It provides a set of tools that allow you to perform Rundeck operations with AI without directly interacting with the command line.\n\n## Features\n\n- **Jobs Management**: List, get information, execute, and predict\n- **Executions Management**: List, get information, get output, and track\n- **Projects Management**: List and get information\n- **Nodes and System Information**: List nodes and get system information\n\n## Installation\n\n### Prerequisites\n\n- Node.js (v14 or higher)\n- Rundeck CLI tool\n\n### Steps\n\n1. Clone this repository:\n\n```bash\ngit clone https://github.com/vanisoul/rundeck-mcp-server\ncd rundeck-mcp-server\n```\n\n2. Install dependencies:\n\n```bash\nnpm install\n```\n\n3. Build the project:\n\n```bash\nnpm run build\n```\n\n4. Configure the MCP settings file:\n\nAdd the following configuration to your MCP settings file. The location of the settings file depends on your environment:\n\n```json\n{\n  \"mcpServers\": {\n    \"rundeck\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/rundeck-mcp-server/build/index.js\"],\n      \"env\": {\n        \"RUNDECK_CLI_PATH\": \"/usr/bin/rd\",\n        \"RUNDECK_BASE_URL\": \"http://your-rundeck-server:port/\",\n        \"RUNDECK_API_TOKEN\": \"your-api-token\"\n      },\n      \"disabled\": false,\n      \"alwaysAllow\": []\n    }\n  }\n}\n```\n\nMake sure to replace the following values:\n\n- `/path/to/rundeck-mcp-server/build/index.js`: The absolute path to the built index.js file\n- `/usr/bin/rd`: The absolute path to the Rundeck CLI tool\n- `http://your-rundeck-server:port/`: Your Rundeck server URL\n- `your-api-token`: Your Rundeck API token\n\n5. Restart VS Code or Claude Desktop for the settings to take effect.\n\n## How to Install Rundeck CLI\n\n- https://docs.rundeck.com/docs/rd-cli/install.html\n\n## Troubleshooting\n\nIf you encounter issues, check the following:\n\n1. Ensure the Rundeck CLI tool is available and working properly\n2. Make sure the RUNDECK_CLI_PATH environment variable points to the correct Rundeck CLI tool path\n3. Ensure the RUNDECK_BASE_URL and RUNDECK_API_TOKEN environment variables are set correctly\n4. Check that the MCP settings file is configured correctly\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "rundeck",
        "devops",
        "workflows",
        "management rundeck",
        "rundeck workflows",
        "rundeck operations"
      ],
      "category": "devops-and-cicd"
    },
    "yupengfei1209--coding_devops_mcp_server": {
      "owner": "yupengfei1209",
      "name": "coding_devops_mcp_server",
      "url": "https://github.com/yupengfei1209/coding_devops_mcp_server",
      "imageUrl": "/freedevtools/mcp/pfp/yupengfei1209.webp",
      "description": "Manage projects and work items on the CODING platform through a standardized interface, including functionalities to list, search, create, and delete projects and issues.",
      "stars": 1,
      "forks": 1,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-04-23T03:46:39Z",
      "readme_content": "# CODING DevOps MCP Server\n\nCODING DevOps MCP Server 是一个基于 Model Context Protocol (MCP) 的服务器实现，用于与 CODING DevOps 平台进行交互。它提供了一套标准化的接口，使得用户可以方便地管理 CODING 平台上的项目和工作项。\n\n## 功能特性\n\n- 项目管理\n  - 列出用户可访问的项目\n  - 按项目名称搜索项目\n- 工作项（Issues）管理\n  - 创建工作项\n  - 列出工作项\n  - 删除工作项\n  - 支持工作项类型、优先级等属性设置\n\n## 安装\n\n1. Clone this repository:\n```bash\ngit clone https://github.com/yupengfei1209/coding_devops_mcp_server.git\ncd coding_devops_mcp_server\n```\n\n2. Install dependencies:\n```bash\nnpm install\n```\n\n3. Build the server:\n```bash\nnpm run build\n```\n\n## 配置\n\n服务器需要以下配置项：\n\n1. CODING Personal Access Token (必需)\n2. 项目名称 (可选)\n\n\n### 添加到 MCP Client\n\n```json\n{\n  \"mcpServers\": {\n    \"coding-devops\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/your_path/coding_devops_mcp_server/build/index.js\"\n      ],\n      \"env\": {\n        \"CODING_TOKEN\": \"coding-token\",\n        \"PROJECT\": \"default project\" // 默认项目,可选配置\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    },\n  }\n}\n```\n\n\n\n## 功能\n\n### 项目管理\n\n- `list_projects`: 列出用户可访问的项目\n  ```typescript\n  // 可选参数\n  {\n    projectName?: string; // 按项目名称筛选\n  }\n  ```\n\n### 工作项管理\n\n- `list_work_items`: 列出工作项\n  ```typescript\n  // 参数\n  {\n    projectName: string;\n    issueType?: string;\n    limit?: string;\n    offset?: string;\n    sortKey?: string;\n    sortValue?: string;\n  }\n  ```\n\n- `create_work_item`: 创建工作项\n  ```typescript\n  // 参数\n  {\n    projectName: string;\n    name: string;\n    type: string;\n    priority: string;\n    description: string;\n  }\n  ```\n\n- `delete_work_item`: 删除工作项\n  ```typescript\n  // 参数\n  {\n    projectName: string;\n    issueCode: number;\n  }\n  ```\n\n## 开发\n\n### 项目结构\n\n```\nsrc/\n├── api/               # API 实现\n├── config/            # 配置相关\n├── tools/            # 工具实现\n│   ├── issue/        # 工作项相关功能\n│   └── project/      # 项目相关功能\n├── errors.ts         # 错误定义\n└── index.ts         # 主入口文件\n```\n\n## 许可证\n\n本项目采用 MIT 许可证。详见 [LICENSE](LICENSE) 文件。",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "coding_devops_mcp_server",
        "devops",
        "cicd",
        "yupengfei1209 coding_devops_mcp_server",
        "coding_devops_mcp_server manage",
        "devops cicd"
      ],
      "category": "devops-and-cicd"
    }
  }
}