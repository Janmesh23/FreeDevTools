{
  "category": "simulation-and-modeling",
  "categoryDisplay": "Simulation and Modeling",
  "description": "",
  "totalRepositories": 25,
  "repositories": {
    "3a3--fujitsu-sdt-mcp": {
      "owner": "3a3",
      "name": "fujitsu-sdt-mcp",
      "url": "https://github.com/3a3/fujitsu-sdt-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/3a3.webp",
      "description": "The Fujitsu Social Digital Twin Server allows users to interact with a simulation of social and traffic scenarios through natural language commands. It enables running simulations, analyzing results, and retrieving simulation data easily.",
      "stars": 2,
      "forks": 2,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-08-27T17:38:46Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/3a3-fujitsu-sdt-mcp-badge.png)](https://mseep.ai/app/3a3-fujitsu-sdt-mcp)\n\n# Fujitsu Social Digital Twin MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@3a3/fujitsu-sdt-mcp)](https://smithery.ai/server/@3a3/fujitsu-sdt-mcp)\n\nThis project integrates [Fujitsu's Social Digital Twin and Digital Rehearsal API](https://portal.research.global.fujitsu.com/converging-technology/) with the [Model Context Protocol (MCP)](https://modelcontextprotocol.io/), allowing Large Language Models (LLMs) to access Fujitsu's Digital Rehearsal API through natural language.\n\n<a href=\"https://glama.ai/mcp/servers/@3a3/fujitsu-sdt-mcp\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@3a3/fujitsu-sdt-mcp/badge\" alt=\"Fujitsu Social Digital Twin Server MCP server\" />\n</a>\n\n## Overview\n\nFujitsu's Social Digital Twin recreates not only the state of people and objects in the digital space based on real-world data, but also entire economic and social activities. Its core function, \"Digital Rehearsal,\" enables users to simulate human and social behavior in a digital space before implementing measures in the real world, allowing for advance verification of their effects and impacts.\n\nThis project uses MCP to bridge the gap between LLMs and the Digital Rehearsal API, enabling users to run simulations and analyze results using natural language.\n\n## Key Features\n\n- Retrieve and display simulation lists\n- Start simulations\n- Retrieve and analyze simulation results\n- Manage simulation data\n- Analyze traffic simulations\n- Compare scenarios\n- Generate simulation configurations from natural language\n\n## Prerequisites\n\n- Python 3.13 or higher\n- Access to Fujitsu API Gateway (API Key)\n- MCP-compatible LLM client (e.g., Claude Desktop)\n\n## Installation\n\n### Installing via Smithery\n\nTo install Fujitsu Social Digital Twin Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@3a3/fujitsu-sdt-mcp):\n\n```bash\nnpx -y @smithery/cli install @3a3/fujitsu-sdt-mcp --client claude\n```\n\n### 1. Clone the Repository\n\n```bash\ngit clone https://github.com/3a3/fujitsu-sdt-mcp.git\ncd fujitsu-sdt-mcp\n```\n\n### 2. Set Up Environment\n\n**Using uv (recommended)**:\n\nFirst, install uv:\n\n```bash\n# Install uv using pip\npip install uv\n\n# Or using curl (Linux/macOS)\ncurl -sSf https://astral.sh/uv/install.sh | sh\n```\n\nThen, set up your environment with uv:\n\n```bash\n# Create virtual environment\nuv venv\n\n# Activate virtual environment\n# Windows:\n.venv\\Scripts\\activate\n# Unix/MacOS:\nsource .venv/bin/activate\n\n# Install dependencies\nuv pip install -r requirements.txt\n```\n\nAlternatively, you can use the provided setup script:\n\n```bash\n# Make the script executable\nchmod +x setup.sh\n\n# Run setup\n./setup.sh\n```\n\n### 3. Set Environment Variables\n\n```bash\n# Windows:\nset FUJITSU_API_BASE_URL=https://apigateway.research.global.fujitsu.com/sdtp\nset FUJITSU_API_KEY=your_api_key_here\n\n# Unix/MacOS:\nexport FUJITSU_API_BASE_URL=https://apigateway.research.global.fujitsu.com/sdtp\nexport FUJITSU_API_KEY=your_api_key_here\n```\n\nAlternatively, you can create a `.env` file with the following settings:\n\n```\nFUJITSU_API_BASE_URL=https://apigateway.research.global.fujitsu.com/sdtp\nFUJITSU_API_KEY=your_api_key_here\n```\n\n## Usage\n\n### Starting the MCP Server\n\n```bash\npython -m fujitsu_sdt_mcp\n```\n\nThe server communicates using standard I/O with MCP clients.\n\n### Using the Interactive Client\n\nA simple client is also provided for direct interaction with the MCP server:\n\n```bash\npython client.py\n```\n\nWhen you start the client, a list of available resources and tools will be displayed, and you can call them from the command line.\n\n### Setup with Claude Desktop\n\nTo use the server with MCP-compatible LLM clients such as Claude Desktop:\n\n1. Open Claude Desktop\n2. Go to Settings > Developer Settings > Edit Config File\n3. Add the following settings:\n\n```json\n\"command\": \"uvx\",\n\"args\": [\n    \"fujitsu-sdt-mcp\"\n],\n\"env\": {\n    \"FUJITSU_API_BASE_URL\": \"https://apigateway.research.global.fujitsu.com/sdtp\",\n    \"FUJITSU_API_KEY\": \"your_api_key_here\"\n}\n```\n\n4. Restart Claude Desktop\n\n## Resources and Tools\n\n### Resources\n\n- `resource://digital_rehearsal_overview`: Overview of Digital Rehearsal technology\n- `resource://simulation_metrics_explanation`: Explanation of simulation metrics\n- `resource://scenario_examples`: Example scenarios\n\n### Tools\n\n- `list_simulations`: Retrieve a list of simulations\n- `start_simulation`: Start a simulation\n- `get_simulation_result`: Retrieve simulation results\n- `get_metrics`: Retrieve simulation metrics\n- `list_simdata`: Retrieve a list of simulation data\n- `get_simdata`: Retrieve simulation data\n- `analyze_traffic_simulation`: Analyze traffic simulation\n- `compare_scenarios`: Compare scenarios\n- `create_natural_language_simulation_config`: Generate simulation settings from natural language\n\n## Usage Examples\n\n### Retrieving a List of Simulations\n\n```\ntool list_simulations\n```\n\n### Starting a Simulation\n\n```\ntool start_simulation {\"simdataId\": \"your_simdata_id\"}\n```\n\n### Analyzing Traffic Simulation\n\n```\ntool analyze_traffic_simulation {\"simulationId\": \"your_simulation_id\", \"region\": \"Tokyo\", \"timeRange\": \"morning rush hour\", \"scenario\": \"traffic optimization\"}\n```\n\n### Generating Simulation Settings from Natural Language\n\n```\ntool create_natural_language_simulation_config {\"description\": \"I want to run a traffic optimization simulation during morning rush hour in Tokyo\"}\n```\n\n## Example LLM Interaction\n\n```\nUser: I want to run a traffic simulation during morning rush hour in Tokyo\n\nClaude: I can help you run a traffic simulation for Tokyo's morning rush hour. Here's how we can set it up.\n\nFirst, let's generate simulation settings from your natural language description:\n[Tool execution: create_natural_language_simulation_config]\n\nGenerated settings:\n{\n  \"simulationType\": \"traffic\",\n  \"parameters\": {\n    \"region\": \"Tokyo\",\n    \"timeRange\": \"morning_rush\"\n  },\n  \"name\": \"traffic_20250416_123045\"\n}\n\nNext, let's check available simulation data:\n[Tool execution: list_simdata]\n\nFrom this data, I can start a simulation using Tokyo's morning traffic data.\nI've selected the appropriate simulation data ID and will start the simulation:\n[Tool execution: start_simulation]\n\nThe simulation has started. The simulation ID is \"sim_12345\".\nIt will take some time for the results to be available. Once complete, I'll analyze them.\n\n(After simulation completes)\nLet's analyze the simulation results:\n[Tool execution: analyze_traffic_simulation]\n\nAnalysis results:\n- CO2 emissions: 1,250kg\n- Average travel time: 42 minutes\n- Total traffic volume: 15,700 vehicles\n\nFrom these results, I can see that the Shibuya-Shinjuku route experiences particularly severe congestion.\nHere are some potential improvements:\n1. Optimize traffic signal control\n2. Implement one-way traffic on certain roads during specific times\n3. Increase public transportation frequency\n\nWould you like to see a more detailed analysis?\n```\n\n## Contributing\n\nPlease report bugs or feature requests via GitHub Issues. Pull requests are welcome.\n\n## License\n\nThis project is released under the MIT License. See the LICENSE file for details.\n\n## Acknowledgments\n\n- Fujitsu Corporation - Development of Social Digital Twin technology\n- Model Context Protocol (MCP) - Enabling seamless integration with LLMs\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "simulations",
        "fujitsu",
        "simulation",
        "simulation social",
        "fujitsu social",
        "fujitsu sdt"
      ],
      "category": "simulation-and-modeling"
    },
    "AlexKissiJr--UnrealMCP": {
      "owner": "AlexKissiJr",
      "name": "UnrealMCP",
      "url": "https://github.com/AlexKissiJr/UnrealMCP",
      "imageUrl": "/freedevtools/mcp/pfp/AlexKissiJr.webp",
      "description": "Control and manipulate the Unreal Engine environment programmatically using AI tools through a Machine Control Protocol (MCP). Facilitate scene manipulation and automation to enhance the game development workflow.",
      "stars": 6,
      "forks": 1,
      "license": "No License",
      "language": "C++",
      "updated_at": "2025-06-11T11:25:27Z",
      "readme_content": "# UnrealMCP Plugin\n\n# VERY WIP REPO\nI'm working on adding more tools now and cleaning up the codebase, \nI plan to allow for easy tool extension outside the main plugin\n\nThis is very much a work in progress, and I need to clean up a lot of stuff!!!!!\n\nAlso, I only use windows, so I don't know how this would be setup for mac/unix\n\n## Overview\nUnrealMCP is an Unofficial Unreal Engine plugin designed to control Unreal Engine with AI tools. It implements a Machine Control Protocol (MCP) within Unreal Engine, allowing external AI systems to interact with and manipulate the Unreal environment programmatically.\n\nI only just learned about MCP a few days ago, so I'm not that familiar with it, I'm still learning so things might be initially pretty rough.\nI've implemented this using https://github.com/ahujasid/blender-mcp as a reference, which relies on Claude for Desktop. It now works with both Claude for Desktop and Cursor. If you experiment with other models, please let me know!\n\n## ⚠️ DISCLAIMER\nThis plugin allows AI agents to directly modify your Unreal Engine project. While it can be a powerful tool, it also comes with risks:\n\n- AI agents may make unexpected changes to your project\n- Files could be accidentally deleted or modified\n- Project settings could be altered\n- Assets could be overwritten\n\n**IMPORTANT SAFETY MEASURES:**\n1. Always use source control (like Git or Perforce) with your project\n2. Make regular backups of your project\n3. Test the plugin in a separate project first\n4. Review changes before committing them\n\nBy using this plugin, you acknowledge that:\n- You are solely responsible for any changes made to your project\n- The plugin author is not responsible for any damage, data loss, or issues caused by AI agents\n- You use this plugin at your own risk\n\n## Features\n- TCP server implementation for remote control of Unreal Engine\n- JSON-based command protocol for AI tools integration\n- Editor UI integration for easy access to MCP functionality\n- Comprehensive scene manipulation capabilities\n- Python companion scripts for client-side interaction\n\n## Roadmap\nThese are what I have in mind for development as of 3/14/2025\nI'm not sure what's possible yet, in theory anything, but it depends on how\ngood the integrated LLM is at utilizing these tools.\n- [X] Basic operations working\n- [X] Python working\n- [X] Materials\n- [ ] User Extensions (in progress)\n- [ ] Asset tools\n- [ ] Blueprints\n- [ ] Niagara VFX\n- [ ] Metasound\n- [ ] Landscape (I might hold off on this because Epic has mentioned they are going to be updating the landscape tools)\n- [ ] Modeling Tools\n- [ ] PCG\n\n## Requirements\n- Unreal Engine 5.5 (I have only tested on this version, may work with earlier, but no official support)\n- C++ development environment configured for Unreal Engine\n- Python 3.7+ for client-side scripting\n- Model to run the commands, in testing I've been using Claude for Desktop https://claude.ai/download\n\n## Prerequisites to run\n- Unreal Editor Installation (Tested with 5.3, but should work on 5.0+)\n- Python 3.7+ (This can run with your existing python install)\n- MCP compatible LLM (Claude for Desktop, Cursor, etc.)\n- Setup: run setup_unreal_mcp.bat in MCP folder as per instructions in MCP/README_MCP_SETUP.md\n\n## Quick Start for Cursor Users\nIf you want to use UnrealMCP with Cursor, follow these simple steps:\n\n1. Clone or download this repository as a zip\n2. Create a new Unreal Project, or open an existing one\n3. Create a \"Plugins\" folder in your project directory if it doesn't exist\n4. Unzip or copy this repository into the Plugins folder\n5. Run `setup_cursor_mcp.bat` in the MCP folder\n6. Open your Unreal project and enable the plugin in Edit > Plugins (if not already enabled)\n7. Start Cursor and ask it to work with your Unreal project\n\nThat's it! The setup script will automatically configure everything needed for Cursor integration.\n\n## Installation\n\n1. Clone or download this repository as a zip\n2. Create a new Unreal Project, or open an existing one\n3. Create a \"Plugins\" folder in your project directory if it doesn't exist\n4. Unzip or copy this repository into the Plugins folder\n5. Setup MCP \n    - Run the `setup_unreal_mcp.bat` script in the MCP folder (see `MCP/README_MCP_SETUP.md` for details)\n    - This will configure Python and your AI assistant (Claude for Desktop or Cursor)\n6. Open your Unreal project, the plugin should be available in the Plugins menu\n7. If not, enable the plugin in Edit > Plugins\n8. Choose your preferred AI assistant:\n    - For Claude for Desktop: follow the instructions in the \"With Claude for Desktop\" section below\n    - For Cursor: follow the instructions in the \"With Cursor\" section below\n\n## With Claude for Desktop\nYou will need to find your installation directory for Claude for Desktop. Find claude_desktop_config.json and add an entry and make it look like so:\n\n**Windows:** `%APPDATA%\\Claude\\claude_desktop_config.json`\n\n```json\n{\n    \"mcpServers\": {\n        \"unreal\": {\n            \"command\": \"C:/path/to/your/project/Plugins/UnrealMCP/MCP/run_unreal_mcp.bat\",\n            \"args\": []\n        }\n    }\n}\n```\n\nAlternatively the unreal_mcp_setup.bat script should do this for you.\n\nTo find the path to your claude for desktop install you can go into settings and click 'Edit Config'\nThis is usually in \n```\nC:\\Users\\USERNAME\\AppData\\Roaming\\Claude\n```\n\n## With Cursor\nCursor should be automatically configured if you've run the setup script with the Cursor option. If you need to manually configure it:\n\n**Windows:** `%APPDATA%\\Cursor\\User\\settings.json`\n\nAdd or update the settings with:\n```json\n{\n    \"mcp\": {\n        \"enabled\": true,\n        \"servers\": {\n            \"unreal\": {\n                \"command\": \"C:/path/to/your/project/Plugins/UnrealMCP/MCP/run_unreal_mcp.bat\",\n                \"args\": []\n            }\n        }\n    }\n}\n```\n\n## Testing\nOnce everything is setup you need to launch the unreal editor.\nNote: Nothing else has to be started or set up to run the mcp bridge, it will run when needed.\n\nOpen Claude for Desktop or Cursor, ensure that the tools have successfully enabled, ask your AI assistant to work in Unreal.\n\nHere are some example prompts to try:\n- \"What actors are in the current level?\" \n- \"Create a cube at position (0, 0, 100)\"\n- \"List available commands I can use with Unreal Engine\"\n\n## Usage\n### In Unreal Editor\nOnce the plugin is enabled, you'll find MCP controls in the editor toolbar button. \n![image](https://github.com/user-attachments/assets/68338e7a-090d-4fd9-acc9-37c0c1b63227)\n\n![image](https://github.com/user-attachments/assets/34f734ee-65a4-448a-a6db-9e941a588e93)\n\nThe TCP server can be started/stopped from here.\nCheck the output log under log filter LogMCP for extra information.\n\nOnce the server is confirmed up and running from the editor.\nOpen Claude for Desktop, ensure that the tools have successfully enabled, ask Claude to work in unreal.\n\nCurrently only basic operations are supported, creating objects, modfiying their transforms, getting scene info, and running python scripts.\nClaude makes a lot of errors with unreal python as I believe there aren't a ton of examples for it, but let it run and it will usually figure things out.\nI would really like to improve this aspect of how it works but it's low hanging fruit for adding functionality into unreal.\n\n### Client-Side Integration\nUse the provided Python scripts in the `MCP` directory to connect to and control your Unreal Engine instance:\n\n```python\nfrom unreal_mcp_client import UnrealMCPClient\n\n# Connect to the Unreal MCP server\nclient = UnrealMCPClient(\"localhost\", 13377)\n\n# Example: Create a cube in the scene\nclient.create_object(\n    class_name=\"StaticMeshActor\",\n    asset_path=\"/Engine/BasicShapes/Cube.Cube\",\n    location=(0, 0, 100),\n    rotation=(0, 0, 0),\n    scale=(1, 1, 1),\n    name=\"MCP_Cube\"\n)\n```\n\n## Command Reference\nThe plugin supports various commands for scene manipulation:\n- `get_scene_info`: Retrieve information about the current scene\n- `create_object`: Spawn a new object in the scene\n- `delete_object`: Remove an object from the scene\n- `modify_object`: Change properties of an existing object\n- `execute_python`: Run Python commands in Unreal's Python environment\n- And more to come...\n\nRefer to the documentation in the `Docs` directory for a complete command reference.\n\n## Security Considerations\n- The MCP server accepts connections from any client by default\n- Limit server exposure to localhost for development\n- Validate all incoming commands to prevent injection attacks\n\n## Troubleshooting\n- Ensure Unreal Engine is running with the MCP plugin.\n- Check logs in Claude for Desktop for stderr output.\n- Reach out on the discord, I just made it, but I will check it periodically\n  Discord (Dreamatron Studios): https://discord.gg/abRftdSe\n  \n### Project Structure\n- `Source/UnrealMCP/`: Core plugin implementation\n  - `Private/`: Internal implementation files\n  - `Public/`: Public header files\n- `Content/`: Plugin assets\n- `MCP/`: Python client scripts and examples\n- `Resources/`: Icons and other resources\n\n## License\nMIT License\n\nCopyright (c) 2025 kvick\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n\n## Credits\n- Created by: kvick\n- X: [@kvickart](https://x.com/kvickart)\n- Discord: https://discord.gg/abRftdSe\n  \n### Thank you to testers!!!\n- https://github.com/TheMurphinatur\n  \n- [@sidahuj](https://x.com/sidahuj) for the inspriation\n\n\n\n## Contributing\nContributions are welcome, but I will need some time to wrap my head around things and cleanup first, lol\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "unrealmcp",
        "ai",
        "automation",
        "unreal engine",
        "unrealmcp control",
        "ai tools"
      ],
      "category": "simulation-and-modeling"
    },
    "BearNetwork-BRNKC--SketchUp-MCP": {
      "owner": "BearNetwork-BRNKC",
      "name": "SketchUp-MCP",
      "url": "https://github.com/BearNetwork-BRNKC/SketchUp-MCP",
      "imageUrl": "/freedevtools/mcp/pfp/BearNetwork-BRNKC.webp",
      "description": "Integrates Sketchup with Claude AI for real-time interaction and control of 3D modeling tasks. Facilitate the creation, modification, and manipulation of components and materials through direct Ruby code execution and fetch details from the current Sketchup scene.",
      "stars": 11,
      "forks": 1,
      "license": "MIT License",
      "language": "Ruby",
      "updated_at": "2025-08-28T16:17:32Z",
      "readme_content": "# SketchupMCP - Sketchup 模型上下文協議（MCP）整合\n[![smithery badge](https://smithery.ai/badge/@BearNetwork-BRNKC/SketchUp-MCP)](https://smithery.ai/server/@BearNetwork-BRNKC/SketchUp-MCP)\n\nSketchupMCP 透過模型上下文協議（MCP）將 Sketchup 連接到 Claude AI，使 Claude 能夠直接與 Sketchup 互動和控制。這項整合允許使用提示輔助 3D 建模、場景創建和操作 Sketchup。\n\n特別感謝 [mhyrr/sketchup-mcp](https://github.com/mhyrr/sketchup-mcp) 提供的架構。\n我們對其原生版本(mhyrr/sketchup-mcp)進行了繁體中文化及部份功能優化與調整。\n\n## 功能\n\n* **雙向通信**：透過 TCP 套接字連接 Claude AI 與 Sketchup\n* **組件操作**：在 Sketchup 中創建、修改、刪除和變換組件\n* **材質控制**：應用和修改材質與顏色\n* **場景檢查**：獲取當前 Sketchup 場景的詳細資訊\n* **選取處理**：獲取並操作已選取的組件\n* **Ruby 代碼執行**：在 Sketchup 中直接執行任意 Ruby 代碼，以進行高級操作\n\n## 組件\n\n該系統由兩個主要組件組成：\n\n1. **Sketchup 擴展**：在 Sketchup 內部創建 TCP 伺服器來接收並執行命令的擴展\n2. **MCP 伺服器（`sketchup_mcp/server.py`）**：實作模型上下文協議並連接到 Sketchup 擴展的 Python 伺服器\n\n## 安裝\n\n### 安裝 Sketchup 擴展\n\n1. 下載或自行構建最新的 `.rbz` 檔案\n2. 在 Sketchup 中，前往 **Window > Extension Manager**\n3. 點擊 **Install Extension**，然後選擇下載的 `.rbz` 檔案\n4. 重新啟動 Sketchup\n\n### Python 套件安裝\n\n我們使用 `uv` 來管理 Python 環境，因此需要先安裝 `uv`：\n\n```sh\npip install uv\n```\n\n### Installing via Smithery\n\n要使用  [Smithery](https://smithery.ai/server/@BearNetwork-BRNKC/SketchUp-MCP) 安裝 Sketchup MCP：\n\n```bash\nnpx -y @smithery/cli install @BearNetwork-BRNKC/SketchUp-MCP --client claude\n```\n\n### 安裝 Sketchup 擴展\n\n1. 下載或自行構建最新的 `.rbz` 檔案\n2. 在 Sketchup 中，前往 **Window > Extension Manager**\n3. 點擊 **Install Extension**，然後選擇下載的 `.rbz` 檔案\n4. 重新啟動 Sketchup\n\n## 使用方式\n\n### 啟動連線\n\n1. 在 Sketchup 中，前往 **Extensions > SketchupMCP > Start Server**\n2. 伺服器將預設啟動在 **9876** 端口\n3. 確保 MCP 伺服器已在終端執行\n\n### 與 Claude 配合使用\n\n在 Claude 配置中加入以下內容，以使用 MCP 伺服器：\n\n```json\n\"mcpServers\": {\n    \"sketchup\": {\n        \"command\": \"uvx\",\n        \"args\": [\n            \"sketchup-mcp\"\n        ]\n    }\n}\n```\n\n這將自動從 [PyPI](https://pypi.org/project/sketchup-mcp/) 下載最新版本。\n\n成功連接後，Claude 將能夠透過以下功能與 Sketchup 互動：\n\n#### 工具\n\n* `get_scene_info` - 獲取當前 Sketchup 場景資訊\n* `get_selected_components` - 獲取當前選取的組件資訊\n* `create_component` - 創建新組件並指定參數\n* `delete_component` - 從場景中刪除組件\n* `transform_component` - 移動、旋轉或縮放組件\n* `set_material` - 為組件應用材質\n* `export_scene` - 將當前場景匯出為多種格式\n* `eval_ruby` - 在 Sketchup 中執行任意 Ruby 代碼以進行高級操作\n\n### 指令示例\n\n以下是一些可以要求 Claude 執行的操作示例：\n\n* \"創建一個帶有屋頂和窗戶的簡單房屋模型\"\n* \"選取所有組件並獲取它們的資訊\"\n* \"將選取的組件變成紅色\"\n* \"將選取的組件向上移動 10 個單位\"\n* \"將當前場景匯出為 3D 模型\"\n* \"使用 Ruby 代碼創建一個複雜的藝術與工藝櫃\"\n\n## 疑難排解\n\n* **連線問題**：確保 Sketchup 擴展伺服器和 MCP 伺服器都在運行\n* **命令執行失敗**：檢查 Sketchup 的 Ruby 控制台以查看錯誤訊息\n* **超時錯誤**：嘗試簡化請求或將操作拆分為較小的步驟\n\n## 技術細節\n\n### 通信協議\n\n該系統使用基於 TCP 套接字的簡單 JSON 協議：\n\n* **命令** 以 JSON 物件的形式發送，包含 `type` 和可選的 `params`\n* **回應** 以 JSON 物件的形式返回，包含 `status` 及 `result` 或 `message`\n\n## 授權\n\nMIT 授權許可證\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "sketchup",
        "modeling",
        "brnkc",
        "brnkc sketchup",
        "sketchup mcp",
        "integrates sketchup"
      ],
      "category": "simulation-and-modeling"
    },
    "InditexTech--mcp-server-simulator-ios-idb": {
      "owner": "InditexTech",
      "name": "mcp-server-simulator-ios-idb",
      "url": "https://github.com/InditexTech/mcp-server-simulator-ios-idb",
      "imageUrl": "/freedevtools/mcp/pfp/InditexTech.webp",
      "description": "Control iOS simulators using natural language commands to automate app management, UI interactions, and debugging tasks, streamlining the development workflow.",
      "stars": 261,
      "forks": 18,
      "license": "Apache License 2.0",
      "language": "TypeScript",
      "updated_at": "2025-10-02T18:22:07Z",
      "readme_content": "# 📱 MCP Server for iOS Simulator\n\n[![MCP Server](https://glama.ai/mcp/servers/@InditexTech/mcp-server-simulator-ios-idb/badge)](https://glama.ai/mcp/servers/@InditexTech/mcp-server-simulator-ios-idb)\n\nA Model Context Protocol (MCP) server that enables LLMs to interact with iOS simulators through natural language commands.\n\n## ℹ️ Overview\n\nThis MCP server provides a bridge between Large Language Models (LLMs) and iOS simulators, offering comprehensive control through natural language commands. Here's what it can do:\n\nFor detailed usage, see the Installation guide and Supported Commands sections. You can use this server either through direct MCP integration or as a standalone library.\n\nCheck out the Architecture section to understand how the components work together to enable natural language control of iOS simulators.\n\n\n\n### 🎮 Simulator Control\n- Create and manage simulator sessions\n- Boot, shutdown, and monitor simulator states\n- List available and running simulators\n- Focus simulator windows\n\n### 📱 Application Management\n- Install and manage iOS applications\n- Launch, terminate, and uninstall apps\n- Monitor app states and verify installations\n- Handle app permissions and configurations\n\n### 🖱️ UI Interaction & Testing\n- Interact with the simulator UI\n- Execute tap, swipe, and button press actions\n- Input text and key sequences\n- Access accessibility elements for UI testing\n- Record videos of UI interactions\n\n### 🛠️ Development & Debugging\n- Capture screenshots and system logs\n- Debug applications in real-time\n- Monitor and analyze crash logs\n- Install dynamic libraries and manage app data\n\n### ⚡ Advanced Features\n- Additional functionality includes:\n  - Location simulation\n  - Media injection\n  - URL scheme handling\n  - Contact database management\n  - Keychain operations\n\nFor detailed usage, see the Installation guide and Supported Commands sections. You can use this server either through direct MCP integration or as a standalone library.\n\nCheck out the Architecture section to understand how the components work together to enable natural language control of iOS simulators.\n\n## 📋 Requirements\n\n- **macOS**: Required for iOS simulator support\n- **Node.js**: v14.0.0 or higher\n- **Homebrew**: Required for installing dependencies\n- **XCode**: With iOS simulators installed\n\n## 🚀 Installation\n\nThe easiest way to install this server is through Cline:\n\n1. Simply ask Cline:\n```\nAdd this mcp to cline https://github.com/InditexTech/mcp-server-simulator-ios-idb\n```\n\n2. Cline will handle the installation process automatically, including dependency management and configuration.\n\nAlternatively, you can install it manually:\n\n```bash\n# Clone the repository\ngit clone https://github.com/InditexTech/mcp-server-simulator-ios-idb.git\ncd mcp-server-simulator-ios-idb\n\n# Create and activate Python virtual environment\npython3 -m venv venv\nsource venv/bin/activate  # On Unix/macOS\n\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n\n# Start the project\nnpm start\n\n# Run tests\nnpm test\n```\n\nThe installation process will automatically:\n1. Check if you're running macOS\n2. Install idb-companion via Homebrew\n3. Install fb-idb via pip in the virtual environment\n\nNote: Make sure to keep the virtual environment activated while using the server. If you close your terminal and come back later, you'll need to reactivate the virtual environment with the `source venv/bin/activate` command before running `npm start`.\n\n## 🔌 MCP Integration\n\nTo use this server with Claude or other LLM assistants:\n\n1. Add the server to your MCP settings in Claude Desktop:\n\n```json\n{\n  \"mcpServers\": {\n    \"ios-simulator\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/mcp-server-simulator-ios-idb/dist/index.js\"],\n      \"env\": {}\n    }\n  }\n}\n```\n\n2. The LLM can now use natural language commands to control iOS simulators:\n\n```\ncreate a simulator session with iPhone 14\ninstall app /path/to/my-app.ipa\nlaunch app com.example.myapp\ntap at 100, 200\ntake a screenshot\n```\n\n## 📚 Usage as a Library\n\nYou can also use this package as a library in your own projects:\n\n### 🔰 Basic Usage\n\n```typescript\nimport { createMCPServer } from 'mcp-server-simulator-ios-idb';\n\nasync function main() {\n  // Create an instance of the MCP server\n  const { orchestrator } = createMCPServer();\n  \n  // Process natural language commands\n  \n  // Create a simulator session\n  const sessionResult = await orchestrator.processInstruction('create session');\n  console.log(`Session created: ${sessionResult.data}`);\n  \n  // Interact with the simulator\n  await orchestrator.processInstruction('tap at 100, 200');\n  \n  // Capture a screenshot\n  const screenshotResult = await orchestrator.processInstruction('take screenshot');\n  console.log(`Screenshot saved at: ${screenshotResult.data}`);\n}\n\nmain().catch(console.error);\n```\n\n### 🚀 Advanced Usage\n\nYou can also use the individual components directly:\n\n```typescript\nimport { \n  IDBManager, \n  NLParser, \n  MCPOrchestrator,\n  ParserToOrchestrator,\n  OrchestratorToIDB\n} from 'mcp-server-simulator-ios-idb';\n\n// Create instances\nconst idbManager = new IDBManager();\nconst parser = new NLParser();\nconst orchestrator = new MCPOrchestrator(parser, idbManager);\n\n// Use the components directly\nconst sessionId = await idbManager.createSimulatorSession({\n  deviceName: 'iPhone 12',\n  platformVersion: '15.0'\n});\n\nawait idbManager.tap(sessionId, 100, 200);\n```\n\n## 🏗️ Project Structure\n\n```\nmcp-server-simulator-ios-idb/\n├── src/                      # Source code\n│   ├── adapters/             # Adapter components\n│   ├── idb/                  # IDB manager implementation\n│   ├── mcp/                  # MCP server implementation\n│   ├── orchestrator/         # Command orchestrator\n│   ├── parser/              # Natural language parser\n│   └── index.ts             # Main entry point\n├── types/                   # TypeScript type definitions\n├── scripts/                 # Installation scripts\n├── package.json            # Project configuration\n└── tsconfig.json          # TypeScript configuration\n```\n\n## 🎯 Supported Commands\n\nThe NLParser supports the following natural language commands:\n\n### 🎮 Simulator Management\n| Command | Description | Example |\n|---------|-------------|---------|\n| Create session | Creates a new simulator session | \"create session\", \"create simulator iPhone 12\" |\n| Terminate session | Terminates the current session | \"terminate session\", \"close simulator\" |\n| List simulators | Lists available simulators | \"list simulators\", \"show simulators\" |\n| List booted simulators | Lists running simulators | \"list booted simulators\", \"show running simulators\" |\n| Boot simulator | Boots a simulator by UDID | \"boot simulator 5A321B8F-4D85-4267-9F79-2F5C91D142C2\" |\n| Shutdown simulator | Shuts down a simulator | \"shutdown simulator 5A321B8F-4D85-4267-9F79-2F5C91D142C2\" |\n| Focus simulator | Brings simulator window to front | \"focus simulator\", \"bring simulator to front\" |\n| List simulator sessions | Lists active simulator sessions | \"list simulator sessions\", \"show active sessions\" |\n\n### 📱 App Management\n| Command | Description | Example |\n|---------|-------------|---------|\n| Install app | Installs an app on the simulator | \"install app /path/to/app.ipa\" |\n| Launch app | Launches an app on the simulator | \"launch app com.example.app\" |\n| Terminate app | Terminates a running app | \"terminate app com.example.app\" |\n| Uninstall app | Uninstalls an app | \"uninstall app com.example.app\" |\n| List apps | Lists installed applications | \"list apps\", \"show installed apps\" |\n| Check if app installed | Checks if an app is installed | \"is app com.example.app installed\" |\n\n### 🖱️ UI Interaction\n| Command | Description | Example |\n|---------|-------------|---------|\n| Tap | Taps at specific coordinates | \"tap at 100, 200\" |\n| Swipe | Performs a swipe gesture | \"swipe from 100, 200 to 300, 400\" |\n| Press button | Presses a device button | \"press button HOME\", \"press button SIRI\" |\n| Input text | Types text | \"input text Hello World\" |\n| Press key | Presses a key by code | \"press key 4\" |\n| Press key sequence | Presses a sequence of keys | \"press key sequence 4 5 6\" |\n\n### ♿ Accessibility\n| Command | Description | Example |\n|---------|-------------|---------|\n| Describe elements | Lists all accessibility elements | \"describe all elements\", \"show accessibility elements\" |\n| Describe point | Describes element at coordinates | \"describe point 100, 200\", \"what's at 150, 300\" |\n\n### 📸 Capture and Logs\n| Command | Description | Example |\n|---------|-------------|---------|\n| Take screenshot | Captures a screenshot | \"take screenshot\", \"capture screen\" |\n| Record video | Records screen activity | \"record video /path/output.mp4\" |\n| Stop recording | Stops video recording | \"stop recording\", \"stop video recording\" |\n| Get logs | Retrieves system or app logs | \"get logs\", \"get logs for com.example.app\" |\n\n### 🐛 Debug\n| Command | Description | Example |\n|---------|-------------|---------|\n| Start debug | Starts a debug session | \"debug app com.example.app\", \"start debug com.example.app\" |\n| Stop debug | Stops a debug session | \"stop debug\", \"terminate debug session\" |\n| Debug status | Gets debug session status | \"debug status\", \"show debug info\" |\n\n### 💥 Crash Logs\n| Command | Description | Example |\n|---------|-------------|---------|\n| List crash logs | Lists available crash logs | \"list crash logs\", \"show crash logs\" |\n| Show crash log | Shows content of a crash log | \"show crash log crash_2023-01-01\" |\n| Delete crash logs | Deletes crash logs | \"delete crash logs\", \"clear crash logs\" |\n\n### 🔧 Additional Commands\n| Command | Description | Example |\n|---------|-------------|---------|\n| Install dylib | Installs a dynamic library | \"install dylib /path/to/library.dylib\" |\n| Open URL | Opens a URL in the simulator | \"open url https://example.com\" |\n| Clear keychain | Clears the simulator's keychain | \"clear keychain\" |\n| Set location | Sets the simulator's location | \"set location 37.7749, -122.4194\" |\n| Add media | Adds media to the camera roll | \"add media /path/to/image.jpg\" |\n| Approve permissions | Approves app permissions | \"approve permissions com.example.app photos camera\" |\n| Update contacts | Updates contacts database | \"update contacts /path/to/contacts.sqlite\" |\n\nThe interface supports all commands available in the idb CLI tool, providing a comprehensive set of operations for iOS simulator automation.\n\n## 🔍 Architecture\n\nThe server consists of three main components:\n\n1. **IDBManager**: Low-level component that interacts directly with iOS simulators through idb.\n2. **NLParser**: Component that interprets natural language instructions and converts them into structured commands.\n3. **MCPOrchestrator**: Central component that coordinates interactions between the parser and the IDBManager.\n\nThese components are connected through adapters:\n- **ParserToOrchestrator**: Converts parser results into orchestrator commands.\n- **OrchestratorToIDB**: Translates orchestrator commands into IDBManager calls.\n\n## 🔌 MCP Integration\n\nTo use this server with the Model Context Protocol:\n\n1. Add the server to your MCP settings:\n\n```json\n{\n  \"mcpServers\": {\n    \"ios-simulator\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/mcp-server-simulator-ios-idb/dist/index.js\"],\n      \"env\": {}\n    }\n  }\n}\n```\n\n2. Connect to the server in your LLM application:\n\n```typescript\nconst result = await useMcpTool({\n  serverName: \"ios-simulator\",\n  toolName: \"process-instruction\",\n  arguments: {\n    instruction: \"create simulator session\"\n  }\n});\n```\n\n## 🙏 Acknowledgments\n\nThis project would not be possible without [facebook/idb](https://github.com/facebook/idb), which provides the underlying iOS simulator control capabilities. We extend our sincere gratitude to the Facebook/Meta team and all contributors to the idb project for creating and maintaining such a powerful and reliable tool.\n\n## 📄 License\n\nThis tool is available as open source under the terms of the Apache-2.0.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "simulators",
        "simulator",
        "ios",
        "ios simulators",
        "simulator ios",
        "simulators using"
      ],
      "category": "simulation-and-modeling"
    },
    "JotaDeRodriguez--Bonsai_mcp": {
      "owner": "JotaDeRodriguez",
      "name": "Bonsai_mcp",
      "url": "https://github.com/JotaDeRodriguez/Bonsai_mcp",
      "imageUrl": "/freedevtools/mcp/pfp/JotaDeRodriguez.webp",
      "description": "Connects Blender with Claude to analyze and manipulate IFC models, enabling querying of project information, exploration of spatial structures, and execution of Python code within Blender.",
      "stars": 26,
      "forks": 6,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-02T21:36:13Z",
      "readme_content": "\n# Bonsai-mcp - Model Context Protocol Integration for IFC through IfcOpenShell and Blender\n\nBonsai-mcp is a fork of [BlenderMCP](https://github.com/ahujasid/blender-mcp) that extends the original functionality with dedicated support for IFC (Industry Foundation Classes) models through Bonsai. This integration is a platform to let LLMs read and modify IFC files.\n\n## Features\n\n- **IFC-specific functionality**: Query IFC models, analyze spatial structures, examine building elements and extract quantities\n\n- **Eleven IFC tools included**: Inspect project info, list entities, examine properties, explore spatial structure, analyze relationships and more\n\n- **Sequential Thinking**: Includes the sequential thinking tool from [modelcontextprotocol/servers](https://github.com/modelcontextprotocol/servers/tree/main/src/sequentialthinking) for structured problem solving\n\n- **Execute Code tool from the original BlenderMCP implementation**: Create and modify objects, apply materials, and execute Python code in Blender\n\n## Components\n\nThe system consists of two main components:\n\n1. **Blender Addon (`addon.py`)**: A Blender addon that creates a socket server within Blender to receive and execute commands, including IFC-specific operations\n\n2. **MCP Server (`tools.py`)**: A Python server that implements the Model Context Protocol and connects to the Blender addon\n\n## Installation - Through MCP Client Settings\n\n### Prerequisites\n\n- Blender 4.0 or newer\n\n- Python 3.12 or newer\n\n- uv package manager\n\n- Bonsai BIM addon for Blender (for IFC functionality)\n\n**Installing uv:**\n\n**Mac:**\n\n```bash\n\nbrew  install  uv\n\n```\n\n**Windows:**\n\n```bash\n\npowershell  -c  \"irm https://astral.sh/uv/install.ps1 | iex\"\n\nset  Path=C:\\Users\\[username]\\.local\\bin;%Path%\n\n```\n\nFor other platforms, see the [uv installation guide](https://docs.astral.sh/uv/getting-started/installation/).\n\n### Clone the repository\n\n```bash\n\ngit  clone  https://github.com/JotaDeRodriguez/Bonsai_mcp\n\n```\n\n### Claude for Desktop Integration\n\nEdit your `claude_desktop_config.json` file (Claude > Settings > Developer > Edit Config) to include:\n\n```json\n{\n    \"mcpServers\": {\n        \"Bonsai-mcp\": {\n            \"command\": \"uv\",\n            \"args\": [\n              \"--directory\",\n              \"\\\\your\\\\path\\\\to\\\\Bonsai_mcp\",\n              \"run\",\n              \"tools.py\"\n          ]\n        }\n    }\n}\n\n```\n\n## Installation via Docker\n\nThe repository comes with a Dockerfile that makes deployment simple and consistent across different environments.\n\n## Quick Start\n\n```bash\n# Clone the repository\ngit clone https://github.com/JotaDeRodriguez/Bonsai_mcp\ncd Bonsai_mcp\n\n# Build the Docker image\ndocker build -t bonsai_mcp .\n\n# Run the container\ndocker run -p 8000:8000 --name bonsai_mcp bonsai_mcp\n```\n\nOnce running, the container will expose the MCP tools as REST/OpenAPI APIs at `http://localhost:8000`.\n\n- To verify youtr installation, open your browser and navigate to\n- `http://localhost:8000/docs`\n- You'll see the Swagger UI with all available endpoints\n- Test an endpoint by clicking on it, then click \"Try it out\" and \"Execute\"\n\n### Connecting to Open WebUI or Other API Clients\n\nTo connect this API to Open WebUI:\n\n1. In Open WebUI, go to Settings > Manage Tool Servers\n2. Add a new connection with:\n\n- URL: `http://localhost:8000`\n- Path to OpenAPI spec: `/openapi.json`\n- Authentication: None (unless configured otherwise)\n\n### Environment Variables\n\nThe Docker container accepts several environment variables to customize its behavior:\n\n```bash\n# Example with custom settings\ndocker run -p 8000:8000 \\\n  -e BLENDER_HOST=host.docker.internal \\\n  -e BLENDER_PORT=9876 \\\n  -e MCP_HOST=0.0.0.0 \\\n  -e MCP_PORT=8000 \\\n  --name bonsai_mcp bonsai_mcp\n```\n\n## Installing the Blender Addon\n\n1. Download the `addon.py` file from this repo\n\n2. Open Blender\n\n3. Go to Edit > Preferences > Add-ons\n\n4. Click \"Install...\" and select the `addon.py` file\n\n5. Enable the addon by checking the box next to \"Interface: Blender MCP - IFC\"\n\n## Usage\n\n### Starting the Connection\n\n1. In Blender, go to the 3D View sidebar (press N if not visible)\n\n2. Find the \"Blender MCP - IFC\" tab\n\n3. Click \"Connect to Claude\"\n\n4. Make sure the MCP server is running\n\n### Using with Claude\n\nOnce connected, you'll see a hammer icon in Claude's interface with tools for the Blender MCP IFC integration.\n\n## IFC Tools\n\nThis repo includes multiple IFC-specific tools that enable comprehensive querying and manipulation of IFC models:\n\n**get_ifc_project_info**: Retrieves basic information about the IFC project, including name, description, and counts of different entity types. Example: \"What is the basic information about this IFC project?\"\n\n**list_ifc_entities**: Lists IFC entities of a specific type (walls, doors, spaces, etc.) with options to limit results and filter by selection. Example: \"List all the walls in this IFC model\" or \"Show me the windows in this building\"\n\n**get_ifc_properties**: Retrieves all properties of a specific IFC entity by its GlobalId or from currently selected objects. Example: \"What are the properties of this wall with ID 1Dvrgv7Tf5IfTEapMkwDQY?\"\n\n**get_ifc_spatial_structure**: Gets the spatial hierarchy of the IFC model (site, building, storeys, spaces). Example: \"Show me the spatial structure of this building\"\n\n**get_ifc_relationships**: Retrieves all relationships for a specific IFC entity. Example: \"What are the relationships of the entrance door?\"\n\n**get_selected_ifc_entities**: Gets information about IFC entities corresponding to objects currently selected in the Blender UI. Example: \"Tell me about the elements I've selected in Blender\"\n\n**get_user_view**: Captures the current Blender viewport as an image, allowing visualization of the model from the user's perspective. Example: \"Show me what the user is currently seeing in Blender\"\n\n**export_ifc_data**: Exports IFC data to a structured JSON or CSV file, with options to filter by entity type or building level. Example: \"Export all wall data to a CSV file\"\n\n**place_ifc_object**: Creates and positions an IFC element in the model at specified coordinates with optional rotation. Example: \"Place a door at coordinates X:10, Y:5, Z:0 with 90 degrees rotation\"\n\n**get_ifc_quantities**: Calculate and get quantities (m2, m3, etc.) for IFC elements, with options to filter by entity type or selected ones. Example: \"Give me the area of all the walls in the building using the tool get_ifc_quantities\"\n\n**export_drawing_png**: Exports 2D and 3D drawings as high-resolution PNG images with customizable resolution and view parameters. Creates orthographic plan views from above at specified height offsets. Example: \"Generate a floor plan PNG for the ground floor at 1920x1080 resolution\"\n\n**get_ifc_georeferencing_info**: Retrieves comprehensive georeferencing information from IFC files including coordinate reference systems (CRS), map conversions, world coordinate systems, true north direction, and site geographic coordinates. Example: \"What georeferencing information is available in this IFC model?\"\n\n**georeference_ifc_model**: Creates or updates georeferencing information in IFC models, allowing you to set coordinate reference systems using EPSG codes or custom CRS definitions, establish map conversions with eastings/northings coordinates, and configure site geographic positioning. Example: \"Georeference this IFC model using EPSG:4326 with coordinates at latitude 40.7589, longitude -73.9851\"\n\n## MCP Resources\n\nThis integration provides access to structured documentation through MCP resources:\n\n**file://table_of_contents.md**: Contains the complete technical report structure template for generating comprehensive building reports. This resource provides a standardized table of contents that can be used as a reference when creating technical documentation from IFC models.\n\n## MCP Prompts\n\nThe server includes specialized MCP Prompts for automated report generation:\n\n**Technical_building_report**: Generates comprehensive technical building reports based on IFC models loaded in Blender. This prompt provides a structured workflow for creating professional architectural documentation in multiple languages (English, Spanish, French, German, Italian, Portuguese). The prompt guides the analysis through systematic data extraction from the IFC model, including spatial structure, quantities, materials, and building systems, culminating in a complete technical report with drawings and 3D visualizations.\n\n## Execute Blender Code\n\nLegacy feature from the original MCP implementation. Allows Claude to execute arbitrary Python code in Blender. Use with caution.\n\n## Sequential Thinking Tool\n\nThis integration includes the Sequential Thinking tool for structured problem-solving and analysis. It facilitates a step-by-step thinking process that can branch, revise, and adapt as understanding deepens - perfect for complex IFC model analysis or planning tasks.\n\nExample: \"Use sequential thinking to analyze this building's energy efficiency based on the IFC model\"\n\n## Example Commands\n\nHere are some examples of what you can ask Claude to do with IFC models:\n\n- \"Analyze this IFC model and tell me how many walls, doors and windows it has\"\n\n- \"Show me the spatial structure of this building model\"\n\n- \"List all spaces in this IFC model and their properties\"\n\n- \"Identify all structural elements in this building\"\n\n- \"What are the relationships between this wall and other elements?\"\n\n- \"Generate a report of the measurements from the IFC model opened in Blender\"\n\n- \"Use sequential thinking to create a maintenance plan for this building based on the IFC model\"\n\n## Troubleshooting\n\n- **Connection issues**: Make sure the Blender addon server is running, and the MCP server is configured in Claude\n- **IFC model not loading**: Verify that you have the Bonsai BIM addon installed and that an IFC file is loaded\n- **Timeout errors**: Try simplifying your requests or breaking them into smaller steps\n\n**Docker:**\n\n- **\"Connection refused\" errors**: Make sure Blender is running and the addon is enabled with the server started\n- **CORS issues**: The API has CORS enabled by default for all origins. If you encounter issues, check your client's CORS settings\n- **Performance concerns**: For large IFC models, the API responses might be slower. Consider adjusting timeouts in your client\n\n## Technical Details\n\nThe IFC integration uses the Bonsai BIM module to access ifcopenshell functionality within Blender. The communication follows the same JSON-based protocol over TCP sockets as the original BlenderMCP.\n\n## Limitations & Security Considerations\n\n- The `execute_blender_code` tool from the original project is still available, allowing running arbitrary Python code in Blender. Use with caution and always save your work.\n\n- Complex IFC models may require breaking down operations into smaller steps.\n\n- IFC query performance depends on model size and complexity.\n\n- Get User View tool returns a base64 encoded image. Please ensure the client supports it.\n\n## Contributions\n\nThis MIT licensed repo is open to be forked, modified and used in any way. I'm open to ideas and collaborations, so don't hesitate to get in contact with me for contributions.\n\n## Credits\n\n- Original BlenderMCP by [Siddharth Ahuja](https://github.com/ahujasid/blender-mcp)\n\n- Sequential Thinking tool from [modelcontextprotocol/servers](https://github.com/modelcontextprotocol/servers/tree/main/src/sequentialthinking)\n\n- IFC integration built upon the Bonsai BIM addon for Blender\n\n## TO DO\n\nIntegration and testing with more MCP Clients\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "python",
        "modeling",
        "simulation",
        "ifc models",
        "simulation modeling",
        "code blender"
      ],
      "category": "simulation-and-modeling"
    },
    "PatrickPalmer--MayaMCP": {
      "owner": "PatrickPalmer",
      "name": "MayaMCP",
      "url": "https://github.com/PatrickPalmer/MayaMCP",
      "imageUrl": "/freedevtools/mcp/pfp/PatrickPalmer.webp",
      "description": "Control Autodesk Maya using natural language commands via the Model Context Protocol, enabling the creation, modification, and querying of Maya scenes without requiring installation inside Maya.",
      "stars": 26,
      "forks": 10,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-17T20:52:14Z",
      "readme_content": "# Maya MCP\r\nModel Context Protocol (MCP) server implementation for Autodesk Maya\r\n\r\nTested with Maya 2023, 2025.\r\n\r\nv0.2.0\r\n\r\nThis project enables AI assistant clients like Claude Desktop to control Autodesk Maya through natural language using the [Model Context Protocol (MCP)](https://modelcontextprotocol.io/). \r\n\r\nThis is early days for Maya MCP server and has a minimal set of functionality. It's really the architecture design and simplicity that has been the initial focus.\r\n\r\nHere is a list of some of the tools registered with Maya MCP.\r\n\r\n## Basic Tools\r\n\r\n| Tool | Description |\r\n|------|-------------|\r\n| list_objects_by_type | Get a list of objects in the scene. Use filter_by to filter for certain objects such as \"cameras\", \"lights\", \"materials\", or \"shapes\". |\r\n| create_object | Create an object in the Maya scene. Object types available are cube, cone, sphere, cylinder, camera, spotLight, pointLight, directionalLight. |\r\n| get_object_attributes | Get a list of attributes on a Maya object. | \r\n| set_object_attributes | Set an object's attribute with a specific value. |\r\n| scene_new | Create a new scene in Maya. Use the force argument to force a new scene when an existing scene is loaded and has been modified. |\r\n| scene_open | Load in a scene into Maya. | \r\n| scene_save | Save the current scene. If the filename is not specified, it will save it as its current name. |\r\n| select_object | Select an object in the scene. |\r\n\r\n## Advanced Modeling Tools\r\n\r\n| Tool | Description |\r\n|------|-------------|\r\n| create_advanced_model | Create complex 3D models like cars, trees, buildings, cups, and chairs with detailed parameters. |\r\n| mesh_operations | Perform modeling operations such as extrude, bevel, subdivide, boolean, combine, bridge, and split. |\r\n| create_material | Create and assign materials with various types (lambert, phong, wood, marble, chrome, glass, etc.) |\r\n| create_curve | Generate NURBS curves for various shapes (line, circle, spiral, helix, star, gear, etc.) |\r\n| curve_modeling | Create geometry using curve-based modeling techniques (extrude, loft, revolve, sweep, etc.) |\r\n| organize_objects | Organize objects through grouping, parenting, layout, alignment, and distribution. |\r\n| generate_scene | Generate complete 3D scenes with multiple objects (city, forest, living room, office, park) |\r\n\r\n## Installation\r\n\r\nMaya MCP server is designed so there is only an MCP server and doesn't require anything to be installed within Maya. This is helpful since you can easily use different versions of Maya and not have to worry about coordinating version changes. This is done by taking advantage of the default Command Port Maya opens up for MEL scripting. \r\n\r\nMCP requires Python 3.10 or greater. Currently using pip as the package requirements are minimal. To install the virtual environment:\r\n\r\n1. download this project\r\n2. Create a virtual env using Python 3.10+ in the project directory. ```python -m venv .venv```\r\n3. activate the virtual environment\r\n   * Windows: ```.venv\\Scripts\\activate.bat```\r\n   * Mac/Linux: ```source .venv\\bin\\activate.sh```\r\n4. ```pip install -r requirements.txt```\r\n\r\nAs stated, there is nothing to install for Maya.\r\n\r\n### MCP Client Configuration\r\n\r\nDepending on which MCP Client you're using, the configuration file location differs. For [Anthopic Claude Desktop](https://claude.ai/download), go to File -> Settings -> Developer Tab and press the Edit Config button. This will bring up the file finder in the directory location of the JSON config file.\r\n\r\nNext you need to edit the config JSON file by hand using a text editor.  Make sure to use full file paths.\r\n\r\n```\r\n{\r\n  \"mcpServers\": {\r\n    \"MayaMCP\": {\r\n      \"command\": \"[FULL PATH TO MayaMCP PROJECT]/.venv/Scripts/python.exe\",\r\n      \"args\": [\r\n        \"[FULL PATH TO MayaMCP PROJECT]/src/maya_mcp_server.py\"\r\n      ]\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nOnce the changes have been made, restart Claude Desktop (use Exit menu item instead of just closing the window). In the Developers Tab, you will now see the Maya MCP server listed.\r\n\r\nIn Claude Desktop, you can verify the Maya MCP tools are available. Press the  button and a detailed popup will appear.\r\n\r\n\r\n\r\n\r\n### Maya Communications\r\n\r\nWhen the Maya MCP server first attempts to communicate with Maya, you will get this popup within Maya. Please click \"Allow All\" to allow for ongoing communication between the MCP server and Maya. This will need to be done each Maya session.\r\n\r\n\r\n\r\n\r\n## Developer Notes\r\n\r\nThe Maya MCP Server module was designed to be easily modified in a non-intrusive way. This is done by having the Maya Python code reside in the MCP server and sent to Maya's command port for execution. The results are sent back to the server and processed.\r\n\r\nThe default Maya command port runs MEL so the Python code is modified to run within MEL function call to the Python interpreter. There is also some limits such as multi-line Python code can't have any returned results. So, each command creates two connections to Maya. First to run the operation and save the results. The second connection then to read back the results. \r\n\r\nTo help minimize populating the namespace in the Maya global Python interpreter, functions and variables sent to Maya will be scoped to start with _mcp_maya_*. Each of the Maya tools are scoped into a function named _mcp_maya_scope(). The results are assigned to the variable _mcp_maya_results. This way should significantly reduce the possibility of name collisions. \r\n\r\nThere is a bit of elegance to this design. You basically can just add the Python file, restart the MCP Client and Maya MCP server and go. You don't need to integrate the operations on both the Maya MCP server and Maya itself. The code you add is only Maya specific Python and doesn't need to add any MCP decorators. This is a much better design to grow and adapt to different installations instead of having a fixed set of tools.\r\n\r\nThe Maya MCP server was built using the low-level Python MCP module. This was necessary to allow for dynamically defining all of the tools at run time. The tool function signatures are captured dynamically at the start of the server. \r\n\r\n### Adding New Tools\r\n\r\nIt is easy to add new tools to Maya MCP. You don't need to change any of the existing code. All you need to do is add a single tool command Python file to the mayatools/thirdparty directory. The tool itself will run in Maya so it will have access to all of the Maya Python modules. There are a few programmer notes in the design of the tool.\r\n\r\n* The name of the Python file and the function name must be the same. Make sure it is unique.\r\n* The Python function will be loaded by both the server and Maya. Any code outside of the function must be able to be loaded into standalone Python. Meaning any imports such as maya.cmds should be done in the scope of the function. The MCP server loads the function so it can inspect the function signature to send the information to MCP Client via JSON-RPC.\r\n* The function signature will be parsed and must include any types in the function argument annotation.\r\n* When your function is sent to Maya, it will be scoped within am _mcp_maya_scope function. This provides a number of benefits. The functions sent to Maya will not polute the Python global space too much running in Maya. Plus, any exceptions thrown will be caught and returned back to the MCP Client as errors.\r\n* Generally, you want to return either a list or dictionary or throw an exception when there is an error.\r\n* Name your function and arguments appropriately so the LLM can understand the operation. Include a function doc string.\r\n* Default arguments are good. \r\n* Error checking is good so error messages can provide better failed explanations.\r\n\r\nI recommend looking at the existing Maya tools in this project as examples.\r\n\r\n## Testing\r\n\r\nCurrently Maya MCP has only been tested on Windows. Should work on both Linux and Mac as everything is using standard Python.\r\n\r\n## Future Ideas\r\n\r\nIt's early days for MCP and there is a lot to improve. Here are some ideas.\r\n\r\n* Expose more functionality.\r\n* Improve using prompt engineering, particularly describing Maya's usage and data relationships.\r\n* Everything is registered as tools, allow for resources and prompts.\r\n* It could be possible to find any plugins within Maya that has MCP tools. Maybe something like looking at the PYTHONPATH within Maya with any directory named MCP. All of those could be inspected and then provided back to the MCP Client.\r\n\r\n## License\r\n\r\nMIT\r\n\r\n## Links\r\n\r\n* [Model Context Protocol (MCP)](https://modelcontextprotocol.io/)\r\n* [Anthopic Claude Desktop](https://claude.ai/download)\r\n* [MCP Python SDK](https://github.com/modelcontextprotocol/python-sdk)\r\n* [Unreal MCP](https://github.com/chongdashu/unreal-mcp)\r\n\r\n\r\n## Important Note\r\n\r\nThis project was done on my personal time and equipment to learn about MCP. The project is not affiliated with my current employer and does not represent their work or interests.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mayamcp",
        "maya",
        "autodesk",
        "mayamcp control",
        "autodesk maya",
        "maya using"
      ],
      "category": "simulation-and-modeling"
    },
    "a2888409--CSAPP": {
      "owner": "a2888409",
      "name": "CSAPP",
      "url": "https://github.com/a2888409/CSAPP",
      "imageUrl": "/freedevtools/mcp/pfp/a2888409.webp",
      "description": "A high-performance HTTP server utilizing the epoll model for efficient connection and task management, supporting event-driven architecture and timer management for handling inactive connections. Includes implementations of memory allocation, a simple proxy server, and a basic shell for process management and signal handling.",
      "stars": 4,
      "forks": 3,
      "license": "No License",
      "language": "C",
      "updated_at": "2021-09-03T11:30:14Z",
      "readme_content": "# 基于epoll模型的http服务器 + CSAPP_lab\n基于epoll模型的http服务器 + CSAPP一书配套的实验中，其中3个经典实验的源码<br>\n###http：基于epoll模型的http服务器<br>\n采用epoll模型，实现了统一事件源，并通过时间堆管理定时器回收非活动连接。<br>\n通过一个线程池实现对任务的处理，然后使用状态机解析HTTP报文，请求了静态文件。<br>\n<br>\n###malloclab-handout：基于分离适配算法的内存分配器<br>\n采用双向链表结构维护分配器，每次分配一个内存块时，通过链表头指针查找到一个大小合适的块，并进行可选的分割。性能较隐式空闲链表分配器提升了大约20%。\n<br>\n###proxylab-handout：实现了一个简单的代理程序\n<br>\n###shlab-handout：Tiny Shell<br>\n实现了一个简易shell程序，主要涉及进程管理和信号处理。定义了一个数据结构管理job，实现了job的add，delete，fg，bg等功能。并正确的处理了SIGINT，SIGCHLD，SIGTSTP信号。\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "csapp",
        "http",
        "server",
        "performance http",
        "http server",
        "a2888409 csapp"
      ],
      "category": "simulation-and-modeling"
    },
    "ariunbolor--nsaf-mcp-server": {
      "owner": "ariunbolor",
      "name": "nsaf-mcp-server",
      "url": "https://github.com/ariunbolor/nsaf-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/ariunbolor.webp",
      "description": "Integrate and utilize neuro-symbolic autonomy capabilities for AI assistants, enabling the execution of customizable NSAF evolution and comparison of different agent architectures. This server exposes NSAF functionalities via a simplified Model Context Protocol implementation without requiring the official MCP SDK.",
      "stars": 1,
      "forks": 2,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-07-05T20:53:49Z",
      "readme_content": "# NSAF MCP Server\n\nThis is a Model Context Protocol (MCP) server for the Neuro-Symbolic Autonomy Framework (NSAF). It allows AI assistants to interact with the NSAF framework through the MCP protocol.\n\n> **Note:** This repository includes both the NSAF framework code and the MCP server implementation, making it a complete package that can be deployed and used anywhere.\n\n> **Note:** This implementation uses a simplified version of the MCP protocol that doesn't require the official MCP SDK. It implements the core functionality needed to expose NSAF capabilities to AI assistants.\n\n## Features\n\n- Run NSAF evolution with customizable parameters\n- Compare different NSAF agent architectures\n- Integrate NSAF capabilities into AI assistants\n\n## Prerequisites\n\n- Node.js 18+ and npm\n- Python 3.8+ with the NSAF framework installed\n\n## Installation\n\n1. Clone this repository:\n```bash\ngit clone https://github.com/ariunbolor/nsaf-mcp-server.git\ncd nsaf-mcp-server\n```\n\n2. Install dependencies:\n```bash\nnpm install\n```\n\n3. Build the server:\n```bash\nnpm run build\n```\n\n## Configuration\n\nThe server includes the NSAF framework code, so no additional configuration is required for basic usage. The MCP server is designed to work out-of-the-box when installed globally.\n\n## Usage\n\n### Running the server locally\n\n```bash\nnpm start\n```\n\n### Deploying to GitHub\n\n1. Create a new GitHub repository for your MCP server:\n   - Go to GitHub and create a new repository named `nsaf-mcp-server`\n   - Initialize it with a README file\n\n2. Use the provided setup script to push your code to GitHub:\n```bash\n# For a new repository\n./setup-github-fixed.sh yourusername\n\n# If the repository already exists and you want to overwrite its content\n./setup-github-fixed.sh yourusername --force\n```\n\nThe script will:\n- Initialize git if needed\n- Set up the remote repository\n- Commit your changes\n- Try to push to GitHub (with options to handle existing repositories)\n\n3. Configure GitHub Actions for CI/CD (optional):\n   - Create a `.github/workflows` directory\n   - Add a workflow file for testing and building the server\n\n### Using with AI Assistants\n\nTo use this MCP server with AI assistants like Claude, you need to:\n\n1. Install the server:\n\n   Option 1: Install from GitHub (after pushing your code):\n   ```bash\n   npm install -g yourusername/nsaf-mcp-server\n   ```\n\n   Option 2: Install from your local directory:\n   ```bash\n   # Navigate to the nsaf-mcp-server directory\n   cd nsaf_mcp_server\n   \n   # Install dependencies and build\n   npm install\n   npm run build\n   \n   # Install globally from the local directory\n   npm install -g .\n   ```\n\n2. Add the server to your MCP settings configuration:\n\nFor Claude Desktop app, edit `~/Library/Application Support/Claude/claude_desktop_config.json` (on macOS):\n\n```json\n{\n  \"mcpServers\": {\n    \"nsaf\": {\n      \"command\": \"nsaf-mcp-server\",\n      \"args\": [],\n      \"env\": {},\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\nFor Cline, edit `/Users/onthego/Library/Application Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"nsaf\": {\n      \"command\": \"nsaf-mcp-server\",\n      \"args\": [],\n      \"env\": {},\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\n## Available Tools\n\n### run_nsaf_evolution\n\nRun NSAF evolution with specified parameters.\n\nParameters:\n- `population_size`: Size of the agent population (default: 20)\n- `generations`: Number of generations to evolve (default: 10)\n- `mutation_rate`: Mutation rate (0.0-1.0) (default: 0.2)\n- `crossover_rate`: Crossover rate (0.0-1.0) (default: 0.7)\n- `architecture_complexity`: Complexity of the agent architecture ('simple', 'medium', 'complex') (default: 'medium')\n\n### compare_nsaf_agents\n\nCompare different NSAF agent architectures.\n\nParameters:\n- `architectures`: List of architectures to compare (default: ['simple', 'medium', 'complex'])\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "nsaf",
        "ai",
        "agent",
        "nsaf mcp",
        "agent architectures",
        "nsaf evolution"
      ],
      "category": "simulation-and-modeling"
    },
    "capoom--houdini-mcp": {
      "owner": "capoom",
      "name": "houdini-mcp",
      "url": "https://github.com/capoom/houdini-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/capoom.webp",
      "description": "Connects Claude AI to Houdini for prompt-assisted 3D modeling, scene creation, and simulation setup. Enables control of Houdini nodes, geometry creation, and direct execution of Python code.",
      "stars": 46,
      "forks": 3,
      "license": "No License",
      "language": "",
      "updated_at": "2025-09-18T07:55:31Z",
      "readme_content": "# HoudiniMCP - Houdini Model Context Protocol Integration\n\nHoudiniMCP connects Houdini to Claude AI through the Model Context Protocol (MCP), allowing Claude to directly interact with and control Houdini. This integration enables prompt-assisted 3D modeling, scene creation, simulation setup, and rendering.\n\n## Redirect\n\nThis repository is moved. Please use the below repo.\n\nhttps://github.com/capoomgit/houdini-mcp\n\n## Disclaimer\n\nThis is a third-party integration and not made by SideFX.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "houdini",
        "python",
        "3d",
        "houdini mcp",
        "houdini prompt",
        "capoom houdini"
      ],
      "category": "simulation-and-modeling"
    },
    "cwahlfeldt--blender-mcp": {
      "owner": "cwahlfeldt",
      "name": "blender-mcp",
      "url": "https://github.com/cwahlfeldt/blender-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/cwahlfeldt.webp",
      "description": "Manage and execute Blender Python scripts in a headless environment while tracking execution results and metadata. Add, edit, and remove scripts efficiently to streamline Blender scripting workflows.",
      "stars": 8,
      "forks": 1,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-06-07T11:17:31Z",
      "readme_content": "# Blender MCP Server\n\nA Model Context Protocol (MCP) server for managing and executing Blender scripts.\n\n## Features\n\n- Add, edit, execute, and remove Blender Python scripts\n- Execute scripts in a headless Blender environment\n- View execution results and errors\n- Track script metadata (creation date, last modified, execution count)\n\n## Requirements\n\n- Python 3.7+\n- Blender installed and accessible\n- MCP library (`pip install mcp`)\n\n## Usage\n\n1. Start the server:\n   ```\n   python server.py\n   ```\n\n2. Connect to the server using an MCP client (like Claude Desktop)\n\n3. Use the provided tools to manage scripts:\n   - `add_script(name, content)` - Add a new script\n   - `edit_script(name, content)` - Edit an existing script\n   - `execute_script(name, blend_file=None)` - Execute a script in Blender, optionally specifying a .blend file\n   - `remove_script(name)` - Remove a script\n\n4. Access resources to get information:\n   - `scripts://list` - Get list of available scripts\n   - `script://{name}` - Get content of a specific script\n   - `result://{name}` - Get execution result of a script\n\n## Examples\n\n### Basic Example\n\n```python\n# Add a simple script\nadd_script(\"hello_cube\", '''\nimport bpy\n\n# Clear existing objects\nbpy.ops.object.select_all(action='SELECT')\nbpy.ops.object.delete()\n\n# Create a cube\nbpy.ops.mesh.primitive_cube_add(size=2, location=(0, 0, 0))\nprint(\"Cube created!\")\n''')\n\n# Execute the script\nexecute_script(\"hello_cube\")\n\n# Get the result\n# Access using: result://hello_cube\n```\n\n### Working with Blend Files\n\n```python\n# Add a script that works with a blend file\nadd_script(\"analyze_scene\", '''\nimport bpy\n\n# Print information about the current scene\nprint(f\"Current Blender version: {bpy.app.version_string}\")\nprint(f\"Current file: {bpy.data.filepath}\")\n\n# List all objects in the scene\nprint(\"\\\\nObjects in the scene:\")\nfor obj in bpy.data.objects:\n    print(f\" - {obj.name} ({obj.type})\")\n''')\n\n# Execute with a specific blend file\nexecute_script(\"analyze_scene\", blend_file=\"/path/to/your/project.blend\")\n\n# Get the result\n# Access using: result://analyze_scene\n```\n\n## How It Works\n\n1. When a script is added, it's stored in the `script_files/scripts` directory\n2. When executed, the script is run in a headless Blender instance\n   - If a blend file is specified, Blender will open that file before running the script\n   - Otherwise, a default empty Blender scene is used\n3. Output and errors are captured and stored in the `script_files/results` directory\n4. Metadata about scripts is tracked in `script_files/metadata.json`\n\n## Installation\n\n1. Clone this repository\n2. Install the MCP library: `pip install mcp`\n3. Ensure Blender is installed and accessible from your PATH\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "scripts",
        "scripting",
        "python",
        "python scripts",
        "blender scripting",
        "scripting workflows"
      ],
      "category": "simulation-and-modeling"
    },
    "davidkingzyb--SCAST": {
      "owner": "davidkingzyb",
      "name": "SCAST",
      "url": "https://github.com/davidkingzyb/SCAST",
      "imageUrl": "/freedevtools/mcp/pfp/davidkingzyb.webp",
      "description": "Static code analysis and visualization tool that converts code into UML diagrams and flowcharts, enhancing understanding of code structure and flow. It supports multiple programming languages and utilizes advanced visualization tools like Mermaid and D3.",
      "stars": 28,
      "forks": 6,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-19T09:32:35Z",
      "readme_content": "# 🔱SCAST\n\n**Static Code Analysis and Visualization**\n\n2024/9/27 by DKZ\n\n![scastbanner](https://davidkingzyb.github.io/blogmd/blogImg/scastbanner.png)\n\nEnglish/[中文](./README.zh.md)\n\n[🔱SCAST](https://davidkingzyb.github.io/scast/SCAST.html) is a programmatic tool that converts code into UML diagrams and flowcharts.\n\n[📽️watch video](https://youtu.be/KYbGcD38gqM)  \n[📽️Tutorial](https://youtu.be/sYqRW7zem8s)  \n[📽️MCP](https://youtu.be/ay4zFeYasPU)  \n\nsupport plan\n- javascript (use [acorn](https://github.com/acornjs/acorn))\n- typescript (use [typescript](https://www.typescriptlang.org/) for now [estree](https://typescript-eslint.io/) later)\n- csharp (use a custom parser no longer supported in future)\n- python (ues a custom parser use [filbert](https://github.com/differentmatt/filbert) later)\n- vue (later)\n\nThe underlying principle involves leveraging a parser to parse the code into an Abstract Syntax Tree (AST), followed by static analysis, and finally utilizing [Mermaid](https://github.com/mermaid-js/mermaid-live-editor) and [D3](https://github.com/d3/d3) for visualization.\n\nYou can try it [online](https://davidkingzyb.github.io/scast/SCAST.html) or just download this repo and open SCAST.html with browser.  \nFor Developers it can be deployed on servers using `npm run server`. Or use it as **MCP** server integrate it into your AI client.\n\n![scast_uml](https://github.com/user-attachments/assets/0185738e-0815-4c92-8770-e9ff2b0da1d5)\n\n## Update\n\n### MCP\n\n![mcp](https://github.com/user-attachments/assets/f35cf086-0105-47ce-a3d2-6ec1e09748d7)\n\n1. `git clone https://github.com/davidkingzyb/SCAST.git` download the source code.\n2. `npm install`\n3. config at your client\n```\n{\n  \"mcpServers\": {\n    \"scast\":{\n      \"command\":\"node\",\n      \"args\":[\n        \"/YOUR_INSTALL_DIR/SCAST/mcp/index.js\",\n        \"/YOUR_WORKSPACE/\",\n        \"C:\\\\Users\\\\DKZ\\\\OTHER_ALLOWED_DIR\\\\\",\n      ]\n    }\n  }\n}\n```\n#### Tools\n##### scast_analysis:\nSCAST is a tool designed to assist users in analyzing and summarizing code through visualization. \nBy simply providing the folder path where the code is located, \nSCAST can perform static analysis on the code,  generating an AST tree to helping users understand the code structure and explain its functionality.\nGenerate various visual charts such as UML diagrams, AST tree diagrams and Mermaid flowcharts.\nFinally return a keyword list containing all class and method names along with their functionality explanations, and include a link to allow users to view the chart details in their browser.\n\n##### scast_retriever\nSCAST is a tool that helps users analyze and summarize code and provides visualizations.\nYou need to provide the file path of the source code folder. SCAST will perform static analysis on the source codes in the folder, generating an AST tree to help users understand the code structure and explain its functionality.\nAfter analyzing the code directory with SCAST, you can use keywords in the AST tree for searching, better answering user questions using a RAG method.\nThis keyword can be a class name, method name, or field name. SCAST will find the source code at its definition and return it.\n\n#### Ollama AI\n\ninstall [ollama](https://ollama.com/) first\nsee [ai.js](./js/ai.js) for more details\n\n![ollama](https://github.com/user-attachments/assets/afe8f504-17f7-4897-9990-4baa4f66213d)\n\n#### ESTree \n\nCompliant with ESTree specification AST parser\n\n#### Force Directed Graph\n\n![FDP](https://github.com/user-attachments/assets/6a34b405-492e-4966-a075-fce60330bccf)\n\n#### More D3 Graph\n\n- Indented tree\n- Tidy tree\n- Cluster tree\n- Tadial tidy tree\n- Radial cluster tree\n- Force directed tree\n- Edge bundling\n\n![scast_d3](https://github.com/user-attachments/assets/11c4e11f-05e6-48b0-a3ee-c1e5f6a0816d)\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "visualization",
        "programming",
        "code",
        "code analysis",
        "uml diagrams",
        "visualization tools"
      ],
      "category": "simulation-and-modeling"
    },
    "davidlin2k--pox-mcp-server": {
      "owner": "davidlin2k",
      "name": "pox-mcp-server",
      "url": "https://github.com/davidlin2k/pox-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/davidlin2k.webp",
      "description": "Automate network analysis and manage OpenFlow devices using a Python-based interface while tracking active components, network topology, and flow rules.",
      "stars": 1,
      "forks": 6,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-03-24T01:03:23Z",
      "readme_content": "# POX MCP Server\n\n## Overview\nA Model Context Protocol (MCP) server implementation that provides network control and management capabilities through the POX SDN controller. This server enables Python-based network programming, OpenFlow device management, and automated network analysis through POX's modular architecture. Perfect for educational environments, network prototyping, and SDN research.\n\n## Components\n\n### Resources\nThe server exposes two dynamic resources:\n- `pox://network-config`: A comprehensive POX controller configuration memo\n  - Tracks active POX components and their configurations\n  - Records network topology and flow rules\n  - Maintains discovered network insights\n- `pox://topology`: Real-time network topology view\n  - Shows active OpenFlow datapaths (switches)\n  - Maps host locations and connections\n  - Displays link status and port mappings\n\n### Prompts\nThe server provides three specialized prompts:\n- `pox-network-manager`: Interactive prompt for POX controller management\n  - Required argument: `topic` - The network control aspect to focus on\n  - Helps configure POX components and modules\n  - Guides through network policy implementation\n  - Integrates with network configuration memo\n\n- `simple-hub`: Basic L2 hub implementation using POX\n  - Required argument: `dpid` - The datapath identifier\n  - Demonstrates POX's event-driven programming\n  - Shows basic packet handling and flooding\n  - Explains POX's core mechanisms\n\n- `learning-switch`: L2 learning switch implementation\n  - Required argument: `dpid` - The datapath identifier\n  - Showcases POX's table management\n  - Implements MAC learning and forwarding\n  - Demonstrates POX's packet handling capabilities\n\n### Tools\nThe server offers five core tools:\n\n#### Datapath Management Tools\n- `get_switches`\n   - List all connected OpenFlow datapaths\n   - No input required\n   - Returns: Array of active POX-controlled switches\n   - Includes connection status and capabilities\n\n- `get_switch_desc`\n   - Get detailed datapath information\n   - Input:\n     - `dpid` (string): Datapath identifier\n   - Returns: POX-managed switch details and features\n\n#### Flow Management Tools\n- `get_flow_stats`\n   - Retrieve POX flow statistics\n   - Input:\n     - `dpid` (string): Datapath identifier\n     - `match` (object, optional): POX match structure\n     - `table_id` (string, optional): OpenFlow table ID\n     - `out_port` (string, optional): Output port filter\n   - Returns: POX flow statistics including packet counts\n\n- `set_table`\n   - Configure POX flow tables\n   - Input:\n     - `dpid` (string): Datapath identifier\n     - `flows` (array): POX flow specifications\n   - Returns: Flow table update confirmation\n\n#### Analysis Tools\n- `append_insight`\n   - Add network insights to POX configuration memo\n   - Input:\n     - `insight` (string): Network observation or analysis\n   - Returns: Insight addition confirmation\n   - Updates pox://network-config resource\n\n## Usage with Claude Desktop\n\n### uv\n\n```json\n{\n  \"mcpServers\": {\n    \"pox\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"parent_of_servers_repo/servers/src/mcp_server_pox\",\n        \"run\",\n        \"server.py\"\n      ],\n      \"env\": {\n        \"POX_SERVER_URL\": \"http://localhost:8000\"\n      }\n    }\n  }\n}\n```\n\n## License\n\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.\n\n## Contributing\n\nContributions are welcome! Please feel free to submit pull requests, report bugs, or suggest new features.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "openflow",
        "network",
        "pox",
        "openflow devices",
        "manage openflow",
        "automate network"
      ],
      "category": "simulation-and-modeling"
    },
    "dustland--genesis-mcp": {
      "owner": "dustland",
      "name": "genesis-mcp",
      "url": "https://github.com/dustland/genesis-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/dustland.webp",
      "description": "Run immersive simulations in the Genesis World with advanced visualization capabilities, enabling dynamic environments and interactions through a user-friendly interface.",
      "stars": 3,
      "forks": 2,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-06-10T01:30:03Z",
      "readme_content": "# Genesis MCP Server\n\nA Model Context Protocol (MCP) server for Genesis World simulations with visualization support.\n\n## Quick Start\n\nFor the fastest way to get started with visualization:\n\n```bash\n# Run the simplified setup script (only installs what's needed)\n./setup.sh\n\n# Run the stdio client (opens a visualization window)\n./examples/stdio_client.py\n```\n\nThis will directly start a Genesis World simulation with visualization using stdio transport.\n\n## Transport Method: stdio\n\nThis server uses **stdio transport** which is required for Genesis World visualization features.\nThe visualization components require a local runtime and cannot work over network transports.\n\n## Setup\n\n### Prerequisites\n\n- Python 3.8+\n- uv package manager (`pip install uv`)\n- npm (optional, for MCP Inspector)\n\n### Installation\n\n#### Linux/macOS\n\n```bash\n# Clone the repository\ngit clone https://github.com/username/genesis-mcp.git\ncd genesis-mcp\n\n# Run the setup script\n./setup.sh\n\n# Activate the virtual environment\nsource .venv/bin/activate\n```\n\n#### Windows\n\n```powershell\n# Clone the repository\ngit clone https://github.com/username/genesis-mcp.git\ncd genesis-mcp\n\n# Run the setup script\nsetup.bat\n\n# Activate the virtual environment\n.venv\\Scripts\\activate.bat\n```\n\n### Manual Installation with uv\n\nIf you prefer to install dependencies manually:\n\n1. Create a virtual environment:\n\n   ```bash\n   uv venv .venv\n   source .venv/bin/activate  # Linux/macOS\n   .venv\\Scripts\\activate.bat  # Windows\n   ```\n\n2. Install dependencies from lock file:\n\n   ```bash\n   uv pip install -r requirements.lock\n   uv pip install -e .\n   uv pip install genesis==0.2.1 --no-deps\n   ```\n\n3. Install MCP Inspector (optional):\n   ```bash\n   npm install -g @modelcontextprotocol/inspector@0.6.0\n   ```\n\n## Running the Server\n\n````bash\n# Run with stdio transport (required for visualization)\n./start.sh\n\n\n### Using with the MCP Inspector\n\nTo use with the MCP Inspector for debugging:\n\n```bash\n# In one terminal, start the inspector\nmcp-inspector\n\n# In another terminal, start the server with stdio transport\npython server.py\n````\n\nConfigure the MCP Inspector with:\n\n- Transport Type: STDIO\n- Command: python\n- Arguments: server.py\n\n## Available Resources\n\n### World Info\n\nGet information about Genesis World features:\n\n```\nworld_info://{name}\n```\n\n## Available Tools\n\n### Run Simulation\n\nRun a Genesis World simulation with provided code and parameters:\n\n```\nrun_simulation\n```\n\n## MCP Client\n\nThe repository includes stdio client for visualization:\n\n```bash\n# Run a simulation with Genesis World visualization\n./examples/stdio_client.py\n```\n\nHappy hacking!",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "dustland",
        "genesis",
        "simulations",
        "dustland genesis",
        "simulations genesis",
        "modeling dustland"
      ],
      "category": "simulation-and-modeling"
    },
    "jhacksman--OpenSCAD-MCP-Server": {
      "owner": "jhacksman",
      "name": "OpenSCAD-MCP-Server",
      "url": "https://github.com/jhacksman/OpenSCAD-MCP-Server",
      "imageUrl": "/freedevtools/mcp/pfp/jhacksman.webp",
      "description": "Generates 3D models from text descriptions or images, focusing on parametric model creation through multi-view reconstruction and integration with OpenSCAD. Facilitates remote processing and includes an image approval workflow for model generation.",
      "stars": 84,
      "forks": 17,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-10-03T04:21:59Z",
      "readme_content": "# OpenSCAD MCP Server\n\nA Model Context Protocol (MCP) server that enables users to generate 3D models from text descriptions or images, with a focus on creating parametric 3D models using multi-view reconstruction and OpenSCAD.\n\n## Features\n\n- **AI Image Generation**: Generate images from text descriptions using Google Gemini or Venice.ai APIs\n- **Multi-View Image Generation**: Create multiple views of the same 3D object for reconstruction\n- **Image Approval Workflow**: Review and approve/deny generated images before reconstruction\n- **3D Reconstruction**: Convert approved multi-view images into 3D models using CUDA Multi-View Stereo\n- **Remote Processing**: Process computationally intensive tasks on remote servers within your LAN\n- **OpenSCAD Integration**: Generate parametric 3D models using OpenSCAD\n- **Parametric Export**: Export models in formats that preserve parametric properties (CSG, AMF, 3MF, SCAD)\n- **3D Printer Discovery**: Optional network printer discovery and direct printing\n\n## Architecture\n\nThe server is built using the Python MCP SDK and follows a modular architecture:\n\n```\nopenscad-mcp-server/\n├── src/\n│   ├── main.py                  # Main application\n│   ├── main_remote.py           # Remote CUDA MVS server\n│   ├── ai/                      # AI integrations\n│   │   ├── gemini_api.py        # Google Gemini API for image generation\n│   │   └── venice_api.py        # Venice.ai API for image generation (optional)\n│   ├── models/                  # 3D model generation\n│   │   ├── cuda_mvs.py          # CUDA Multi-View Stereo integration\n│   │   └── code_generator.py    # OpenSCAD code generation\n│   ├── workflow/                # Workflow components\n│   │   ├── image_approval.py    # Image approval mechanism\n│   │   └── multi_view_to_model_pipeline.py  # Complete pipeline\n│   ├── remote/                  # Remote processing\n│   │   ├── cuda_mvs_client.py   # Client for remote CUDA MVS processing\n│   │   ├── cuda_mvs_server.py   # Server for remote CUDA MVS processing\n│   │   ├── connection_manager.py # Remote connection management\n│   │   └── error_handling.py    # Error handling for remote processing\n│   ├── openscad_wrapper/        # OpenSCAD CLI wrapper\n│   ├── visualization/           # Preview generation and web interface\n│   ├── utils/                   # Utility functions\n│   └── printer_discovery/       # 3D printer discovery\n├── scad/                        # Generated OpenSCAD files\n├── output/                      # Output files (models, previews)\n│   ├── images/                  # Generated images\n│   ├── multi_view/              # Multi-view images\n│   ├── approved_images/         # Approved images for reconstruction\n│   └── models/                  # Generated 3D models\n├── templates/                   # Web interface templates\n└── static/                      # Static files for web interface\n```\n\n## Installation\n\n1. Clone the repository:\n   ```\n   git clone https://github.com/jhacksman/OpenSCAD-MCP-Server.git\n   cd OpenSCAD-MCP-Server\n   ```\n\n2. Create a virtual environment:\n   ```\n   python -m venv venv\n   source venv/bin/activate  # On Windows: venv\\Scripts\\activate\n   ```\n\n3. Install dependencies:\n   ```\n   pip install -r requirements.txt\n   ```\n\n4. Install OpenSCAD:\n   - Ubuntu/Debian: `sudo apt-get install openscad`\n   - macOS: `brew install openscad`\n   - Windows: Download from [openscad.org](https://openscad.org/downloads.html)\n\n5. Install CUDA Multi-View Stereo:\n   ```\n   git clone https://github.com/fixstars/cuda-multi-view-stereo.git\n   cd cuda-multi-view-stereo\n   mkdir build && cd build\n   cmake ..\n   make\n   ```\n\n6. Set up API keys:\n   - Create a `.env` file in the root directory\n   - Add your API keys:\n     ```\n     GEMINI_API_KEY=your-gemini-api-key\n     VENICE_API_KEY=your-venice-api-key  # Optional\n     REMOTE_CUDA_MVS_API_KEY=your-remote-api-key  # For remote processing\n     ```\n\n## Remote Processing Setup\n\nThe server supports remote processing of computationally intensive tasks, particularly CUDA Multi-View Stereo reconstruction. This allows you to offload processing to more powerful machines within your LAN.\n\n### Server Setup (on the machine with CUDA GPU)\n\n1. Install CUDA Multi-View Stereo on the server machine:\n   ```\n   git clone https://github.com/fixstars/cuda-multi-view-stereo.git\n   cd cuda-multi-view-stereo\n   mkdir build && cd build\n   cmake ..\n   make\n   ```\n\n2. Start the remote CUDA MVS server:\n   ```\n   python src/main_remote.py\n   ```\n\n3. The server will automatically advertise itself on the local network using Zeroconf.\n\n### Client Configuration\n\n1. Configure remote processing in your `.env` file:\n   ```\n   REMOTE_CUDA_MVS_ENABLED=True\n   REMOTE_CUDA_MVS_USE_LAN_DISCOVERY=True\n   REMOTE_CUDA_MVS_API_KEY=your-shared-secret-key\n   ```\n\n2. Alternatively, you can specify a server URL directly:\n   ```\n   REMOTE_CUDA_MVS_ENABLED=True\n   REMOTE_CUDA_MVS_USE_LAN_DISCOVERY=False\n   REMOTE_CUDA_MVS_SERVER_URL=http://server-ip:8765\n   REMOTE_CUDA_MVS_API_KEY=your-shared-secret-key\n   ```\n\n### Remote Processing Features\n\n- **Automatic Server Discovery**: Find CUDA MVS servers on your local network\n- **Job Management**: Upload images, track job status, and download results\n- **Fault Tolerance**: Automatic retries, circuit breaker pattern, and error tracking\n- **Authentication**: Secure API key authentication for all remote operations\n- **Health Monitoring**: Continuous server health checks and status reporting\n\n## Usage\n\n1. Start the server:\n   ```\n   python src/main.py\n   ```\n\n2. The server will start on http://localhost:8000\n\n3. Use the MCP tools to interact with the server:\n\n   - **generate_image_gemini**: Generate an image using Google Gemini API\n     ```json\n     {\n       \"prompt\": \"A low-poly rabbit with black background\",\n       \"model\": \"gemini-2.0-flash-exp-image-generation\"\n     }\n     ```\n\n   - **generate_multi_view_images**: Generate multiple views of the same 3D object\n     ```json\n     {\n       \"prompt\": \"A low-poly rabbit\",\n       \"num_views\": 4\n     }\n     ```\n\n   - **create_3d_model_from_images**: Create a 3D model from approved multi-view images\n     ```json\n     {\n       \"image_ids\": [\"view_1\", \"view_2\", \"view_3\", \"view_4\"],\n       \"output_name\": \"rabbit_model\"\n     }\n     ```\n\n   - **create_3d_model_from_text**: Complete pipeline from text to 3D model\n     ```json\n     {\n       \"prompt\": \"A low-poly rabbit\",\n       \"num_views\": 4\n     }\n     ```\n\n   - **export_model**: Export a model to a specific format\n     ```json\n     {\n       \"model_id\": \"your-model-id\",\n       \"format\": \"obj\"  // or \"stl\", \"ply\", \"scad\", etc.\n     }\n     ```\n\n   - **discover_remote_cuda_mvs_servers**: Find CUDA MVS servers on your network\n     ```json\n     {\n       \"timeout\": 5\n     }\n     ```\n\n   - **get_remote_job_status**: Check the status of a remote processing job\n     ```json\n     {\n       \"server_id\": \"server-id\",\n       \"job_id\": \"job-id\"\n     }\n     ```\n\n   - **download_remote_model_result**: Download a completed model from a remote server\n     ```json\n     {\n       \"server_id\": \"server-id\",\n       \"job_id\": \"job-id\",\n       \"output_name\": \"model-name\"\n     }\n     ```\n\n   - **discover_printers**: Discover 3D printers on the network\n     ```json\n     {}\n     ```\n\n   - **print_model**: Print a model on a connected printer\n     ```json\n     {\n       \"model_id\": \"your-model-id\",\n       \"printer_id\": \"your-printer-id\"\n     }\n     ```\n\n## Image Generation Options\n\nThe server supports multiple image generation options:\n\n1. **Google Gemini API** (Default): Uses the Gemini 2.0 Flash Experimental model for high-quality image generation\n   - Supports multi-view generation with consistent style\n   - Requires a Google Gemini API key\n\n2. **Venice.ai API** (Optional): Alternative image generation service\n   - Supports various models including flux-dev and fluently-xl\n   - Requires a Venice.ai API key\n\n3. **User-Provided Images**: Skip image generation and use your own images\n   - Upload images directly to the server\n   - Useful for working with existing photographs or renders\n\n## Multi-View Workflow\n\nThe server implements a multi-view workflow for 3D reconstruction:\n\n1. **Image Generation**: Generate multiple views of the same 3D object\n2. **Image Approval**: Review and approve/deny each generated image\n3. **3D Reconstruction**: Convert approved images into a 3D model using CUDA MVS\n   - Can be processed locally or on a remote server within your LAN\n4. **Model Refinement**: Optionally refine the model using OpenSCAD\n\n## Remote Processing Workflow\n\nThe remote processing workflow allows you to offload computationally intensive tasks to more powerful machines:\n\n1. **Server Discovery**: Automatically discover CUDA MVS servers on your network\n2. **Image Upload**: Upload approved multi-view images to the remote server\n3. **Job Processing**: Process the images on the remote server using CUDA MVS\n4. **Status Tracking**: Monitor the job status and progress\n5. **Result Download**: Download the completed 3D model when processing is finished\n\n## Supported Export Formats\n\nThe server supports exporting models in various formats:\n\n- **OBJ**: Wavefront OBJ format (standard 3D model format)\n- **STL**: Standard Triangle Language (for 3D printing)\n- **PLY**: Polygon File Format (for point clouds and meshes)\n- **SCAD**: OpenSCAD source code (for parametric models)\n- **CSG**: OpenSCAD CSG format (preserves all parametric properties)\n- **AMF**: Additive Manufacturing File Format (preserves some metadata)\n- **3MF**: 3D Manufacturing Format (modern replacement for STL with metadata)\n\n## Web Interface\n\nThe server provides a web interface for:\n\n- Generating and approving multi-view images\n- Previewing 3D models from different angles\n- Downloading models in various formats\n\nAccess the interface at http://localhost:8000/ui/\n\n## License\n\nMIT\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "openscad",
        "modeling",
        "3d",
        "openscad mcp",
        "openscad facilitates",
        "jhacksman openscad"
      ],
      "category": "simulation-and-modeling"
    },
    "kimjune01--synth-mcp": {
      "owner": "kimjune01",
      "name": "synth-mcp",
      "url": "https://github.com/kimjune01/synth-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/kimjune01.webp",
      "description": "Dynamic MIDI composition and audio synthesis with functions for instrument control, effects management, track handling, and real-time collaboration with MIDI devices.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-05-06T12:30:42Z",
      "readme_content": "Here's what you would need to create an effective MIDI composition system built on FluidSynth:\nCore MIDI Functions for Your MCP Server\n\n1. FluidSynth Integration Functions\n\ninitialize_fluidsynth() - Set up FluidSynth with proper configurations\nload_soundfont(soundfont_path) - Load SoundFont files (.sf2) for instrument sounds\nset_gain(gain_value) - Control the overall volume of the synth\nset_reverb(room_size, damping, width, level) - Configure reverb effects\nset_chorus(nr, level, speed, depth, type) - Configure chorus effects\n\n2. MIDI Composition Functions\n\nplay_note(note, velocity, duration, channel) - Play single notes with control over velocity and duration\nplay_chord(notes, velocity, duration, channel) - Play multiple notes simultaneously as chords\ncreate_sequence(notes, durations, velocities, channel) - Create sequences of notes with timing\nplay_midi_file(file_path) - Load and play existing MIDI files\nrecord_midi(duration) - Record MIDI input for a specified duration\n\n3. Advanced Musical Functions\n\ncreate_melody(scale, key, length, rhythm_pattern) - Generate melodies based on musical rules\ncreate_chord_progression(progression, style, tempo) - Create harmonic progressions with different voicings\ncreate_drum_pattern(style, tempo, variations) - Generate rhythmic patterns for percussion\ncreate_arpeggio(chord, pattern, tempo) - Create arpeggiated patterns from chord structures\ncreate_bassline(chord_progression, style, tempo) - Generate bass patterns that complement chord progressions\n\n4. Composition Management\n\ncreate_track(name, instrument, channel) - Create a new track with specified instrument\nmute_track(track_id) - Silence a specific track\nsolo_track(track_id) - Solo a specific track\nset_track_volume(track_id, volume) - Adjust volume for individual tracks\nset_track_pan(track_id, pan) - Adjust stereo positioning\n\n5. Project Management\n\ncreate_project(name, tempo, time_signature) - Initialize a new composition project\nsave_project(path) - Save the current project state\nload_project(path) - Load a saved project\nexport_midi(path) - Export the composition as a standard MIDI file\nexport_audio(path, format) - Render the composition to audio using FluidSynth\n\n6. Real-time Collaboration and Interaction\n\nstart_midi_server(port) - Start a server that listens for MIDI events\nconnect_midi_device(device_name) - Connect to external MIDI hardware\nsend_midi_event(event_type, parameters) - Send MIDI events to connected devices\nsync_tempo(tempo) - Synchronize tempo across connected systems\n\nImplementation Approach\nBased on the SuperCollider MCP server I examined, here's how you could structure your FluidSynth MIDI server:\n\nPython Backend: Use Python with the python-osc library for communication and pyfluidsynth for FluidSynth integration\nMCP Protocol Implementation: Create a server that follows the Model Context Protocol structure\nArchitecture:\n\nAI Assistant (Claude) calls methods on your MCP Server\nYour server translates these to FluidSynth commands\nFluidSynth generates the actual audio\n\nGetting Started\nTo build this system, you would need to:\n\nCreate a Python project with the necessary dependencies:\n\npyfluidsynth - For FluidSynth integration\nmcp - For MCP protocol support\npython-osc - For OSC communication (if needed)\nmido - For MIDI file handling\n\nCreate a main server file (e.g., server.py) that:\n\nInitializes FluidSynth\nRegisters all your music composition methods\nHandles communication with Claude\n\nDesign the method signatures in a way that allows Claude to easily compose music, with well-defined parameters and reasonable defaults.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "midi",
        "synth",
        "kimjune01",
        "dynamic midi",
        "collaboration midi",
        "midi composition"
      ],
      "category": "simulation-and-modeling"
    },
    "lobstercare--geofs-mcp": {
      "owner": "lobstercare",
      "name": "geofs-mcp",
      "url": "https://github.com/lobstercare/geofs-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/lobstercare.webp",
      "description": "Control and interact with aircraft in the GeoFS flight simulator. Access real-time flight data, execute maneuvers, and navigate between waypoints using AI models.",
      "stars": 4,
      "forks": 1,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-08-09T15:17:30Z",
      "readme_content": "# GeoFS MCP Server\n\nA Model Context Protocol (MCP) server for the GeoFS flight simulator, allowing AI models to control and interact with aircraft in the GeoFS browser-based flight simulator.\n![image](https://github.com/user-attachments/assets/9b9f8c68-10c1-43b5-b040-f9b7740c04cd)\n![image](https://github.com/user-attachments/assets/611c64f4-1b88-4e86-b289-adfcb12dc97d)\n![image](https://github.com/user-attachments/assets/c713ff6d-7188-4a22-99a6-4673fc9d25f0)\n\n## Features\n\n- 🛫 Control aircraft flight parameters (throttle, heading, etc.)\n- 📊 Access real-time flight data (position, speed, attitude)\n- 🗺️ Navigate between waypoints and airports\n- ✈️ Select different aircraft models\n- 🔄 Execute flight maneuvers (takeoff, landing)\n\n## Prerequisites\n\n- Node.js (v14 or higher)\n- npm or yarn\n- A modern web browser (Chrome recommended)\n\n## Installation\n\n1. Clone this repository:\n   ```\n   git clone https://github.com/yourusername/geofs-mcp-server.git\n   cd geofs-mcp-server\n   ```\n\n2. Install dependencies:\n   ```\n   npm install\n   ```\n\n3. Build the project:\n   ```\n   npm run build\n   ```\n\n## Usage\n\n### Starting the Server\n\n1. Start the MCP server:\n   ```\n   npm start\n   ```\n\n2. The server will launch a browser window that navigates to GeoFS\n   - You may need to log in to GeoFS if required\n   - The server will wait for GeoFS to fully load before accepting commands\n\n3. The MCP server will be available at:\n   - HTTP: `http://localhost:3000`\n   - WebSocket: `ws://localhost:3000`\n\n### Using with AI Models\n\nThis MCP server can be used with AI models that support the Model Context Protocol, allowing them to:\n\n1. Control aircraft in the simulator\n2. Retrieve flight data and simulator state\n3. Execute complex flight maneuvers\n4. Plan and follow flight routes\n\n### API Endpoints\n\n- `GET /mcp` - Get server capabilities and available endpoints\n- `GET /mcp/aircraft` - Get current aircraft data\n- `POST /mcp/aircraft` - Control aircraft parameters\n- `GET /mcp/flight-data` - Get comprehensive flight data\n- `POST /mcp/navigation` - Set navigation parameters\n- `GET /mcp/simulation` - Get simulation status\n- `POST /mcp/simulation` - Control simulation parameters\n\n### WebSocket Commands\n\nThe server also supports WebSocket for real-time communication:\n\n```javascript\n// Example WebSocket message\n{\n  \"id\": 1,\n  \"type\": \"command\",\n  \"command\": \"setThrottle\",\n  \"params\": {\n    \"value\": 0.75\n  }\n}\n```\n\nAvailable commands:\n- `setThrottle` - Set engine throttle (0-1)\n- `setHeading` - Set target heading in degrees\n- `getPosition` - Get current aircraft position\n- `selectAircraft` - Change to a different aircraft\n- `takeOff` - Execute takeoff procedure\n- `land` - Execute landing procedure\n- `getFlightData` - Get comprehensive flight data\n\n## Example Client\n\nSee the `examples/simple-client.js` file for a basic example of how to connect to and use the GeoFS MCP server.\n\nTo run the example:\n```\nnode examples/simple-client.js\n```\n\n## How It Works\n\nThe GeoFS MCP server uses Puppeteer to control a browser instance running GeoFS. It provides a standardized MCP interface that allows AI models to interact with the flight simulator through HTTP and WebSocket APIs.\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## Acknowledgements\n\n- [GeoFS](https://www.geo-fs.com/) - The browser-based flight simulator\n- [Model Context Protocol](https://github.com/modelcontextprotocol/mcp) - Protocol specification for AI model context\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "simulator",
        "flight",
        "maneuvers",
        "flight simulator",
        "geofs flight",
        "aircraft geofs"
      ],
      "category": "simulation-and-modeling"
    },
    "neka-nat--freecad-mcp": {
      "owner": "neka-nat",
      "name": "freecad-mcp",
      "url": "https://github.com/neka-nat/freecad-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/neka-nat.webp",
      "description": "Control FreeCAD directly from the desktop, enabling integration with Claude Desktop for enhanced design workflows and automation. Supports various design tasks including creating flanges, toy cars, and converting 2D drawings into 3D models.",
      "stars": 319,
      "forks": 56,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-03T09:14:17Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/neka-nat-freecad-mcp-badge.png)](https://mseep.ai/app/neka-nat-freecad-mcp)\n\n# FreeCAD MCP\n\nThis repository is a FreeCAD MCP that allows you to control FreeCAD from Claude Desktop.\n\n## Demo\n\n### Design a flange\n\n\n\n### Design a toy car\n\n\n\n### Design a part from 2D drawing\n\n#### Input 2D drawing\n\n\n\n#### Demo\n\n\n\nThis is the conversation history.\nhttps://claude.ai/share/7b48fd60-68ba-46fb-bb21-2fbb17399b48\n\n## Install addon\n\nFreeCAD Addon directory is\n* Windows: `%APPDATA%\\FreeCAD\\Mod\\`\n* Mac: `~/Library/Application\\ Support/FreeCAD/Mod/`\n* Linux:\n  * Ubuntu: `~/.FreeCAD/Mod/` or `~/snap/freecad/common/Mod/` (if you install FreeCAD from snap)\n  * Debian: `~/.local/share/FreeCAD/Mod`\n\nPlease put `addon/FreeCADMCP` directory to the addon directory.\n\n```bash\ngit clone https://github.com/neka-nat/freecad-mcp.git\ncd freecad-mcp\ncp -r addon/FreeCADMCP ~/.FreeCAD/Mod/\n```\n\nWhen you install addon, you need to restart FreeCAD.\nYou can select \"MCP Addon\" from Workbench list and use it.\n\n\n\nAnd you can start RPC server by \"Start RPC Server\" command in \"FreeCAD MCP\" toolbar.\n\n\n\n## Setting up Claude Desktop\n\nPre-installation of the [uvx](https://docs.astral.sh/uv/guides/tools/) is required.\n\nAnd you need to edit Claude Desktop config file, `claude_desktop_config.json`.\n\nFor user.\n\n```json\n{\n  \"mcpServers\": {\n    \"freecad\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"freecad-mcp\"\n      ]\n    }\n  }\n}\n```\n\nIf you want to save token, you can set `only_text_feedback` to `true` and use only text feedback.\n\n```json\n{\n  \"mcpServers\": {\n    \"freecad\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"freecad-mcp\",\n        \"--only-text-feedback\"\n      ]\n    }\n  }\n}\n```\n\n\nFor developer.\nFirst, you need clone this repository.\n\n```bash\ngit clone https://github.com/neka-nat/freecad-mcp.git\n```\n\n```json\n{\n  \"mcpServers\": {\n    \"freecad\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/path/to/freecad-mcp/\",\n        \"run\",\n        \"freecad-mcp\"\n      ]\n    }\n  }\n}\n```\n\n## Tools\n\n* `create_document`: Create a new document in FreeCAD.\n* `create_object`: Create a new object in FreeCAD.\n* `edit_object`: Edit an object in FreeCAD.\n* `delete_object`: Delete an object in FreeCAD.\n* `execute_code`: Execute arbitrary Python code in FreeCAD.\n* `insert_part_from_library`: Insert a part from the [parts library](https://github.com/FreeCAD/FreeCAD-library).\n* `get_view`: Get a screenshot of the active view.\n* `get_objects`: Get all objects in a document.\n* `get_object`: Get an object in a document.\n* `get_parts_list`: Get the list of parts in the [parts library](https://github.com/FreeCAD/FreeCAD-library).\n\n## Contributors\n\n<a href=\"https://github.com/neka-nat/freecad-mcp/graphs/contributors\">\n  <img alt=\"freecad_mcp\" src=\"https://contrib.rocks/image?repo=neka-nat/freecad-mcp\" />\n</a>\n\nMade with [contrib.rocks](https://contrib.rocks).",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "freecad",
        "3d",
        "modeling",
        "freecad directly",
        "control freecad",
        "freecad mcp"
      ],
      "category": "simulation-and-modeling"
    },
    "parmarjh--mcp-reasoner": {
      "owner": "parmarjh",
      "name": "mcp-reasoner",
      "url": "https://github.com/parmarjh/mcp-reasoner",
      "imageUrl": "/freedevtools/mcp/pfp/parmarjh.webp",
      "description": "Systematic reasoning server implementing Beam Search and Monte Carlo Tree Search (MCTS) for decision-making tasks. It evaluates thought processes through statistical analysis and provides tree-based reasoning paths.",
      "stars": 12,
      "forks": 4,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-12T19:32:51Z",
      "readme_content": "# MCP Reasoner\nA systematic reasoning MCP server implementation for Claude Desktop featuring both Beam Search and Monte Carlo Tree Search (MCTS) capabilities.\n\n## Features\n* Dual search strategies:\n   * Beam search with configurable width\n   * MCTS for complex decision spaces\n* Thought scoring and evaluation\n* Tree-based reasoning paths\n* Statistical analysis of reasoning process\n* MCP protocol compliance\n\n## Installation\n```\ngit clone https://github.com/Jacck/mcp-reasoner.git\ncd mcp-reasoner\nnpm install\nnpm run build\n```\n\n## Configuration\nAdd to Claude Desktop config:\n```\n{\n  \"mcpServers\": {\n    \"mcp-reasoner\": {\n      \"command\": \"node\",\n      \"args\": [\"path/to/mcp-reasoner/dist/index.js\"],\n    }\n  }\n}\n```\n\n## Search Strategies\n\n### Beam Search\n* Maintains fixed-width set of most promising paths\n* Optimal for step-by-step reasoning\n* Best for: Mathematical problems, logical puzzles\n\n### Monte Carlo Tree Search\n* Simulation-based exploration of decision space\n* Balances exploration and exploitation\n* Best for: Complex problems with uncertain outcomes\n\n**Note:** Monte Carlo Tree Search allowed Claude to perform really well on the Arc AGI benchmark (scored 6/10 on the public test), whereas beam search yielded a (3/10) on the same puzzles. For super complex tasks, you'd want to direct Claude to utilize the MCTS strategy over the beam search.\n\n## Algorithm Details\n1. Search Strategy Selection\n   * Beam Search: Evaluates and ranks multiple solution paths\n   * MCTS: Uses UCT for node selection and random rollouts\n2. Thought Scoring Based On:\n   * Detail level\n   * Mathematical expressions\n   * Logical connectors\n   * Parent-child relationship strength\n3. Process Management\n   * Tree-based state tracking\n   * Statistical analysis of reasoning\n   * Progress monitoring\n\n## Use Cases\n* Mathematical problems\n* Logical puzzles\n* Step-by-step analysis\n* Complex problem decomposition\n* Decision tree exploration\n* Strategy optimization\n\n## Future Implementations\n* Implement New Algorithms\n   * Iterative Deepening Depth-First Search (IDDFS)\n   * Alpha-Beta Pruning\n\n## License\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcts",
        "mcp",
        "reasoner",
        "mcp reasoner",
        "reasoning server",
        "search mcts"
      ],
      "category": "simulation-and-modeling"
    },
    "phuhao00--MayaMCP": {
      "owner": "phuhao00",
      "name": "MayaMCP",
      "url": "https://github.com/phuhao00/MayaMCP",
      "imageUrl": "/freedevtools/mcp/pfp/phuhao00.webp",
      "description": "Control Autodesk Maya using natural language commands to access and manipulate scenes, objects, and attributes without requiring installation inside Maya. The server simplifies integration with AI assistant clients through a minimal and extensible toolset.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "",
      "updated_at": "2025-04-25T04:23:14Z",
      "readme_content": "# Maya MCP\r\nModel Context Protocol (MCP) server implementation for Autodesk Maya\r\n\r\nTested with Maya 2023, 2025.\r\n\r\nv0.1.0\r\n\r\nThis project enables AI assistant clients like Claude Desktop to control Autodesk Maya through natural language using the [Model Context Protocol (MCP)](https://modelcontextprotocol.io/). \r\n\r\nThis is early days for Maya MCP server and has a minimal set of functionality. It's really the architecture design and simplicity that has been the initial focus.\r\n\r\nHere is a list of some of the tools registered with Maya MCP.\r\n\r\n| Tool | Description |\r\n|------|-------------|\r\n| list_objects_by_type | Get a list of objects in the scene. Use filter_by to filter for certain objects such as \"cameras\", \"lights\", \"materials\", or \"shapes\". |\r\n| create_object | Create an object in the Maya scene. Object types available are cube, cone, sphere, cylinder, camera, spotLight, pointLight, directionalLight. |\r\n| get_object_attributes | Get a list of attributes on a Maya object. | \r\n| set_object_attributes | Set an object's attribute with a specific value. |\r\n| scene_new | Create a new scene in Maya. Use the force argument to force a new scene when an existing scene is loaded and has been modified. |\r\n| scene_open | Load in a scene into Maya. | \r\n| scene_save | Save the current scene. If the filename is not specified, it will save it as its current name. |\r\n| select_object | Select an object in the scene. |\r\n\r\n\r\n## Installation\r\n\r\nMaya MCP server is designed so there is only an MCP server and doesn't require anything to be installed within Maya. This is helpful since you can easily use different versions of Maya and not have to worry about coordinating version changes. This is done by taking advantage of the default Command Port Maya opens up for MEL scripting. \r\n\r\nMCP requires Python 3.10 or greater. Currently using pip as the package requirements are minimal. To install the virtual environment:\r\n\r\n1. download this project\r\n2. Create a virtual env using Python 3.10+ in the project directory. ```python -m venv .venv```\r\n3. activate the virtual environment\r\n   * Windows: ```.venv\\Scripts\\activate.bat```\r\n   * Mac/Linux: ```source .venv\\bin\\activate.sh```\r\n4. ```pip install -r requirements.txt```\r\n\r\nAs stated, there is nothing to install for Maya.\r\n\r\n### MCP Client Configuration\r\n\r\nDepending on which MCP Client you're using, the configuration file location differs. For [Anthopic Claude Desktop](https://claude.ai/download), go to File -> Settings -> Developer Tab and press the Edit Config button. This will bring up the file finder in the directory location of the JSON config file.\r\n\r\nNext you need to edit the config JSON file by hand using a text editor.  Make sure to use full file paths.\r\n\r\n```\r\n{\r\n  \"mcpServers\": {\r\n    \"MayaMCP\": {\r\n      \"command\": \"[FULL PATH TO MayaMCP PROJECT]/.venv/Scripts/python.exe\",\r\n      \"args\": [\r\n        \"[FULL PATH TO MayaMCP PROJECT]/src/maya_mcp_server.py\"\r\n      ]\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nOnce the changes have been made, restart Claude Desktop (use Exit menu item instead of just closing the window). In the Developers Tab, you will now see the Maya MCP server listed.\r\n\r\nIn Claude Desktop, you can verify the Maya MCP tools are available. Press the  button and a detailed popup will appear.\r\n\r\n\r\n\r\n\r\n### Maya Communications\r\n\r\nWhen the Maya MCP server first attempts to communicate with Maya, you will get this popup within Maya. Please click \"Allow All\" to allow for ongoing communication between the MCP server and Maya. This will need to be done each Maya session.\r\n\r\n\r\n\r\n\r\n## Developer Notes\r\n\r\nThe Maya MCP Server module was designed to be easily modified in a non-intrusive way. This is done by having the Maya Python code reside in the MCP server and sent to Maya's command port for execution. The results are sent back to the server and processed.\r\n\r\nThe default Maya command port runs MEL so the Python code is modified to run within MEL function call to the Python interpreter. There is also some limits such as multi-line Python code can't have any returned results. So, each command creates two connections to Maya. First to run the operation and save the results. The second connection then to read back the results. \r\n\r\nTo help minimize populating the namespace in the Maya global Python interpreter, functions and variables sent to Maya will be scoped to start with _mcp_maya_*. Each of the Maya tools are scoped into a function named _mcp_maya_scope(). The results are assigned to the variable _mcp_maya_results. This way should significantly reduce the possibility of name collisions. \r\n\r\nThere is a bit of elegance to this design. You basically can just add the Python file, restart the MCP Client and Maya MCP server and go. You don't need to integrate the operations on both the Maya MCP server and Maya itself. The code you add is only Maya specific Python and doesn't need to add any MCP decorators. This is a much better design to grow and adapt to different installations instead of having a fixed set of tools.\r\n\r\nThe Maya MCP server was built using the low-level Python MCP module. This was necessary to allow for dynamically defining all of the tools at run time. The tool function signatures are captured dynamically at the start of the server. \r\n\r\n### Adding New Tools\r\n\r\nIt is easy to add new tools to Maya MCP. You don't need to change any of the existing code. All you need to do is add a single tool command Python file to the mayatools/thirdparty directory. The tool itself will run in Maya so it will have access to all of the Maya Python modules. There are a few programmer notes in the design of the tool.\r\n\r\n* The name of the Python file and the function name must be the same. Make sure it is unique.\r\n* The Python function will be loaded by both the server and Maya. Any code outside of the function must be able to be loaded into standalone Python. Meaning any imports such as maya.cmds should be done in the scope of the function. The MCP server loads the function so it can inspect the function signature to send the information to MCP Client via JSON-RPC.\r\n* The function signature will be parsed and must include any types in the function argument annotation.\r\n* When your function is sent to Maya, it will be scoped within am _mcp_maya_scope function. This provides a number of benefits. The functions sent to Maya will not polute the Python global space too much running in Maya. Plus, any exceptions thrown will be caught and returned back to the MCP Client as errors.\r\n* Generally, you want to return either a list or dictionary or throw an exception when there is an error.\r\n* Name your function and arguments appropriately so the LLM can understand the operation. Include a function doc string.\r\n* Default arguments are good. \r\n* Error checking is good so error messages can provide better failed explanations.\r\n\r\nI recommend looking at the existing Maya tools in this project as examples.\r\n\r\n## Testing\r\n\r\nCurrently Maya MCP has only been tested on Windows. Should work on both Linux and Mac as everything is using standard Python.\r\n\r\n## Future Ideas\r\n\r\nIt's early days for MCP and there is a lot to improve. Here are some ideas.\r\n\r\n* Expose more functionality.\r\n* Improve using prompt engineering, particularly describing Maya's usage and data relationships.\r\n* Everything is registered as tools, allow for resources and prompts.\r\n* It could be possible to find any plugins within Maya that has MCP tools. Maybe something like looking at the PYTHONPATH within Maya with any directory named MCP. All of those could be inspected and then provided back to the MCP Client.\r\n\r\n## License\r\n\r\nMIT\r\n\r\n## Links\r\n\r\n* [Model Context Protocol (MCP)](https://modelcontextprotocol.io/)\r\n* [Anthopic Claude Desktop](https://claude.ai/download)\r\n* [MCP Python SDK](https://github.com/modelcontextprotocol/python-sdk)\r\n* [Unreal MCP](https://github.com/chongdashu/unreal-mcp)\r\n\r\n\r\n## Important Note\r\n\r\nThis project was done on my personal time and equipment to learn about MCP. The project is not affiliated with my current employer and does not represent their work or interests.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mayamcp",
        "maya",
        "autodesk",
        "autodesk maya",
        "maya using",
        "mayamcp control"
      ],
      "category": "simulation-and-modeling"
    },
    "priyankark--a11y-mcp": {
      "owner": "priyankark",
      "name": "a11y-mcp",
      "url": "https://github.com/priyankark/a11y-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/priyankark.webp",
      "description": "Perform accessibility audits on webpages and generate detailed reports and summaries that comply with WCAG standards. Integrate the findings into an AI-assisted workflow to fix accessibility issues efficiently.",
      "stars": 27,
      "forks": 7,
      "license": "Mozilla Public License 2.0",
      "language": "JavaScript",
      "updated_at": "2025-09-29T08:04:09Z",
      "readme_content": "# A11y MCP Server\n\nAn MCP (Model Context Protocol) server for performing accessibility audits on webpages using axe-core. Use the results in an agentic loop with your favorite AI assistants (Cline/Cursor/GH Copilot) and let them fix a11y issues for you!\n\n<a href=\"https://glama.ai/mcp/servers/@priyankark/a11y-mcp\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@priyankark/a11y-mcp/badge\" alt=\"a11y-mcp MCP server\" />\n</a>\n\n## Features\n\n- Perform detailed accessibility audits on any webpage\n- Get a summary of accessibility issues\n- Filter audits by specific WCAG criteria\n- Include HTML snippets in the results for easier debugging\n\n## Installation\n\n```bash\n# Install globally\nnpm install -g a11y-mcp\n\n# Or use directly with npx\nnpx a11y-mcp\n```\n\n## Configuration\n\nTo use this MCP server with Cline, you need to add it to your MCP settings configuration file.\n\n### MCP configuration \n\nAdd the following to the `mcpServers` object:\n\n```json\n{\n  \"mcpServers\": {\n    \"a11y\": {\n      \"command\": \"npx\",\n      \"args\": [\"a11y-mcp\"],\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\n## Available Tools\n\n### audit_webpage\n\nPerforms a detailed accessibility audit on a webpage.\n\n**Parameters:**\n- `url` (required): URL of the webpage to audit\n- `includeHtml` (optional): Whether to include HTML snippets in the results (default: false)\n- `tags` (optional): Array of specific accessibility tags to check (e.g., wcag2a, wcag2aa, wcag21a, best-practice)\n\n**Example:**\n```\nUse the a11y MCP server to audit example.com for accessibility issues\n```\n\n### get_summary\n\nGets a summary of accessibility issues for a webpage.\n\n**Parameters:**\n- `url` (required): URL of the webpage to audit\n\n**Example:**\n```\nGive me an accessibility summary of example.com\n```\n\n## Example Usage\n\nOnce configured, you can ask Claude to use the MCP server to perform accessibility audits:\n\n1. \"Can you check example.com for accessibility issues?\"\n2. \"Audit my website at https://mywebsite.com for WCAG 2.1 AA compliance\"\n3. \"Give me a summary of accessibility issues on https://example.com\"\n4. \"Check if my local development server at http://localhost:3000 has any critical accessibility problems\"\n\n## Development\n\nTo run the server locally for development:\n\n```bash\nnpm start\n```\n\n## Releasing\n\nThis project includes a release script to help with versioning and publishing to npm. The script handles version bumping, running tests, git tagging, and npm publishing.\n\nTo release a new version:\n\n```bash\n# Make sure the script is executable\nchmod +x release.sh\n\n# Release a patch version (default)\n./release.sh\n\n# Release a minor version\n./release.sh --minor\n\n# Release a major version\n./release.sh --major\n\n# Release a specific version\n./release.sh --version=1.2.3\n\n# Skip git operations\n./release.sh --skip-git\n\n# Dry run (no changes will be made)\n./release.sh --dry-run\n\n# Force release even with uncommitted changes\n./release.sh --force\n```\n\nFor more information, run:\n\n```bash\n./release.sh --help\n```\n\n## License\nMPL 2.0\n\n## Credits\nThis project builds atop the awesome work done by [axe-core](https://github.com/dequelabs/axe-core)",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "accessibility",
        "priyankark",
        "workflow",
        "accessibility audits",
        "perform accessibility",
        "accessibility issues"
      ],
      "category": "simulation-and-modeling"
    },
    "radial-hks--MCP-Unreal-Server": {
      "owner": "radial-hks",
      "name": "MCP-Unreal-Server",
      "url": "https://github.com/radial-hks/MCP-Unreal-Server",
      "imageUrl": "/freedevtools/mcp/pfp/radial-hks.webp",
      "description": "Manage and execute Python code in Unreal Engine environments, with automatic discovery of Unreal instances and real-time monitoring of their status. Provides robust logging capabilities and support for remote execution in both attended and unattended modes.",
      "stars": 4,
      "forks": 5,
      "license": "No License",
      "language": "HTML",
      "updated_at": "2025-07-25T07:11:11Z",
      "readme_content": "# MCP Unreal Server\n\nA server implementation for interacting with Unreal Engine instances through remote Python execution.\n\n## Features\n\n- 🚀 **Unreal Instance Management**\n  - Automatic discovery of Unreal nodes via multicast\n  - Real-time node status monitoring\n  - Resource listing through LSP-compatible clients\n\n- 💻 **Remote Execution**\n  - Execute Python code in Unreal Engine environments\n  - Support for both attended and unattended execution modes\n  - File execution and statement evaluation modes\n\n- 📊 **Logging & Monitoring**\n  - Detailed logging to file (`mcp_unreal.log`)\n  - Console logging with different verbosity levels\n  - Node connection health monitoring\n\n## Installation\n\n```bash\n# Clone repository\ngit clone https://github.com/your-org/mcp-unreal-server.git\ncd mcp-unreal-server\n\n# Install dependencies\npip install -r requirements.txt\n```\n\n## Configuration\n\n### Network Settings\nConfigure multicast parameters in `RemoteExecutionConfig`:\n```python\n# Default multicast settings (modify in server.py)\nconfig.multicast_group_endpoint = (\"239.0.0.1\", 6766)\n```\n\n### Logging\nModify logging configuration in `server.py`:\n```python\n# Adjust log levels\nfile_handler.setLevel(logging.DEBUG)  # File logging\nconsole_handler.setLevel(logging.INFO)  # Console logging\n```\n\n## Usage\n\n### Starting the Server\n```bash\npython -m src.mcp_server_unreal.server\n```\n\n### Supported Tools\n\n1. **Connect to Unreal Instance**\n```json\n{\n  \"host\": \"239.0.0.1\",\n  \"port\": 6766\n}\n```\n\n2. **Execute Python Code**\n```json\n{\n  \"node_id\": \"<unreal-node-id>\",\n  \"code\": \"print('Hello Unreal')\",\n  \"unattended\": true\n}\n```\n\n## API Documentation\n\n### Resource Format\n```python\ntypes.Resource(\n    uri=\"unreal://<node_id>\",\n    name=f\"Unreal Instance: {node_id}\",\n    description=\"Unreal Engine instance\",\n    mimeType=\"application/x-unreal\"\n)\n```\n\n### Execution Modes\n| Mode                 | Description                     |\n|----------------------|---------------------------------|\n| MODE_EXEC_FILE       | Execute Python file             |\n| MODE_EXEC_STATEMENT  | Execute Python statement        |\n| MODE_EVAL_STATEMENT  | Evaluate Python expression      |\n\n## Troubleshooting\n\n**Common Issues:**\n- No nodes discovered: Verify Unreal instances are running with MCP plugin\n- Execution timeout: Check firewall settings for multicast traffic\n- Connection drops: Monitor `mcp_unreal.log` for node status changes\n\n## License\nApache-2.0 License",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "logging",
        "python",
        "hks",
        "unreal server",
        "unreal instances",
        "remote execution"
      ],
      "category": "simulation-and-modeling"
    },
    "tahooki--unreal-blender-mcp": {
      "owner": "tahooki",
      "name": "unreal-blender-mcp",
      "url": "https://github.com/tahooki/unreal-blender-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/tahooki.webp",
      "description": "Control and manipulate scenes, manage assets, and interface between Blender and Unreal Engine using AI agents. Integrate AI capabilities into creative workflows through a unified server architecture.",
      "stars": 7,
      "forks": 6,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-09-29T21:09:17Z",
      "readme_content": "# Unreal-Blender MCP\n\nUnreal-Blender MCP is a unified server for controlling both Blender and Unreal Engine via AI agents using the MCP (Machine Control Protocol) approach.\n\n## Overview\n\nThis project extends the [blender-mcp](https://github.com/ahujasid/blender-mcp.git) framework to include support for Unreal Engine, allowing AI agents like Claude and ChatGPT to simultaneously control both platforms through a single interface.\n\n## Submodule Information\n\nThis project includes `blender-mcp` as a Git submodule. When cloning the repository, use the following commands:\n\n```bash\n# Clone with submodules\ngit clone --recursive https://github.com/tahooki/unreal-blender-mcp.git\n\n# Or clone normally and then initialize submodules\ngit clone https://github.com/tahooki/unreal-blender-mcp.git\ncd unreal-blender-mcp\ngit submodule update --init --recursive\n```\n\n## Features\n\n- **Unified Control**: Single MCP server to control both Blender and Unreal Engine\n- **AI Agent Integration**: Designed to work with Claude, ChatGPT, and other AI assistants\n- **Blender Features**: Retains all blender-mcp functionality including:\n  - Scene manipulation\n  - Object creation and editing\n  - Material management\n  - PolyHaven asset integration\n  - Hyper3D Rodin model generation\n- **Unreal Engine Features**:\n  - Level creation and management\n  - Asset importing\n  - Python code execution\n  - Scene manipulation\n- **Extension Structure**: Easily extend both Blender addon and server while maintaining compatibility with upstream updates\n\n## Architecture\n\nThe system consists of three main components:\n\n1. **MCP Server**: Central hub communicating with AI agents via SSE (Server-Sent Events) on port 8000\n2. **Blender Addon**: Socket server within Blender on port 8400 (standard) or 8401 (extended)\n3. **Unreal Plugin**: HTTP server within Unreal Engine on port 8500\n\n```\n[AI Agent] <--SSE--> [MCP Server (8300)] \n                        |\n                        |--HTTP--> [Blender Addon (8400)]\n                        |\n                        |--HTTP--> [Unreal Plugin (8500)]\n```\n\n## Extension Structure\n\nThis project uses an extension approach to maintain compatibility with upstream changes:\n\n- **Blender Addon Extension**: Extends the original `BlenderMCPServer` while keeping the original code intact\n- **Server Extension**: Enhances the original server with additional tools and Unreal Engine integration\n- **Interface Tools**: Provides utilities for installing, configuring, and running extensions\n\nThis approach allows easy updates from the original projects without code conflicts.\n\n## Step-by-Step Installation and Setup Guide\n\n### Prerequisites\n\n- Python 3.10 or later\n- Blender 3.0 or later\n- Unreal Engine 5.0 or later\n- uv package manager (install with `pip install uv` if you don't have it)\n\n### 1. Clone the Repository\n\n```bash\n# Clone with submodules (recommended)\ngit clone --recursive https://github.com/tahooki/unreal-blender-mcp.git\ncd unreal-blender-mcp\n\n# Or if you already cloned without --recursive:\ngit clone https://github.com/tahooki/unreal-blender-mcp.git\ncd unreal-blender-mcp\ngit submodule update --init --recursive\n```\n\n### 2. Set Up Python Environment\n\n```bash\n# Create a virtual environment and activate it\nuv venv\n# On Windows:\n.\\venv\\Scripts\\activate\n# On macOS/Linux:\nsource venv/bin/activate\n\n# Install project dependencies\nuv pip install -e .\n```\n\n### 3. Install Blender Addon\n\nChoose ONE of the following options:\n\n#### Option A: Standard Addon (Original blender-mcp)\n1. Open Blender\n2. Navigate to Edit > Preferences > Add-ons\n3. Click \"Install...\" button\n4. Browse and select `blender-mcp/addon.py` file\n5. Enable the \"Interface: Blender MCP\" addon (check the box)\n\n#### Option B: Extended Addon (With additional features)\n1. Run the extension installer script:\n   ```bash\n   python -c \"from src.unreal_blender_mcp.blender_addon import BlenderAddonManager; BlenderAddonManager().install_to_blender(force=True)\"\n   ```\n2. Open Blender\n3. Navigate to Edit > Preferences > Add-ons\n4. Find and enable the \"Interface: Extended Blender MCP\" addon (check the box)\n\n### 4. Install Unreal Engine Plugin\n\n1. Locate the `UEPythonServer` folder in this project\n2. Copy the entire folder to your Unreal project's `Plugins` directory\n   - If your project doesn't have a `Plugins` directory, create one\n3. Start Unreal Engine with your project\n4. Navigate to Edit > Plugins in the menu\n5. Find and enable the Python Server plugin\n6. Restart Unreal Engine when prompted\n\n### 5. Start the MCP Server\n\nChoose ONE of the following options:\n\n#### Option A: Standard Server\n```bash\n# Make sure your virtual environment is activated\npython main.py\n```\n\n#### Option B: Extended Server (More features)\n```bash\n# Make sure your virtual environment is activated\npython run_extended_server.py\n\n# Optional: Customize server options\npython run_extended_server.py --host 127.0.0.1 --port 8080 --log-level DEBUG\n```\n\n### 6. Enable the Blender Server Connection\n\n1. Start Blender (if not already running)\n2. In the 3D viewport, press `N` to open the sidebar panel\n3. Select the appropriate tab:\n   - \"BlenderMCP\" (if using standard addon)\n   - \"ExtBlenderMCP\" (if using extended addon)\n4. Click the \"Start Server\" button\n5. Verify the server starts successfully (check console output)\n\n### 7. Verify Unreal Engine Connection\n\n1. With Unreal Engine running and plugin enabled\n2. The Python server should automatically start\n3. Check the Output Log (Window > Developer Tools > Output Log) for any messages\n4. The Unreal plugin should now be ready to receive commands\n\n### 8. Connect an AI Agent\n\n#### Option A: Integrate with Claude for Desktop\n\nAdd the following to Claude for Desktop's configuration:\n\n```json\n{\n    \"mcpServers\": {\n        \"unreal-blender\": {\n            \"command\": \"uvx\",\n            \"args\": [\n                \"unreal-blender-mcp\"\n            ]\n        },\n        \"unreal-blender-ext\": {\n            \"command\": \"python\",\n            \"args\": [\n                \"/path/to/unreal-blender-mcp/run_extended_server.py\"\n            ]\n        }\n    }\n}\n```\nReplace `/path/to/` with your actual project path.\n\n#### Option B: Integrate with Cursor\n\n1. Open Cursor Settings\n2. Navigate to MCP section\n3. Add the following commands:\n   - Standard Server: `uvx unreal-blender-mcp`\n   - Extended Server: `python /path/to/unreal-blender-mcp/run_extended_server.py`\n   \n   Replace `/path/to/` with your actual project path.\n\n#### Option C: Integrate with Other AI Tools\n\nRefer to your AI tool's documentation for integrating with MCP servers, and point it to:\n- MCP Server URL: `http://localhost:8000` (or custom port if specified)\n\n### 9. Testing the System\n\nOnce all components are running:\n\n1. Use your AI agent to interact with Blender by asking it to:\n   - Create a simple cube or sphere\n   - Modify object properties\n   - Create materials\n\n2. Use your AI agent to interact with Unreal Engine by asking it to:\n   - Create a new level\n   - Place assets\n   - Modify scene properties\n\n3. Try more complex operations that involve both platforms working together\n\n### Troubleshooting\n\nIf you encounter issues:\n\n1. Check that all servers are running (MCP, Blender, Unreal)\n2. Verify port configurations match (default: 8000 for MCP, 8400/8401 for Blender, 8500 for Unreal)\n3. Check console outputs for error messages\n4. Restart components in the correct order: MCP server first, then Blender, then Unreal Engine\n\nFor more detailed information on development and extending the system, see the [Project Document](Project-document.md) and [workflow](workflow/) directory.\n\n## Comparison: Standard vs Extended\n\n| Feature | Standard Server | Extended Server |\n|---------|----------------|----------------|\n| Blender Control | ✅ | ✅ |\n| Unreal Control | ✅ | ✅ |\n| Custom Blender Commands | ❌ | ✅ |\n| Enhanced Scene Info | ❌ | ✅ |\n| Auto Feature Detection | ❌ | ✅ |\n| Upstream Compatibility | ✅ | ✅ |\n\nChoose the standard server for basic functionality or the extended server for advanced features.\n\n## Development\n\nSee the [Project Document](Project-document.md) and [workflow](workflow/) directory for detailed development information.\n\nFor extending this project:\n- To add new Blender addon features: Modify `src/unreal_blender_mcp/blender_addon/extended_addon.py`\n- To add new server tools: Modify `src/unreal_blender_mcp/server_extension/extended_server.py`\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## Acknowledgements\n\n- This project builds upon [blender-mcp](https://github.com/ahujasid/blender-mcp.git) by Siddharth Ahuja.\n\n## Future Developments\n\nThe following improvements are planned for future releases:\n\n### Structured Unreal Engine API\n\nCurrently, the Unreal Engine communication relies primarily on direct Python code execution. A planned enhancement is to implement a structured API similar to the Blender integration:\n\n- Create predefined functions for common Unreal Engine operations\n- Implement proper error handling and validation\n- Improve security by limiting execution scope\n- Enhance stability and predictability of operations\n- Maintain backward compatibility while adding structure\n\nThis enhancement will create a more consistent experience across both engines and improve the overall reliability of the system. See the [workflow documentation](workflow/08-unreal-engine-refinement.md) for more details on this planned development.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ai",
        "agents",
        "blender",
        "unreal engine",
        "ai agents",
        "blender unreal"
      ],
      "category": "simulation-and-modeling"
    },
    "team-plask--3d-mcp": {
      "owner": "team-plask",
      "name": "3d-mcp",
      "url": "https://github.com/team-plask/3d-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/team-plask.webp",
      "description": "Creates a unified TypeScript interface for interacting with multiple 3D software applications such as Blender, Maya, and Unreal Engine through a single API. Facilitates operations like creating keyframes and managing 3D object properties with streamlined code generation.",
      "stars": 14,
      "forks": 1,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-09-21T17:08:44Z",
      "readme_content": "# 3D MCP\n\n![Plugin Tests](https://github.com/team-plask/3d-mcp/workflows/Plugin%20Code%20Generation%20Tests/badge.svg) ![TypeScript](https://img.shields.io/badge/TypeScript-5.0%2B-blue) ![License](https://img.shields.io/badge/License-Apache_2.0-green)\n\n## Overview\n\n3D-MCP is a universal implementation of the [Model Context Protocol](https://modelcontextprotocol.io/introduction) for 3D software. It creates a unified TypeScript interface for LLMs to interact with Blender, Maya, Unreal Engine, and other 3D applications through a single coherent API.\n\n```typescript\n// LLMs use the same interface regardless of underlying 3D software\nawait tools.animation.createKeyframe({\n  objectId: \"cube_1\",\n  property: \"rotation.x\",\n  time: 30,\n  value: Math.PI/2\n});\n```\n\n## Core Philosophy & Design Decisions\n\n3D-MCP is built on four interconnected architectural principles that together create a unified system for 3D content creation:\n\n1. **Entity-First Design**: Well-defined domain entities form the foundation of all operations, enabling consistent data modeling across platforms\n2. **Type-Safe CRUD Operations**: Automated generation of create, read, update, delete operations with complete type validation\n3. **Atomic Operation Layer**: A minimal set of platform-specific implementations that handle fundamental operations\n4. **Composable Tool Architecture**: Complex functionality built by combining atomic operations in a platform-agnostic way\n\nThis architecture creates a **dependency inversion** where platform-specific implementation details are isolated to atomic operations, while the majority of the codebase remains platform-independent.\n\n```\n┌─────────────────────────────────────────────────────────────────────────┐\n│                             LLM / User API                              │\n└───────────────────────────────────┬─────────────────────────────────────┘\n                                    │ MCP Tool API\n                                    ▼\n┌─────────────────────────────────────────────────────────────────────────┐\n│                          Compound Operations                            │\n│                                                                         │\n│  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────────────┐  │\n│  │ Modeling Tools  │  │ Animation Tools │  │ Rigging Tools           │  │\n│  └─────────────────┘  └─────────────────┘  └─────────────────────────┘  │\n└───────────────────────────────────┬─────────────────────────────────────┘\n                                    │ Implemented by\n                                    ▼\n┌─────────────────────────────────────────────────────────────────────────┐\n│                           Atomic Operations                             │\n│                                                                         │\n│  ┌─────────── Entity CRUD ────────────┐ ┌────────── Non-CRUD ─────────┐ │ \n│  │ create{Entity}s update{Entity}s ...│ │  select, undo, redo, etc.   │ │  \n│  └────────────────────────────────────┘ └─────────────────────────────┘ │\n└───────────────────────────────────┬─────────────────────────────────────┘\n                                    │ Plug-in Server Request\n                                    ▼\n┌─────────────────────────────────────────────────────────────────────────┐\n│                       Platform-Specific Adapters                        │\n│                                                                         │\n│  ┌──── Blender ────┐  ┌────── Maya ─────┐  ┌─── Unreal Engine ────┐     │\n│  │ createKeyframes │  │ createKeyframes │  │ createKeyframes      │     │    \n│  └─────────────────┘  └─────────────────┘  └──────────────────────┘     │\n└─────────────────────────────────────────────────────────────────────────┘\n```\n\n## Why These Design Decisions?\n\n**Entity-First Design** was chosen because:\n- 3D applications use different object models but share core concepts (meshes, materials, animations)\n- Zod schemas provide single-source-of-truth for validation, typing, and documentation\n- Strong typing catches errors at compile time rather than runtime\n- Rich metadata enables better AI understanding of domain objects\n\n**CRUD Operations as Foundation** because:\n- They map cleanly to what 3D applications need to do with entities\n- Standardized patterns reduce cognitive overhead\n- Auto-generation eliminates repetitive code using `createCrudOperations`\n- Every entity automatically gets the same consistent interface\n\n**Atomic and Compound Tool Separation** because:\n- Only atomic tools need platform-specific implementation (~20% of codebase)\n- Compound tools work across all platforms without modification (~80% of codebase)\n- New platforms only need to implement atomic operations to gain all functionality\n- Maintainable architecture with clear separation of concerns\n\n## Technical Architecture\n\n### 1. Entity-Centric CRUD Architecture\n\nThe system's foundation is a rich type system of domain entities that generates CRUD operations:\n\n```typescript\n// Define entities with rich metadata using Zod\nexport const Mesh = NodeBase.extend({\n  vertices: z.array(Tensor.VEC3).describe(\"Array of vertex positions [x, y, z]\"),\n  normals: z.array(Tensor.VEC3).optional().describe(\"Array of normal vectors\"),\n  // ... other properties\n});\n\n// CRUD operations generated automatically from entity schemas\nconst entityCruds = createCrudOperations(ModelEntities);\n// => Creates createMeshs, getMeshs, updateMeshs, deleteMeshs, listMeshs\n\n// All operations preserve complete type information\nawait tool.createRigControls.execute({\n  name: \"arm_ctrl\",          \n  shape: \"cube\",            // TypeScript error if not a valid enum value\n  targetJointIds: [\"joint1\"], // Must be string array\n  color: [0.2, 0.4, 1],     // Must match Color schema format\n  // IDE autocomplete shows all required/optional fields\n});\n```\n\nEntity schemas provide:\n- **Schema Validation**: Runtime parameter checking with detailed error messages\n- **Type Information**: Complete TypeScript types for IDE assistance\n- **Documentation**: Self-documenting API with descriptions\n- **Code Generation**: Templates for platform-specific implementations\n\n#### Entity Architecture Diagram\n\n```\n┌──────────────────────────────────────────────────────────────┐\n│                Core Entity Definitions                       │\n│                                                              │\n│  ┌─────────────┐  ┌─────────────┐  ┌─────────────────────┐   │\n│  │ BaseEntity  │  │ NodeBase    │  │ Other Core Entities │   │\n│  └─────────────┘  └─────────────┘  └─────────────────────┘   │\n└──────────────────────────────────────────────────────────────┘\n                           ▲\n                           │ extends\n                           │\n┌──────────────────────────────────────────────────────────────┐\n│                Domain-Specific Entities                      │\n│                                                              │\n│  ┌─────────────┐  ┌─────────────┐  ┌─────────────────────┐   │\n│  │ Model       │  │ Animation   │  │ Rigging             │   │\n│  │ Entities    │  │ Entities    │  │ Entities            │   │\n│  └─────────────┘  └─────────────┘  └─────────────────────┘   │\n└──────────────────────────────────────────────────────────────┘\n                           │\n                           │ input to\n                           ▼\n┌──────────────────────────────────────────────────────────────┐\n│                Automatic CRUD Generation                     │\n│                                                              │\n│  ┌─────────────────────────────────────────────────────────┐ │\n│  │ createCrudOperations(Entities)                          │ │\n│  └─────────────────────────────────────────────────────────┘ │\n└──────────────────────────────────────────────────────────────┘\n                           │\n                           │ generates\n                           ▼\n┌──────────────────────────────────────────────────────────────┐\n│                     Atomic Operations                        │\n│                                                              │\n│  ┌─────────────────┐ ┌──────────────┐ ┌─────────────────┐    │\n│  │ create{Entity}s │ │ get{Entity}s │ │ update{Entity}s │ .. │\n│  └─────────────────┘ └──────────────┘ └─────────────────┘    │\n└──────────────────────────────────────────────────────────────┘\n                           │\n                           │ foundation for\n                           ▼\n┌──────────────────────────────────────────────────────────────┐\n│                    Compound Operations                       │\n│                                                              │\n│  ┌─────────────────────────────────────────────────────────┐ │\n│  │ No need for platform-specific code. Use atomic ops only.│ │\n│  └─────────────────────────────────────────────────────────┘ │\n└──────────────────────────────────────────────────────────────┘\n```\n\n\n### 2. Compound Tool Architecture\n\nThe system creates a clear separation between atomic and compound operations:\n\n```typescript\n// From compounded.ts - Higher level operations composed from atomic operations\ncreateIKFKSwitch: defineCompoundTool({\n  // ...parameter and return definitions...\n  execute: async (params) => {\n    // Create IK chain using atomic operations\n    const ikChainResult = await tool.createIKChains.execute({/*...*/});\n    \n    // Create control with full type-checking\n    const ikControlResult = await tool.createRigControls.execute({\n      name: `${switchName}_IK_CTRL`,\n      shape: ikControlShape,  // Type-checked against schema\n      targetJointIds: [jointIds[jointIds.length - 1]],\n      color: ikColor,\n      // ...other parameters\n    });\n    \n    // Position the control at the end effector\n    await tool.batchTransform.execute({/*...*/});\n    \n    // Create constraints to connect the system\n    await tool.createConstraint.execute({/*...*/});\n    \n    // Return standardized response with created IDs\n    return {\n      success: true,\n      switchControlId: switchControlResult.id,\n      ikControlId: ikControlResult.id,\n      fkControlIds,\n      poleVectorId: poleVectorId || undefined,\n    };\n  }\n})\n```\n\nThis architecture provides several technical advantages:\n\n1. **Atomic Operations** (~20% of the system):\n   - Directly interact with platform APIs\n   - Need platform-specific implementations\n   - Focus on single entity operations (create, read, update, delete)\n   - Form minimal implementation required for new platforms\n\n2. **Compound Operations** (~80% of the system):\n   - Built entirely from atomic operations\n   - Zero platform-specific code\n   - Implement higher-level domain concepts\n   - Work on any platform without modification\n\n#### Tool Composition Flow\n\n```\n┌─────────────────────────────────────────────────────────────────────────┐\n│                        High-Level Tool Definition                       │\n└──────────────────────────────────────┬──────────────────────────────────┘\n                                       │\n                                       ▼\n┌─────────────────────────────────────────────────────────────────────────┐\n│                         Compound Tool Pattern                           │\n│                                                                         │\n│  ┌──────────────────────────────────────────────────────────────────┐   │\n│  │ defineCompoundTool({                                             │   │\n│  │   description: string,                                           │   │\n│  │   parameters: zod.Schema,                                        │   │\n│  │   returns: zod.Schema,                                           │   │\n│  │   execute: async (params) => {                                   │   │\n│  │     // Composed entirely from atomic operations                  │   │\n│  │     await tool.atomicOperation1.execute({...});                  │   │\n│  │     await tool.atomicOperation2.execute({...});                  │   │\n│  │     return { success: true, ...results };                        │   │\n│  │   }                                                              │   │\n│  │ })                                                               │   │\n│  └──────────────────────────────────────────────────────────────────┘   │\n└───────────────────────────────────┬─────────────────────────────────────┘\n                                    │ Plug-in Server Request\n                                    ▼\n┌─────────────────────────────────────────────────────────────────────────┐\n│                         Platform Adaptation                             │\n│                                                                         │\n│  ┌──────────────────────────┐  ┌─────────────────────────────────────┐  │\n│  │ Blender Implementation   │  │ Maya Implementation                 │  │\n│  │ of Atomic Operations     │  │ of Atomic Operations                │  │\n│  └──────────────────────────┘  └─────────────────────────────────────┘  │\n└─────────────────────────────────────────────────────────────────────────┘\n```\n\nKey files for the compound tool architecture:\n- compounded.ts: Compound modeling tools\n- compounded.ts: Compound animation tools\n- compounded.ts: Compound rigging tools\n\n### 3. Code Generation Pipeline\n\nThe system automatically generates platform-specific implementations from TypeScript definitions:\n\n```\n┌─────────────────┐     ┌────────────────────┐     ┌─────────────────────────┐\n│ Entity Schemas  │     │ Schema             │     │ Platform-Specific Code  │\n│ & Tools (TS)    │ ──> │ Extraction (TS)    │ ──> │ (Python/C++/etc.)       │\n└─────────────────┘     └────────────────────┘     └─────────────────────────┘\n      │                        │                             │\n      │                        │                             │\n      ▼                        ▼                             ▼\n┌─────────────────┐     ┌────────────────────┐     ┌─────────────────────────┐\n│ Type            │     │ Parameter          │     │ Implementation          │\n│ Definitions     │     │ Validation         │     │ Templates               │\n└─────────────────┘     └────────────────────┘     └─────────────────────────┘\n```\n\nKey aspects of the generation system:\n- **Entity Extraction**: Analyzes Zod schemas to understand entity structure\n- **Parameter Mapping**: Converts TypeScript types to platform-native types\n- **Validation Generation**: Creates parameter validation in target languages\n- **Implementation Templates**: Provides platform-specific code patterns\n\nThe codegen system is implemented in:\n- [plugin-codegen.ts](./packages/scripts/plugin-codegen.ts): Main code generation script\n- [extract-schemas.ts](./packages/scripts/extract-schemas.ts): Extracts Zod schemas from TypeScript files into temporary JSON files.\n\n### 4. Domain Organization\n\nThe system is organized into domains that mirror 3D content creation workflows:\n\n- **Core**: Base entities and operations used across all domains\n- **Modeling**: Mesh creation, editing, and topology operations\n- **Animation**: Keyframes, curves, clips, and animation control\n- **Rigging**: Skeletal systems, controls, and deformation\n- **Rendering**: Materials, lights, and render settings\n\nEach domain follows the same organizational pattern:\n- [`entity.ts`](./packages/src/tool/animation/entity.ts): Domain-specific entity definitions\n- [`atomic.ts`](./packages/src/tool/animation/atomic.ts): Atomic operations for domain entities\n- [`compounded.ts`](./packages/src/tool/animation/compounded.ts): Higher-level operations built from atomic tools\n\n#### Domain Structure Diagram\n\n```\npackages/src/tool/\n│\n├── core/                  # Core shared components\n│   ├── entity.ts          # Base entities all domains use\n│   ├── utils.ts           # Shared utilities including CRUD generation\n│   └── ...\n│\n├── model/                 # Modeling domain\n│   ├── entity.ts          # Mesh, Vertex, Face, etc.\n│   ├── atomic.ts          # Atomic modeling operations\n│   ├── compounded.ts      # Higher-level modeling tools\n│   └── ...\n│\n├── animation/             # Animation domain\n│   ├── entity.ts          # Keyframe, AnimCurve, Clip, etc.\n│   ├── atomic.ts          # Atomic animation operations\n│   ├── compounded.ts      # Higher-level animation tools\n│   └── ...\n│\n├── rig/                   # Rigging domain\n│   ├── entity.ts          # Joint, IKChain, Control, etc.\n│   ├── atomic.ts          # Atomic rigging operations\n│   ├── compounded.ts      # Higher-level rigging tools\n│   └── ...\n│\n└── rendering/             # Rendering domain\n    ├── entity.ts          # Camera, Light, RenderSettings, etc.\n    ├── atomic.ts          # Atomic rendering operations\n    ├── compounded.ts      # Higher-level rendering tools\n    └── ...\n```\n\n### 5. Entity-Centric CRUD Architecture\n\nThe system implements a sophisticated entity-centric approach where:\n\n1. **Entities as Domain Models**: Each domain (modeling, animation, rigging) defines its core entities that represent its fundamental concepts. These are implemented as Zod schemas with rich type information.\n\n2. **CRUD as Foundation**: Every entity automatically receives a complete set of CRUD operations (Create, Read, Update, Delete) through the `createCrudOperations` utility:\n\n```typescript\n// Each domain starts with CRUD operations for all its entities\nconst entityCruds = createCrudOperations(ModelEntities);\n\nconst modelAtomicTools = {\n  ...entityCruds,  // Foundation of all atomic tools\n  // Domain-specific operations build on this foundation\n}\n```\n\n3. **Entity Reuse and Inheritance**: Core entities defined in `core/entity.ts` are extended by domain-specific entities, promoting code reuse and consistent design across domains.\n\n4. **DDD-Inspired Architecture**: The system follows Domain-Driven Design principles by organizing code around domain entities and aggregates rather than technical concerns.\n\nThis architecture provides several key benefits:\n\n- **Consistency**: All entities have the same patterns for basic operations\n- **Reduced Boilerplate**: CRUD operations are generated automatically  \n- **Clear Organization**: Tools are organized around domain entities\n- **Separation of Concerns**: Each domain manages its own entities while sharing common patterns\n\nThe combination of rich entity models with automatic CRUD operations creates a robust foundation that simplifies development while maintaining flexibility for domain-specific operations.\n\n## Getting Started\n\n```bash\n# Install dependencies\nbun install\n\n# Run the server\nbun run index.ts\n\n# Extract schemas and generate plugins\nbun run packages/scripts/plugin-codegen.ts\n```\n\n## Development Workflow\n\n1. **Define Entities**: Create or extend entity schemas in `src/tool/<domain>/entity.ts`\n2. **Generate CRUD**: Use `createCrudOperations` to generate atomic operations\n3. **Create Compound Tools**: Build higher-level operations from atomic tools\n4. **Generate Plugins**: Run the code generator to create platform-specific implementations\n\n## Contributing\n\nThe architectural decisions in 3D-MCP make it uniquely extensible:\n\n1. **Add New Entities**: Define new entities and automatically get CRUD operations\n2. **Add New Compound Tools**: Combine existing atomic operations to create new functionality\n3. **Add New Platforms**: Implement the atomic tool interfaces in a new plugin\n\nSee our contributing guide for more details on how to contribute.\n\n---\n\n*3D-MCP: One API to rule all 3D software*",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "3d",
        "plask",
        "typescript",
        "plask 3d",
        "3d mcp",
        "3d software"
      ],
      "category": "simulation-and-modeling"
    },
    "ttiimmaacc--cinema4d-mcp": {
      "owner": "ttiimmaacc",
      "name": "cinema4d-mcp",
      "url": "https://github.com/ttiimmaacc/cinema4d-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/ttiimmaacc.webp",
      "description": "Connects Cinema 4D to Claude for prompt-assisted 3D manipulation, enabling users to create, modify, and render scenes through integrated scripting and object management tools.",
      "stars": 23,
      "forks": 7,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-14T18:49:05Z",
      "readme_content": "# Cinema4D MCP — Model Context Protocol (MCP) Server\n\nCinema4D MCP Server connects Cinema 4D to Claude, enabling prompt-assisted 3D manipulation.\n\n## Table of Contents\n\n- [Components](#components)\n- [Prerequisites](#prerequisites)\n- [Installation](#installation)\n- [Setup](#setup)\n- [Usage](#usage)\n- [Development](#development)\n- [Troubleshooting & Debugging](#troubleshooting--debugging)\n- [File Structure](#file-structure)\n- [Tool Commands](#tool-commands)\n\n## Components\n\n1. **C4D Plugin**: A socket server that listens for commands from the MCP server and executes them in the Cinema 4D environment.\n2. **MCP Server**: A Python server that implements the MCP protocol and provides tools for Cinema 4D integration.\n\n## Prerequisites\n\n- Cinema 4D (R2024+ recommended)\n- Python 3.10 or higher (for the MCP Server component)\n\n## Installation\n\nTo install the project, follow these steps:\n\n### Clone the Repository\n\n```bash\ngit clone https://github.com/ttiimmaacc/cinema4d-mcp.git\ncd cinema4d-mcp\n```\n\n### Install the MCP Server Package\n\n```bash\npip install -e .\n```\n\n### Make the Wrapper Script Executable\n\n```bash\nchmod +x bin/cinema4d-mcp-wrapper\n```\n\n## Setup\n\n### Cinema 4D Plugin Setup\n\nTo set up the Cinema 4D plugin, follow these steps:\n\n1. **Copy the Plugin File**: Copy the `c4d_plugin/mcp_server_plugin.pyp` file to Cinema 4D's plugin folder. The path varies depending on your operating system:\n\n   - macOS: `/Users/USERNAME/Library/Preferences/Maxon/Maxon Cinema 4D/plugins/`\n   - Windows: `C:\\Users\\USERNAME\\AppData\\Roaming\\Maxon\\Maxon Cinema 4D\\plugins\\`\n\n2. **Start the Socket Server**:\n   - Open Cinema 4D.\n   - Go to Extensions > Socket Server Plugin\n   - You should see a Socket Server Control dialog window. Click Start Server.\n\n### Claude Desktop Configuration\n\nTo configure Claude Desktop, you need to modify its configuration file:\n\n1. **Open the Configuration File**:\n\n   - macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n   - Alternatively, use the Settings menu in Claude Desktop (Settings > Developer > Edit Config).\n\n2. **Add MCP Server Configuration**:\n   For development/unpublished server, add the following configuration:\n   ```json\n   \"mcpServers\": {\n     \"cinema4d\": {\n       \"command\": \"python3\",\n       \"args\": [\"/Users/username/cinema4d-mcp/main.py\"]\n     }\n   }\n   ```\n3. **Restart Claude Desktop** after updating the configuration file.\n<details>\n\n  <summary>[TODO] For published server</summary>\n\n```json\n{\n  \"mcpServers\": {\n    \"cinema4d\": {\n      \"command\": \"cinema4d-mcp-wrapper\",\n      \"args\": []\n    }\n  }\n}\n```\n\n   </details>\n\n## Usage\n\n1. Ensure the Cinema 4D Socket Server is running.\n2. Open Claude Desktop and look for the hammer icon 🔨 in the input box, indicating MCP tools are available.\n3. Use the available [Tool Commands](#tool-commands) to interact with Cinema 4D through Claude.\n\n## Testing\n\n### Command Line Testing\n\nTo test the Cinema 4D socket server directly from the command line:\n\n```bash\npython main.py\n```\n\nYou should see output confirming the server's successful start and connection to Cinema 4D.\n\n### Testing with MCP Test Harness\n\nThe repository includes a simple test harness for running predefined command sequences:\n\n1. **Test Command File** (`tests/mcp_test_harness.jsonl`): Contains a sequence of commands in JSONL format that can be executed in order. Each line represents a single MCP command with its parameters.\n\n2. **GUI Test Runner** (`tests/mcp_test_harness_gui.py`): A simple Tkinter GUI for running the test commands:\n\n   ```bash\n   python tests/mcp_test_harness_gui.py\n   ```\n\n   The GUI allows you to:\n\n   - Select a JSONL test file\n   - Run the commands in sequence\n   - View the responses from Cinema 4D\n\nThis test harness is particularly useful for:\n\n- Rapidly testing new commands\n- Verifying plugin functionality after updates\n- Recreating complex scenes for debugging\n- Testing compatibility across different Cinema 4D versions\n\n## Troubleshooting & Debugging\n\n1. Check the log files:\n\n   ```bash\n   tail -f ~/Library/Logs/Claude/mcp*.log\n   ```\n\n2. Verify Cinema 4D shows connections in its console after you open Claude Desktop.\n\n3. Test the wrapper script directly:\n\n   ```bash\n   cinema4d-mcp-wrapper\n   ```\n\n4. If there are errors finding the mcp module, install it system-wide:\n\n   ```bash\n   pip install mcp\n   ```\n\n5. For advanced debugging, use the [MCP Inspector](https://github.com/modelcontextprotocol/inspector):\n   ```bash\n   npx @modelcontextprotocol/inspector uv --directory /Users/username/cinema4d-mcp run cinema4d-mcp\n   ```\n\n## Project File Structure\n\n```\ncinema4d-mcp/\n├── .gitignore\n├── LICENSE\n├── README.md\n├── main.py\n├── pyproject.toml\n├── setup.py\n├── bin/\n│   └── cinema4d-mcp-wrapper\n├── c4d_plugin/\n│   └── mcp_server_plugin.pyp\n├── src/\n│   └── cinema4d_mcp/\n│       ├── __init__.py\n│       ├── server.py\n│       ├── config.py\n│       └── utils.py\n└── tests/\n    ├── test_server.py\n    ├── mcp_test_harness.jsonl\n    └── mcp_test_harness_gui.py\n```\n\n## Tool Commands\n\n### General Scene & Execution\n\n- `get_scene_info`: Get summary info about the active Cinema 4D scene. ✅\n- `list_objects`: List all scene objects (with hierarchy). ✅\n- `group_objects`: Group selected objects under a new null. ✅\n- `execute_python`: Execute custom Python code inside Cinema 4D. ✅\n- `save_scene`: Save the current Cinema 4D project to disk. ✅\n- `load_scene`: Load a `.c4d` file into the scene. ✅\n- `set_keyframe`: Set a keyframe on an objects property (position, rotation, etc.). ✅\n\n### Object Creation & Modification\n\n- `add_primitive`: Add a primitive (cube, sphere, cone, etc.) to the scene. ✅\n- `modify_object`: Modify transform or attributes of an existing object. ✅\n- `create_abstract_shape`: Create an organic, non-standard abstract form. ✅\n\n### Cameras & Animation\n\n- `create_camera`: Add a new camera to the scene. ✅\n- `animate_camera`: Animate a camera along a path (linear or spline-based). ✅\n\n### Lighting & Materials\n\n- `create_light`: Add a light (omni, spot, etc.) to the scene. ✅\n- `create_material`: Create a standard Cinema 4D material. ✅\n- `apply_material`: Apply a material to a target object. ✅\n- `apply_shader`: Generate and apply a stylized or procedural shader. ✅\n\n### Redshift Support\n\n- `validate_redshift_materials`: Check Redshift material setup and connections. ✅ ⚠️ (Redshift materials not fully implemented)\n\n### MoGraph & Fields\n\n- `create_mograph_cloner`: Add a MoGraph Cloner (linear, radial, grid, etc.). ✅\n- `add_effector`: Add a MoGraph Effector (Random, Plain, etc.). ✅\n- `apply_mograph_fields`: Add and link a MoGraph Field to objects. ✅\n\n### Dynamics & Physics\n\n- `create_soft_body`: Add a Soft Body tag to an object. ✅\n- `apply_dynamics`: Apply Rigid or Soft Body physics. ✅\n\n### Rendering & Preview\n\n- `render_frame`: Render a frame and save it to disk (file-based output only). ⚠️ (Works, but fails on large resolutions due to MemoryError: Bitmap Init failed. This is a resource limitation.)\n- `render_preview`: Render a quick preview and return base64 image (for AI). ✅\n- `snapshot_scene`: Capture a snapshot of the scene (objects + preview image). ✅\n\n## Compatibility Plan & Roadmap\n\n| Cinema 4D Version | Python Version | Compatibility Status | Notes                                             |\n| ----------------- | -------------- | -------------------- | ------------------------------------------------- |\n| R21 / S22         | Python 2.7     | ❌ Not supported     | Legacy API and Python version too old             |\n| R23               | Python 3.7     | 🔍 Not planned       | Not currently tested                              |\n| S24 / R25 / S26   | Python 3.9     | ⚠️ Possible (TBD)    | Requires testing and fallbacks for missing APIs   |\n| 2023.0 / 2023.1   | Python 3.9     | 🧪 In progress       | Targeting fallback support for core functionality |\n| 2023.2            | Python 3.10    | 🧪 In progress       | Aligns with planned testing base                  |\n| 2024.0            | Python 3.11    | ✅ Supported         | Verified                                          |\n| 2025.0+           | Python 3.11    | ✅ Fully Supported   | Primary development target                        |\n\n### Compatibility Goals\n\n- **Short Term**: Ensure compatibility with C4D 2023.1+ (Python 3.9 and 3.10)\n- **Mid Term**: Add conditional handling for missing MoGraph and Field APIs\n- **Long Term**: Consider optional legacy plugin module for R23–S26 support if demand arises\n\n## Recent Fixes\n\n- Context Awareness: Implemented robust object tracking using GUIDs. Commands creating objects return context (guid, actual_name, etc.). Subsequent commands correctly use GUIDs passed by the test harness/server to find objects reliably.\n- Object Finding: Reworked find_object_by_name to correctly handle GUIDs (numeric string format), fixed recursion errors, and improved reliability when doc.SearchObject fails.\n- GUID Detection: Command handlers (apply_material, create_mograph_cloner, add_effector, apply_mograph_fields, set_keyframe, group_objects) now correctly detect if identifiers passed in various parameters (object_name, target, target_name, list items) are GUIDs and search accordingly.\n- create_mograph_cloner: Fixed AttributeError for missing MoGraph parameters (like MG_LINEAR_PERSTEP) by using getattr fallbacks. Fixed logic bug where the found object wasn't correctly passed for cloning.\n- Rendering: Fixed TypeError in render_frame related to doc.ExecutePasses. snapshot_scene now correctly uses the working base64 render logic. Large render_frame still faces memory limits.\n- Registration: Fixed AttributeError for c4d.NilGuid.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "cinema4d",
        "4d",
        "3d",
        "cinema4d mcp",
        "ttiimmaacc cinema4d",
        "cinema 4d"
      ],
      "category": "simulation-and-modeling"
    },
    "waldzellai--waldzell-mcp": {
      "owner": "waldzellai",
      "name": "waldzell-mcp",
      "url": "https://github.com/waldzellai/waldzell-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/waldzellai.webp",
      "description": "Enhance decision-making capabilities using advanced stochastic algorithms to navigate complex problem-solving and avoid repetitive local solutions.",
      "stars": 175,
      "forks": 28,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-10-03T12:34:58Z",
      "readme_content": "# Waldzell MCP Servers\n\nThis repository contains a set of Model Context Protocol (MCP) servers. Each server lives in its own folder under `servers/` and can be used independently. The project is intentionally lightweight and does not make use of a complex monorepo toolchain.\n\n## Available servers\n\n- [Clear Thought](./servers/server-clear-thought) – Sequential thinking tools inspired by James Clear\n- [Google Styleguide](./servers/server-google-styleguide) – Google TypeScript style guide server\n- [Stochastic Thinking](./servers/server-stochasticthinking) – Stochastic thinking utilities\n- [TypeStyle](./servers/server-typestyle) – TypeScript style guide server\n\n## Getting started\n\n### Prerequisites\n\n- Node.js 18 or higher\n- npm (comes with Node.js)\n\nInstall dependencies for all servers:\n\n```bash\nnpm install\n```\n\nBuild every server:\n\n```bash\nnpm run build --workspaces\n```\n\nRun tests for all servers:\n\n```bash\nnpm test --workspaces\n```\n\nRefer to each server's README for usage instructions and additional scripts.\n\n## Publishing\n\nTo publish the packages defined in this repository:\n\n```bash\nnpm run build --workspaces && changeset publish\n```\n\n## License\n\nAll code in this repository is licensed under the MIT License.\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "stochastic",
        "waldzell",
        "mcp",
        "waldzell mcp",
        "decision making",
        "stochastic algorithms"
      ],
      "category": "simulation-and-modeling"
    }
  }
}