{
  "category": "multimedia-process",
  "categoryDisplay": "Multimedia Process",
  "description": "Provides the ability to handle multimedia, such as audio and video editing, playback, format conversion, also includes video filters, enhancements, and so on",
  "totalRepositories": 5,
  "repositories": {
    "ananddtyagi--gif-creator-mcp": {
      "owner": "ananddtyagi",
      "name": "gif-creator-mcp",
      "url": "https://github.com/ananddtyagi/gif-creator-mcp/tree/main",
      "imageUrl": "",
      "description": "A MCP server for creating GIFs from your videos.",
      "stars": 9,
      "forks": 4,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-08T19:47:09Z",
      "readme_content": "# GIF Creator MCP\n\nAn MCP (Model Context Protocol) server that converts video files to GIF animations.\n![gif-creator-demo](https://github.com/user-attachments/assets/0543d53f-8bc7-4a16-8a4b-e41ef13568c6)\n\n\n## Features\n\n- Convert any video file to GIF format\n- Customize output settings (FPS, dimensions, duration)\n- Extract specific portions of videos\n- High-quality GIF generation with optimized palette\n\n## Installation\n\n```bash\nnpm install\nnpm run build\n```\n\n## Usage\n\nRight now, Claude Desktop does not support video input. I'd recommend using a different client like [Goose](https://block.github.io/goose/) and adding it as an extension.\n\nIn Goose, you can use the Gif Creator tool by going to Advanced Settings > Extension > + Add Custom Extension > and in the command pasting:\n```\nnode /path/to/gif-creator-mcp/dist/index.js\n```\n\nI'd also increase the time out to 1000.\n\n\nFor other MCP clients, you can use the following command to start the server:\n\n```json\n{\n  \"mcpServers\": {\n    \"gif-creator\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/gif-creator-mcp/dist/index.js\"]\n    }\n  }\n}\n```\n\n## Tools\n\n### convert_video_to_gif\n\nConverts a video file to a GIF file, saving it in the same directory as the source video.\n\n**Parameters:**\n- `video_path` (required): Path to the video file to convert\n- `fps` (optional): Frames per second for the GIF (1-30, default: 10)\n- `width` (optional): Width of the output GIF (maintains aspect ratio if height not specified)\n- `height` (optional): Height of the output GIF (maintains aspect ratio if width not specified)\n- `start_time` (optional): Start time in seconds (default: 0)\n- `duration` (optional): Duration in seconds (default: entire video)\n\n## Examples\n\n### Basic conversion\n```json\n{\n  \"video_path\": \"/path/to/video.mp4\"\n}\n```\n\n### Custom settings\n```json\n{\n  \"video_path\": \"/path/to/video.mp4\",\n  \"fps\": 15,\n  \"width\": 480,\n  \"start_time\": 5,\n  \"duration\": 10\n}\n```\n\n### Extract a specific portion\n```json\n{\n  \"video_path\": \"/path/to/long-video.mov\",\n  \"start_time\": 30,\n  \"duration\": 5,\n  \"fps\": 20\n}\n```\n\n## Requirements\n\n- Node.js\n- FFmpeg (automatically installed via @ffmpeg-installer/ffmpeg)\n\n## Notes\n\n- The output GIF is saved in the same directory as the input video\n- The filename is the same as the video file but with a .gif extension\n- Large videos may take some time to process\n- The tool uses optimized palette generation for better quality GIFs\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "multimedia",
        "mcp",
        "gifs",
        "multimedia process",
        "gifs videos",
        "handle multimedia"
      ],
      "category": "multimedia-process"
    },
    "bogdan01m--zapcap-mcp-server": {
      "owner": "bogdan01m",
      "name": "zapcap-mcp-server",
      "url": "https://github.com/bogdan01m/zapcap-mcp-server",
      "imageUrl": "",
      "description": "MCP server for ZapCap API providing video caption and B-roll generation via natural language",
      "stars": 0,
      "forks": 4,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-11T07:55:46Z",
      "readme_content": "# ZapCap MCP Server\n\n[![PyPI version](https://badge.fury.io/py/zapcap-mcp-server.svg)](https://pypi.org/project/zapcap-mcp-server/)\n[![MCP Server](https://img.shields.io/badge/MCP-Server-blue?logo=data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZD0iTTEyIDJMMTMuMDkgOC4yNkwyMCA5TDEzLjA5IDE1Ljc0TDEyIDIyTDEwLjkxIDE1Ljc0TDQgOUwxMC45MSA4LjI2TDEyIDJaIiBmaWxsPSJ3aGl0ZSIvPgo8L3N2Zz4K)](https://modelcontextprotocol.io/)\n[![Author](https://img.shields.io/badge/by-Bogdan%20Minko-purple?style=flat)](https://bogdan01m.github.io/)\n\n[![Trust Score](https://archestra.ai/mcp-catalog/api/badge/quality/bogdan01m/zapcap-mcp-server)](https://archestra.ai/mcp-catalog/bogdan01m__zapcap-mcp-server)\n\n**NOTE**: This is an unofficial implementation of MCP Server for ZapCap.\n\n<a href=\"https://glama.ai/mcp/servers/@bogdan01m/zapcap-mcp-server\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@bogdan01m/zapcap-mcp-server/badge\" alt=\"zapcap-mcp-server MCP server\" />\n</a>\n\nAn MCP (Model Context Protocol) server that provides tools for uploading videos, creating processing tasks, and monitoring their progress through the [ZapCap API](https://zapcap.ai/).\n\n## Requirements\n\n- uv \n- ZapCap API key\n\nYou can install uv from here: https://docs.astral.sh/uv/\n\nYou can get api key from ZapCap API after registation at https://zapcap.ai/ in their platform here: https://platform.zapcap.ai/dashboard/api-key\n\n## Installation in MCP-client\n\nAdd to your MCP client `mcp.json` configuration (e.g., Claude Desktop, Cursor and etc.):\n\n```json\n{\n  \"mcpServers\": {\n    \"zapcap\": {\n      \"command\": \"uvx\",\n      \"args\": [\"zapcap-mcp-server\"],\n      \"env\": {\n        \"ZAPCAP_API_KEY\": \"your_api_key_here\"\n      }\n    }\n  }\n}\n```\n\n## Alternative Installation\n\n```bash\nuv tool install zapcap-mcp-server\n```\n\n## Docker Installation\n\nYou can also run the MCP server in a Docker container using the pre-built image from Docker Hub:\n\n### Using pre-built image from Docker Hub:\n```json\n{\n  \"mcpServers\": {\n    \"zapcap\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\", \n        \"--rm\", \n        \"--init\",\n        \"-i\",\n        \"--net=host\",\n        \"-v\", \"/home/$USER:/host/home/$USER\",\n        \"-e\", \"ZAPCAP_API_KEY=your_api_key_here\",\n        \"bogdan01m/zapcap-mcp-server:latest\"\n      ],\n      \"env\": {\n        \"DOCKER_CLI_HINTS\": \"false\"\n      }\n    }\n  }\n}\n```\n\n## Configuration\n\nSet your ZapCap API key as an environment variable:\n\n```bash\nexport ZAPCAP_API_KEY=\"your_api_key_here\"\n```\n\n## Usage\n\n### Demo Videos\n\n**How to use:**\n\n[<img alt=\"maxresdefault\" src=\"https://img.youtube.com/vi/GcoyTgTVd6Q/maxresdefault.jpg\" width=\"100%\">](https://youtu.be/GcoyTgTVd6Q)\n\n**Results:**\n\n[<img alt=\"maxresdefault\" src=\"https://img.youtube.com/vi/rxqAQZRiyxA/maxresdefault.jpg\" width=\"100%\">](https://youtu.be/rxqAQZRiyxA)\n\n### Available Tools\n\nThe server provides the following tools:\n\n### zapcap_mcp_upload_video\nUpload a video file to ZapCap.\n\n**Parameters:**\n- `file_path`: Path to the video file\n\n### zapcap_mcp_upload_video_by_url\nUpload a video by URL to ZapCap.\n\n**Parameters:**\n- `url`: URL to the video file\n\n### zapcap_mcp_get_templates\nGet available processing templates from ZapCap.\n\n### zapcap_mcp_create_task\nCreate a video processing task with full customization options.\n\n**Parameters:**\n- `video_id`: Video ID from upload\n- `template_id`: Template ID\n- `auto_approve`: Auto approve the task (default: true)\n- `language`: Language code (default: \"en\")\n- `enable_broll`: Enable B-roll (default: false)\n- `broll_percent`: B-roll percentage 0-100 (default: 30)\n\n**Subtitle options:**\n- `emoji`: Enable emoji in subtitles (default: true)\n- `emoji_animation`: Enable emoji animation (default: true)\n- `emphasize_keywords`: Emphasize keywords (default: true)\n- `animation`: Enable subtitle animation (default: true)\n- `punctuation`: Include punctuation (default: true)\n- `display_words`: Number of words to display (default: 1)\n\n**Style options:**\n- `position_top`: Subtitle position from top (default: 60)\n- `font_uppercase`: Use uppercase font (default: true)\n- `font_size`: Font size (default: 30)\n- `font_weight`: Font weight (default: 900)\n- `font_color`: Font color (default: \"#ffffff\")\n- `font_shadow`: Font shadow s/m/l (default: \"l\")\n- `stroke`: Stroke style (default: \"s\")\n- `stroke_color`: Stroke color (default: \"#000000\")\n- `highlight_color_1`: First highlight color (default: \"#2bf82a\")\n- `highlight_color_2`: Second highlight color (default: \"#fdfa14\")\n- `highlight_color_3`: Third highlight color (default: \"#f01916\")\n\n### zapcap_mcp_monitor_task\nMonitor task progress.\n\n**Parameters:**\n- `video_id`: Video ID\n- `task_id`: Task ID\n\n## Benefits Over Direct API Usage\n\n### Token Management\nUnlike using curl or direct API calls where you need to manually include your API key in every request:\n\n```bash\n# Traditional curl approach - token needed every time\ncurl -X POST \"https://api.zapcap.ai/upload\" \\\n  -H \"Authorization: Bearer your_token_here\" \\\n  -F \"file=@video.mp4\"\n```\n\nWith this MCP server, your API key is configured once in the environment and automatically used for all operations:\n\n```json\n{\n  \"env\": {\n    \"ZAPCAP_API_KEY\": \"your_api_key_here\"\n  }\n}\n```\n\n### Natural Language Interface\nInstead of constructing complex API requests with parameters, you can describe what you want:\n\n**Traditional API:** \n```bash\ncurl -X POST \"https://api.zapcap.ai/tasks\" \\\n  -H \"Authorization: Bearer token\" \\\n  -d '{\n    \"video_id\": \"abc123\",\n    \"template_id\": \"viral\",\n    \"font_size\": 30,\n    \"highlight_color_1\": \"#00ff00\",\n    \"enable_broll\": true,\n    \"broll_percent\": 40\n  }'\n```\n\n**MCP Server:**\n```\n\"Add green highlighted subtitles with 40% B-roll using viral template\"\n```\n\n### Type Safety & Validation\n- **Pydantic Integration**: All parameters are validated automatically with type checking\n\n## Future Plans\n\n### Testing Integration\nWe're planning to add basic testing capabilities:\n\n- **API Integration Tests**: Verify that ZapCap API calls work correctly\n- **MCP Tool Tests**: Ensure all MCP tools respond properly to requests\n\n### Planned Features\n- **Named configurations**: Save frequently used parameter combinations (\"my_brand\", \"youtube_style\")\n- **Template enhancement**: Override template defaults with consistent brand colors/fonts\n\n## License\n\nMIT licence",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "multimedia",
        "zapcap",
        "playback",
        "multimedia process",
        "handle multimedia",
        "zapcap mcp"
      ],
      "category": "multimedia-process"
    },
    "stass--exif-mcp": {
      "owner": "stass",
      "name": "exif-mcp",
      "url": "https://github.com/stass/exif-mcp",
      "imageUrl": "",
      "description": "A MCP server that allows one to examine image metadata like EXIF, XMP, JFIF and GPS. This provides foundation for LLM-powered search and analysis of photo librares and image collections.",
      "stars": 19,
      "forks": 5,
      "license": "BSD 2-Clause \"Simplified\" License",
      "language": "TypeScript",
      "updated_at": "2025-09-23T19:41:13Z",
      "readme_content": "# exif-mcp\n\nAn MCP server that allows LLMs (or humans) to read image metadata on-demand, entirely offline. Based on the excellent exifr library it's exremely fast and does not rely on any external tools.\n\nUsecases:\n* Analyze image metadata and visualize it\n* Perform analysis of your image library: what are my most used cameras?  Lens distribution?  Which dates of the week I take most pictures on?  Most favorite locations?\n* Debugging image manipulation code.\n\nThs tool is used extensively by the reverse geolocation service [PlaceSpotter](https://www.placespotter.com/) for development and testing.\n\n## Overview\n\n`exif-mcp` is a Model Context Protocol (MCP) server that provides tools for extracting various metadata segments from images. Built with TypeScript, it leverages the excellent [exifr](https://github.com/MikeKovarik/exifr) library to parse metadata from images in common formats like JPEG, PNG, TIFF, and HEIC.  This allows this service to parse image metadata without executing any external tools which allows it to be both highly efficient and secure.\n\n### Features\n\n- **Local operation**: Works completely offline with no remote network required\n- **Multiple segments**: Extracts EXIF, GPS, XMP, ICC, IPTC, JFIF, and IHDR metadata\n- **Various input formats**: Supports JPEG, TIFF, HEIC/AVIF, and PNG\n- **Flexible image sources**: Read from file system, URLs, base64 data, or buffers\n- **Specialized tools**: Get orientation, rotation info, GPS coordinates, and thumbnails\n\n## Installation\n\n```csh\n# Clone the repository\ngit clone https://github.com/stass/exif-mcp.git\ncd exif-mcp\n\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n```\n\n## Usage\n### Claude Desktop\n\nPut this into Claude config file (claude_desktop_config.json):\n```json\n\"mcpServers\": {\n    \"exif-mcp\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/path/to/exif-mcp/dist/server.js\"\n      ]\n    }\n  },\n```\n\nRestart Claude.  Now you can ask Claude to inspect images for you or e.g. find files taken with specific camera.  This works best in combination with filesystem MCP tools so Claude can find files and list directories.\n\n### Starting the server\n\n```csh\n# Start the server\nnpm start\n\n# For development with auto-reload\nnpm run dev\n```\n\nThe server uses the `StdioServerTransport` from the MCP SDK, making it compatible with any MCP client that supports STDIO transport.\n\nYou can use mcp-proxy to enable remote access.\n\n### Available Tools\n\nThe following tools are provided by the server:\n\n| Tool name | Description |\n|-----------|-------------|\n| `read-metadata` | Reads all or specified metadata segments |\n| `read-exif` | Reads EXIF data specifically |\n| `read-xmp` | Reads XMP data |\n| `read-icc` | Reads ICC color profile data |\n| `read-iptc` | Reads IPTC metadata |\n| `read-jfif` | Reads JFIF segment data |\n| `read-ihdr` | Reads IHDR segment data |\n| `orientation` | Gets image orientation (1-8) |\n| `rotation-info` | Gets rotation and flip information |\n| `gps-coordinates` | Extracts GPS coordinates |\n| `thumbnail` | Extracts embedded thumbnail |\n\n### Debugging with MCP Inspector\n\n1. Start the inspector: `npx @modelcontextprotocol/inspector node dist/server.js`\n2. Connect to it with MCP Inspector using the STDIO transport\n3. Call a tool, e.g., `read-metadata` with parameter:\n   ```json\n   {\n     \"image\": {\n       \"kind\": \"path\",\n       \"path\": \"/path/to/image.jpg\"\n     }\n   }\n   ```\n4. You cal also use MCP inspector command line like this: `npx @modelcontextprotocol/inspector --cli node dist/server.js --method tools/call --tool-name read-exif --tool-arg image='{\"kind\": \"path\", \"path\": \"/path/to/image.jpeg\"}' --tool-arg pick=\"[]\"`\n\n### Image Source Types\n\nThe server supports multiple ways to provide image data:\n\n```typescript\n// From local file system\n{\n  \"kind\": \"path\",\n  \"path\": \"/path/to/image.jpg\"\n}\n\n// From URL (http, https, or file://)\n{\n  \"kind\": \"url\",\n  \"url\": \"https://example.com/image.jpg\"\n}\n\n// From base64 data (raw or data URI)\n{\n  \"kind\": \"base64\",\n  \"data\": \"data:image/jpeg;base64,/9j/4AAQSkZ...\"\n}\n\n// From base64 buffer\n{\n  \"kind\": \"buffer\",\n  \"buffer\": \"/9j/4AAQSkZ...\"\n}\n```\n\n## Development\n\n### Running Tests\n\n```bash\n# Run tests\nnpm test\n\n# Run tests with watch mode\nnpm run test:watch\n```\n\n### Project Structure\n\n```\nexif-mcp/\n├── src/\n│   ├── server.ts         # Main entry point\n│   ├── tools/\n│   │   ├── index.ts      # Tool registration\n│   │   ├── loaders.ts    # Image loading utilities\n│   │   └── segments.ts   # exifr options builders\n│   └── types/\n│       └── image.ts      # Type definitions\n├── tests/                # Test files\n└── README.md\n```\n\n## Error Handling\n\nThe server provides standardized error handling for common issues:\n\n- Unsupported formats or missing metadata\n- Network fetch failures\n- Oversized payloads\n- Internal exifr errors\n\n## License\n\nBSD 2-clause\n\n## Acknowledgements\n\n- [exifr](https://github.com/MikeKovarik/exifr) - Extremely fast and robust EXIF parsing library\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "multimedia",
        "exif",
        "mcp",
        "exif mcp",
        "multimedia process",
        "handle multimedia"
      ],
      "category": "multimedia-process"
    },
    "sunriseapps--imagesorcery-mcp": {
      "owner": "sunriseapps",
      "name": "imagesorcery-mcp",
      "url": "https://github.com/sunriseapps/imagesorcery-mcp",
      "imageUrl": "",
      "description": "ComputerVision-based 🪄 sorcery of image recognition and editing tools for AI assistants.",
      "stars": 206,
      "forks": 25,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-03T20:49:49Z",
      "readme_content": "# 🪄 ImageSorcery MCP\n**ComputerVision-based 🪄 sorcery of local image recognition and editing tools for AI assistants**\n\nOfficial website: [imagesorcery.net](https://imagesorcery.net?utm_source=readme)\n\n[![License](https://img.shields.io/badge/License-MIT-green)](https://opensource.org/licenses/MIT) [![MCP](https://img.shields.io/badge/Protocol-MCP-lightgrey)](https://github.com/microsoft/mcp)\n[![Claude](https://img.shields.io/badge/Works_with-Claude-orange)](https://claude.ai) [![Cursor](https://img.shields.io/badge/Works_with-Cursor-white)](https://cursor.so) [![Cline](https://img.shields.io/badge/Works_with-Cline-purple)](https://github.com/ClineLabs/cline)\n[![Verified on MseeP](https://mseep.ai/badge.svg)](https://mseep.ai/app/2620351a-15b1-4840-a93a-cbdbd23a6944) [![PyPI Downloads](https://static.pepy.tech/badge/imagesorcery-mcp)](https://pepy.tech/projects/imagesorcery-mcp)\n\n<a href=\"https://glama.ai/mcp/servers/@sunriseapps/imagesorcery-mcp\">\n  <img alt=\"badge\" width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@sunriseapps/imagesorcery-mcp/badge\" />\n</a>\n\n## ✅ With ImageSorcery MCP\n\n`🪄 ImageSorcery` empowers AI assistants with powerful image processing capabilities:\n\n- ✅ Crop, resize, and rotate images with precision\n- ✅ Remove background\n- ✅ Draw text and shapes on images\n- ✅ Add logos and watermarks\n- ✅ Detect objects using state-of-the-art models\n- ✅ Extract text from images with OCR\n- ✅ Use a wide range of pre-trained models for object detection, OCR, and more\n- ✅ Do all of this **locally**, without sending your images to any servers\n\nJust ask your AI to help with image tasks:\n\n> \"copy photos with pets from folder `photos` to folder `pets`\"\n![Copying pets](https://i.imgur.com/wsaDWbf.gif)\n\n> \"Find a cat at the photo.jpg and crop the image in a half in height and width to make the cat be centered\"\n![Centerizing cat](https://i.imgur.com/tD0O3l6.gif)\n😉 _**Hint:** Use full path to your files\"._\n\n> \"Enumerate form fields on this `form.jpg` with `foduucom/web-form-ui-field-detection` model and fill the `form.md` with a list of described fields\"\n![Numerate form fields](https://i.imgur.com/1SNGfaP.gif)\n😉 _**Hint:** Specify the model and the confidence\"._\n\n😉 _**Hint:** Add \"use imagesorcery\" to make sure it will use the proper tool\"._\n\nYour tool will combine multiple tools listed below to achieve your goal.\n\n## 🛠️ Available Tools\n\n| Tool | Description | Example Prompt |\n|------|-------------|----------------|\n| `blur` | Blurs specified rectangular or polygonal areas of an image using OpenCV. Can also invert the provided areas e.g. to blur background. | \"Blur the area from (150, 100) to (250, 200) with a blur strength of 21 in my image 'test_image.png' and save it as 'output.png'\" |\n| `change_color` | Changes the color palette of an image | \"Convert my image 'test_image.png' to sepia and save it as 'output.png'\" |\n| `config` | View and update ImageSorcery MCP configuration settings | \"Show me the current configuration\" or \"Set the default detection confidence to 0.8\" |\n| `crop` | Crops an image using OpenCV's NumPy slicing approach | \"Crop my image 'input.png' from coordinates (10,10) to (200,200) and save it as 'cropped.png'\" |\n| `detect` | Detects objects in an image using models from Ultralytics. Can return segmentation masks (as PNG files) or polygons. | \"Detect objects in my image 'photo.jpg' with a confidence threshold of 0.4\" |\n| `draw_arrows` | Draws arrows on an image using OpenCV | \"Draw a red arrow from (50,50) to (150,100) on my image 'photo.jpg'\" |\n| `draw_circles` | Draws circles on an image using OpenCV | \"Draw a red circle with center (100,100) and radius 50 on my image 'photo.jpg'\" |\n| `draw_lines` | Draws lines on an image using OpenCV | \"Draw a red line from (50,50) to (150,100) on my image 'photo.jpg'\" |\n| `draw_rectangles` | Draws rectangles on an image using OpenCV | \"Draw a red rectangle from (50,50) to (150,100) and a filled blue rectangle from (200,150) to (300,250) on my image 'photo.jpg'\" |\n| `draw_texts` | Draws text on an image using OpenCV | \"Add text 'Hello World' at position (50,50) and 'Copyright 2023' at the bottom right corner of my image 'photo.jpg'\" |\n| `fill` | Fills specified rectangular, polygonal, or mask-based areas of an image with a color and opacity, or makes them transparent. Can also invert the provided areas e.g. to remove background. | \"Fill the area from (150, 100) to (250, 200) with semi-transparent red in my image 'test_image.png'\" |\n| `find` | Finds objects in an image based on a text description. Can return segmentation masks (as PNG files) or polygons. | \"Find all dogs in my image 'photo.jpg' with a confidence threshold of 0.4\" |\n| `get_metainfo` | Gets metadata information about an image file | \"Get metadata information about my image 'photo.jpg'\" |\n| `ocr` | Performs Optical Character Recognition (OCR) on an image using EasyOCR | \"Extract text from my image 'document.jpg' using OCR with English language\" |\n| `overlay` | Overlays one image on top of another, handling transparency | \"Overlay 'logo.png' on top of 'background.jpg' at position (10, 10)\" |\n| `resize` | Resizes an image using OpenCV | \"Resize my image 'photo.jpg' to 800x600 pixels and save it as 'resized_photo.jpg'\" |\n| `rotate` | Rotates an image using imutils.rotate_bound function | \"Rotate my image 'photo.jpg' by 45 degrees and save it as 'rotated_photo.jpg'\" |\n\n😉 _**Hint:** detailed information and usage instructions for each tool can be found in the tool's `/src/imagesorcery_mcp/tools/README.md`._\n\n## 📚 Available Resources\n\n| Resource URI | Description | Example Prompt |\n|--------------|-------------|----------------|\n| `models://list` | Lists all available models in the models directory | \"Which models are available in ImageSorcery?\" |\n\n😉 _**Hint:** detailed information and usage instructions for each resource can be found in the resource's `/src/imagesorcery_mcp/resources/README.md`._\n\n## 💬 Available Prompts\n\n| Prompt Name | Description | Example Usage |\n|-------------|-------------|---------------|\n| `remove-background` | Guides the AI through a comprehensive background removal workflow using object detection and masking tools | \"Use the remove-background prompt to remove the background from my photo 'portrait.jpg', keeping only the person\" |\n\n😉 _**Hint:** detailed information and usage instructions for each prompt can be found in the prompt's `/src/imagesorcery_mcp/prompts/README.md`._\n\n## 🚀 Getting Started\n\n### Requirements\n\n- `Python 3.10` or higher\n- `pipx` (recommended) - for easy installation and virtual environment management\n- `ffmpeg`, `libsm6`, `libxext6`, `libgl1-mesa-glx` - system libraries required by OpenCV\n- `Claude.app`, `Cline`, or another MCP client\n\n<details>\n<summary>Virtual environments (e.g. Docker)</summary>\n\nThese dependencies are typically included with OpenCV installation and don't require separate installation. But they might be missing in some virtual environments like Docker.\n\n**For Ubuntu/Debian systems:**\n```bash\nsudo apt-get update && sudo apt-get install -y ffmpeg libsm6 libxext6 libgl1-mesa-glx\n```\n\n**For Docker containers:**\nAdd this line to your Dockerfile:\n```dockerfile\nRUN apt-get update && apt-get install -y ffmpeg libsm6 libxext6 libgl1-mesa-glx\n```\n</details>\n\n### Installation\n\n![ImageSorcery Demo](https://i.imgur.com/pRfTlHV.gif)\n<details>\n<summary>For Cline just copy-paste LLM-INSTALL.md</summary>\n\n```md\n1.  Load MCP documentation if you have the tool for it. It will give you path to *MCP-configuration file* and other needed instructions.\n2.  Run command `pipx install imagesorcery-mcp`\n3.  Run command `imagesorcery-mcp --post-install`\n4.  Create or modify *MCP-configuration file*.\n5.  Add the `imagesorcery-mcp` server configuration to the `mcpServers` object in the *MCP-configuration file*\n    `\"imagesorcery-mcp\": {\"command\": \"imagesorcery-mcp\",\"timeout\": 100}`\n6.  Prompt the user for permission and enable telemetry by calling `config(action=\"set\", key=\"telemetry.enabled\", value=True, persist=True)`.\n7.  Attempt completion, indicating that the installation and configuration are complete.\n```\n</details>\n\n#### Method 1: Using pipx (Recommended)\n\n`pipx` is the recommended way to install ImageSorcery MCP as it automatically handles virtual environment creation and management, making the installation process much simpler.\n\n<details>\n<summary>0.  Install pipx (if not already installed):</summary>\n\n0.  **Install pipx (if not already installed):**\n    ```bash\n    # On macOS with Homebrew:\n    brew install pipx\n\n    # On Ubuntu/Debian:\n    sudo apt update && sudo apt install pipx\n\n    # On other systems with pip:\n    pip install --user pipx\n    pipx ensurepath\n    ```\n</details>\n\n1.  **Install ImageSorcery MCP with pipx:**\n    ```bash\n    pipx install imagesorcery-mcp\n    ```\n\n2.  **Run the post-installation script:**\n    This step is crucial. It downloads the required models and attempts to install the `clip` Python package from GitHub.\n    ```bash\n    imagesorcery-mcp --post-install\n    ```\n\n#### Method 2: Manual Virtual Environment (Plan B)\n\n<details>\n<summary>If pipx doesn't work for your system, you can manually create a virtual environment</summary>\n\nFor reliable installation of all components, especially the `clip` package (installed via the post-install script), it is **strongly recommended to use Python's built-in `venv` module instead of `uv venv`**.\n\n1.  **Create and activate a virtual environment:**\n    ```bash\n    python -m venv imagesorcery-mcp\n    source imagesorcery-mcp/bin/activate  # For Linux/macOS\n    # source imagesorcery-mcp\\Scripts\\activate    # For Windows\n    ```\n\n2.  **Install the package into the activated virtual environment:**\n    You can use `pip` or `uv pip`.\n    ```bash\n    pip install imagesorcery-mcp\n    # OR, if you prefer using uv for installation into the venv:\n    # uv pip install imagesorcery-mcp\n    ```\n\n3.  **Run the post-installation script:**\n    This step is crucial. It downloads the required models and attempts to install the `clip` Python package from GitHub into the active virtual environment.\n    ```bash\n    imagesorcery-mcp --post-install\n    ```\n\n**Note:** When using this method, you'll need to provide the full path to the executable in your MCP client configuration (e.g., `/full/path/to/venv/bin/imagesorcery-mcp`).\n</details>\n\n\n#### Additional Notes\n<details>\n<summary>What does the post-installation script do?</summary>\nThe `imagesorcery-mcp --post-install` script performs the following actions:\n\n- **Creates a `config.toml` configuration file** in the current directory, allowing users to customize default tool parameters.\n- Creates a `models` directory (usually within the site-packages directory of your virtual environment, or a user-specific location if installed globally) to store pre-trained models.\n- Generates an initial `models/model_descriptions.json` file there.\n- Downloads default YOLO models (`yoloe-11l-seg-pf.pt`, `yoloe-11s-seg-pf.pt`, `yoloe-11l-seg.pt`, `yoloe-11s-seg.pt`) required by the `detect` tool into this `models` directory.\n- **Attempts to install the `clip` Python package** from Ultralytics' GitHub repository directly into the active Python environment. This is required for text prompt functionality in the `find` tool.\n- Downloads the CLIP model file required by the `find` tool into the `models` directory.\n\nYou can run this process anytime to restore the default models and attempt `clip` installation.\n</details>\n\n<details>\n<summary>Important Notes for `uv` users (<code>uv venv</code> and <code>uvx</code>)</summary>\n\n-   **Using `uv venv` to create virtual environments:**\n    Based on testing, virtual environments created with `uv venv` may not include `pip` in a way that allows the `imagesorcery-mcp --post-install` script to automatically install the `clip` package from GitHub (it might result in a \"No module named pip\" error during the `clip` installation step).\n    **If you choose to use `uv venv`:**\n    1.  Create and activate your `uv venv`.\n    2.  Install `imagesorcery-mcp`: `uv pip install imagesorcery-mcp`.\n    3.  Manually install the `clip` package into your active `uv venv`:\n        ```bash\n        uv pip install git+https://github.com/ultralytics/CLIP.git\n        ```\n    3.  Run `imagesorcery-mcp --post-install`. This will download models but may fail to install the `clip` Python package.\n    For a smoother automated `clip` installation via the post-install script, using `python -m venv` (as described in step 1 above) is the recommended method for creating the virtual environment.\n\n-   **Using `uvx imagesorcery-mcp --post-install`:**\n    Running the post-installation script directly with `uvx` (e.g., `uvx imagesorcery-mcp --post-install`) will likely fail to install the `clip` Python package. This is because the temporary environment created by `uvx` typically does not have `pip` available in a way the script can use. Models will be downloaded, but the `clip` package won't be installed by this command.\n    If you intend to use `uvx` to run the main `imagesorcery-mcp` server and require `clip` functionality, you'll need to ensure the `clip` package is installed in an accessible Python environment that `uvx` can find, or consider installing `imagesorcery-mcp` into a persistent environment created with `python -m venv`.\n</details>\n\n## ⚙️ Configure MCP client\n\nAdd to your MCP client these settings.\n\n**For pipx installation (recommended):**\n```json\n\"mcpServers\": {\n    \"imagesorcery-mcp\": {\n      \"command\": \"imagesorcery-mcp\",\n      \"transportType\": \"stdio\",\n      \"autoApprove\": [\"blur\", \"change_color\", \"config\", \"crop\", \"detect\", \"draw_arrows\", \"draw_circles\", \"draw_lines\", \"draw_rectangles\", \"draw_texts\", \"fill\", \"find\", \"get_metainfo\", \"ocr\", \"overlay\", \"resize\", \"rotate\"],\n      \"timeout\": 100\n    }\n}\n```\n\n**For manual venv installation:**\n```json\n\"mcpServers\": {\n    \"imagesorcery-mcp\": {\n      \"command\": \"/full/path/to/venv/bin/imagesorcery-mcp\",\n      \"transportType\": \"stdio\",\n      \"autoApprove\": [\"blur\", \"change_color\", \"config\", \"crop\", \"detect\", \"draw_arrows\", \"draw_circles\", \"draw_lines\", \"draw_rectangles\", \"draw_texts\", \"fill\", \"find\", \"get_metainfo\", \"ocr\", \"overlay\", \"resize\", \"rotate\"],\n      \"timeout\": 100\n    }\n}\n```\n<details>\n<summary>If you're using the server in HTTP mode, configure your client to connect to the HTTP endpoint:</summary>\n\n```json\n\"mcpServers\": {\n    \"imagesorcery-mcp\": {\n      \"url\": \"http://127.0.0.1:8000/mcp\", // Use your custom host, port, and path if specified\n      \"transportType\": \"http\",\n      \"autoApprove\": [\"blur\", \"change_color\", \"config\", \"crop\", \"detect\", \"draw_arrows\", \"draw_circles\", \"draw_lines\", \"draw_rectangles\", \"draw_texts\", \"fill\", \"find\", \"get_metainfo\", \"ocr\", \"overlay\", \"resize\", \"rotate\"],\n      \"timeout\": 100\n    }\n}\n```\n</details>\n\n<details>\n<summary>For Windows</summary>\n\n**For pipx installation (recommended):**\n```json\n\"mcpServers\": {\n    \"imagesorcery-mcp\": {\n      \"command\": \"imagesorcery-mcp.exe\",\n      \"transportType\": \"stdio\",\n      \"autoApprove\": [\"blur\", \"change_color\", \"config\", \"crop\", \"detect\", \"draw_arrows\", \"draw_circles\", \"draw_lines\", \"draw_rectangles\", \"draw_texts\", \"fill\", \"find\", \"get_metainfo\", \"ocr\", \"overlay\", \"resize\", \"rotate\"],\n      \"timeout\": 100\n    }\n}\n```\n\n**For manual venv installation:**\n```json\n\"mcpServers\": {\n    \"imagesorcery-mcp\": {\n      \"command\": \"C:\\\\full\\\\path\\\\to\\\\venv\\\\Scripts\\\\imagesorcery-mcp.exe\",\n      \"transportType\": \"stdio\",\n      \"autoApprove\": [\"blur\", \"change_color\", \"config\", \"crop\", \"detect\", \"draw_arrows\", \"draw_circles\", \"draw_lines\", \"draw_rectangles\", \"draw_texts\", \"fill\", \"find\", \"get_metainfo\", \"ocr\", \"overlay\", \"resize\", \"rotate\"],\n      \"timeout\": 100\n    }\n}\n```\n</details>\n\n## 📦 Additional Models\n\nSome tools require specific models to be available in the `models` directory:\n\n```bash\n# Download models for the detect tool\ndownload-yolo-models --ultralytics yoloe-11l-seg\ndownload-yolo-models --huggingface ultralytics/yolov8:yolov8m.pt\n```\n\n<details>\n<summary>About Model Descriptions</summary>\n\nWhen downloading models, the script automatically updates the `models/model_descriptions.json` file:\n\n- For Ultralytics models: Descriptions are predefined in `src/imagesorcery_mcp/scripts/create_model_descriptions.py` and include detailed information about each model's purpose, size, and characteristics.\n\n- For Hugging Face models: Descriptions are automatically extracted from the model card on Hugging Face Hub. The script attempts to use the model name from the model index or the first line of the description.\n\nAfter downloading models, it's recommended to check the descriptions in `models/model_descriptions.json` and adjust them if needed to provide more accurate or detailed information about the models' capabilities and use cases.\n</details>\n\n### Running the Server\n\nImageSorcery MCP server can be run in different modes:\n- `STDIO` - default\n- `Streamable HTTP` - for web-based deployments\n- `Server-Sent Events (SSE)` - for web-based deployments that rely on SSE\n\n<details>\n<summary>About different modes:</summary>\n\n1. **STDIO Mode (Default)** - This is the standard mode for local MCP clients:\n   ```bash\n   imagesorcery-mcp\n   ```\n\n2. **Streamable HTTP Mode** - For web-based deployments:\n   ```bash\n   imagesorcery-mcp --transport=streamable-http\n   ```\n   \n   With custom host, port, and path:\n   ```bash\n   imagesorcery-mcp --transport=streamable-http --host=0.0.0.0 --port=4200 --path=/custom-path\n   ```\n\nAvailable transport options:\n- `--transport`: Choose between \"stdio\" (default), \"streamable-http\", or \"sse\"\n- `--host`: Specify host for HTTP-based transports (default: 127.0.0.1)\n- `--port`: Specify port for HTTP-based transports (default: 8000)\n- `--path`: Specify endpoint path for HTTP-based transports (default: /mcp)\n</details>\n\n## 🔒 Privacy & Telemetry\n\nWe are committed to your privacy. ImageSorcery MCP is designed to run locally, ensuring your images and data stay on your machine.\n\nTo help us understand which features are most popular and fix bugs faster, we've included optional, anonymous telemetry.\n\n-   **It is disabled by default.** You must explicitly opt-in to enable it.\n-   **What we collect:** Anonymized usage data, including features used (e.g., `crop`, `detect`), application version, operating system type (e.g., 'linux', 'win32'), and tool failures.\n-   **What we NEVER collect:** We do not collect any personal or sensitive information. This includes image data, file paths, IP addresses, or any other personally identifiable information.\n-   **How to enable/disable:** You can control telemetry by setting `enabled = true` or `enabled = false` in the `[telemetry]` section of your `config.toml` file.\n\n## ⚙️ Configuring the Server\n\nThe server can be configured using a `config.toml` file in the current directory. The file is created automatically during installation with default values. You can customize the default tool parameters in this file. More in [CONFIG.md](CONFIG.md).\n\n## 🤝 Contributing\n<details>\n<summary>Whether you're a 👤 human or an 🤖 AI agent, we welcome your contributions to this project!</summary>\n\n### Directory Structure\n\nThis repository is organized as follows:\n\n```\n.\n├── .gitignore                 # Specifies intentionally untracked files that Git should ignore.\n├── pyproject.toml             # Configuration file for Python projects, including build system, dependencies, and tool settings.\n├── pytest.ini                 # Configuration file for the pytest testing framework.\n├── README.md                  # The main documentation file for the project.\n├── setup.sh                   # A shell script for quick setup (legacy, for reference or local use).\n├── models/                    # This directory stores pre-trained models used by tools like `detect` and `find`. It is typically ignored by Git due to the large file sizes.\n│   ├── model_descriptions.json  # Contains descriptions of the available models.\n│   ├── settings.json            # Contains settings related to model management and training runs.\n│   └── *.pt                     # Pre-trained model.\n├── src/                       # Contains the source code for the 🪄 ImageSorcery MCP server.\n│   └── imagesorcery_mcp/       # The main package directory for the server.\n│       ├── README.md            # High-level overview of the core architecture (server and middleware).\n│       ├── __init__.py          # Makes `imagesorcery_mcp` a Python package.\n│       ├── __main__.py          # Entry point for running the package as a script.\n│       ├── logging_config.py    # Configures the logging for the server.\n│       ├── server.py            # The main server file, responsible for initializing FastMCP and registering tools.\n│       ├── middleware.py        # Custom middleware for improved validation error handling.\n│       ├── logs/                # Directory for storing server logs.\n│       ├── scripts/             # Contains utility scripts for model management.\n│       │   ├── README.md        # Documentation for the scripts.\n│       │   ├── __init__.py      # Makes `scripts` a Python package.\n│       │   ├── create_model_descriptions.py # Script to generate model descriptions.\n│       │   ├── download_clip.py # Script to download CLIP models.\n│       │   ├── post_install.py  # Script to run post-installation tasks.\n│       │   └── download_models.py # Script to download other models (e.g., YOLO).\n│       ├── tools/               # Contains the implementation of individual MCP tools.\n│       │   ├── README.md        # Documentation for the tools.\n│       │   ├── __init__.py      # Makes `tools` a Python package.\n│       │   └── *.py           # Implements the tool.\n│       ├── prompts/             # Contains the implementation of individual MCP prompts.\n│       │   ├── README.md        # Documentation for the prompts.\n│       │   ├── __init__.py      # Makes `prompts` a Python package.\n│       │   └── *.py           # Implements the prompt.\n│       └── resources/           # Contains the implementation of individual MCP resources.\n│           ├── README.md        # Documentation for the resources.\n│           ├── __init__.py      # Makes `resources` a Python package.\n│           └── *.py           # Implements the resource.\n└── tests/                     # Contains test files for the project.\n    ├── test_server.py         # Tests for the main server functionality.\n    ├── data/                  # Contains test data, likely image files used in tests.\n    ├── tools/                 # Contains tests for individual tools.\n    ├── prompts/               # Contains tests for individual prompts.\n    └── resources/             # Contains tests for individual resources.\n```\n\n### Development Setup\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/sunriseapps/imagesorcery-mcp.git # Or your fork\ncd imagesorcery-mcp\n```\n\n2. (Recommended) Create and activate a virtual environment:\n```bash\npython -m venv venv\nsource venv/bin/activate # For Linux/macOS\n# venv\\Scripts\\activate    # For Windows\n```\n\n3. Install the package in editable mode along with development dependencies:\n```bash\npip install -e \".[dev]\"\n```\nThis will install `imagesorcery-mcp` and all dependencies from `[project.dependencies]` and `[project.optional-dependencies].dev` (including `build` and `twine`).\n\n### Rules\n\nThese rules apply to all contributors: humans and AI.\n\n0. Read all the `README.md` files in the project. Understand the project structure and purpose. Understand the guidelines for contributing. Think through how it relates to your task, and how to make changes accordingly.\n1. Read `pyproject.toml`.\nPay attention to sections: `[tool.ruff]`, `[tool.ruff.lint]`, `[project.optional-dependencies]` and `[project]dependencies`.\nStrictly follow code style defined in `pyproject.toml`.\nStick to the stack defined in `pyproject.toml` dependencies and do not add any new dependencies without a good reason.\n2. Write your code in new and existing files.\nIf new dependencies are needed, update `pyproject.toml` and install them via `pip install -e .` or `pip install -e \".[dev]\"`. Do not install them directly via `pip install`.\nCheck out existing source codes for examples (e.g. `src/imagesorcery_mcp/server.py`, `src/imagesorcery_mcp/tools/crop.py`). Stick to the code style, naming conventions, input and output data formats, code structure, architecture, etc. of the existing code.\n3. Update related `README.md` files with your changes.\nStick to the format and structure of the existing `README.md` files.\n4. Write tests for your code.\nCheck out existing tests for examples (e.g. `tests/test_server.py`, `tests/tools/test_crop.py`).\nStick to the code style, naming conventions, input and output data formats, code structure, architecture, etc. of the existing tests.\n\n5. Run tests and linter to ensure everything works:\n```bash\npytest\nruff check .\n```\nIn case of failures - fix the code and tests. It is **strictly required** to have all new code to comply with the linter rules and pass all tests.\n\n\n### Coding hints\n- Use type hints where appropriate\n- Use pydantic for data validation and serialization\n</details>\n\n## 📝 Questions?\n\nIf you have any questions, issues, or suggestions regarding this project, feel free to reach out to:\n\n- Project Author: [titulus](https://www.linkedin.com/in/titulus/) via LinkedIn\n- Sunrise Apps CEO: [Vlad Karm](https://www.linkedin.com/in/vladkarm/) via LinkedIn\n\nYou can also open an issue in the repository for bug reports or feature requests.\n\n## 📜 License\n\nThis project is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "multimedia",
        "computervision",
        "imagesorcery",
        "multimedia process",
        "handle multimedia",
        "video editing"
      ],
      "category": "multimedia-process"
    },
    "video-creator--ffmpeg-mcp": {
      "owner": "video-creator",
      "name": "ffmpeg-mcp",
      "url": "https://github.com/video-creator/ffmpeg-mcp.git",
      "imageUrl": "",
      "description": "Using ffmpeg command line to achieve an mcp server, can be very convenient, through the dialogue to achieve the local video search, tailoring, stitching, playback and other functions",
      "stars": 84,
      "forks": 14,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-04T04:24:05Z",
      "readme_content": "# FFmpeg-MCP\nUsing ffmpeg command line to achieve an mcp server, can be very convenient, through the dialogue to achieve the local video search, tailoring, stitching, playback and other functions\n\n<a href=\"https://glama.ai/mcp/servers/@video-creator/ffmpeg-mcp\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@video-creator/ffmpeg-mcp/badge\" alt=\"FFmpeg-Server MCP server\" />\n</a>\n\n## Support Tools\nThe server implements the following tools: <br/>\n- `find_video_path`\n  The parameters are directory and file name, file name can be complete, or is not suffixed, recursive search in the directory, return the full path\n- `get_video_info`\n  The parameters are video path, return the video info, linkes duration/fps/codec/width/height.\n- `clip_video`\n  The parameter is the file path, start time, end time or duration, and returns the trimmed file path\n- `concat_videos`\n  The parameters are the list of files, the output path, and if the video elements in the list of files, such as width, height, frame rate, etc., are consistent, quick mode synthesis is automatically used\n- `play_video`\n  Play video/audio with ffplay, support many format, like mov/mp4/avi/mkv/3gp, video_path: video path speed: play rate loop: play count\n- `overlay_video`\n  Two video overlay. <br/>\n  background_video: backgroud video path <br/>\n  overlay_video: front video path <br/>\n  output_path: output video path<br/>\n  position: relative location<br/>\n  dx: x offset<br/>\n  dy: y offset<br/>\n- `scale_video`\n  Video scale. <br/>\n  video_path: in video path <br/>\n  width: out video width, -2 keep aspect <br/>\n  height: out video height, -2 keep aspect <br/>\n  output_path: output video path <br/>\n- `extract_frames_from_video`\n  Extract images from a video.<br/>\n  Parameters: <br/>\n  video_path (str): The path to the video.<br/>\n  fps (int): Extract one frame every specified number of seconds. If set to 0, extract all frames; if set to 1, extract one frame per second.<br/>\n  output_folder (str): The directory where the images will be saved.<br/>\n  format (int): The format of the extracted images; 0: PNG, 1: JPG, 2: WEBP.<br/>\n  total_frames (int): The maximum number of frames to extract. If set to 0, there is no limit<br/>\n<br/>\nMore features are coming\n\n## Installation procedure\n1. Download project\n```\ngit clone  https://github.com/video-creator/ffmpeg-mcp.git\ncd ffmpeg-mcp\nuv sync\n```\n\n2. Configuration in Cline\n```\n{\n  \"mcpServers\": {\n    \"ffmpeg-mcp\": {\n      \"autoApprove\": [],\n      \"disabled\": false,\n      \"timeout\": 60,\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/Users/xxx/Downloads/ffmpeg-mcp\",\n        \"run\",\n        \"ffmpeg-mcp\"\n      ],\n      \"transportType\": \"stdio\"\n    }\n  }\n}\n```\nNote: the value:`/Users/XXX/Downloads/ffmpeg` in args  need to replace the actual download ffmpeg-mcp directory\n\n## Supported platforms\nCurrently, only macos platforms are supported, including ARM64 or x86_64",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "multimedia",
        "ffmpeg",
        "mcp",
        "multimedia process",
        "ffmpeg mcp",
        "handle multimedia"
      ],
      "category": "multimedia-process"
    }
  }
}