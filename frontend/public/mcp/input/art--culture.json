{
  "category": "art--culture",
  "categoryDisplay": "Art & Culture",
  "description": "Access and explore art collections, cultural heritage, and museum databases. Enables AI models to search and analyze artistic and cultural content.",
  "totalRepositories": 17,
  "repositories": {
    "OctoEverywhere--mcp": {
      "owner": "OctoEverywhere",
      "name": "mcp",
      "url": "https://github.com/OctoEverywhere/mcp",
      "imageUrl": "",
      "description": "A 3D printer MCP server that allows for getting live printer state, webcam snapshots, and printer control.",
      "stars": 16,
      "forks": 2,
      "license": "Apache License 2.0",
      "language": "",
      "updated_at": "2025-10-03T06:03:39Z",
      "readme_content": "<p align=\"center\"><img src=\"https://octoeverywhere.com/img/logo.png\" alt=\"OctoEverywhere's Logo\" style=\"width:100px\" /></p>\n<h1 align=\"center\" style=\"margin-bottom:20px\"><a href=\"https://octoeverywhere.com/mcp?utm_campaign=mcp_repo&utm_content=header&utm_source=github\">MCP For 3D Printing</a></h1>\n\n[A free, private, and secure cloud MCP server for 3D printer access, monitoring, and control.](https://octoeverywhere.com/mcp?utm_campaign=mcp_repo&utm_content=intro&utm_source=github) OctoEverywhere's 3D printing MCP server enables access to your 3D printers via the Model Context Protocol (MCP) for AI chatbots, agents, and workflows. Link your 3D printer to OctoEverywhere, grab your MCP access token, and you're ready to chat!\n\n## Features\n\n- 🚀 Live 3D printer status and print information, including:\n    - Printer state and status information.\n    - Print progress, elapsed time, and estimated time to completion.\n    - [Gadget AI](https://octoeverywhere.com/gadget?utm_campaign=mcp_repo&utm_content=gadget&utm_source=github) print failure detection status.\n    - Hotend, bed, and chamber temperatures.\n    - Print file information, including the file name.\n    - Current layer and total layer information.\n- 📷 Live webcam snapshots\n    - Supports multi-camera setups.\n- ⏸️ Printer control including:\n    - Pausing, resuming, and canceling print jobs.\n- ❤️ Works with any 3D printer, including:\n    - OctoPrint\n    - Klipper\n    - Bambu Lab\n    - Creality\n    - Prusa\n    - AnyCubic\n    - Elegoo\n    - And more\n- 🔒 Secure cloud MCP server:\n    - Accessible from anywhere, in your  home or over the internet.\n    - Easy setup - no local setup required.\n    - Secure and private remote access.\n- 😍 Free for the entire 3D printing community:\n    - [OctoEverywhere](https://octoeverywhere.com/?utm_campaign=mcp_repo&utm_content=community&utm_source=github) builds awesome cloud tools free for the entire community!\n\n\n## Try It Now\n\n1) [Create an OctoEverywhere account](https://octoeverywhere.com/getstarted?utm_campaign=mcp_repo&utm_content=try_it_now&utm_source=github) and link your 3D printer.\n2) [Visit the OctoEverywhere MCP setup page](https://octoeverywhere.com/mcp?utm_campaign=mcp_repo&utm_content=mcp_setup&utm_source=github) to get your Access Token.\n3) Use the OctoEverywhere MCP server URL and Access Token with any AI agent!\n\n## What's OctoEverywhere?\n\nOctoEverywhere cloud empowers your [OctoPrint](https://octoeverywhere.com/?utm_campaign=mcp_repo&utm_content=octoprint&utm_source=github), [Klipper](https://octoeverywhere.com/klipper?utm_campaign=mcp_repo&utm_content=klipper&utm_source=github), [Bambu Lab](https://octoeverywhere.com/bambu?utm_campaign=mcp_repo&utm_content=bambu&utm_source=github), and [Elegoo Centauri](https://octoeverywhere.com/elegoo-centauri?utm_campaign=mcp_repo&utm_content=elegoo&utm_source=github) 3D printers with **free, private, unlimited remote access, AI print failure detection, and more!** OctoEverywhere is developed by the maker community for the maker community.\n\n[Learn More About OctoEverywhere](https://octoeverywhere.com/?utm_campaign=mcp_repo&utm_content=learn_more&utm_source=github)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcp",
        "museum",
        "printer",
        "mcp 3d",
        "printer mcp",
        "mcp server"
      ],
      "category": "art--culture"
    },
    "PatrickPalmer--MayaMCP": {
      "owner": "PatrickPalmer",
      "name": "MayaMCP",
      "url": "https://github.com/PatrickPalmer/MayaMCP",
      "imageUrl": "",
      "description": "MCP server for Autodesk Maya",
      "stars": 26,
      "forks": 10,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-17T20:52:14Z",
      "readme_content": "# Maya MCP\r\nModel Context Protocol (MCP) server implementation for Autodesk Maya\r\n\r\nTested with Maya 2023, 2025.\r\n\r\nv0.2.0\r\n\r\nThis project enables AI assistant clients like Claude Desktop to control Autodesk Maya through natural language using the [Model Context Protocol (MCP)](https://modelcontextprotocol.io/). \r\n\r\nThis is early days for Maya MCP server and has a minimal set of functionality. It's really the architecture design and simplicity that has been the initial focus.\r\n\r\nHere is a list of some of the tools registered with Maya MCP.\r\n\r\n## Basic Tools\r\n\r\n| Tool | Description |\r\n|------|-------------|\r\n| list_objects_by_type | Get a list of objects in the scene. Use filter_by to filter for certain objects such as \"cameras\", \"lights\", \"materials\", or \"shapes\". |\r\n| create_object | Create an object in the Maya scene. Object types available are cube, cone, sphere, cylinder, camera, spotLight, pointLight, directionalLight. |\r\n| get_object_attributes | Get a list of attributes on a Maya object. | \r\n| set_object_attributes | Set an object's attribute with a specific value. |\r\n| scene_new | Create a new scene in Maya. Use the force argument to force a new scene when an existing scene is loaded and has been modified. |\r\n| scene_open | Load in a scene into Maya. | \r\n| scene_save | Save the current scene. If the filename is not specified, it will save it as its current name. |\r\n| select_object | Select an object in the scene. |\r\n\r\n## Advanced Modeling Tools\r\n\r\n| Tool | Description |\r\n|------|-------------|\r\n| create_advanced_model | Create complex 3D models like cars, trees, buildings, cups, and chairs with detailed parameters. |\r\n| mesh_operations | Perform modeling operations such as extrude, bevel, subdivide, boolean, combine, bridge, and split. |\r\n| create_material | Create and assign materials with various types (lambert, phong, wood, marble, chrome, glass, etc.) |\r\n| create_curve | Generate NURBS curves for various shapes (line, circle, spiral, helix, star, gear, etc.) |\r\n| curve_modeling | Create geometry using curve-based modeling techniques (extrude, loft, revolve, sweep, etc.) |\r\n| organize_objects | Organize objects through grouping, parenting, layout, alignment, and distribution. |\r\n| generate_scene | Generate complete 3D scenes with multiple objects (city, forest, living room, office, park) |\r\n\r\n## Installation\r\n\r\nMaya MCP server is designed so there is only an MCP server and doesn't require anything to be installed within Maya. This is helpful since you can easily use different versions of Maya and not have to worry about coordinating version changes. This is done by taking advantage of the default Command Port Maya opens up for MEL scripting. \r\n\r\nMCP requires Python 3.10 or greater. Currently using pip as the package requirements are minimal. To install the virtual environment:\r\n\r\n1. download this project\r\n2. Create a virtual env using Python 3.10+ in the project directory. ```python -m venv .venv```\r\n3. activate the virtual environment\r\n   * Windows: ```.venv\\Scripts\\activate.bat```\r\n   * Mac/Linux: ```source .venv\\bin\\activate.sh```\r\n4. ```pip install -r requirements.txt```\r\n\r\nAs stated, there is nothing to install for Maya.\r\n\r\n### MCP Client Configuration\r\n\r\nDepending on which MCP Client you're using, the configuration file location differs. For [Anthopic Claude Desktop](https://claude.ai/download), go to File -> Settings -> Developer Tab and press the Edit Config button. This will bring up the file finder in the directory location of the JSON config file.\r\n\r\nNext you need to edit the config JSON file by hand using a text editor.  Make sure to use full file paths.\r\n\r\n```\r\n{\r\n  \"mcpServers\": {\r\n    \"MayaMCP\": {\r\n      \"command\": \"[FULL PATH TO MayaMCP PROJECT]/.venv/Scripts/python.exe\",\r\n      \"args\": [\r\n        \"[FULL PATH TO MayaMCP PROJECT]/src/maya_mcp_server.py\"\r\n      ]\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nOnce the changes have been made, restart Claude Desktop (use Exit menu item instead of just closing the window). In the Developers Tab, you will now see the Maya MCP server listed.\r\n\r\nIn Claude Desktop, you can verify the Maya MCP tools are available. Press the  button and a detailed popup will appear.\r\n\r\n\r\n\r\n\r\n### Maya Communications\r\n\r\nWhen the Maya MCP server first attempts to communicate with Maya, you will get this popup within Maya. Please click \"Allow All\" to allow for ongoing communication between the MCP server and Maya. This will need to be done each Maya session.\r\n\r\n\r\n\r\n\r\n## Developer Notes\r\n\r\nThe Maya MCP Server module was designed to be easily modified in a non-intrusive way. This is done by having the Maya Python code reside in the MCP server and sent to Maya's command port for execution. The results are sent back to the server and processed.\r\n\r\nThe default Maya command port runs MEL so the Python code is modified to run within MEL function call to the Python interpreter. There is also some limits such as multi-line Python code can't have any returned results. So, each command creates two connections to Maya. First to run the operation and save the results. The second connection then to read back the results. \r\n\r\nTo help minimize populating the namespace in the Maya global Python interpreter, functions and variables sent to Maya will be scoped to start with _mcp_maya_*. Each of the Maya tools are scoped into a function named _mcp_maya_scope(). The results are assigned to the variable _mcp_maya_results. This way should significantly reduce the possibility of name collisions. \r\n\r\nThere is a bit of elegance to this design. You basically can just add the Python file, restart the MCP Client and Maya MCP server and go. You don't need to integrate the operations on both the Maya MCP server and Maya itself. The code you add is only Maya specific Python and doesn't need to add any MCP decorators. This is a much better design to grow and adapt to different installations instead of having a fixed set of tools.\r\n\r\nThe Maya MCP server was built using the low-level Python MCP module. This was necessary to allow for dynamically defining all of the tools at run time. The tool function signatures are captured dynamically at the start of the server. \r\n\r\n### Adding New Tools\r\n\r\nIt is easy to add new tools to Maya MCP. You don't need to change any of the existing code. All you need to do is add a single tool command Python file to the mayatools/thirdparty directory. The tool itself will run in Maya so it will have access to all of the Maya Python modules. There are a few programmer notes in the design of the tool.\r\n\r\n* The name of the Python file and the function name must be the same. Make sure it is unique.\r\n* The Python function will be loaded by both the server and Maya. Any code outside of the function must be able to be loaded into standalone Python. Meaning any imports such as maya.cmds should be done in the scope of the function. The MCP server loads the function so it can inspect the function signature to send the information to MCP Client via JSON-RPC.\r\n* The function signature will be parsed and must include any types in the function argument annotation.\r\n* When your function is sent to Maya, it will be scoped within am _mcp_maya_scope function. This provides a number of benefits. The functions sent to Maya will not polute the Python global space too much running in Maya. Plus, any exceptions thrown will be caught and returned back to the MCP Client as errors.\r\n* Generally, you want to return either a list or dictionary or throw an exception when there is an error.\r\n* Name your function and arguments appropriately so the LLM can understand the operation. Include a function doc string.\r\n* Default arguments are good. \r\n* Error checking is good so error messages can provide better failed explanations.\r\n\r\nI recommend looking at the existing Maya tools in this project as examples.\r\n\r\n## Testing\r\n\r\nCurrently Maya MCP has only been tested on Windows. Should work on both Linux and Mac as everything is using standard Python.\r\n\r\n## Future Ideas\r\n\r\nIt's early days for MCP and there is a lot to improve. Here are some ideas.\r\n\r\n* Expose more functionality.\r\n* Improve using prompt engineering, particularly describing Maya's usage and data relationships.\r\n* Everything is registered as tools, allow for resources and prompts.\r\n* It could be possible to find any plugins within Maya that has MCP tools. Maybe something like looking at the PYTHONPATH within Maya with any directory named MCP. All of those could be inspected and then provided back to the MCP Client.\r\n\r\n## License\r\n\r\nMIT\r\n\r\n## Links\r\n\r\n* [Model Context Protocol (MCP)](https://modelcontextprotocol.io/)\r\n* [Anthopic Claude Desktop](https://claude.ai/download)\r\n* [MCP Python SDK](https://github.com/modelcontextprotocol/python-sdk)\r\n* [Unreal MCP](https://github.com/chongdashu/unreal-mcp)\r\n\r\n\r\n## Important Note\r\n\r\nThis project was done on my personal time and equipment to learn about MCP. The project is not affiliated with my current employer and does not represent their work or interests.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mayamcp",
        "maya",
        "museum",
        "autodesk maya",
        "explore art",
        "art collections"
      ],
      "category": "art--culture"
    },
    "abhiemj--manim-mcp-server": {
      "owner": "abhiemj",
      "name": "manim-mcp-server",
      "url": "https://github.com/abhiemj/manim-mcp-server",
      "imageUrl": "",
      "description": "A local MCP server that generates animations using Manim.",
      "stars": 478,
      "forks": 51,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-02T22:11:47Z",
      "readme_content": "# Manim MCP Server\n\n\n\n\n## Overview\n\nThis is an MCP (Model Context Protocol) server that executes Manim animation code and returns the generated video. It allows users to send Manim scripts and receive the rendered animation.\n\n## Features\n\n- Executes Manim Python scripts.\n- Saves animation output in a visible media folder.\n- Allows users to clean up temporary files after execution.\n- Portable and configurable via environment variables.\n\n## Installation\n\n### Prerequisites\n\nEnsure you have the following installed:\n\n- Python 3.8+\n- Manim (Community Version)\n- MCP\n\n### Install Manim\n\n```sh\npip install manim\n```\n\n### Install MCP\n\n```sh\npip install mcp\n```\n\n### Clone the Repository\n\n```sh\ngit clone https://github.com/abhiemj/manim-mcp-server.git\ncd manim-mcp-server\n```\n\n## Integration with Claude\n\nTo integrate the Manim MCP server with Claude, add the following to your `claude_desktop_config.json` file:\n\n```json\n{\n  \"mcpServers\": {\n     \"manim-server\": {\n      \"command\": \"/absolute/path/to/python\",\n      \"args\": [\n        \"/absolute/path/to/manim-mcp-server/src/manim_server.py\"\n      ],\n      \"env\": {\n        \"MANIM_EXECUTABLE\": \"/Users/[Your_username]/anaconda3/envs/manim2/Scripts/manim.exe\"\n      }\n    }\n  }\n}\n```\n\n### Finding Your Python Path\n\nTo find your Python executable path, use the following command:\n\n#### Windows (PowerShell):\n```sh\n(Get-Command python).Source\n```\n\n#### Windows (Command Prompt/Terminal):\n```sh\nwhere python\n```\n\n#### Linux/macOS (Terminal):\n```sh\nwhich python\n```\n\nThis ensures that Claude can communicate with the Manim MCP server to generate animations dynamically.\n\n## Contributing\n\n1. Fork the repository.\n2. Create a new branch:\n   ```sh\n   git checkout -b add-feature\n   ```\n3. Make changes and commit:\n   ```sh\n   git commit -m \"Added a new feature\"\n   ```\n4. Push to your fork:\n   ```sh\n   git push origin add-feature\n   ```\n5. Open a pull request.\n\n## License\n\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.\n\n## Author\n\nCreated by **[abhiemj](https://github.com/abhiemj)**. Contributions welcome! 🚀\n\n### **Listed in Awesome MCP Servers**  \nThis repository is featured in the [Awesome MCP Servers](https://github.com/punkpeye/awesome-mcp-servers) repository under the **Animation & Video** category. Check it out along with other great MCP server implementations!\n\n\n## **Acknowledgments**  \n- Thanks to the [Manim Community](https://www.manim.community/) for their amazing animation library.  \n- Inspired by the open-source MCP ecosystem.\n\n## Find me at\n<a href=\"https://www.instagram.com/aiburner_official\" target=\"blank\"><img align=\"center\" src=\"https://raw.githubusercontent.com/rahuldkjain/github-profile-readme-generator/master/src/images/icons/Social/instagram.svg\" alt=\"aiburner_official\" height=\"30\" width=\"40\" /></a>\n@aiburner_official",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "art",
        "artistic",
        "animations",
        "artistic cultural",
        "explore art",
        "art culture"
      ],
      "category": "art--culture"
    },
    "ahujasid--blender-mcp": {
      "owner": "ahujasid",
      "name": "blender-mcp",
      "url": "https://github.com/ahujasid/blender-mcp",
      "imageUrl": "",
      "description": "MCP server for working with Blender",
      "stars": 13688,
      "forks": 1295,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-04T12:37:54Z",
      "readme_content": "# BlenderMCP - Blender Model Context Protocol Integration\n\nBlenderMCP connects Blender to Claude AI through the Model Context Protocol (MCP), allowing Claude to directly interact with and control Blender. This integration enables prompt assisted 3D modeling, scene creation, and manipulation.\n\n**We have no official website. Any website you see online is unofficial and has no affiliation with this project. Use them at your own risk.**\n\n[Full tutorial](https://www.youtube.com/watch?v=lCyQ717DuzQ)\n\n### Join the Community\n\nGive feedback, get inspired, and build on top of the MCP: [Discord](https://discord.gg/z5apgR8TFU)\n\n### Supporters\n\n<div align=\"center\" markdown=\"1\">\n   <sup>Special thanks to:</sup>\n   <br>\n   <br>\n   <a href=\"https://www.warp.dev/blender-mcp\">\n      <img alt=\"Warp sponsorship\" width=\"400\" src=\"https://github.com/user-attachments/assets/c21102f7-bab9-4344-a731-0cf6b341cab2\">\n   </a>\n\n### [Warp, the intelligent terminal for developers](https://www.warp.dev/blender-mcp)\n[Available for MacOS, Linux, & Windows](https://www.warp.dev/blender-mcp)<br>\n\n</div>\n<hr>\n\n**Other supporters:**\n\n[CodeRabbit](https://www.coderabbit.ai/)\n\n[Satish Goda](https://github.com/satishgoda)\n\n**All supporters:**\n\n[Support this project](https://github.com/sponsors/ahujasid)\n\n## Release notes (1.2.0)\n- View screenshots for Blender viewport to better understand the scene\n- Search and download Sketchfab models\n\n\n### Previously added features:\n- Support for Poly Haven assets through their API\n- Support to generate 3D models using Hyper3D Rodin\n- For newcomers, you can go straight to Installation. For existing users, see the points below\n- Download the latest addon.py file and replace the older one, then add it to Blender\n- Delete the MCP server from Claude and add it back again, and you should be good to go!\n\n## Features\n\n- **Two-way communication**: Connect Claude AI to Blender through a socket-based server\n- **Object manipulation**: Create, modify, and delete 3D objects in Blender\n- **Material control**: Apply and modify materials and colors\n- **Scene inspection**: Get detailed information about the current Blender scene\n- **Code execution**: Run arbitrary Python code in Blender from Claude\n\n## Components\n\nThe system consists of two main components:\n\n1. **Blender Addon (`addon.py`)**: A Blender addon that creates a socket server within Blender to receive and execute commands\n2. **MCP Server (`src/blender_mcp/server.py`)**: A Python server that implements the Model Context Protocol and connects to the Blender addon\n\n## Installation\n\n\n### Prerequisites\n\n- Blender 3.0 or newer\n- Python 3.10 or newer\n- uv package manager: \n\n**If you're on Mac, please install uv as**\n```bash\nbrew install uv\n```\n**On Windows**\n```bash\npowershell -c \"irm https://astral.sh/uv/install.ps1 | iex\" \n```\nand then\n```bash\nset Path=C:\\Users\\nntra\\.local\\bin;%Path%\n```\n\nOtherwise installation instructions are on their website: [Install uv](https://docs.astral.sh/uv/getting-started/installation/)\n\n**⚠️ Do not proceed before installing UV**\n\n### Environment Variables\n\nThe following environment variables can be used to configure the Blender connection:\n\n- `BLENDER_HOST`: Host address for Blender socket server (default: \"localhost\")\n- `BLENDER_PORT`: Port number for Blender socket server (default: 9876)\n\nExample:\n```bash\nexport BLENDER_HOST='host.docker.internal'\nexport BLENDER_PORT=9876\n```\n\n### Claude for Desktop Integration\n\n[Watch the setup instruction video](https://www.youtube.com/watch?v=neoK_WMq92g) (Assuming you have already installed uv)\n\nGo to Claude > Settings > Developer > Edit Config > claude_desktop_config.json to include the following:\n\n```json\n{\n    \"mcpServers\": {\n        \"blender\": {\n            \"command\": \"uvx\",\n            \"args\": [\n                \"blender-mcp\"\n            ]\n        }\n    }\n}\n```\n\n### Cursor integration\n\n[![Install MCP Server](https://cursor.com/deeplink/mcp-install-dark.svg)](https://cursor.com/install-mcp?name=blender&config=eyJjb21tYW5kIjoidXZ4IGJsZW5kZXItbWNwIn0%3D)\n\nFor Mac users, go to Settings > MCP and paste the following \n\n- To use as a global server, use \"add new global MCP server\" button and paste\n- To use as a project specific server, create `.cursor/mcp.json` in the root of the project and paste\n\n\n```json\n{\n    \"mcpServers\": {\n        \"blender\": {\n            \"command\": \"uvx\",\n            \"args\": [\n                \"blender-mcp\"\n            ]\n        }\n    }\n}\n```\n\nFor Windows users, go to Settings > MCP > Add Server, add a new server with the following settings:\n\n```json\n{\n    \"mcpServers\": {\n        \"blender\": {\n            \"command\": \"cmd\",\n            \"args\": [\n                \"/c\",\n                \"uvx\",\n                \"blender-mcp\"\n            ]\n        }\n    }\n}\n```\n\n[Cursor setup video](https://www.youtube.com/watch?v=wgWsJshecac)\n\n**⚠️ Only run one instance of the MCP server (either on Cursor or Claude Desktop), not both**\n\n### Visual Studio Code Integration\n\n_Prerequisites_: Make sure you have [Visual Studio Code](https://code.visualstudio.com/) installed before proceeding.\n\n[![Install in VS Code](https://img.shields.io/badge/VS_Code-Install_blender--mcp_server-0098FF?style=flat-square&logo=visualstudiocode&logoColor=ffffff)](vscode:mcp/install?%7B%22name%22%3A%22blender-mcp%22%2C%22type%22%3A%22stdio%22%2C%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22blender-mcp%22%5D%7D)\n\n### Installing the Blender Addon\n\n1. Download the `addon.py` file from this repo\n1. Open Blender\n2. Go to Edit > Preferences > Add-ons\n3. Click \"Install...\" and select the `addon.py` file\n4. Enable the addon by checking the box next to \"Interface: Blender MCP\"\n\n\n## Usage\n\n### Starting the Connection\n\n\n1. In Blender, go to the 3D View sidebar (press N if not visible)\n2. Find the \"BlenderMCP\" tab\n3. Turn on the Poly Haven checkbox if you want assets from their API (optional)\n4. Click \"Connect to Claude\"\n5. Make sure the MCP server is running in your terminal\n\n### Using with Claude\n\nOnce the config file has been set on Claude, and the addon is running on Blender, you will see a hammer icon with tools for the Blender MCP.\n\n\n\n#### Capabilities\n\n- Get scene and object information \n- Create, delete and modify shapes\n- Apply or create materials for objects\n- Execute any Python code in Blender\n- Download the right models, assets and HDRIs through [Poly Haven](https://polyhaven.com/)\n- AI generated 3D models through [Hyper3D Rodin](https://hyper3d.ai/)\n\n\n### Example Commands\n\nHere are some examples of what you can ask Claude to do:\n\n- \"Create a low poly scene in a dungeon, with a dragon guarding a pot of gold\" [Demo](https://www.youtube.com/watch?v=DqgKuLYUv00)\n- \"Create a beach vibe using HDRIs, textures, and models like rocks and vegetation from Poly Haven\" [Demo](https://www.youtube.com/watch?v=I29rn92gkC4)\n- Give a reference image, and create a Blender scene out of it [Demo](https://www.youtube.com/watch?v=FDRb03XPiRo)\n- \"Generate a 3D model of a garden gnome through Hyper3D\"\n- \"Get information about the current scene, and make a threejs sketch from it\" [Demo](https://www.youtube.com/watch?v=jxbNI5L7AH8)\n- \"Make this car red and metallic\" \n- \"Create a sphere and place it above the cube\"\n- \"Make the lighting like a studio\"\n- \"Point the camera at the scene, and make it isometric\"\n\n## Hyper3D integration\n\nHyper3D's free trial key allows you to generate a limited number of models per day. If the daily limit is reached, you can wait for the next day's reset or obtain your own key from hyper3d.ai and fal.ai.\n\n## Troubleshooting\n\n- **Connection issues**: Make sure the Blender addon server is running, and the MCP server is configured on Claude, DO NOT run the uvx command in the terminal. Sometimes, the first command won't go through but after that it starts working.\n- **Timeout errors**: Try simplifying your requests or breaking them into smaller steps\n- **Poly Haven integration**: Claude is sometimes erratic with its behaviour\n- **Have you tried turning it off and on again?**: If you're still having connection errors, try restarting both Claude and the Blender server\n\n\n## Technical Details\n\n### Communication Protocol\n\nThe system uses a simple JSON-based protocol over TCP sockets:\n\n- **Commands** are sent as JSON objects with a `type` and optional `params`\n- **Responses** are JSON objects with a `status` and `result` or `message`\n\n## Limitations & Security Considerations\n\n- The `execute_blender_code` tool allows running arbitrary Python code in Blender, which can be powerful but potentially dangerous. Use with caution in production environments. ALWAYS save your work before using it.\n- Poly Haven requires downloading models, textures, and HDRI images. If you do not want to use it, please turn it off in the checkbox in Blender. \n- Complex operations might need to be broken down into smaller steps\n\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## Disclaimer\n\nThis is a third-party integration and not made by Blender. Made by [Siddharth](https://x.com/sidahuj)",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "museum",
        "art",
        "ai",
        "explore art",
        "museum databases",
        "art collections"
      ],
      "category": "art--culture"
    },
    "burningion--video-editing-mcp": {
      "owner": "burningion",
      "name": "video-editing-mcp",
      "url": "https://github.com/burningion/video-editing-mcp",
      "imageUrl": "",
      "description": "Add, Analyze, Search, and Generate Video Edits from your Video Jungle Collection",
      "stars": 214,
      "forks": 29,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-09-25T07:41:40Z",
      "readme_content": "# Video Editor MCP server\n\n[](https://www.video-jungle.com)\n\nSee a demo here: [https://www.youtube.com/watch?v=KG6TMLD8GmA](https://www.youtube.com/watch?v=KG6TMLD8GmA)\n\nUpload, edit, search, and generate videos from everyone's favorite LLM and [Video Jungle](https://www.video-jungle.com/).\n\nYou'll need to sign up for an account at [Video Jungle](https://app.video-jungle.com/register) in order to use this tool, and add your API key.\n\n[![PyPI version](https://badge.fury.io/py/video-editor-mcp.svg)](https://badge.fury.io/py/video-editor-mcp)\n\n## Components\n\n### Resources\n\nThe server implements an interface to upload, generate, and edit videos with:\n- Custom vj:// URI scheme for accessing individual videos and projects\n- Each project resource has a name, description\n- Search results are returned with metadata about what is in the video, and when, allowing for edit generation directly\n\n### Prompts\n\nComing soon.\n\n### Tools\n\nThe server implements a few tools:\n- add-video\n  - Add a Video File for analysis from a URL. Returns an vj:// URI to reference the Video file\n- create-videojungle-project\n  - Creates a Video Jungle project to contain generative scripts, analyzed videos, and images for video edit generation\n- edit-locally\n  - Creates an OpenTimelineIO project and downloads it to your machine to open in a Davinci Resolve Studio instance (Resolve Studio _must_ already be running before calling this tool.) \n- generate-edit-from-videos\n  - Generates a rendered video edit from a set of video files\n- generate-edit-from-single-video\n  - Generate an edit from a single input video file\n- get-project-assets\n  - Get assets within a project for video edit generation.\n- search-videos\n  - Returns video matches based upon embeddings and keywords\n- update-video-edit\n  - Live update a video edit's information. If Video Jungle is open, edit will be updated in real time.\n\n### Using Tools in Practice\n\nIn order to use the tools, you'll need to sign up for Video Jungle and add your API key.\n\n**add-video**\n\nHere's an example prompt to invoke the `add-video` tool:\n\n```\ncan you download the video at https://www.youtube.com/shorts/RumgYaH5XYw and name it fly traps?\n```\n\nThis will download a video from a URL, add it to your library, and analyze it for retrieval later. Analysis is multi-modal, so both audio and visual components can be queried against.\n\n**search-videos**\n\nOnce you've got a video downloaded and analyzed, you can then do queries on it using the `search-videos` tool:\n\n```\ncan you search my videos for fly traps?\n```\n\nSearch results contain relevant metadata for generating a video edit according to details discovered in the initial analysis.\n\n**search-local-videos**\n\nYou must set the environment variable `LOAD_PHOTOS_DB=1` in order to use this tool, as it will make Claude prompt to access your files on your local machine.\n\nOnce that's done, you can search through your Photos app for videos that exist on your phone, using Apple's tags.\n\nIn my case, when I search for \"Skateboard\", I get 1903 video files.\n\n```\ncan you search my local video files for Skateboard?\n```\n\n**generate-edit-from-videos**\n\nFinally, you can use these search results to generate an edit:\n\n```\ncan you create an edit of all the times the video says \"fly trap\"?\n```\n\n(Currently), the video edits tool relies on the context within the current chat. \n\n**generate-edit-from-single-video**\n\nFinally, you can cut down an edit from a single, existing video:\n\n```\ncan you create an edit of all the times this video says the word \"fly trap\"?\n```\n\n## Configuration\n\nYou must login to [Video Jungle settings](https://app.video-jungle.com/profile/settings), and get your [API key](https://app.video-jungle.com/profile/settings). Then, use this to start Video Jungle MCP:\n\n```bash\n$ uv run video-editor-mcp YOURAPIKEY\n```\n\nTo allow this MCP server to search your Photos app on MacOS:\n\n```\n$ LOAD_PHOTOS_DB=1 uv run video-editor-mcp YOURAPIKEY\n```\n## Quickstart\n\n### Install\n\n#### Installing via Smithery\n\nTo install Video Editor for Claude Desktop automatically via [Smithery](https://smithery.ai/server/video-editor-mcp):\n\n```bash\nnpx -y @smithery/cli install video-editor-mcp --client claude\n```\n\n#### Claude Desktop\n\nYou'll need to adjust your `claude_desktop_config.json` manually:\n\nOn MacOS: `~/Library/Application\\ Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n<details>\n<details>\n  <summary>Published Server Configuration</summary>\n  \n ```json\n  \"mcpServers\": {\n    \"video-editor-mcp\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"video-editor-mcp\",\n        \"YOURAPIKEY\"\n      ]\n    }\n  }\n  ```\n</details>\n  <summary>Development/Unpublished Servers Configuration</summary>\n  \n ```json\n  \"mcpServers\": {\n    \"video-editor-mcp\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/Users/YOURDIRECTORY/video-editor-mcp\",\n        \"run\",\n        \"video-editor-mcp\",\n        \"YOURAPIKEY\"\n      ]\n    }\n  }\n  ```\n\n  With local Photos app access enabled (search your Photos app):\n\n  ```json\n    \"video-jungle-mcp\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/Users/<PATH_TO>/video-jungle-mcp\",\n        \"run\",\n        \"video-editor-mcp\",\n        \"<YOURAPIKEY>\"\n      ],\n     \"env\": {\n\t      \"LOAD_PHOTOS_DB\": \"1\"\n      }\n    },\n  ```\n\n</details>\n\nBe sure to replace the directories with the directories you've placed the repository in on **your** computer.\n\n## Development\n\n### Building and Publishing\n\nTo prepare the package for distribution:\n\n1. Sync dependencies and update lockfile:\n```bash\nuv sync\n```\n\n2. Build package distributions:\n```bash\nuv build\n```\n\nThis will create source and wheel distributions in the `dist/` directory.\n\n3. Publish to PyPI:\n```bash\nuv publish\n```\n\nNote: You'll need to set PyPI credentials via environment variables or command flags:\n- Token: `--token` or `UV_PUBLISH_TOKEN`\n- Or username/password: `--username`/`UV_PUBLISH_USERNAME` and `--password`/`UV_PUBLISH_PASSWORD`\n\n### MCP Server Registry\n\n```\nmcp-name: io.github.burningion/video-editing-mcp\n```\n\n### Debugging\n\nSince MCP servers run over stdio, debugging can be challenging. For the best debugging\nexperience, we strongly recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector).\n\n\nYou can launch the MCP Inspector via [`npm`](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm) with this command:\n\n(Be sure to replace `YOURDIRECTORY` and `YOURAPIKEY` with the directory this repo is in, and your Video Jungle API key, found in the settings page.)\n\n```bash\nnpx @modelcontextprotocol/inspector uv run --directory /Users/YOURDIRECTORY/video-editor-mcp video-editor-mcp YOURAPIKEY\n```\n\n\nUpon launching, the Inspector will display a URL that you can access in your browser to begin debugging.\n\nAdditionally, I've added logging to `app.log` in the project directory. You can add logging to diagnose API calls via a:\n\n```\nlogging.info(\"this is a test log\")\n```\n\nA reasonable way to follow along as you're workin on the project is to open a terminal session and do a:\n\n```bash\n$ tail -n 90 -f app.log\n```",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ai",
        "art",
        "artistic",
        "explore art",
        "artistic cultural",
        "art culture"
      ],
      "category": "art--culture"
    },
    "cantian-ai--bazi-mcp": {
      "owner": "cantian-ai",
      "name": "bazi-mcp",
      "url": "https://github.com/cantian-ai/bazi-mcp",
      "imageUrl": "",
      "description": "Provides comprehensive and accurate Bazi (Chinese Astrology) charting and analysis",
      "stars": 177,
      "forks": 57,
      "license": "ISC License",
      "language": "TypeScript",
      "updated_at": "2025-10-04T10:53:29Z",
      "readme_content": "# Bazi MCP (八字 MCP) by Cantian AI\n\n[![smithery badge](https://smithery.ai/badge/@cantian-ai/bazi-mcp)](https://smithery.ai/server/@cantian-ai/bazi-mcp)\n[![Verified on MseeP](https://mseep.ai/badge.svg)](https://mseep.ai/app/453ac410-d93a-45fb-8563-7d3cccfbe956)\n\nUnlock precise Bazi insights with the **Bazi MCP**, the first AI-powered Bazi calculator. Built to address inaccuracies in existing AI fortune-telling tools like GPT and DeepSeek, our MCP delivers reliable Bazi data for personality analysis, destiny forecasting, and more.\n\n### Why Bazi MCP?\n\n- **Accurate Bazi Calculations**: Provide insightful Bazi information.\n- **AI Agent Integration**: Empowers AI agents with precise Bazi data.\n- **Community-Driven**: Join enthusiasts to advance Chinese metaphysics.\n\nOriginating from the popular [_Chinese Bazi Fortune Teller_](https://chatgpt.com/g/g-67c3f7b74d148191a2167f44fd13412d-chinese-bazi-fortune-teller-can-tian-ba-zi-suan-ming-jing-zhun-pai-pan-jie-du) GPTs in the GPT Store, this project is now integrated with **Cantian AI** ([cantian.ai](https://cantian.ai)). We invite Bazi practitioners and AI enthusiasts to collaborate, share insights, and contribute to our open-source community.\n\n### Get Involved\n\n- **Contact**: [support@cantian.ai](mailto:support@cantian.ai)\n\n## 中文\n\n**八字 MCP**是参天 AI 推出的首个面向玄学领域的 MCP，针对 GPT 和 DeepSeek 等算命工具常出现的排盘错误，提供精准的八字数据，助力性格分析、命运预测等应用。\n\n### 八字 MCP 亮点\n\n- **精准排盘**：提供全面的八字排盘信息。\n- **AI 赋能**：为 AI 智能体提供可靠八字服务。\n- **社区共建**：欢迎命理爱好者参与交流与开发。\n\n项目源于 GPT Store 热门应用[_Chinese Bazi Fortune Teller_](https://chatgpt.com/g/g-67c3f7b74d148191a2167f44fd13412d-chinese-bazi-fortune-teller-can-tian-ba-zi-suan-ming-jing-zhun-pai-pan-jie-du)，现已融入**参天 AI**平台 ([cantian.ai](https://cantian.ai))。我们诚邀命理研究者与 AI 开发者加入，共同推动中国传统文化的传承与创新。\n\n### 联系我们\n\n- **邮箱**：[support@cantian.ai](mailto:support@cantian.ai)\n- **微信**：\n\n  <img src=\"https://github.com/user-attachments/assets/7790b64e-e03f-47e2-b824-38459549a6d8\" alt=\"WeChat QR Code\" width=\"200\"/>\n\n## 前置需求 ｜ Prerequisite\n\nNode.js 22 版本或以上。\n\nNode.js 22 or above.\n\n## 开始使用 ｜ Start\n\n配置 AI 应用（例如 Claude Descktop）。\n\nConfigure AI application (e.g. Claude Desktop).\n\n```json\n{\n  \"mcpServers\": {\n    \"Bazi\": {\n      \"command\": \"npx\",\n      \"args\": [\"bazi-mcp\"]\n    }\n  }\n}\n```\n\n### Installing via Smithery\n\nTo install bazi-mcp for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@cantian-ai/bazi-mcp):\n\n```bash\nnpx -y @smithery/cli install @cantian-ai/bazi-mcp --client claude\n```\n\n## 工具列表 | Tools\n\n### getBaziDetail\n\n> 根据给定的公历或农历时间计算八字信息。\n> Calculate the Bazi results based on the solar/lunar datetime.\n\n#### 参数 | Arguments\n\n- solarDatetime: `String`\n\n  > ISO 格式的阳历时间。例如：`2000-05-15T12:00:00+08:00`。  \n  > Solar datetime in ISO format. Example: `2000-05-15T12:00:00+08:00`.\n\n- lunarDatetime: `String`\n\n  > 农历时间。例如：`2000-05-15 12:00:00`。  \n  > Lunar datetime. Example: `2000-05-15 12:00:00`.\n\n- gender: `Number`\n\n  > 性别。可选。0 - 女，1-男。默认 1。  \n  > Gender. Optional. 0 for female, 1 for male. 1 by default.\n\n- eightCharProviderSect： `Number`\n\n  > 早晚子时配置。可选。1 - 表示 23:00-23:59 日干支为明天，2 - 表示 23:00-23:59 日干支为当天。默认 2。\n  > Configuration for eight char provider. Optional. 1 for meaning the day stem of 23:00-23:59 is for tomorrow, 2 for meaning the day stem of 23:00-23:59 is for today. 2 by default.\n\n#### 结果示例 ｜ Result example\n\n```json\n{\n  \"性别\": \"男\",\n  \"阳历\": \"1998年7月31日 14:10:00\",\n  \"农历\": \"农历戊寅年六月初九辛未时\",\n  \"八字\": \"戊寅 己未 己卯 辛未\",\n  \"生肖\": \"虎\",\n  \"日主\": \"己\",\n  \"年柱\": {\n    \"天干\": {\n      \"天干\": \"戊\",\n      \"五行\": \"土\",\n      \"阴阳\": \"阳\",\n      \"十神\": \"劫财\"\n    },\n    \"地支\": {\n      \"地支\": \"寅\",\n      \"五行\": \"木\",\n      \"阴阳\": \"阳\",\n      \"藏干\": {\n        \"主气\": {\n          \"天干\": \"甲\",\n          \"十神\": \"正官\"\n        },\n        \"中气\": {\n          \"天干\": \"丙\",\n          \"十神\": \"正印\"\n        },\n        \"余气\": {\n          \"天干\": \"戊\",\n          \"十神\": \"劫财\"\n        }\n      }\n    },\n    \"纳音\": \"城头土\",\n    \"旬\": \"甲戌\",\n    \"空亡\": \"申酉\",\n    \"星运\": \"死\",\n    \"自坐\": \"长生\"\n  },\n  \"月柱\": {\n    \"天干\": {\n      \"天干\": \"己\",\n      \"五行\": \"土\",\n      \"阴阳\": \"阴\",\n      \"十神\": \"比肩\"\n    },\n    \"地支\": {\n      \"地支\": \"未\",\n      \"五行\": \"土\",\n      \"阴阳\": \"阴\",\n      \"藏干\": {\n        \"主气\": {\n          \"天干\": \"己\",\n          \"十神\": \"比肩\"\n        },\n        \"中气\": {\n          \"天干\": \"丁\",\n          \"十神\": \"偏印\"\n        },\n        \"余气\": {\n          \"天干\": \"乙\",\n          \"十神\": \"七杀\"\n        }\n      }\n    },\n    \"纳音\": \"天上火\",\n    \"旬\": \"甲寅\",\n    \"空亡\": \"子丑\",\n    \"星运\": \"冠带\",\n    \"自坐\": \"冠带\"\n  },\n  \"日柱\": {\n    \"天干\": {\n      \"天干\": \"己\",\n      \"五行\": \"土\",\n      \"阴阳\": \"阴\"\n    },\n    \"地支\": {\n      \"地支\": \"卯\",\n      \"五行\": \"木\",\n      \"阴阳\": \"阴\",\n      \"藏干\": {\n        \"主气\": {\n          \"天干\": \"乙\",\n          \"十神\": \"七杀\"\n        }\n      }\n    },\n    \"纳音\": \"城头土\",\n    \"旬\": \"甲戌\",\n    \"空亡\": \"申酉\",\n    \"星运\": \"病\",\n    \"自坐\": \"病\"\n  },\n  \"时柱\": {\n    \"天干\": {\n      \"天干\": \"辛\",\n      \"五行\": \"金\",\n      \"阴阳\": \"阴\",\n      \"十神\": \"食神\"\n    },\n    \"地支\": {\n      \"地支\": \"未\",\n      \"五行\": \"土\",\n      \"阴阳\": \"阴\",\n      \"藏干\": {\n        \"主气\": {\n          \"天干\": \"己\",\n          \"十神\": \"比肩\"\n        },\n        \"中气\": {\n          \"天干\": \"丁\",\n          \"十神\": \"偏印\"\n        },\n        \"余气\": {\n          \"天干\": \"乙\",\n          \"十神\": \"七杀\"\n        }\n      }\n    },\n    \"纳音\": \"路旁土\",\n    \"旬\": \"甲子\",\n    \"空亡\": \"戌亥\",\n    \"星运\": \"冠带\",\n    \"自坐\": \"衰\"\n  },\n  \"胎元\": \"庚戌\",\n  \"胎息\": \"甲戌\",\n  \"命宫\": \"乙卯\",\n  \"身宫\": \"乙卯\",\n  \"神煞\": {\n    \"年柱\": [\"国印\", \"亡神\"],\n    \"月柱\": [\"天德合\", \"月德合\", \"天乙贵人\", \"太极贵人\", \"福星贵人\", \"金舆\", \"血刃\", \"华盖\", \"天喜\", \"元辰\"],\n    \"日柱\": [\"天德合\", \"月德合\", \"桃花\", \"九丑\", \"童子煞\"],\n    \"时柱\": [\"天乙贵人\", \"太极贵人\", \"福星贵人\", \"金舆\", \"血刃\", \"华盖\", \"天喜\", \"元辰\", \"童子煞\"]\n  },\n  \"大运\": {\n    \"起运年龄\": 4,\n    \"起运日期\": \"2001-1-26\",\n    \"大运\": [\n      {\n        \"干支\": \"庚申\",\n        \"开始年份\": 2001,\n        \"结束\": 2010,\n        \"天干十神\": \"伤官\",\n        \"地支十神\": [\"伤官\", \"正财\", \"劫财\"],\n        \"地支藏干\": [\"庚\", \"壬\", \"戊\"],\n        \"开始年龄\": 4,\n        \"结束年龄\": 13\n      },\n      {\n        \"干支\": \"辛酉\",\n        \"开始年份\": 2011,\n        \"结束\": 2020,\n        \"天干十神\": \"食神\",\n        \"地支十神\": [\"食神\"],\n        \"地支藏干\": [\"辛\"],\n        \"开始年龄\": 14,\n        \"结束年龄\": 23\n      },\n      {\n        \"干支\": \"壬戌\",\n        \"开始年份\": 2021,\n        \"结束\": 2030,\n        \"天干十神\": \"正财\",\n        \"地支十神\": [\"劫财\", \"食神\", \"偏印\"],\n        \"地支藏干\": [\"戊\", \"辛\", \"丁\"],\n        \"开始年龄\": 24,\n        \"结束年龄\": 33\n      },\n      {\n        \"干支\": \"癸亥\",\n        \"开始年份\": 2031,\n        \"结束\": 2040,\n        \"天干十神\": \"偏财\",\n        \"地支十神\": [\"正财\", \"正官\"],\n        \"地支藏干\": [\"壬\", \"甲\"],\n        \"开始年龄\": 34,\n        \"结束年龄\": 43\n      },\n      {\n        \"干支\": \"甲子\",\n        \"开始年份\": 2041,\n        \"结束\": 2050,\n        \"天干十神\": \"正官\",\n        \"地支十神\": [\"偏财\"],\n        \"地支藏干\": [\"癸\"],\n        \"开始年龄\": 44,\n        \"结束年龄\": 53\n      },\n      {\n        \"干支\": \"乙丑\",\n        \"开始年份\": 2051,\n        \"结束\": 2060,\n        \"天干十神\": \"七杀\",\n        \"地支十神\": [\"比肩\", \"偏财\", \"食神\"],\n        \"地支藏干\": [\"己\", \"癸\", \"辛\"],\n        \"开始年龄\": 54,\n        \"结束年龄\": 63\n      },\n      {\n        \"干支\": \"丙寅\",\n        \"开始年份\": 2061,\n        \"结束\": 2070,\n        \"天干十神\": \"正印\",\n        \"地支十神\": [\"正官\", \"正印\", \"劫财\"],\n        \"地支藏干\": [\"甲\", \"丙\", \"戊\"],\n        \"开始年龄\": 64,\n        \"结束年龄\": 73\n      },\n      {\n        \"干支\": \"丁卯\",\n        \"开始年份\": 2071,\n        \"结束\": 2080,\n        \"天干十神\": \"偏印\",\n        \"地支十神\": [\"七杀\"],\n        \"地支藏干\": [\"乙\"],\n        \"开始年龄\": 74,\n        \"结束年龄\": 83\n      },\n      {\n        \"干支\": \"戊辰\",\n        \"开始年份\": 2081,\n        \"结束\": 2090,\n        \"天干十神\": \"劫财\",\n        \"地支十神\": [\"劫财\", \"七杀\", \"偏财\"],\n        \"地支藏干\": [\"戊\", \"乙\", \"癸\"],\n        \"开始年龄\": 84,\n        \"结束年龄\": 93\n      },\n      {\n        \"干支\": \"己巳\",\n        \"开始年份\": 2091,\n        \"结束\": 2100,\n        \"天干十神\": \"比肩\",\n        \"地支十神\": [\"正印\", \"伤官\", \"劫财\"],\n        \"地支藏干\": [\"丙\", \"庚\", \"戊\"],\n        \"开始年龄\": 94,\n        \"结束年龄\": 103\n      }\n    ]\n  },\n  \"刑冲合会\": {\n    \"年\": {\n      \"天干\": {},\n      \"地支\": {}\n    },\n    \"月\": {\n      \"天干\": {},\n      \"地支\": {\n        \"半合\": [\n          {\n            \"柱\": \"日\",\n            \"知识点\": \"未卯半合木\",\n            \"元素\": \"木\"\n          }\n        ]\n      }\n    },\n    \"日\": {\n      \"天干\": {},\n      \"地支\": {\n        \"半合\": [\n          {\n            \"柱\": \"月\",\n            \"知识点\": \"卯未半合木\",\n            \"元素\": \"木\"\n          },\n          {\n            \"柱\": \"时\",\n            \"知识点\": \"卯未半合木\",\n            \"元素\": \"木\"\n          }\n        ]\n      }\n    },\n    \"时\": {\n      \"天干\": {},\n      \"地支\": {\n        \"半合\": [\n          {\n            \"柱\": \"日\",\n            \"知识点\": \"未卯半合木\",\n            \"元素\": \"木\"\n          }\n        ]\n      }\n    }\n  }\n}\n```\n\n### getSolarTimes\n\n> 根据给定的八字返回可能的公历时间列表。\n> Return a list of possible solar calendar datetime based on the given Bazi.\n\n#### 参数 | Arguments\n\n- bazi: `String`\n\n  > 八字，各柱用空格隔开。\n  > Bazi, with each pillar separated by a space.\n\n#### 结果示例 ｜ Result example\n\n```json\n[\"1758-07-29 14:00:00\", \"1818-07-15 14:00:00\", \"1998-07-31 14:00:00\"]\n```\n\n### getChineseCalendar\n\n> 获取指定公历时间（默认今天）的黄历信息。\n> Get chinese calendar information for the specified solar calendar date (default is today).\n\n#### 参数 | Arguments\n\n- solarDatetime\n\n  > ISO 格式的阳历时间。例如：`2000-05-15T12:00:00+08:00`。  \n  > Solar datetime in ISO format. Example: `2000-05-15T12:00:00+08:00`.\n\n#### 结果示例 ｜ Result example\n\n```json\n{\n  \"公历\": \"2025年5月7日 星期三\",\n  \"农历\": \"农历乙巳年四月初十\",\n  \"干支\": \"乙巳 辛巳 丙子\",\n  \"生肖\": \"蛇\",\n  \"纳音\": \"涧下水\",\n  \"节气\": \"立夏\",\n  \"二十八宿\": \"箕水豹吉\",\n  \"彭祖百忌\": \"丙不修灶必见灾殃 子不问卜自惹祸殃\",\n  \"喜神方位\": \"西南\",\n  \"阳贵神方位\": \"西\",\n  \"阴贵神方位\": \"西北\",\n  \"福神方位\": \"东\",\n  \"财神方位\": \"西南\",\n  \"冲煞\": \"冲马(午)煞南\",\n  \"宜\": \"嫁娶,祭祀,祈福,求嗣,开光,出行,拆卸,动土,上梁,出火,进人口,入宅,移徙,安床,栽种,纳畜,牧养,竖柱,安门,修造,解除,会亲友\",\n  \"忌\": \"\"\n}\n```\n\n### ~~buildBaziFromLunarDatetime~~ (deprecated)\n\n> 根据`农历`时间计算八字结果。  \n> Calculate the BaZi results based on the lunar datetime.\n\n#### 参数 ｜ Arguments\n\n- lunarDatetime: `String`\n\n  > 农历时间。例如：`2000-05-15 12:00:00`。  \n  > Lunar datetime. Example: `2000-05-15 12:00:00`.\n\n- gender: `Number`\n\n  > 性别。可选。0 - 女，1-男。默认 1。  \n  > Gender. Optional. 0 for female, 1 for male. 1 by default.\n\n- eightCharProviderSect： `Number`\n\n  > 早晚子时配置。可选。1 - 表示 23:00-23:59 日干支为明天，2 - 表示 23:00-23:59 日干支为当天。默认 2。\n  > Configuration for eight char provider. Optional. 1 for meaning the day stem of 23:00-23:59 is for tomorrow, 2 for meaning the day stem of 23:00-23:59 is for today. 2 by default.\n\n### ~~buildBaziFromSolarDatetime~~ (deprecated)\n\n> 根据`阳历`时间计算八字结果。  \n> Calculate the BaZi results based on the solar datetime.\n\n#### 参数 ｜ Arguments\n\n- solarDatetime: `String`\n\n  > ISO 格式的阳历时间。例如：`2000-05-15T12:00:00+08:00`。  \n  > Solar datetime in ISO format. Example: `2000-05-15T12:00:00+08:00`.\n\n- gender: `Number`\n\n  > 性别。可选。0 - 女，1-男。  \n  > Gender. Optional. 0 for female, 1 for male.\n\n- eightCharProviderSect： `Number`\n\n  > 早晚子时配置。可选。1 - 表示 23:00-23:59 日干支为明天，2 - 表示 23:00-23:59 日干支为当天。默认 2。\n  > Configuration for eight char provider. Optional. 1 for meaning the day stem of 23:00-23:59 is for tomorrow, 2 for meaning the day stem of 23:00-23:59 is for today. 2 by default.\n\n**Keywords**: Bazi MCP, Bazi AI Agent, Fengshui AI Agent, Bazi Calculator MCP, Bazi Calculator AI, Cantian AI\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "astrology",
        "art",
        "artistic",
        "chinese astrology",
        "explore art",
        "artistic cultural"
      ],
      "category": "art--culture"
    },
    "cswkim--discogs-mcp-server": {
      "owner": "cswkim",
      "name": "discogs-mcp-server",
      "url": "https://github.com/cswkim/discogs-mcp-server",
      "imageUrl": "",
      "description": "MCP server to interact with the Discogs API",
      "stars": 56,
      "forks": 4,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-02T22:12:02Z",
      "readme_content": "[![License](https://img.shields.io/github/license/cswkim/discogs-mcp-server)](LICENSE)\n[![GitHub Release](https://img.shields.io/github/v/release/cswkim/discogs-mcp-server)](https://github.com/cswkim/discogs-mcp-server/releases)\n[![GitHub Actions Workflow Status](https://img.shields.io/github/actions/workflow/status/cswkim/discogs-mcp-server/.github%2Fworkflows%2Fcheck-pr.yml)](https://github.com/cswkim/discogs-mcp-server/actions/workflows/check-pr.yml)\n[![NPM Downloads](https://img.shields.io/npm/d18m/discogs-mcp-server)](https://www.npmjs.com/package/discogs-mcp-server)\n[![Sponsor](https://img.shields.io/static/v1?label=sponsor&message=%E2%9D%A4&logo=GitHub&color=ff69b4)](https://github.com/sponsors/cswkim)\n\n# Discogs MCP Server\n\nMCP Server for the Discogs API, enabling music catalog operations, search functionality, and more.\n\n## Quickstart\n\nIf you just want to get started immediately using this MCP Server with the [Claude](https://claude.ai) desktop app and don't care about development or running the server yourself, then make sure you have [Node.js](https://nodejs.org/en) installed and your Discogs personal access token ready and skip straight to the [Claude configuration section](#claude-desktop-configuration). Use the `NPX` method from that section.\n\n## Table of Contents\n\n- [Acknowledgements](#acknowledgements)\n- [Available Tools](#available-tools)\n- [Caveats](#caveats)\n- [Prerequisites](#prerequisites)\n- [Setup](#setup)\n- [Running the Server](#running-the-server-locally)\n  - [Option 1: Local Development](#option-1-local-development)\n  - [Option 2: Docker](#option-2-docker)\n- [Inspection](#inspection)\n- [MCP Clients](#mcp-clients)\n  - [Claude Desktop Configuration](#claude-desktop-configuration)\n    - [NPX](#npx)\n    - [Local Node](#local-node)\n    - [Docker](#docker)\n  - [LibreChat](#librechat)\n  - [LM Studio](#lm-studio)\n- [TODO](#todo)\n- [License](#license)\n\n## Acknowledgements\n\nThis MCP server is built using [FastMCP](https://github.com/punkpeye/fastmcp), a typescript framework for building MCP servers. For more information about MCP and how to use MCP servers, please refer to the [FastMCP documentation](https://github.com/punkpeye/fastmcp/blob/main/README.md) and the [official MCP documentation](https://modelcontextprotocol.io).\n\n## Available Tools\n\nCheck out the list of available tools: [TOOLS.md](TOOLS.md)\n\n## Caveats\n\n- The [Discogs API documentation](https://www.discogs.com/developers) is not perfect and some endpoints may not be fully documented or may have inconsistencies.\n- Due to the vast number of API endpoints and response types, it's not feasible to verify type safety for every possible response. Please report any type-related issues you encounter.\n- This MCP server allows for editing data in your Discogs collection. Please use with caution and verify your actions before executing them.\n- The Discogs API `per_page` default is `50`, which can be too much data for some clients to process effectively, so within this project a `discogs.config.defaultPerPage` value has been set to `5`. You can request more data in your prompts, but be aware that some clients may struggle with larger responses.\n\n## Prerequisites\n\n- Node.js (tested with Node.js `20.x.x`, but `18.x.x` should work as well)\n  - Check your Node.js version with: `node --version`\n- Docker (optional, for running a local docker image without having to deal with Node or dependencies)\n\n## Setup\n\n1. Clone the repository\n2. Create a `.env` file in the root directory based on `.env.example`\n3. Set the following required environment variables in your `.env`:\n   - `DISCOGS_PERSONAL_ACCESS_TOKEN`: Your Discogs personal access token\n\nTo get your Discogs personal access token, go to your [Discogs Settings > Developers](https://www.discogs.com/settings/developers) page and find your token or generate a new one. **_DO NOT SHARE YOUR TOKEN_**. OAuth support will be added in a future release.\n\nThe other environment variables in `.env.example` are optional and have sensible defaults, so you don't need to set them unless you have specific requirements.\n\n## Running the Server Locally\n\n### Option 1: Local Development\n\n1. Install dependencies:\n   ```bash\n   pnpm install\n   ```\n\n2. Available commands:\n   - `pnpm run dev`: Start the development server with hot reloading\n   - `pnpm run dev:stream`: Start the development server with hot reloading in HTTP streaming mode\n   - `pnpm run build`: Build the production version\n   - `pnpm run start`: Run the production build\n   - `pnpm run inspect`: Run the MCP Inspector (see [Inspection](#inspection) section)\n   - `pnpm run format`: Check code formatting (prettier)\n   - `pnpm run lint`: Run linter (eslint)\n   - `pnpm run test`: Run vitest\n   - `pnpm run test:coverage`: Run vitest v8 coverage\n   - `pnpm run version:check`: Checks that the package.json version and src/version.ts match\n\n### Option 2: Docker\n\n1. Build the Docker image:\n   ```bash\n   docker build -t discogs-mcp-server:latest .\n   ```\n\n2. Run the container:\n   ```bash\n   docker run --env-file .env discogs-mcp-server:latest\n   ```\n\n   For HTTP Streaming transport mode:\n   ```bash\n   # The port should match what is in your .env file\n   docker run --env-file .env -p 3001:3001 discogs-mcp-server:latest stream\n   ```\n\n## Inspection\n\nRun the MCP Inspector to test your local MCP server:\n\n```bash\npnpm run inspect\n```\n\nThis will start the MCP Inspector at `http://127.0.0.1:6274`. Visit this URL in your browser to interact with your local MCP server.\n\nFor more information about the MCP Inspector, visit [the official documentation](https://modelcontextprotocol.io/docs/tools/inspector).\n\n## MCP Clients\n\nMore client examples will be added in the future. If you'd like configuration for a specific client, either\nrequest it by opening a new issue or creating the pull request to edit this section of the README yourself.\n\n### Claude Desktop Configuration\n\nFind your `claude_desktop_config.json` at `Claude > Settings > Developer > Edit Config` and depending on which option you'd like, add **JUST ONE** of the following:\n\n#### NPX\n\nRunning it straight from the npm registry.\n\n```json\n{\n  \"mcpServers\": {\n    \"discogs\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"discogs-mcp-server\"\n      ],\n      \"env\": {\n        \"DISCOGS_PERSONAL_ACCESS_TOKEN\": \"<YOUR_TOKEN>\"\n      }\n    }\n  }\n}\n```\n\n#### Local Node\n\nDependencies should have been installed before you use this method (`pnpm install`).\n\n```json\n{\n  \"mcpServers\": {\n    \"discogs\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"tsx\",\n        \"/PATH/TO/YOUR/PROJECT/FOLDER/src/index.ts\"\n      ],\n      \"env\": {\n        \"DISCOGS_PERSONAL_ACCESS_TOKEN\": \"<YOUR_TOKEN>\"\n      }\n    }\n  }\n}\n```\n\n#### Docker\n\nThe docker image should have been built before using this method.\n\n```json\n{\n  \"mcpServers\": {\n    \"discogs\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"-i\",\n        \"--env-file\",\n        \"/PATH/TO/YOUR/PROJECT/FOLDER/.env\",\n        \"discogs-mcp-server:latest\"\n      ]\n    }\n  }\n}\n```\n\nAny changes to local code will require Claude to be restarted to take effect. Also, Claude requires human-in-the-loop interaction to allow an MCP tool to be run, so everytime a new tool is accessed Claude will ask for permission. You usually only have to do this once per tool per chat. _If using the free version, long chats may result in more frequent errors trying to run tools as Claude limits the amount of context within a single chat._\n\n### LibreChat\n\nIn the `librechat.yaml` configuration file, add this under the `mcpServers` section:\n\n```yaml\ndiscogs:\n  type: stdio\n  command: npx\n  args: [\"-y\", \"discogs-mcp-server\"]\n  env:\n    DISCOGS_PERSONAL_ACCESS_TOKEN: YOUR_TOKEN_GOES_HERE\n```\n\n### LM Studio\n\nGet to the Chat `Settings`. In the `Program` tab there will be a dropdown with a default of `Install`. Select `Edit mcp.json`. Add this under the `mcpServers` section:\n\n```json\n\"discogs\": {\n  \"command\": \"npx\",\n  \"args\": [\n    \"-y\",\n    \"discogs-mcp-server\"\n  ],\n  \"env\": {\n    \"DISCOGS_PERSONAL_ACCESS_TOKEN\": \"YOUR_TOKEN_GOES_HERE\"\n  }\n}\n```\n\nAfter you Save, in the `Program` tab there should now be an `mcp/discogs` toggle to enable the server. Within every chat box there is an `Integrations` menu where you can also enable mcp servers.\n\n## TODO\n\n- OAuth support\n- Missing tools:\n  - Inventory uploading\n\n## License\n\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "museum",
        "art",
        "artistic",
        "explore art",
        "museum databases",
        "artistic cultural"
      ],
      "category": "art--culture"
    },
    "diivi--aseprite-mcp": {
      "owner": "diivi",
      "name": "aseprite-mcp",
      "url": "https://github.com/diivi/aseprite-mcp",
      "imageUrl": "",
      "description": "MCP server using the Aseprite API to create pixel art",
      "stars": 87,
      "forks": 9,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-02T22:12:08Z",
      "readme_content": "# Aseprite MCP Tools\n\nA Python module that serves as an MCP server for interacting with the Aseprite API\n\nDemo where Cursor draws a cloud in aseprite using the MCP:\n\nhttps://github.com/user-attachments/assets/572edf75-ab66-4700-87ee-d7d3d196c597\n\n## Docker Usage\n\n### Quick Start\n\nBuild and run the Docker image:\n```bash\ndocker build -t aseprite-mcp:latest .\ndocker run -it --rm aseprite-mcp:latest\n```\n\nOr use the provided build scripts:\n- **Linux/macOS**: `chmod +x build-docker.sh && ./build-docker.sh`\n- **Windows**: `.\\build-docker.ps1`\n\n### Using Docker Compose\n```bash\n# Production\ndocker-compose up aseprite-mcp\n\n# Development mode\ndocker-compose --profile dev up aseprite-mcp-dev\n```\n\nSee [DOCKER.md](DOCKER.md) for detailed Docker setup instructions.\n\n### Optional: Install Aseprite via Steam\n\nTo have the container install Aseprite via SteamCMD at startup, provide Steam credentials:\n\n```powershell\n# Create a .env with STEAM_USERNAME/STEAM_PASSWORD (and optional STEAM_GUARD_CODE)\n# Then\ndocker run --rm -i --env-file .env aseprite-mcp:latest\n```\n\nIf installed, the binary will be at `/opt/steamapps/common/Aseprite/aseprite` and `ASEPRITE_PATH` will be picked up automatically.\n\n## Local Installation\n\n### Prerequisites\n- Python 3.13+\n- `uv` package manager\n\n### Installation:\n```json\n{\n  \"mcpServers\": {\n      \"aseprite\": {\n          \"command\": \"/opt/homebrew/bin/uv\",\n          \"args\": [\n              \"--directory\",\n              \"/path/to/repo\",\n              \"run\",\n              \"-m\",\n              \"aseprite_mcp\"\n          ]\n      }\n  }\n}\n```\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "art",
        "artistic",
        "ai",
        "explore art",
        "pixel art",
        "artistic cultural"
      ],
      "category": "art--culture"
    },
    "djalal--quran-mcp-server": {
      "owner": "djalal",
      "name": "quran-mcp-server",
      "url": "https://github.com/djalal/quran-mcp-server",
      "imageUrl": "",
      "description": "[raveenb/fal-mcp-server](https://github.com/raveenb/fal-mcp-server) 🐍 ☁️ - Generate AI images, videos, and music using Fal.ai models (FLUX, Stable Diffusion, MusicGen) directly in Claude Desktop",
      "stars": 50,
      "forks": 12,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-02T22:12:12Z",
      "readme_content": "# MCP Server for Quran.com API\n\nMCP server to interact with Quran.com corpus via the official [REST API v4](https://api-docs.quran.com/docs/content_apis_versioned/4.0.0/content-apis).\n\n## Overview\n\nThis is a Model Context Protocol (MCP) server generated from the [OpenAPI specification](v4.json).\n\n## Endpoints\n\nThe following endpoints from the API have been made available as tools, that LLMs can use via compatible clients.\n\n### Chapters\n* GET /chapters - List Chapters\n* GET /chapters/{id} - Get Chapter\n* GET /chapters/{chapter_id}/info - Get Chapter Info\n\n### Verses\n* GET /verses/by_chapter/{chapter_number} - Get verses by Chapter / Surah number\n* GET /verses/by_page/{page_number} - Get all verses of a specific Madani Mushaf page\n* GET /verses/by_juz/{juz_number} - Get verses by Juz number\n* GET /verses/by_hizb/{hizb_number} - Get verses by Hizb number\n* GET /verses/by_rub/{rub_el_hizb_number} - Get verses by Rub el Hizb number\n* GET /verses/by_key/{verse_key} - Get verse by key\n* GET /verses/random - Get a random verse\n\n### Juzs\n* GET /juzs - Get list of all juzs\n\n### Search\n* GET /search - Search the Quran for specific terms\n\n### Translations\n* GET /resources/translations - Get list of available translations\n* GET /resources/translations/{translation_id}/info - Get information of a specific translation\n\n### Tafsirs\n* GET /resources/tafsirs - Get list of available tafsirs\n* GET /resources/tafsirs/{tafsir_id}/info - Get the information of a specific tafsir\n* GET /quran/tafsirs/{tafsir_id} - Get a single tafsir\n\n### Audio\n* GET /resources/chapter_reciters - List of Chapter Reciters\n* GET /resources/recitation_styles - Get the available recitation styles\n\n### Languages\n* GET /resources/languages - Get all languages\n\n## Setup\n\n### Requirements\n\n* Node.js 22+\n* Docker\n\n### Building the Docker Image\n\nBefore using the Docker-based production mode, you need to build the Docker image:\n\n```bash\n# Build the Docker image\ndocker build -t quran-mcp-server .\n```\n\n## Claude Desktop Integration\n\nTo use this MCP server with Claude Desktop, add the following configuration to your `claude_desktop_config.json` file (typically located at `~/Library/Application Support/Claude/claude_desktop_config.json` on macOS or `%APPDATA%\\Claude\\claude_desktop_config.json` on Windows):\n\n### Docker-based Production Mode\n\n```json\n{\n  \"mcpServers\": {\n    \"quran-api\": {\n      \"command\": \"docker\",\n      \"args\": [\"run\", \"-i\", \"--rm\", \"--init\", \"-e\", \"API_KEY=your_api_key_if_needed\", \"-e\", \"VERBOSE_MODE=true\", \"quran-mcp-server\"],\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\n### Production Mode (Node.js)\n\n```json\n{\n  \"mcpServers\": {\n    \"quran-api\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/quran-mcp-server/dist/src/server.js\"],\n      \"env\": {\n        \"API_KEY\": \"your_api_key_if_needed\",\n        \"VERBOSE_MODE\": \"true\" // Set to \"true\" to enable verbose logging\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\n### Development Mode\n\n```json\n{\n  \"mcpServers\": {\n    \"quran-api\": {\n      \"command\": \"npx\",\n      \"args\": [\"ts-node\", \"/path/to/quran-mcp-server/src/server.ts\"],\n      \"env\": {\n        \"API_KEY\": \"your_api_key_if_needed\",\n        \"VERBOSE_MODE\": \"true\" // Set to \"true\" to enable verbose logging\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\n**Important Notes:**\n- Replace `/path/to/quran-mcp-server` with the actual path to this repository on your system\n- You'll need to build the project first with `npm run build` or `docker build -t quran-mcp-server .` if using the production mode configuration\n- Replace `your_api_key_if_needed` with an actual API key if required by the Quran.com API\n- If you already have other MCP servers configured, add this configuration to the existing `mcpServers` object\n- After updating the configuration, restart Claude Desktop for the changes to take effect\n\n## Environment Variables\n\n* `API_KEY`: API key for authentication\n* `PORT`: Server port (default: 8000 or 3000 depending on language)\n* `VERBOSE_MODE`: Set to 'true' to enable verbose logging of API requests and responses (default: false)\n\n## Verbose Mode\n\nWhen `VERBOSE_MODE` is set to 'true', the server will log detailed information about API requests and responses to the console. This is useful for debugging and monitoring API interactions.\n\nThe verbose logging includes:\n\n* **Requests**: Logs the tool name and arguments for each incoming request\n* **Responses**: Logs the tool name and result data for each response\n* **Errors**: Logs detailed error information including error name, message, and stack trace when available\n\nEach log entry is timestamped and prefixed with the log type (REQUEST, RESPONSE, or ERROR) for easy identification.\n\n## Testing\n\n```bash\n# Run tests\nnpm test\n```\n\n## License\n\nThis project is licensed under the MIT License.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ai",
        "artistic",
        "art",
        "ai images",
        "explore art",
        "artistic cultural"
      ],
      "category": "art--culture"
    },
    "drakonkat--wizzy-mcp-tmdb": {
      "owner": "drakonkat",
      "name": "wizzy-mcp-tmdb",
      "url": "https://github.com/drakonkat/wizzy-mcp-tmdb",
      "imageUrl": "",
      "description": "A MCP server for The Movie Database API that enables AI assistants to search and retrieve movie, TV show, and person information.",
      "stars": 0,
      "forks": 1,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-30T10:59:23Z",
      "readme_content": "# wizzy-mcp-tmdb\n\n[![Build Status](https://img.shields.io/github/actions/workflow/status/drakonkat/wizzy-mcp-tmdb/ci.yml)](https://github.com/drakonkat/wizzy-mcp-tmdb/actions)\n\n[![Coverage](https://img.shields.io/codecov/c/github/drakonkat/wizzy-mcp-tmdb)](https://codecov.io/gh/drakonkat/wizzy-mcp-tmdb)\n\n## Project Overview and Purpose\n\nThe wizzy-mcp-tmdb project is an MCP (Model Context Protocol) server implemented in JavaScript that provides tools to search and retrieve information from The Movie Database (TMDB). It allows AI clients to access movie, TV show, and person data through a standardized protocol.\n\n## Key Features\n\n- **Search Movies**: Perform multi-search across movies, TV shows, and people using the `search_tmdb` tool.\n- **Get Details**: Fetch detailed information for specific items using the `get_tmdb_details` tool.\n- **Trending Content**: Retrieve trending content across all media types with the `trending_all` tool.\n\n## Installation\n\n### Prerequisites\n\n- Node.js version 18 or higher (required for global fetch support)\n- A TMDB API key (Bearer token) from your admin, used with the TNL TMDB proxy (production-api.tnl.one)\n\n### Setup\n\n1. Clone the repository and navigate to the project directory.\n\n2. Install dependencies:\n\n   ```bash\n   npm install\n   ```\n\n3. Set up your TMDB API key as an environment variable:\n\n   - On Windows PowerShell:\n     ```powershell\n     $env:TMDB_AUTH_TOKEN=\"YOUR_TNL_PROXY_BEARER_TOKEN\"\n     ```\n\n   - On macOS/Linux:\n     ```bash\n     export TMDB_AUTH_TOKEN=\"YOUR_TNL_PROXY_BEARER_TOKEN\"\n     ```\n\n## Usage\n\n### Starting the MCP Server\n\nTo start the server:\n\n```bash\nnpm start\n```\n\nThe server communicates over stdio and should be configured in your MCP-compatible client (e.g., IDE or chat client) with the command `node mcp-tmdb-server.js` and the `TMDB_AUTH_TOKEN` environment variable.\n\n### MCP Integration Examples\n\nHere are code snippets showing how to integrate with the MCP tools:\n\n#### Search for Movies\n\n```javascript\n// Example MCP tool call for searching\n{\n  \"method\": \"tools/call\",\n  \"params\": {\n    \"name\": \"search_tmdb\",\n    \"arguments\": {\n      \"query\": \"dune\",\n      \"page\": 1,\n      \"language\": \"en-US\",\n      \"include_adult\": false\n    }\n  }\n}\n```\n\n#### Get Movie Details\n\n```javascript\n// Example MCP tool call for getting details\n{\n  \"method\": \"tools/call\",\n  \"params\": {\n    \"name\": \"get_tmdb_details\",\n    \"arguments\": {\n      \"type\": \"movie\",\n      \"id\": 438631,\n      \"append\": \"credits,images\"\n    }\n  }\n}\n```\n\n#### Get Trending Content\n\n```javascript\n// Example MCP tool call for trending content\n{\n  \"method\": \"tools/call\",\n  \"params\": {\n    \"name\": \"trending_all\",\n    \"arguments\": {\n      \"time_window\": \"day\",\n      \"page\": 1,\n      \"language\": \"en-US\"\n    }\n  }\n}\n```\n\n## MCP Client Integration\n\nPer integrare questo MCP server nel tuo client MCP (come un IDE o un client di chat compatibile), segui questi passi:\n\n1. Installa il pacchetto npm se necessario:\n\n   ```bash\n   npm install -g wizzy-mcp-tmdb\n   ```\n\n2. Crea o aggiorna il file `mcp.json` nel tuo client MCP con la seguente configurazione:\n\n   ```json\n   {\n     \"mcpServers\": {\n       \"tmdb\": {\n         \"command\": \"npx\",\n         \"args\": [\"wizzy-mcp-tmdb\"],\n         \"env\": {\n           \"TMDB_AUTH_TOKEN\": \"YOUR_TNL_PROXY_BEARER_TOKEN\"\n         },\n         \"alwaysAllow\": [\n           \"get_watch_providers\",\n           \"discover_tv\",\n           \"discover_by_provider\"\n         ]\n       }\n     }\n   }\n   ```\n\n   Nota: Il `TMDB_AUTH_TOKEN` può essere impostato a un valore casuale per ora, poiché le chiamate API TMDB sono gratuite e non richiedono autenticazione obbligatoria.\n\n## Testing Strategy\n\nThe project uses Jest for comprehensive testing, including:\n\n- **Unit Tests**: Validate individual handler functions, input validation, and response formatting (see `tests/unit/handlers.test.js`).\n- **Integration Tests**: Test API interactions with mocked responses, error handling, and network failures (see `tests/integration/api.test.js`).\n- **Protocol Tests**: Ensure MCP protocol compliance, including tool listing and calling (see `tests/protocol/mcp.test.js`).\n\nRun the test suite with:\n\n```bash\nnpm test\n```\n\nFor watch mode:\n\n```bash\nnpm run test:watch\n```\n\n## Project Structure\n\n```\nwizzy-mcp-tmdb/\n├── mcp-tmdb-server.js          # Main MCP server implementation\n├── package.json                # Project configuration and dependencies\n├── MCP_GUIDE.md                # Detailed MCP integration guide\n├── babel.config.cjs            # Babel configuration for Jest\n├── tests/\n│   ├── unit/\n│   │   └── handlers.test.js    # Unit tests for handlers\n│   ├── integration/\n│   │   └── api.test.js         # Integration tests for API calls\n│   └── protocol/\n│       └── mcp.test.js         # MCP protocol compliance tests\n└── tests/fixtures/             # Mock data for tests\n    ├── movieDetails.json\n    ├── searchMultiResponse.json\n    └── trendingAllResponse.json\n```\n\n## Contributing\n\nWe welcome contributions! Please follow these guidelines:\n\n1. Fork the repository.\n2. Create a feature branch.\n3. Make your changes and add tests.\n4. Ensure all tests pass.\n5. Submit a pull request.\n\n## License\n\nThis project is licensed under the MIT License. See the LICENSE file for details.\n\n## Acknowledgments\n\n- Thanks to The Movie Database (TMDB) for providing the API.\n- Built using the Model Context Protocol SDK.\n\n## Contact\n\nFor questions or support, please open an issue on GitHub.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "museum",
        "ai",
        "tmdb",
        "movie database",
        "museum databases",
        "art collections"
      ],
      "category": "art--culture"
    },
    "mikechao--metmuseum-mcp": {
      "owner": "mikechao",
      "name": "metmuseum-mcp",
      "url": "https://github.com/mikechao/metmuseum-mcp",
      "imageUrl": "",
      "description": "Metropolitan Museum of Art Collection API integration to search and display artworks in the collection.",
      "stars": 13,
      "forks": 5,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-29T15:45:19Z",
      "readme_content": "[![themet logo](https://upload.wikimedia.org/wikipedia/commons/thumb/7/73/The_Metropolitan_Museum_of_Art_Logo.svg/250px-The_Metropolitan_Museum_of_Art_Logo.svg.png)](https://www.metmuseum.org/)\n\n# Met Museum MCP Server\n\nA Model Context Protocol (MCP) server that provides access to the Metropolitan Museum of Art Collection through natural language interactions. This server allows AI models to search The Met's art collection and have art works available as a Resource.\n\n<a href=\"https://glama.ai/mcp/servers/@mikechao/metmuseum-mcp\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@mikechao/metmuseum-mcp/badge\" alt=\"Met Museum MCP Server\" /></a>\n\n[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/mikechao-metmuseum-mcp-badge.png)](https://mseep.ai/app/mikechao-metmuseum-mcp)\n\n[![Verified on MseeP](https://mseep.ai/badge.svg)](https://mseep.ai/app/ccc75a48-9b33-4a9a-8ef7-8dc3848db263)\n\n## Features\n\nThis server provides AI models the following tools to interact with the art collection of The Met\n\n### 1. List Departments (list-departments)\n\nLists all the valid departments at The Met\n\n- Inputs:\n  - None\n- Output:\n  ```\n  Department ID: 1, Display Name: American Decorative Arts\n  Department ID: 3, Display Name: Ancient Near Eastern Art\n  ...\n  ```\n\n### 2. Search Museum Objects (search-museum-objects)\n\nSearch for various objects in The Met based on the inputs.\n\n- Inputs:\n  - `q` (string): The search term e.g. sunflowers\n  - `hasImages` (boolean, optional, default: false): Only search for objects with images\n  - `title` (boolean, optional, default: false): Returns objects that match the query, specifically searching against the title field for objects.\n  - `departmentId` (number, optional): Returns objects that are a part of a specific department.\n- Outputs:\n\n  ```\n  Total objects found: 54\n  Object IDs: 436532, 789578, 436840, 438722,...\n  ```\n\n### 3. Get Museum Objects (get-museum-object)\n\nGet a specific object from The Met containing all open access data about that object, including its image (if the image is available under Open Access).\n\nIf there is an image it is added to the Resource of the server via the title of the object.\n\n- Inputs:\n  - `objectId` (number): The id of the object to retrieve\n  - `returnImage` (boolean, optional, default: true): Whether to return the image (if available) of the object and add it to the server resources\n- Outputs:\n  ```\n  Title: Self-Portrait with a Straw Hat (obverse: The Potato Peeler)\n  Artist: Vincent van Gogh\n  Artist Bio: Dutch, Zundert 1853–1890 Auvers-sur-Oise\n  Department: European Paintings\n  Credit Line: Bequest of Miss Adelaide Milton de Groot (1876-1967), 1967\n  Medium: Oil on canvas\n  Dimensions: 16 x 12 1/2 in. (40.6 x 31.8 cm)\n  Primary Image URL: https://images.metmuseum.org/CRDImages/ep/original/DT1502_cropped2.jpg\n  Tags: Men, Self-portraits\n  ```\n  If returnImage is true\n  ```\n  **base64 encoding of jpeg image**\n  ```\n\n### Usage with Claude Desktop\n\n## Via Desktop Extension (DXT)\n\n1. Download the `dxt` file from the [Releases](https://github.com/mikechao/metmuseum-mcp/releases)\n2. Open it with Claude Desktop\n   or\n   Go to File -> Settings -> Extensions and drag the .DXT file to the window to install it\n\n## Via npx\n\nAdd this to your `claude_desktop_config.json`:\n\n```json\n{\n  \"mcp-servers\": {\n    \"met-museum\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"metmuseum-mcp\"\n      ]\n    }\n  }\n}\n```\n\n### Usage with LibreChat\n\nAdd the following in your `librechat.yaml`\n\n```yaml\nmcpServers:\n  metmuseum:\n    command: npx\n    args:\n      - -y\n      - metmuseum-mcp\n```\n\n## Example queries\n\nHere some questions you can ask the AI model when this server in connected:\n\n```\nCan you show me a few painting from the Asian Art department?\nCan you find the painting titled \"Corridor in the Asylum\"?\nCan you find any art that has \"cat\" in the title or features \"cats\"?\n```\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## License\n\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.\n\n## Disclaimer\n\nThis library is not officially associated with The Metropolitan Museum of Art in New York. It is a third-party implementation of the [The Metropolitan Museum of Art Collection API](https://metmuseum.github.io/) with a MCP Server.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "museum",
        "artworks",
        "art",
        "museum art",
        "museum databases",
        "art collections"
      ],
      "category": "art--culture"
    },
    "omni-mcp--isaac-sim-mcp": {
      "owner": "omni-mcp",
      "name": "isaac-sim-mcp",
      "url": "https://github.com/omni-mcp/isaac-sim-mcp",
      "imageUrl": "",
      "description": "A MCP Server and an extension enables natural language control of NVIDIA Isaac Sim, Lab, OpenUSD and etc.",
      "stars": 84,
      "forks": 20,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-16T08:43:23Z",
      "readme_content": "# Isaac Sim MCP Extension and MCP Server\n\nThe MCP Server and its extension leverage the Model Context Protocol (MCP) framework to enable natural language control of NVIDIA Isaac Sim, transforming conversational AI inputs into precise simulation manipulation. This expansion bridges the MCP ecosystem with embodied intelligence applications.\n\n## Features\n\n- Natural language control of Isaac Sim\n- Dynamic robot positioning and movement\n- Custom lighting and scene creation\n- Advanced robot simulations with obstacle navigation\n- Interactive code preview before execution\n\n## Requirements\n\n- NVIDIA Isaac Sim 4.2.0 or higher\n- Python 3.9+\n- Cursor AI editor for MCP integration\n\n## **Mandatory** Pre-requisite\n\n- Install uv/uvx: [https://github.com/astral-sh/uv](https://github.com/astral-sh/uv)\n- Install mcp[cli] to base env: [uv pip install \"mcp[cli]\"](https://pypi.org/project/mcp/)\n\n## Installation\n\n```bash\ncd ~/Documents\ngit clone https://github.com/omni-mcp/isaac-sim-mcp\n```\n\n### Install and Enable Extension\n\nIsaac Sim extension folder should point to your project folder:\n- Extension location: `~/Documents/isaac-sim-mcp` \n- Extension ID: `isaac.sim.mcp_extension`\n\n```bash\n# Enable extension in Isaac Simulation\n# cd to your Isaac Sim installation directory\n# You can change assets root to local with --/persistent/isaac/asset_root/default=\"<your asset location>\"\n# By default it is an AWS bucket, e.g. --/persistent/isaac/asset_root/default=\"/share/Assets/Isaac/4.2\"\n# Setup API KEY for Beaver3d and NVIDIA\nexport BEAVER3D_MODEL=<your beaver3d model name>\nexport export ARK_API_KEY=<Your Bearver3D API Key>\nexport NVIDIA_API_KEY=\"<your nvidia api key  and apply it from https://ngc.nvidia.com/signout>\"\n\ncd ~/.local/share/ov/pkg/isaac-sim-4.2.0\n./isaac-sim.sh --ext-folder /home/ubuntu/Documents/isaac-sim-mcp/ --enable isaac.sim.mcp_extension \n```\n\nVerify the extension starts successfully. The output should look like:\n\n```\n[7.160s] [ext: isaac.sim.mcp_extension-0.1.0] startup\ntrigger  on_startup for:  isaac.sim.mcp_extension-0.1.0\nsettings:  {'envPath': '/home/ubuntu/.local/share/ov/data/Kit/Isaac-Sim/4.2/pip3-envs/default', 'archiveDirs': {}, 'installCheckIgnoreVersion': False, 'allowOnlineIndex': True, 'tryUpgradePipOnFirstUse': False}\nServer thread startedIsaac Sim MCP server started on localhost:8766\n```\n\nThe extension should be listening at **localhost:8766** by default.\n\n\n\n### Install MCP Server\n\n1. Go to terminal and run, make sure mcp server could start sucessfully at terminal with base venv.\n   ```\n   uv pip install \"mcp[cli]\"\n   uv run /home/ubuntu/Documents/isaac-sim-mcp/isaac_mcp/server.py\n   ```\n2. Start Cursor and open the folder `~/Documents/isaac-sim-mcp`\n3. Go to Cursor preferences, choose MCP and add a global MCP server:\n\n```json\n{\n    \"mcpServers\": {\n        \"isaac-sim\": {\n            \"command\": \"uv run /home/ubuntu/Documents/isaac-sim-mcp/isaac_mcp/server.py\"\n        }\n    }\n}\n```\n\n### Development Mode\n\nTo develop the MCP Server, start the MCP inspector:\n\n```bash\nuv run mcp dev ~/Documents/isaac-sim-mcp/isaac_mcp/server.py\n```\n\nYou can visit the debug page through http://localhost:5173\n\n## Example Prompts for Simulation\nNotice: Switch to Agent mode in top left of Chat dialog before you type prompt and choose sonnet 3.7 for better coding.\n\n### Robot Party\n```\n# Create robots and improve lighting\ncreate  3x3 frankas robots in these current stage across location [3, 0, 0] and [6, 3, 0]\nalways check connection with get_scene_info before execute code.\nadd more light in the stage\n\n\n# Add specific robots at positions\ncreate a g1 robot at [3, 9, 0]\nadd Go1 robot at location [2, 1, 0]\nmove go1 robot to [1, 1, 0]\n```\n\n### Factory Setup\n```\n# Create multiple robots in a row\nacreate  3x3 frankas robots in these current stage across location [3, 0, 0] and [6, 3, 0]\nalways check connection with get_scene_info before execute code.\nadd more light in the stage\n\n\n```\n### Vibe Coding from scratch\n```\nreference to g1.py to create an new g1 robot simulation and allow robot g1 walk straight  from [0, 0, 0] to [3, 0, 0] and [3, 3, 0]\ncreate more obstacles in the stage\n\n```\n### Gen3D with beaver3d model support\n\n```\nUse following images to generate beaver 3d objects and place them into a grid area across [0, 0, 0] to [40, 40, 0] with scale [3, 3, 3]\n\n<your image url here, could be multiple images urls>\n```\n\n### USD search\n```\nsearch a rusty desk and place it at [0, 5, 0] with scale [3, 3, 3]\n```\n\n## MCP Tools\n\nThe Isaac Sim MCP Extension provides several specialized tools that can be accessed through natural language in Cursor AI. These tools enable you to control and manipulate NVIDIA Isaac Sim with simple commands:\n\n### Connection and Scene Management\n\n- **get_scene_info** - Pings the Isaac Sim Extension Server to verify connection status and retrieve basic scene information. Always use this first to ensure the connection is active.\n\n### Physics and Environment Creation\n\n- **create_physics_scene** - Creates a physics scene with configurable parameters:\n  - `objects`: List of objects to create (each with type and position)\n  - `floor`: Whether to create a ground plane (default: true)\n  - `gravity`: Vector defining gravity direction and magnitude (default: [0, -0.981, 0])\n  - `scene_name`: Name for the scene (default: \"physics_scene\")\n\n### Robot Creation and Control\n\n- **create_robot** - Creates a robot in the scene at a specified position:\n  - `robot_type`: Type of robot to create (options: \"franka\", \"jetbot\", \"carter\", \"g1\", \"go1\")\n  - `position`: [x, y, z] position coordinates\n\n### Omniverse Kit and Scripting\n\n- **omni_kit_command** - Executes an Omni Kit command:\n  - `command`: The Omni Kit command to execute (e.g., \"CreatePrim\")\n  - `prim_type`: The primitive type for the command (e.g., \"Sphere\")\n\n- **execute_script** - Executes arbitrary Python code in Isaac Sim:\n  - `code`: Python code to execute\n\n### Usage Best Practices\n\n1. Always check connection with `get_scene_info` before executing any commands\n2. Initialize a physics scene with `create_physics_scene` before adding robots\n3. Use `create_robot` for standard robot placement before trying custom scripts\n4. For complex simulations, use `execute_script` with proper async patterns\n5. Preview code in chat before execution for verification\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## Video Demonstrations\n\nBelow are demonstrations of the Isaac Sim MCP Extension in action:\n\n### Robot Party Demo\n\n\n\n*GIF: Adding more robots to the simulation using natural language commands*\n\n\n### Video Format (MP4)\n\nFor higher quality video, you can access the MP4 version directly:\n\n- [Robot Party Demo (MP4)](media/add_more_robot_into_party.mp4)\n\nWhen viewing on GitHub, you can click the link above to view or download the MP4 file.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ai",
        "mcp",
        "art",
        "mcp isaac",
        "explore art",
        "omni mcp"
      ],
      "category": "art--culture"
    },
    "peek-travel--mcp-intro": {
      "owner": "peek-travel",
      "name": "mcp-intro",
      "url": "https://github.com/peek-travel/mcp-intro",
      "imageUrl": "",
      "description": "Remote MCP Server for discovering and planning experiences, at home and on vacation",
      "stars": 0,
      "forks": 1,
      "license": "No License",
      "language": "",
      "updated_at": "2025-09-23T16:58:01Z",
      "readme_content": "# Peek.com Remote MCP Server\n\n**AI-Powered Travel Planning:** Simplify your trip planning with the Travel Industry's first Remote MCP Server for AI Assistants.\n\n## TL;DR\n\n[Peek.com](https://peek.com)'s amazing experiences cover every major destination worldwide, 300,000+ verified activities, and millions of authentic reviews. Let AI help you find the best experiences for your next trip.\n\n### Ask Questions Like\n\n* \"Grandparents in town for weekend. Fun experiences for them and the grandkids?\"\n* \"Create a table comparing and contrasting 5 food tours in Rome, including duration, price, and what's included.\"\n* \"I have $200 and 4 hours in Tokyo. Find me the most unique cultural experiences that fit my budget and time constraints.\"\n* \"What are the pros and cons of different whale watching tours in Monterey Bay? Include pricing, duration, and success rates.\"\n\n### How to Access\n\n* MCP Server: `https://mcp.peek.com`\n* Public Page: [peek.com/mcp](https://peek.com/mcp)\n* Improvement Suggestions: [Feedback Form](https://tally.so/r/wk2Gl1)\n* Custom GPT (backup option): [Peek's OpenAI CustomGPT](https://chatgpt.com/g/g-68ba0d2499ec8191bf6e119df33ac586-peek-experiences)\n\n[Peek's MCP Server](https://peek.com/mcp) validates that the experience is actually available in the timeframe you're looking for and provides deep links making snapping up that last spot easy.\n\n### Need A Server Configuration?\n\nAlso located in the `server.json` file in this repo.\n\n```json\n{\n    \"$schema\": \"https://static.modelcontextprotocol.io/schemas/2025-07-09/server.schema.json\",\n    \"name\": \"com.peek/mcp\",\n    \"description\": \"Build travel itineraries with Peek's 300k+ experiences. Search, details, and availability!\",\n    \"status\": \"active\",\n    \"version\": \"0.1.0\",\n    \"remotes\": [\n        {\n            \"type\": \"streamable-http\",\n            \"url\": \"https://mcp.peek.com\"\n        }\n    ]\n}\n```\n\n## Why a Peek Remote MCP Server?\n\nOrganizing the perfect trip used to be a lot of work, involving many hours of research. However, thanks to generative AI assistants, building the perfect, personalized itinerary has become a breeze.\n\nToday's AIs know everything about the city you're traveling to, its attractions, the quality of the hotels, and the hidden gems.\n\n### But There's a Problem...\n\nPlanning the best things to do has remained an elusive challenge. Listed experiences often have out-of-date descriptions or are out of season or already booked out.\n\n### Introducing the Solution\n\nThis is where the [Peek.com Remote MCP Server](https://peek.com/mcp) comes in. It is a free service that makes your AI assistant smarter, giving it access to the greatest experiences with real-time availability and prices for a better trip planning experience.\n\n## What Is a Remote MCP Server?\n\nMCP stands for Model Context Protocol. It is a standard originally introduced by Anthropic in Nov 2024. It is a tool that you can connect to your AI assistant. It allows your AI assistant to request and understand information about relevant experiences as based on your prompts.\n\n## What About Privacy?\n\n[Peek's MCP Server](https://peek.com/mcp) does not collect or store any personal information that you may have shared with your AI assistant. It is designed to answer requests around experience listings, availability, and pricing in an AI friendly format.\n\n## Which Assistants Support Remote MCPs?\n\n* Claude (Anthropic) - Add \"Custom Connectors\" in Claude on web/desktop; mobile can use connectors you've added on web.\n* ChatGPT (OpenAI) - Limited support with enterprise account. Use [Peek's OpenAI CustomGPT](https://chatgpt.com/g/g-68ba0d2499ec8191bf6e119df33ac586-peek-experiences) as a backup.\n* Developer tools (Cursor, Windsurf, Augment, etc) - Yes, see tool specific documentation.\n* Gemini (Google) - Gemini CLI and SDKs can connect to remote MCP servers (OAuth, SSE/HTTP).\n* Microsoft Copilot - Copilot Studio can add MCP tools; VS Code GitHub Copilot and Visual Studio support MCP server clients; Windows is adding platform-level MCP.\n* Perplexity - No MCP support yet.\n* xAI Grok - No MCP support yet.\n\n## Where Is the Code?\n\nOffering the service as a remote service instead of a local tool makes it easier to use with your favorite AI assistant. As such, [Peek's Remote MCP Server](https://peek.com/mcp) is a proprietary service. The code for this project is not open source at this time. For any feedback, please contact us using the [Feedback Form](https://tally.so/r/wk2Gl1).\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcp",
        "explore",
        "museum",
        "explore art",
        "mcp server",
        "museum databases"
      ],
      "category": "art--culture"
    },
    "r-huijts--oorlogsbronnen-mcp": {
      "owner": "r-huijts",
      "name": "oorlogsbronnen-mcp",
      "url": "https://github.com/r-huijts/oorlogsbronnen-mcp",
      "imageUrl": "",
      "description": "Oorlogsbronnen (War Sources) API integration for accessing historical WWII records, photographs, and documents from the Netherlands (1940-1945)",
      "stars": 11,
      "forks": 4,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-07-22T13:29:18Z",
      "readme_content": "# Oorlogsbronnen MCP Server\n\nA Model Context Protocol (MCP) server that provides AI-powered access to the Oorlogsbronnen (War Sources) database. This server enables natural language interactions with historical World War II archives from the Netherlands.\n\n## Natural Language Interaction Examples\n\nAsk your AI assistant questions like these to explore Dutch WWII history:\n\n- **\"What happened during the bombing of Rotterdam in May 1940?\"**\n- **\"Tell me about Anne Frank's life in hiding based on historical records.\"**\n- **\"Show me photographs of the Dutch Hunger Winter of 1944-1945.\"**\n- **\"Were any of my ancestors imprisoned in Camp Vught during the war?\"**\n- **\"I'm visiting Arnhem next week. What historical sites related to Operation Market Garden should I see?\"**\n- **\"Find information about resistance activities in Utrecht during the Nazi occupation.\"**\n- **\"What was daily life like for Jewish families in Amsterdam before deportations began?\"**\n- **\"Show me firsthand accounts from people who witnessed the liberation of the Netherlands in 1945.\"**\n- **\"What records exist about children who were hidden by Dutch families during the war?\"**\n- **\"I'm researching the impact of WWII on Dutch infrastructure. Can you find documents about the reconstruction of bridges and railways?\"**\n\n## Features\n\n- 🔍 Natural language search across the Oorlogsbronnen database\n- 🏷️ Filter results by content type (person, photo, article, etc.)\n- 📊 Control the number of results returned\n- 🤖 AI-friendly JSON responses for further processing\n\n## Installation\n\nYou can install this server in two ways:\n\n### 1. Using Claude Desktop with NPX Package\n\nUpdate your Claude configuration file (`~/Library/Application Support/Claude/claude_desktop_config.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"oorlogsbronnen-server\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"oorlogsbronnen-mcp\"\n      ]\n    }\n  }\n}\n```\n\nAfter updating the configuration, restart Claude Desktop for the changes to take effect.\n\n### 2. From Source\n\n1. Clone this repository:\n```bash\ngit clone https://github.com/r-huijts/oorlogsbronnen-mcp.git\ncd oorlogsbronnen-mcp\n```\n\n2. Install dependencies:\n```bash\nnpm install\n```\n\n3. Build the project:\n```bash\nnpm run build\n```\n\n4. Configure Claude Desktop by updating your configuration file (located at `~/Library/Application Support/Claude/claude_desktop_config.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"oorlogsbronnen-server\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/absolute/path/to/oorlogsbronnen-mcp/dist/mcp-server.js\"\n      ]\n    }\n  }\n}\n```\n\nReplace `/absolute/path/to/oorlogsbronnen-mcp` with the actual path to your installation.\n\n## Usage Examples\n\nThe MCP server understands natural language queries and can help you explore World War II archives. Here are some example queries you can use with Claude:\n\n### Basic Searches\n\n- \"Use search_ww2_nl_archives to find documents about the resistance movement in Amsterdam\"\n- \"Search the Dutch WW2 archives for information about Jewish refugees in 1942\"\n- \"Look through the Netherlands war archives for records of Allied bombing raids\"\n\n### Filtering by Type\n\n- \"Use search_ww2_nl_archives to show me photographs of the liberation of Rotterdam\"\n- \"Find personal accounts in the Dutch WW2 archives about life in concentration camps\"\n- \"Search the Netherlands war archives for newspaper articles about food shortages\"\n\n### Specific Queries\n\n- \"Search the Dutch WW2 archives for documents about Anne Frank's time in Amsterdam\"\n- \"Use search_ww2_nl_archives to find records of the February Strike of 1941\"\n- \"Look through the Netherlands war archives for information about Operation Market Garden\"\n\n### Research Examples\n\n1. **Personal History Research**:\n   ```\n   Use search_ww2_nl_archives to find any records or documents about the Rosenberg family in Amsterdam between 1940-1945\n   ```\n\n2. **Local History**:\n   ```\n   Search the Dutch WW2 archives for photographs and documents about daily life in Utrecht during the occupation\n   ```\n\n3. **Military Operations**:\n   ```\n   Use search_ww2_nl_archives to find firsthand accounts and official reports about the Battle of the Scheldt\n   ```\n\n### Advanced Usage\n\nYou can combine different search criteria:\n```\nSearch the Netherlands WW2 archives for photographs and personal accounts of the Dutch famine in 1944-1945, limit to 20 results\n```\n\n## API Reference\n\nThe server exposes the following MCP tool:\n\n### search_ww2_nl_archives\n\nA powerful search tool designed to query the Oorlogsbronnen (War Sources) database for World War II related content in the Netherlands. This tool can be used to find historical documents, photographs, personal accounts, and other archival materials from 1940-1945.\n\n**When to use this tool:**\n- Searching for specific historical events during WWII in the Netherlands\n- Finding information about people, places, or organizations during the war\n- Locating photographs or documents from specific time periods or locations\n- Researching personal or family history related to WWII\n- Finding primary sources about the Dutch resistance, occupation, or liberation\n- Discovering materials about Jewish life and persecution during the war\n- Researching military operations that took place in the Netherlands\n\nParameters:\n- `query` (required): \n  - Type: string\n  - Description: The main search term or phrase to look for in the archives\n  - Can include: names, places, dates, events, or descriptive terms\n  - Examples:\n    - \"Anne Frank\"\n    - \"Rotterdam bombing 1940\"\n    - \"Dutch resistance Amsterdam\"\n    - \"Jewish deportation Westerbork\"\n    - \"Operation Market Garden\"\n\n- `type` (optional):\n  - Type: string\n  - Description: Filter results by specific content type\n  - Available types:\n    - \"person\": Individual biographical records\n    - \"photo\": Historical photographs\n    - \"article\": News articles and written documents\n    - \"video\": Video footage\n    - \"object\": Physical artifacts and objects\n    - \"location\": Places and geographical records\n    - \"book\": Published books, memoirs, and monographs\n  - Use when: You need to focus on specific types of historical materials\n  - Default: All types included\n\n- `count` (optional):\n  - Type: number\n  - Description: Number of results to return in the response\n  - Minimum: 1\n  - Maximum: 100\n  - Default: 10\n  - Use when: You need to control the volume of returned results\n  - Note: Larger numbers will provide more comprehensive results but may take longer to process\n\n**Response Format:**\n```json\n{\n  \"results\": [\n    {\n      \"id\": string,          // Unique identifier for the record\n      \"title\": string,       // Title or name of the item\n      \"type\": string,        // Content type (person, photo, article, etc.)\n      \"description\": string, // Detailed description (if available)\n      \"url\": string         // Direct link to view the item on Oorlogsbronnen\n    }\n  ]\n}\n```\n\n**Example Queries and Their Tool Calls:**\n\n1. Basic Historical Search:\n```typescript\n{\n  query: \"February Strike 1941\",\n  type: \"article\",\n  count: 5\n}\n```\n\n2. Person Research:\n```typescript\n{\n  query: \"Rosenberg family Amsterdam Jewish\",\n  type: \"person\",\n  count: 20\n}\n```\n\n3. Photo Collection Search:\n```typescript\n{\n  query: \"liberation celebrations Amsterdam Dam Square 1945\",\n  type: \"photo\",\n  count: 15\n}\n```\n\n**Error Handling:**\n- The tool will return an error message if:\n  - The query is empty or contains invalid characters\n  - The specified type is not supported\n  - The count is outside the valid range (1-100)\n  - The API is temporarily unavailable\n  - Rate limits are exceeded\n\n**Best Practices:**\n1. Start with broader searches and narrow down with specific terms\n2. Use location names to focus on specific areas\n3. Include dates when searching for specific events\n4. Combine person names with locations for family research\n5. Use type filtering to focus on specific kinds of historical materials\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## Acknowledgments\n\n- Oorlogsbronnen for providing access to their valuable historical archives\n- The Model Context Protocol (MCP) community for enabling AI-powered interactions ",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "museum",
        "art",
        "search",
        "museum databases",
        "art collections",
        "heritage museum"
      ],
      "category": "art--culture"
    },
    "r-huijts--rijksmuseum-mcp": {
      "owner": "r-huijts",
      "name": "rijksmuseum-mcp",
      "url": "https://github.com/r-huijts/rijksmuseum-mcp",
      "imageUrl": "",
      "description": "Rijksmuseum API integration for artwork search, details, and collections",
      "stars": 58,
      "forks": 12,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-29T15:45:22Z",
      "readme_content": "![rijksmuseum logo](https://upload.wikimedia.org/wikipedia/commons/thumb/d/d1/Logo_Rijksmuseum.svg/799px-Logo_Rijksmuseum.svg.png)\n\n# Rijksmuseum MCP Server\n\nA Model Context Protocol (MCP) server that provides access to the Rijksmuseum's collection through natural language interactions. This server enables AI models to explore, analyze, and interact with artworks and collections from the Rijksmuseum.\n\n<a href=\"https://glama.ai/mcp/servers/4rmiexp64y\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/4rmiexp64y/badge\" alt=\"Rijksmuseum Server MCP server\" /></a>\n\n## Features\n\nThe server provides several tools for interacting with the Rijksmuseum's collection:\n\n### 1. Search Artworks (`search_artwork`)\nSearch and filter artworks using various criteria including:\n- Text-based search\n- Artist name\n- Artwork type\n- Materials and techniques\n- Time periods\n- Colors\n- And more\n\n### 2. Artwork Details (`get_artwork_details`)\nRetrieve comprehensive information about specific artworks, including:\n- Basic details (title, artist, dates)\n- Physical properties\n- Historical context\n- Visual information\n- Curatorial information\n- Exhibition history\n\n### 3. High-Resolution Images (`get_artwork_image`)\nAccess high-resolution image data with deep zoom capabilities:\n- Multiple zoom levels\n- Tile-based image loading\n- Full resolution support\n- Position information\n\n### 4. User Collections (`get_user_sets` & `get_user_set_details`)\nExplore user-created collections:\n- Browse curated sets\n- View thematic groupings\n- Analyze collection patterns\n- Access detailed set information\n\n### 5. Image Viewing (`open_image_in_browser`)\nOpen artwork images directly in your browser for detailed viewing.\n\n### 6. Artist Timeline (`get_artist_timeline`)\nGenerate chronological timelines of artists' works:\n- Track artistic development\n- Analyze periods and styles\n- Study career progression\n\n## Example Use Cases\n\nHere are some example queries you can ask the AI when using this server:\n\n### Artwork Discovery\n```\n\"Show me all paintings by Rembrandt from the 1640s\"\n\"Find artworks that prominently feature the color blue\"\n\"What are the most famous masterpieces in the collection?\"\n\"Search for still life paintings from the Dutch Golden Age\"\n```\n\n### Artwork Analysis\n```\n\"Tell me everything about The Night Watch\"\n\"What are the dimensions and materials used in Van Gogh's Self Portrait?\"\n\"Show me high-resolution details of the brushwork in Vermeer's The Milkmaid\"\n\"Compare the colors used in different versions of The Potato Eaters\"\n```\n\n### Artist Research\n```\n\"Create a timeline of Rembrandt's self-portraits\"\n\"How did Van Gogh's use of color evolve throughout his career?\"\n\"Show me all works by Frans Hals in chronological order\"\n\"What techniques did Jan Steen use in his paintings?\"\n```\n\n### Thematic Exploration\n```\n\"Find all artworks depicting biblical scenes\"\n\"Show me paintings of Amsterdam in the 17th century\"\n\"What artworks feature flowers or still life arrangements?\"\n\"Find portraits that include musical instruments\"\n```\n\n### Collection Analysis\n```\n\"Show me the most popular user-curated collections\"\n\"Find sets that focus on landscape paintings\"\n\"What are the recent additions to the museum's collection?\"\n\"Show me collections featuring works from multiple artists\"\n```\n\n### Visual Details\n```\n\"Let me examine the details in the background of The Night Watch\"\n\"Show me a close-up of the jewelry in Girl with a Pearl Earring\"\n\"Can you display the highest resolution version of The Jewish Bride?\"\n\"I want to study the facial expressions in The Syndics\"\n```\n\n## Getting Started\n\nYou can install this server in two ways:\n\n### 1. Using Claude Desktop with NPM Package\nUpdate your Claude configuration file (`~/Library/Application Support/Claude/claude_desktop_config.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"rijksmuseum-server\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"mcp-server-rijksmuseum\"\n      ],\n      \"env\": {\n        \"RIJKSMUSEUM_API_KEY\": \"your_api_key_here\"\n      }\n    }\n  }\n}\n```\nYou can get an API key from the [Rijksmuseum API Portal](https://data.rijksmuseum.nl/docs/api/).\n\n### 2. From Source\n1. Clone this repository\n2. Install dependencies:\n   ```bash\n   npm install\n   ```\n3. Copy the example environment file:\n   ```bash\n   cp .env.example .env\n   ```\n4. Add your Rijksmuseum API key to the `.env` file:\n   ```\n   RIJKSMUSEUM_API_KEY=your_api_key_here\n   ```\n5. Then update your Claude configuration file:\n   ```json\n   {\n     \"mcpServers\": {\n       \"rijksmuseum-server\": {\n         \"command\": \"node\",\n         \"args\": [\n           \"/path/to/rijksmuseum-server/build/index.js\"\n         ],\n         \"env\": {\n           \"RIJKSMUSEUM_API_KEY\": \"your_api_key_here\"\n         }\n       }\n     }\n   }\n   ```\n\nMake sure to:\n- Replace `/path/to/rijksmuseum-server` with the actual path to your installation\n- Add your Rijksmuseum API key in the `env` section\n\nAfter updating the configuration, restart Claude Desktop for the changes to take effect.\n\n## Configuration\n\nThe server can be configured through environment variables:\n- `RIJKSMUSEUM_API_KEY`: Your Rijksmuseum API key (required)\n- `PORT`: Server port (default: 3000)\n- `LOG_LEVEL`: Logging level (default: 'info')\n\n## API Documentation\n\nFor detailed information about the Rijksmuseum API endpoints used by this server, visit:\n[Rijksmuseum API Documentation](https://data.rijksmuseum.nl/object-metadata/api/)\n\n## Contributing\n\nContributions are welcome! Please feel free to submit pull requests or create issues for bugs and feature requests.\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "artwork",
        "museum",
        "art",
        "artwork search",
        "art collections",
        "museum databases"
      ],
      "category": "art--culture"
    },
    "samuelgursky--davinci-resolve-mcp": {
      "owner": "samuelgursky",
      "name": "davinci-resolve-mcp",
      "url": "https://github.com/samuelgursky/davinci-resolve-mcp",
      "imageUrl": "",
      "description": "MCP server integration for DaVinci Resolve providing powerful tools for video editing, color grading, media management, and project control",
      "stars": 321,
      "forks": 31,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-03T13:15:15Z",
      "readme_content": "# DaVinci Resolve MCP Server\n\n[![Version](https://img.shields.io/badge/version-1.3.8-blue.svg)](https://github.com/samuelgursky/davinci-resolve-mcp/releases)\n[![DaVinci Resolve](https://img.shields.io/badge/DaVinci%20Resolve-18.5+-darkred.svg)](https://www.blackmagicdesign.com/products/davinciresolve)\n[![Python](https://img.shields.io/badge/python-3.6+-green.svg)](https://www.python.org/downloads/)\n[![macOS](https://img.shields.io/badge/macOS-stable-brightgreen.svg)](https://www.apple.com/macos/)\n[![Windows](https://img.shields.io/badge/Windows-stable-brightgreen.svg)](https://www.microsoft.com/windows)\n[![License](https://img.shields.io/badge/license-MIT-blue.svg)](https://opensource.org/licenses/MIT)\n\nA Model Context Protocol (MCP) server that connects AI coding assistants (Cursor, Claude Desktop) to DaVinci Resolve, enabling them to query and control DaVinci Resolve through natural language.\n\n## Features\n\nFor a comprehensive list of implemented and planned features, see [docs/FEATURES.md](docs/FEATURES.md).\n\n## Requirements\n\n- **macOS** or **Windows** with DaVinci Resolve installed\n- **Python 3.6+**\n- DaVinci Resolve running in the background\n- (Optional) Node.js/npm for some features\n\n## Installation Guide\n\nFor detailed installation instructions, please see [INSTALL.md](INSTALL.md). This guide covers:\n- Prerequisites and system requirements\n- Step-by-step installation process\n- Configuration details\n- Common troubleshooting steps\n\n## Platform Support\n\n| Platform | Status | One-Step Install | Quick Start |\n|----------|--------|------------------|-------------|\n| macOS | ✅ Stable | `./install.sh` | `./run-now.sh` |\n| Windows | ✅ Stable | `install.bat` | `run-now.bat` |\n| Linux | ❌ Not supported | N/A | N/A |\n\n## Quick Start Guide\n\n### New One-Step Installation (Recommended)\n\nThe easiest way to get started is with our new unified installation script. This script does everything automatically:\n\n- Clone the repository:\n   ```bash\n   git clone https://github.com/samuelgursky/davinci-resolve-mcp.git\n   cd davinci-resolve-mcp\n   ```\n\n- Make sure DaVinci Resolve Studio is installed and running\n\n- Run the installation script:\n   **macOS/Linux:**\n   ```bash\n   ./install.sh\n   ```\n   \n   **Windows:**\n   ```batch\n   install.bat\n   ```\n\nThis will:\n1. Automatically detect the correct paths on your system\n2. Create a Python virtual environment\n3. Install the MCP SDK from the official repository\n4. Set up environment variables\n5. Configure Cursor/Claude integration \n6. Verify the installation is correct\n7. Optionally start the MCP server\n\n### Alternative Quick Start\n\nYou can also use the original quick start scripts:\n\n**Windows Users:**\n```bash\nrun-now.bat\n``` \n\n**macOS Users:**\n```bash\nchmod +x run-now.sh\n./run-now.sh\n```\n\n## Configuration\n\nFor configuration of DaVinci Resolve MCP with different AI assistant clients like Cursor or Claude, see the [config-templates](config-templates) directory.\n\n## Troubleshooting\n\nFor detailed troubleshooting guidance, refer to the [INSTALL.md](INSTALL.md#troubleshooting) file which contains solutions to common issues.\n\n### Common Issues\n\n#### Path Resolution\n- The installation scripts now use more robust path resolution, fixing issues with `run-now.sh` looking for files in the wrong locations\n- Always let the scripts determine the correct paths based on their location\n\n#### DaVinci Resolve Detection\n- We've improved the process detection to reliably find DaVinci Resolve regardless of how it appears in the process list\n- Make sure DaVinci Resolve is running before starting the MCP server\n\n#### Environment Variables\n- Make sure all required environment variables are set correctly\n- Review the log file at `scripts/cursor_resolve_server.log` for troubleshooting\n\n### Windows\n- Make sure to use forward slashes (/) in configuration files\n- Python must be installed and paths configured in configs\n- DaVinci Resolve must be running before starting the server\n\n### macOS\n- Make sure scripts have execute permissions\n- Check Console.app for any Python-related errors\n- Verify environment variables are set correctly\n- DaVinci Resolve must be running before starting the server\n\n## Support\n\nFor issues and feature requests, please use the GitHub issue tracker.\n\n## Launch Options\n\nAfter installation, you have several ways to start the server:\n\n### Client-Specific Launch Scripts\n\nThe repository includes dedicated scripts for launching with specific clients:\n\n```bash\n# For Cursor integration (macOS)\nchmod +x scripts/mcp_resolve-cursor_start\n./scripts/mcp_resolve-cursor_start\n\n# For Claude Desktop integration (macOS)\nchmod +x scripts/mcp_resolve-claude_start\n./scripts/mcp_resolve-claude_start\n```\n\nThese specialized scripts:\n- Set up the proper environment for each client\n- Verify DaVinci Resolve is running\n- Configure client-specific settings\n- Start the MCP server with appropriate parameters\n\n### Pre-Launch Check\n\nBefore connecting AI assistants, verify your environment is properly configured:\n\n```bash\n# On macOS\n./scripts/check-resolve-ready.sh\n\n# On Windows\n./scripts/check-resolve-ready.bat\n```\n\nThese scripts will:\n- Verify DaVinci Resolve is running (and offer to start it)\n- Check environment variables are properly set\n- Ensure the Python environment is configured correctly\n- Validate Cursor/Claude configuration\n- Optionally launch Cursor\n\n### Universal Launcher\n\nFor advanced users, our unified launcher provides full control over both Cursor and Claude Desktop servers:\n\n```bash\n# Make the script executable (macOS only)\nchmod +x scripts/mcp_resolve_launcher.sh\n\n# Run in interactive mode\n./scripts/mcp_resolve_launcher.sh\n\n# Or use command line options\n./scripts/mcp_resolve_launcher.sh --start-cursor    # Start Cursor server (uses mcp_resolve-cursor_start)\n./scripts/mcp_resolve_launcher.sh --start-claude    # Start Claude Desktop server (uses mcp_resolve-claude_start)\n./scripts/mcp_resolve_launcher.sh --start-both      # Start both servers\n./scripts/mcp_resolve_launcher.sh --stop-all        # Stop all running servers\n./scripts/mcp_resolve_launcher.sh --status          # Show server status\n```\n\nAdditional options:\n- Force mode (skip Resolve running check): `--force`\n- Project selection: `--project \"Project Name\"`\n\n## Full Installation\n\nFor a complete manual installation:\n\n1. Clone this repository:\n   ```bash\n   git clone https://github.com/samuelgursky/davinci-resolve-mcp.git\n   cd davinci-resolve-mcp\n   ```\n\n2. Create a Python virtual environment:\n   ```bash\n   # Create virtual environment\n   python -m venv venv\n   \n   # Activate it\n   # On macOS/Linux:\n   source venv/bin/activate\n   # On Windows:\n   venv\\Scripts\\activate\n   \n   # Install dependencies from requirements.txt\n   pip install -r requirements.txt\n   \n   # Alternatively, install MCP SDK directly\n   pip install git+https://github.com/modelcontextprotocol/python-sdk.git\n   ```\n\n3. Set up DaVinci Resolve scripting environment variables:\n\n   **For macOS**:\n   ```bash\n   export RESOLVE_SCRIPT_API=\"/Library/Application Support/Blackmagic Design/DaVinci Resolve/Developer/Scripting\"\n   export RESOLVE_SCRIPT_LIB=\"/Applications/DaVinci Resolve/DaVinci Resolve.app/Contents/Libraries/Fusion/fusionscript.so\"\n   export PYTHONPATH=\"$PYTHONPATH:$RESOLVE_SCRIPT_API/Modules/\"\n   ```\n\n   **For Windows**:\n   ```cmd\n   set RESOLVE_SCRIPT_API=C:\\ProgramData\\Blackmagic Design\\DaVinci Resolve\\Support\\Developer\\Scripting\n   set RESOLVE_SCRIPT_LIB=C:\\Program Files\\Blackmagic Design\\DaVinci Resolve\\fusionscript.dll\n   set PYTHONPATH=%PYTHONPATH%;%RESOLVE_SCRIPT_API%\\Modules\n   ```\n   \n   Alternatively, run the pre-launch check script which will set these for you:\n   ```\n   # On macOS\n   ./scripts/check-resolve-ready.sh\n   \n   # On Windows\n   ./scripts/check-resolve-ready.bat\n   ```\n\n4. Configure Cursor to use the server by creating a configuration file:\n\n   **For macOS** (`~/.cursor/mcp.json`):\n   ```json\n   {\n     \"mcpServers\": {\n       \"davinci-resolve\": {\n         \"name\": \"DaVinci Resolve MCP\",\n         \"command\": \"/path/to/your/venv/bin/python\",\n         \"args\": [\n           \"/path/to/your/davinci-resolve-mcp/src/main.py\"\n         ]\n       }\n     }\n   }\n   ```\n\n   **For Windows** (`%APPDATA%\\Cursor\\mcp.json`):\n   ```json\n   {\n     \"mcpServers\": {\n       \"davinci-resolve\": {\n         \"name\": \"DaVinci Resolve MCP\",\n         \"command\": \"C:\\\\path\\\\to\\\\venv\\\\Scripts\\\\python.exe\",\n         \"args\": [\"C:\\\\path\\\\to\\\\davinci-resolve-mcp\\\\src\\\\main.py\"]\n       }\n     }\n   }\n   ```\n\n5. Start the server using one of the client-specific scripts:\n   ```bash\n   # For Cursor\n   ./scripts/mcp_resolve-cursor_start\n   \n   # For Claude Desktop\n   ./scripts/mcp_resolve-claude_start\n   ```\n\n## Usage with AI Assistants\n\n### Using with Cursor\n\n1. Start the Cursor server using the dedicated script:\n   ```bash\n   ./scripts/mcp_resolve-cursor_start\n   ```\n   Or use the universal launcher:\n   ```bash\n   ./scripts/mcp_resolve_launcher.sh --start-cursor\n   ```\n\n2. Start Cursor and open a project.\n\n3. In Cursor's AI chat, you can now interact with DaVinci Resolve. Try commands like:\n   - \"What version of DaVinci Resolve is running?\"\n   - \"List all projects in DaVinci Resolve\"\n   - \"Create a new timeline called 'My Sequence'\"\n   - \"Add a marker at the current position\"\n\n### Using with Claude Desktop\n\n1. Create a `claude_desktop_config.json` file in your Claude Desktop configuration directory using the template in the `config-templates` directory.\n\n2. Run the Claude Desktop server using the dedicated script:\n   ```bash\n   ./scripts/mcp_resolve-claude_start\n   ```\n   Or use the universal launcher:\n   ```bash\n   ./scripts/mcp_resolve_launcher.sh --start-claude\n   ```\n\n3. In Claude Desktop, you can now interact with DaVinci Resolve using the same commands as with Cursor.\n\n## Available Features\n\n### General\n- Get DaVinci Resolve version\n- Get/switch current page (Edit, Color, Fusion, etc.)\n\n### Project Management\n- List available projects\n- Get current project name\n- Open project by name\n- Create new project\n- Save current project\n\n### Timeline Operations\n- List all timelines\n- Get current timeline info\n- Create new timeline\n- Switch to timeline by name\n- Add marker to timeline\n\n### Media Pool Operations\n- List media pool clips\n- Import media file\n- Create media bin\n- Add clip to timeline\n\n## Windows Support Notes\n\nWindows support is stable in v1.3.3 and should not require additional troubleshooting:\n- Ensure DaVinci Resolve is installed in the default location\n- Environment variables are properly set as described above\n- Windows paths may require adjustment based on your installation\n- For issues, please check the logs in the `logs/` directory\n\n## Troubleshooting\n\n### DaVinci Resolve Connection\nMake sure DaVinci Resolve is running before starting the server. If the server can't connect to Resolve, check that:\n\n1. Your environment variables are set correctly\n2. You have the correct paths for your DaVinci Resolve installation\n3. You have restarted your terminal after setting environment variables\n\n## Project Structure\n\n```\ndavinci-resolve-mcp/\n├── README.md               # This file\n├── docs/                   # Documentation\n│   ├── FEATURES.md         # Feature list and status\n│   ├── CHANGELOG.md        # Version history\n│   ├── VERSION.md          # Version information\n│   ├── TOOLS_README.md     # Tools documentation\n│   ├── PROJECT_MCP_SETUP.md # Project setup guide\n│   └── COMMIT_MESSAGE.txt  # Latest commit information\n├── config-templates/       # Configuration templates\n│   ├── sample_config.json  # Example configuration\n│   ├── cursor-mcp-example.json # Cursor config example\n│   └── mcp-project-template.json # MCP project template\n├── scripts/                # Utility scripts\n│   ├── tests/              # Test scripts\n│   │   ├── benchmark_server.py # Performance tests\n│   │   ├── test_improvements.py # Test scripts\n│   │   ├── test_custom_timeline.py # Timeline tests\n│   │   ├── create_test_timeline.py # Create test timeline\n│   │   ├── test-after-restart.sh # Test after restart (Unix)\n│   │   └── test-after-restart.bat # Test after restart (Windows)\n│   ├── batch_automation.py # Batch automation script\n│   ├── restart-server.sh   # Server restart script (Unix)\n│   ├── restart-server.bat  # Server restart script (Windows)\n│   ├── run-now.sh          # Quick start script (Unix)\n│   └── run-now.bat         # Quick start script (Windows)\n├── resolve_mcp_server.py   # Main server implementation\n├── src/                    # Source code\n│   ├── api/                # API implementation\n│   ├── features/           # Feature modules\n│   └── utils/              # Utility functions\n├── logs/                   # Log files\n├── tools/                  # Development tools\n├── assets/                 # Project assets\n└── examples/               # Example code\n```\n\n## License\n\nMIT\n\n## Acknowledgments\n\n- Blackmagic Design for DaVinci Resolve and its API\n- The MCP protocol team for enabling AI assistant integration\n\n## Author\n\nSamuel Gursky (samgursky@gmail.com)\n- GitHub: [github.com/samuelgursky](https://github.com/samuelgursky)\n\n## Future Plans\n\n- Windows and Linux support\n- Additional DaVinci Resolve features\n- Support for Claude Desktop\n\n## Development\n\nIf you'd like to contribute, please check the feature checklist in the repo and pick an unimplemented feature to work on. The code is structured with clear sections for different areas of functionality.\n\n## License\n\nMIT\n\n## Acknowledgments\n\n- Blackmagic Design for DaVinci Resolve and its API\n- The MCP protocol team for enabling AI assistant integration\n\n## Project Structure\n\nAfter cleanup, the project has the following structure:\n\n- `resolve_mcp_server.py` - The main MCP server implementation\n- `run-now.sh` - Quick start script that handles setup and runs the server\n- `setup.sh` - Complete setup script for installation\n- `check-resolve-ready.sh` - Pre-launch check to verify DaVinci Resolve is ready\n- `start-server.sh` - Script to start the server\n- `run-server.sh` - Simplified script to run the server directly\n\n**Key Directories:**\n- `src/` - Source code and modules\n- `assets/` - Project assets and resources\n- `logs/` - Log files directory\n- `scripts/` - Helper scripts\n\nWhen developing, it's recommended to use `./run-now.sh` which sets up the environment and launches the server in one step. \n\n## Changelog\n\nSee [docs/CHANGELOG.md](docs/CHANGELOG.md) for a detailed history of changes. \n\n### Cursor-Specific Setup\n\nWhen integrating with Cursor, follow these specific steps:\n\n1. Make sure DaVinci Resolve is running before starting Cursor\n\n2. Install required dependencies:\n   ```bash\n   # From the davinci-resolve-mcp directory:\n   pip install -r requirements.txt\n   ```\n   Note: This will install the MCP package and other dependencies automatically.\n\n3. Set up the MCP server configuration in Cursor:\n   \n   Create or edit `~/.cursor/mcp.json` on macOS (or `%USERPROFILE%\\.cursor\\mcp.json` on Windows):\n   \n   ```json\n   {\n     \"mcpServers\": {\n       \"davinci-resolve\": {\n         \"name\": \"DaVinci Resolve MCP\",\n         \"command\": \"/path/to/your/venv/bin/python\",\n         \"args\": [\n           \"/path/to/your/davinci-resolve-mcp/src/main.py\"\n         ]\n       }\n     }\n   }\n   ```\n   \n   **Important Notes:**\n   - Use `main.py` as the entry point (not `resolve_mcp_server.py`)\n   - Use absolute paths in the configuration\n\n4. Common issues:\n   - \"Client closed\" error: Check that paths are correct in mcp.json and dependencies are installed\n   - Connection problems: Make sure DaVinci Resolve is running before starting Cursor\n   - Environment variables: The main.py script will handle setting environment variables",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "davinci",
        "museum",
        "art",
        "davinci resolve",
        "explore art",
        "art collections"
      ],
      "category": "art--culture"
    },
    "yuna0x0--anilist-mcp": {
      "owner": "yuna0x0",
      "name": "anilist-mcp",
      "url": "https://github.com/yuna0x0/anilist-mcp",
      "imageUrl": "",
      "description": "A MCP server integrating AniList API for anime and manga information",
      "stars": 55,
      "forks": 8,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-02T17:09:05Z",
      "readme_content": "# AniList MCP Server\n\nA Model Context Protocol (MCP) server that interfaces with the AniList API, allowing LLM clients to access and interact with anime, manga, character, staff, and user data from AniList.\n\n## Features\n\n- Search for anime, manga, characters, staff, and studios\n- Get detailed information about specific anime, manga, characters, and staff members\n- Access user profiles and lists\n- Support for advanced filtering options\n- Retrieve genres and media tags\n- **Dual transport support**: Both HTTP and STDIO transports\n- **Cloud deployment ready**: Support Smithery and other platforms\n\n## Requirements\n\n- Node.js 18+\n\n## Local Installation (STDIO Transport)\n\n1. Add this server to your `mcp.json` / `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"anilist\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"anilist-mcp\"],\n      \"env\": {\n        \"ANILIST_TOKEN\": \"your_api_token\"\n      }\n    }\n  }\n}\n```\n\nYou may remove the `env` object entirely, if you are not planning to use the AniList Token for operations that require login.\n\n2. Restart your MCP client (e.g., Claude Desktop)\n3. Use the tools to interact with AniList\n\n## Server Deployment (HTTP Transport)\n\n### Self-Hosting\nFollow the [Local Development](#local-development) instructions to set up the project locally, then run:\n```bash\npnpm run start:http\n```\nThis will start the server on port 8081 by default. You can change the port by setting the `PORT` environment variable.\n\n### Cloud Deployment\n\nYou can deploy this MCP server to any cloud platform that supports Node.js server applications.\n\nYou can also deploy via MCP platforms like [Smithery](https://smithery.ai/server/@yuna0x0/anilist-mcp).\n\n## Configuration\n### Environment Variables (STDIO Transport and HTTP Transport server where host provides the config)\n\nWhen using the STDIO transport or hosting the HTTP transport server, you can pass configuration via environment variables:\n- `ANILIST_TOKEN`: (Optional) AniList API Token (Only needed for operations that require login)\n\n> [!CAUTION]\n> If you are hosting the HTTP transport server with token pre-configured, you should protect your endpoint and implement authentication before allowing users to access it. Otherwise, anyone can access your MCP server while using your AniList token.\n\n### HTTP Headers (HTTP Transport where user provides the config)\n\nWhen using the HTTP transport, user can pass configuration via HTTP headers:\n- `Anilist-Token`: (Optional) AniList API Token (Only needed for operations that require login)\n\nIf the user provides the token in the header, while the server also has `ANILIST_TOKEN` set, the header value will take precedence.\n\n### Get an AniList API Token (Optional)\n\nTo get an API token, follow these steps:\n\n1. Go to [AniList settings](https://anilist.co/settings/developer).\n2. Click on \"Create New Client\".\n3. Use this URL as your client's \"Redirect URL\":\n```\nhttps://anilist.co/api/v2/oauth/pin\n```\n\n4. Click \"Save\"\n5. Then go to https://anilist.co/api/v2/oauth/authorize?client_id={clientID}&response_type=token, replace the `{clientID}` with the client ID you get. It will ask you to log in and then provide you with the token to use.\n6. Copy the generated token and use it in your `.env` file or environment variables.\n\n## Available Tools\n\n### Misc Tools\n- **get_genres**: Get all available genres on AniList\n- **get_media_tags**: Get all available media tags on AniList\n- **get_site_statistics**: Get AniList site statistics over the last seven days\n- **get_studio**: Get information about a studio by its AniList ID or name\n- **favourite_studio**: [Requires Login] Favourite or unfavourite a studio by its ID\n\n### Activity Tools\n- **delete_activity**: [Requires Login] Delete the current authorized user's activity post\n- **get_activity**: Get a specific AniList activity by its ID\n- **get_user_activity**: Fetch activities from a user\n- **post_message_activity**: [Requires Login] Post a new message activity or update an existing one\n- **post_text_activity**: [Requires Login] Post a new text activity or update an existing one\n\n### List Tools\n- **get_user_anime_list**: Get a user's anime list\n- **get_user_manga_list**: Get a user's manga list\n- **add_list_entry**: [Requires Login] Add an entry to the authorized user's list\n- **remove_list_entry**: [Requires Login] Remove an entry from the authorized user's list\n- **update_list_entry**: [Requires Login] Update an entry on the authorized user's list\n\n### Media Tools\n- **get_anime**: Get detailed information about an anime by its AniList ID\n- **get_manga**: Get detailed information about a manga by its AniList ID\n- **favourite_anime**: [Requires Login] Favourite or unfavourite an anime by its ID\n- **favourite_manga**: [Requires Login] Favourite or unfavourite a manga by its ID\n\n### People Tools\n- **get_character**: Get information about a character by their AniList ID\n- **get_staff**: Get information about staff member by their AniList ID\n- **favourite_character**: [Requires Login] Favourite or unfavourite a character by its ID\n- **favourite_staff**: [Requires Login] Favourite or unfavourite a staff member by their ID\n- **get_todays_birthday_characters**: Get all characters whose birthday is today\n- **get_todays_birthday_staff**: Get all staff members whose birthday is today\n\n### Recommendation Tools\n- **get_recommendation**: Get an AniList recommendation by its ID\n- **get_recommendations_for_media**: Get AniList recommendations for a specific media\n\n### Search Tools\n- **search_activity**: Search for activities on AniList\n- **search_anime**: Search for anime with query term and filters\n- **search_manga**: Search for manga with query term and filters\n- **search_character**: Search for characters based on a query term\n- **search_staff**: Search for staff members based on a query term\n- **search_studio**: Search for studios based on a query term\n- **search_user**: Search for users on AniList\n\n### Thread Tools\n- **get_thread**: Get a specific thread by its AniList ID\n- **get_thread_comments**: Get comments for a specific thread\n- **delete_thread**: [Requires Login] Delete a thread by its ID\n\n### User Tools\n- **get_user_profile**: Get a user's AniList profile\n- **get_user_stats**: Get a user's AniList statistics\n- **get_full_user_info**: Get a user's complete profile and stats information\n- **get_user_recent_activity**: Get recent activity from a user\n- **get_authorized_user**: [Requires Login] Get profile information of the currently authorized user\n- **follow_user**: [Requires Login] Follow or unfollow a user by their ID\n- **update_user**: [Requires Login] Update user settings\n\n## Example Usage\n\n### Basic Anime Search\n\n```\nCan you search for anime similar to \"Bocchi the Rock!\"?\n```\n\n### Get Character Info\n\n```\nCan you tell me about the character Hitori Gotou? Use the AniList tools to find information.\n```\n\n### Compare Studio Works\n\n```\nWhat anime has Studio Ghibli produced? Can you list their most popular works?\n```\n\n## Local Development\n\nThis project uses [pnpm](https://pnpm.io) as its package manager.\n\nClone the repository and install dependencies:\n\n```bash\ngit clone https://github.com/yuna0x0/anilist-mcp.git\ncd anilist-mcp\npnpm install\n```\n\n### Configuration (Optional)\n\n1. Create a `.env` file by copying the example:\n```bash\ncp env.example .env\n```\n\n2. Edit the `.env` file and add your AniList API token:\n```\nANILIST_TOKEN=your_api_token\n```\n\n## Debugging with MCP Inspector\n\nYou can use the MCP Inspector to test and debug the AniList MCP server:\n\n```bash\nnpx @modelcontextprotocol/inspector -e ANILIST_TOKEN=your_api_token npx anilist-mcp\n\n# Use this instead when Local Development\npnpm run inspector\n```\n\nThen open your browser to the provided URL (usually http://localhost:6274) to access the MCP Inspector interface. From there, you can:\n\n1. Connect to your running AniList MCP server\n2. Browse available tools\n3. Run tools with custom parameters\n4. View the responses\n\nThis is particularly useful for testing your setup before connecting it to MCP clients like Claude Desktop.\n\n## Docker\n\nPull from GitHub Container Registry:\n```bash\ndocker pull ghcr.io/yuna0x0/anilist-mcp\n```\n\nDocker build (Local Development):\n```bash\ndocker build -t ghcr.io/yuna0x0/anilist-mcp .\n```\n\nDocker multi-platform build (Local Development):\n```bash\ndocker buildx build --platform linux/amd64,linux/arm64 -t ghcr.io/yuna0x0/anilist-mcp .\n```\n\n## MCP Bundles (MCPB)\n\nTo create an MCP Bundle for this server, run:\n```bash\npnpm run pack:mcpb\n```\n\n## Security Notice\n\nThis MCP server accepts your AniList API token in the .env file, environment variable or HTTP header. Keep this information secure and never commit it to version control.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "anime",
        "manga",
        "art",
        "api anime",
        "manga information",
        "art collections"
      ],
      "category": "art--culture"
    }
  }
}