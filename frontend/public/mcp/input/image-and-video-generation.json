{
  "category": "image-and-video-generation",
  "categoryDisplay": "Image and Video Generation",
  "description": "",
  "totalRepositories": 135,
  "repositories": {
    "13rac1--videocapture-mcp": {
      "owner": "13rac1",
      "name": "videocapture-mcp",
      "url": "https://github.com/13rac1/videocapture-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/13rac1.webp",
      "description": "The Video Still Capture MCP server allows AI models to access and control webcams to take still images and adjust camera settings using OpenCV, without streaming video.",
      "stars": 11,
      "forks": 3,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-09-20T23:19:39Z",
      "readme_content": "# Video Still Capture MCP\n\n**A Model Context Protocol server for accessing and controlling webcams via OpenCV**\n\n## Overview\n\nVideo Still Capture MCP is a Python implementation of the Model Context Protocol (MCP) that provides AI assistants with the ability to access and control webcams and video sources through OpenCV. This server exposes a set of tools that allow language models to capture images, manipulate camera settings, and manage video connections. There is no video capture.\n\n## Examples\n\nHere are some examples of the Video Still Capture  MCP server in action:\n\n### Orange Example\nLeft: Claude's view of the image | Right: Actual webcam capture\n:-------------------------:|:-------------------------:\n | \n\n### Magnet Example\nLeft: Claude's view of the image | Right: Actual webcam capture\n:-------------------------:|:-------------------------:\n | \n\n## Installation\n\n### Prerequisites\n\n- Python 3.10+\n- [OpenCV](https://opencv.org/) (`opencv-python`)\n- [MCP Python SDK](https://modelcontextprotocol.io/docs/)\n- [UV](https://astral.sh/uv/) (optional)\n\n### Installation from source\n\n```bash\ngit clone https://github.com/13rac1/videocapture-mcp.git\ncd videocapture-mcp\npip install -e .\n```\n\nRun the MCP server:\n\n```bash\nmcp dev videocapture_mcp.py\n```\n\n## Integrating with Claude for Desktop\n\n### macOS/Linux\n\nEdit your Claude Desktop configuration:\n\n```bash\n# Mac\nnano ~/Library/Application\\ Support/Claude/claude_desktop_config.json\n# Linux\nnano ~/.config/Claude/claude_desktop_config.json \n```\n\nAdd this MCP server configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"VideoCapture \": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"run\",\n        \"--with\",\n        \"mcp[cli]\",\n        \"--with\",\n        \"numpy\",\n        \"--with\",\n        \"opencv-python\",\n        \"mcp\",\n        \"run\",\n        \"/ABSOLUTE_PATH/videocapture_mcp.py\"\n      ]\n    }\n  }\n}\n```\n\nEnsure you replace `/ABSOLUTE_PATH/videocapture-mcp` with the project's absolute path.\n\n### Windows\n\nEdit your Claude Desktop configuration:\n\n```powershell\nnano $env:AppData\\Claude\\claude_desktop_config.json\n```\n\nAdd this MCP server configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"VideoCapture\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"run\",\n        \"--with\",\n        \"mcp[cli]\",\n        \"--with\",\n        \"numpy\",\n        \"--with\",\n        \"opencv-python\",\n        \"mcp\",\n        \"run\",\n        \"C:\\ABSOLUTE_PATH\\videocapture-mcp\\videocapture_mcp.py\"\n      ]\n    }\n  }\n}\n```\n\nEnsure you replace `C:\\ABSOLUTE_PATH\\videocapture-mcp` with the project's absolute path.\n\n### Using the Installation Command\n\nAlternatively, you can use the `mcp` CLI to install the server:\n\n```bash\nmcp install videocapture_mcp.py\n```\n\nThis will automatically configure Claude Desktop to use your videocapture MCP server.\n\nOnce integrated, Claude will be able to access your webcam or video source when requested. Simply ask Claude to take a photo or perform any webcam-related task.\n\n## Features\n\n- **Quick Image Capture**: Capture a single image from a webcam without managing connections\n- **Connection Management**: Open, manage, and close camera connections\n- **Video Properties**: Read and adjust camera settings like brightness, contrast, and resolution\n- **Image Processing**: Basic image transformations like horizontal flipping\n\n## Tools Reference\n\n### `quick_capture`\n\nQuickly open a camera, capture a single frame, and close it.\n\n```python\nquick_capture(device_index: int = 0, flip: bool = False) -> Image\n```\n\n- **device_index**: Camera index (0 is usually the default webcam)\n- **flip**: Whether to horizontally flip the image\n- **Returns**: The captured frame as an Image object\n\n### `open_camera`\n\nOpen a connection to a camera device.\n\n```python\nopen_camera(device_index: int = 0, name: Optional[str] = None) -> str\n```\n\n- **device_index**: Camera index (0 is usually the default webcam)\n- **name**: Optional name to identify this camera connection\n- **Returns**: Connection ID for the opened camera\n\n### `capture_frame`\n\nCapture a single frame from the specified video source.\n\n```python\ncapture_frame(connection_id: str, flip: bool = False) -> Image\n```\n\n- **connection_id**: ID of the previously opened video connection\n- **flip**: Whether to horizontally flip the image\n- **Returns**: The captured frame as an Image object\n\n### `get_video_properties`\n\nGet properties of the video source.\n\n```python\nget_video_properties(connection_id: str) -> dict\n```\n\n- **connection_id**: ID of the previously opened video connection\n- **Returns**: Dictionary of video properties (width, height, fps, etc.)\n\n### `set_video_property`\n\nSet a property of the video source.\n\n```python\nset_video_property(connection_id: str, property_name: str, value: float) -> bool\n```\n\n- **connection_id**: ID of the previously opened video connection\n- **property_name**: Name of the property to set (width, height, brightness, etc.)\n- **value**: Value to set\n- **Returns**: True if successful, False otherwise\n\n### `close_connection`\n\nClose a video connection and release resources.\n\n```python\nclose_connection(connection_id: str) -> bool\n```\n\n- **connection_id**: ID of the connection to close\n- **Returns**: True if successful\n\n### `list_active_connections`\n\nList all active video connections.\n\n```python\nlist_active_connections() -> list\n```\n\n- **Returns**: List of active connection IDs\n\n## Example Usage\n\nHere's how an AI assistant might use the Webcam MCP server:\n\n1. **Take a quick photo**:\n   ```\n   I'll take a photo using your webcam.\n   ```\n   (The AI would call `quick_capture()` behind the scenes)\n\n2. **Open a persistent connection**:\n   ```\n   I'll open a connection to your webcam so we can take multiple photos.\n   ```\n   (The AI would call `open_camera()` and store the connection ID)\n\n3. **Adjust camera settings**:\n   ```\n   Let me increase the brightness of the webcam feed.\n   ```\n   (The AI would call `set_video_property()` with the appropriate parameters)\n\n## Advanced Usage\n\n### Resource Management\n\nThe server automatically manages camera resources, ensuring all connections are properly released when the server shuts down. For long-running applications, it's good practice to explicitly close connections when they're no longer needed.\n\n### Multiple Cameras\n\nIf your system has multiple cameras, you can specify the device index when opening a connection:\n\n```python\n# Open the second webcam (index 1)\nconnection_id = open_camera(device_index=1)\n```\n\n## Troubleshooting\n\n- **Camera Not Found**: Ensure your webcam is properly connected and not in use by another application\n- **Permission Issues**: Some systems require explicit permission to access the camera\n- **OpenCV Installation**: If you encounter issues with OpenCV, refer to the [official installation guide](https://docs.opencv.org/master/d5/de5/tutorial_py_setup_in_windows.html)\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "videocapture",
        "mcp",
        "webcams",
        "videocapture mcp",
        "mcp video",
        "13rac1 videocapture"
      ],
      "category": "image-and-video-generation"
    },
    "396001000--ComfyUI_StoryDiffusion": {
      "owner": "396001000",
      "name": "ComfyUI_StoryDiffusion",
      "url": "https://github.com/396001000/ComfyUI_StoryDiffusion",
      "imageUrl": "/freedevtools/mcp/pfp/null.webp",
      "description": "ComfyUI_StoryDiffusion allows users to create visually enhanced stories by integrating advanced image generation features into the ComfyUI platform. It utilizes the StoryDiffusion and MS-Diffusion models for creative storytelling through visuals.",
      "stars": 0,
      "forks": 0,
      "license": "Unknown",
      "language": "Unknown",
      "updated_at": "",
      "readme_content": "",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "comfyui_storydiffusion",
        "storydiffusion",
        "comfyui",
        "comfyui_storydiffusion allows",
        "comfyui_storydiffusion comfyui_storydiffusion",
        "storytelling visuals"
      ],
      "category": "image-and-video-generation"
    },
    "8bitsats--GROK_MCP": {
      "owner": "8bitsats",
      "name": "GROK_MCP",
      "url": "https://github.com/8bitsats/GROK_MCP",
      "imageUrl": "/freedevtools/mcp/pfp/null.webp",
      "description": "Analyze Solana blockchain transactions and addresses, process images through vision capabilities, and answer general queries with contextual understanding.",
      "stars": 0,
      "forks": 0,
      "license": "Unknown",
      "language": "Unknown",
      "updated_at": "",
      "readme_content": "",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "8bitsats",
        "solana",
        "blockchain",
        "solana blockchain",
        "8bitsats grok_mcp",
        "generation 8bitsats"
      ],
      "category": "image-and-video-generation"
    },
    "8bitsats--Grok-MCP": {
      "owner": "8bitsats",
      "name": "Grok-MCP",
      "url": "https://github.com/8bitsats/Grok-MCP",
      "imageUrl": "/freedevtools/mcp/pfp/8bitsats.webp",
      "description": "MCP server for generating images using Grok's AI image generation capabilities, accepting text prompts and returning images as URLs or base64-encoded data. Supports multiple image generation requests and error handling, with configuration options for API keys.",
      "stars": 7,
      "forks": 0,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-10-03T22:32:23Z",
      "readme_content": "Grok AI Image Generation MCP Server \n\n\nAI Image Generation MCP Server\n\nA server that connects to the xAI/Grok image generation API\nImplemented proper error handling with lazy API key initialization\nAdded support for multiple image generation (up to 10 images)\nAdded support for different response formats (URL or base64 JSON)\nDocker Support:\n\nAdded a Dockerfile to containerize the MCP server\nConfigured the Dockerfile with a dummy API key that can be overridden at runtime\nSet up proper layer caching for efficient builds\nMCP Tools Available:\n\ngenerate_image: Generate images using the Grok-2-image model\nset_api_key: Set the xAI API key at runtime if not provided via environment variable\nHow to Use\nYou can now generate images with prompts like:\n\n\"Generate an image of a cat in a space suit\"\n\"Create a picture of a futuristic city at night\"\nThe MCP server has been configured in your Claude desktop app, and the implementation handles API key management gracefully, allowing the server to start even without an API key initially set.\n\nIf you want to run the server in Docker, you can build and run it with:\n\ncd /Users/8bit/Documents/Cline/MCP/ai-image-generator\ndocker build -t grokart .\ndocker run -e XAI_API_KEY=your-api-key -p 8080:8080 grokart\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "grok",
        "mcp",
        "base64",
        "grok mcp",
        "using grok",
        "8bitsats grok"
      ],
      "category": "image-and-video-generation"
    },
    "Antipas--4oimage-mcp": {
      "owner": "Antipas",
      "name": "4oimage-mcp",
      "url": "https://github.com/Antipas/4oimage-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/Antipas.webp",
      "description": "Generate and edit high-quality images using text prompts. Transform existing images or create new visuals and 3D characters with real-time updates and automatic viewing in the browser.",
      "stars": 4,
      "forks": 2,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-05-26T22:44:07Z",
      "readme_content": "# 4o-image MCP Server\n\nAn MCP server implementation that integrates with 4o-image API, enabling LLMs and other AI systems to generate and edit images through a standardized protocol. Create high-quality art, 3D characters, and custom images using simple text prompts.\n\n<a href=\"https://glama.ai/mcp/servers/@Antipas/4oimage-mcp\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@Antipas/4oimage-mcp/badge\" alt=\"mcp-4o-Image-Generator MCP server\" />\n</a>\n\n[![npm version](https://img.shields.io/npm/v/4oimage-mcp.svg)](https://www.npmjs.com/package/4oimage-mcp)\n[![Node.js Version](https://img.shields.io/node/v/4oimage-mcp.svg)](https://nodejs.org)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\n## Features\n\n* **Text-to-Image Generation**: Create images from text descriptions with AI\n* **Image Editing**: Transform existing images using text prompts\n* **Real-time Progress Updates**: Get feedback on generation status\n* **Browser Integration**: Automatically open generated images in your default browser\n\n\n## Tools\n\n* **generateImage**\n  * Generate images based on text prompts with optional image editing\n  * Inputs:\n    * `prompt` (string, required): Text description of the desired image\n    * `imageBase64` (string, optional): Base64-encoded image for editing or style transfer\n\n## Configuration\n\n### Getting an API Key\n\n1. Register for an account at [4o-image.app](https://4o-image.app/dashboard/)\n2. Obtain your API key from the user dashboard\n3. Set the API key as an environment variable when running the server\n\n### Usage with Claude Desktop\n\nAdd this to your `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"4o-image\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"4oimage-mcp\"\n      ],\n      \"env\": {\n        \"API_KEY\": \"YOUR_API_KEY_HERE\"\n      }\n    }\n  }\n}\n```\n\n## Example Usage\n\nHere's an example of using this MCP server with Claude:\n\n```\nGenerate an image of a dog running on the beach at sunset\n```\n\nClaude will use the MCP server to generate the image, which will automatically open in your default browser. You'll also get a direct link to the image in Claude's response.\n\nFor image editing, you can include a base image and prompt Claude to modify it:\n\n```\nEdit this image to make the sky more dramatic with storm clouds\n```\n\n## License\n\nThis MCP server is licensed under the MIT License. You are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "antipas",
        "images",
        "4oimage",
        "antipas 4oimage",
        "4oimage mcp",
        "generation antipas"
      ],
      "category": "image-and-video-generation"
    },
    "Bob-lance--grok-mcp": {
      "owner": "Bob-lance",
      "name": "grok-mcp",
      "url": "https://github.com/Bob-lance/grok-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/Bob-lance.webp",
      "description": "Connects to Grok AI to generate chat responses, analyze images, and invoke function calls, integrating these features directly into applications using the Model Context Protocol.",
      "stars": 15,
      "forks": 7,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-13T14:48:07Z",
      "readme_content": "# Grok MCP Plugin\n\n<!-- Add badges here -->\n[![npm version](https://img.shields.io/npm/v/grok-mcp.svg?style=flat-square)](https://www.npmjs.com/package/grok-mcp) <!-- Replace with your actual package name if different -->\n[![Smithery Build Status](https://api.smithery.ai/badges/github.com/Bob-lance/grok-mcp/build-status.svg)](https://smithery.ai/Bob-lance/grok-mcp) <!-- Replace with your actual repo path -->\n\nA Model Context Protocol (MCP) plugin that provides seamless access to Grok AI's powerful capabilities directly from Cline.\n\n## Features\n\nThis plugin exposes three powerful tools through the MCP interface:\n\n1. **Chat Completion** - Generate text responses using Grok's language models\n2. **Image Understanding** - Analyze images with Grok's vision capabilities\n3. **Function Calling** - Use Grok to call functions based on user input\n\n## Prerequisites\n\n- Node.js (v16 or higher)\n- A Grok AI API key (obtain from [console.x.ai](https://console.x.ai/))\n- Cline with MCP support\n\n## Installation\n\n1. Clone this repository:\n   ```bash\n   git clone https://github.com/Bob-lance/grok-mcp.git\n   cd grok-mcp\n   ```\n\n2. Install dependencies:\n   ```bash\n   npm install\n   ```\n\n3. Build the project:\n   ```bash\n   npm run build\n   ```\n\n4. Add the MCP server to your Cline MCP settings:\n\n   For VSCode Cline extension, edit the file at:\n   ```\n   ~/Library/Application Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json\n   ```\n\n   Add the following configuration:\n   ```json\n   {\n     \"mcpServers\": {\n       \"grok-mcp\": {\n         \"command\": \"node\",\n         \"args\": [\"/path/to/grok-mcp/build/index.js\"],\n         \"env\": {\n           \"XAI_API_KEY\": \"your-grok-api-key\"\n         },\n         \"disabled\": false,\n         \"autoApprove\": []\n       }\n     }\n   }\n   ```\n\n   Replace `/path/to/grok-mcp` with the actual path to your installation and `your-grok-api-key` with your Grok AI API key.\n\n## Usage\n\nOnce installed and configured, the Grok MCP plugin provides three tools that can be used in Cline:\n\n### Chat Completion\n\nGenerate text responses using Grok's language models:\n\n```javascript\n<use_mcp_tool>\n<server_name>grok-mcp</server_name>\n<tool_name>chat_completion</tool_name>\n<arguments>\n{\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"You are a helpful assistant.\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"Hello, what can you tell me about Grok AI?\"\n    }\n  ],\n  \"temperature\": 0.7\n}\n</arguments>\n</use_mcp_tool>\n```\n\n### Image Understanding\n\nAnalyze images with Grok's vision capabilities:\n\n```javascript\n<use_mcp_tool>\n<server_name>grok-mcp</server_name>\n<tool_name>image_understanding</tool_name>\n<arguments>\n{\n  \"image_url\": \"https://example.com/image.jpg\",\n  \"prompt\": \"What is shown in this image?\"\n}\n</arguments>\n</use_mcp_tool>\n```\n\nYou can also use base64-encoded images:\n\n```javascript\n<use_mcp_tool>\n<server_name>grok-mcp</server_name>\n<tool_name>image_understanding</tool_name>\n<arguments>\n{\n  \"base64_image\": \"base64-encoded-image-data\",\n  \"prompt\": \"What is shown in this image?\"\n}\n</arguments>\n</use_mcp_tool>\n```\n\n### Function Calling\n\nUse Grok to call functions based on user input:\n\n```javascript\n<use_mcp_tool>\n<server_name>grok-mcp</server_name>\n<tool_name>function_calling</tool_name>\n<arguments>\n{\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"What's the weather like in San Francisco?\"\n    }\n  ],\n  \"tools\": [\n    {\n      \"type\": \"function\",\n      \"function\": {\n        \"name\": \"get_weather\",\n        \"description\": \"Get the current weather in a given location\",\n        \"parameters\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"location\": {\n              \"type\": \"string\",\n              \"description\": \"The city and state, e.g. San Francisco, CA\"\n            },\n            \"unit\": {\n              \"type\": \"string\",\n              \"enum\": [\"celsius\", \"fahrenheit\"],\n              \"description\": \"The unit of temperature to use\"\n            }\n          },\n          \"required\": [\"location\"]\n        }\n      }\n    }\n  ]\n}\n</arguments>\n</use_mcp_tool>\n```\n\n## API Reference\n\n### Chat Completion\n\nGenerate a response using Grok AI chat completion.\n\n**Parameters:**\n\n- `messages` (required): Array of message objects with role and content\n- `model` (optional): Grok model to use (defaults to grok-3-mini-beta)\n- `temperature` (optional): Sampling temperature (0-2, defaults to 1)\n- `max_tokens` (optional): Maximum number of tokens to generate (defaults to 16384)\n\n### Image Understanding\n\nAnalyze images using Grok AI vision capabilities.\n\n**Parameters:**\n\n- `prompt` (required): Text prompt to accompany the image\n- `image_url` (optional): URL of the image to analyze\n- `base64_image` (optional): Base64-encoded image data (without the data:image prefix)\n- `model` (optional): Grok vision model to use (defaults to grok-2-vision-latest)\n\nNote: Either `image_url` or `base64_image` must be provided.\n\n### Function Calling\n\nUse Grok AI to call functions based on user input.\n\n**Parameters:**\n\n- `messages` (required): Array of message objects with role and content\n- `tools` (required): Array of tool objects with type, function name, description, and parameters\n- `tool_choice` (optional): Tool choice mode (auto, required, none, defaults to auto)\n- `model` (optional): Grok model to use (defaults to grok-3-mini-beta)\n\n## Development\n\n### Project Structure\n\n- `src/index.ts` - Main server implementation\n- `src/grok-api-client.ts` - Grok API client implementation\n\n### Building\n\n```bash\nnpm run build\n```\n\n### Running\n\n```bash\nXAI_API_KEY=\"your-grok-api-key\" node build/index.js\n```\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Acknowledgements\n\n- [Model Context Protocol](https://github.com/modelcontextprotocol/mcp)\n- [Grok AI](https://x.ai/)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "grok",
        "protocol",
        "ai",
        "grok ai",
        "connects grok",
        "grok mcp"
      ],
      "category": "image-and-video-generation"
    },
    "CLOUDWERX-DEV--DiffuGen": {
      "owner": "CLOUDWERX-DEV",
      "name": "DiffuGen",
      "url": "https://github.com/CLOUDWERX-DEV/DiffuGen",
      "imageUrl": "/freedevtools/mcp/pfp/CLOUDWERX-DEV.webp",
      "description": "Seamlessly generate AI images directly within development environments by leveraging local Stable Diffusion models and precise control over parameters. Integrate with MCP-compatible IDEs to facilitate creative development without disruption.",
      "stars": 15,
      "forks": 6,
      "license": "MIT License",
      "language": "Shell",
      "updated_at": "2025-08-25T15:46:42Z",
      "readme_content": "# DiffuGen - Advanced Local Image Generator with MCP Integration\n\n<p align=\"center\">\n  \n</p>\n\n<p align=\"center\">\n  <em>Your AI art studio embedded directly in code. Generate, iterate, and perfect visual concepts through this powerful MCP server for Cursor, Windsurf, and other compatible IDEs, utilizing cutting-edge Flux and Stable Diffusion models without disrupting your development process.</em>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://github.com/CLOUDWERX-DEV/diffugen/stargazers\"><img src=\"https://img.shields.io/github/stars/CLOUDWERX-DEV/diffugen\" alt=\"Stars Badge\"/></a>\n  <a href=\"https://github.com/CLOUDWERX-DEV/diffugen/network/members\"><img src=\"https://img.shields.io/github/forks/CLOUDWERX-DEV/diffugen\" alt=\"Forks Badge\"/></a>\n  <a href=\"https://github.com/CLOUDWERX-DEV/diffugen/issues\"><img src=\"https://img.shields.io/github/issues/CLOUDWERX-DEV/diffugen\" alt=\"Issues Badge\"/></a>\n  <a href=\"https://github.com/CLOUDWERX-DEV/diffugen/blob/master/LICENSE\"><img src=\"https://img.shields.io/github/license/CLOUDWERX-DEV/diffugen\" alt=\"License Badge\"/></a>\n</p>\n\n> ⭐ **New**: Now includes OpenAPI server support and OpenWebUI OpenAPI Tools (OWUI Version 0.60.0 Required) integration for seamless image generation and display in chat interfaces! The OpenAPI is seperate from the MCP server and allowss for initigrations into your own projects!\n\n## 📃 Table of Contents\n\n- [Introduction](#-introduction)\n- [Understanding MCP and DiffuGen](#-understanding-mcp-and-diffugen)\n- [Features](#-features)\n- [System Requirements](#-system-requirements)\n- [Installation](#-installation)\n- [IDE Setup Instructions](#-ide-setup-instructions)\n- [Usage](#-usage)\n  - [OpenAPI Server Usage](#openapi-server-usage)\n  - [Default Parameters by Model](#default-parameters-by-model)\n  - [Asking a LLM to Generate Images](#asking-a-llm-to-generate-images)\n  - [Parameter Reference](#parameter-reference)\n  - [Model-Specific Parameter Recommendations](#model-specific-parameter-recommendations)\n  - [Default Parameter Changes](#default-parameter-changes)\n  - [Command Line Usage Notes](#command-line-usage-notes)\n- [Configuration](#️-configuration)\n  - [Configuration Approach](#configuration-approach)\n  - [Environment Variable Overrides](#environment-variable-overrides)\n  - [Setting IDE-Specific Configurations](#setting-ide-specific-configurations)\n  - [Key Configuration Elements](#key-configuration-elements)\n  - [IDE-Specific Options](#ide-specific-options)\n  - [Customizing Default Parameters](#customizing-default-parameters)\n  - [Updating Configuration Files](#updating-configuration-files)\n- [Advanced Usage](#-advanced-usage)\n  - [Using the OpenAPI Server](#using-the-openapi-server)\n- [License](#-license)\n- [Acknowledgments](#-acknowledgments)\n- [Contact](#-contact)\n\n## 🚀 Introduction\n\nDiffuGen is a powerful MCP-based image generation system that brings cutting-edge AI models directly into your development workflow. It seamlessly integrates both Flux models (Flux Schnell, Flux Dev) and Stable Diffusion variants (SDXL, SD3, SD1.5) into a unified interface, allowing you to leverage the unique strengths of each model family without switching tools. With comprehensive parameter control and multi-GPU support, DiffuGen scales from rapid concept sketches on modest hardware to production-quality visuals on high-performance systems.\n\nBuilt on top of the highly optimized [stable-diffusion.cpp](https://github.com/leejet/stable-diffusion.cpp) implementation, DiffuGen offers exceptional performance even on modest hardware while maintaining high-quality output.\n\n## 🧠 Understanding MCP and DiffuGen\n\n### What is MCP?\n\nMCP (Model Context Protocol) is a protocol that enables LLMs (Large Language Models) to access custom tools and services. In simple terms, an MCP client (like Cursor, Windsurf, Roo Code, or Cline) can make requests to MCP servers to access tools that they provide.\n\n### DiffuGen as an MCP Server\n\nDiffuGen functions as an MCP server that provides text-to-image generation capabilities. It implements the MCP protocol to allow compatible IDEs to send generation requests and receive generated images.\n\nThe server exposes two main tools:\n1. `generate_stable_diffusion_image`: Generate with Stable Diffusion models\n2. `generate_flux_image`: Generate with Flux models\n\n### Technical Architecture\n\nDiffuGen consists of several key components:\n\n- **setup-diffugen.sh**: The complete install utility and model downloader and manager\n- **diffugen.py**: The core Python script that implements the MCP server functionality and defines the generation tools\n- **diffugen.sh**: A shell script launcher that sets up the environment and launches the Python server\n- **diffugen.json**: Template configuration file for MCP integration with various IDEs (to be copied into IDE's MCP configuration)\n- **stable-diffusion.cpp**: The optimized C++ implementation of Stable Diffusion used for actual image generation\n\nThe system works by:\n1. Receiving prompt and parameter data from an MCP client\n2. Processing the request through the Python server\n3. Calling the stable-diffusion.cpp binary with appropriate parameters\n4. Saving the generated image to a configured output directory\n5. Returning the path and metadata of the generated image to the client\n\n### About stable-diffusion.cpp\n\n[stable-diffusion.cpp](https://github.com/leejet/stable-diffusion.cpp) is a highly optimized C++ implementation of the Stable Diffusion algorithm. Compared to the Python reference implementation, it offers:\n\n- Significantly faster inference speed (up to 3-4x faster)\n- Lower memory usage (works on GPUs with as little as 4GB VRAM)\n- Optimized CUDA kernels for NVIDIA GPUs\n- Support for various sampling methods and model formats\n- Support for model quantization for better performance\n- No Python dependencies for the core generation process\n\nThis allows DiffuGen to provide high-quality image generation with exceptional performance, even on modest hardware setups.\n\n## ✨ Features\n\n- **Multiple Model Support**: Generate images using various models including Flux Schnell, Flux Dev, SDXL, SD3, and SD1.5\n- **MCP Integration**: Seamlessly integrates with IDEs that support MCP (Cursor, Windsurf, Roo Code, Cline, etc.)\n- **OpenAPI Server**: Additional REST API interface for direct HTTP access to image generation capabilities\n- **Cross-Platform**: Works on Linux, macOS, and Windows (via native or WSL)\n- **Parameter Control**: Fine-tune your generations with controls for:\n  - Image dimensions (width/height)\n  - Sampling steps\n  - CFG scale\n  - Seed values\n  - Negative prompts (for SD models only, Flux does not support negative prompts.)\n  - Sampling methods\n- **CUDA Acceleration**: Utilizes GPU acceleration for faster image generation\n- **Natural Language Interface**: Generate images using simple natural language commands\n- **Smart Error Recovery**: Robust error handling with operation-aware recovery procedures\n- **User-Friendly Setup**: Interactive setup script with improved interrupt handling\n- **Resource Tracking**: Session-aware resource management for efficient cleanup\n- **Customizable Interface**: Support for custom ANSI art logos and visual enhancements\n\n## 💻 System Requirements\n\n### Minimum Requirements:\n\n- **CPU**: 4-core processor (Intel i5/AMD Ryzen 5 or equivalent)\n- **RAM**: 8GB system memory\n- **Storage**: 5GB free disk space (SSD preferred for faster model loading)\n- **Python**: 3.8 or newer\n- **GPU**: Integrated graphics or entry-level dedicated GPU (optional)\n- **Network**: Broadband connection for model downloads (5+ Mbps)\n\n### Recommended Requirements:\n\n- **CPU**: 8+ core processor (Intel i7/i9 or AMD Ryzen 7/9)\n- **RAM**: 16GB+ system memory\n- **GPU**: NVIDIA GPU with 6GB+ VRAM (RTX 2060 or better for optimal performance)\n- **Storage**: 20GB+ free SSD space\n- **Python**: 3.10 or newer (3.11 offers best performance)\n- **Network**: High-speed connection (20+ Mbps) for efficient model downloads\n\n## 📥 Installation\n\n### Automatic Installation (Recommended)\n\nThe easiest way to install DiffuGen is using the provided setup script:\n\n```bash\ngit clone https://github.com/CLOUDWERX-DEV/diffugen.git\ncd DiffuGen\nchmod +x diffugen.sh\nchmod +x setup_diffugen.sh\n./setup_diffugen.sh\n```\n\nFollow the interactive prompts to complete the installation.\n\nThe setup script will:\n- Install necessary dependencies\n- Clone and build stable-diffusion.cpp\n- Set up a Python virtual environment\n- Download selected models (Note: Some models require Clip\\VAE Models as well)\n- Configure file paths for your system\n\n### Manual Installation\n\nIf you prefer to install manually, follow these steps:\n\n1. Clone the repositories:\n\n```bash\ngit clone https://github.com/CLOUDWERX-DEV/diffugen.git\ncd DiffuGen\ngit clone --recursive https://github.com/leejet/stable-diffusion.cpp\n```\n\n2. Build stable-diffusion.cpp:\n\n```bash\ncd stable-diffusion.cpp\nmkdir -p build && cd build\n```\n\nWith CUDA:\n```bash\ncmake .. -DCMAKE_BUILD_TYPE=Release -DSD_CUDA=ON\nmake -j$(nproc)\ncd ../..\n```\n\nWithout CUDA:\n```bash\ncmake .. -DCMAKE_BUILD_TYPE=Release\nmake -j$(nproc)\ncd ../..\n```\n\n3. Create and activate a Python virtual environment:\n\n```bash\npython3 -m venv diffugen_env\nsource diffugen_env/bin/activate  # On Windows: diffugen_env\\Scripts\\activate\npip install -r requirements.txt\n```\n\n4. Download required models (structure shown below):\n\n```\nstable-diffusion.cpp/models/\n├── ae.sft                           # VAE model\n├── clip_l.safetensors               # CLIP model\n├── flux/\n│   ├── flux1-schnell-q8_0.gguf     # Flux Schnell model (default)\n│   └── flux1-dev-q8_0.gguf          # Flux Dev model\n├── sd3-medium.safetensors           # SD3 model\n├── sdxl-1.0-base.safetensors        # SDXL model\n├── sdxl_vae-fp16-fix.safetensors    # SDXL VAE\n├── t5xxl_fp16.safetensors           # T5 model\n└── v1-5-pruned-emaonly.safetensors  # SD1.5 model\n```\n\nYou can download the models from the following sources:\n\n```bash\n# Create model directories\nmkdir -p stable-diffusion.cpp/models/flux\n\n# Flux models\n# Flux Schnell - Fast generation model (Q8 Quantized,requires t5xxl, clip-l, vae)\ncurl -L https://huggingface.co/leejet/FLUX.1-schnell-gguf/resolve/main/flux1-schnell-q8_0.gguf -o stable-diffusion.cpp/models/flux/flux1-schnell-q8_0.gguf\n\n# Flux Dev - Development model with better quality (Q8 QUantized, requires t5xxl, clip-l, vae)\ncurl -L https://huggingface.co/leejet/FLUX.1-dev-gguf/resolve/main/flux1-dev-q8_0.gguf -o stable-diffusion.cpp/models/flux/flux1-dev-q8_0.gguf\n\n# Required models for Flux\n# T5XXL Text Encoder\ncurl -L https://huggingface.co/Sanami/flux1-dev-gguf/resolve/main/t5xxl_fp16.safetensors -o stable-diffusion.cpp/models/t5xxl_fp16.safetensors\n\n# CLIP-L Text Encoder\ncurl -L https://huggingface.co/Sanami/flux1-dev-gguf/resolve/main/clip_l.safetensors -o stable-diffusion.cpp/models/clip_l.safetensors\n\n# VAE for image decoding\ncurl -L https://huggingface.co/pretentioushorsefly/flux-models/resolve/main/models/vae/ae.safetensors -o stable-diffusion.cpp/models/ae.sft\n\n# Stable Diffusion models\n# SDXL 1.0 Base Model (requires sdxl-vae)\ncurl -L https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors -o stable-diffusion.cpp/models/sd_xl_base_1.0.safetensors\n\n# SDXL VAE (required for SDXL)\ncurl -L https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/resolve/main/sdxl_vae-fp16-fix.safetensors -o stable-diffusion.cpp/models/sdxl_vae-fp16-fix.safetensors\n\n# Stable Diffusion 1.5 (standalone)\ncurl -L https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors -o stable-diffusion.cpp/models/v1-5-pruned-emaonly.safetensors\n\n# Stable Diffusion 3 Medium (standalone)\ncurl -L https://huggingface.co/leo009/stable-diffusion-3-medium/resolve/main/sd3_medium_incl_clips_t5xxlfp16.safetensors -o stable-diffusion.cpp/models/sd3_medium_incl_clips_t5xxlfp16.safetensors\n```\n\nNote: Model download may take a long time depending on your internet connection. The SDXL model is approximately 6GB, SD3 is about 13GB, SD1.5 is around 4GB, and Flux models are 8-13GB each.\n\n5. Update file paths in configuration:\n\nSet shell script as Executable\n\n```\nchmod +x diffugen.sh\n```\n\n**Configuration Approach**:\nDiffuGen uses a single configuration file (`diffugen.json`) as the source of truth for all settings. The workflow is:\n\n1. Edit `diffugen.json` in the DiffuGen root directory with your desired settings\n2. Run option 5 in `setup_diffugen.sh` to automatically update paths in this file\n3. Copy the content of `diffugen.json` to your IDE's MCP configuration file\n\nThe file contains all necessary settings:\n- File paths (command, SD_CPP_PATH, models_dir, output_dir)\n- Default model parameters (steps, cfg_scale, sampling_method)\n- VRAM usage settings\n- Metadata for IDE integration\n\n```json\n{\n  \"mcpServers\": {\n    \"diffugen\": {\n      \"command\": \"/home/cloudwerxlab/Desktop/Servers/MCP/Tools/DiffuGen/diffugen.sh\",\n      \"args\": [],\n      \"env\": {\n        \"CUDA_VISIBLE_DEVICES\": \"0\",\n        \"SD_CPP_PATH\": \"path/to/stable-diffusion.cpp\",\n        \"default_model\": \"flux-schnell\"\n      },\n      \"resources\": {\n        \"models_dir\": \"path/to/stable-diffusion.cpp/models\",\n        \"output_dir\": \"path/to/outputs\",\n        \"vram_usage\": \"adaptive\"\n      },\n      \"metadata\": {\n        \"name\": \"DiffuGen\",\n        \"version\": \"1.0\",\n        \"description\": \"Your AI art studio embedded directly in code. Generate, iterate, and perfect visual concepts through this powerful MCP server for Cursor, Windsurf, and other compatible IDEs, utilizing cutting-edge Flux and Stable Diffusion models without disrupting your development process.\",\n        \"author\": \"CLOUDWERX LAB\",\n        \"homepage\": \"https://github.com/CLOUDWERX-DEV/diffugen\",\n        \"usage\": \"Generate images using two primary methods:\\n1. Standard generation: 'generate an image of [description]' with optional parameters:\\n   - model: Choose from flux-schnell (default), flux-dev, sdxl, sd3, sd15\\n   - dimensions: width and height (default: 512x512)\\n   - steps: Number of diffusion steps (default: 20, lower for faster generation)\\n   - cfg_scale: Guidance scale (default: 7.0, lower for more creative freedom)\\n   - seed: For reproducible results (-1 for random)\\n   - sampling_method: euler, euler_a (default), heun, dpm2, dpm++2s_a, dpm++2m, dpm++2mv2, lcm\\n   - negative_prompt: Specify elements to avoid in the image\\n2. Quick Flux generation: 'generate a flux image of [description]' for faster results with fewer steps (default: 4)\"\n      },\n      \"cursorOptions\": {\n        \"autoApprove\": true,\n        \"category\": \"Image Generation\",\n        \"icon\": \"🖼️\",\n        \"displayName\": \"DiffuGen\"\n      },\n      \"windsurfOptions\": {\n        \"displayName\": \"DiffuGen\",\n        \"icon\": \"🖼️\",\n        \"category\": \"Creative Tools\"\n      },\n      \"default_params\": {\n        \"steps\": {\n          \"flux-schnell\": 8,\n          \"flux-dev\": 20,\n          \"sdxl\": 20,\n          \"sd3\": 20,\n          \"sd15\": 20\n        },\n        \"cfg_scale\": {\n          \"flux-schnell\": 1.0,\n          \"flux-dev\": 1.0,\n          \"sdxl\": 7.0,\n          \"sd3\": 7.0, \n          \"sd15\": 7.0\n        },\n        \"sampling_method\": {\n          \"flux-schnell\": \"euler\",\n          \"flux-dev\": \"euler\",\n          \"sdxl\": \"euler\",\n          \"sd3\": \"euler\",\n          \"sd15\": \"euler\"\n        }\n      }\n    }\n  }\n}\n```\n\n## 🔧 IDE Setup Instructions\n\n### Setting up with Cursor\n\n1. Download and install [Cursor](https://cursor.sh)\n2. Go to Cursor Settings > MCP and click \"Add new global MCP server\"\n3. **Copy the contents of your DiffuGen's `diffugen.json` file** and paste it into `~/.cursor/mcp.json`\n4. Refresh MCP Servers in Settings > MCP\n5. Use DiffuGen by opening the AI chat panel (Ctrl+K or Cmd+K) and requesting image generation\n\n### Setting up with Windsurf\n\n1. Download and install [Windsurf](https://codeium.com/windsurf)\n2. Navigate to Windsurf > Settings > Advanced Settings or Command Palette > Open Windsurf Settings Page\n3. Scroll down to the Cascade section and click \"Add Server\" > \"Add custom server +\"\n4. **Copy the contents of your DiffuGen's `diffugen.json` file** and paste into `~/.codeium/windsurf/mcp_config.json`\n5. Use DiffuGen through the Cascade chat interface\n\n### Setting up with Roo Code\n\n1. Download and install [Roo Code](https://roo.ai)\n2. Locate the MCP configuration file for Roo Code\n3. **Copy the contents of your DiffuGen's `diffugen.json` file** into Roo Code's MCP configuration\n4. Use DiffuGen through the AI assistant feature\n\n### Setting up with Cline\n\n1. Download and install [Cline](https://cline.live)\n2. **Copy the contents of your DiffuGen's `diffugen.json` file** into Cline's MCP settings\n3. Use DiffuGen through the AI chat or command interface\n\n### Setting up with Claude in Anthropic Console\n\nClaude can use DiffuGen if you've set it up as an MCP server on your system. When asking Claude to generate images, be specific about using DiffuGen and provide the parameters you want to use.\n\n## 🎮 Usage\n\nTo start the DiffuGen server manually:\n\n```bash\ncd /path/to/diffugen\n./diffugen.sh\n```\n\nOr using Python directly:\n\n```bash\ncd /path/to/diffugen\npython -m diffugen\n```\n\nYou should see: `DiffuGen ready` when the server is successfully started.\n\n### OpenAPI Server Usage\n\nThe OpenAPI server provides a REST API interface for direct HTTP access to DiffuGen's image generation capabilities. This is in addition to the MCP integration and can be useful for:\n- Direct HTTP API access\n- Integration with other tools that don't support MCP\n- Custom applications that need programmatic access\n\nFor detailed setup instructions and advanced configuration options, see the [OpenAPI Integration Guide](OPENAPI_SETUP.md).\n\nTo start the OpenAPI server:\n```bash\npython diffugen_openapi.py\n```\n\nThe server can be configured to use a different host or port if needed. By default, it runs on:\n- Host: 0.0.0.0\n- Port: 8080\n\nThe server will be available at http://0.0.0.0:8080 with interactive documentation at http://0.0.0.0:8080/docs.\n\nGenerated images are saved to the `/output` directory by default. If this directory is not accessible, the server will automatically create an `output` directory in the current working directory. Images are served through the `/images` endpoint.\n\n#### OpenWebUI Integration\n\n1. Open OpenWebUI Settings (gear icon)\n2. Navigate to the \"Tools\" section\n3. Click the \"+\" button to add a new tool server\n4. Enter the following details:\n   - URL: http://0.0.0.0:5199\n   - API Key: (leave empty)\n5. Click \"Save\"\n\nOnce added, DiffuGen will appear in the available tools list when clicking the tools icon in the chat interface. The following endpoints will be available:\n- `generate_stable_image_generate_stable_post`: Generate with Stable Diffusion\n- `generate_flux_image_endpoint_generate_flux_post`: Generate with Flux Models\n- `list_models_models_get`: List Available Models\n\nExample using curl:\n```bash\ncurl -X POST \"http://0.0.0.0:5199/generate/flux\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"prompt\": \"A beautiful sunset\", \"model\": \"flux-schnell\"}'\n```\n\nExample using Python requests:\n```python\nimport requests\n\nresponse = requests.post(\n    \"http://0.0.0.0:5199/generate/flux\",\n    json={\n        \"prompt\": \"A beautiful sunset\",\n        \"model\": \"flux-schnell\"\n    }\n)\nresult = response.json()\n```\n\n### Default Parameters by Model\n\nEach model has specific default parameters optimized for best results:\n\n| Model | Default Steps | Default CFG Scale | Best For |\n|-------|--------------|-----------------|----------|\n| flux-schnell | 8 | 1.0 | Fast drafts, conceptual images |\n| flux-dev | 20 | 1.0 | Better quality flux generations |\n| sdxl | 20 | 7.0 | High-quality detailed images |\n| sd3 | 20 | 7.0 | Latest generation with good quality |\n| sd15 | 20 | 7.0 | Classic baseline model |\n\nThese default parameters can be customized by adding a `default_params` section to your IDE's MCP configuration file:\n\n```json\n\"default_params\": {\n  \"steps\": {\n    \"flux-schnell\": 12,  // Customize steps for better quality\n    \"sdxl\": 30           // Increase steps for more detailed SDXL images\n  },\n  \"cfg_scale\": {\n    \"sd15\": 9.0          // Higher cfg_scale for stronger prompt adherence\n  }\n}\n```\n\nYou only need to specify the parameters you want to override - any unspecified values will use the built-in defaults.\n\n> **Note**: For model-specific command line examples and recommendations, see [Model-Specific Parameter Recommendations](#model-specific-parameter-recommendations) section.\n\n### Asking a LLM to Generate Images\n\nHere are examples of how to ask an AI assistant to generate images with DiffuGen:\n\n#### Basic Requests:\n\n```\nGenerate an image of a cat playing with yarn\n```\n\n```\nCreate a picture of a futuristic cityscape with flying cars\n```\n\n#### With Model Specification:\n\n```\nGenerate an image of a medieval castle using the sdxl model\n```\n\n```\nCreate a flux image of a sunset over mountains\n```\n\n#### With Advanced Parameters:\n\n```\nGenerate an image of a cyberpunk street scene, model=flux-dev, width=768, height=512, steps=25, cfg_scale=1.0, seed=42\n```\n\n```\nCreate an illustration of a fantasy character with model=sd15, width=512, height=768, steps=30, cfg_scale=7.5, sampling_method=dpm++2m, negative_prompt=blurry, low quality, distorted\n```\n\n### Parameter Reference\n\nDiffuGen can be used from the command line with the following basic syntax:\n\n```bash\n./diffugen.sh \"Your prompt here\" [options]\n```\n\nExample:\n```bash\n./diffugen.sh \"A futuristic cityscape with flying cars\"\n```\n\nThis command generates an image using default parameters (flux-schnell model, 512x512 resolution, etc.) and saves it to the configured output directory.\n\nBelow are the parameters that can be used with DiffuGen (applicable to both MCP interface and command line):\n\n| Parameter | Description | Default | Valid Values | Command Line Flag |\n|-----------|-------------|---------|-------------|-------------------|\n| model | The model to use for generation | flux-schnell/sd15 | flux-schnell, flux-dev, sdxl, sd3, sd15 | --model |\n| width | Image width in pixels | 512 | 256-2048 | --width |\n| height | Image height in pixels | 512 | 256-2048 | --height |\n| steps | Number of diffusion steps | model-specific | 1-100 | --steps |\n| cfg_scale | Classifier-free guidance scale | model-specific | 0.1-30.0 | --cfg-scale |\n| seed | Random seed for reproducibility | -1 (random) | -1 or any integer | --seed |\n| sampling_method | Diffusion sampling method | euler | euler, euler_a, heun, dpm2, dpm++2s_a, dpm++2m, dpm++2mv2, lcm | --sampling-method |\n| negative_prompt | Elements to avoid in the image | \"\" (empty) | Any text string | --negative-prompt |\n| output_dir | Directory to save images | Config-defined | Valid path | --output-dir |\n\nThese parameters can be specified when asking an AI assistant to generate images or when using the command line interface. Parameters are passed in different formats depending on the interface:\n\n- **In MCP/AI Assistant**: `parameter=value` (e.g., `model=sdxl, width=768, height=512`)\n- **In Command Line**: `--parameter value` (e.g., `--model sdxl --width 768 --height 512`)\n\nThe default values are chosen to provide good results out-of-the-box with minimal waiting time. For higher quality images, consider increasing steps or switching to models like sdxl.\n\n### Model-Specific Parameter Recommendations\n\n> **Note**: These recommendations build on the [Default Parameters by Model](#default-parameters-by-model) section and provide practical examples.\n\nFor best results when using specific models via command line:\n\n#### Flux Models (flux-schnell, flux-dev)\n```bash\n# Flux-Schnell (fastest)\n./diffugen.sh \"Vibrant colorful abstract painting\" \\\n  --model flux-schnell \\\n  --cfg-scale 1.0 \\\n  --sampling-method euler \\\n  --steps 8\n\n# Flux-Dev (better quality)\n./diffugen.sh \"Detailed fantasy landscape with mountains and castles\" \\\n  --model flux-dev \\\n  --cfg-scale 1.0 \\\n  --sampling-method euler \\\n  --steps 20\n```\n\n#### Standard SD Models (sdxl, sd3, sd15)\n```bash\n# SDXL (highest quality)\n./diffugen.sh \"Hyperrealistic portrait of a Celtic warrior\" \\\n  --model sdxl \\\n  --cfg-scale 7.0 \\\n  --sampling-method dpm++2m \\\n  --steps 30\n\n# SD15 (classic model)\n./diffugen.sh \"Photorealistic landscape at sunset\" \\\n  --model sd15 \\\n  --cfg-scale 7.0 \\\n  --sampling-method euler_a \\\n  --steps 20\n```\n\n### Default Parameter Changes\n\nThe command-line interface of DiffuGen uses the following defaults if not otherwise specified in configuration:\n\n- Default Model: If not specified, function-appropriate models are used (flux-schnell for Flux functions, sd15 for SD functions)\n- Default Sampling Method: `euler` (best for Flux models)\n- Default CFG Scale: `1.0` for Flux models, `7.0` for standard SD models\n- Default Steps: `8` for flux-schnell, `20` for other models\n- Default Dimensions: 512x512 pixels\n\nWhen using the command line, you don't need to specify these parameters unless you want to override the defaults. If you frequently use specific parameters, consider adding them to your configuration file rather than specifying them on each command line.\n\n### Command Line Usage Notes\n\n- Generated images are saved to the configured output directory with filenames based on timestamp and parameters\n- You can generate multiple images in sequence by running the command multiple times\n- For batch processing, consider creating a shell script that calls DiffuGen with different parameters\n- To see all available command-line options, run `./diffugen.sh --help`\n- The same engine powers both the MCP interface and command-line tool, so quality and capabilities are identical\n\n## ⚙️ Configuration\n\n### Configuration Approach\n\nDiffuGen uses a single configuration approach centered around the `diffugen.json` file:\n\n1. **Primary Configuration File**: `diffugen.json` in the DiffuGen root directory is the single source of truth for all settings\n2. **IDE Integration**: Copy the contents of `diffugen.json` to your IDE's MCP configuration file\n3. **Environment Variables**: For advanced usage, you can override settings with environment variables\n\n### Environment Variable Overrides\n\nFor advanced usage, you can override settings using environment variables:\n\n- `SD_CPP_PATH`: Override the path to stable-diffusion.cpp\n- `DIFFUGEN_OUTPUT_DIR`: Override the output directory\n- `DIFFUGEN_DEFAULT_MODEL`: Override the default model\n- `DIFFUGEN_VRAM_USAGE`: Override VRAM usage settings\n- `CUDA_VISIBLE_DEVICES`: Control which GPUs are used for generation\n\n### Setting IDE-Specific Configurations\n\nDiffuGen allows you to have different configurations for different IDEs by using environment variables in each IDE's MCP configuration. This lets you maintain a single base `diffugen.json` while customizing parameters per IDE.\n\nThe configuration priority works as follows:\n1. Environment variables (highest priority)\n2. Settings from local `diffugen.json` file (base configuration)\n\n**Example: Different Output Directories for Different IDEs**\n\nFor Cursor (in `~/.cursor/mcp.json`):\n```json\n\"env\": {\n  \"CUDA_VISIBLE_DEVICES\": \"0\",\n  \"SD_CPP_PATH\": \"/path/to/stable-diffusion.cpp\",\n  \"DIFFUGEN_OUTPUT_DIR\": \"/cursor/specific/output/directory\",\n  \"default_model\": \"flux-schnell\"\n}\n```\n\nFor Windsurf (in `~/.codeium/windsurf/mcp_config.json`):\n```json\n\"env\": {\n  \"CUDA_VISIBLE_DEVICES\": \"0\",\n  \"SD_CPP_PATH\": \"/path/to/stable-diffusion.cpp\",\n  \"DIFFUGEN_OUTPUT_DIR\": \"/windsurf/specific/output/directory\",\n  \"default_model\": \"sdxl\"\n}\n```\n\n**Example: Different Default Models and VRAM Settings**\n\n```json\n\"env\": {\n  \"CUDA_VISIBLE_DEVICES\": \"0\",\n  \"SD_CPP_PATH\": \"/path/to/stable-diffusion.cpp\",\n  \"default_model\": \"flux-dev\", \n  \"DIFFUGEN_VRAM_USAGE\": \"maximum\"\n}\n```\n\nThis approach lets you customize DiffuGen's behavior per IDE while still using the same underlying installation.\n\n### Key Configuration Elements\n\n#### Command and Arguments\n\n- **command**: Full path to the `diffugen.sh` script (must be absolute path)\n- **args**: Additional command-line arguments to pass to the script (usually left empty)\n\n#### Environment Variables\n\n- **CUDA_VISIBLE_DEVICES**: Controls which GPUs are used for generation\n  - `\"0\"`: Use only the first GPU\n  - `\"1\"`: Use only the second GPU\n  - `\"0,1\"`: Use both first and second GPUs\n  - `\"-1\"`: Disable CUDA and use CPU only\n\n- **SD_CPP_PATH**: Path to the stable-diffusion.cpp installation directory\n  - This is used to locate the stable-diffusion.cpp binary and models\n\n- **default_model**: The default model to use when none is specified\n\n#### Resource Configuration\n\n- **models_dir**: Directory containing the model files\n  - Should point to the `models` directory inside your stable-diffusion.cpp installation\n\n- **output_dir**: Directory where generated images will be saved\n  - Must be writable by the user running DiffuGen\n\n- **vram_usage**: Controls VRAM usage strategy\n  - `\"adaptive\"`: Automatically adjust memory usage based on available VRAM\n  - `\"minimal\"`: Use minimal VRAM at the cost of speed\n  - `\"balanced\"`: Balance memory usage and speed (default)\n  - `\"maximum\"`: Use maximum available VRAM for best performance\n\n### IDE-Specific Options\n\nEach IDE has specific options you can customize in the `diffugen.json` file:\n\n#### Cursor Options\n\n```json\n\"cursorOptions\": {\n  \"autoApprove\": true,\n  \"category\": \"Image Generation\",\n  \"icon\": \"🖼️\",\n  \"displayName\": \"DiffuGen\"\n}\n```\n\n#### Windsurf Options\n\n```json\n\"windsurfOptions\": {\n  \"displayName\": \"DiffuGen\",\n  \"icon\": \"🖼️\",\n  \"category\": \"Creative Tools\"\n}\n```\n\n### Customizing Default Parameters\n\nYou can customize default parameters for each model in the `default_params` section:\n\n```json\n\"default_params\": {\n  \"steps\": {\n    \"flux-schnell\": 12,\n    \"sdxl\": 30\n  },\n  \"cfg_scale\": {\n    \"sd15\": 9.0\n  },\n  \"sampling_method\": {\n    \"flux-schnell\": \"euler\",\n    \"sdxl\": \"dpm++2m\"\n  }\n}\n```\n\n### Updating Configuration Files\n\nWhen using the automatic setup script, a properly configured `diffugen.json` file is created with the correct paths for your system when you run option 5. To integrate DiffuGen with your IDE:\n\n1. Run option 5 in `setup_diffugen.sh` to update paths in `diffugen.json`\n2. Copy the entire contents of the generated `diffugen.json` file\n3. Paste it into your IDE's MCP configuration file (e.g., `~/.cursor/mcp.json`)\n4. Restart your IDE to apply changes\n\nThe key advantage of this approach is a single source of truth for configuration, making it easier to maintain and update your DiffuGen setup.\n\n## 📃 Advanced Usage\n\nThe DiffuGen Python module can be imported and used programmatically in your own Python scripts:\n\n```python\nfrom diffugen import generate_image\n\n# Generate an image programmatically\nresult = generate_image(\n    prompt=\"A starry night over a quiet village\",\n    model=\"sdxl\",\n    width=1024,\n    height=768,\n    steps=30,\n    cfg_scale=7.0,\n    seed=42,\n    sampling_method=\"dpm++2m\",\n    negative_prompt=\"blurry, low quality\"\n)\n\nprint(f\"Image saved to: {result['file_path']}\")\n```\n\n### Using the OpenAPI Server\n\nYou can also use the OpenAPI server programmatically in your applications:\n\n```python\nimport requests\n\ndef generate_image_via_api(prompt, model=\"flux-schnell\", width=512, height=512):\n    response = requests.post(\n        \"http://0.0.0.0:5199/generate/flux\",\n        json={\n            \"prompt\": prompt,\n            \"model\": model,\n            \"width\": width,\n            \"height\": height\n        }\n    )\n    return response.json()\n\n# Example usage\nresult = generate_image_via_api(\n    prompt=\"A magical forest at night\",\n    model=\"flux-schnell\",\n    width=768,\n    height=512\n)\nprint(f\"Generated image: {result['file_path']}\")\n```\n\n## 🔍 Troubleshooting\n\n### Common Issues and Solutions\n\n1. **Missing models or incorrect paths**\n   - Ensure all model files are downloaded and placed in the correct directories\n   - Check that paths in the configuration file are correctly set\n   - Verify file permissions allow read access to model files\n\n2. **CUDA/GPU issues**\n   - Make sure your NVIDIA drivers are up-to-date\n   - Set `CUDA_VISIBLE_DEVICES` to target a specific GPU\n   - If running out of VRAM, try using a smaller model or reducing dimensions\n\n3. **Image quality issues**\n   - Increase steps for better quality (at the cost of generation time)\n   - Adjust CFG scale: higher for more prompt adherence, lower for creativity\n   - Try different sampling methods (dpm++2m often provides good results)\n   - Use more detailed prompts with specific style descriptions\n\n4. **File permission errors**\n   - Ensure the output directory is writable by the user running DiffuGen\n   - Check that all scripts have execution permissions (`chmod +x diffugen.sh`)\n\n### Getting Help\n\nIf you encounter issues not covered here, you can:\n- Check the GitHub repository for issues and solutions\n- Run with debug logging enabled: `DEBUG=1 ./diffugen.sh \"your prompt\"`\n- Contact the developers via GitHub issues\n\n## 🌟 Contributing\n\nContributions to DiffuGen are welcome! To contribute:\n\n1. Fork the repository\n2. Create a feature branch\n3. Make your changes\n4. Submit a pull request\n\nPlease ensure your code follows the project's coding standards and includes appropriate tests.\n\n## 📄 License\n\nThis project is licensed under the Apache License - see the LICENSE file for details.\n\n* All models are licensed under their respective distribution and are not in any way licensed or provided by CLOUDWERX.DEV\n* HuggingFace.co is used to download models and is not affiliated in any way with CLOUDWERX.DEV\n\n## 🙏 Acknowledgments\n\n- [stable-diffusion.cpp](https://github.com/leejet/stable-diffusion.cpp) for the optimized C++ implementation\n- [Stability AI](https://stability.ai/) for Stable Diffusion models\n- [Black Forest Labs](https://blackforestlabs.ai/) for their Flux Models\n- [Hugging Face](https://huggingface.co/) for the download links\n- All contributors to the MCP protocol\n\n## 📬 Contact\n\n- GitHub: [CLOUDWERX-DEV](https://github.com/CLOUDWERX-DEV)\n- Website: [cloudwerx.dev](http://cloudwerx.dev)\n- Mail: [sysop@cloudwerx.dev](mailto:sysop@cloudwerx.dev)\n- Discord: [Join our server](https://discord.gg/SvZFuufNTQ)\n\n```\n                   ______   __   ___   ___         _______              \n                  |   _  \\ |__|.'  _|.'  _|.--.--.|   _   |.-----.-----.\n                  |.  |   \\|  ||   _||   _||  |  ||.  |___||  -__|     |\n                  |.  |    \\__||__|  |__|  |_____||.  |   ||_____|__|__|\n                  |:  1    /                      |:  1   |             \n                  |::.. . /                       |::.. . |             \n                  `------'                        `-------'             \n```\n\n<p align=\"center\">\n  Made with ❤️ by CLOUDWERX LAB\n</p>",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ai",
        "cloudwerx",
        "dev",
        "generate ai",
        "ai images",
        "generation cloudwerx"
      ],
      "category": "image-and-video-generation"
    },
    "CLOUDWERX-DEV--gpt-image-1-mcp": {
      "owner": "CLOUDWERX-DEV",
      "name": "gpt-image-1-mcp",
      "url": "https://github.com/CLOUDWERX-DEV/gpt-image-1-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/CLOUDWERX-DEV.webp",
      "description": "Enables AI assistants to generate and edit images from text prompts, supporting both creation and modification of images using specified masks. Integrates with various MCP clients and provides flexible workflows for image handling, including automatic file saving and comprehensive error reporting.",
      "stars": 16,
      "forks": 5,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-15T19:40:52Z",
      "readme_content": "<p align=\"center\">\n  \n</p>\n\n<h1 align=\"center\">@cloudwerxlab/gpt-image-1-mcp</h1>\n\n<p align=\"center\">\n  <a href=\"https://www.npmjs.com/package/@cloudwerxlab/gpt-image-1-mcp\"><img src=\"https://img.shields.io/npm/v/@cloudwerxlab/gpt-image-1-mcp.svg\" alt=\"npm version\"></a>\n  <a href=\"https://www.npmjs.com/package/@cloudwerxlab/gpt-image-1-mcp\"><img src=\"https://img.shields.io/npm/dm/@cloudwerxlab/gpt-image-1-mcp.svg\" alt=\"npm downloads\"></a>\n  <a href=\"https://github.com/CLOUDWERX-DEV/gpt-image-1-mcp/blob/main/LICENSE\"><img src=\"https://img.shields.io/github/license/CLOUDWERX-DEV/gpt-image-1-mcp.svg\" alt=\"license\"></a>\n  <a href=\"https://nodejs.org/\"><img src=\"https://img.shields.io/node/v/@cloudwerxlab/gpt-image-1-mcp.svg\" alt=\"node version\"></a>\n  <a href=\"https://cloudwerx.dev\"><img src=\"https://img.shields.io/badge/website-cloudwerx.dev-blue\" alt=\"Website\"></a>\n</p>\n\n<p align=\"center\">\n  A Model Context Protocol (MCP) server for generating and editing images using the OpenAI <code>gpt-image-1</code> model.\n</p>\n\n<p align=\"center\">\n  <img src=\"https://img.shields.io/badge/OpenAI-GPT--Image--1-6E46AE\" alt=\"OpenAI GPT-Image-1\">\n  <img src=\"https://img.shields.io/badge/MCP-Compatible-00A3E0\" alt=\"MCP Compatible\">\n</p>\n\n## 🚀 Quick Start\n\n<div align=\"center\">\n  <a href=\"https://www.npmjs.com/package/@cloudwerxlab/gpt-image-1-mcp\"><img src=\"https://img.shields.io/badge/NPX-Ready-red.svg\" alt=\"NPX Ready\"></a>\n</div>\n\n<p align=\"center\">Run this MCP server directly using NPX without installing it. <a href=\"https://www.npmjs.com/package/@cloudwerxlab/gpt-image-1-mcp\">View on npm</a>.</p>\n\n```bash\nnpx -y @cloudwerxlab/gpt-image-1-mcp\n```\n\n<p align=\"center\">The <code>-y</code> flag automatically answers \"yes\" to any prompts that might appear during the installation process.</p>\n\n### 📋 Prerequisites\n\n<table>\n  <tr>\n    <td width=\"50%\" align=\"center\">\n      <img src=\"https://img.shields.io/badge/Node.js-v14+-339933?logo=node.js&logoColor=white\" alt=\"Node.js v14+\">\n      <p>Node.js (v14 or higher)</p>\n    </td>\n    <td width=\"50%\" align=\"center\">\n      <img src=\"https://img.shields.io/badge/OpenAI-API_Key-412991?logo=openai&logoColor=white\" alt=\"OpenAI API Key\">\n      <p>OpenAI API key with access to gpt-image-1</p>\n    </td>\n  </tr>\n</table>\n\n### 🔑 Environment Variables\n\n<table>\n  <tr>\n    <th>Variable</th>\n    <th>Required</th>\n    <th>Description</th>\n  </tr>\n  <tr>\n    <td><code>OPENAI_API_KEY</code></td>\n    <td>✅ Yes</td>\n    <td>Your OpenAI API key with access to the gpt-image-1 model</td>\n  </tr>\n  <tr>\n    <td><code>GPT_IMAGE_OUTPUT_DIR</code></td>\n    <td>❌ No</td>\n    <td>Custom directory for saving generated images (defaults to user's Pictures folder under <code>gpt-image-1</code> subfolder)</td>\n  </tr>\n</table>\n\n### 💻 Example Usage with NPX\n\n<table>\n  <tr>\n    <th>Operating System</th>\n    <th>Command Line Example</th>\n  </tr>\n  <tr>\n    <td><strong>Linux/macOS</strong></td>\n    <td>\n\n```bash\n# Set your OpenAI API key\nexport OPENAI_API_KEY=sk-your-openai-api-key\n\n# Optional: Set custom output directory\nexport GPT_IMAGE_OUTPUT_DIR=/home/username/Pictures/ai-generated-images\n\n# Run the server with NPX\nnpx -y @cloudwerxlab/gpt-image-1-mcp\n```\n  </tr>\n  <tr>\n    <td><strong>Windows (PowerShell)</strong></td>\n    <td>\n\n```powershell\n# Set your OpenAI API key\n$env:OPENAI_API_KEY = \"sk-your-openai-api-key\"\n\n# Optional: Set custom output directory\n$env:GPT_IMAGE_OUTPUT_DIR = \"C:\\Users\\username\\Pictures\\ai-generated-images\"\n\n# Run the server with NPX\nnpx -y @cloudwerxlab/gpt-image-1-mcp\n```\n  </tr>\n  <tr>\n    <td><strong>Windows (Command Prompt)</strong></td>\n    <td>\n\n```cmd\n:: Set your OpenAI API key\nset OPENAI_API_KEY=sk-your-openai-api-key\n\n:: Optional: Set custom output directory\nset GPT_IMAGE_OUTPUT_DIR=C:\\Users\\username\\Pictures\\ai-generated-images\n\n:: Run the server with NPX\nnpx -y @cloudwerxlab/gpt-image-1-mcp\n```\n  </tr>\n</table>\n\n## 🔌 Integration with MCP Clients\n\n<div align=\"center\">\n  <img src=\"https://img.shields.io/badge/VS_Code-MCP_Extension-007ACC?logo=visual-studio-code&logoColor=white\" alt=\"VS Code MCP Extension\">\n  <img src=\"https://img.shields.io/badge/Roo-Compatible-FF6B6B\" alt=\"Roo Compatible\">\n  <img src=\"https://img.shields.io/badge/Cursor-Compatible-4C2889\" alt=\"Cursor Compatible\">\n  <img src=\"https://img.shields.io/badge/Augment-Compatible-6464FF\" alt=\"Augment Compatible\">\n  <img src=\"https://img.shields.io/badge/Windsurf-Compatible-00B4D8\" alt=\"Windsurf Compatible\">\n</div>\n\n### 🛠️ Setting Up in an MCP Client\n\n<table>\n  <tr>\n    <td>\n      <h4>Step 1: Locate Settings File</h4>\n      <ul>\n        <li>For <strong>Roo</strong>: <code>c:\\Users\\&lt;username&gt;\\AppData\\Roaming\\Code\\User\\globalStorage\\rooveterinaryinc.roo-cline\\settings\\mcp_settings.json</code></li>\n        <li>For <strong>VS Code MCP Extension</strong>: Check your extension documentation for the settings file location</li>\n        <li>For <strong>Cursor</strong>: <code>~/.config/cursor/mcp_settings.json</code> (Linux/macOS) or <code>%APPDATA%\\Cursor\\mcp_settings.json</code> (Windows)</li>\n        <li>For <strong>Augment</strong>: <code>~/.config/augment/mcp_settings.json</code> (Linux/macOS) or <code>%APPDATA%\\Augment\\mcp_settings.json</code> (Windows)</li>\n        <li>For <strong>Windsurf</strong>: <code>~/.config/windsurf/mcp_settings.json</code> (Linux/macOS) or <code>%APPDATA%\\Windsurf\\mcp_settings.json</code> (Windows)</li>\n      </ul>\n    </td>\n  </tr>\n  <tr>\n    <td>\n      <h4>Step 2: Add Configuration</h4>\n      <p>Add the following configuration to the <code>mcpServers</code> object:</p>\n    </td>\n  </tr>\n</table>\n\n```json\n{\n  \"mcpServers\": {\n    \"gpt-image-1\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@cloudwerxlab/gpt-image-1-mcp\"\n      ],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"PASTE YOUR OPEN-AI KEY HERE\",\n        \"GPT_IMAGE_OUTPUT_DIR\": \"OPTIONAL: PATH TO SAVE GENERATED IMAGES\"\n      }\n    }\n  }\n}\n```\n\n#### Example Configurations for Different Operating Systems\n\n<table>\n  <tr>\n    <th>Operating System</th>\n    <th>Example Configuration</th>\n  </tr>\n  <tr>\n    <td><strong>Windows</strong></td>\n    <td>\n\n```json\n{\n  \"mcpServers\": {\n    \"gpt-image-1\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@cloudwerxlab/gpt-image-1-mcp\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"sk-your-openai-api-key\",\n        \"GPT_IMAGE_OUTPUT_DIR\": \"C:\\\\Users\\\\username\\\\Pictures\\\\ai-generated-images\"\n      }\n    }\n  }\n}\n```\n  </tr>\n  <tr>\n    <td><strong>Linux/macOS</strong></td>\n    <td>\n\n```json\n{\n  \"mcpServers\": {\n    \"gpt-image-1\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@cloudwerxlab/gpt-image-1-mcp\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"sk-your-openai-api-key\",\n        \"GPT_IMAGE_OUTPUT_DIR\": \"/home/username/Pictures/ai-generated-images\"\n      }\n    }\n  }\n}\n```\n  </tr>\n</table>\n\n> **Note**: For Windows paths, use double backslashes (`\\\\`) to escape the backslash character in JSON. For Linux/macOS, use forward slashes (`/`).\n\n## ✨ Features\n\n<div align=\"center\">\n  <table>\n    <tr>\n      <td align=\"center\">\n        <h3>🎨 Core Tools</h3>\n        <ul>\n          <li><code>create_image</code>: Generate new images from text prompts</li>\n          <li><code>create_image_edit</code>: Edit existing images with text prompts and masks</li>\n        </ul>\n      </td>\n      <td align=\"center\">\n        <h3>🚀 Key Benefits</h3>\n        <ul>\n          <li>Simple integration with MCP clients</li>\n          <li>Full access to OpenAI's gpt-image-1 capabilities</li>\n          <li>Streamlined workflow for AI image generation</li>\n        </ul>\n      </td>\n    </tr>\n  </table>\n</div>\n\n### 💡 Enhanced Capabilities\n\n<table>\n  <tr>\n    <td>\n      <h4>📊 Output & Formatting</h4>\n      <ul>\n        <li>✅ <strong>Beautifully Formatted Output</strong>: Responses include emojis and detailed information</li>\n        <li>✅ <strong>Automatic Image Saving</strong>: All generated images saved to disk for easy access</li>\n        <li>✅ <strong>Detailed Token Usage</strong>: View token consumption for each request</li>\n      </ul>\n    </td>\n    <td>\n      <h4>⚙️ Configuration & Handling</h4>\n      <ul>\n        <li>✅ <strong>Configurable Output Directory</strong>: Customize where images are saved</li>\n        <li>✅ <strong>File Path Support</strong>: Edit images using file paths instead of base64 encoding</li>\n        <li>✅ <strong>Comprehensive Error Handling</strong>: Detailed error reporting with specific error codes, descriptions, and troubleshooting suggestions</li>\n      </ul>\n    </td>\n  </tr>\n</table>\n\n## 🔄 How It Works\n\n<div align=\"center\">\n  <table>\n    <tr>\n      <th align=\"center\">🖼️ Image Generation</th>\n      <th align=\"center\">✏️ Image Editing</th>\n    </tr>\n    <tr>\n      <td>\n        <ol>\n          <li>Server receives prompt and parameters</li>\n          <li>Calls OpenAI API using gpt-image-1 model</li>\n          <li>API returns base64-encoded images</li>\n          <li>Server saves images to configured directory</li>\n          <li>Returns formatted response with paths and metadata</li>\n        </ol>\n      </td>\n      <td>\n        <ol>\n          <li>Server receives image, prompt, and optional mask</li>\n          <li>For file paths, reads and prepares files for API</li>\n          <li>Uses direct curl command for proper MIME handling</li>\n          <li>API returns base64-encoded edited images</li>\n          <li>Server saves images to configured directory</li>\n          <li>Returns formatted response with paths and metadata</li>\n        </ol>\n      </td>\n    </tr>\n  </table>\n</div>\n\n### 📁 Output Directory Behavior\n\n<table>\n  <tr>\n    <td width=\"50%\">\n      <h4>📂 Storage Location</h4>\n      <ul>\n        <li>🔹 <strong>Default Location</strong>: User's Pictures folder under <code>gpt-image-1</code> subfolder (e.g., <code>C:\\Users\\username\\Pictures\\gpt-image-1</code> on Windows)</li>\n        <li>🔹 <strong>Custom Location</strong>: Set via <code>GPT_IMAGE_OUTPUT_DIR</code> environment variable</li>\n        <li>🔹 <strong>Fallback Location</strong>: <code>./generated-images</code> (if Pictures folder can't be determined)</li>\n      </ul>\n    </td>\n    <td width=\"50%\">\n      <h4>🗂️ File Management</h4>\n      <ul>\n        <li>🔹 <strong>Directory Creation</strong>: Automatically creates output directory if it doesn't exist</li>\n        <li>🔹 <strong>File Naming</strong>: Images saved with timestamped filenames (e.g., <code>image-2023-05-05T12-34-56-789Z.png</code>)</li>\n        <li>🔹 <strong>Cross-Platform</strong>: Works on Windows, macOS, and Linux with appropriate Pictures folder detection</li>\n      </ul>\n    </td>\n  </tr>\n</table>\n\n## Installation & Usage\n\n### NPM Package\n\nThis package is available on npm: [@cloudwerxlab/gpt-image-1-mcp](https://www.npmjs.com/package/@cloudwerxlab/gpt-image-1-mcp)\n\nYou can install it globally:\n\n```bash\nnpm install -g @cloudwerxlab/gpt-image-1-mcp\n```\n\nOr run it directly with npx as shown in the Quick Start section.\n\n### Tool: `create_image`\n\nGenerates a new image based on a text prompt.\n\n#### Parameters\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `prompt` | string | Yes | The text description of the image to generate (max 32,000 chars) |\n| `size` | string | No | Image size: \"1024x1024\" (default), \"1536x1024\", or \"1024x1536\" |\n| `quality` | string | No | Image quality: \"high\" (default), \"medium\", or \"low\" |\n| `n` | integer | No | Number of images to generate (1-10, default: 1) |\n| `background` | string | No | Background style: \"transparent\", \"opaque\", or \"auto\" (default) |\n| `output_format` | string | No | Output format: \"png\" (default), \"jpeg\", or \"webp\" |\n| `output_compression` | integer | No | Compression level (0-100, default: 0) |\n| `user` | string | No | User identifier for OpenAI usage tracking |\n| `moderation` | string | No | Moderation level: \"low\" or \"auto\" (default) |\n\n#### Example\n\n```xml\n<use_mcp_tool>\n<server_name>gpt-image-1</server_name>\n<tool_name>create_image</tool_name>\n<arguments>\n{\n  \"prompt\": \"A futuristic city skyline at sunset, digital art\",\n  \"size\": \"1024x1024\",\n  \"quality\": \"high\",\n  \"n\": 1,\n  \"background\": \"auto\"\n}\n</arguments>\n</use_mcp_tool>\n```\n\n#### Response\n\nThe tool returns:\n- A formatted text message with details about the generated image(s)\n- The image(s) as base64-encoded data\n- Metadata including token usage and file paths\n\n### Tool: `create_image_edit`\n\nEdits an existing image based on a text prompt and optional mask.\n\n#### Parameters\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `image` | string, object, or array | Yes | The image(s) to edit (base64 string or file path object) |\n| `prompt` | string | Yes | The text description of the desired edit (max 32,000 chars) |\n| `mask` | string or object | No | The mask that defines areas to edit (base64 string or file path object) |\n| `size` | string | No | Image size: \"1024x1024\" (default), \"1536x1024\", or \"1024x1536\" |\n| `quality` | string | No | Image quality: \"high\" (default), \"medium\", or \"low\" |\n| `n` | integer | No | Number of images to generate (1-10, default: 1) |\n| `background` | string | No | Background style: \"transparent\", \"opaque\", or \"auto\" (default) |\n| `user` | string | No | User identifier for OpenAI usage tracking |\n\n#### Example with Base64 Encoded Image\n\n```xml\n<use_mcp_tool>\n<server_name>gpt-image-1</server_name>\n<tool_name>create_image_edit</tool_name>\n<arguments>\n{\n  \"image\": \"BASE64_ENCODED_IMAGE_STRING\",\n  \"prompt\": \"Add a small robot in the corner\",\n  \"mask\": \"BASE64_ENCODED_MASK_STRING\",\n  \"quality\": \"high\"\n}\n</arguments>\n</use_mcp_tool>\n```\n\n#### Example with File Path\n\n```xml\n<use_mcp_tool>\n<server_name>gpt-image-1</server_name>\n<tool_name>create_image_edit</tool_name>\n<arguments>\n{\n  \"image\": {\n    \"filePath\": \"C:/path/to/your/image.png\"\n  },\n  \"prompt\": \"Add a small robot in the corner\",\n  \"mask\": {\n    \"filePath\": \"C:/path/to/your/mask.png\"\n  },\n  \"quality\": \"high\"\n}\n</arguments>\n</use_mcp_tool>\n```\n\n#### Response\n\nThe tool returns:\n- A formatted text message with details about the edited image(s)\n- The edited image(s) as base64-encoded data\n- Metadata including token usage and file paths\n\n## 🔧 Troubleshooting\n\n<div align=\"center\">\n  <img src=\"https://img.shields.io/badge/Support-Available-brightgreen\" alt=\"Support Available\">\n</div>\n\n### 🚨 Common Issues\n\n<table>\n  <tr>\n    <th align=\"center\">Issue</th>\n    <th align=\"center\">Solution</th>\n  </tr>\n  <tr>\n    <td>\n      <h4>🖼️ MIME Type Errors</h4>\n      <p>Errors related to image format or MIME type handling</p>\n    </td>\n    <td>\n      <p>Ensure image files have the correct extension (.png, .jpg, etc.) that matches their actual format. The server uses file extensions to determine MIME types.</p>\n    </td>\n  </tr>\n  <tr>\n    <td>\n      <h4>🔑 API Key Issues</h4>\n      <p>Authentication errors with OpenAI API</p>\n    </td>\n    <td>\n      <p>Verify your OpenAI API key is correct and has access to the gpt-image-1 model. Check for any spaces or special characters that might have been accidentally included.</p>\n    </td>\n  </tr>\n  <tr>\n    <td>\n      <h4>🛠️ Build Errors</h4>\n      <p>Issues when building from source</p>\n    </td>\n    <td>\n      <p>Ensure you have the correct TypeScript version installed (v5.3.3 or compatible) and that your <code>tsconfig.json</code> is properly configured. Run <code>npm install</code> to ensure all dependencies are installed.</p>\n    </td>\n  </tr>\n  <tr>\n    <td>\n      <h4>📁 Output Directory Issues</h4>\n      <p>Problems with saving generated images</p>\n    </td>\n    <td>\n      <p>Check if the process has write permissions to the configured output directory. Try using an absolute path for <code>GPT_IMAGE_OUTPUT_DIR</code> if relative paths aren't working.</p>\n    </td>\n  </tr>\n</table>\n\n### 🔍 Error Handling and Reporting\n\nThe MCP server includes comprehensive error handling that provides detailed information when something goes wrong. When an error occurs:\n\n1. **Error Format**: All errors are returned with:\n   - A clear error message describing what went wrong\n   - The specific error code or type\n   - Additional context about the error when available\n\n2. **AI Assistant Behavior**: When using this MCP server with AI assistants:\n   - The AI will always report the full error message to help with troubleshooting\n   - The AI will explain the likely cause of the error in plain language\n   - The AI will suggest specific steps to resolve the issue\n\n## 📄 License\n\n<div align=\"center\">\n  <a href=\"LICENSE\"><img src=\"https://img.shields.io/badge/License-MIT-blue.svg\" alt=\"MIT License\"></a>\n</div>\n\n<p align=\"center\">\n  This project is licensed under the MIT License - see the <a href=\"LICENSE\">LICENSE</a> file for details.\n</p>\n\n<details>\n  <summary>License Summary</summary>\n\n  <p>The MIT License is a permissive license that is short and to the point. It lets people do anything with your code with proper attribution and without warranty.</p>\n\n  <p><strong>You are free to:</strong></p>\n  <ul>\n    <li>Use the software commercially</li>\n    <li>Modify the software</li>\n    <li>Distribute the software</li>\n    <li>Use and modify the software privately</li>\n  </ul>\n\n  <p><strong>Under the following terms:</strong></p>\n  <ul>\n    <li>Include the original copyright notice and the license notice in all copies or substantial uses of the work</li>\n  </ul>\n\n  <p><strong>Limitations:</strong></p>\n  <ul>\n    <li>The authors provide no warranty with the software and are not liable for any damages</li>\n  </ul>\n</details>\n\n## 🙏 Acknowledgments\n\n<div align=\"center\">\n  <table>\n    <tr>\n      <td align=\"center\">\n        <a href=\"https://openai.com/\">\n          <img src=\"https://img.shields.io/badge/OpenAI-412991?logo=openai&logoColor=white\" alt=\"OpenAI\">\n          <p>For providing the gpt-image-1 model</p>\n        </a>\n      </td>\n      <td align=\"center\">\n        <a href=\"https://github.com/model-context-protocol/mcp\">\n          <img src=\"https://img.shields.io/badge/MCP-Protocol-00A3E0\" alt=\"MCP Protocol\">\n          <p>For the protocol specification</p>\n        </a>\n      </td>\n    </tr>\n  </table>\n</div>\n\n<div align=\"center\">\n  <p>\n    <a href=\"https://github.com/CLOUDWERX-DEV/gpt-image-1-mcp/issues\">Report Bug</a> •\n    <a href=\"https://github.com/CLOUDWERX-DEV/gpt-image-1-mcp/issues\">Request Feature</a> •\n    <a href=\"https://cloudwerx.dev\">Visit Our Website</a>\n  </p>\n</div>\n\n<div align=\"center\">\n  <p>\n    Developed with ❤️ by <a href=\"https://cloudwerx.dev\">CLOUDWERX</a>\n  </p>\n</div>",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "cloudwerx",
        "mcp",
        "images",
        "image mcp",
        "gpt image",
        "generation cloudwerx"
      ],
      "category": "image-and-video-generation"
    },
    "CaullenOmdahl--pexels-mcp-server": {
      "owner": "CaullenOmdahl",
      "name": "pexels-mcp-server",
      "url": "https://github.com/CaullenOmdahl/pexels-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/CaullenOmdahl.webp",
      "description": "Access and retrieve photos, videos, and collections from Pexels using a standardized protocol. Supports search by various criteria and provides detailed information about media content.",
      "stars": 4,
      "forks": 6,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-07-30T15:07:46Z",
      "readme_content": "# Pexels MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@CaullenOmdahl/pexels-mcp-server)](https://smithery.ai/server/@CaullenOmdahl/pexels-mcp-server)\n\nA Model Context Protocol (MCP) server that provides access to the Pexels API, allowing AI models to search for and retrieve photos, videos, and collections from Pexels.\n\n## Features\n\n- Search for photos and videos by query, orientation, size, and color\n- Access curated and popular content from Pexels\n- Browse Pexels collections\n- Get detailed information about specific photos and videos\n- Access content via tools or direct URI resources\n\n## Requirements\n\n- Node.js 18 or higher\n- A Pexels API key (get one at [https://www.pexels.com/api/](https://www.pexels.com/api/))\n\n## Local Development\n\n1. Clone the repository\n2. Install dependencies\n   ```bash\n   pnpm install\n   ```\n3. Build the project\n   ```bash\n   pnpm build\n   ```\n4. Run in development mode\n   ```bash\n   PEXELS_API_KEY=your_api_key pnpm dev\n   ```\n\n## Deploying to Smithery\n\nThis MCP server is ready to be deployed to Smithery. Follow these steps:\n\n1. Add the server to Smithery or claim an existing server\n2. Go to the Deployments tab (only visible to authenticated owners)\n3. Deploy the server\n4. When configuring the deployment, provide your Pexels API key in the configuration settings\n\n## API Usage\n\nThe server provides the following tools:\n\n### Photo Tools\n\n- `searchPhotos`: Search for photos by query (use descriptive keywords for relevant results, e.g., 'Thai hotel reception', 'red sports car driving', not just 'hotel' or 'car'; combine with parameters like `orientation`, `size`, `color`, and `locale` for refined results), with optional filters for orientation, size, color, locale (e.g., 'en-US', 'es-ES'), page, and results per page. Returns metadata including photo IDs and URLs, plus current API rate limit status.\n- `downloadPhoto`: Fetches a specific photo by its ID and desired size (optional, defaults to 'original'). Available sizes: 'original', 'large2x', 'large', 'medium', 'small', 'portrait', 'landscape', 'tiny'. Returns a direct download link for the requested image size, suggested filename (including size), and attribution information. The AI client should use its available local tools (like `curl` or PowerShell's `Invoke-WebRequest`) to download the photo using the provided link.\n- `getCuratedPhotos`: Retrieve a curated set of photos from Pexels, optionally paginated.\n- `getPhoto`: Retrieve detailed information about a specific photo by its ID.\n\n### Video Tools\n\n- `searchVideos`: Search for videos by query (use descriptive keywords for relevant results, e.g., 'drone footage beach sunset', 'time lapse city traffic', not just 'beach' or 'city'; combine with parameters like `orientation` and `size` for refined results), with optional filters for orientation, size, locale (e.g., 'en-US', 'es-ES'), page, and results per page. Returns metadata including video IDs and URLs, plus current API rate limit status.\n- `getPopularVideos`: Retrieve a list of popular videos from Pexels, with optional filters for dimensions, duration, page, and results per page.\n- `getVideo`: Retrieve detailed information about a specific video by its ID.\n- `downloadVideo`: Fetches a specific video by its ID and preferred quality (hd/sd). Returns a direct download link, suggested filename, and attribution information. The AI client should use its available local tools (like `curl` or PowerShell's `Invoke-WebRequest`) to download the video using the provided link.\n\n### Collection Tools\n\n- `getFeaturedCollections`: Retrieve a list of featured collections from Pexels, optionally paginated.\n- ~~`getMyCollections`~~: (Commented out in code) Requires OAuth 2.0 authentication, not supported by this server.\n- `getCollectionMedia`: Retrieve media items (photos or videos) from a specific collection by collection ID, with optional filters for type, sort order, page, and results per page.\n\n### Resources\n\nThe server provides the following URI-addressable resources:\n\n- `pexels-photo://{id}`: Access a specific photo by ID\n- `pexels-video://{id}`: Access a specific video by ID\n- `pexels-collection://{id}`: Access a specific collection by ID\n\n## Error Handling\n\nThe server attempts to provide informative error messages for common issues like invalid API keys, rate limits, or missing resources. Successful responses also include the current Pexels API rate limit status (remaining requests, reset time) in the output.\n\n## Attribution Requirements\n\nWhen using the Pexels API, you must follow their attribution requirements:\n\n- Always show a prominent link to Pexels (e.g., \"Photos provided by Pexels\")\n- Always credit photographers (e.g., \"Photo by John Doe on Pexels\")\n\n## License\n\nISC",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "pexels",
        "photos",
        "videos",
        "pexels mcp",
        "pexels using",
        "caullenomdahl pexels"
      ],
      "category": "image-and-video-generation"
    },
    "Dreamboat-Rachel--MCP-Server-For-Local": {
      "owner": "Dreamboat-Rachel",
      "name": "MCP-Server-For-Local",
      "url": "https://github.com/Dreamboat-Rachel/MCP-Server-For-Local",
      "imageUrl": "/freedevtools/mcp/pfp/Dreamboat-Rachel.webp",
      "description": "Connect AI models to real-time data and tools with features such as weather querying, Google search automation, camera control, and image generation. The server supports modular expansion and custom API integration for tailored functionalities.",
      "stars": 14,
      "forks": 2,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-09-21T02:08:22Z",
      "readme_content": "# MCP Server for Local\n\n一个基于 MCP (Multi-Component Platform) 的本地代理服务器和客户端实现，提供多种 AI 工具调用能力。\n\n## 功能特点\n\n### 核心功能\n- **天气查询**：实时获取全球任意位置的天气信息，支持温度、湿度、风速等详细数据\n- **谷歌搜索**：智能检索互联网信息，支持多语言和高级搜索语法\n- **摄像头控制**：支持拍照、视频流和微表情分析，可用于情绪识别\n- **图片生成**：集成 ComfyUI，支持文本到图像的 AI 生成\n- **智能对话**：基于 DashScope 的 AI 对话能力，支持上下文理解和多轮对话\n\n### 技术特性\n- 跨平台支持（Windows 和 Linux）\n- 模块化设计，易于扩展新功能\n- 完整的日志系统，便于调试和监控\n- 支持自定义工具和 API 集成\n- 高性能并发处理能力\n\n## 环境配置\n\n### 系统要求\n- Python 3.8+\n- Node.js (可选，用于运行 JavaScript 服务器)\n- Chrome 浏览器（用于谷歌搜索功能）\n- 摄像头（用于拍照功能）\n- 至少 4GB 内存\n- 支持 CUDA 的显卡（可选，用于加速 AI 计算）\n\n### 安装步骤\n\n1. 克隆仓库：\n```bash\ngit clone https://github.com/yourusername/mcp-server-for-local.git\ncd mcp-server-for-local\n```\n\n2. 创建并激活虚拟环境：\n```bash\n# Windows\npython -m venv .venv\n.venv\\Scripts\\activate\n\n# Linux\npython3 -m venv .venv\nsource .venv/bin/activate\n```\n\n3. 安装依赖：\n```bash\n# 使用 uv 安装依赖\nuv pip install -r requirements.txt\n\n# 如果遇到网络问题，可以使用国内镜像\nuv pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple\n```\n\n4. 配置环境变量：\n```bash\n# 复制环境变量模板\ncp .env.example .env\n\n# 编辑 .env 文件，设置你的配置\n```\n\n### 环境变量配置\n编辑 `.env` 文件，设置以下配置：\n\n- `DASHSCOPE_API_KEY`: DashScope API 密钥（必填）\n- `MODEL`: 使用的模型名称（默认：qwen-max）\n- `CONFIG_FILE`: 服务器配置文件路径\n- `GAODE_API_KEY`: 高德地图 API 密钥（用于天气查询）\n- `CHROME_PATH`: Chrome 浏览器路径\n- `CHROMEDRIVER_PATH`: ChromeDriver 路径\n- `BASE_URL`: ComfyUI 服务器地址\n- `SERVERS_DIR`: 服务器脚本目录\n- `LOG_LEVEL`: 日志级别（可选：DEBUG, INFO, WARNING, ERROR）\n\n## 使用方法\n\n### 基本使用\n\n1. 进入项目目录：\n```bash\ncd src/mcp\n```\n\n2. 运行客户端：\n```bash\nuv run .\\client\\mcp_client.py .\\proxy\\proxy_server.py\n```\n\n3. 在客户端中输入命令，例如：\n- \"北京的天气怎么样？\"\n- \"在谷歌上搜索 Python 教程\"\n- \"拍照\"\n- \"生成一张猫的图片\"\n\n### 高级功能\n\n1. **自定义工具**：\n   - 在 `src/mcp/tools` 目录下添加新的工具类\n   - 实现必要的接口方法\n   - 在配置文件中注册新工具\n\n2. **API 扩展**：\n   - 支持添加新的 API 服务\n   - 可配置 API 密钥和端点\n   - 支持自定义请求和响应处理\n\n3. **日志管理**：\n   - 支持多级别日志记录\n   - 可配置日志输出位置\n   - 支持日志轮转和归档\n\n## 常见问题\n\n### 安装问题\n\n1. 依赖安装失败：\n```bash\n# 尝试清理缓存后重新安装\nuv pip cache purge\nuv pip install -r requirements.txt\n```\n\n2. 虚拟环境问题：\n```bash\n# 如果激活失败，尝试重新创建虚拟环境\nrm -rf .venv\npython -m venv .venv\n```\n\n### 运行问题\n\n1. 权限问题：\n```bash\n# Linux\nchmod +x src/mcp/proxy/proxy_server.py\nchmod +x src/mcp/client/mcp_client.py\n```\n\n2. Chrome 相关问题：\n- 确保 Chrome 和 ChromeDriver 版本匹配\n- 检查 Chrome 路径是否正确\n- 确保有足够的权限运行 Chrome\n- 如果遇到驱动问题，可以手动下载对应版本的 ChromeDriver\n\n3. API 密钥问题：\n- 检查 `.env` 文件中的 API 密钥是否正确\n- 确保 API 密钥有足够的配额\n- 检查网络连接是否正常\n\n## 开发指南\n\n### 项目结构\n```\nsrc/mcp/\n├── client/          # 客户端代码\n├── proxy/           # 代理服务器代码\n├── tools/           # 工具实现\n├── utils/           # 工具函数\n└── config/          # 配置文件\n```\n\n### 添加新功能\n1. 在 `tools` 目录下创建新的工具类\n2. 实现必要的接口方法\n3. 在配置文件中注册新工具\n4. 编写测试用例\n5. 更新文档\n\n## 贡献指南\n\n欢迎提交 Issue 和 Pull Request！在提交之前，请确保：\n1. 代码符合项目规范\n2. 添加了必要的测试\n3. 更新了相关文档\n4. 通过了所有测试\n\n## 许可证\n\nMIT License\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ai",
        "automation",
        "server",
        "connect ai",
        "automation camera",
        "ai models"
      ],
      "category": "image-and-video-generation"
    },
    "Emmanuel97423--video_maker": {
      "owner": "Emmanuel97423",
      "name": "video_maker",
      "url": "https://github.com/Emmanuel97423/video_maker",
      "imageUrl": "/freedevtools/mcp/pfp/Emmanuel97423.webp",
      "description": "Create and manage video projects using an intuitive interface built with Next.js, facilitating video content creation and project management through streamlined workflows and powerful features.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-04-01T18:44:57Z",
      "readme_content": "pmThis is a [Next.js](https://nextjs.org) project bootstrapped with [`create-next-app`](https://nextjs.org/docs/app/api-reference/cli/create-next-app).\n\n## Getting Started\n\nFirst, run the development server:\n\n```bash\nnpm run dev\n# or\nyarn dev\n# or\npnpm dev\n# or\nbun dev\n```\n\nOpen [http://localhost:3000](http://localhost:3000) with your browser to see the result.\n\nYou can start editing the page by modifying `app/page.tsx`. The page auto-updates as you edit the file.\n\nThis project uses [`next/font`](https://nextjs.org/docs/app/building-your-application/optimizing/fonts) to automatically optimize and load [Geist](https://vercel.com/font), a new font family for Vercel.\n\n## Learn More\n\nTo learn more about Next.js, take a look at the following resources:\n\n- [Next.js Documentation](https://nextjs.org/docs) - learn about Next.js features and API.\n- [Learn Next.js](https://nextjs.org/learn) - an interactive Next.js tutorial.\n\nYou can check out [the Next.js GitHub repository](https://github.com/vercel/next.js) - your feedback and contributions are welcome!\n\n## Deploy on Vercel\n\nThe easiest way to deploy your Next.js app is to use the [Vercel Platform](https://vercel.com/new?utm_medium=default-template&filter=next.js&utm_source=create-next-app&utm_campaign=create-next-app-readme) from the creators of Next.js.\n\nCheck out our [Next.js deployment documentation](https://nextjs.org/docs/app/building-your-application/deploying) for more details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "video_maker",
        "video",
        "projects",
        "video generation",
        "video_maker create",
        "video projects"
      ],
      "category": "image-and-video-generation"
    },
    "GMKR--mcp-imagegen": {
      "owner": "GMKR",
      "name": "mcp-imagegen",
      "url": "https://github.com/GMKR/mcp-imagegen",
      "imageUrl": "/freedevtools/mcp/pfp/GMKR.webp",
      "description": "Generate images from text prompts using advanced AI models. Supports both local and SSE endpoint configurations with specific provider requirements.",
      "stars": 4,
      "forks": 3,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-06-18T01:58:09Z",
      "readme_content": "# MCP Image Generator\n\nA Model Context Protocol (MCP) server for generating images using Together AI's image generation models. This MCP Server can be run locally or using an SSE endpoint. \nThe MCP Image Generator required a provider, only \"Replicate\" and \"Together\" are supported currently. You need to set the `TOGETHER_API_KEY` or `REPLICATE_API_TOKEN` environment variables. and set the `PROVIDER` environment variable to \"replicate\" or \"together\"/\n\n## SSE Endpoint (Docker environment)\n\n### Clone the repository\n\n```bash\ngit clone https://github.com/gmkr/mcp-imagegen.git\ncd mcp-imagegen\n```\n\n### Build and run Docker container\n\n```bash\ndocker build -f Dockerfile.server -t mcp-imagegen .\ndocker run -p 3000:3000 mcp-imagegen\n```\n\n### Configuring with MCP Client\n```\n{\n  \"mcpServers\": {\n    \"imagegenerator\": {\n      \"url\": \"http://localhost:3000/sse\",\n      \"env\": {\n        \"PROVIDER\": \"replicate\",\n        \"REPLICATE_API_TOKEN\": \"your-replicate-api-token\"\n      }\n    }\n  }\n}\n```\nAdjust the `url` to the endpoint of the MCP server you want to use.  `provider` can be \"replicate\" or \"together\".\n\n## Running locally using stdio\n\n### Prerequisites\n\n- Node.js\n- Together AI API key or Replicate API token\n\n### Installation\n\n1. Clone the repository:\n   ```bash\n   git clone https://github.com/gmkr/mcp-imagegen.git\n   cd mcp-imagegen\n   ```\n\n2. Install dependencies:\n   ```bash\n   pnpm install\n   ```\n### Configuration\nCreate a configuration file for your MCP client. Here's an example configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"imagegenerator\": {\n      \"command\": \"pnpx\",\n      \"args\": [\n        \"-y\",\n        \"tsx\",\n        \"/path/to/mcp-imagegen/src/index.ts\"\n      ],\n      \"env\": {\n        \"PROVIDER\": \"replicate\",\n        \"REPLICATE_API_TOKEN\": \"your-replicate-api-token\"\n      }\n    }\n  }\n}\n```\n\nReplace `/path/to/mcp-imagegen` with the absolute path to your cloned repository and `your-replicate-api-token` with your actual Replicate API token.\n\n## Usage\n\nThe MCP Image Generator provides a tool called `generate_image` that can be used to generate images based on text prompts.\n\n### Tool: generate_image\n\nGenerates an image based on the provided prompt.\n\n**Parameters:**\n- `prompt` (string): The text prompt to generate an image for\n- `width` (number, optional): The width of the image to generate (default: 512)\n- `height` (number, optional): The height of the image to generate (default: 512)\n- `numberOfImages` (number, optional): The number of images to generate (default: 1)\n\n## Environment Variables\n- `PROVIDER`: The provider to use for image generation (default: \"replicate\")\n- `REPLICATE_API_TOKEN`: Your Replicate API token\n- `TOGETHER_API_KEY`: Your Together AI API key\n- `MODEL_NAME`: The model to use for image generation (default: \"black-forest-labs/flux-schnell\")\n\n## License\n\nMIT \n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "imagegen",
        "mcp",
        "images",
        "mcp imagegen",
        "generate images",
        "imagegen generate"
      ],
      "category": "image-and-video-generation"
    },
    "Garoth--dalle-mcp": {
      "owner": "Garoth",
      "name": "dalle-mcp",
      "url": "https://github.com/Garoth/dalle-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/Garoth.webp",
      "description": "Generate images from text prompts using OpenAI's DALL-E API. Edit existing images and create variations of them while ensuring API key validation for secure access.",
      "stars": 10,
      "forks": 8,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-08-14T03:51:46Z",
      "readme_content": "# DALL-E MCP Server\n\n\n\nAn MCP (Model Context Protocol) server for generating images using OpenAI's DALL-E API.\n\n## Features\n\n- Generate images using DALL-E 2 or DALL-E 3\n- Edit existing images (DALL-E 2 only)\n- Create variations of existing images (DALL-E 2 only)\n- Validate OpenAI API key\n\n## Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/Garoth/dalle-mcp.git\ncd dalle-mcp\n\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n```\n\n## Important Note for Cline Users\n\nWhen using this DALL-E MCP server with Cline, it's recommended to save generated images in your current workspace directory by setting the `saveDir` parameter to match your current working directory. This ensures Cline can properly locate and display the generated images in your conversation.\n\nExample usage with Cline:\n```json\n{\n  \"prompt\": \"A tropical beach at sunset\",\n  \"saveDir\": \"/path/to/current/workspace\"\n}\n```\n\n\n## Usage\n\n### Running the Server\n\n```bash\n# Run the server\nnode build/index.js\n```\n\n### Configuration for Cline\n\nAdd the dall-e server to your Cline MCP settings file inside VSCode's settings (ex. ~/.config/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json):\n\n```json\n{\n  \"mcpServers\": {\n    \"dalle-mcp\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/dalle-mcp-server/build/index.js\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"your-api-key-here\",\n        \"SAVE_DIR\": \"/path/to/save/directory\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\nMake sure to:\n1. Replace `/path/to/dalle-mcp-server/build/index.js` with the actual path to the built index.js file\n2. Replace `your-api-key-here` with your OpenAI API key\n\n### Available Tools\n\n#### generate_image\n\nGenerate an image using DALL-E based on a text prompt.\n\n```json\n{\n  \"prompt\": \"A futuristic city with flying cars and neon lights\",\n  \"model\": \"dall-e-3\",\n  \"size\": \"1024x1024\",\n  \"quality\": \"standard\",\n  \"style\": \"vivid\",\n  \"n\": 1,\n  \"saveDir\": \"/path/to/save/directory\",\n  \"fileName\": \"futuristic-city\"\n}\n```\n\nParameters:\n- `prompt` (required): Text description of the desired image\n- `model` (optional): DALL-E model to use (\"dall-e-2\" or \"dall-e-3\", default: \"dall-e-3\")\n- `size` (optional): Size of the generated image (default: \"1024x1024\")\n  - DALL-E 3: \"1024x1024\", \"1792x1024\", or \"1024x1792\"\n  - DALL-E 2: \"256x256\", \"512x512\", or \"1024x1024\"\n- `quality` (optional): Quality of the generated image, DALL-E 3 only (\"standard\" or \"hd\", default: \"standard\")\n- `style` (optional): Style of the generated image, DALL-E 3 only (\"vivid\" or \"natural\", default: \"vivid\")\n- `n` (optional): Number of images to generate (1-10, default: 1)\n- `saveDir` (optional): Directory to save the generated images (default: current directory or SAVE_DIR from .env). **For Cline users:** Setting this to your current workspace directory is recommended for proper image display.\n- `fileName` (optional): Base filename for the generated images without extension (default: \"dalle-{timestamp}\")\n\n#### edit_image\n\nEdit an existing image using DALL-E based on a text prompt.\n\n> **⚠️ Known Issue (March 18, 2025):** The DALL-E 2 image edit API currently has a bug where it sometimes ignores the prompt and returns the original image without any edits, even when using proper RGBA format images and masks. This issue has been reported in the [OpenAI community forum](https://community.openai.com/t/dall-e-2-image-edit-issue/668376/7). If you experience this issue, try using the `create_variation` tool instead, which seems to work more reliably.\n\n```json\n{\n  \"prompt\": \"Add a red hat\",\n  \"imagePath\": \"/path/to/image.png\",\n  \"mask\": \"/path/to/mask.png\",\n  \"model\": \"dall-e-2\",\n  \"size\": \"1024x1024\",\n  \"n\": 1,\n  \"saveDir\": \"/path/to/save/directory\",\n  \"fileName\": \"edited-image\"\n}\n```\n\nParameters:\n- `prompt` (required): Text description of the desired edits\n- `imagePath` (required): Path to the image to edit\n- `mask` (optional): Path to the mask image (white areas will be edited, black areas preserved)\n- `model` (optional): DALL-E model to use (currently only \"dall-e-2\" supports editing, default: \"dall-e-2\")\n- `size` (optional): Size of the generated image (default: \"1024x1024\")\n- `n` (optional): Number of images to generate (1-10, default: 1)\n- `saveDir` (optional): Directory to save the edited images (default: current directory or SAVE_DIR from .env). **For Cline users:** Setting this to your current workspace directory is recommended for proper image display.\n- `fileName` (optional): Base filename for the edited images without extension (default: \"dalle-edit-{timestamp}\")\n\n#### create_variation\n\nCreate variations of an existing image using DALL-E.\n\n```json\n{\n  \"imagePath\": \"/path/to/image.png\",\n  \"model\": \"dall-e-2\",\n  \"size\": \"1024x1024\",\n  \"n\": 4,\n  \"saveDir\": \"/path/to/save/directory\",\n  \"fileName\": \"image-variation\"\n}\n```\n\nParameters:\n- `imagePath` (required): Path to the image to create variations of\n- `model` (optional): DALL-E model to use (currently only \"dall-e-2\" supports variations, default: \"dall-e-2\")\n- `size` (optional): Size of the generated image (default: \"1024x1024\")\n- `n` (optional): Number of variations to generate (1-10, default: 1)\n- `saveDir` (optional): Directory to save the variation images (default: current directory or SAVE_DIR from .env). **For Cline users:** Setting this to your current workspace directory is recommended for proper image display.\n- `fileName` (optional): Base filename for the variation images without extension (default: \"dalle-variation-{timestamp}\")\n\n#### validate_key\n\nValidate the OpenAI API key.\n\n```json\n{}\n```\n\nNo parameters required.\n\n## Development\n\n## Testing Configuration\n\n**Note: The following .env configuration is ONLY needed for running tests, not for normal operation.**\n\nIf you're developing or running tests for this project, create a `.env` file in the root directory with your OpenAI API key:\n\n```\n# Required for TESTS ONLY: OpenAI API Key\nOPENAI_API_KEY=your-api-key-here\n\n# Optional: Default save directory for test images\n# If not specified, images will be saved to the current directory\n# SAVE_DIR=/path/to/save/directory\n```\n\nFor normal operation with Cline, configure your API key in the MCP settings JSON as described in the \"Adding to MCP Settings\" section above.\n\nYou can get your API key from [OpenAI's API Keys page](https://platform.openai.com/api-keys).\n\n### Running Tests\n\n```bash\n# Run basic tests\nnpm test\n\n# Run all tests including edit and variation tests\nnpm run test:all\n\n# Run tests in watch mode\nnpm run test:watch\n\n# Run specific test by name\nnpm run test:name \"should validate API key\"\n```\n\nNote: Tests use real API calls and may incur charges on your OpenAI account.\n\n### Generating Test Images\n\nThe project includes a script to generate test images for development and testing:\n\n```bash\n# Generate a test image in the assets directory\nnpm run generate-test-image\n  ```\n\nThis will create a simple test image in the `assets` directory that can be used for testing the edit and variation features.\n\n## License\n\nMIT",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "openai",
        "images",
        "garoth",
        "generate images",
        "mcp generate",
        "images create"
      ],
      "category": "image-and-video-generation"
    },
    "GongRzhe--Image-Generation-MCP-Server": {
      "owner": "GongRzhe",
      "name": "Image-Generation-MCP-Server",
      "url": "https://github.com/GongRzhe/Image-Generation-MCP-Server",
      "imageUrl": "/freedevtools/mcp/pfp/GongRzhe.webp",
      "description": "Generate images from text prompts using the Replicate Flux model, enabling the creation of unique visuals tailored to specific specifications.",
      "stars": 40,
      "forks": 8,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-30T20:18:52Z",
      "readme_content": "# Image Generation MCP Server\n![](https://badge.mcpx.dev?type=server 'MCP Server')\n\n[![smithery badge](https://smithery.ai/badge/@GongRzhe/Image-Generation-MCP-Server)](https://smithery.ai/server/@GongRzhe/Image-Generation-MCP-Server)\n\nThis MCP server provides image generation capabilities using the Replicate Flux model.\n\n## Installation\n\n### Installing via Smithery\n\nTo install Image Generation MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@GongRzhe/Image-Generation-MCP-Server):\n\n```bash\nnpx -y @smithery/cli install @GongRzhe/Image-Generation-MCP-Server --client claude\n```\n\n### Option 1: NPX Method (No Local Setup Required)\nYou can use the package directly from npm without installing it locally:\n\n```bash\n# No installation needed - npx will handle it\n```\n\n### Option 2: Local Installation\nIf you prefer a local installation:\n\n```bash\n# Global installation\nnpm install -g @gongrzhe/image-gen-server\n\n# Or local installation\nnpm install @gongrzhe/image-gen-server\n```\n\n## Setup\n\n### Configure Claude Desktop\n\nEdit your Claude Desktop configuration file:\n\n- On MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n- On Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n#### Option 1: NPX Configuration (Recommended)\nThis method runs the server directly from npm without needing local files:\n\n```json\n{\n  \"mcpServers\": {\n    \"image-gen\": {\n      \"command\": \"npx\",\n      \"args\": [\"@gongrzhe/image-gen-server\"],\n      \"env\": {\n        \"REPLICATE_API_TOKEN\": \"your-replicate-api-token\",\n        \"MODEL\": \"alternative-model-name\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\n#### Option 2: Local Installation Configuration\nIf you installed the package locally:\n\n```json\n{\n  \"mcpServers\": {\n    \"image-gen\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/image-gen-server/build/index.js\"],\n      \"env\": {\n        \"REPLICATE_API_TOKEN\": \"your-replicate-api-token\",\n        \"MODEL\": \"alternative-model-name\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\n### Get Your Replicate API Token\n\n1. Sign up/login at https://replicate.com\n2. Go to https://replicate.com/account/api-tokens\n3. Create a new API token\n4. Copy the token and replace `your-replicate-api-token` in the MCP settings\n\n![image](https://github.com/user-attachments/assets/583afa78-1a08-4eb5-9a37-decb95bd50c4)\n\n### Environment Variables\n\n- `REPLICATE_API_TOKEN` (required): Your Replicate API token for authentication\n- `MODEL` (optional): The Replicate model to use for image generation. Defaults to \"black-forest-labs/flux-schnell\"\n\n### Configuration Parameters\n\n- `disabled`: Controls whether the server is enabled (`false`) or disabled (`true`)\n- `autoApprove`: Array of tool names that can be executed without user confirmation. Empty array means all tool calls require confirmation.\n\n## Available Tools\n\n### generate_image\n\nGenerates images using the Flux model based on text prompts.\n\n![image](https://github.com/user-attachments/assets/766921ce-ca8e-4d68-866d-8c7b55b2e09d)\n\n![out-0 (1)](https://github.com/user-attachments/assets/83549b2e-525a-4ff9-825c-83ba74459575)\n\n#### Parameters\n\n- `prompt` (required): Text description of the image to generate\n- `seed` (optional): Random seed for reproducible generation\n- `aspect_ratio` (optional): Image aspect ratio (default: \"1:1\")\n- `output_format` (optional): Output format - \"webp\", \"jpg\", or \"png\" (default: \"webp\")\n- `num_outputs` (optional): Number of images to generate (1-4, default: 1)\n\n#### Example Usage\n\n```typescript\nconst result = await use_mcp_tool({\n  server_name: \"image-gen\",\n  tool_name: \"generate_image\",\n  arguments: {\n    prompt: \"A beautiful sunset over mountains\",\n    aspect_ratio: \"16:9\",\n    output_format: \"png\",\n    num_outputs: 1\n  }\n});\n```\n\nThe tool returns an array of URLs to the generated images.\n\n## 📜 License\n\nThis project is licensed under the MIT License.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "generate",
        "mcp",
        "replicate",
        "generate images",
        "image generation",
        "video generation"
      ],
      "category": "image-and-video-generation"
    },
    "Hajime-Y--deep-research-mcp": {
      "owner": "Hajime-Y",
      "name": "deep-research-mcp",
      "url": "https://github.com/Hajime-Y/deep-research-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/Hajime-Y.webp",
      "description": "Provides advanced web search capabilities, document analysis, and image processing. Extracts information from various sources including PDFs and YouTube transcripts efficiently.",
      "stars": 12,
      "forks": 1,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-09-06T18:57:01Z",
      "readme_content": "# Deep Research MCP Server\n\nDeep Research is an agent-based tool that provides web search and advanced research capabilities. It leverages HuggingFace's `smolagents` and is implemented as an MCP server.\n\nThis project is based on [HuggingFace's open_deep_research example](https://github.com/huggingface/smolagents/tree/main/examples/open_deep_research).\n\n## Features\n\n- Web search and information gathering\n- PDF and document analysis\n- Image analysis and description\n- YouTube transcript retrieval\n- Archive site search\n\n## Requirements\n\n- Python 3.11 or higher\n- `uv` package manager\n- The following API keys:\n  - OpenAI API key\n  - HuggingFace token\n  - SerpAPI key\n\n## Installation\n\n1. Clone the repository:\n\n```bash\ngit clone https://github.com/Hajime-Y/deep-research-mcp.git\ncd deep-research-mcp\n```\n\n2. Create a virtual environment and install dependencies:\n\n```bash\nuv venv\nsource .venv/bin/activate # For Linux or Mac\n# .venv\\Scripts\\activate # For Windows\nuv sync\n```\n\n## Environment Variables\n\nCreate a `.env` file in the root directory of the project and set the following environment variables:\n\n```\nOPENAI_API_KEY=your_openai_api_key\nHF_TOKEN=your_huggingface_token\nSERPER_API_KEY=your_serper_api_key\n```\n\nYou can obtain a SERPER_API_KEY by signing up at [Serper.dev](https://serper.dev/signup).\n\n## Usage\n\nStart the MCP server:\n\n```bash\nuv run deep_research.py\n```\n\nThis will launch the `deep_research` agent as an MCP server.\n\n## Docker Usage\n\nYou can also run this MCP server in a Docker container:\n\n```bash\n# Build the Docker image\ndocker build -t deep-research-mcp .\n\n# Run with required API keys\ndocker run -p 8080:8080 \\\n  -e OPENAI_API_KEY=your_openai_api_key \\\n  -e HF_TOKEN=your_huggingface_token \\\n  -e SERPER_API_KEY=your_serper_api_key \\\n  deep-research-mcp\n```\n\n### Registering with MCP Clients\n\nTo register this Docker container as an MCP server in different clients:\n\n#### Claude Desktop\n\nAdd the following to your Claude Desktop configuration file (typically located at `~/.config/Claude/claude_desktop_config.json` on Linux, `~/Library/Application Support/Claude/claude_desktop_config.json` on macOS, or `%APPDATA%\\Claude\\claude_desktop_config.json` on Windows):\n\n```json\n{\n  \"mcpServers\": {\n    \"deep-research-mcp\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\", \n        \"-i\", \n        \"--rm\", \n        \"-e\", \"OPENAI_API_KEY=your_openai_api_key\",\n        \"-e\", \"HF_TOKEN=your_huggingface_token\", \n        \"-e\", \"SERPER_API_KEY=your_serper_api_key\",\n        \"deep-research-mcp\"\n      ]\n    }\n  }\n}\n```\n\n#### Cursor IDE\n\nFor Cursor IDE, add the following configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"deep-research-mcp\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\", \n        \"-i\", \n        \"--rm\", \n        \"-e\", \"OPENAI_API_KEY=your_openai_api_key\",\n        \"-e\", \"HF_TOKEN=your_huggingface_token\", \n        \"-e\", \"SERPER_API_KEY=your_serper_api_key\",\n        \"deep-research-mcp\"\n      ]\n    }\n  }\n}\n```\n\n#### Using with Remote MCP Server\n\nIf you're running the MCP server on a remote machine or exposing it as a service, you can use the URL-based configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"deep-research-mcp\": {\n      \"url\": \"http://your-server-address:8080/mcp\",\n      \"type\": \"sse\"\n    }\n  }\n}\n```\n\n## Key Components\n\n- `deep_research.py`: Entry point for the MCP server\n- `create_agent.py`: Agent creation and configuration\n- `scripts/`: Various tools and utilities\n  - `text_web_browser.py`: Text-based web browser\n  - `text_inspector_tool.py`: File inspection tool\n  - `visual_qa.py`: Image analysis tool\n  - `mdconvert.py`: Converts various file formats to Markdown\n\n## License\n\nThis project is provided under the Apache License 2.0.\n\n## Acknowledgements\n\nThis project uses code from HuggingFace's `smolagents` and Microsoft's `autogen` projects.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcp",
        "hajime",
        "search",
        "mcp provides",
        "research mcp",
        "hajime deep"
      ],
      "category": "image-and-video-generation"
    },
    "Hzzy2O--flux-cloudfare-mcp": {
      "owner": "Hzzy2O",
      "name": "flux-cloudfare-mcp",
      "url": "https://github.com/Hzzy2O/flux-cloudfare-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/Hzzy2O.webp",
      "description": "Provides high-quality image generation via the Flux model through a Cloudflare Worker API, enabling seamless integration into applications with customizable parameters for image output.",
      "stars": 0,
      "forks": 2,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-03-17T01:14:19Z",
      "readme_content": "# Flux Cloudflare MCP\n\n![MCP Compatible](https://img.shields.io/badge/MCP-Compatible-blue)\n![License](https://img.shields.io/badge/license-MIT-green)\n![TypeScript](https://img.shields.io/badge/TypeScript-4.9+-blue)\n![Model Context Protocol](https://img.shields.io/badge/MCP-Enabled-purple)\n\nA powerful Model Context Protocol (MCP) server that provides AI assistants with the ability to generate images using [Black Forest Labs' Flux model](https://developer.cloudflare.com/ai-gateway/models/flux-1/) via a Cloudflare Worker API.\n\n[Installation](#installation) • [Features](#features) • [Usage](#usage) • [Documentation](#documentation) • [Contributing](#contributing)\n\n---\n\n## 🌟 Features\n\n- **🖼️ High-Quality Image Generation**: Access to Flux, a state-of-the-art image generation model\n- **🤖 Seamless AI Integration**: Enable AI assistants like Claude to generate images directly\n- **🎛️ Customizable Parameters**: Control aspect ratio, inference steps, and more\n- **🔌 MCP Compatible**: Works with any MCP client (Cursor, Claude Desktop, Cline, Zed, etc.)\n- **🔒 Local Processing**: All requests are processed securely through the Cloudflare Worker\n- **💬 Chat Completions**: Get text completions using the same API\n\n## 📦 Installation\n\n### Direct Usage with NPX\n\n```bash\nFLUX_API_TOKEN=your_token FLUX_API_URL=your_api_url npx -y flux-cloudflare-mcp\n```\n\n### From Source\n\n```bash\n# Clone the repository\ngit clone https://github.com/Hzzy2O/flux-cloudflare-mcp.git\ncd flux-cloudflare-mcp\n\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n```\n\n## 🚀 Setting Up Your Flux API\n\nThis MCP server requires a Flux API endpoint to function. You have two options for setting up the API:\n\n### Option 1: Deploy using snakeying/flux-api-worker (Recommended)\n\n[snakeying/flux-api-worker](https://github.com/snakeying/flux-api-worker) provides a simple and efficient Cloudflare Worker for accessing the Flux model:\n\n1. Fork the [flux-api-worker repository](https://github.com/snakeying/flux-api-worker)\n2. Deploy it to Cloudflare Workers:\n   - Create a new Worker in your Cloudflare dashboard\n   - Connect it to your forked repository\n   - Set up the required environment variables:\n     - `API_KEY`: Your chosen API key for authentication\n     - `CF_ACCOUNT_ID`: Your Cloudflare account ID\n     - `CF_API_TOKEN`: Your Cloudflare API token with Workers AI access\n     - `FLUX_MODEL`: The Flux model to use (default: \"@cf/black-forest-labs/flux-1-schnell\")\n3. Once deployed, your API will be available at `https://your-worker-name.your-subdomain.workers.dev`\n4. Use this URL as your `FLUX_API_URL` and your chosen API key as `FLUX_API_TOKEN`\n\n### Option 2: Deploy using aigem/cf-flux-remix\n\nFor a more feature-rich implementation with a web UI, you can use [aigem/cf-flux-remix](https://github.com/aigem/cf-flux-remix):\n\n1. Follow the installation instructions in the [cf-flux-remix repository](https://github.com/aigem/cf-flux-remix)\n2. Once deployed, your API will be available at your deployed URL\n3. Use this URL as your `FLUX_API_URL` and your configured API key as `FLUX_API_TOKEN`\n\n## 📚 Documentation\n\n### Available Tools\n\n#### `generate_image`\n\nGenerates an image based on a text prompt using the Flux model.\n\n```typescript\n{\n  prompt: string;                // Required: Text description of the image to generate\n  num_inference_steps?: number;  // Optional: Number of denoising steps (1-4) (default: 4)\n  aspect_ratio?: string;         // Optional: Aspect ratio (e.g., \"16:9\", \"4:3\") (default: \"1:1\")\n}\n```\n\n## 🔧 Usage\n\n### Cursor Integration\n\n#### Method 1: Using mcp.json\n\n1. Create or edit the `.cursor/mcp.json` file in your project directory:\n\n```json\n{\n  \"mcpServers\": {\n    \"flux-cloudflare-mcp\": {\n      \"command\": \"env FLUX_API_TOKEN=YOUR_TOKEN FLUX_API_URL=YOUR_API_URL npx\",\n      \"args\": [\"-y\", \"flux-cloudflare-mcp\"]\n    }\n  }\n}\n```\n\n2. Replace `YOUR_TOKEN` with your actual Flux API token and `YOUR_API_URL` with your API URL\n3. Restart Cursor to apply the changes\n\n#### Method 2: Using Cursor MCP Settings\n\n1. Open Cursor and go to Settings\n2. Navigate to the \"MCP\" or \"Model Context Protocol\" section\n3. Click \"Add Server\" or equivalent\n4. Enter the following command in the appropriate field:\n\n```\nenv FLUX_API_TOKEN=YOUR_TOKEN FLUX_API_URL=YOUR_API_URL npx -y flux-cloudflare-mcp\n```\n\n5. Replace `YOUR_TOKEN` with your actual Flux API token and `YOUR_API_URL` with your API URL\n6. Save the settings and restart Cursor if necessary\n\n### Claude Desktop Integration\nenv FLUX_API_TOKEN=YOUR_TOKEN FLUX_API_URL=YOUR_API_URL npx -y flux-cloudflare-mcp\n\n```json\n{\n  \"mcpServers\": {\n    \"flux-cloudflare-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"flux-cloudflare-mcp\"],\n      \"env\": {\n        \"FLUX_API_TOKEN\": \"YOUR_TOKEN\",\n        \"FLUX_API_URL\": \"YOUR_API_URL\"\n      }\n    }\n  }\n}\n```\n\n## 💻 Local Development\n\n1. Clone the repository:\n\n```bash\ngit clone https://github.com/Hzzy2O/flux-cloudflare-mcp.git\ncd flux-cloudflare-mcp\n```\n\n2. Install dependencies:\n\n```bash\nnpm install\n```\n\n3. Build the project:\n\n```bash\nnpm run build\n```\n\n## 🛠 Technical Stack\n\n* Model Context Protocol SDK - Core MCP functionality\n* Cloudflare Workers - Serverless API for image generation\n* TypeScript - Type safety and modern JavaScript features\n* Zod - Runtime type validation\n\n## ⚙️ Configuration\n\nThe server requires the following environment variables:\n\n- `FLUX_API_TOKEN`: Your API token for authentication with the Flux API\n- `FLUX_API_URL`: The URL of your deployed Flux API (from snakeying/flux-api-worker or aigem/cf-flux-remix)\n\n## 🔍 Troubleshooting\n\n### Common Issues\n\n#### Authentication Error\n- Ensure your `FLUX_API_TOKEN` is correctly set in the environment\n- Verify your token is valid by testing it with the Flux API directly\n\n#### API Connection Issues\n- Check that your Flux API (Cloudflare Worker) is running and accessible\n- Ensure your network allows connections to Cloudflare Workers\n\n#### Safety Filter Triggered\n- The model has a built-in safety filter that may block certain prompts\n- Try modifying your prompt to avoid potentially problematic content\n\n## 🤝 Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n1. Fork the repository\n2. Create your feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add some amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n\n## 📄 License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## 🔗 Resources\n\n- [Model Context Protocol Documentation](https://modelcontextprotocol.io)\n- [Cloudflare Workers Documentation](https://developers.cloudflare.com/workers/)\n- [Flux Model Documentation](https://developer.cloudflare.com/ai-gateway/models/flux-1/)\n- [MCP TypeScript SDK](https://github.com/modelcontextprotocol/typescript-sdk)\n- [snakeying/flux-api-worker](https://github.com/snakeying/flux-api-worker) - Simple Flux API implementation\n- [aigem/cf-flux-remix](https://github.com/aigem/cf-flux-remix) - Feature-rich Flux API with web UI\n\n[![smithery badge](https://smithery.ai/badge/@Hzzy2O/flux-cloudfare-mcp)](https://smithery.ai/server/@Hzzy2O/flux-cloudfare-mcp)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "cloudflare",
        "flux",
        "cloudfare",
        "flux cloudfare",
        "cloudfare mcp",
        "model cloudflare"
      ],
      "category": "image-and-video-generation"
    },
    "IA-Programming--mcp-images": {
      "owner": "IA-Programming",
      "name": "mcp-images",
      "url": "https://github.com/IA-Programming/mcp-images",
      "imageUrl": "/freedevtools/mcp/pfp/IA-Programming.webp",
      "description": "Fetch and process images from URLs and local file paths, handling automatic compression and MIME type retrieval. Images are returned as base64-encoded strings to facilitate integration and support parallel processing with robust error handling.",
      "stars": 13,
      "forks": 4,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-24T05:36:12Z",
      "readme_content": "# MCP Server - Image\nA Model Context Protocol (MCP) server that provides tools for fetching and processing images from URLs, local file paths, and numpy arrays. The server includes a tool called fetch_images that returns images as base64-encoded strings along with their MIME types.\n\n## Support Us\n\nIf you find this project helpful and would like to support future projects, consider buying us a coffee! Your support helps us continue building innovative AI solutions.\n\n<a href=\"https://www.buymeacoffee.com/blazzmocompany\"><img src=\"https://img.buymeacoffee.com/button-api/?text=Buy me a coffee&emoji=&slug=blazzmocompany&button_colour=40DCA5&font_colour=ffffff&font_family=Cookie&outline_colour=000000&coffee_colour=FFDD00\"></a>\n\nYour contributions go a long way in fueling our passion for creating intelligent and user-friendly applications.\n\n## Table of Contents\n- [Features](#features)\n- [Prerequisites](#prerequisites)\n- [Installation](#installation)\n- [Running the Server](#running-the-server)\n  - [Direct Method](#1-direct-method)\n  - [Configure for Windsurf/Cursor](#2-configure-for-windsurfcursor)\n- [Available Tools](#available-tools)\n  - [Usage Examples](#usage-examples)\n- [Debugging](#debugging)\n- [Contributing](#contributing)\n- [License](#license)\n\n## Features\n- Fetch images from URLs (http/https)\n- Load images from local file paths\n- Specialized handling for large local images\n- Automatic image compression for large images (>1MB)\n- Parallel processing of multiple images\n- Proper MIME type mapping for different file extensions\n- Comprehensive error handling and logging\n## Prerequisites\n- Python 3.10+\n- uv package manager (recommended)\n## Installation\n1. Clone this repository\n2. Create and activate a virtual environment using uv:\n```bash\nuv venv\n# On Windows:\n.venv\\Scripts\\activate\n# On Unix/MacOS:\nsource .venv/bin/activate\n```\n3. Install dependencies using uv:\n```bash\nuv pip install -r requirements.txt\n```\n## Running the Server\nThere are two ways to run the MCP server:\n\n### 1. Direct Method\nTo start the MCP server directly:\n\n```bash\nuv run python mcp_image.py\n```\n### 2. Configure for Windsurf/Cursor\n#### Windsurf\nTo add this MCP server to Windsurf:\n\n1. Edit the configuration file at ~/.codeium/windsurf/mcp_config.json\n2. Add the following configuration:\n```json\n{\n  \"mcpServers\": {\n    \"image\": {\n      \"command\": \"uv\",\n        \"args\": [\"--directory\", \"/path/to/mcp-image\", \"run\", \"mcp_image.py\"]\n    }\n  }\n}\n```\n#### Cursor\nTo add this MCP server to Cursor:\n\n1. Open Cursor and go to *Settings* (Navbar → Cursor Settings)\n2. Navigate to *Features* → *MCP Servers*\n3. Click on + Add New MCP Server\n4. Enter the following configuration:\n```json\n{\n  \"mcpServers\": {\n    \"image\": {\n      \"command\": \"uv\",\n      \"args\": [\"--directory\", \"/path/to/mcp-image\", \"run\", \"mcp_image.py\"]\n    }\n  }\n}\n```\n\n## Available Tools\nThe server provides the following tools:\n\n[fetch_images](mcp_image.py#L318): Fetch and process images from URLs or local file paths\nParameters:\nimage_sources: List of URLs or file paths to images\nReturns:\nList of processed images with base64 encoding and MIME types\n\n### Usage Examples\nYou can now use commands like:\n\n- \"Fetch these images: [list of URLs or file paths]\"\n- \"Load and process this local image: [file_path]\"\n\n#### Examples\n```\n# URL-only test\n[\n  \"https://upload.wikimedia.org/wikipedia/commons/thumb/7/70/Chocolate_%28blue_background%29.jpg/400px-Chocolate_%28blue_background%29.jpg\",\n  \"https://imgs.search.brave.com/Sz7BdlhBoOmU4wZjnUkvgestdwmzOzrfc3GsiMr27Ik/rs:fit:860:0:0:0/g:ce/aHR0cHM6Ly9pbWdj/ZG4uc3RhYmxlZGlm/ZnVzaW9ud2ViLmNv/bS8yMDI0LzEwLzE4/LzJmOTY3NTViLTM0/YmQtNDczNi1iNDRh/LWJlMTVmNGM5MDBm/My5qcGc\",\n  \"https://shigacare.fukushi.shiga.jp/mumeixxx/img/main.png\"\n]\n\n# Mixed URL and local file test\n[\n  \"https://upload.wikimedia.org/wikipedia/commons/thumb/7/70/Chocolate_%28blue_background%29.jpg/400px-Chocolate_%28blue_background%29.jpg\",\n  \"C:\\\\Users\\\\username\\\\Pictures\\\\image1.jpg\",\n  \"https://imgs.search.brave.com/Sz7BdlhBoOmU4wZjnUkvgestdwmzOzrfc3GsiMr27Ik/rs:fit:860:0:0:0/g:ce/aHR0cHM6Ly9pbWdj/ZG4uc3RhYmxlZGlm/ZnVzaW9ud2ViLmNv/bS8yMDI0LzEwLzE4/LzJmOTY3NTViLTM0/YmQtNDczNi1iNDRh/LWJlMTVmNGM5MDBm/My5qcGc\",\n  \"C:\\\\Users\\\\username\\\\Pictures\\\\image2.jpg\"\n]\n```\n\n## Debugging\nIf you encounter any issues:\n\n1. Check that all dependencies are installed correctly\n2. Verify that the server is running and listening for connections\n3. For local image loading issues, ensure the file paths are correct and accessible\n4. For \"Unsupported image type\" errors, verify the content type handling\n5. Look for any error messages in the server output\n## Contributing\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## License\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "base64",
        "images",
        "mcp",
        "mcp images",
        "process images",
        "programming mcp"
      ],
      "category": "image-and-video-generation"
    },
    "IncomeStreamSurfer--chatgpt-native-image-gen-mcp": {
      "owner": "IncomeStreamSurfer",
      "name": "chatgpt-native-image-gen-mcp",
      "url": "https://github.com/IncomeStreamSurfer/chatgpt-native-image-gen-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/IncomeStreamSurfer.webp",
      "description": "Generates and edits images using OpenAI's advanced image generation model based on text prompts. Supports image inpainting and variations, with customizable filenames for automated saving.",
      "stars": 15,
      "forks": 3,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-10-03T22:33:09Z",
      "readme_content": "# OpenAI Image Generation MCP Server\n\nThis project implements an MCP (Model Context Protocol) server that provides tools for generating and editing images using OpenAI's `gpt-image-1` model via the official Python SDK.\n\n## Features\n\nThis MCP server provides the following tools:\n\n*   **`generate_image`**: Generates an image using OpenAI's `gpt-image-1` model based on a text prompt and saves it.\n    *   **Input Schema:**\n        ```json\n        {\n          \"type\": \"object\",\n          \"properties\": {\n            \"prompt\": { \"type\": \"string\", \"description\": \"The text description of the desired image(s).\" },\n            \"model\": { \"type\": \"string\", \"default\": \"gpt-image-1\", \"description\": \"The model to use (currently 'gpt-image-1').\" },\n            \"n\": { \"type\": [\"integer\", \"null\"], \"default\": 1, \"description\": \"The number of images to generate (Default: 1).\" },\n            \"size\": { \"type\": [\"string\", \"null\"], \"enum\": [\"1024x1024\", \"1536x1024\", \"1024x1536\", \"auto\"], \"default\": \"auto\", \"description\": \"Image dimensions ('1024x1024', '1536x1024', '1024x1536', 'auto'). Default: 'auto'.\" },\n            \"quality\": { \"type\": [\"string\", \"null\"], \"enum\": [\"low\", \"medium\", \"high\", \"auto\"], \"default\": \"auto\", \"description\": \"Rendering quality ('low', 'medium', 'high', 'auto'). Default: 'auto'.\" },\n            \"user\": { \"type\": [\"string\", \"null\"], \"default\": null, \"description\": \"An optional unique identifier representing your end-user.\" },\n            \"save_filename\": { \"type\": [\"string\", \"null\"], \"default\": null, \"description\": \"Optional filename (without extension). If None, a default name based on the prompt and timestamp is used.\" }\n          },\n          \"required\": [\"prompt\"]\n        }\n        ```\n    *   **Output:** `{\"status\": \"success\", \"saved_path\": \"path/to/image.png\"}` or error dictionary.\n\n*   **`edit_image`**: Edits an image or creates variations using OpenAI's `gpt-image-1` model and saves it. Can use multiple input images as reference or perform inpainting with a mask.\n    *   **Input Schema:**\n        ```json\n        {\n          \"type\": \"object\",\n          \"properties\": {\n            \"prompt\": { \"type\": \"string\", \"description\": \"The text description of the desired final image or edit.\" },\n            \"image_paths\": { \"type\": \"array\", \"items\": { \"type\": \"string\" }, \"description\": \"A list of file paths to the input image(s). Must be PNG. < 25MB.\" },\n            \"mask_path\": { \"type\": [\"string\", \"null\"], \"default\": null, \"description\": \"Optional file path to the mask image (PNG with alpha channel) for inpainting. Must be same size as input image(s). < 25MB.\" },\n            \"model\": { \"type\": \"string\", \"default\": \"gpt-image-1\", \"description\": \"The model to use (currently 'gpt-image-1').\" },\n            \"n\": { \"type\": [\"integer\", \"null\"], \"default\": 1, \"description\": \"The number of images to generate (Default: 1).\" },\n            \"size\": { \"type\": [\"string\", \"null\"], \"enum\": [\"1024x1024\", \"1536x1024\", \"1024x1536\", \"auto\"], \"default\": \"auto\", \"description\": \"Image dimensions ('1024x1024', '1536x1024', '1024x1536', 'auto'). Default: 'auto'.\" },\n            \"quality\": { \"type\": [\"string\", \"null\"], \"enum\": [\"low\", \"medium\", \"high\", \"auto\"], \"default\": \"auto\", \"description\": \"Rendering quality ('low', 'medium', 'high', 'auto'). Default: 'auto'.\" },\n            \"user\": { \"type\": [\"string\", \"null\"], \"default\": null, \"description\": \"An optional unique identifier representing your end-user.\" },\n            \"save_filename\": { \"type\": [\"string\", \"null\"], \"default\": null, \"description\": \"Optional filename (without extension). If None, a default name based on the prompt and timestamp is used.\" }\n          },\n          \"required\": [\"prompt\", \"image_paths\"]\n        }\n        ```\n    *   **Output:** `{\"status\": \"success\", \"saved_path\": \"path/to/image.png\"}` or error dictionary.\n\n## Prerequisites\n\n*   Python (3.8 or later recommended)\n*   pip (Python package installer)\n*   An OpenAI API Key (set directly in the script or via the `OPENAI_API_KEY` environment variable - **using environment variables is strongly recommended for security**).\n*   An MCP client environment (like the one used by Cline) capable of managing and launching MCP servers.\n\n## Installation\n\n1.  **Clone the repository:**\n    ```bash\n    git clone https://github.com/IncomeStreamSurfer/chatgpt-native-image-gen-mcp.git\n    cd chatgpt-native-image-gen-mcp\n    ```\n2.  **Set up a virtual environment (Recommended):**\n    ```bash\n    python -m venv venv\n    source venv/bin/activate  # On Windows use `venv\\Scripts\\activate`\n    ```\n3.  **Install dependencies:**\n    ```bash\n    pip install -r requirements.txt\n    ```\n4.  **(Optional but Recommended) Set Environment Variable:**\n    Set the `OPENAI_API_KEY` environment variable with your OpenAI key instead of hardcoding it in the script. How you set this depends on your operating system.\n\n## Configuration (for Cline MCP Client)\n\nTo make this server available to your AI assistant (like Cline), add its configuration to your MCP settings file (e.g., `cline_mcp_settings.json`).\n\nFind the `mcpServers` object in your settings file and add the following entry:\n\n```json\n{\n  \"mcpServers\": {\n    // ... other server configurations ...\n\n    \"openai-image-gen-mcp\": {\n      \"autoApprove\": [\n        \"generate_image\",\n        \"edit_image\"\n      ],\n      \"disabled\": false,\n      \"timeout\": 180, // Increased timeout for potentially long image generation\n      \"command\": \"python\", // Or path to python executable if not in PATH\n      \"args\": [\n        // IMPORTANT: Replace this path with the actual absolute path\n        // to the openai_image_mcp.py file on your system\n        \"C:/path/to/your/cloned/repo/chatgpt-native-image-gen-mcp/openai_image_mcp.py\"\n      ],\n      \"env\": {\n        // If using environment variables for the API key:\n        // \"OPENAI_API_KEY\": \"YOUR_API_KEY_HERE\"\n      },\n      \"transportType\": \"stdio\"\n    }\n\n    // ... other server configurations ...\n  }\n}\n```\n\n**Important:** Replace `C:/path/to/your/cloned/repo/` with the correct absolute path to where you cloned this repository on your machine. Ensure the path separator is correct for your operating system (e.g., use backslashes `\\` on Windows). If you set the API key via environment variable, you can remove it from the script and potentially add it to the `env` section here if your MCP client supports it.\n\n## Running the Server\n\nYou don't typically need to run the server manually. The MCP client (like Cline) will automatically start the server using the `command` and `args` specified in the configuration file when one of its tools is called for the first time.\n\nIf you want to test it manually (ensure dependencies are installed and API key is available):\n```bash\npython openai_image_mcp.py\n```\n\n## Usage\n\nThe AI assistant interacts with the server using the `generate_image` and `edit_image` tools. Images are saved within an `ai-images` subdirectory created where the `openai_image_mcp.py` script is located. The tools return the absolute path to the saved image upon success.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "openai",
        "images",
        "image",
        "image generation",
        "image gen",
        "video generation"
      ],
      "category": "image-and-video-generation"
    },
    "InhiblabCore--mcp-image-compression": {
      "owner": "InhiblabCore",
      "name": "mcp-image-compression",
      "url": "https://github.com/InhiblabCore/mcp-image-compression",
      "imageUrl": "/freedevtools/mcp/pfp/InhiblabCore.webp",
      "description": "Optimizes images by compressing various formats for faster loading and improved user experience, while offering features like offline usage and batch processing. Supports smart compression to balance file size and visual quality based on image content.",
      "stars": 26,
      "forks": 6,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-08-22T03:13:54Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/inhiblabcore-mcp-image-compression-badge.png)](https://mseep.ai/app/inhiblabcore-mcp-image-compression)\n\n# mcp-image-compression\n\n## Project Overview\n\nmcp-image-compression is a high-performance image compression microservice based on MCP (Modal Context Protocol) architecture. This service focuses on providing fast and high-quality image compression capabilities to help developers optimize image resources for websites and applications, improving loading speed and user experience.\n\n## Features\n\n- **Multi-format support**: Compress mainstream image formats including JPEG, PNG, WebP, AVIF\n- **Offline Usage**: No need to connect to the internet to use\n- **Smart compression**: Automatically select optimal compression parameters based on image content\n- **Batch processing**: Support parallel compression of multiple images for improved efficiency\n- **Quality control**: Customizable compression quality to balance file size and visual quality\n\n## TOOLS\n\n1. `image_compression`\n   - Image compression\n   - Inputs:\n     - `urls` (strings): URLs of images to compress\n     - `quality` (int): Quality of compression (0-100)\n     - `format` (string): Format of compressed image (e.g. \"jpeg\", \"png\", \"webp\", \"avif\")\n   - Returns: Compressed images url\n\n## Setup\n\n### NPX\n\n```json\n{\n  \"mcpServers\": {\n    \"Image compression\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@inhiblab-core/mcp-image-compression\"\n      ],\n      \"env\": {\n        \"IMAGE_COMPRESSION_DOWNLOAD_DIR\": \"<YOUR_DIR>\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\n## Build\n\n```bash\ndocker build -t mcp-image-compression .\n```\n\n## License\n\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "compression",
        "compressing",
        "inhiblabcore",
        "image compression",
        "images compressing",
        "smart compression"
      ],
      "category": "image-and-video-generation"
    },
    "JeremyNixon--mcp-fetch": {
      "owner": "JeremyNixon",
      "name": "mcp-fetch",
      "url": "https://github.com/JeremyNixon/mcp-fetch",
      "imageUrl": "/freedevtools/mcp/pfp/JeremyNixon.webp",
      "description": "Fetches web content and processes images for integration with AI models, streamlining the retrieval and handling of online content in various applications.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "",
      "updated_at": "2025-03-15T18:56:32Z",
      "readme_content": "# MCP Fetch\n\n[![smithery badge](https://smithery.ai/badge/@kazuph/mcp-fetch)](https://smithery.ai/server/@kazuph/mcp-fetch)\n\nModel Context Protocol server for fetching web content and processing images. This allows Claude Desktop (or any MCP client) to fetch web content and handle images appropriately.\n\n## Quick Start (For Users)\n\nTo use this tool with Claude Desktop, simply add the following to your Claude Desktop configuration (`~/Library/Application Support/Claude/claude_desktop_config.json`):\n\n```json\n{\n  \"tools\": {\n    \"fetch\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@kazuph/mcp-fetch\"]\n    }\n  }\n}\n```\n\nThis will automatically download and run the latest version of the tool when needed.\n\n### Required Setup\n\n1. Enable Accessibility for Claude:\n   - Open System Settings\n   - Go to Privacy & Security > Accessibility\n   - Click the \"+\" button\n   - Add Claude from your Applications folder\n   - Turn ON the toggle for Claude\n\nThis accessibility setting is required for automated clipboard operations (Cmd+V) to work properly.\n\n## For Developers\n\nThe following sections are for those who want to develop or modify the tool.\n\n## Prerequisites\n\n- Node.js 18+\n- macOS (for clipboard operations)\n- Claude Desktop (install from https://claude.ai/desktop)\n- tsx (install via `npm install -g tsx`)\n\n## Installation\n\n### Installing via Smithery\n\nTo install MCP Fetch for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@kazuph/mcp-fetch):\n\n```bash\nnpx -y @smithery/cli install @kazuph/mcp-fetch --client claude\n```\n\n### Manual Installation\n```bash\ngit clone https://github.com/kazuph/mcp-fetch.git\ncd mcp-fetch\nnpm install\nnpm run build\n```\n\n## Image Processing Specifications\n\nWhen processing images from web content, the following limits are applied:\n\n- Maximum 6 images per group\n- Maximum height of 8000 pixels per group\n- Maximum size of 30MB per group\n\nIf content exceeds these limits, images will be automatically split into multiple groups, and you'll need to paste (Cmd+V) multiple times.\n\n## Configuration\n\n1. Make sure Claude Desktop is installed and running.\n\n2. Install tsx globally if you haven't:\n```bash\nnpm install -g tsx\n# or\npnpm add -g tsx\n```\n\n3. Modify your Claude Desktop config located at:\n`~/Library/Application Support/Claude/claude_desktop_config.json`\n\nYou can easily find this through the Claude Desktop menu:\n1. Open Claude Desktop\n2. Click Claude on the Mac menu bar\n3. Click \"Settings\"\n4. Click \"Developer\"\n\nAdd the following to your MCP client's configuration:\n\n```json\n{\n  \"tools\": {\n    \"fetch\": {\n      \"args\": [\"tsx\", \"/path/to/mcp-fetch/index.ts\"]\n    }\n  }\n}\n```\n\n## Available Tools\n\n- `fetch`: Retrieves URLs from the Internet and extracts their content as markdown. Images are automatically processed and prepared for clipboard operations.\n\n## Notes\n\n- This tool is designed for macOS only due to its dependency on macOS-specific clipboard operations.\n- Images are processed using Sharp for optimal performance and quality.\n- When multiple images are found, they are merged vertically with consideration for size limits.\n- Animated GIFs are automatically handled by extracting their first frame.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ai",
        "images",
        "retrieval",
        "images integration",
        "processes images",
        "ai models"
      ],
      "category": "image-and-video-generation"
    },
    "JigsawStack--jigsawstack-mcp-server": {
      "owner": "JigsawStack",
      "name": "jigsawstack-mcp-server",
      "url": "https://github.com/JigsawStack/jigsawstack-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/JigsawStack.webp",
      "description": "Generate images from text using advanced AI models. The server facilitates the integration and management of image generation tools within an MCP framework.",
      "stars": 23,
      "forks": 5,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-08-22T15:15:38Z",
      "readme_content": "# JigsawStack MCP Server\n\n## Introduction\nJigsawStack MCP (Model Context Protocol) Server is a versatile platform designed to facilitate the integration and management of various tools. Each directory within the server represents a distinct tool that can be utilized for different purposes by an LLM. The server is built using Node.js and Express.js, and each tool is encapsulated within its own directory, making it easy to add, remove, or update tools without affecting the overall system.\n\nStart by obtaining your JIGSAWSTACK_API_KEY from the our website. You will need this key to access the JigsawStack services. You can get your API key by signing up for a free account at [JigsawStack](https://jigsawstack.com/dashboard).\n\nYou can also install our MCPs via [Smithery AI](https://smithery.ai/?q=jigsawstack)\n\n## Installation\n\n### Prerequisites\n- Ensure you have `git` installed on your system.\n- Ensure you have `node.js` and `npm` installed.\n- Alternatively, you can use `yarn` instead of `npm`. as a package manager.\n\n### Steps to Setup the repository:\n1. Clone the repository:\n    ```sh\n    git clone https://github.com/yourusername/jigsawstack-mcp-server.git\n    ```\n2. Navigate to the project directory:\n    ```sh\n    cd jigsawstack-mcp-server\n    ```\n3. Install the necessary dependencies:\n    ```sh\n    npm install or yarn install\n    ```\n\n## What is MCP?\nMCP stands for Model Context Protocol. It is a framework that allows users to integrate LLMs and manage various tools and components exposing external data in a modular fashion. Here each tool is encapsulated within its own directory, making it easy to add, remove, or update tools without affecting the overall system.\n\n## Using JigsawStack MCP Server\nThere are four tools available in the MCP Server. Each tool is contained within its own directory and has its own set of instructions for use.\n\n### Running a tool\nTo run a tool,\n1. cd into the tool directory and follow the instructions.\n2. Export the JIGSAWSTACK_API_KEY environment variable with your JIGSAWSTACK API key.\n    ```sh\n    export JIGSAWSTACK_API_KEY=your_api_key\n    ```\n3. Start the server:\n    ```sh\n    npm start\n    ```\n4. Access the server through your web browser at `http://localhost:3000`.\n\n### Directory Structure\n- `/ai-web-scraper`: Let AI scrape the internet for you!\n- `/ai-web-search`: Search powered by AI capable of handling complex queries.\n- `/image-generation`: Generate images using prompts, to receive a base64 string of the image.\n\n## Contact\nFor any questions or issues, please contact us at hello@jigsawstack.com.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "jigsawstack",
        "ai",
        "mcp",
        "generate images",
        "image generation",
        "jigsawstack mcp"
      ],
      "category": "image-and-video-generation"
    },
    "Kira-Pgr--PromptShopMCP": {
      "owner": "Kira-Pgr",
      "name": "PromptShopMCP",
      "url": "https://github.com/Kira-Pgr/PromptShopMCP",
      "imageUrl": "/freedevtools/mcp/pfp/Kira-Pgr.webp",
      "description": "Transforms images based on natural language commands, enabling users to edit photos by describing desired changes such as adding accessories or modifying backgrounds.",
      "stars": 14,
      "forks": 7,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-03T20:38:19Z",
      "readme_content": "# PromptShopMCP\n\n![](https://badge.mcpx.dev?type=server 'MCP Server')  \n\nEnglish | [中文](README_ZH.md)   \n\n\nA powerful MCP (Model Context Protocol) server that transforms images using simple text commands. Edit photos like a professional designer - just describe what you want in natural language!\n## Demo\nOriginal Image  \n<img src=\"https://github.com/user-attachments/assets/a987b4c4-3bba-4a52-a2a8-9f088868d857\" width=\"300\"/>  \n\nPrompt: **add a coat to the dog**  \n<img src=\"https://github.com/user-attachments/assets/6de3cdd1-a3b9-422b-95dd-12e2172f6f1d\" width=\"300\"/>  \n\nPrompt: **Add a hat to it**  \n<img src=\"https://github.com/user-attachments/assets/047289ca-f3d0-4d16-acf7-09d5af641c68\" width=\"300\"/>  \n \n\n##  Features\n\n- **Image Generation**: Create images from text prompts using Google's Gemini models\n- **Image Modification**: Transform existing images based on text instructions\n- **Background Removal**: Remove backgrounds from images using the remove.bg API\n- **Image Hosting**: Share generated images via FreeImage.host\n- **Resource Management**: Track and manage generated and uploaded images\n\n## Requirements\n\n- Python 3.11 or higher\n- Required API keys:\n  - Google Gemini API key [Get key](https://aistudio.google.com/apikey)\n  - FreeImage.host API key [Get key](https://freeimage.host/page/api)\n  - Remove.bg API key [Get key](https://www.remove.bg/dashboard#api-key)\n\n##  Installation\n\n1. Clone this repository:\n   ```sh\n   git https://github.com/Kira-Pgr/Image-Toolkit-MCP-Server.git\n   cd Image-Toolkit-MCP-Server\n   ```\n\n2. Install UV (if not already installed):\n   ```sh\n   # On macOS and Linux.\n   curl -LsSf https://astral.sh/uv/install.sh | sh\n   # On Windows.\n   powershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n   # With pip.\n   pip install uv\n   ```\n\n3. Install dependencies using UV:\n   ```sh\n   uv venv --python=python3.11\n   source .venv/bin/activate #or .venv/Scripts/activate on Windows\n   uv pip install -r requirements.txt\n   ```\n\n##  Usage\n\n1. **Claude Desktop Integration**: Add the following configuration to your `claude_desktop_config.json` file to run the server directly from Claude Desktop:\n   ```json\n   \"PromptShopMCP\": {\n     \"command\": \"uv\",\n     \"args\": [\n       \"--directory\",\n       \"/project/dir/\",\n       \"run\",\n       \"mcp\",\n       \"run\",\n       \"/project/dir/server.py\"\n     ],\n     \"env\": {\n       \"GEMINI_API_KEY\": \"key\",\n       \"FREEIMAGE_API_KEY\": \"key\",\n       \"REMOVEBG_API_KEY\": \"key\"\n     }\n   }\n   ```\n   Note: Replace the placeholder `\"key\"` values with your actual API keys.\n2. **Cursor Integration**:    \n   **Linux/macOS**:\n  Modify the `cursor.sh` file to set your API keys and project directory.   \n  * In cursor settings, go to the \"MCP\" tab, click on `Add new MCP server`,   \n  * Name the server whatever you want, and set the command to `sh /absolute/path/to/cursor.sh`.   \n  * Wait for the server to start, and you can see the server and available tools.   \n  * Then when you use the agent, it would automatically detect whether use the tools.   \n  <img width=\"1240\" alt=\"image\" src=\"https://github.com/user-attachments/assets/b41016fe-a0f8-4029-8f5d-82f25c606a65\" />\n  \n  **Windows**: \n  Modify the `cursor.bat` file to set your API keys and project directory.   \n  * In cursor settings, go to the \"MCP\" tab, click on `Add new MCP server`,   \n  * Name the server whatever you want, and set the command to `cmd /c C:\\absolute\\path\\to\\cursor.bat`.   \n  * Wait for the server to start, and you can see the server and available tools.   \n  * Then when you use the agent, it would automatically detect whether use the tools.   \n\n\n\n\n## Acknowledgements\n\n- [Google Gemini](https://aistudio.google.com/): For the image generation capabilities\n- [Remove.bg](https://www.remove.bg/): For background removal services\n- [FreeImage.host](https://freeimage.host/): For image hosting services\n- [MCP](https://modelcontextprotocol.io/introduction): For the Model Context Protocol\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "promptshopmcp",
        "images",
        "pgr",
        "pgr promptshopmcp",
        "promptshopmcp transforms",
        "video generation"
      ],
      "category": "image-and-video-generation"
    },
    "Letz-AI--letzai-mcp": {
      "owner": "Letz-AI",
      "name": "letzai-mcp",
      "url": "https://github.com/Letz-AI/letzai-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/Letz-AI.webp",
      "description": "Create and upscale images based on prompts using the LetzAI MCP. This server integrates with the Claude Desktop App for seamless image generation.",
      "stars": 1,
      "forks": 2,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-03-25T17:46:55Z",
      "readme_content": "# LetzAI MCP Setup Guide\n\nThis guide will walk you through the process of setting up and using the LetzAI MCP (Model Context Protocol) for image generation.\n\n## Prerequisites\n\nBefore you begin, ensure that you have the following:\n\n- **Node.js** installed on your system. You can download it from [Node.js official site](https://nodejs.org/).\n- **Claude Desktop App** installed. If you don't have it, download it from [Claude Desktop App](https://claude.app).\n- **LetzAI API Key**. You can obtain it by visiting [LetzAI API](https://letz.ai/docs/api).\n\n## Setup Steps\n\n### 1. Download the Git Folder\n\nDownload the repository containing the LetzAI MCP project and place it in a location outside of your Downloads folder. For example:\n\n```\nC:\\\\Users\\\\username\\\\desktop\n```\n\nAlternatively, you can use `git clone` to clone the repository:\n\n```bash\ngit clone <repository-url> C:\\\\Users\\\\username\\\\desktop\n```\n\n### 2. Install Dependencies\n\nNavigate to the project folder using your terminal or command prompt:\n\n```bash\ncd C:\\\\Users\\\\username\\\\desktop\n```\n\nRun the following command to install all required dependencies:\n\n```bash\nnpm install\n```\n\n### 3. Compile the Project\n\nAfter installing the dependencies, compile the TypeScript files into JavaScript using the following command:\n\n```bash\nnpx tsc\n```\n\nThis will generate the compiled JavaScript files in the `build` folder.\n\n### 4. Restart Claude App\n\nAfter running `npx tsc`, you must **restart** the Claude Desktop App for it to recognize the updated MCP configuration and compiled files.\n\n### 5. Set Up MCP Configuration in Claude Desktop App\n\n\n\n1. **Open the Claude Desktop App**.\n2. **Click on the Menu Icon** in the top-left corner.\n3. From the dropdown, select **File**.\n4. Navigate to **Settings**.\n5. Under the **Developer** section, you will see an option for **Edit Config**.\n   \n6. Click on **Edit Config** — this will open the configuration folder.\n7. Locate the file `claude_desktop_config.json` and edit it as needed.\n\n#### Windows Configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"letzai\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"C:\\\\ABSOLUTE\\\\PATH\\\\TO\\\\PARENT\\\\FOLDER\\\\letzai-mcp\\\\build\\\\index.js\"\n      ],\n      \"env\": {\n        \"LETZAI_API_KEY\": \"<Your LetzAI API Key>\"\n      }\n    }\n  }\n}\n```\n\n#### Ubuntu Configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"letzai\": {\n      \"command\": \"node\",\n      \"args\": [\"/ABSOLUTE/PATH/TO/PARENT/FOLDER/letzai-mcp/build/index.js\"],\n      \"env\": {\n        \"LETZAI_API_KEY\": \"<Your LetzAI API Key>\"\n      }\n    }\n  }\n}\n```\n\n#### macOS Configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"letzai\": {\n      \"command\": \"node\",\n      \"args\": [\"/ABSOLUTE/PATH/TO/PARENT/FOLDER/letzai-mcp/build/index.js\"],\n      \"env\": {\n        \"LETZAI_API_KEY\": \"<Your LetzAI API Key>\"\n      }\n    }\n  }\n}\n```\n\n### Configuration Explanation\n\n- **command**: The command to run the application. We use `node` to run the JavaScript file generated by TypeScript.\n- **args**: This is the path to the compiled `index.js` file. Make sure the path is correct according to where your files are located after compilation. If you've placed the folder at `C:\\\\Users\\\\username\\\\desktop\\\\letzai-mcp`, the path will be:\n\n```\n\nC:\\\\Users\\\\username\\\\desktop\\\\letzai-mcp\\\\build\\\\index.js\n\n```\n\n### 6. Run the MCP Server\n\nNow that everything is set up, you can start using the LetzAI MCP in the Claude Desktop App. The server should be ready for image generation tasks once the app is running with the correct API key in the environment.\n\n**Important:** After making changes to the configuration, you **must restart Claude** for the changes to take effect.\n\n### 7. Testing the New MCP in Claude\n\n\nClick on the hammer icon to view the installed MCP tools.\n\n\nOnce you've set up the MCP in the Claude Desktop App, you can test it by running the following prompt:\n\n- **Create image with LetzAI using prompt: \"photo of @mischstrotz drinking a beer, dressed as a knight\"**\n\nThis will create the image based on the provided prompt, using the model @mischstrotz from LetzAI. Claude will open the image in your preferred browser.\n\n- **Upscale this image with strength 1: [https://letz.ai/image/d6a67077-f156-46d7-a1a2-1dc49e83dd91](https://images.letz.ai/5ed74083-f9d1-4897-b8e3-c8f1596af767/d6a67077-f156-46d7-a1a2-1dc49e83dd91/high_quality_photo_of_mischstrotz_holding_a_beer_s20250322080513.jpg)**\n\nThis will upscale the image using the strength parameter 1. You can pass entire URLs, or just the LetzAI Image IDs e.g. d6a67077-f156-46d7-a1a2-1dc49e83dd91\n\n## Troubleshooting\n\n- **Node.js not found**: Ensure that Node.js is installed and added to your system's PATH environment variable.\n- **Invalid API Key**: Double-check that you have correctly added your API key under the `LETZAI_API_KEY` variable in the Claude Desktop App settings.\n- **File Path Issues**: Make sure that the path to the `index.js` file is correct. If you're unsure about the path, use the absolute path to the file.\n\nFor more detailed documentation and support, visit [LetzAI Docs](https://letz.ai/docs/api).",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "upscale",
        "letzai",
        "images",
        "image generation",
        "upscale images",
        "video generation"
      ],
      "category": "image-and-video-generation"
    },
    "LoganLxb--LoganLxb": {
      "owner": "LoganLxb",
      "name": "LoganLxb",
      "url": "https://github.com/LoganLxb/LoganLxb",
      "imageUrl": "/freedevtools/mcp/pfp/LoganLxb.webp",
      "description": "Logan provides tools and applications aimed at enhancing user interaction in mixed reality environments through augmented and virtual reality technologies. It focuses on facilitating the development of immersive digital experiences and applications.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "",
      "updated_at": "2024-10-08T18:42:17Z",
      "readme_content": "<h2 align=\"center\">Hi there 👋</h2>\n<!--\n**LoganLxb/LoganLxb** is a ✨ _special_ ✨ repository because its `README.md` (this file) appears on your GitHub profile.\n-->\n\n## 🖥️ Logan\n\nI'm a developers experienced in creating and developing the future thanks to AR,VR and Mixed reality.\n\n- 🔭 I’m currently working on democratizing mixed reality with Glassear\n- 🌱 I’m currently learning computer vision, python and c#\n\n## 💬 Ask me about ...\n* Unity development\n* Mobile / headmounted Augmented Reality\n* Virtual Reality\n* Image detection\n\n##  👀 Find me\n- 📫 How to reach me: logan@xrexp.io\n\n[![Top Langs](https://github-readme-stats.vercel.app/api/top-langs/?username=LoganLxb&layout=compact&theme=gruvbox)](https://github.com/LoganLxb/github-readme-stats)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "loganlxb",
        "immersive",
        "logan",
        "virtual reality",
        "augmented virtual",
        "generation loganlxb"
      ],
      "category": "image-and-video-generation"
    },
    "Lucker631--mcp-templateio": {
      "owner": "Lucker631",
      "name": "mcp-templateio",
      "url": "https://github.com/Lucker631/mcp-templateio",
      "imageUrl": "/freedevtools/mcp/pfp/Lucker631.webp",
      "description": "Generates customized visuals by creating images based on templates using the Templated.io API. Supports dynamic graphics creation through user-provided text and image URLs.",
      "stars": 0,
      "forks": 4,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-07-10T15:36:42Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/lucker631-mcp-templateio-badge.png)](https://mseep.ai/app/lucker631-mcp-templateio)\n\n# MCP TemplateIO - Image Generation Tool\n\nA Model Context Protocol (MCP) server built with mcp-framework that provides an image generation tool using Templated.io.\n\n## Overview\n\nThis template provides a starting point for building MCP servers with custom tools. It includes an example tool and instructions on how to add more tools, develop them, and publish them to npm. This README will guide you through the process of setting up, developing, and deploying your own MCP server.\n\n## Quick Start\n\n```bash\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n```\n\n## Project Structure\n\n```\nmcp-templateio/\n├── src/\n│   ├── tools/        # MCP Tools\n│   │   ├── ExampleTool.ts\n│   │   └── TemplatedImageTool.ts # Image generation tool\n│   └── index.ts      # Server entry point\n├── package.json\n└── tsconfig.json\n```\n\n## Available Tools\n\n### Templated Image Generator\n\nThis tool generates an image based on a template, given text and image URLs, using the Templated.io API.\n\n**Input Parameters:**\n\n- `templateId`: ID of the Templated.io template to use\n- `photoBgImageUrl`: URL for the image to place in the \"photo-bg\" layer.\n- `bgYellowImageUrl`: URL for the image to place in the \"bg-yellow\" layer.\n- `buildText`: Text content for the \"build\" text layer.\n\n## Tool Development\n\nExample tool structure:\n\n```typescript\nimport { MCPTool } from \"mcp-framework\";\nimport { z } from \"zod\";\n\ninterface MyToolInput {\n  message: string;\n}\n\nclass MyTool extends MCPTool<MyToolInput> {\n  name = \"my_tool\";\n  description = \"Describes what your tool does\";\n\n  schema = {\n    message: {\n      type: z.string(),\n      description: \"Description of this input parameter\",\n    },\n  };\n\n  async execute(input: MyToolInput) {\n    // Your tool logic here\n    return `Processed: ${input.message}`;\n  }\n}\n\nexport default MyTool;\n```\n\n## Adding Components\n\nThe project comes with an example tool in `src/tools/ExampleTool.ts` and the `TemplatedImageTool.ts`. You can add more tools using the CLI:\n\n```bash\n# Add a new tool\nmcp add tool my-tool\n\n# Example tools you might create:\nmcp add tool data-processor\nmcp add tool api-client\nmcp add tool file-handler\n```\n\n## Publishing to npm\n\n1. Update your package.json:\n\n   - Ensure `name` is unique and follows npm naming conventions\n   - Set appropriate `version`\n   - Add `description`, `author`, `license`, etc.\n   - Check `bin` points to the correct entry file\n\n2. Build and test locally:\n\n   ```bash\n   npm run build\n   npm link\n   mcp-templateio  # Test your CLI locally\n   ```\n\n3. Login to npm (create account if necessary):\n\n   ```bash\n   npm login\n   ```\n\n4. Publish your package:\n   ```bash\n   npm publish\n   ```\n\nAfter publishing, users can add it to their claude desktop client (read below) or run it with npx\n\n## Using with Claude Desktop\n\n### Local Development\n\nAdd this configuration to your Claude Desktop config file:\n\n**MacOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`\n**Windows**: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-templateio\": {\n      \"command\": \"node\",\n      \"args\": [\"/absolute/path/to/mcp-templateio/dist/index.js\"]\n    }\n  }\n}\n```\n\n### After Publishing\n\nGET YOUR API KEY HERE: https://app.templated.io/api-integration?template=4ae9a86b-4ecd-44ee-aebd-7c5a49c16969\n\nAdd this configuration to your Claude Desktop config file:\n\n**MacOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`\n**Windows**: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-templateio\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"C:\\\\Users\\\\alex0\\\\Documents\\\\AA_CodeAndScripts\\\\modelcontextprotocol\\\\mcp-templateio\\\\dist\\\\index.js\"\n      ],\n      \"env\": {\"TEMPLATED_API_KEY\":\"YOUR-API-KEY-HERE\"}\n    },\n  }\n}\n```\n\n## Building and Testing\n\n1. Make changes to your tools\n2. Run `npm run build` to compile\n3. The server will automatically load your tools on startup\n\n## Learn More\n\n- [MCP Framework Github](https://github.com/QuantGeekDev/mcp-framework)\n- [MCP Framework Docs](https://mcp-framework.com)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "templateio",
        "templated",
        "templates",
        "mcp templateio",
        "templateio generates",
        "graphics creation"
      ],
      "category": "image-and-video-generation"
    },
    "MichaelYangjson--mcp-ghibli-video": {
      "owner": "MichaelYangjson",
      "name": "mcp-ghibli-video",
      "url": "https://github.com/MichaelYangjson/mcp-ghibli-video",
      "imageUrl": "/freedevtools/mcp/pfp/MichaelYangjson.webp",
      "description": "Transforms static images into animated videos using AI technology. Users can manage video generation tasks and check API credits through a straightforward interface.",
      "stars": 4,
      "forks": 5,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-29T13:57:06Z",
      "readme_content": "# mcp-server-ghibli MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@MichaelYangjson/mcp-ghibli-video)](https://smithery.ai/server/@MichaelYangjson/mcp-ghibli-video)\n\nA TypeScript-based MCP server that provides AI image and video generation capabilities through a simple interface.\n\n> **Note**: This server requires an API key from [GPT4O Image Generator](https://www.gpt4oimg.com/). Please visit the website to obtain your API key before using this service.\n\n## Features\n\n### Tools\n\n#### 1. Image to Video Conversion\n\n- `image_to_video` - Convert static images into animated videos\n  - Required parameters:\n    - `image`: Base64 encoded image or image URL\n    - `api_key`: Authentication key\n  - Optional parameters:\n    - `prompt`: Text prompt to guide video generation (default: \"in the style of ghibli\")\n    - `aspect_ratio`: Output video aspect ratio (default: \"9:16\")\n    - `negative_prompt`: Negative prompt to guide generation (default: \"bad prompt\")\n\n#### 2. Points Management\n\n- `get_points` - Check remaining API credits\n  - Required parameters:\n    - `api_key`: Authentication key\n\n#### 3. Task Management\n\n- `get_task_result` - Check the status of a video generation task\n  - Required parameters:\n    - `taskId`: Task ID returned from image_to_video\n    - `api_key`: Authentication key\n\n## Development\n\nInstall dependencies:\n\n```bash\nnpm install\n```\n\nBuild the server:\n\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n\n```bash\nnpm run watch\n```\n\n## Installation\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-server-ghibli-video\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@openmcprouter/mcp-server-ghibli-video\"],\n      \"env\": {\n        \"Ghibli_API_URL\": \"https://www.gpt4oimg.com\"\n      }\n    }\n  }\n}\n```\n\n### Installing via Smithery\n\nTo install mcp-server-ghibli MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@MichaelYangjson/mcp-ghibli-video):\n\n```bash\nnpx -y @smithery/cli install @MichaelYangjson/mcp-ghibli-video --client claude\n```\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "animated",
        "ghibli",
        "videos",
        "animated videos",
        "video generation",
        "ghibli video"
      ],
      "category": "image-and-video-generation"
    },
    "MiniMax-AI--MiniMax-MCP-JS": {
      "owner": "MiniMax-AI",
      "name": "MiniMax-MCP-JS",
      "url": "https://github.com/MiniMax-AI/MiniMax-MCP-JS",
      "imageUrl": "/freedevtools/mcp/pfp/MiniMax-AI.webp",
      "description": "Integrates with MiniMax's AI capabilities to facilitate interaction with multimedia generation tools, including image generation, video generation, text-to-speech, and voice cloning. Supports a flexible and configurable JavaScript/TypeScript framework for versatile deployment scenarios.",
      "stars": 84,
      "forks": 29,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-28T15:24:03Z",
      "readme_content": "![export](https://github.com/MiniMax-AI/MiniMax-01/raw/main/figures/MiniMaxLogo-Light.png)\n\n<div align=\"center\">\n\n# MiniMax MCP JS\n\nJavaScript/TypeScript implementation of MiniMax MCP, providing image generation, video generation, text-to-speech, and more.\n\n<div style=\"line-height: 1.5;\">\n  <a href=\"https://www.minimax.io\" target=\"_blank\" style=\"margin: 2px; color: var(--fgColor-default);\">\n    <img alt=\"Homepage\" src=\"https://img.shields.io/badge/_Homepage-MiniMax-FF4040?style=flat-square&labelColor=2C3E50&logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB2aWV3Qm94PSIwIDAgNDkwLjE2IDQxMS43Ij48ZGVmcz48c3R5bGU+LmNscy0xe2ZpbGw6I2ZmZjt9PC9zdHlsZT48L2RlZnM+PHBhdGggY2xhc3M9ImNscy0xIiBkPSJNMjMzLjQ1LDQwLjgxYTE3LjU1LDE3LjU1LDAsMSwwLTM1LjEsMFYzMzEuNTZhNDAuODIsNDAuODIsMCwwLDEtODEuNjMsMFYxNDVhMTcuNTUsMTcuNTUsMCwxLDAtMzUuMDksMHY3OS4wNmE0MC44Miw0MC44MiwwLDAsMS04MS42MywwVjE5NS40MmExMS42MywxMS42MywwLDAsMSwyMy4yNiwwdjI4LjY2YTE3LjU1LDE3LjU1LDAsMCwwLDM1LjEsMFYxNDVBNDAuODIsNDAuODIsMCwwLDEsMTQwLDE0NVYzMzEuNTZhMTcuNTUsMTcuNTUsMCwwLDAsMzUuMSwwVjIxNy41aDBWNDAuODFhNDAuODEsNDAuODEsMCwxLDEsODEuNjIsMFYyODEuNTZhMTEuNjMsMTEuNjMsMCwxLDEtMjMuMjYsMFptMjE1LjksNjMuNEE0MC44Niw0MC44NiwwLDAsMCw0MDguNTMsMTQ1VjMwMC44NWExNy41NSwxNy41NSwwLDAsMS0zNS4wOSwwdi0yNjBhNDAuODIsNDAuODIsMCwwLDAtODEuNjMsMFYzNzAuODlhMTcuNTUsMTcuNTUsMCwwLDEtMzUuMSwwVjMzMGExMS42MywxMS42MywwLDEsMC0yMy4yNiwwdjQwLjg2YTQwLjgxLDQwLjgxLDAsMCwwLDgxLjYyLDBWNDAuODFhMTcuNTUsMTcuNTUsMCwwLDEsMzUuMSwwdjI2MGE0MC44Miw0MC44MiwwLDAsMCw4MS42MywwVjE0NWExNy41NSwxNy41NSwwLDEsMSwzNS4xLDBWMjgxLjU2YTExLjYzLDExLjYzLDAsMCwwLDIzLjI2LDBWMTQ1QTQwLjg1LDQwLjg1LDAsMCwwLDQ0OS4zNSwxMDQuMjFaIi8+PC9zdmc+&logoWidth=20\" style=\"display: inline-block; vertical-align: middle;\"/>\n  </a>\n  <a href=\"https://arxiv.org/abs/2501.08313\" target=\"_blank\" style=\"margin: 2px;\">\n    <img alt=\"Paper\" src=\"https://img.shields.io/badge/📖_Paper-MiniMax--01-FF4040?style=flat-square&labelColor=2C3E50\" style=\"display: inline-block; vertical-align: middle;\"/>\n  </a>\n  <a href=\"https://chat.minimax.io/\" target=\"_blank\" style=\"margin: 2px;\">\n    <img alt=\"Chat\" src=\"https://img.shields.io/badge/_MiniMax_Chat-FF4040?style=flat-square&labelColor=2C3E50&logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB2aWV3Qm94PSIwIDAgNDkwLjE2IDQxMS43Ij48ZGVmcz48c3R5bGU+LmNscy0xe2ZpbGw6I2ZmZjt9PC9zdHlsZT48L2RlZnM+PHBhdGggY2xhc3M9ImNscy0xIiBkPSJNMjMzLjQ1LDQwLjgxYTE3LjU1LDE3LjU1LDAsMSwwLTM1LjEsMFYzMzEuNTZhNDAuODIsNDAuODIsMCwwLDEtODEuNjMsMFYxNDVhMTcuNTUsMTcuNTUsMCwxLDAtMzUuMDksMHY3OS4wNmE0MC44Miw0MC44MiwwLDAsMS04MS42MywwVjE5NS40MmExMS42MywxMS42MywwLDAsMSwyMy4yNiwwdjI4LjY2YTE3LjU1LDE3LjU1LDAsMCwwLDM1LjEsMFYxNDVBNDAuODIsNDAuODIsMCwwLDEsMTQwLDE0NVYzMzEuNTZhMTcuNTUsMTcuNTUsMCwwLDAsMzUuMSwwVjIxNy41aDBWNDAuODFhNDAuODEsNDAuODEsMCwxLDEsODEuNjIsMFYyODEuNTZhMTEuNjMsMTEuNjMsMCwxLDEtMjMuMjYsMFptMjE1LjksNjMuNEE0MC44Niw0MC44NiwwLDAsMCw0MDguNTMsMTQ1VjMwMC44NWExNy41NSwxNy41NSwwLDAsMS0zNS4wOSwwdi0yNjBhNDAuODIsNDAuODIsMCwwLDAtODEuNjMsMFYzNzAuODlhMTcuNTUsMTcuNTUsMCwwLDEtMzUuMSwwVjMzMGExMS42MywxMS42MywwLDEsMC0yMy4yNiwwdjQwLjg2YTQwLjgxLDQwLjgxLDAsMCwwLDgxLjYyLDBWNDAuODFhMTcuNTUsMTcuNTUsMCwwLDEsMzUuMSwwdjI2MGE0MC44Miw0MC44MiwwLDAsMCw4MS42MywwVjE0NWExNy41NSwxNy41NSwwLDEsMSwzNS4xLDBWMjgxLjU2YTExLjYzLDExLjYzLDAsMCwwLDIzLjI2LDBWMTQ1QTQwLjg1LDQwLjg1LDAsMCwwLDQ0OS4zNSwxMDQuMjFaIi8+PC9zdmc+&logoWidth=20\" style=\"display: inline-block; vertical-align: middle;\"/>\n  </a>\n  <a href=\"https://www.minimax.io/platform\" style=\"margin: 2px;\">\n    <img alt=\"API\" src=\"https://img.shields.io/badge/⚡_API-Platform-FF4040?style=flat-square&labelColor=2C3E50\" style=\"display: inline-block; vertical-align: middle;\"/>\n  </a>\n</div>\n\n<div style=\"line-height: 1.5;\">\n  <a href=\"https://huggingface.co/MiniMaxAI\" target=\"_blank\" style=\"margin: 2px;\">\n    <img alt=\"Hugging Face\" src=\"https://img.shields.io/badge/🤗_Hugging_Face-MiniMax-FF4040?style=flat-square&labelColor=2C3E50\" style=\"display: inline-block; vertical-align: middle;\"/>\n  </a>\n  <a href=\"https://github.com/MiniMax-AI/MiniMax-AI.github.io/blob/main/images/wechat-qrcode.jpeg\" target=\"_blank\" style=\"margin: 2px;\">\n    <img alt=\"WeChat\" src=\"https://img.shields.io/badge/_WeChat-MiniMax-FF4040?style=flat-square&labelColor=2C3E50\" style=\"display: inline-block; vertical-align: middle;\"/>\n  </a>\n  <a href=\"https://www.modelscope.cn/organization/MiniMax\" target=\"_blank\" style=\"margin: 2px;\">\n    <img alt=\"ModelScope\" src=\"https://img.shields.io/badge/_ModelScope-MiniMax-FF4040?style=flat-square&labelColor=2C3E50\" style=\"display: inline-block; vertical-align: middle;\"/>\n  </a>\n</div>\n\n<div style=\"line-height: 1.5;\">\n  <a href=\"https://github.com/MiniMax-AI/MiniMax-MCP-JS/blob/main/LICENSE\" style=\"margin: 2px;\">\n    <img alt=\"Code License\" src=\"https://img.shields.io/badge/_Code_License-MIT-FF4040?style=flat-square&labelColor=2C3E50\" style=\"display: inline-block; vertical-align: middle;\"/>\n  </a>\n  <a href=\"https://smithery.ai/server/@MiniMax-AI/MiniMax-MCP-JS\"><img alt=\"Smithery Badge\" src=\"https://smithery.ai/badge/@MiniMax-AI/MiniMax-MCP-JS\"></a>\n</div>\n\n</div>\n\n## Documentation\n\n- [中文文档](README.zh-CN.md)\n- [Python Version](https://github.com/MiniMax-AI/MiniMax-MCP) - Official Python implementation of MiniMax MCP\n\n## Release Notes\n\n### July 22, 2025\n\n#### 🔧 Fixes & Improvements\n- **TTS Tool Fixes**: Fixed parameter handling for `languageBoost` and `subtitleEnable` in the `text_to_audio` tool\n- **API Response Enhancement**: TTS API can return both audio file and subtitle file, providing a more complete speech-to-text experience\n\n### July 7, 2025\n\n#### 🆕 What's New\n- **Voice Design**: New `voice_design` tool - create custom voices from descriptive prompts with preview audio\n- **Video Enhancement**: Added `MiniMax-Hailuo-02` model with ultra-clear quality and duration/resolution controls  \n- **Music Generation**: Enhanced `music_generation` tool powered by `music-1.5` model\n\n#### 📈 Enhanced Tools\n- `voice_design` - Generate personalized voices from text descriptions\n- `generate_video` - Now supports MiniMax-Hailuo-02 with 6s/10s duration and 768P/1080P resolution options\n- `music_generation` - High-quality music creation with music-1.5 model\n\n## Features\n\n- Text-to-Speech (TTS)\n- Image Generation\n- Video Generation\n- Voice Cloning\n- Music Generation\n- Voice Design\n- Dynamic configuration (supports both environment variables and request parameters)\n- Compatible with MCP platform hosting (ModelScope and other MCP platforms)\n\n## Installation\n\n### Installing via Smithery\n\nTo install MiniMax MCP JS for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@MiniMax-AI/MiniMax-MCP-JS):\n\n```bash\nnpx -y @smithery/cli install @MiniMax-AI/MiniMax-MCP-JS --client claude\n```\n\n### Installing manually\n```bash\n# Install with pnpm (recommended)\npnpm add minimax-mcp-js\n```\n\n## Quick Start\n\nMiniMax MCP JS implements the [Model Context Protocol (MCP)](https://github.com/anthropics/model-context-protocol) specification and can be used as a server to interact with MCP-compatible clients (such as Claude AI).\n\n### Quickstart with MCP Client\n\n1. Get your API key from [MiniMax International Platform](https://www.minimax.io/platform/user-center/basic-information/interface-key).\n2. Make sure that you already installed [Node.js and npm](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm)\n3. **Important: API HOST&KEY are different in different region**, they must match, otherwise you will receive an `Invalid API key` error.\n\n|Region| Global  | Mainland  |\n|:--|:-----|:-----|\n|MINIMAX_API_KEY| go get from [MiniMax Global](https://www.minimax.io/platform/user-center/basic-information/interface-key) | go get from [MiniMax](https://platform.minimaxi.com/user-center/basic-information/interface-key) |\n|MINIMAX_API_HOST| ​https://api.minimaxi.chat (note the extra **\"i\"**) | ​https://api.minimax.chat |\n\n\n### Using with MCP Clients (Recommended)\n\nConfigure your MCP client:\n\n#### Claude Desktop\n\nGo to `Claude > Settings > Developer > Edit Config > claude_desktop_config.json` to include:\n\n```json\n{\n  \"mcpServers\": {\n    \"minimax-mcp-js\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"minimax-mcp-js\"\n      ],\n      \"env\": {\n        \"MINIMAX_API_HOST\": \"<https://api.minimaxi.chat|https://api.minimax.chat>\",\n        \"MINIMAX_API_KEY\": \"<your-api-key-here>\",\n        \"MINIMAX_MCP_BASE_PATH\": \"<local-output-dir-path, such as /User/xxx/Desktop>\",\n        \"MINIMAX_RESOURCE_MODE\": \"<optional, [url|local], url is default, audio/image/video are downloaded locally or provided in URL format>\"\n      }\n    }\n  }\n}\n```\n\n#### Cursor\n\nGo to `Cursor → Preferences → Cursor Settings → MCP → Add new global MCP Server` to add the above config.\n\n⚠️ **Note**: If you encounter a \"No tools found\" error when using MiniMax MCP JS with Cursor, please update your Cursor to the latest version. For more information, see this [discussion thread](https://forum.cursor.com/t/mcp-servers-no-tools-found/49094/23).\n\nThat's it. Your MCP client can now interact with MiniMax through these tools.\n\n**For local development**: \nWhen developing locally, you can use `npm link` to test your changes:\n```bash\n# In your project directory\nnpm link\n```\n\nThen configure Claude Desktop or Cursor to use npx as shown above. This will automatically use your linked version.\n\n⚠️ **Note**: The API key needs to match the host address. Different hosts are used for global and mainland China versions:\n- Global Host: `https://api.minimaxi.chat` (note the extra \"i\")\n- Mainland China Host: `https://api.minimaxi.chat`\n\n## Transport Modes\n\nMiniMax MCP JS supports three transport modes:\n\n| Feature | stdio (default) | REST | SSE |\n|:-----|:-----|:-----|:-----|\n| Environment | Local only | Local or cloud deployment | Local or cloud deployment |\n| Communication | Via `standard I/O` | Via `HTTP requests` | Via `server-sent events` |\n| Use Cases | Local MCP client integration | API services, cross-language calls | Applications requiring server push |\n| Input Restrictions | Supports `local files` or `URL` resources | When deployed in cloud, `URL` input recommended | When deployed in cloud, `URL` input recommended |\n\n## Configuration\n\nMiniMax-MCP-JS provides multiple flexible configuration methods to adapt to different use cases. The configuration priority from highest to lowest is as follows:\n\n### 1. Request Parameter Configuration (Highest Priority)\n\nIn platform hosting environments (like ModelScope or other MCP platforms), you can provide an independent configuration for each request via the `meta.auth` object in the request parameters:\n\n```json\n{\n  \"params\": {\n    \"meta\": {\n      \"auth\": {\n        \"api_key\": \"your_api_key_here\",\n        \"api_host\": \"<https://api.minimaxi.chat|https://api.minimaxi.chat>\",\n        \"base_path\": \"/path/to/output\",\n        \"resource_mode\": \"url\"\n      }\n    }\n  }\n}\n```\n\nThis method enables multi-tenant usage, where each request can use different API keys and configurations.\n\n### 2. API Configuration\n\nWhen used as a module in other projects, you can pass configuration through the `startMiniMaxMCP` function:\n\n```javascript\nimport { startMiniMaxMCP } from 'minimax-mcp-js';\n\nawait startMiniMaxMCP({\n  apiKey: 'your_api_key_here',\n  apiHost: 'https://api.minimaxi.chat', // Global Host - https://api.minimaxi.chat, Mainland Host - https://api.minimax.chat\n  basePath: '/path/to/output',\n  resourceMode: 'url'\n});\n```\n\n### 3. Command Line Arguments\n\n1. Install the CLI tool globally:\n```bash\n# Install globally\npnpm install -g minimax-mcp-js\n```\n\n2. When used as a CLI tool, you can provide configuration via command line arguments:\n\n```bash\nminimax-mcp-js --api-key your_api_key_here --api-host https://api.minimaxi.chat --base-path /path/to/output --resource-mode url\n```\n\n### 4. Environment Variables (Lowest Priority)\n\nThe most basic configuration method is through environment variables:\n\n```bash\n# MiniMax API Key (required)\nMINIMAX_API_KEY=your_api_key_here\n\n# Base path for output files (optional, defaults to user's desktop)\nMINIMAX_MCP_BASE_PATH=~/Desktop\n\n# MiniMax API Host (optional, defaults to https://api.minimaxi.chat, Global Host - https://api.minimaxi.chat, Mainland Host - https://api.minimax.chat)\nMINIMAX_API_HOST=https://api.minimaxi.chat\n\n# Resource mode (optional, defaults to 'url')\n# Options: 'url' (return URLs), 'local' (save files locally)\nMINIMAX_RESOURCE_MODE=url\n```\n\n### Configuration Priority\n\nWhen multiple configuration methods are used, the following priority order applies (from highest to lowest):\n\n1. **Request-level configuration** (via `meta.auth` in each API request)\n2. **Command line arguments**\n3. **Environment variables**\n4. **Configuration file**\n5. **Default values**\n\nThis prioritization ensures flexibility across different deployment scenarios while maintaining per-request configuration capabilities for multi-tenant environments.\n\n### Configuration Parameters\n\n| Parameter | Description | Default Value |\n|-----------|-------------|---------------|\n| apiKey | MiniMax API Key | None (Required) |\n| apiHost | MiniMax API Host | Global Host - https://api.minimaxi.chat, Mainland Host - https://api.minimax.chat |\n| basePath | Base path for output files | User's desktop |\n| resourceMode | Resource handling mode, 'url' or 'local' | url |\n\n⚠️ **Note**: The API key needs to match the host address. Different hosts are used for global and mainland China versions:\n- Global Host: `https://api.minimaxi.chat` (note the extra \"i\")\n- Mainland China Host: `https://api.minimax.chat`\n\n## Example usage\n\n⚠️ Warning: Using these tools may incur costs.\n\n### 1. broadcast a segment of the evening news\n<img src=\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/Snipaste_2025-04-09_20-07-53.png?x-oss-process=image/resize,p_50/format,webp\" style=\"display: inline-block; vertical-align: middle;\"/>\n\n### 2. clone a voice\n<img src=\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/Snipaste_2025-04-09_19-45-13.png?x-oss-process=image/resize,p_50/format,webp\" style=\"display: inline-block; vertical-align: middle;\"/>\n\n### 3. generate a video\n<img src=\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/Snipaste_2025-04-09_19-58-52.png?x-oss-process=image/resize,p_50/format,webp\" style=\"display: inline-block; vertical-align: middle;\"/>\n<img src=\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/Snipaste_2025-04-09_19-59-43.png?x-oss-process=image/resize,p_50/format,webp\" style=\"display: inline-block; vertical-align: middle; \"/>\n\n### 4. generate images\n<img src=\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/gen_image.png?x-oss-process=image/resize,p_50/format,webp\" style=\"display: inline-block; vertical-align: middle;\"/>\n<img src=\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/gen_image1.png?x-oss-process=image/resize,p_50/format,webp\" style=\"display: inline-block; vertical-align: middle; \"/>\n\n### 5. generate music\n<img src=\"https://filecdn.minimax.chat/public/5675b3dc-6789-4ceb-9505-8ef39ae4224f.png?x-oss-process=image/resize,p_50/format,webp\" style=\"display: inline-block; vertical-align: middle;\"/>\n\n### 6. voice design\n<img src=\"https://filecdn.minimax.chat/public/5654f5df-0642-477f-9c5d-b853d185b8b0.png?x-oss-process=image/resize,p_50/format,webp\" style=\"display: inline-block; vertical-align: middle;\"/>\n\n## Available Tools\n\n### Text to Audio\n\nConvert text to speech audio file.\n\nTool Name: `text_to_audio`\n\nParameters:\n- `text`: Text to convert (required)\n- `model`: Model version, options are 'speech-02-hd', 'speech-02-turbo', 'speech-01-hd', 'speech-01-turbo', 'speech-01-240228', 'speech-01-turbo-240228', default is 'speech-02-hd'\n- `voiceId`: Voice ID, default is 'male-qn-qingse'\n- `speed`: Speech speed, range 0.5-2.0, default is 1.0\n- `vol`: Volume, range 0.1-10.0, default is 1.0\n- `pitch`: Pitch, range -12 to 12, default is 0\n- `emotion`: Emotion, options are 'happy', 'sad', 'angry', 'fearful', 'disgusted', 'surprised', 'neutral', default is 'happy'. Note: This parameter only works with 'speech-02-hd', 'speech-02-turbo', 'speech-01-turbo', 'speech-01-hd' models\n- `format`: Audio format, options are 'mp3', 'pcm', 'flac', 'wav', default is 'mp3'\n- `sampleRate`: Sample rate (Hz), options are 8000, 16000, 22050, 24000, 32000, 44100, default is 32000\n- `bitrate`: Bitrate (bps), options are 64000, 96000, 128000, 160000, 192000, 224000, 256000, 320000, default is 128000\n- `channel`: Audio channels, options are 1 or 2, default is 1\n- `languageBoost`: Enhance the ability to recognize specified languages and dialects.\nSupported values include:\n'Chinese', 'Chinese,Yue', 'English', 'Arabic', 'Russian', 'Spanish', 'French', 'Portuguese', 'German', 'Turkish', 'Dutch', 'Ukrainian', 'Vietnamese', 'Indonesian', 'Japanese', 'Italian', 'Korean', 'Thai', 'Polish', 'Romanian', 'Greek', 'Czech', 'Finnish', 'Hindi', 'auto', default is 'auto'\n- `stream`: Enable streaming output\n- `subtitleEnable`: The parameter controls whether the subtitle service is enabled. The model must be 'speech-01-turbo' or 'speech-01-hd'. If this parameter is not provided, the default value is false\n- `outputDirectory`: Directory to save the output file. `outputDirectory` is relative to `MINIMAX_MCP_BASE_PATH` (or `basePath` in config). The final save path is `${basePath}/${outputDirectory}`. For example, if `MINIMAX_MCP_BASE_PATH=~/Desktop` and `outputDirectory=workspace`, the output will be saved to `~/Desktop/workspace/`. (optional)\n- `outputFile`: Path to save the output file (optional, auto-generated if not provided)\n\n### Play Audio\n\nPlay an audio file. Supports WAV and MP3 formats. Does not support video.\n\nTool Name: `play_audio`\n\nParameters:\n- `inputFilePath`: Path to the audio file to play (required)\n- `isUrl`: Whether the audio file is a URL, default is false\n\n### Voice Clone\n\nClone a voice from an audio file.\n\nTool Name: `voice_clone`\n\nParameters:\n- `audioFile`: Path to audio file (required)\n- `voiceId`: Voice ID (required)\n- `text`: Text for demo audio (optional)\n- `outputDirectory`: Directory to save the output file. `outputDirectory` is relative to `MINIMAX_MCP_BASE_PATH` (or `basePath` in config). The final save path is `${basePath}/${outputDirectory}`. For example, if `MINIMAX_MCP_BASE_PATH=~/Desktop` and `outputDirectory=workspace`, the output will be saved to `~/Desktop/workspace/`. (optional)\n\n### Text to Image\n\nGenerate images based on text prompts.\n\nTool Name: `text_to_image`\n\nParameters:\n- `prompt`: Image description (required)\n- `model`: Model version, default is 'image-01'\n- `aspectRatio`: Aspect ratio, default is '1:1', options are '1:1', '16:9','4:3', '3:2', '2:3', '3:4', '9:16', '21:9'\n- `n`: Number of images to generate, range 1-9, default is 1\n- `promptOptimizer`: Whether to optimize the prompt, default is true\n- `subjectReference`: Path to local image file or public URL for character reference (optional)\n- `outputDirectory`: Directory to save the output file. `outputDirectory` is relative to `MINIMAX_MCP_BASE_PATH` (or `basePath` in config). The final save path is `${basePath}/${outputDirectory}`. For example, if `MINIMAX_MCP_BASE_PATH=~/Desktop` and `outputDirectory=workspace`, the output will be saved to `~/Desktop/workspace/`. (optional)\n- `outputFile`: Path to save the output file (optional, auto-generated if not provided)\n- `asyncMode`: Whether to use async mode. Defaults to False. If True, the video generation task will be submitted asynchronously and the response will return a task_id. Should use `query_video_generation` tool to check the status of the task and get the result. (optional)\n\n### Generate Video\n\nGenerate videos based on text prompts.\n\nTool Name: `generate_video`\n\nParameters:\n- `prompt`: Video description (required)\n- `model`: Model version, options are 'T2V-01', 'T2V-01-Director', 'I2V-01', 'I2V-01-Director', 'I2V-01-live', 'S2V-01', 'MiniMax-Hailuo-02', default is 'MiniMax-Hailuo-02'\n- `firstFrameImage`: Path to first frame image (optional)\n- `duration`: The duration of the video. The model must be \"MiniMax-Hailuo-02\". Values can be 6 and 10. (optional)\n- `resolution`: The resolution of the video. The model must be \"MiniMax-Hailuo-02\". Values range [\"768P\", \"1080P\"]. (optional)\n- `outputDirectory`: Directory to save the output file. `outputDirectory` is relative to `MINIMAX_MCP_BASE_PATH` (or `basePath` in config). The final save path is `${basePath}/${outputDirectory}`. For example, if `MINIMAX_MCP_BASE_PATH=~/Desktop` and `outputDirectory=workspace`, the output will be saved to `~/Desktop/workspace/`. (optional)\n- `outputFile`: Path to save the output file (optional, auto-generated if not provided)\n- `asyncMode`: Whether to use async mode. Defaults to False. If True, the video generation task will be submitted asynchronously and the response will return a task_id. Should use `query_video_generation` tool to check the status of the task and get the result. (optional)\n\n### Query Video Generation Status\n\nQuery the status of a video generation task.\n\nTool Name: `query_video_generation`\n\nParameters:\n- `taskId`: The Task ID to query. Should be the task_id returned by `generate_video` tool if `async_mode` is True. (required)\n- `outputDirectory`: Directory to save the output file. `outputDirectory` is relative to `MINIMAX_MCP_BASE_PATH` (or `basePath` in config). The final save path is `${basePath}/${outputDirectory}`. For example, if `MINIMAX_MCP_BASE_PATH=~/Desktop` and `outputDirectory=workspace`, the output will be saved to `~/Desktop/workspace/`. (optional)\n\n### Generate Music\n\nGenerate music from prompt and lyrics.\n\nTool Name: `music_generation`\n\nParameters:\n- `prompt`: Music creation inspiration describing style, mood, scene, etc. Example: \"Pop music, sad, suitable for rainy nights\". Character range: [10, 300]. (required)\n- `lyrics`: Song lyrics for music generation. Use newline (\\\\n) to separate each line of lyrics. Supports lyric structure tags [Intro] [Verse] [Chorus] [Bridge] [Outro] to enhance musicality. Character range: [10, 600] (each Chinese character, punctuation, and letter counts as 1 character). (required)\n- `sampleRate`: Sample rate of generated music. Values: [16000, 24000, 32000, 44100], default is 32000. (optional)\n- `bitrate`: Bitrate of generated music. Values: [32000, 64000, 128000, 256000], default is 128000. (optional)\n- `format`: Format of generated music. Values: [\"mp3\", \"wav\", \"pcm\"], default is 'mp3'. (optional)\n- `outputDirectory`: The directory to save the output file. `outputDirectory` is relative to `MINIMAX_MCP_BASE_PATH` (or `basePath` in config). The final save path is `${basePath}/${outputDirectory}`. For example, if `MINIMAX_MCP_BASE_PATH=~/Desktop` and `outputDirectory=workspace`, the output will be saved to `~/Desktop/workspace/`. (optional)\n\n\n### Voice Design\n\nGenerate a voice based on description prompts.\n\nTool Name: `voice_design`\n\nParameters:\n- `prompt`: The prompt to generate the voice from. (required)\n- `previewText`: The text to preview the voice. (required)\n- `voiceId`: The id of the voice to use. For example, \"male-qn-qingse\"/\"audiobook_female_1\"/\"cute_boy\"/\"Charming_Lady\"... (optional)\n- `outputDirectory`: The directory to save the output file. `outputDirectory` is relative to `MINIMAX_MCP_BASE_PATH` (or `basePath` in config). The final save path is `${basePath}/${outputDirectory}`. For example, if `MINIMAX_MCP_BASE_PATH=~/Desktop` and `outputDirectory=workspace`, the output will be saved to `~/Desktop/workspace/`. (optional)\n\n## FAQ\n\n### 1. How to use `generate_video` in async-mode\nDefine completion rules before starting:\n<img src=\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/cursor_rule2.png?x-oss-process=image/resize,p_50/format,webp\" style=\"display: inline-block; vertical-align: middle;\"/>\nAlternatively, these rules can be configured in your IDE settings (e.g., Cursor):\n<img src=\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/cursor_video_rule.png?x-oss-process=image/resize,p_50/format,webp\" style=\"display: inline-block; vertical-align: middle;\"/>\n\n## Development\n\n### Setup\n\n```bash\n# Clone the repository\ngit clone https://github.com/MiniMax-AI/MiniMax-MCP-JS.git\ncd minimax-mcp-js\n\n# Install dependencies\npnpm install\n```\n\n### Build\n\n```bash\n# Build the project\npnpm run build\n```\n\n### Run\n\n```bash\n# Run the MCP server\npnpm start\n```\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "minimax",
        "multimedia",
        "javascript",
        "minimax ai",
        "ai minimax",
        "mcp js"
      ],
      "category": "image-and-video-generation"
    },
    "Momo707577045--tinypng-script-with-cache": {
      "owner": "Momo707577045",
      "name": "tinypng-script-with-cache",
      "url": "https://github.com/Momo707577045/tinypng-script-with-cache",
      "imageUrl": "/freedevtools/mcp/pfp/Momo707577045.webp",
      "description": "Compress images without dependencies, automatically skip already compressed images, and replace source files, while maintaining quality. The server utilizes multiple API keys for compression and generates compression reports while ensuring no redundant files are created during the process.",
      "stars": 23,
      "forks": 8,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-06-24T13:15:05Z",
      "readme_content": "# 无依赖的 tinypng node 脚本\n## 特点\n- 【无依赖，纯脚本】\n  - 下载脚本代码，直接使用 node 命令即可运行。\n  - 将使用门槛降到最低。\n- 【过滤重复压缩】\n  - 自动记录已被压缩过的图片，跳过压缩，加快进度。\n  - 记录图片压缩后的 md5 值，再次运行压缩脚本时，跳过压缩。\n  - 通过 md5 值比较文件变更，即使「文件迁移」也能自动过滤。\n  - 通过 md5 值比较文件变更，即使「使用同名文件替换」也能自动识别，并压缩，没有漏网之鱼。\n- 【替换源文件】\n  - 压缩成功，直接替换源文件，不生成冗余文件，不需要复制粘贴，移动图片。\n  - 静默压缩，对项目无感知，无任何影响。\n- 【自动切换 api key】\n  - tinypng 申请的 [api key](https://tinypng.com/developers) 每月只有 500 次免费压缩额度。\n  - 可设置多个 api key，当某 key 超过使用次数时，自动切换下一个 key 进行压缩。\n- 【压缩报告】\n  - 记录每个图片的压缩数据，并生成汇总信息。\n- 【压缩安全边界】\n  - 压缩安全线，当压缩比例低于该百分比值时，保持源文件，避免过分压缩，损伤图片质量。\n- 【源码携带详细备注，自带测试图片】\n  - 降低源码阅读门槛，降低测试门槛，减低使用门槛。\n  - 推荐阅读源码，打破恐惧，便于定制个性化需求。\n\n\n## 专为小型项目定制\n- 纯脚本，不依赖 gulp，不依赖 webpack，无需搭建脚手架环境\n- 小型项目，或者只有几个静态页面，搭建脚手架的成本过高。本脚解决的即是脚手架依赖的问题。\n- 当然，中大型项目也可以用，只是其「无依赖」的特点在里面没那么突出。中大型项目推荐使用其 [gulp 版本](https://segmentfault.com/a/1190000023895556)，实现更灵活的配置。\n\n\n## 单文件使用方式\n- 第一步，点击[下载源码](http://upyun.luckly-mjw.cn/lib/mtp.js)\n- 第二步，在脚本文件头部添加 tinypng 的 [api key](https://tinypng.com/developers)\n  ```\n  global.tinypngConf = {\n    apiKeyList: [\n      // 'XgNgkoyWbdIZd8OizINMjX2TpxAd_Gp3', // 无效 key\n      // 'IAl6s3ekmONUVMEqWZdIp1nV2ItJL1PC', // 无效 key\n      'IAl6s3ekmONUVMEqWZdIp1nV2ItJLyPC', // 有效 key\n    ]\n  }\n  ```\n  ![配置图](http://upyun.luckly-mjw.cn/Assets/tinypng/004.png)\n- 第三步，赋予脚本文件「可执行」权限，```chmod +x ./mtp.js```\n- 第四步，将脚本文件放置到项目所在目录\n  ![运行效果](http://upyun.luckly-mjw.cn/Assets/tinypng/007.jpeg)\n- 第五步，在项目所在目录运行脚本```node ./mtp.js```\n  ![运行效果](http://upyun.luckly-mjw.cn/Assets/tinypng/006.jpeg)\n- 后续使用，仅需最后两步「第四步」「第五步」\n\n\n## 全局配置使用方式\n- 第一步，全局安装```npm install -g tinypng-script-with-cache```\n- 第二步，全局配置 api key\n  ```mtp setKey XgNgkoyWbdIZd8OizINMjX2TpxAd_Gp3,IAl6s3ekmONUVMEqWZdIp1nV2ItJLyPC```\n- 第三步，在项目所在目录运行脚本```mtp```\n- 后续使用，无需配置，直接在目标目录运行```mtp```\n\n  ![运行效果](http://upyun.luckly-mjw.cn/Assets/tinypng/008.png)\n\n## 参数传递方式\n#### 默认配置\n- 默认压缩「运行命令所在文件夹」下的图片\n- 「命令传参」优先级高于「修改源文件设置」\n\n\n#### 修改源文件设置\n- 在源文件头部，写入全局参数，程序运行时自动获取\n- 全部参考配置如下\n  ```\n  global.tinypngConf = {\n     basePath: '/Users/mjw/Desktop/git/tinypng-script-with-cache/test-img', // 压缩路径\n     createMd5FormOrigin: false, // 不进行压缩操作，只生成现有图片的 md5 信息，并作为缓存。用于「初次项目接入」及手动清理冗余的「图片md5信息」\n     apiKeyList: [ // tiny png 的 api key 数组，当其中一个不可用或超过使用次数时，自动切换下一个 key 调用\n       'IAl6s3ekmONUVMEqWZdIp1nV2ItJLyPC', // 有效 key\n     ]\n   }\n  ```\n  ![配置图](http://upyun.luckly-mjw.cn/Assets/tinypng/004.png)\n\n#### 命令传参\n- 参数通过空格区分\n- 参数一：压缩路径\n- 参数二：是否不进行压缩操作，只生成现有图片的 md5 信息。除空字符串```''```外，其余值均为 true\n- 参数三：apiKeyList，以逗号区分```,```\n- 传参参考\n  ```\n  node ./mtp.js /Users/mjw/Desktop/git/tinypng-script-with-cache/test-img '' IAl6s3ekmONUVMEqWZdIp1nV2ItJLyPC\n  ```\n  ![运行效果](http://upyun.luckly-mjw.cn/Assets/tinypng/005.jpeg)\n\n#### 配置合并优先级源码\n```\nconst vfs = require('vinyl-fs');\nlet tinypng = require('./tinypng-with-cache')\n\nlet apiKeyList = [] // 接口 key 默认为空\nlet basePath = process.cwd() // 默认运行脚本所在目录\nlet createMd5FormOrigin = false // 不进行压缩操作，只生成现有图片的 md5 信息，并作为缓存。用于「初次项目接入」及手动清理冗余的「图片md5信息」\n\n// 如果有全局传值\nif (global.tinypngConf) {\n  basePath = tinypngConf.basePath || basePath\n  apiKeyList = tinypngConf.apiKeyList || apiKeyList\n  createMd5FormOrigin = tinypngConf.createMd5FormOrigin || createMd5FormOrigin\n}\n\n// 动态参数传值\nbasePath = process.argv[2] || basePath\ncreateMd5FormOrigin = process.argv[3] || createMd5FormOrigin\napiKeyList = process.argv[4] ? process.argv[4].split(',') : apiKeyList\n\nlet fileFilter = tinypngConf.fileFilter || [\n  basePath + '/**/*.png',\n  basePath + '/**/*.jpg',\n  basePath + '/**/*.jpeg',\n  `!${basePath}/**/node_modules/**`, // 忽略无需遍历的文件，路径匹配语法参考：https://www.gulpjs.com.cn/docs/getting-started/explaining-globs/\n  `!${basePath}/**/dist/**`,\n]\n\nconsole.log({\n  basePath,\n  apiKeyList,\n  fileFilter,\n  createMd5FormOrigin,\n})\n\nif (!apiKeyList.length) {\n  return console.error('tinypng-script-with-cache', 'tinypny key 列表不能为空!')\n}\n\nvfs.src(fileFilter, {\n  base: './', // 对文件使用相路径，为了后面覆盖源文件\n  nodir: true, // 忽略文件夹\n})\n.pipe(tinypng({\n  apiKeyList,\n  reportFilePath: basePath + '/tinypngReport.json', // 不设置，则不进行日志记录\n  md5RecordFilePath: basePath + '/tinypngMd5Record.json', // 不设置，则不进行缓存过滤\n  minCompressPercentLimit: 10, // 默认值为零，最小压缩百分比限制，为保证图片质量，当压缩比例低于该值时，保持源文件，避免过分压缩，损伤图片质量\n  createMd5FormOrigin, // 不进行压缩操作，只生成现有图片的 md5 信息，并作为缓存。用于「初次项目接入」及手动清理冗余的「图片md5信息」\n}))\n.pipe(vfs.dest('./', { overwrite: true })) // 覆写原文件\n```\n\n## [项目地址](https://github.com/Momo707577045/tinypng-script-with-cache)\n\n## 二次开发，生成自定义脚本\n- git clone 下载项目\n- npm install 安装依赖\n- 修改「tinypng-mjw.js」与「tinypng-with-cache.js」源文件\n- 执行```npx webpack --config webpack.config.js```命令，进行打包\n- 生成目标文件```dist/mtp.js```\n\n\n## 测试资源\n- test-img：图片压缩测试目录\n- test-img-origin：测试图片备份目录，用于恢复测试\n\n\n## 运行效果\n![运行效果](http://upyun.luckly-mjw.cn/Assets/tinypng/006.jpeg)\n\n## 压缩报告\n![压缩报告](http://upyun.luckly-mjw.cn/Assets/tinypng/002.png)\n\n## md5 记录\n![md5 记录](http://upyun.luckly-mjw.cn/Assets/tinypng/003.png)\n\n## gulp 版本请参考[这里](https://segmentfault.com/a/1190000023895556)",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "tinypng",
        "compression",
        "compressed",
        "momo707577045 tinypng",
        "compress images",
        "compressed images"
      ],
      "category": "image-and-video-generation"
    },
    "MubarakHAlketbi--game-asset-mcp": {
      "owner": "MubarakHAlketbi",
      "name": "game-asset-mcp",
      "url": "https://github.com/MubarakHAlketbi/game-asset-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/MubarakHAlketbi.webp",
      "description": "Generates 2D and 3D game assets from text prompts using AI models. Integrates with Hugging Face Spaces for asset generation, facilitating rapid prototyping for game developers.",
      "stars": 85,
      "forks": 20,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-21T17:45:58Z",
      "readme_content": "# Game Asset Generator using MCP and Hugging Face Spaces\n\nThis project is an innovative tool that simplifies game asset creation by leveraging AI-powered generation. Whether you're a game developer seeking rapid prototypes or an AI enthusiast exploring generative models, this tool enables you to create **2D** and **3D game assets** from text prompts effortlessly. It integrates AI models from **Hugging Face Spaces**—powered by `\"gokaygokay/Flux-2D-Game-Assets-LoRA\"`, `\"gokaygokay/Flux-Game-Assets-LoRA-v2\"`, and one of three 3D model generation spaces (`InstantMesh`, `Hunyuan3D-2`, or `Hunyuan3D-2mini-Turbo`, which you must duplicate to your account)—and uses the **Model Context Protocol (MCP)** for seamless interaction with AI assistants like **Claude Desktop**.\n\n<p align=\"center\">\n  <a href=\"https://pay.ziina.com/MubarakHAlketbi\">\n    <img src=\"https://img.shields.io/badge/Support_Me-Donate-9626ff?style=for-the-badge&logo=https%3A%2F%2Fimgur.com%2FvwC39JY\" alt=\"Support Me - Donate\">\n  </a>\n  <a href=\"https://github.com/RooVetGit/Roo-Code\">\n    <img src=\"https://img.shields.io/badge/Built_With-Roo_Code-412894?style=for-the-badge\" alt=\"Built With - Roo Code\">\n  </a>\n  <br>\n  <a href=\"https://glama.ai/mcp/servers/@MubarakHAlketbi/game-asset-mcp\">\n    <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@MubarakHAlketbi/game-asset-mcp/badge\" />\n  </a>\n</p>\n\n---\n\n## Table of Contents\n\n1. [Project Overview](#project-overview)\n2. [Features](#features)\n3. [How It Works](#how-it-works)\n4. [Prerequisites](#prerequisites)\n5. [Installation](#installation)\n6. [Usage](#usage)\n7. [Configuration](#configuration)\n8. [File Management](#file-management)\n9. [MCP Integration](#mcp-integration)\n10. [Troubleshooting](#troubleshooting)\n11. [Advanced](#advanced)\n12. [Contributing](#contributing)\n13. [License](#license)\n\n---\n\n## Project Overview\n\nThe **Game Asset Generator** (version **0.3.0**) harnesses AI to streamline the creation of game assets. It supports generating **2D assets** (e.g., pixel art sprites) and **3D assets** (e.g., OBJ and GLB models) from text prompts, integrating with **Hugging Face Spaces** and the **Model Context Protocol (MCP)**. This release introduces support for multiple 3D model generation spaces—`InstantMesh`, `Hunyuan3D-2`, and `Hunyuan3D-2mini-Turbo`—offering flexibility and enhanced performance. Built with **Node.js** and the **MCP TypeScript SDK (v1.7.0)**, it provides a robust, cross-platform solution for asset generation.\n\n---\n\n## Features\n\n- **2D Asset Generation**: Create pixel art, sprites, or other 2D assets from text prompts (e.g., \"pixel art sword\").\n- **3D Asset Generation**: Generate 3D models (OBJ and GLB formats) from text descriptions, with automatic image-to-model conversion.\n- **Multiple 3D Model Spaces**: Supports `InstantMesh`, `Hunyuan3D-2`, and `Hunyuan3D-2mini-Turbo` for varied 3D generation workflows.\n- **MCP Integration**: Seamlessly interact with the tool via MCP-compatible clients like **Claude Desktop**.\n- **File Management**: Automatically saves and organizes assets in a local `assets` directory with resource URIs (e.g., `asset://{type}/{id}`).\n- **Robust Input Validation**: Uses **Zod** for secure and reliable input processing.\n- **Multi-Client Support**: Handles multiple simultaneous connections via **SSE transport**.\n- **Secure Remote Access**: Optional **HTTPS** support for safe remote communication.\n- **Extensible Backend**: Modular design for easy integration of new models or features.\n- **Cross-Platform**: Compatible with Windows, macOS, and Linux using **Node.js**.\n- **Configurable 3D Generation**: Customize parameters like inference steps, guidance scale, and turbo mode via environment variables.\n\n---\n\n## How It Works\n\nThe Game Asset Generator transforms text prompts into game-ready assets through an automated pipeline:\n\n1. **User Input**: Submit a text prompt (e.g., \"pixel art sword\" or \"isometric 3D castle\").\n2. **MCP Server**: Routes the prompt to the appropriate tool (`generate_2d_asset` or `generate_3d_asset`).\n3. **AI Model Interaction**:\n   - **2D Assets**: Utilizes the **Hugging Face Inference API** with `\"gokaygokay/Flux-2D-Game-Assets-LoRA\"` (50 steps).\n   - **3D Assets**:\n     - Generates an initial image using `\"gokaygokay/Flux-Game-Assets-LoRA-v2\"` (30 steps).\n     - Converts the image to a 3D model using one of:\n       - **InstantMesh**: Multi-step process (`/preprocess`, `/generate_mvs`, `/make3d`).\n       - **Hunyuan3D-2**: Single-step process (`/generation_all`).\n       - **Hunyuan3D-2mini-Turbo**: Single-step process (`/generation_all`) with configurable turbo modes.\n4. **File Output**: Saves assets (PNG for 2D, OBJ/GLB for 3D) in the `assets` directory.\n5. **Response**: Returns resource URIs (e.g., `asset://3d_model/filename.glb`) for immediate use.\n\n### Workflow Diagram\n```\nUser Prompt → MCP Server → AI Model(s) → Local File → Resource URI Response\n```\n\nPrompts are automatically enhanced with \"high detailed, complete object, not cut off, white solid background\" for optimal quality.\n\n---\n\n## Prerequisites\n\n- **Node.js**: Version 16+ (includes `npm`).\n- **Git**: For cloning the repository.\n- **Internet Access**: Required for Hugging Face API connectivity.\n- **Hugging Face Account**: Needed for API access; obtain your token from [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens).\n- **NPM Packages**:\n  - `@gradio/client`: Interacts with Hugging Face Spaces.\n  - `@huggingface/inference`: For direct model inference.\n  - `@modelcontextprotocol/sdk`: Implements the MCP server.\n  - `dotenv`: Loads environment variables.\n  - `express`: Enables SSE transport.\n  - `zod`: Ensures input validation.\n  - `sharp`: Handles image processing.\n- **Optional**: **Claude Desktop** (or another MCP client) for enhanced interaction.\n\n---\n\n## Installation\n\n1. **Clone the Repository**:\n   ```bash\n   git clone https://github.com/yourusername/game-asset-mcp.git\n   cd game-asset-mcp\n   ```\n\n2. **Install Dependencies**:\n   ```bash\n   npm install\n   ```\n\n3. **Configure Environment**:\n   - Copy the example `.env` file:\n     ```bash\n     cp .env.example .env\n     ```\n   - Edit `.env` with your **Hugging Face API token** and duplicated **MODEL_SPACE**. See [Configuration](#configuration) for details.\n\n4. **Run the Server**:\n   - **Local (stdio transport)**:\n     ```bash\n     npm start\n     ```\n   - **Custom Working Directory**:\n     ```bash\n     node src/index.js /path/to/directory\n     ```\n   - **Remote (SSE transport)**:\n     ```bash\n     node src/index.js --sse\n     ```\n   - **Remote with HTTPS**:\n     ```bash\n     node src/index.js --sse --https\n     ```\n     Requires `ssl/key.pem` and `ssl/cert.pem` (see [ssl/README.md](ssl/README.md)).\n\n> **Note**: Uses ES modules (`\"type\": \"module\"` in `package.json`). Ensure Node.js 16+ is installed (`node --version`).\n\n---\n\n## Usage\n\nInteract with the server via an **MCP client** (e.g., Claude Desktop) or programmatically:\n\n- **Generate a 2D Asset**:\n  - **Command**: `generate_2d_asset prompt:\"pixel art sword\"`\n  - **Output**: Saves a PNG file (e.g., `2d_asset_generate_2d_asset_1698765432.png`) and returns its URI.\n\n- **Generate a 3D Asset**:\n  - **Command**: `generate_3d_asset prompt:\"isometric 3D castle\"`\n  - **Output**: Saves OBJ/GLB files and intermediate images, returning their URIs. Provides an operation ID for long-running tasks.\n\n### Prompt Examples\n- **Natural Interaction**:\n  - `generate_2d_sprite prompt:\"pixel art sword\"`\n  - `generate_3d_model prompt:\"isometric 3D castle\"`\n\n### With Claude Desktop\nAfter configuring (see [Configuration](#configuration)), type commands directly in the interface.\n\n---\n\n## Configuration\n\nCustomize the server via the `.env` file:\n\n### Required Settings\n- **HF_TOKEN**: Hugging Face API token.\n  ```plaintext\n  HF_TOKEN=your_hf_token\n  ```\n- **MODEL_SPACE**: Your duplicated 3D model space (e.g., `your-username/InstantMesh`).\n  - Duplicate one of:\n    - [InstantMesh](https://huggingface.co/spaces/tencentARC/InstantMesh)\n    - [Hunyuan3D-2](https://huggingface.co/spaces/tencent/Hunyuan3D-2)\n    - [Hunyuan3D-2mini-Turbo](https://huggingface.co/spaces/tencent/Hunyuan3D-2mini-Turbo)\n  ```plaintext\n  MODEL_SPACE=your-username/InstantMesh\n  ```\n\n### Optional 3D Model Settings\n| Variable                  | Description                                   | Valid Range/Default       |\n|---------------------------|-----------------------------------------------|---------------------------|\n| `MODEL_3D_STEPS`         | Inference steps                              | Varies by space (see below) |\n| `MODEL_3D_GUIDANCE_SCALE`| How closely the model follows the prompt     | 0.0-100.0 (default: 5.0-5.5) |\n| `MODEL_3D_OCTREE_RESOLUTION` | Detail level of the 3D model            | Varies by space (see below) |\n| `MODEL_3D_SEED`          | Randomness control                          | 0-10000000 (default: varies) |\n| `MODEL_3D_REMOVE_BACKGROUND` | Remove image background                | `true`/`false` (default: `true`) |\n| `MODEL_3D_TURBO_MODE`    | Generation mode (Hunyuan3D-2mini-Turbo only) | `Turbo`, `Fast`, `Standard` (default: `Turbo`) |\n| `MODEL_SPACE_TYPE`       | Override space type detection               | `instantmesh`, `hunyuan3d`, `hunyuan3d_mini_turbo` |\n\n#### Space-Specific Defaults\n- **InstantMesh**:\n  - Steps: 30-75 (default: 75)\n  - Seed: Default 42\n- **Hunyuan3D-2**:\n  - Steps: 20-50 (default: 20)\n  - Guidance Scale: Default 5.5\n  - Octree Resolution: `256`, `384`, `512` (default: `256`)\n  - Seed: Default 1234\n- **Hunyuan3D-2mini-Turbo**:\n  - Steps: 1-100 (default: 5 for `Turbo`, 10 for `Fast`, 20 for `Standard`)\n  - Guidance Scale: Default 5.0\n  - Octree Resolution: 16-512 (default: 256)\n  - Seed: Default 1234\n\n### Transport Settings\n- **PORT**: SSE transport port (default: 3000).\n  ```plaintext\n  PORT=3000\n  ```\n\n### Claude Desktop Setup\nEdit the config file:\n- **MacOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`\n- **Windows**: `%APPDATA%\\Claude\\claude_desktop_config.json`\n```json\n{\n  \"mcpServers\": {\n    \"game-asset-generator\": {\n      \"command\": \"node\",\n      \"args\": [\"/full/path/to/game-asset-mcp/src/index.js\"]\n    }\n  }\n}\n```\nRestart Claude Desktop after editing.\n\n---\n\n## File Management\n\n- **Storage Location**: Assets are saved in `./assets` within the working directory.\n- **Naming Convention**: Files use a prefix, tool name, timestamp, and unique ID (e.g., `2d_asset_generate_2d_asset_1698765432_abcd1234.png`).\n- **Customization**: Set a custom directory:\n  ```bash\n  node src/index.js /path/to/custom/directory\n  ```\n- **Resource Access**: Use MCP URIs (e.g., `asset://2d_asset/filename.png`) to list or read assets.\n\n---\n\n## MCP Integration\n\nThe **Model Context Protocol (MCP)** enables this tool to serve AI clients securely:\n- **Tools**: `generate_2d_asset`, `generate_3d_asset`.\n- **Resources**: Managed via `asset://` URIs.\n- **Prompts**: `generate_2d_sprite`, `generate_3d_model`.\n- **Compatibility**: Works with **Claude Desktop** and other MCP clients.\n\n---\n\n## Troubleshooting\n\n- **API Errors**: Check network connectivity or rate limits; review `./logs/server.log`.\n- **Authentication Issues**: Verify `HF_TOKEN` and `MODEL_SPACE` in `.env`.\n- **ES Modules Error**: Ensure Node.js 16+ (`node --version`).\n- **Logs**: Inspect detailed logs:\n  ```bash\n  tail -f ./logs/server.log\n  ```\n\n---\n\n## Advanced\n\n### API Endpoints and Integration\n- **2D Asset Generation**: Uses `\"gokaygokay/Flux-2D-Game-Assets-LoRA\"` (50 steps).\n- **3D Asset Image Generation**: Uses `\"gokaygokay/Flux-Game-Assets-LoRA-v2\"` (30 steps).\n- **3D Model Conversion**:\n  - **InstantMesh**: Multi-step (`/check_input_image`, `/preprocess`, `/generate_mvs`, `/make3d`).\n  - **Hunyuan3D-2**: Single-step (`/generation_all`).\n  - **Hunyuan3D-2mini-Turbo**: Single-step (`/generation_all`) with turbo modes.\n\n### Versioning\n- **Current Version**: 0.3.0 (Added Hunyuan3D-2mini-Turbo support).\n- **MCP SDK Version**: 1.7.0.\n- **Format**: MAJOR.MINOR.PATCH (SemVer).\n\n### Backend Architecture\n- **Core File**: `src/index.js`.\n- **Dependencies**: See `package.json`.\n- **Security**: Zod validation, path traversal prevention, HTTPS support, rate limiting.\n- **Performance**: Async processing, retry with backoff, GPU quota handling.\n\n---\n\n## Contributing\n\nWe welcome contributions! To participate:\n1. **Fork the Repository**: Create your copy on GitHub.\n2. **Make Changes**: Add features, fix bugs, or enhance docs.\n3. **Submit a Pull Request**: Detail your changes.\n4. **Open Issues**: Report bugs or suggest improvements.\n\nFollow standard coding conventions and include tests where applicable.\n\n---\n\n## License\n\nLicensed under the **MIT License**. See the [LICENSE](LICENSE) file for details.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcp",
        "prototyping",
        "3d",
        "game assets",
        "game asset",
        "prototyping game"
      ],
      "category": "image-and-video-generation"
    },
    "NON906--omniparser-autogui-mcp": {
      "owner": "NON906",
      "name": "omniparser-autogui-mcp",
      "url": "https://github.com/NON906/omniparser-autogui-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/NON906.webp",
      "description": "Analyzes the screen using OmniParser to automatically operate graphical user interfaces. It provides capabilities for interpreting visual content and executing GUI actions based on analysis.",
      "stars": 55,
      "forks": 10,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-02T00:52:32Z",
      "readme_content": "# omniparser-autogui-mcp\n\n（[日本語版はこちら](README_ja.md)）\n\nThis is an [MCP server](https://modelcontextprotocol.io/introduction) that analyzes the screen with [OmniParser](https://github.com/microsoft/OmniParser) and automatically operates the GUI.  \nConfirmed on Windows.\n\n## License notes\n\nThis is MIT license, but Excluding submodules and sub packages.  \nOmniParser's repository is CC-BY-4.0.  \nEach OmniParser model has a different license ([reference](https://github.com/microsoft/OmniParser?tab=readme-ov-file#model-weights-license)).\n\n## Installation\n\n1. Please do the following:\n\n```\ngit clone --recursive https://github.com/NON906/omniparser-autogui-mcp.git\ncd omniparser-autogui-mcp\nuv sync\nset OCR_LANG=en\nuv run download_models.py\n```\n\n(Other than Windows, use ``export`` instead of ``set``.)  \n(If you want ``langchain_example.py`` to work, ``uv sync --extra langchain`` instead.)\n\n2. Add this to your ``claude_desktop_config.json``:\n\n```claude_desktop_config.json\n{\n  \"mcpServers\": {\n    \"omniparser_autogui_mcp\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"D:\\\\CLONED_PATH\\\\omniparser-autogui-mcp\",\n        \"run\",\n        \"omniparser-autogui-mcp\"\n      ],\n      \"env\": {\n        \"PYTHONIOENCODING\": \"utf-8\",\n        \"OCR_LANG\": \"en\"\n      }\n    }\n  }\n}\n```\n\n(Replace ``D:\\\\CLONED_PATH\\\\omniparser-autogui-mcp`` with the directory you cloned.)\n\n``env`` allows for the following additional configurations:\n\n- ``OMNI_PARSER_BACKEND_LOAD``  \nIf it does not work with other clients (such as [LibreChat](https://github.com/danny-avila/LibreChat)), specify ``1``.\n\n- ``TARGET_WINDOW_NAME``  \nIf you want to specify the window to operate, please specify the window name.  \nIf not specified, operates on the entire screen.\n\n- ``OMNI_PARSER_SERVER``  \nIf you want OmniParser processing to be done on another device, specify the server's address and port, such as ``127.0.0.1:8000``.  \nThe server can be started with ``uv run omniparserserver``.\n\n- ``SSE_HOST``, ``SSE_PORT``  \nIf specified, communication will be done via SSE instead of stdio.\n\n- ``SOM_MODEL_PATH``, ``CAPTION_MODEL_NAME``, ``CAPTION_MODEL_PATH``, ``OMNI_PARSER_DEVICE``, ``BOX_TRESHOLD``  \nThese are for OmniParser configuration.  \nUsually, they are not necessary.\n\n## Usage Examples\n\n- Search for \"MCP server\" in the on-screen browser.\n\netc.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "omniparser",
        "gui",
        "autogui",
        "omniparser autogui",
        "omniparser automatically",
        "using omniparser"
      ],
      "category": "image-and-video-generation"
    },
    "NightTrek--moondream-mcp": {
      "owner": "NightTrek",
      "name": "moondream-mcp",
      "url": "https://github.com/NightTrek/moondream-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/NightTrek.webp",
      "description": "Advanced image analysis capabilities including captioning, object detection, and visual question answering for applications requiring sophisticated computer vision tasks.",
      "stars": 18,
      "forks": 9,
      "license": "Apache License 2.0",
      "language": "JavaScript",
      "updated_at": "2025-08-09T18:23:23Z",
      "readme_content": "# 🌙 Moondream MCP Server\n\nA powerful Model Context Protocol (MCP) server that brings advanced image analysis capabilities to your applications using the Moondream vision model. This server seamlessly integrates with Claude and Cline, providing a bridge between AI assistants and sophisticated computer vision tasks.\n\nThis IS NOT an offical Moondream package. All credit to [moondream.ai](https://github.com/vikhyat/moondream) for making the best open source vision model that you can run on consumer hardware.\n\n<div align=\"center\" style=\"height: 150px; overflow: hidden; display: flex; align-items: center; margin: 20px 0;\">\n  <img src=\"https://github.com/user-attachments/assets/e999ada0-9dfa-4f3d-a489-e4ce58434ecb\" alt=\"Moondream MCP Banner\" style=\"width: 100%; object-fit: cover;\">\n</div>\n\n\n## ✨ Features\n\n- 🖼️ **Image Captioning**: Generate natural language descriptions of images\n- 🔍 **Object Detection**: Identify and locate specific objects within images\n- 💭 **Visual Question Answering**: Ask questions about image content and receive intelligent responses\n- 🚀 **High Performance**: Uses quantized 8-bit models for efficient inference\n- 🔄 **Automatic Setup**: Handles model downloading and environment setup\n- 🛠️ **MCP Integration**: Standardized protocol for seamless tool usage\n\n## 🎯 Use Cases\n\n- **Content Analysis**: Automatically generate descriptions for image content\n- **Accessibility**: Create alt text for visually impaired users\n- **Data Extraction**: Extract specific information from images through targeted questions\n- **Object Verification**: Confirm the presence of specific objects in images\n- **Scene Understanding**: Analyze complex scenes and their components\n\n## 🚀 Quick Start\n\n### Prerequisites\n\n- Node.js v18 or higher\n- Python 3.8+\n- UV package manager (automatically installed if not present)\n\n### Installation\n\n1. **Clone and Setup**\n```bash\ngit clone <repository-url>\ncd moondream-server\npnpm install\n```\n\n2. **Build the Server**\n```bash\npnpm run build\n```\n\nThe server handles the rest automatically:\n- Creates Python virtual environment\n- Installs UV if not present\n- Downloads and sets up the Moondream model\n- Manages the model server process\n\n### Integration with Claude/Cline\n\nAdd to your MCP settings file (`claude_desktop_config.json` or `cline_mcp_settings.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"moondream\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/moondream-server/build/index.js\"]\n    }\n  }\n}\n```\n\n## 🛠️ Available Tools\n\n### analyze_image\n\nPowerful image analysis tool with multiple modes:\n\n```typescript\n{\n  \"name\": \"analyze_image\",\n  \"arguments\": {\n    \"image_path\": string,  // Path to image file\n    \"prompt\": string       // Analysis command\n  }\n}\n```\n\n**Prompt Types:**\n- `\"generate caption\"` - Creates natural language description\n- `\"detect: [object]\"` - Finds specific objects (e.g., \"detect: car\")\n- `\"[question]\"` - Answers questions about the image\n\n**Examples:**\n\n```javascript\n// Image Captioning\n{\n  \"image_path\": \"photo.jpg\",\n  \"prompt\": \"generate caption\"\n}\n\n// Object Detection\n{\n  \"image_path\": \"scene.jpg\",\n  \"prompt\": \"detect: person\"\n}\n\n// Visual Q&A\n{\n  \"image_path\": \"painting.jpg\",\n  \"prompt\": \"What colors are used in this painting?\"\n}\n```\n\n## 🔧 Technical Details\n\n### Architecture\n\nThe server operates as a dual-component system:\n\n1. **MCP Interface Layer**\n   - Handles protocol communication\n   - Manages tool interfaces\n   - Processes requests/responses\n\n2. **Moondream Model Server**\n   - Runs the vision model\n   - Processes image analysis\n   - Provides HTTP API endpoints\n\n### Model Information\n\nUses the Moondream quantized model:\n- Default: `moondream-2b-int8.mf.gz`\n- Efficient 8-bit quantization\n- Automatic download from Hugging Face\n- ~500MB model size\n\n### Performance\n\n- Fast startup with automatic caching\n- Efficient memory usage through quantization\n- Responsive API endpoints\n- Concurrent request handling\n\n## 🔍 Debugging\n\nCommon issues and solutions:\n\n1. **Model Download Issues**\n   ```bash\n   # Manual model download\n   wget https://huggingface.co/vikhyatk/moondream2/resolve/main/moondream-0_5b-int4.mf.gz\n   ```\n\n2. **Server Port Conflicts**\n   - Default port: 3475\n   - Check for process using: `lsof -i :3475`\n\n3. **Python Environment**\n   - UV manages dependencies\n   - Check logs in temp directory\n   - Virtual env in system temp folder\n\n## 🤝 Contributing\n\nContributions welcome! Areas of interest:\n\n- Additional model support\n- Performance optimizations\n- New analysis capabilities\n- Documentation improvements\n\n## 📄 License\n\n[Add your license information here]\n\n## 🙏 Acknowledgments\n\n- [Moondream Model Team](https://github.com/vikhyat/moondream)\n- Model Context Protocol (MCP) Community\n- Contributors and maintainers\n\n---\n\n<p align=\"center\">\nMade with ❤️ by Nighttrek\n</p>\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "nighttrek",
        "vision",
        "captioning",
        "nighttrek moondream",
        "moondream mcp",
        "advanced image"
      ],
      "category": "image-and-video-generation"
    },
    "PawNzZi--image-server": {
      "owner": "PawNzZi",
      "name": "image-server",
      "url": "https://github.com/PawNzZi/image-server",
      "imageUrl": "/freedevtools/mcp/pfp/PawNzZi.webp",
      "description": "Transform text prompts into images using advanced AI techniques, creating unique visuals tailored to user descriptions.",
      "stars": 1,
      "forks": 1,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-04-17T12:56:27Z",
      "readme_content": "[![smithery badge](https://smithery.ai/badge/@PawNzZi/image-server)](https://smithery.ai/server/@PawNzZi/image-server)\n\n### Installing via Smithery\n\nTo install text2image for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@PawNzZi/image-server):\n\n```bash\nnpx -y @smithery/cli install @PawNzZi/image-server --client claude\n```\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ai",
        "text",
        "prompts",
        "prompts images",
        "pawnzzi image",
        "advanced ai"
      ],
      "category": "image-and-video-generation"
    },
    "Sheshiyer--jina-ai-mcp-multimodal-search": {
      "owner": "Sheshiyer",
      "name": "jina-ai-mcp-multimodal-search",
      "url": "https://github.com/Sheshiyer/jina-ai-mcp-multimodal-search",
      "imageUrl": "/freedevtools/mcp/pfp/Sheshiyer.webp",
      "description": "Seamless integration with Jina AI's neural search capabilities enables semantic, image, and cross-modal searches through a simple interface. Perform searches based on natural language queries, visual similarities, and text-to-image or image-to-text conversions.",
      "stars": 4,
      "forks": 2,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-08-19T08:35:51Z",
      "readme_content": "# Jina AI MCP Server\n\nA Model Context Protocol (MCP) server that provides seamless integration with Jina AI's neural search capabilities. This server enables semantic search, image search, and cross-modal search functionalities through a simple interface.\n\n## 🚀 Features\n\n- **Semantic Search**: Find semantically similar documents using natural language queries\n- **Image Search**: Search for visually similar images using image URLs\n- **Cross-Modal Search**: Perform text-to-image or image-to-text searches\n\n## 📋 Prerequisites\n\n- Node.js 16 or higher\n- A Jina AI account and API key ([Get one here](https://cloud.jina.ai/))\n- MCP-compatible environment (e.g., Cline)\n\n## 🛠️ Installation\n\n1. Clone the repository:\n```bash\ngit clone <repository-url>\ncd jina-ai-mcp\n```\n\n2. Install dependencies:\n```bash\nnpm install\n```\n\n3. Create a `.env` file with your Jina AI API key:\n```bash\nJINA_API_KEY=your_api_key_here\n```\n\n4. Build the server:\n```bash\nnpm run build\n```\n\n## ⚙️ Configuration\n\nAdd the following configuration to your MCP settings file:\n\n```json\n{\n  \"mcpServers\": {\n    \"jina-ai\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/path/to/jina-ai-mcp/build/index.js\"\n      ],\n      \"env\": {\n        \"JINA_API_KEY\": \"your_api_key_here\"\n      }\n    }\n  }\n}\n```\n\n## 🔍 Available Tools\n\n### 1. Semantic Search\nPerform semantic/neural search on text documents.\n\n```typescript\nuse_mcp_tool({\n  server_name: \"jina-ai\",\n  tool_name: \"semantic_search\",\n  arguments: {\n    query: \"search query text\",\n    collection: \"your-collection-name\",\n    limit: 10 // optional, defaults to 10\n  }\n})\n```\n\n### 2. Image Search\nSearch for similar images using an image URL.\n\n```typescript\nuse_mcp_tool({\n  server_name: \"jina-ai\",\n  tool_name: \"image_search\",\n  arguments: {\n    imageUrl: \"https://example.com/image.jpg\",\n    collection: \"your-collection-name\",\n    limit: 10 // optional, defaults to 10\n  }\n})\n```\n\n### 3. Cross-Modal Search\nPerform text-to-image or image-to-text search.\n\n```typescript\nuse_mcp_tool({\n  server_name: \"jina-ai\",\n  tool_name: \"cross_modal_search\",\n  arguments: {\n    query: \"a beautiful sunset\", // or image URL for image2text\n    mode: \"text2image\", // or \"image2text\"\n    collection: \"your-collection-name\",\n    limit: 10 // optional, defaults to 10\n  }\n})\n```\n\n## 📝 Response Format\n\nAll search tools return results in the following format:\n\n```typescript\n{\n  content: [\n    {\n      type: \"text\",\n      text: JSON.stringify({\n        results: [\n          {\n            id: string,\n            score: number,\n            data: Record<string, any>\n          }\n        ]\n      }, null, 2)\n    }\n  ]\n}\n```\n\n## 🔐 Error Handling\n\nThe server handles various error cases:\n- Invalid API key\n- Missing or invalid parameters\n- API rate limits\n- Network errors\n- Invalid collection names\n\nAll errors are properly formatted and returned with appropriate error codes and messages.\n\n## 🤝 Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## 📄 License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## 🙏 Acknowledgments\n\n- [Jina AI](https://jina.ai/) for their excellent neural search platform\n- [Model Context Protocol](https://github.com/modelcontextprotocol/protocol) for the MCP specification\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "multimodal",
        "search",
        "searches",
        "multimodal search",
        "mcp multimodal",
        "modal searches"
      ],
      "category": "image-and-video-generation"
    },
    "Siddhant-K-code--memory-journal-mcp-server": {
      "owner": "Siddhant-K-code",
      "name": "memory-journal-mcp-server",
      "url": "https://github.com/Siddhant-K-code/memory-journal-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/Siddhant-K-code.webp",
      "description": "Search and analyze photos in a library using various intuitive tools, including location-based searches to easily find images taken in specific places.",
      "stars": 21,
      "forks": 4,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-07-28T18:59:40Z",
      "readme_content": "# 📸 Smart Photo Journal MCP Server\n\n**Smart Photo Journal** is an MCP server designed to help you search and analyze your photo library with powerful, intuitive tools. Whether you're reminiscing about family moments or looking for a specific photo with friends, this server has got you covered! 🎉\n\n> **Inspired by:** [burningion/video-editing-mcp](https://github.com/burningion/video-editing-mcp)\n> A huge shoutout to [@burningion](https://x.com/burningion) for the innovative idea of using MCP for creative media management!\n\n<a href=\"https://glama.ai/mcp/servers/51jiworg5k\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/51jiworg5k/badge\" alt=\"Smart Photo Journal Server MCP server\" /></a>\n\n## 🎯 Features\n\n- **Location Search:** Find photos from specific places with ease. 🌍\n- **Label Search:** Search photos by keywords or labels like \"Birthday,\" \"Beach,\" or \"Vacation.\" 🎉\n- **People Search:** Quickly locate photos featuring specific people. 👥\n- **Photo Analysis:** Discover fun insights like the most popular times and days for your photo shoots. 🕰️\n- **Fuzzy Matching:** Not sure of the exact name? Don't worry! The server supports fuzzy matching for flexibility. 🔍\n\n## 🚀 Getting started\n\n### Prerequisites\n\n1. Ensure you have macOS with a Photos library.\n2. Install [uv](https://docs.astral.sh/uv/) to manage dependencies and run the server.\n\n### Installation\n\n1. Clone the repository:\n\n   ```bash\n   git clone https://github.com/Siddhant-K-code/memory-journal-mcp-server.git\n   cd memory-journal-mcp-server\n   ```\n\n2. Install dependencies using `uv`:\n\n   ```bash\n   uv sync\n   ```\n\n3. Configure the MCP server. Update your `claude_desktop_config.json` with the following configuration:\n\n   ```json\n   {\n     \"mcpServers\": {\n       \"smart-photo-journal\": {\n         \"command\": \"/Users/<YOUR_DEVICE_USERNAME>/.local/bin/uv\",\n         \"args\": [\n           \"--directory\",\n           \"/Users/<PATH_TO_CLONED_DIR>/memory-journal-mcp-server\",\n           \"run\",\n           \"server.py\"\n         ]\n       }\n     }\n   }\n   ```\n\n4. Start the server with following command or just open Claude Desktop:\n   ```bash\n   uv run server.py\n   ```\n\n> **Note:** Replace `<YOUR_DEVICE_USERNAME>` and `<PATH_TO_CLONED_DIR>` with your actual device username and the path to the cloned directory.\n> You will get a popup to authorize the server to access your photos. It will be in local only, and no data will be shared with anyone except Claude services.\n\n### MCP Server Initialization\n\nWhen the server starts, you'll see:\n\n```\nStarting Smart Photo Journal MCP server.\n```\n\nIt's now ready to process your photo queries! 🎉\n\n---\n\n## 🛠️ Usage\n\n### Available Tools\n\n1. **Location Search**\n\n   - Description: Find photos taken in a specific location.\n   - Input Example:\n     ```json\n     {\n       \"location\": \"Udaipur\"\n     }\n     ```\n   - Expected Output:\n     ```\n     Found 5 photos from Udaipur:\n     📷 IMG_1234.jpg\n     ...\n     ```\n\n2. **Label Search**\n\n   - Description: Search for photos by labels or keywords.\n   - Input Example:\n     ```json\n     {\n       \"label\": \"Birthday\"\n     }\n     ```\n   - Expected Output:\n     ```\n     Photos labeled as 'Birthday' (3 found):\n     📷 IMG_5678.jpg\n     ...\n     ```\n\n3. **People Search**\n\n   - Description: Find photos containing specific people.\n   - Input Example:\n     ```json\n     {\n       \"person\": \"Maa\"\n     }\n     ```\n   - Expected Output:\n     ```\n     Photos with Maa (10 found):\n     📷 IMG_9101.jpg\n     ...\n     ```\n\n4. **Photo Analysis**\n   - Description: Analyze patterns in your photo library, such as the most common times or days for photo shoots.\n   - Input Example:\n     ```json\n     {}\n     ```\n   - Expected Output:\n     ```\n     📸 Photo Taking Patterns:\n     Total Photos: 200\n     ...\n     ```\n\n---\n\n## 📚 Example Use-Cases\n\n### 1. **Family & Friends Album Organizer**\n\nWant to gather all your family moments in one place? Use the `people-search` tool with names like \"Papa\" or \"Mom\" or \"Any Friend\" to find photos with specific people.\n\n### 2. **Vacation Highlights**\n\nSearch for photos from your vacation destination using the `location-search` tool.\n\n### 3. **Throwback Fun**\n\nCurious about your past birthday photos? Use `label-search` with \"Birthday\" and relive the fun!\n\n### 4. **Understand Your Photography Habits**\n\nUse the `photo-analysis` tool to understand when and where you take most of your photos. Plan your next shoot accordingly!\n\n---\n\n## ⚡ Tips for Best Results\n\n- Ensure your Photos library is loaded in macOS.\n- Be as specific as possible with search queries for more accurate results.\n- Use fuzzy matching for flexibility when you're unsure of the exact name.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "photos",
        "images",
        "searches",
        "photos library",
        "analyze photos",
        "easily images"
      ],
      "category": "image-and-video-generation"
    },
    "Sunwood-ai-labs--ideagram-mcp-server": {
      "owner": "Sunwood-ai-labs",
      "name": "ideagram-mcp-server",
      "url": "https://github.com/Sunwood-ai-labs/ideagram-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/Sunwood-ai-labs.webp",
      "description": "Generate images based on prompts with customizable parameters like aspect ratio and style using the Ideogram API.",
      "stars": 5,
      "forks": 7,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-08-20T21:40:42Z",
      "readme_content": "<div align=\"center\">\n\n\n\n  <h1>🎨 Ideogram MCP Server</h1>\n\n  <p>\n    <img alt=\"GitHub\" src=\"https://img.shields.io/github/license/sunwood-ai-labs/ideagram-mcp-server\">\n    <img alt=\"GitHub package.json version\" src=\"https://img.shields.io/github/package-json/v/sunwood-ai-labs/ideagram-mcp-server\">\n    <img alt=\"GitHub issues\" src=\"https://img.shields.io/github/issues/sunwood-ai-labs/ideagram-mcp-server\">\n    <img alt=\"GitHub pull requests\" src=\"https://img.shields.io/github/issues-pr/sunwood-ai-labs/ideagram-mcp-server\">\n    <img alt=\"npm\" src=\"https://img.shields.io/npm/v/@sunwood-ai-labs/ideagram-mcp-server\">\n    <img alt=\"npm\" src=\"https://img.shields.io/npm/dt/@sunwood-ai-labs/ideagram-mcp-server\">\n  </p>\n\n  <p>\n    Ideogram APIを使って画像生成を提供するModel Context Protocol (MCP) サーバーだよ！<br>\n    <b>Ideogram 3.0</b>対応で、Claude DesktopやMCPクライアントから爆速連携できるのが神✨\n  </p>\n</div>\n\n---\n\n## 📦 プロジェクト概要\n\n- Ideogram API (v3.0) をMCPサーバー経由で使えるTypeScript製ツール\n- 画像生成・スタイル参照・マジックプロンプト・アスペクト比・モデル選択など多機能\n- Claude Desktopや他MCPクライアントから即利用OK\n\n---\n\n\n## ⚡️ クイックスタート\n\nClaude Desktopや他MCPクライアントで爆速連携したいなら、  \n下記JSONスニペットを設定ファイルにコピペでOK！✨\n\n```json\n{\n  \"mcpServers\": {\n    \"ideogram\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"@sunwood-ai-labs/ideagram-mcp-server\"\n      ],\n      \"env\": {\n        \"IDEOGRAM_API_KEY\": \"your_api_key_here\"\n      }\n    }\n  }\n}\n```\n\n\n---\n\n## 🛠️ MCPツール仕様\n\n### generate_image\n\n#### パラメータ一覧（最新版）\n\n| パラメータ         | 型         | 説明                                                                                 | 必須/任意 | 備考                      |\n|--------------------|------------|--------------------------------------------------------------------------------------|-----------|---------------------------|\n| prompt             | string     | 画像生成プロンプト（英語推奨）                                                        | 必須      |                           |\n| aspect_ratio       | string     | アスペクト比（例: \"1x1\", \"16x9\", \"4x3\" など）                                        | 任意      | 15種類                    |\n| resolution         | string     | 解像度（公式ドキュメント参照、全69種）                                               | 任意      |                           |\n| seed               | integer    | 乱数シード（再現性担保用）                                                            | 任意      | 0～2147483647             |\n| magic_prompt       | string     | マジックプロンプト（\"AUTO\"|\"ON\"|\"OFF\"）                                               | 任意      | デフォルト\"AUTO\"          |\n| rendering_speed    | string     | v3用レンダリング速度（\"TURBO\"|\"DEFAULT\"|\"QUALITY\"）                                  | 任意      |                           |\n| style_codes        | string[]   | 8文字のスタイルコード配列                                                             | 任意      |                           |\n| style_type         | string     | スタイルタイプ（\"AUTO\"|\"GENERAL\"|\"REALISTIC\"|\"DESIGN\"）                              | 任意      |                           |\n| negative_prompt    | string     | 除外要素（英語推奨）                                                                  | 任意      |                           |\n| num_images         | number     | 生成画像数（1～8）                                                                    | 任意      |                           |\n| style_reference    | object     | スタイル参照（Ideogram 3.0新機能）                                                   | 任意      | 下記詳細                   |\n| └ urls             | string[]   | 参照画像URL配列（最大3つ）                                                            | 任意      |                           |\n| └ style_code       | string     | スタイルコード                                                                        | 任意      |                           |\n| └ random_style     | boolean    | ランダムスタイル使用                                                                  | 任意      |                           |\n| output_dir         | string     | 画像保存ディレクトリ（デフォルト: \"docs\"）                                            | 任意      |                           |\n| base_filename      | string     | 保存ファイル名のベース（デフォルト: \"ideogram-image\"）                                | 任意      | タイムスタンプ・ID付与     |\n| blur_mask          | boolean    | 画像の縁をぼかす（trueでマスク合成）                                                  | 任意      | デフォルト: false          |\n\n#### 📝 使用例\n\n```typescript\nconst result = await use_mcp_tool({\n  server_name: \"ideagram-mcp-server\",\n  tool_name: \"generate_image\",\n  arguments: {\n    prompt: \"A beautiful sunset over mountains\",\n    aspect_ratio: \"16x9\",\n    rendering_speed: \"QUALITY\",\n    num_images: 2,\n    style_reference: {\n      urls: [\n        \"https://example.com/ref1.jpg\",\n        \"https://example.com/ref2.jpg\"\n      ],\n      random_style: false\n    },\n    blur_mask: true\n  }\n});\n```\n\n---\n\n## 🧑‍💻 開発・ビルド・テスト\n\n- `npm run build` ... TypeScriptビルド\n- `npm run watch` ... 開発モード（自動ビルド）\n- `npm run lint` ... コードリント\n- `npm test` ... テスト実行\n\n---\n\n## 🗂️ ディレクトリ構成\n\n```bash\nideagram-mcp-server/\n├── assets/\n├── docs/\n│   └── ideogram-image_2025-05-18T06-31-45-777Z.png\n├── src/\n│   ├── tools/\n│   ├── types/\n│   ├── utils/\n│   ├── ideogram-client.ts\n│   ├── index.ts\n│   ├── server.ts\n│   └── test.ts\n├── .env.example\n├── package.json\n├── tsconfig.json\n├── README.md\n└── ...（省略）\n```\n\n---\n\n## 📝 コントリビューション\n\n1. このリポジトリをフォーク\n2. 新ブランチ作成 (`git checkout -b feature/awesome`)\n3. 変更コミット（コミットメッセージは日本語＋絵文字推奨！）\n4. プッシュ＆プルリク作成\n\n---\n\n## 🚀 デプロイ & リリース\n\n- GitHub Actionsで自動npm公開\n- バージョン更新→タグpushで自動デプロイ\n\n```bash\nnpm version patch|minor|major\ngit push --follow-tags\n```\n\n詳細は [docs/npm-deploy.md](docs/npm-deploy.md) を参照！\n\n---\n\n## 📄 ライセンス\n\nMIT\n\n---\n\n<div align=\"center\">\n\n\n\n</div>",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ideagram",
        "ideogram",
        "images",
        "generate images",
        "ideagram mcp",
        "ideogram api"
      ],
      "category": "image-and-video-generation"
    },
    "SureScaleAI--openai-gpt-image-mcp": {
      "owner": "SureScaleAI",
      "name": "openai-gpt-image-mcp",
      "url": "https://github.com/SureScaleAI/openai-gpt-image-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/SureScaleAI.webp",
      "description": "Generate and edit images using the latest OpenAI GPT-4o and gpt-image-1 models with advanced prompt control. Outputs can be saved to disk or received in base64 format for integration with MCP-compatible clients.",
      "stars": 74,
      "forks": 23,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T22:32:34Z",
      "readme_content": "# openai-gpt-image-mcp\n\n<p align=\"center\">\n  <a href=\"https://www.npmjs.com/package/@modelcontextprotocol/sdk\"><img src=\"https://img.shields.io/npm/v/@modelcontextprotocol/sdk?label=MCP%20SDK&color=blue\" alt=\"MCP SDK\"></a>\n  <a href=\"https://www.npmjs.com/package/openai\"><img src=\"https://img.shields.io/npm/v/openai?label=OpenAI%20SDK&color=blueviolet\" alt=\"OpenAI SDK\"></a>\n  <a href=\"https://github.com/SureScaleAI/openai-gpt-image-mcp/blob/main/LICENSE\"><img src=\"https://img.shields.io/github/license/SureScaleAI/openai-gpt-image-mcp?color=brightgreen\" alt=\"License\"></a>\n  <a href=\"https://github.com/SureScaleAI/openai-gpt-image-mcp/stargazers\"><img src=\"https://img.shields.io/github/stars/SureScaleAI/openai-gpt-image-mcp?style=social\" alt=\"GitHub stars\"></a>\n  <a href=\"https://github.com/SureScaleAI/openai-gpt-image-mcp/actions\"><img src=\"https://img.shields.io/github/actions/workflow/status/SureScaleAI/openai-gpt-image-mcp/main.yml?label=build&logo=github\" alt=\"Build Status\"></a>\n</p>\n\n---\n\nA Model Context Protocol (MCP) tool server for OpenAI's GPT-4o/gpt-image-1 image generation and editing APIs.\n\n- **Generate images** from text prompts using OpenAI's latest models.\n- **Edit images** (inpainting, outpainting, compositing) with advanced prompt control.\n- **Supports**: Claude Desktop, Cursor, VSCode, Windsurf, and any MCP-compatible client.\n\n---\n\n## ✨ Features\n\n- **create-image**: Generate images from a prompt, with advanced options (size, quality, background, etc).\n- **edit-image**: Edit or extend images using a prompt and optional mask, supporting both file paths and base64 input.\n- **File output**: Save generated images directly to disk, or receive as base64.\n\n---\n\n## 🚀 Installation\n\n```sh\ngit clone https://github.com/SureScaleAI/openai-gpt-image-mcp.git\ncd openai-gpt-image-mcp\nyarn install\nyarn build\n```\n\n---\n\n## 🔑 Configuration\n\nAdd to Claude Desktop or VSCode (including Cursor/Windsurf) config:\n\n```json\n{\n  \"mcpServers\": {\n    \"openai-gpt-image-mcp\": {\n      \"command\": \"node\",\n      \"args\": [\"/absolute/path/to/dist/index.js\"],\n      \"env\": { \"OPENAI_API_KEY\": \"sk-...\" }\n    }\n  }\n}\n```\n\nAlso supports Azure deployments:\n\n```json\n{\n  \"mcpServers\": {\n    \"openai-gpt-image-mcp\": {\n      \"command\": \"node\",\n      \"args\": [\"/absolute/path/to/dist/index.js\"],\n      \"env\": { \n        \"AZURE_OPENAI_API_KEY\": \"sk-...\",\n        \"AZURE_OPENAI_ENDPOINT\": \"my.endpoint.com\",\n        \"OPENAI_API_VERSION\": \"2024-12-01-preview\"\n      }\n    }\n  }\n}\n```\n\nAlso supports supplying an environment files:\n\n```json\n{\n  \"mcpServers\": {\n    \"openai-gpt-image-mcp\": {\n      \"command\": \"node\",\n      \"args\": [\"/absolute/path/to/dist/index.js\", \"--env-file\", \"./deployment/.env\"]\n    }\n  }\n}\n```\n\n---\n\n## ⚡ Advanced\n\n- For `create-image`, set `n` to generate up to 10 images at once.\n- For `edit-image`, provide a mask image (file path or base64) to control where edits are applied.\n- Provide an environment file with `--env-file path/to/file/.env`\n- See `src/index.ts` for all options.\n\n---\n\n## 🧑‍💻 Development\n\n- TypeScript source: `src/index.ts`\n- Build: `yarn build`\n- Run: `node dist/index.js`\n\n---\n\n## 📝 License\n\nMIT\n\n---\n\n## 🩺 Troubleshooting\n\n- Make sure your `OPENAI_API_KEY` is valid and has image API access.\n- You must have a [verified OpenAI organization](https://platform.openai.com/account/organization). After verifying, it can take 15–20 minutes for image API access to activate.\n- File paths must be absolute.\n  - **Unix/macOS/Linux**: Starting with `/` (e.g., `/path/to/image.png`)\n  - **Windows**: Drive letter followed by `:` (e.g., `C:/path/to/image.png` or `C:\\path\\to\\image.png`)\n- For file output, ensure the directory is writable.\n- If you see errors about file types, check your image file extensions and formats.\n\n---\n\n## ⚠️ Limitations & Large File Handling\n\n- **1MB Payload Limit:** MCP clients (including Claude Desktop) have a hard 1MB limit for tool responses. Large images (especially high-res or multiple images) can easily exceed this limit if returned as base64.\n- **Auto-Switch to File Output:** If the total image size exceeds 1MB, the tool will automatically save images to disk and return the file path(s) instead of base64. This ensures compatibility and prevents errors like `result exceeds maximum length of 1048576`.\n- **Default File Location:** If you do not specify a `file_output` path, images will be saved to `/tmp` (or the directory set by the `MCP_HF_WORK_DIR` environment variable) with a unique filename.\n- **Environment Variable:**\n  - `MCP_HF_WORK_DIR`: Set this to control where large images and file outputs are saved. Example: `export MCP_HF_WORK_DIR=/your/desired/dir`\n- **Best Practice:** For large or production images, always use file output and ensure your client is configured to handle file paths.\n\n---\n\n## 📚 References\n\n- [OpenAI Images API Documentation](https://platform.openai.com/docs/api-reference/images)\n\n---\n\n## 🙏 Credits\n\n- Built with [@modelcontextprotocol/sdk](https://www.npmjs.com/package/@modelcontextprotocol/sdk)\n- Uses [openai](https://www.npmjs.com/package/openai) Node.js SDK \n- Built by [SureScale.ai](https://surescale.ai)\n- Contributions from [Axle Research and Technology](https://axleinfo.com/)",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "openai",
        "gpt",
        "mcp",
        "openai gpt",
        "gpt image",
        "image mcp"
      ],
      "category": "image-and-video-generation"
    },
    "Tencent--cos-mcp": {
      "owner": "Tencent",
      "name": "cos-mcp",
      "url": "https://github.com/Tencent/cos-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/Tencent.webp",
      "description": "Integrate large language models with Tencent Cloud Object Storage (COS) and Data Insight (CI), enabling file management, automated cloud data handling, and various image and video processing tasks. Supports natural language-based metadata search and efficient backup workflows.",
      "stars": 15,
      "forks": 6,
      "license": "Other",
      "language": "TypeScript",
      "updated_at": "2025-10-02T12:48:08Z",
      "readme_content": "中文 | [English](README.en.md)\n\n# 腾讯云 COS MCP Server 🚀🚀🚀\n ![](https://badge.mcpx.dev?type=server 'MCP Server') [![npm Version](https://img.shields.io/npm/v/cos-mcp)](https://www.npmjs.com/package/cos-mcp) [![license](http://img.shields.io/badge/license-BSD3-brightgreen.svg?style=flat)](License.txt)\n\n<p align=\"center\">\n  <img alt=\"logo\" src=\"https://raw.githubusercontent.com/Tencent/cos-mcp/master/src/img/logo.png\"/>\n</p>\n\n基于 MCP 协议的腾讯云 COS MCP Server，无需编码即可让大模型快速接入腾讯云存储 (COS) 和数据万象 (CI) 能力。\n\n---\n\n## ✨ 核心功能\n\n### 云端存储能力\n- ⬆️ 文件上传到云端\n- ⬇️ 文件从云端下载\n- 📋 获取云端文件列表\n\n### 云端处理能力\n- 🖼️ 获取图片信息\n- 🔍 图片超分辨率\n- ✂️ 图片裁剪\n- 📲 二维码识别\n- 🏆 图片质量评估\n- 🅰️ 文字水印\n- 🎬 元数据/自然语言检索 (MateInsight)\n- 📄 文档转 PDF\n- 🎥 视频封面\n\n---\n\n## 💡 典型应用场景\n\n- 使用其他 MCP 能力获取的文本/图片/视频/音频等数据，可直接上传到 COS 云端存储。\n- 本地数据快速通过大模型转存到 COS 云端存储/备份。\n- 通过大模型实现自动化：将网页里的视频/图片/音频/文本等数据批量转存到 COS 云端存储。\n- 自动化将视频/图片/音频/文本等数据在云端处理，并转存到 COS 云端存储。\n\n---\n\n## 🌟 功能示例\n\n1. 上传文件到 COS  \n   ![eg1](https://raw.githubusercontent.com/Tencent/cos-mcp/master/src/img/eg1.png)\n2. 图片质量评估  \n   ![eg3](https://raw.githubusercontent.com/Tencent/cos-mcp/master/src/img/eg3.png)\n3. 自然语言检索图片  \n   ![eg2](https://raw.githubusercontent.com/Tencent/cos-mcp/master/src/img/eg2.png)\n4. 视频截帧  \n   ![eg15](https://raw.githubusercontent.com/Tencent/cos-mcp/master/src/img/eg15.png)\n\n---\n\n# 🔧 安装使用\n\n## 参数说明\n\n为了保护您的数据私密性，请准备以下参数：\n\n### 1. **SecretId / SecretKey**\n- **说明**: 腾讯云 COS 的密钥，用于身份认证，请妥善保管，切勿泄露。\n- **获取方式**: \n  1. 访问 [腾讯云密钥管理](https://console.cloud.tencent.com/cam/capi)。\n  2. 新建密钥并复制生成的 **SecretId** 和 **SecretKey**。\n\n### 2. **Bucket**\n- **示例**: `mybucket-123456`\n- **说明**: 存储桶名称，用于存放数据，相当于您的个人存储空间。\n- **获取方式**: \n  1. 访问 [存储桶列表](https://console.cloud.tencent.com/cos/bucket)。\n  2. 复制存储桶名称。如果没有存储桶，可点击“创建存储桶”，一般选择默认配置即可快速完成创建。\n\n### 3. **Region**\n- **示例**: `ap-beijing`\n- **说明**: 存储桶所在的地域。\n- **获取方式**: \n  1. 在 [存储桶列表](https://console.cloud.tencent.com/cos/bucket) 中找到存储桶。\n  2. 在存储桶名称一行查看所属地域并复制，例如：`ap-beijing`。\n\n### 4. **DatasetName**\n- **说明**: 非必填参数，数据智能检索操作需要此参数。\n- **获取方式**: \n  1. 访问 [数据集管理](https://console.cloud.tencent.com/cos/metaInsight/dataManage)。\n  2. 创建数据集并等待索引建立完成后，复制数据集名称。\n\n### 5. **connectType**\n- **说明**: 非必填参数，指定连接方式，可选值为 `stdio`（本地）或 `sse`（远程）。\n- **默认值**: `stdio`\n\n### 6. **port**\n- **说明**: 非必填参数，当连接方式为 `sse` 时，可自由设置端口。\n- **默认值**: `3001`\n\n---\n\n## 从 npx 启动\n\n在大模型内使用时（例如: cursor），需要在 `mcp.json` 中配置：\n\n```json\n{\n  \"mcpServers\": {\n    \"cos-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"cos-mcp\",\n        \"--Region=yourRegion\",\n        \"--Bucket=yourBucket\",\n        \"--SecretId=yourSecretId\",\n        \"--SecretKey=yourSecretKey\",\n        \"--DatasetName=yourDatasetname\"\n      ]\n    }\n  }\n}\n```\n\n也可以通过 JSON 配置：\n\n```json\n{\n  \"mcpServers\": {\n    \"cos-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"cos-mcp\",\n        \"--cos-config='{\\\"Region\\\":\\\"yourRegion\\\",\\\"Bucket\\\":\\\"yourBucket\\\",\\\"SecretId\\\":\\\"yourSecretId\\\",\\\"SecretKey\\\":\\\"yourSecretKey\\\",\\\"DatasetName\\\":\\\"yourDatasetname\\\"}'\"\n      ]\n    }\n  }\n}\n```\n\n---\n\n## 使用 npm 安装\n\n```bash\n# 安装\nnpm install -g cos-mcp@latest\n\n# 运行开启 SSE 模式\ncos-mcp --Region=yourRegion --Bucket=yourBucket --SecretId=yourSecretId --SecretKey=yourSecretKey --DatasetName=yourDatasetname --port=3001 --connectType=sse\n\n# 或通过 JSON 配置\ncos-mcp --cos-config='{\"Region\":\"yourRegion\",\"Bucket\":\"BucketName-APPID\",\"SecretId\":\"yourSecretId\",\"SecretKey\":\"yourSecretKey\",\"DatasetName\":\"datasetName\"}' --port=3001 --connectType=sse\n```\n\n在大模型内使用 SSE 模式时（例如: cursor），需要在 `mcp.json` 中配置：\n\n```json\n{\n  \"mcpServers\": {\n    \"cos-mcp\": {\n      \"url\": \"http://localhost:3001/sse\"\n    }\n  }\n}\n```\n\n---\n\n## 使用源码安装\n\n### 步骤 1: 克隆项目代码\n\n```bash\ngit clone https://github.com/Tencent/cos-mcp.git\ncd cos-mcp\n```\n\n### 步骤 2: 安装依赖\n\n```bash\nnpm install\n```\n\n### 步骤 3: 启动服务\n\n#### 3.1 配置本地环境变量\n\n创建 `.env` 文件，并配置以下环境变量：\n\n```env\nRegion='yourRegion'\nBucket='yourBucket'\nSecretId='yourSecretId'\nSecretKey='yourSecretKey'\nDatasetName=\"yourDatasetName\"\n```\n\n#### 3.2 本地 SSE 模式启动（方式一）\n\n```bash\nnpm run start:sse\n```\n\n#### 3.3 本地构建后使用 STDIO 模式（方式二）\n\n```bash\nnpm run build\n```\n\n构建产物位于 `dist/index.js`。\n\n---\n\n### 步骤 4: 在大模型内使用\n\n#### SSE 模式配置\n\n```json\n{\n  \"mcpServers\": {\n    \"cos-mcp\": {\n      \"url\": \"http://localhost:3001/sse\"\n    }\n  }\n}\n```\n\n#### STDIO 模式配置\n\n```json\n{\n  \"mcpServers\": {\n    \"cos-mcp\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"${your work space}/dist/index.js\"\n      ]\n    }\n  }\n}\n```\n\n完成以上步骤后，即可通过源码运行 COS MCP Server。\n\n---\n\n## ⚠️ 注意事项\n\n1. 如果安装了旧版本的包，可以将上述内容内 `cos-mcp` 改为 `cos-mcp@latest` 安装最新版包。\n2. 如果全局安装后直接使用 `cos-mcp` 不行，可能是全局变量有问题，可以使用拆分变量或 `npx` 的方式启动：\n   ```bash\n   npm install -g cos-mcp@latest\n   cos-mcp --cos-config=xxx --port=3001 --connectType=sse\n   ```\n   上述命令效果等同于：\n   ```bash\n   npx cos-mcp@latest --cos-config=xxx --port=3001 --connectType=sse\n   ```\n3. 如果出现解析问题，可能是终端对双引号敏感，可以将配置参数改为以下格式再尝试：\n   ```bash\n   --cos-config='{\\\"Region\\\":\\\"yourRegion\\\",\\\"Bucket\\\":\\\"BucketName-APPID\\\",\\\"SecretId\\\":\\\"yourSecretId\\\",\\\"SecretKey\\\":\\\"yourSecretKey\\\",\\\"DatasetName\\\":\\\"datasetName\\\"}' --port=3001 --connectType=sse\n   ```\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "cloud",
        "storage",
        "metadata",
        "tencent cloud",
        "automated cloud",
        "storage cos"
      ],
      "category": "image-and-video-generation"
    },
    "agan2023416--workers": {
      "owner": "agan2023416",
      "name": "workers",
      "url": "https://github.com/agan2023416/workers",
      "imageUrl": "/freedevtools/mcp/pfp/agan2023416.webp",
      "description": "An MCP server for image generation that interfaces with a Cloudflare Worker to enable asynchronous image creation, real-time status updates, and error handling. It supports type-safe API calls for generating images based on given prompts.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-09-14T00:28:04Z",
      "readme_content": "# Cloudflare Workers Collection\n\nThis repository contains a collection of specialized Cloudflare Workers and related tools, each designed to provide specific functionality and services.\n\n## Available Projects\n\n### [replicate-2-r2](./replicate-2-r2)\nA worker that integrates Replicate's AI image generation with Cloudflare R2 storage. This worker:\n- Generates images using Replicate's API\n- Stores generated images in Cloudflare R2\n- Provides immediate URL generation\n- Supports webhook notifications\n- Includes MCP server integration for seamless AI tooling\n\n👉 [Learn more about replicate-2-r2](./replicate-2-r2)\n\n### [generate-image](./mcps/generate-image)\nA Model Context Protocol (MCP) server that provides a simple interface to the replicate-2-r2 worker. This server:\n- Interfaces with replicate-2-r2 worker\n- Provides type-safe API calls\n- Handles asynchronous image generation\n- Supports real-time status updates\n\n👉 [Learn more about generate-image](./mcps/generate-image)\n\n### [n8n-image-generator](./mcps/n8n-image-generator) ⭐ NEW\nA specialized MCP server designed specifically for n8n integration with SSE protocol support. This server:\n- **Perfect n8n Integration**: Works seamlessly with n8n's MCP Client Tool\n- **SSE Protocol Support**: Real-time communication using Server-Sent Events\n- **Multi-Model Support**: Supports Flux, Stable Diffusion, and more AI models\n- **Production Ready**: Built with error handling and monitoring\n- **Zero Worker Changes**: Uses existing replicate-2-r2 worker without modifications\n\n👉 [Learn more about n8n-image-generator](./mcps/n8n-image-generator)\n\n## 🚀 Quick Start for n8n Users\n\nIf you want to use AI image generation in n8n workflows, follow these steps:\n\n### 1. Deploy the Worker\n```bash\ncd replicate-2-r2\nnpm install\nnpm run deploy\n```\n\n### 2. Set up the MCP Server\n```bash\ncd mcps/n8n-image-generator\nnpm install\nnpm run build\n```\n\n### 3. Configure Environment\n```bash\nexport CLOUDFLARE_WORKERS_URL=https://your-worker.workers.dev\nexport WORKER_API_TOKEN=your-api-token\nnpm start\n```\n\n### 4. Add to n8n\nIn your n8n workflow:\n1. Add **MCP Client Tool** node\n2. Configure connection to your MCP server\n3. Use `generate_image` tool with your prompt\n\n## Architecture Overview\n\n```mermaid\ngraph TB\n    A[n8n Workflow] -->|SSE/MCP| B[n8n-image-generator MCP Server]\n    B -->|HTTP API| C[replicate-2-r2 Worker]\n    C -->|AI Generation| D[Replicate API]\n    C -->|Storage| E[Cloudflare R2]\n    C -->|Webhook| C\n    \n    style A fill:#e1f5fe\n    style B fill:#f3e5f5\n    style C fill:#e8f5e8\n    style D fill:#fff3e0\n    style E fill:#fce4ec\n```\n\n## Getting Started\n\nEach project is contained in its own directory with its own documentation. To get started:\n\n1. Choose the project you want to use\n2. Navigate to its directory\n3. Follow the setup instructions in its README.md\n\n## Repository Structure\n\n```\ncloudflare-workers/\n├── README.md\n├── replicate-2-r2/         # Replicate integration worker\n│   ├── README.md           # Worker-specific documentation\n│   ├── src/                # Source code\n│   └── ...                 # Other worker files\n└── mcps/                   # MCP servers\n    ├── generate-image/     # Original MCP server\n    │   ├── README.md       # Server documentation\n    │   ├── src/           # Source code\n    │   └── ...            # Other server files\n    └── n8n-image-generator/ # ⭐ NEW: n8n-specific MCP server\n        ├── README.md       # Detailed setup guide\n        ├── src/           # TypeScript source\n        └── ...            # Configuration files\n```\n\n## 🔄 Migration from generate-image to n8n-image-generator\n\nIf you're currently using the original `generate-image` MCP server, consider migrating to `n8n-image-generator` for better n8n integration:\n\n### Benefits of n8n-image-generator:\n- ✅ **Better SSE Support**: Designed specifically for n8n's MCP Client Tool\n- ✅ **Enhanced Error Handling**: More robust error messages and logging\n- ✅ **Improved Performance**: Optimized for n8n workflow patterns\n- ✅ **Better Documentation**: Comprehensive setup and usage guides\n- ✅ **Active Development**: Focused on n8n use cases\n\n### Migration Steps:\n1. Install the new MCP server: `cd mcps/n8n-image-generator && npm install`\n2. Update your n8n MCP Client Tool configuration\n3. Test your workflows with the new server\n4. Enjoy improved reliability and performance!\n\nMore projects will be added to this collection in the future. Stay tuned for updates!",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "cloudflare",
        "mcp",
        "images",
        "server image",
        "generating images",
        "video generation"
      ],
      "category": "image-and-video-generation"
    },
    "aigc17--Al-StoryLab": {
      "owner": "aigc17",
      "name": "Al-StoryLab",
      "url": "https://github.com/aigc17/Al-StoryLab",
      "imageUrl": "/freedevtools/mcp/pfp/aigc17.webp",
      "description": "AI-StoryLab generates interactive stories with accompanying audio effects and provides illustration prompts. It leverages AI services for story creation, voice synthesis, sound effect generation, and suggests relevant audio placements.",
      "stars": 0,
      "forks": 1,
      "license": "No License",
      "language": "",
      "updated_at": "2025-01-21T02:57:12Z",
      "readme_content": "# AI-StoryLab\n\nAI-StoryLab 是一个基于 Next.js 开发的智能故事创作平台，它能够帮助用户生成故事并添加音频效果，让故事更加生动有趣。同时支持生成配套的绘图提示词，方便用户使用 Midjourney、Recraft 等 AI 绘图工具创建插图。\n\n## 主要功能\n\n- **故事生成**：根据主题自动生成故事内容\n- **语音合成**：支持中英文语音生成\n  - 中文：使用 海螺 MiniMax 语音服务\n  - 英文：使用 Replicate Kokoro 语音服务\n- **音效生成**：使用 ElevenLabs 生成逼真的音效\n- **智能建议**：自动推荐合适的音效位置\n- **绘图提示词**：为故事场景自动生成 AI 绘图提示词\n- **导出功能**：\n  - 导出音效位置指南\n  - 导出绘图提示词\n\n## 技术栈\n\n- **框架**：Next.js 14\n- **语言**：TypeScript\n- **样式**：Tailwind CSS\n- **UI组件**：shadcn/ui (基于 Radix UI 的组件库)\n- **AI服务**：\n  - DeepSeek：故事生成和绘图提示词生成\n  - MiniMax：中文语音\n  - Kokoro：英文语音\n  - ElevenLabs：音效生成\n\n## 开始使用\n\n1. 克隆项目\n```bash\ngit clone https://github.com/nicekate/Al-StoryLab.git\ncd Al-StoryLab\n```\n\n2. 安装依赖\n```bash\nnpm install\n```\n\n3. 配置环境变量\n复制 `.env.example` 文件并重命名为 `.env.local`，填入必要的 API 密钥：\n\n需要在以下平台注册并获取 API 密钥：\n- DeepSeek API Key ([获取地址](https://api-docs.deepseek.com/zh-cn/))\n- MiniMax API Key 和 Group ID ([获取地址](https://platform.minimaxi.com/))\n- ElevenLabs API Key ([获取地址](https://elevenlabs.io))\n- Replicate API Token ([获取地址](https://replicate.com/))\n\n将获取的密钥填入 `.env.local`：\n- DEEPSEEK_API_KEY\n- MINIMAX_API_KEY\n- MINIMAX_GROUP_ID\n- ELEVENLABS_API_KEY\n- REPLICATE_API_TOKEN\n\n4. 启动开发服务器\n```bash\nnpm run dev\n```\n\n5. 访问 [http://localhost:3000](http://localhost:3000) 开始使用\n\n## 使用指南\n\n### 生成故事\n1. 输入故事主题或使用自动生成的提示\n2. 选择语言（中文/英文）\n3. 点击生成按钮\n\n### 添加音效\n1. 使用智能建议生成音效提示词\n2. 选择合适的音效位置\n3. 点击生成音效\n\n### 生成绘图提示词\n1. 在故事生成后，点击\"生成绘图提示词\"\n2. 系统会为每个关键场景生成 AI 绘图提示词\n3. 可以直接复制使用或导出保存\n\n## 许可证\n\nMIT",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "storylab",
        "audio",
        "interactive",
        "ai storylab",
        "storylab ai",
        "storylab generates"
      ],
      "category": "image-and-video-generation"
    },
    "aiyogg--tinypng-mcp-server": {
      "owner": "aiyogg",
      "name": "tinypng-mcp-server",
      "url": "https://github.com/aiyogg/tinypng-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/aiyogg.webp",
      "description": "Compress images using the TinyPNG API to reduce file size while maintaining quality. Integrate image optimization into various projects seamlessly.",
      "stars": 4,
      "forks": 4,
      "license": "Apache License 2.0",
      "language": "TypeScript",
      "updated_at": "2025-04-28T10:03:48Z",
      "readme_content": "## MCP server for TinyPNG\n[![smithery badge](https://smithery.ai/badge/@aiyogg/tinypng-mcp-server)](https://smithery.ai/server/@aiyogg/tinypng-mcp-server) [![MseeP.ai Security Assessment Badge](https://mseep.net/mseep-audited.png)](https://mseep.ai/app/aiyogg-tinypng-mcp-server)\n\n### Usage\n\n### Use `bun` or `node` to run the server\n\n1. Install dependencies and build\n\n```bash\npnpm i\npnpm build\n```\n\n2. Edit the `mcp.json` file\n\n```json\n{\n  \"mcpServers\": {\n    \"tinypng\": {\n      \"command\": \"bun\", // or \"node\"\n      \"args\": [\"/path/to/tinypng-mcp-server/src/index.ts\"], // or \"dist/index.js\"\n      \"env\": {\n        \"TINYPNG_API_KEY\": \"your-tinypng-api-key\"\n      }\n    }\n  }\n}\n```\n\n### Installing via Smithery\n\nTo install TinyPNG MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@aiyogg/tinypng-mcp-server):\n\n```bash\nnpx -y @smithery/cli install @aiyogg/tinypng-mcp-server --client claude\n```\n\n### Tools\n\n1. Compress local image\n\n```js\n{\n  name: 'compress_local_image',\n  description: 'Compress a local image file',\n  inputSchema: {\n    type: 'object',\n    properties: {\n      imagePath: {\n        type: 'string',\n        description: 'The ABSOLUTE path to the image file to compress',\n        example: '/Users/user/Downloads/image.jpg',\n      },\n      outputPath: {\n        type: 'string',\n        description: 'The ABSOLUTE path to save the compressed image file',\n        example: '/Users/user/Downloads/image_compressed.jpg',\n      },\n      outputFormat: {\n        type: 'string',\n        description: 'The format to save the compressed image file',\n        enum: SUPPORTED_IMAGE_TYPES,\n        example: 'image/jpeg',\n      },\n    },\n    required: ['imagePath'],\n  },\n}\n```\n\n2. Compress remote image\n\n```js\n{\n  name: 'compress_remote_image',\n  description: 'Compress a remote image file by giving the URL of the image',\n  inputSchema: {\n    type: 'object',\n    properties: {\n      imageUrl: {\n        type: 'string',\n        description: 'The URL of the image file to compress',\n        example: 'https://example.com/image.jpg',\n      },\n      outputPath: {\n        type: 'string',\n        description: 'The ABSOLUTE path to save the compressed image file',\n        example: '/Users/user/Downloads/image_compressed.jpg',\n      },\n      outputFormat: {\n        type: 'string',\n        description: 'The format to save the compressed image file',\n        enum: SUPPORTED_IMAGE_TYPES,\n        example: 'image/jpeg',\n      },\n    },\n    required: ['imageUrl'],\n  },\n}\n```\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "tinypng",
        "compress",
        "images",
        "tinypng mcp",
        "compress images",
        "using tinypng"
      ],
      "category": "image-and-video-generation"
    },
    "apinetwork--piapi-mcp-server": {
      "owner": "apinetwork",
      "name": "piapi-mcp-server",
      "url": "https://github.com/apinetwork/piapi-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/apinetwork.webp",
      "description": "Integrates with PiAPI's API to facilitate media content generation using various services like Midjourney, Flux, and more. It connects AI models with tools for seamless content creation directly from applications that support the Model Context Protocol.",
      "stars": 61,
      "forks": 22,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-27T21:10:22Z",
      "readme_content": "# piapi-mcp-server\n\n[![Website](https://img.shields.io/badge/Website-piapi.ai-blue?style=flat-square&logo=internet-explorer)](https://piapi.ai)\n[![Documentation](https://img.shields.io/badge/Documentation-docs-green?style=flat-square&logo=bookstack)](https://piapi.ai/docs)\n[![Discord](https://img.shields.io/badge/Discord-Join%20chat-7289da?style=flat-square&logo=discord)](https://discord.gg/qRRvcGa7Wb)\n\n[![smithery badge](https://smithery.ai/badge/piapi-mcp-server)](https://smithery.ai/server/piapi-mcp-server)\n\nA TypeScript implementation of a Model Context Protocol (MCP) server that integrates with PiAPI's API. PiAPI makes user able to generate media content with Midjourney/Flux/Kling/LumaLabs/Udio/Chrip/Trellis directly from Claude or any other MCP-compatible apps.\n\n<a href=\"https://glama.ai/mcp/servers/ywvke8xruo\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/ywvke8xruo/badge\" alt=\"PiAPI-Server MCP server\" /></a>\n\n## Features (more coming soon)\n\nNote: Time-consuming tools like video generation may not complete due to Claude's timeout limitations\n\n- [x] Base Image toolkit\n- [x] Base Video toolkit\n- [x] Flux Image generation from text/image prompt\n- [x] Hunyuan Video generation from text/image prompt\n- [x] Skyreels Video generation from image prompt\n- [x] Wan Video generation from text/image prompt\n- [x] MMAudio Music generation from video\n- [x] TTS Zero-Shot voice generation\n- [ ] Midjourney Image generation\n  - [x] imagine\n  - [ ] other\n- [x] Kling Video and Effects generation\n- [x] Luma Dream Machine video generation\n- [x] Suno Music generation\n- [ ] Suno Lyrics generation\n- [ ] Udio Music and Lyrics generation\n- [x] Trellis 3D model generation from image\n- [ ] Workflow planning inside LLMs\n\n## Working with Claude Desktop Example\n\n\n\n## Prerequisites\n\n- Node.js 16.x or higher\n- npm or yarn\n- A PiAPI API key (get one at [piapi.ai](https://piapi.ai/workspace/key))\n\n## Installation\n\n### Installing via Smithery\n\nTo install PiAPI MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/piapi-mcp-server):\n\n```bash\nnpx -y @smithery/cli install piapi-mcp-server --client claude\n```\n\n### Manual Installation\n1. Clone the repository:\n\n```bash\ngit clone https://github.com/apinetwork/piapi-mcp-server\ncd piapi-mcp-server\n```\n\n2. Install dependencies:\n\n```bash\nnpm install\n```\n\n3. Build the project:\n\n```bash\nnpm run build\n```\n\nAfter building, a `dist/index.js` file will be generated. You can then configure this file with Claude Desktop and other applications. For detailed configuration instructions, please refer to the Usage section.\n\n4. (Optional) Test server with MCP Inspector:\n\nFirst, create a `.env` file in the project root directory with your API key:\n\n```bash\nPIAPI_API_KEY=your_api_key_here\n```\n\nThen run the following command to start the MCP Inspector:\n\n```bash\nnpm run inspect\n```\n\nAfter running the command, MCP Inspector will be available at http://localhost:5173 (default port: 5173). Open this URL in your browser to start testing. The default timeout for inspector operations is 10000ms (10 seconds), which may not be sufficient for image generation tasks. It's recommended to increase the timeout when testing image generation or other time-consuming operations. You can adjust the timeout by adding a timeout parameter to the URL, for example: http://localhost:5173?timeout=60000 (sets timeout to 60 seconds)\n\nThe MCP Inspector is a powerful development tool that helps you test and debug your MCP server implementation. Key features include:\n\n- **Interactive Testing**: Test your server's functions directly through a web interface\n- **Real-time Feedback**: See immediate results of your function calls and any errors that occur\n- **Request/Response Inspection**: View detailed information about requests and responses\n- **Function Documentation**: Browse available functions and their parameters\n- **Custom Parameters**: Set custom timeout values and other configuration options\n- **History Tracking**: Keep track of your previous function calls and their results\n\nFor detailed information about using the MCP Inspector and its features, visit the [official MCP documentation](https://modelcontextprotocol.io/docs/tools/inspector).\n\n## Usage\n\n### Connecting to Claude Desktop\n\nAdd this to your Claude Desktop configuration file (`~/Library/Application Support/Claude/claude_desktop_config.json` on macOS or `%APPDATA%\\Claude\\claude_desktop_config.json` on Windows):\n\n```json\n{\n  \"mcpServers\": {\n    \"piapi\": {\n      \"command\": \"node\",\n      \"args\": [\"/absolute/path/to/piapi-mcp-server/dist/index.js\"],\n      \"env\": {\n        \"PIAPI_API_KEY\": \"your_api_key_here\"\n      }\n    }\n  }\n}\n```\n\nAfter updating your configuration file, you need to restart Claude for Desktop. Upon restarting, you should see a hammer icon in the bottom right corner of the input box.\nFor more detailed information, visit the [official MCP documentation](https://modelcontextprotocol.io/quickstart/user)\n\n### Connecting to Cursor\n\nNote: Following guide is based on Cursor 0.47.5. Features and behaviors may vary in different versions.\n\nTo configure the MCP server:\n\n1. Navigate to: File > Preferences > Cursor Settings, or use the shortcut key `Ctrl+Shift+J`\n2. Select \"MCP\" tab on the left panel\n3. Click \"Add new global MCP server\" button in the top right\n4. Add your configuration in the opened mcp.json file\n\n```json\n{\n  \"mcpServers\": {\n    \"piapi\": {\n      \"command\": \"node\",\n      \"args\": [\"/absolute/path/to/piapi-mcp-server/dist/index.js\"],\n      \"env\": {\n        \"PIAPI_API_KEY\": \"your_api_key_here\"\n      }\n    }\n  }\n}\n```\n\n5. After configuration, you'll see a \"piapi\" entry in MCP Servers page\n6. Click the Refresh button on the entry or restart Cursor to connect to the piapi server\n\nTo test the piapi image generation:\n\n1. Open and select \"Agent mode\" in Cursor Chat, or use the shortcut key `Ctrl+I`\n2. Enter a test prompt, for example: \"generate image of a dog\"\n3. The image will be generated based on your prompt using piapi server\n\nTo disable the piapi server:\n\n1. Navigate to the MCP Servers page in Cursor Settings\n2. Find the \"piapi\" entry in the server list\n3. Click the \"Enabled\" toggle button to switch it to \"Disabled\"\n\n## Development\n\n### Project Structure\n\n```\npiapi-mcp-server/\n├── assets/\n├── src/\n│   ├── index.ts        # Main server entry point\n├── package.json\n├── tsconfig.json\n└── .env.example\n```\n\n## License\n\nMIT",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "apinetwork",
        "piapi",
        "api",
        "piapi api",
        "apinetwork piapi",
        "video generation"
      ],
      "category": "image-and-video-generation"
    },
    "attarmau--StyleCLIP": {
      "owner": "attarmau",
      "name": "StyleCLIP",
      "url": "https://github.com/attarmau/StyleCLIP",
      "imageUrl": "/freedevtools/mcp/pfp/attarmau.webp",
      "description": "A CLIP-based fashion recommendation system that enables users to upload clothing images and receive similar clothing tag recommendations through an interactive web interface. It utilizes YOLO for clothing detection and integrates seamlessly with an MCP framework.",
      "stars": 0,
      "forks": 3,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-09-19T08:44:33Z",
      "readme_content": "# FastMCP_RecSys\nThis is a CLIP-Based Fashion Recommender with MCP. \n\n### 📌 Sample Components for UI\n1. Image upload\n2. Submit button\n3. Display clothing tags + recommendations\n\n# Mockup\nA user uploads a clothing image → YOLO detects clothing → CLIP encodes → Recommend similar\n\n<img width=\"463\" alt=\"Screenshot 2025-04-26 at 10 26 13 AM\" src=\"https://github.com/user-attachments/assets/93c0a75b-4ed1-4fa1-b25d-5137b8eb6af0\" />\n\n\n# Folder Structure\n```\n/project-root\n│\n├── /backend\n│   ├── Dockerfile            \n│   ├── /app\n│   ├── /aws\n│   │   │   └── rekognition_wrapper.py         # AWS Rekognition logic\n│   │   ├── /utils\n│   │   │   └── image_utils.py                 # Bounding box crop utils\n│   │   ├── /controllers\n│   │   │   └── clothing_detector.py           # Coordinates Rekognition + cropping\n│   │   ├── /tests\n│   │   │   ├── test_rekognition_wrapper.py\n│   │   │   └── test_clothing_tagging.py\n│   │   ├── server.py                    # FastAPI app code\n│   │   ├── /routes\n│   │   │   └── clothing_routes.py\n│   │   ├── /controllers\n│   │   │   ├── clothing_controller.py\n│   │   │   ├── clothing_tagging.py\n│   │   │   └── tag_extractor.py         # Pending: define core CLIP functionality\n│   │   ├── schemas/\n│   │   │   └── clothing_schemas.py\n│   │   ├── config/\n│   │   │   ├── tag_list_en.py           $ Tool for mapping: https://jsoncrack.com/editor\n│   │   │   ├── database.py       \n│   │   │   ├── settings.py       \n│   │   │   └── api_keys.py     \n│   │   └── requirements.txt      \n│   └── .env                      \n│                      \n├── /frontend \n│   ├── Dockerfile        \n│   ├── package.json              \n│   ├── package-lock.json         \n│   ├── /public\n│   │   └── index.html            \n│   ├── /src\n│   │   ├── /components            \n│   │   │   ├── ImageUpload.jsx    \n│   │   │   ├── DetectedTags.jsx   \n│   │   │   └── Recommendations.jsx \n│   │   ├── /utils\n│   │   │   └── api.js             \n│   │   ├── App.js                    # Main React component\n│   │   ├── index.js\n│   │   ├── index.css            \n│   │   ├── tailwind.config.js        \n│   │   └── postcss.config.js                    \n│   └── .env                                \n├── docker-compose.yml                     \n└── README.md \n```\n\n## Quick Start Guide\n### Step 1: Clone the GitHub Project\n### Step 2: Set Up the Python Environment\n```\npython -m venv venv\nsource venv/bin/activate  # On macOS or Linux\nvenv\\Scripts\\activate     # On Windows\n```\n### Step 3: Install Dependencies\n```\npip install -r requirements.txt\n```\n### Step 4: Start the FastAPI Server (Backend)\n```\nuvicorn backend.app.server:app --reload\n```\nOnce the server is running and the database is connected, you should see the following message in the console:\n```\nDatabase connected\nINFO:     Application startup complete.\n```\n<img width=\"750\" alt=\"Screenshot 2025-04-25 at 1 15 45 AM\" src=\"https://github.com/user-attachments/assets/7f3fc403-fb33-4107-a00c-61796a48ecec\" />\n\n### Step 5: Install Dependencies\nDatabase connected\nINFO:     Application startup complete.\n```\nnpm install\n```\n### Step 6: Start the Development Server (Frontend)\n```\nnpm start\n```\nOnce running, the server logs a confirmation and opens the app in your browser: [http://localhost:3000/](http://localhost:3000/)\n\n<img width=\"372\" alt=\"Screenshot 2025-04-25 at 9 08 50 PM\" src=\"https://github.com/user-attachments/assets/794a6dba-9fbb-40f1-9e57-c5c2e2af1013\" />\n\n# What’s completed so far:\n1. FastAPI server is up and running (24 Apr)\n2. Database connection is set up (24 Apr)\n3. Backend architecture is functional (24 Apr)\n4. Basic front-end UI for uploading picture (25 Apr)\n## 5. Mock Testing for AWS Rekognition -> bounding box (15 May)\n```\nPYTHONPATH=. pytest backend/app/tests/test_rekognition_wrapper.py\n```\n<img width=\"1067\" alt=\"Screenshot 2025-05-20 at 4 58 14 PM\" src=\"https://github.com/user-attachments/assets/7a25a92d-2aca-42a8-abdd-194dd9d2e8a5\" />\n\n- Tested Rekognition integration logic independently using a mock → verified it correctly extracts bounding boxes only when labels match the garment set\n- Confirmed the folder structure and PYTHONPATH=. works smoothly with pytest from root\n\n## 6. Mock Testing for AWS Rekognition -> CLIP (20 May)\n```\nPYTHONPATH=. pytest backend/app/tests/test_clothing_tagging.py\n```\n<img width=\"1062\" alt=\"Screenshot 2025-05-21 at 9 25 33 AM\" src=\"https://github.com/user-attachments/assets/6c64b658-3414-4115-9e20-520132605cab\" />\n\n- Detecting garments using AWS Rekognition \n\n- Cropping the image around detected bounding boxes\n\n- Tagging the cropped image using CLIP\n\n## 7. Mock Testing for full image tagging pipeline (Image bytes → AWS Rekognition (detect garments) → Crop images → CLIP (predict tags) + Error Handling (25 May)\n| **Negative Test Case**         | **Description**                                                                 |\n| -------------------------------| ------------------------------------------------------------------------------- |\n| No Detection Result            | AWS doesn't detect any garments — should return an empty list.                  |\n| Image Not Clothing             | CLIP returns vague or empty tags — verify fallback behavior.                    |\n| AWS Returns Exception          | Simulate `rekognition.detect_labels` throwing an error — check `try-except`.    |\n| Corrupted Image File           | Simulate a broken (non-JPEG) image — verify it raises an error or gives a hint. |\n\n```\nPYTHONPATH=. pytest backend/app/tests/test_clothing_tagging.py\n```\n<img width=\"1072\" alt=\"Screenshot 2025-05-21 at 11 19 47 AM\" src=\"https://github.com/user-attachments/assets/b41f07f4-7926-44a3-8b64-34fe3c6ef049\" />\n\n- detect_garments: simulates AWS Rekognition returning one bounding box: {\"Left\": 0.1, \"Top\": 0.1, \"Width\": 0.5, \"Height\": 0.5}\n- crop_by_bounding_box: simulates the cropping step returning a dummy \"cropped_image\" object\n- get_tags_from_clip: simulates CLIP returning a list of tags: [\"T-shirt\", \"Cotton\", \"Casual\"]\n\n## 8. Run Testing for CLIP Output (30 May)\n```\npython3 -m venv venv\npip install -r requirements.txt\npip install git+https://github.com/openai/CLIP.git\npython -m backend.app.tests.test_tag_extractor\n```\n<img width=\"1111\" alt=\"Screenshot 2025-06-06 at 5 12 13 PM\" src=\"https://github.com/user-attachments/assets/d0b3b288-20f8-482f-9d39-dcccf9a775ee\" />\n\nNext Step:\n1. Evaluate CLIP’s tagging accuracy on sample clothing images\n2. Fine-tune the tagging system for better recommendations\n3. Test the backend integration with real-time user data\n4. Set up monitoring for model performance\n5. Front-end demo\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "styleclip",
        "fashion",
        "clothing",
        "clothing images",
        "upload clothing",
        "clothing tag"
      ],
      "category": "image-and-video-generation"
    },
    "awkoy--replicate-flux-mcp": {
      "owner": "awkoy",
      "name": "replicate-flux-mcp",
      "url": "https://github.com/awkoy/replicate-flux-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/awkoy.webp",
      "description": "Generate images from text prompts using advanced AI models. Customize parameters for tailored outputs with secure and local processing.",
      "stars": 50,
      "forks": 11,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-14T19:36:15Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/awkoy-replicate-flux-mcp-badge.png)](https://mseep.ai/app/awkoy-replicate-flux-mcp)\n\n# Replicate Flux MCP\n\n![MCP Compatible](https://img.shields.io/badge/MCP-Compatible-blue)\n![License](https://img.shields.io/badge/license-MIT-green)\n![TypeScript](https://img.shields.io/badge/TypeScript-4.9+-blue)\n![Model Context Protocol](https://img.shields.io/badge/MCP-Enabled-purple)\n[![smithery badge](https://smithery.ai/badge/@awkoy/replicate-flux-mcp)](https://smithery.ai/server/@awkoy/replicate-flux-mcp)\n![NPM Downloads](https://img.shields.io/npm/dw/replicate-flux-mcp)\n![Stars](https://img.shields.io/github/stars/awkoy/replicate-flux-mcp)\n\n<a href=\"https://glama.ai/mcp/servers/ss8n1knen8\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/ss8n1knen8/badge\" />\n</a>\n\n**Replicate Flux MCP** is an advanced Model Context Protocol (MCP) server that empowers AI assistants to generate high-quality images and vector graphics. Leveraging [Black Forest Labs' Flux Schnell model](https://replicate.com/black-forest-labs/flux-schnell) for raster images and [Recraft's V3 SVG model](https://replicate.com/recraft-ai/recraft-v3-svg) for vector graphics via the Replicate API.\n\n## 📑 Table of Contents\n\n- [Getting Started & Integration](#-getting-started--integration)\n  - [Setup Process](#setup-process)\n  - [Cursor Integration](#cursor-integration)\n  - [Claude Desktop Integration](#claude-desktop-integration)\n  - [Smithery Integration](#smithery-integration)\n  - [Glama.ai Integration](#glamaai-integration)\n- [Features](#-features)\n- [Documentation](#-documentation)\n  - [Available Tools](#available-tools)\n  - [Available Resources](#available-resources)\n- [Development](#-development)\n- [Technical Details](#-technical-details)\n- [Troubleshooting](#-troubleshooting)\n- [Contributing](#-contributing)\n- [License](#-license)\n- [Resources](#-resources)\n- [Examples](#-examples)\n\n## 🚀 Getting Started & Integration\n\n### Setup Process\n\n1. **Obtain a Replicate API Token**\n   - Sign up at [Replicate](https://replicate.com/)\n   - Create an API token in your account settings\n\n2. **Choose Your Integration Method**\n   - Follow one of the integration options below based on your preferred MCP client\n\n3. **Ask Your AI Assistant to Generate an Image**\n   - Simply ask naturally: \"Can you generate an image of a serene mountain landscape at sunset?\"\n   - Or be more specific: \"Please create an image showing a peaceful mountain scene with a lake reflecting the sunset colors in the foreground\"\n\n4. **Explore Advanced Features**\n   - Try different parameter settings for customized results\n   - Experiment with SVG generation using `generate_svg`\n   - Use batch image generation or variant generation features\n\n### Cursor Integration\n\n#### Method 1: Using mcp.json\n\n1. Create or edit the `.cursor/mcp.json` file in your project directory:\n\n```json\n{\n  \"mcpServers\": {\n    \"replicate-flux-mcp\": {\n      \"command\": \"env REPLICATE_API_TOKEN=YOUR_TOKEN npx\",\n      \"args\": [\"-y\", \"replicate-flux-mcp\"]\n    }\n  }\n}\n```\n\n2. Replace `YOUR_TOKEN` with your actual Replicate API token\n3. Restart Cursor to apply the changes\n\n#### Method 2: Manual Mode\n\n1. Open Cursor and go to Settings\n2. Navigate to the \"MCP\" or \"Model Context Protocol\" section\n3. Click \"Add Server\" or equivalent\n4. Enter the following command in the appropriate field:\n\n```\nenv REPLICATE_API_TOKEN=YOUR_TOKEN npx -y replicate-flux-mcp\n```\n\n5. Replace `YOUR_TOKEN` with your actual Replicate API token\n6. Save the settings and restart Cursor if necessary\n\n### Claude Desktop Integration\n\n1. Create or edit the `mcp.json` file in your configuration directory:\n\n```json\n{\n  \"mcpServers\": {\n    \"replicate-flux-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"replicate-flux-mcp\"],\n      \"env\": {\n        \"REPLICATE_API_TOKEN\": \"YOUR TOKEN\"\n      }\n    }\n  }\n}\n```\n\n2. Replace `YOUR_TOKEN` with your actual Replicate API token\n3. Restart Claude Desktop to apply the changes\n\n### Smithery Integration\n\nThis MCP server is available as a hosted service on Smithery, allowing you to use it without setting up your own server.\n\n1. Visit [Smithery](https://smithery.ai/) and create an account if you don't have one\n2. Navigate to the [Replicate Flux MCP server page](https://smithery.ai/server/@awkoy/replicate-flux-mcp)\n3. Click \"Add to Workspace\" to add the server to your Smithery workspace\n4. Configure your MCP client (Cursor, Claude Desktop, etc.) to use your Smithery workspace URL\n\nFor more information on using Smithery with your MCP clients, visit the [Smithery documentation](https://smithery.ai/docs).\n\n### Glama.ai Integration\n\nThis MCP server is also available as a hosted service on Glama.ai, providing another option to use it without local setup.\n\n1. Visit [Glama.ai](https://glama.ai/) and create an account if you don't have one\n2. Go to the [Replicate Flux MCP server page](https://glama.ai/mcp/servers/ss8n1knen8)\n3. Click \"Install Server\" to add the server to your workspace\n4. Configure your MCP client to use your Glama.ai workspace\n\nFor more information, visit the [Glama.ai MCP servers documentation](https://glama.ai/mcp/servers).\n\n## 🌟 Features\n\n- **🖼️ High-Quality Image Generation** - Create stunning images using Flux Schnell, a state-of-the-art AI model\n- **🎨 Vector Graphics Support** - Generate professional SVG vector graphics with Recraft V3 SVG model\n- **🤖 AI Assistant Integration** - Seamlessly enable AI assistants like Claude to generate visual content\n- **🎛️ Advanced Customization** - Fine-tune generation with controls for aspect ratio, quality, resolution, and more\n- **🔌 Universal MCP Compatibility** - Works with all MCP clients including Cursor, Claude Desktop, Cline, and Zed\n- **🔒 Secure Local Processing** - All requests are processed locally for enhanced privacy and security\n- **🔍 Comprehensive History Management** - Track, view, and retrieve your complete generation history\n- **📊 Batch Processing** - Generate multiple images from different prompts in a single request\n- **🔄 Variant Exploration** - Create and compare multiple interpretations of the same concept\n- **✏️ Prompt Engineering** - Fine-tune image variations with specialized prompt modifications\n\n## 📚 Documentation\n\n### Available Tools\n\n#### `generate_image`\n\nGenerates an image based on a text prompt using the Flux Schnell model.\n\n```typescript\n{\n  prompt: string;                // Required: Text description of the image to generate\n  seed?: number;                 // Optional: Random seed for reproducible generation\n  go_fast?: boolean;             // Optional: Run faster predictions with optimized model (default: true)\n  megapixels?: \"1\" | \"0.25\";     // Optional: Image resolution (default: \"1\")\n  num_outputs?: number;          // Optional: Number of images to generate (1-4) (default: 1)\n  aspect_ratio?: string;         // Optional: Aspect ratio (e.g., \"16:9\", \"4:3\") (default: \"1:1\")\n  output_format?: string;        // Optional: Output format (\"webp\", \"jpg\", \"png\") (default: \"webp\")\n  output_quality?: number;       // Optional: Image quality (0-100) (default: 80)\n  num_inference_steps?: number;  // Optional: Number of denoising steps (1-4) (default: 4)\n  disable_safety_checker?: boolean; // Optional: Disable safety filter (default: false)\n}\n```\n\n#### `generate_multiple_images`\n\nGenerates multiple images based on an array of prompts using the Flux Schnell model.\n\n```typescript\n{\n  prompts: string[];             // Required: Array of text descriptions for images to generate (1-10 prompts)\n  seed?: number;                 // Optional: Random seed for reproducible generation\n  go_fast?: boolean;             // Optional: Run faster predictions with optimized model (default: true)\n  megapixels?: \"1\" | \"0.25\";     // Optional: Image resolution (default: \"1\")\n  aspect_ratio?: string;         // Optional: Aspect ratio (e.g., \"16:9\", \"4:3\") (default: \"1:1\")\n  output_format?: string;        // Optional: Output format (\"webp\", \"jpg\", \"png\") (default: \"webp\")\n  output_quality?: number;       // Optional: Image quality (0-100) (default: 80)\n  num_inference_steps?: number;  // Optional: Number of denoising steps (1-4) (default: 4)\n  disable_safety_checker?: boolean; // Optional: Disable safety filter (default: false)\n}\n```\n\n#### `generate_image_variants`\n\nGenerates multiple variants of the same image from a single prompt.\n\n```typescript\n{\n  prompt: string;                // Required: Text description for the image to generate variants of\n  num_variants: number;          // Required: Number of image variants to generate (2-10, default: 4)\n  prompt_variations?: string[];  // Optional: List of prompt modifiers to apply to variants (e.g., [\"in watercolor style\", \"in oil painting style\"])\n  variation_mode?: \"append\" | \"replace\"; // Optional: How to apply variations - 'append' adds to base prompt, 'replace' uses variations directly (default: \"append\")\n  seed?: number;                 // Optional: Base random seed. Each variant will use seed+variant_index\n  go_fast?: boolean;             // Optional: Run faster predictions with optimized model (default: true)\n  megapixels?: \"1\" | \"0.25\";     // Optional: Image resolution (default: \"1\")\n  aspect_ratio?: string;         // Optional: Aspect ratio (e.g., \"16:9\", \"4:3\") (default: \"1:1\")\n  output_format?: string;        // Optional: Output format (\"webp\", \"jpg\", \"png\") (default: \"webp\")\n  output_quality?: number;       // Optional: Image quality (0-100) (default: 80)\n  num_inference_steps?: number;  // Optional: Number of denoising steps (1-4) (default: 4)\n  disable_safety_checker?: boolean; // Optional: Disable safety filter (default: false)\n}\n```\n\n#### `generate_svg`\n\nGenerates an SVG vector image based on a text prompt using the Recraft V3 SVG model.\n\n```typescript\n{\n  prompt: string;                // Required: Text description of the SVG to generate\n  size?: string;                 // Optional: Size of the generated SVG (default: \"1024x1024\")\n  style?: string;                // Optional: Style of the generated image (default: \"any\")\n                                // Options: \"any\", \"engraving\", \"line_art\", \"line_circuit\", \"linocut\"\n}\n```\n\n#### `prediction_list`\n\nRetrieves a list of your recent predictions from Replicate.\n\n```typescript\n{\n  limit?: number;  // Optional: Maximum number of predictions to return (1-100) (default: 50)\n}\n```\n\n#### `get_prediction`\n\nGets detailed information about a specific prediction.\n\n```typescript\n{\n  predictionId: string;  // Required: ID of the prediction to retrieve\n}\n```\n\n### Available Resources\n\n#### `imagelist`\n\nBrowse your history of generated images created with the Flux Schnell model.\n\n#### `svglist`\n\nBrowse your history of generated SVG images created with the Recraft V3 SVG model.\n\n#### `predictionlist`\n\nBrowse all your Replicate predictions history.\n\n## 💻 Development\n\n1. Clone the repository:\n\n```bash\ngit clone https://github.com/awkoy/replicate-flux-mcp.git\ncd replicate-flux-mcp\n```\n\n2. Install dependencies:\n\n```bash\nnpm install\n```\n\n3. Start development mode:\n\n```bash\nnpm run dev\n```\n\n4. Build the project:\n\n```bash\nnpm run build\n```\n\n5. Connect to Client:\n\n```json\n{\n  \"mcpServers\": {\n    \"image-generation-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"/Users/{USERNAME}/{PATH_TO}/replicate-flux-mcp/build/index.js\"\n      ],\n      \"env\": {\n        \"REPLICATE_API_TOKEN\": \"YOUR REPLICATE API TOKEN\"\n      }\n    }\n  }\n}\n```\n\n## ⚙️ Technical Details\n\n### Stack\n\n- **Model Context Protocol SDK** - Core MCP functionality for tool and resource management\n- **Replicate API** - Provides access to state-of-the-art AI image generation models\n- **TypeScript** - Ensures type safety and leverages modern JavaScript features\n- **Zod** - Implements runtime type validation for robust API interactions\n\n### Configuration\n\nThe server can be configured by modifying the `CONFIG` object in `src/config/index.ts`:\n\n```javascript\nconst CONFIG = {\n  serverName: \"replicate-flux-mcp\",\n  serverVersion: \"0.1.2\",\n  imageModelId: \"black-forest-labs/flux-schnell\",\n  svgModelId: \"recraft-ai/recraft-v3-svg\",\n  pollingAttempts: 25,\n  pollingInterval: 2000, // ms\n};\n```\n\n## 🔍 Troubleshooting\n\n### Common Issues\n\n#### Authentication Error\n- Ensure your `REPLICATE_API_TOKEN` is correctly set in the environment\n- Verify your token is valid by testing it with the Replicate API directly\n\n#### Safety Filter Triggered\n- The model has a built-in safety filter that may block certain prompts\n- Try modifying your prompt to avoid potentially problematic content\n\n#### Timeout Error\n- For larger images or busy servers, you might need to increase `pollingAttempts` or `pollingInterval` in the configuration\n- Default settings should work for most use cases\n\n## 🤝 Contributing\n\nContributions are welcome! Please follow these steps to contribute:\n\n1. Fork the repository\n2. Create your feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add some amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n\nFor feature requests or bug reports, please create a GitHub issue. If you like this project, consider starring the repository!\n\n## 📄 License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## 🔗 Resources\n\n- [Model Context Protocol Documentation](https://modelcontextprotocol.io)\n- [Replicate API Documentation](https://replicate.com/docs)\n- [Flux Schnell Model](https://replicate.com/black-forest-labs/flux-schnell)\n- [Recraft V3 SVG Model](https://replicate.com/recraft-ai/recraft-v3-svg)\n- [MCP TypeScript SDK](https://github.com/modelcontextprotocol/typescript-sdk)\n- [Smithery Documentation](https://smithery.ai/docs)\n- [Glama.ai MCP Servers](https://glama.ai/mcp/servers)\n\n## 🎨 Examples\n\n![Demo](https://github.com/user-attachments/assets/ad6db606-ae3a-48db-a1cc-e1f88847769e)\n\n| Multiple Prompts | Prompt Variants |\n|-----------------|-----------------|\n| ![Multiple prompts example: \"A serene mountain lake at sunset\", \"A bustling city street at night\", \"A peaceful garden in spring\"](https://github.com/user-attachments/assets/e5ac56d2-bfbb-4f33-938c-a3d7bffeee60) | ![Variants example: Base prompt \"A majestic castle\" with modifiers \"in watercolor style\", \"as an oil painting\", \"with gothic architecture\"](https://github.com/user-attachments/assets/8ebe5992-4803-4bf3-a82a-251135b0698a) |\n\nHere are some examples of how to use the tools:\n\n### Batch Image Generation with `generate_multiple_images`\n\nCreate multiple distinct images at once with different prompts:\n\n```json\n{\n  \"prompts\": [\n    \"A red sports car on a mountain road\", \n    \"A blue sports car on a beach\", \n    \"A vintage sports car in a city street\"\n  ]\n}\n```\n\n### Image Variants with `generate_image_variants`\n\nCreate different interpretations of the same concept using seeds:\n\n```json\n{\n  \"prompt\": \"A futuristic city skyline at night\",\n  \"num_variants\": 4,\n  \"seed\": 42\n}\n```\n\nOr explore style variations with prompt modifiers:\n\n```json\n{\n  \"prompt\": \"A character portrait\",\n  \"prompt_variations\": [\n    \"in anime style\", \n    \"in watercolor style\", \n    \"in oil painting style\", \n    \"as a 3D render\"\n  ]\n}\n```\n\n---\n\nMade with ❤️ by Yaroslav Boiko\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ai",
        "mcp",
        "prompts",
        "mcp generate",
        "generate images",
        "awkoy replicate"
      ],
      "category": "image-and-video-generation"
    },
    "awslabs--mcp": {
      "owner": "awslabs",
      "name": "mcp",
      "url": "https://github.com/awslabs/mcp",
      "imageUrl": "/freedevtools/mcp/pfp/awslabs.webp",
      "description": "Generates images from text prompts and specific color palettes, utilizing customizable options for dimensions and quality. Supports both text-based and color-guided image generation, allowing for multiple images in a single request.",
      "stars": 6585,
      "forks": 942,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-10-04T06:19:32Z",
      "readme_content": "# AWS MCP Servers\n\nA suite of specialized MCP servers that help you get the most out of AWS, wherever you use MCP.\n\n[![GitHub](https://img.shields.io/badge/github-awslabs/mcp-blue.svg?style=flat&logo=github)](https://github.com/awslabs/mcp)\n[![License](https://img.shields.io/badge/license-Apache--2.0-brightgreen)](LICENSE)\n[![Codecov](https://img.shields.io/codecov/c/github/awslabs/mcp)](https://app.codecov.io/gh/awslabs/mcp)\n[![OSSF-Scorecard Score](https://img.shields.io/ossf-scorecard/github.com/awslabs/mcp)](https://scorecard.dev/viewer/?uri=github.com/awslabs/mcp)\n\n## Table of Contents\n\n- [AWS MCP Servers](#aws-mcp-servers)\n  - [Table of Contents](#table-of-contents)\n  - [What is the Model Context Protocol (MCP) and how does it work with AWS MCP Servers?](#what-is-the-model-context-protocol-mcp-and-how-does-it-work-with-aws-mcp-servers)\n  - [Server Sent Events Support Removal](#server-sent-events-support-removal)\n  - [Why AWS MCP Servers?](#why-aws-mcp-servers)\n  - [Available MCP Servers: Quick Installation](#available-mcp-servers-quick-installation)\n    - [🚀Getting Started with AWS](#-getting-started-with-aws)\n    - [Browse by What You're Building](#browse-by-what-youre-building)\n      - [📚 Real-time access to official AWS documentation](#-real-time-access-to-official-aws-documentation)\n      - [🏗️ Infrastructure \\& Deployment](#️-infrastructure--deployment)\n        - [Infrastructure as Code](#infrastructure-as-code)\n        - [Container Platforms](#container-platforms)\n        - [Serverless \\& Functions](#serverless--functions)\n        - [Support](#support)\n      - [🤖 AI \\& Machine Learning](#-ai--machine-learning)\n      - [📊 Data \\& Analytics](#-data--analytics)\n        - [SQL \\& NoSQL Databases](#sql--nosql-databases)\n        - [Search \\& Analytics](#search--analytics)\n        - [Caching \\& Performance](#caching--performance)\n      - [🛠️ Developer Tools \\& Support](#️-developer-tools--support)\n      - [📡 Integration \\& Messaging](#-integration--messaging)\n      - [💰 Cost \\& Operations](#-cost--operations)\n      - [🧬 Healthcare \\& Lifesciences](#-healthcare--lifesciences)\n    - [Browse by How You're Working](#browse-by-how-youre-working)\n      - [👨‍💻 Vibe Coding \\& Development](#-vibe-coding--development)\n        - [Core Development Workflow](#core-development-workflow)\n        - [Infrastructure as Code](#infrastructure-as-code-1)\n        - [Application Development](#application-development)\n        - [Container \\& Serverless Development](#container--serverless-development)\n        - [Testing \\& Data](#testing--data)\n        - [Lifesciences Workflow Development](#lifesciences-workflow-development)\n      - [💬 Conversational Assistants](#-conversational-assistants)\n        - [Knowledge \\& Search](#knowledge--search)\n        - [Content Processing \\& Generation](#content-processing--generation)\n        - [Business Services](#business-services)\n      - [🤖 Autonomous Background Agents](#-autonomous-background-agents)\n        - [Data Operations \\& ETL](#data-operations--etl)\n        - [Caching \\& Performance](#caching--performance-1)\n        - [Workflow \\& Integration](#workflow--integration)\n        - [Operations \\& Monitoring](#operations--monitoring)\n  - [MCP AWS Lambda Handler Module](#mcp-aws-lambda-handler-module)\n  - [When to use Local vs Remote MCP Servers?](#when-to-use-local-vs-remote-mcp-servers)\n    - [Local MCP Servers](#local-mcp-servers)\n    - [Remote MCP Servers](#remote-mcp-servers)\n  - [Use Cases for the Servers](#use-cases-for-the-servers)\n  - [Installation and Setup](#installation-and-setup)\n    - [Running MCP servers in containers](#running-mcp-servers-in-containers)\n    - [Getting Started with Amazon Q Developer CLI](#getting-started-with-amazon-q-developer-cli)\n      - [`~/.aws/amazonq/mcp.json`](#awsamazonqmcpjson)\n    - [Getting Started with Kiro](#getting-started-with-kiro)\n      - [`kiro_mcp_settings.json`](#kiro_mcp_settingsjson)\n    - [Getting Started with Cline and Amazon Bedrock](#getting-started-with-cline-and-amazon-bedrock)\n      - [`cline_mcp_settings.json`](#cline_mcp_settingsjson)\n    - [Getting Started with Cursor](#getting-started-with-cursor)\n      - [`.cursor/mcp.json`](#cursormcpjson)\n    - [Getting Started with Windsurf](#getting-started-with-windsurf)\n      - [`~/.codeium/windsurf/mcp_config.json`](#codeiumwindsurfmcp_configjson)\n    - [Getting Started with VS Code](#getting-started-with-vs-code)\n      - [`.vscode/mcp.json`](#vscodemcpjson)\n    - [Getting Started with Claude Code](#getting-started-with-claude-code)\n      - [`.mcp.json`](#mcpjson)\n  - [Samples](#samples)\n  - [Vibe coding](#vibe-coding)\n  - [Additional Resources](#additional-resources)\n  - [Security](#security)\n  - [Contributing](#contributing)\n  - [Developer guide](#developer-guide)\n  - [License](#license)\n  - [Disclaimer](#disclaimer)\n\n## What is the Model Context Protocol (MCP) and how does it work with AWS MCP Servers?\n\n> The Model Context Protocol (MCP) is an open protocol that enables seamless integration between LLM applications and external data sources and tools. Whether you're building an AI-powered IDE, enhancing a chat interface, or creating custom AI workflows, MCP provides a standardized way to connect LLMs with the context they need.\n>\n> &mdash; [Model Context Protocol README](https://github.com/modelcontextprotocol#:~:text=The%20Model%20Context,context%20they%20need.)\n\nAn MCP Server is a lightweight program that exposes specific capabilities through the standardized Model Context Protocol. Host applications (such as chatbots, IDEs, and other AI tools) have MCP clients that maintain 1:1 connections with MCP servers. Common MCP clients include agentic AI coding assistants (like Q Developer, Cline, Cursor, Windsurf) as well as chatbot applications like Claude Desktop, with more clients coming soon. MCP servers can access local data sources and remote services to provide additional context that improves the generated outputs from the models.\n\nAWS MCP Servers use this protocol to provide AI applications access to AWS documentation, contextual guidance, and best practices. Through the standardized MCP client-server architecture, AWS capabilities become an intelligent extension of your development environment or AI application.\n\nAWS MCP servers enable enhanced cloud-native development, infrastructure management, and development workflows—making AI-assisted cloud computing more accessible and efficient.\n\nThe Model Context Protocol is an open source project run by Anthropic, PBC. and open to contributions from the entire community. For more information on MCP, you can find further documentation [here](https://modelcontextprotocol.io/introduction)\n\n## Server Sent Events Support Removal\n\n**Important Notice:** On May 26th, 2025, Server Sent Events (SSE) support was removed from all MCP servers in their latest major versions. This change aligns with the Model Context Protocol specification's [backwards compatibility guidelines](https://modelcontextprotocol.io/specification/2025-03-26/basic/transports#backwards-compatibility).\n\nWe are actively working towards supporting [Streamable HTTP](https://modelcontextprotocol.io/specification/draft/basic/transports#streamable-http), which will provide improved transport capabilities for future versions.\n\nFor applications still requiring SSE support, please use the previous major version of the respective MCP server until you can migrate to alternative transport methods.\n\n### Why AWS MCP Servers?\n\nMCP servers enhance the capabilities of foundation models (FMs) in several key ways:\n\n- **Improved Output Quality**: By providing relevant information directly in the model's context, MCP servers significantly improve model responses for specialized domains like AWS services. This approach reduces hallucinations, provides more accurate technical details, enables more precise code generation, and ensures recommendations align with current AWS best practices and service capabilities.\n\n- **Access to Latest Documentation**: FMs may not have knowledge of recent releases, APIs, or SDKs. MCP servers bridge this gap by pulling in up-to-date documentation, ensuring your AI assistant always works with the latest AWS capabilities.\n\n- **Workflow Automation**: MCP servers convert common workflows into tools that foundation models can use directly. Whether it's CDK, Terraform, or other AWS-specific workflows, these tools enable AI assistants to perform complex tasks with greater accuracy and efficiency.\n\n- **Specialized Domain Knowledge**: MCP servers provide deep, contextual knowledge about AWS services that might not be fully represented in foundation models' training data, enabling more accurate and helpful responses for cloud development tasks.\n\n## Available MCP Servers: Quick Installation\n\nGet started quickly with one-click installation buttons for popular MCP clients. Click the buttons below to install servers directly in Cursor or VS Code:\n\n### 🚀 Getting Started with AWS\n\nFor general AWS interactions and comprehensive API support, we recommend starting with:\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [AWS API MCP Server](src/aws-api-mcp-server) | Start here for general AWS interactions! Comprehensive AWS API support with command validation, security controls, and access to all AWS services. Perfect for managing infrastructure, exploring resources, and executing AWS operations through natural language. | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-api-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWFwaS1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D)<br/>[![Install VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20API%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-api-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_REGION%22%3A%22us-east-1%22%7D%2C%22type%22%3A%22stdio%22%7D) |\n| [AWS Knowledge MCP Server](src/aws-knowledge-mcp-server) | A remote, fully-managed MCP server hosted by AWS that provides access to the latest AWS docs, API references, What's New Posts, Getting Started information, Builder Center, Blog posts, Architectural references, and Well-Architected guidance. | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-knowledge-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWtub3dsZWRnZS1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUFJPRklMRSI6InlvdXItYXdzLXByb2ZpbGUiLCJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIiwiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D)<br/>[![Install VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Knowledge%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-knowledge-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n### Browse by What You're Building\n\n#### 📚 Real-time access to official AWS documentation\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [AWS Knowledge MCP Server](src/aws-knowledge-mcp-server) | A remote, fully-managed MCP server hosted by AWS that provides access to the latest AWS docs, API references, What's New Posts, Getting Started information, Builder Center, Blog posts, Architectural references, and Well-Architected guidance. | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-knowledge-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWtub3dsZWRnZS1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUFJPRklMRSI6InlvdXItYXdzLXByb2ZpbGUiLCJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIiwiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D)<br/>[![Install VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Knowledge%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-knowledge-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS Documentation MCP Server](src/aws-documentation-mcp-server) | Get latest AWS docs and API references | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-documentation-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWRvY3VtZW50YXRpb24tbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiIsIkFXU19ET0NVTUVOVEFUSU9OX1BBUlRJVElPTiI6ImF3cyJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Documentation%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-documentation-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%2C%22AWS_DOCUMENTATION_PARTITION%22%3A%22aws%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n\n### 🏗️ Infrastructure & Deployment\n\nBuild, deploy, and manage cloud infrastructure with Infrastructure as Code best practices.\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [AWS Cloud Control API MCP Server](src/ccapi-mcp-server) | Direct AWS resource management with security scanning and best practices | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.ccapi-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuY2NhcGktbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJ5b3VyLWF3cy1wcm9maWxlIiwiQVdTX1JFR0lPTiI6InVzLWVhc3QtMSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Cloud%20Control%20API%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.ccapi-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS CDK MCP Server](src/cdk-mcp-server) | AWS CDK development with security compliance and best practices | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.cdk-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuY2RrLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=CDK%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.cdk-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS Terraform MCP Server](src/terraform-mcp-server) | Terraform workflows with integrated security scanning | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.terraform-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMudGVycmFmb3JtLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Terraform%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.terraform-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS CloudFormation MCP Server](src/cfn-mcp-server) | Direct CloudFormation resource management via Cloud Control API | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.cfn-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuY2ZuLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1uYW1lZC1wcm9maWxlIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=CloudFormation%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.cfn-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-named-profile%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n#### Container Platforms\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [Amazon EKS MCP Server](src/eks-mcp-server) | Kubernetes cluster management and application deployment | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.eks-mcp-server&config=eyJhdXRvQXBwcm92ZSI6W10sImRpc2FibGVkIjpmYWxzZSwiY29tbWFuZCI6InV2eCBhd3NsYWJzLmVrcy1tY3Atc2VydmVyQGxhdGVzdCAtLWFsbG93LXdyaXRlIC0tYWxsb3ctc2Vuc2l0aXZlLWRhdGEtYWNjZXNzIiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwidHJhbnNwb3J0VHlwZSI6InN0ZGlvIn0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=EKS%20MCP%20Server&config=%7B%22autoApprove%22%3A%5B%5D%2C%22disabled%22%3Afalse%2C%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.eks-mcp-server%40latest%22%2C%22--allow-write%22%2C%22--allow-sensitive-data-access%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22transportType%22%3A%22stdio%22%7D) |\n| [Amazon ECS MCP Server](src/ecs-mcp-server) | Container orchestration and ECS application deployment | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.ecs-mcp-server&config=eyJjb21tYW5kIjoidXZ4IC0tZnJvbSBhd3NsYWJzLWVjcy1tY3Atc2VydmVyIGVjcy1tY3Atc2VydmVyIiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ5b3VyLWF3cy1yZWdpb24iLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIiwiRkFTVE1DUF9MT0dfRklMRSI6Ii9wYXRoL3RvL2Vjcy1tY3Atc2VydmVyLmxvZyIsIkFMTE9XX1dSSVRFIjoiZmFsc2UiLCJBTExPV19TRU5TSVRJVkVfREFUQSI6ImZhbHNlIn19) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=ECS%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22--from%22%2C%22awslabs-ecs-mcp-server%22%2C%22ecs-mcp-server%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22your-aws-region%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%2C%22FASTMCP_LOG_FILE%22%3A%22%2Fpath%2Fto%2Fecs-mcp-server.log%22%2C%22ALLOW_WRITE%22%3A%22false%22%2C%22ALLOW_SENSITIVE_DATA%22%3A%22false%22%7D%7D) |\n| [Finch MCP Server](src/finch-mcp-server) | Local container building with ECR integration | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.finch-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuZmluY2gtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJkZWZhdWx0IiwiQVdTX1JFR0lPTiI6InVzLXdlc3QtMiIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiSU5GTyJ9LCJ0cmFuc3BvcnRUeXBlIjoic3RkaW8iLCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Finch%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.finch-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22default%22%2C%22AWS_REGION%22%3A%22us-west-2%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22INFO%22%7D%2C%22transportType%22%3A%22stdio%22%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n\n\n#### Serverless & Functions\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [AWS Serverless MCP Server](src/aws-serverless-mcp-server) | Complete serverless application lifecycle with SAM CLI | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-serverless-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLXNlcnZlcmxlc3MtbWNwLXNlcnZlckBsYXRlc3QgLS1hbGxvdy13cml0ZSAtLWFsbG93LXNlbnNpdGl2ZS1kYXRhLWFjY2VzcyIsImVudiI6eyJBV1NfUFJPRklMRSI6InlvdXItYXdzLXByb2ZpbGUiLCJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Serverless%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-serverless-mcp-server%40latest%22%2C%22--allow-write%22%2C%22--allow-sensitive-data-access%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS Lambda Tool MCP Server](src/lambda-tool-mcp-server) | Execute Lambda functions as AI tools for private resource access | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.lambda-tool-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMubGFtYmRhLXRvb2wtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJ5b3VyLWF3cy1wcm9maWxlIiwiQVdTX1JFR0lPTiI6InVzLWVhc3QtMSIsIkZVTkNUSU9OX1BSRUZJWCI6InlvdXItZnVuY3Rpb24tcHJlZml4IiwiRlVOQ1RJT05fTElTVCI6InlvdXItZmlyc3QtZnVuY3Rpb24sIHlvdXItc2Vjb25kLWZ1bmN0aW9uIiwiRlVOQ1RJT05fVEFHX0tFWSI6InlvdXItdGFnLWtleSIsIkZVTkNUSU9OX1RBR19WQUxVRSI6InlvdXItdGFnLXZhbHVlIiwiRlVOQ1RJT05fSU5QVVRfU0NIRU1BX0FSTl9UQUdfS0VZIjoieW91ci1mdW5jdGlvbi10YWctZm9yLWlucHV0LXNjaGVtYSJ9fQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Lambda%20Tool%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.lambda-tool-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FUNCTION_PREFIX%22%3A%22your-function-prefix%22%2C%22FUNCTION_LIST%22%3A%22your-first-function%2C%20your-second-function%22%2C%22FUNCTION_TAG_KEY%22%3A%22your-tag-key%22%2C%22FUNCTION_TAG_VALUE%22%3A%22your-tag-value%22%2C%22FUNCTION_INPUT_SCHEMA_ARN_TAG_KEY%22%3A%22your-function-tag-for-input-schema%22%7D%7D) |\n\n\n#### Support\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [AWS Support MCP Server](src/aws-support-mcp-server) | Help users create and manage AWS Support cases | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs_support_mcp_server&config=eyJjb21tYW5kIjoidXZ4IC1tIGF3c2xhYnMuYXdzLXN1cHBvcnQtbWNwLXNlcnZlckBsYXRlc3QgLS1kZWJ1ZyAtLWxvZy1maWxlIC4vbG9ncy9tY3Bfc3VwcG9ydF9zZXJ2ZXIubG9nIiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSJ9fQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Support%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22-m%22%2C%22awslabs.aws-support-mcp-server%40latest%22%2C%22--debug%22%2C%22--log-file%22%2C%22.%2Flogs%2Fmcp_support_server.log%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%7D%7D) |\n\n### 🤖 AI & Machine Learning\nEnhance AI applications with knowledge retrieval, content generation, and ML capabilities\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [Amazon Bedrock Knowledge Bases Retrieval MCP Server ](src/bedrock-kb-retrieval-mcp-server) | Query enterprise knowledge bases with citation support | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.bedrock-kb-retrieval-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYmVkcm9jay1rYi1yZXRyaWV2YWwtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJ5b3VyLXByb2ZpbGUtbmFtZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIiwiS0JfSU5DTFVTSU9OX1RBR19LRVkiOiJvcHRpb25hbC10YWcta2V5LXRvLWZpbHRlci1rYnMiLCJCRURST0NLX0tCX1JFUkFOS0lOR19FTkFCTEVEIjoiZmFsc2UifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Bedrock%20KB%20Retrieval%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.bedrock-kb-retrieval-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-profile-name%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%2C%22KB_INCLUSION_TAG_KEY%22%3A%22optional-tag-key-to-filter-kbs%22%2C%22BEDROCK_KB_RERANKING_ENABLED%22%3A%22false%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Kendra Index MCP Server](src/amazon-kendra-index-mcp-server) | Enterprise search and RAG enhancement | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.amazon-kendra-index-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYW1hem9uLWtlbmRyYS1pbmRleC1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIiwiS0VORF9JTkRFWF9JRCI6InlvdXIta2VuZHJhLWluZGV4LWlkIiwiS0VORF9ST0xFX0FSTiI6InlvdXIta2VuZHJhLXJvbGUtYXJuIiwiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Amazon%20Kendra%20Index%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.amazon-kendra-index-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_REGION%22%3A%22us-east-1%22%2C%22KEND_INDEX_ID%22%3A%22your-kendra-index-id%22%2C%22KEND_ROLE_ARN%22%3A%22your-kendra-role-arn%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Q Business MCP Server](src/amazon-qbusiness-anonymous-mcp-server) | AI assistant for your ingested content with anonymous access | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.amazon-qbusiness-anonymous-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYW1hem9uLXFidXNpbmVzcy1hbm9ueW1vdXMtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiUUJVU0lORVNTX0FQUF9JRCI6InlvdXItcWJ1c2luZXNzLWFwcC1pZCIsIlFCVVNJTkVTU19VU0VSX0lEIjoieW91ci11c2VyLWlkIiwiQVdTX1BST0ZJTEUiOiJ5b3VyLWF3cy1wcm9maWxlIiwiQVdTX1JFR0lPTiI6InVzLWVhc3QtMSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Amazon%20Q%20Business%20Anonymous%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.amazon-qbusiness-anonymous-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22QBUSINESS_APP_ID%22%3A%22your-qbusiness-app-id%22%2C%22QBUSINESS_USER_ID%22%3A%22your-user-id%22%2C%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Q Index MCP Server](src/amazon-qindex-mcp-server) | Data accessors to search through enterprise's Q index | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.amazon-qindex-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYW1hem9uLXFpbmRleC1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIiwiUUlOREVYX0lEIjoieW91ci1xaW5kZXgtaWQiLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Amazon%20Q%20Index%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.amazon-qindex-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_REGION%22%3A%22us-east-1%22%2C%22QINDEX_ID%22%3A%22your-qindex-id%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Nova Canvas MCP Server](src/nova-canvas-mcp-server) | AI image generation using Amazon Nova Canvas | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.nova-canvas-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMubm92YS1jYW52YXMtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJ5b3VyLWF3cy1wcm9maWxlIiwiQVdTX1JFR0lPTiI6InVzLWVhc3QtMSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Nova%20Canvas%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.nova-canvas-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Rekognition MCP Server (deprecated)](src/amazon-rekognition-mcp-server) | Analyze images using computer vision capabilities | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.amazon-rekognition-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYW1hem9uLXJla29nbml0aW9uLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Amazon%20Rekognition%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.amazon-rekognition-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS Bedrock Data Automation MCP Server](src/aws-bedrock-data-automation-mcp-server) | Analyze documents, images, videos, and audio files | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=bedrock-data-automation-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWJlZHJvY2stZGF0YS1hdXRvbWF0aW9uLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJBV1NfQlVDS0VUX05BTUUiOiJ5b3VyLXMzLWJ1Y2tldC1uYW1lIiwiQkFTRV9ESVIiOiIvcGF0aC90by9iYXNlL2RpcmVjdG9yeSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Bedrock%20Data%20Automation%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-bedrock-data-automation-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22AWS_BUCKET_NAME%22%3A%22your-s3-bucket-name%22%2C%22BASE_DIR%22%3A%22%2Fpath%2Fto%2Fbase%2Fdirectory%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS Bedrock Custom Model Import MCP Server](src/aws-bedrock-custom-model-import-mcp-server) | Manage custom models in Bedrock for on-demand inference | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=aws-bedrock-custom-model-import-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWJlZHJvY2stY3VzdG9tLW1vZGVsLWltcG9ydC1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUFJPRklMRSI6InlvdXItYXdzLXByb2ZpbGUiLCJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIiwiQkVEUk9DS19NT0RFTF9JTVBPUlRfUzNfQlVDS0VUIjoieW91ci1zMy1idWNrZXQtbmFtZSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Bedrock%20Custom%20Model%20Import%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-bedrock-custom-model-import-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22BEDROCK_MODEL_IMPORT_S3_BUCKET%22%3A%22your-s3-bucket-name%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS Bedrock AgentCore MCP Server](src/amazon-bedrock-agentcore-mcp-server) | Provides comprehensive documentation access on AgentCore platform services, APIs, and best practices | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.amazon-bedrock-agentcore-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYW1hem9uLWJlZHJvY2stYWdlbnRjb3JlLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Bedrock%20AgentCore%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.amazon-bedrock-agentcore-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n### 📊 Data & Analytics\n\nWork with databases, caching systems, and data processing workflows.\n\n#### SQL & NoSQL Databases\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [Amazon DynamoDB MCP Server](src/dynamodb-mcp-server) | Complete DynamoDB operations and table management | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.dynamodb-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuZHluYW1vZGItbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiRERCLU1DUC1SRUFET05MWSI6InRydWUiLCJBV1NfUFJPRklMRSI6ImRlZmF1bHQiLCJBV1NfUkVHSU9OIjoidXMtd2VzdC0yIiwiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=DynamoDB%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.dynamodb-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22DDB-MCP-READONLY%22%3A%22true%22%2C%22AWS_PROFILE%22%3A%22default%22%2C%22AWS_REGION%22%3A%22us-west-2%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Aurora PostgreSQL MCP Server](src/postgres-mcp-server) | PostgreSQL database operations via RDS Data API | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.postgres-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMucG9zdGdyZXMtbWNwLXNlcnZlckBsYXRlc3QgLS1jb25uZWN0aW9uLXN0cmluZyBwb3N0Z3Jlc3FsOi8vW3VzZXJuYW1lXTpbcGFzc3dvcmRdQFtob3N0XTpbcG9ydF0vW2RhdGFiYXNlXSIsImVudiI6eyJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdLCJ0cmFuc3BvcnRUeXBlIjoic3RkaW8iLCJhdXRvU3RhcnQiOnRydWV9) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=PostgreSQL%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.postgres-mcp-server%40latest%22%2C%22--connection-string%22%2C%22postgresql%3A%2F%2F%5Busername%5D%3A%5Bpassword%5D%40%5Bhost%5D%3A%5Bport%5D%2F%5Bdatabase%5D%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%2C%22transportType%22%3A%22stdio%22%2C%22autoStart%22%3Atrue%7D) |\n| [Amazon Aurora MySQL MCP Server](src/mysql-mcp-server) | MySQL database operations via RDS Data API | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.mysql-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMubXlzcWwtbWNwLXNlcnZlckBsYXRlc3QgLS1yZXNvdXJjZV9hcm4gW3lvdXIgZGF0YV0gLS1zZWNyZXRfYXJuIFt5b3VyIGRhdGFdIC0tZGF0YWJhc2UgW3lvdXIgZGF0YV0gLS1yZWdpb24gW3lvdXIgZGF0YV0gLS1yZWFkb25seSBUcnVlIiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=MySQL%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.mysql-mcp-server%40latest%22%2C%22--resource_arn%22%2C%22%5Byour%20data%5D%22%2C%22--secret_arn%22%2C%22%5Byour%20data%5D%22%2C%22--database%22%2C%22%5Byour%20data%5D%22%2C%22--region%22%2C%22%5Byour%20data%5D%22%2C%22--readonly%22%2C%22True%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Aurora DSQL MCP Server](src/aurora-dsql-mcp-server) | Distributed SQL with PostgreSQL compatibility | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aurora-dsql-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXVyb3JhLWRzcWwtbWNwLXNlcnZlckBsYXRlc3QgLS1jbHVzdGVyX2VuZHBvaW50IFt5b3VyIGRzcWwgY2x1c3RlciBlbmRwb2ludF0gLS1yZWdpb24gW3lvdXIgZHNxbCBjbHVzdGVyIHJlZ2lvbiwgZS5nLiB1cy1lYXN0LTFdIC0tZGF0YWJhc2VfdXNlciBbeW91ciBkc3FsIHVzZXJuYW1lXSAtLXByb2ZpbGUgZGVmYXVsdCIsImVudiI6eyJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Aurora%20DSQL%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aurora-dsql-mcp-server%40latest%22%2C%22--cluster_endpoint%22%2C%22%5Byour%20dsql%20cluster%20endpoint%5D%22%2C%22--region%22%2C%22%5Byour%20dsql%20cluster%20region%2C%20e.g.%20us-east-1%5D%22%2C%22--database_user%22%2C%22%5Byour%20dsql%20username%5D%22%2C%22--profile%22%2C%22default%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon DocumentDB MCP Server](src/documentdb-mcp-server) | MongoDB-compatible document database operations | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.documentdb-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuZG9jdW1lbnRkYi1tY3Atc2VydmVAbGF0ZXN0IiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IiLCJBV1NfUFJPRklMRSI6InlvdXItYXdzLXByb2ZpbGUifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=DocumentDB%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.documentdb-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%2C%22AWS_PROFILE%22%3A%22your-aws-profile%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Neptune MCP Server](src/amazon-neptune-mcp-server) | Graph database queries with openCypher and Gremlin | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.amazon-neptune-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYW1hem9uLW5lcHR1bmUtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiTkVQVFVORV9FTkRQT0lOVCI6Imh0dHBzOi8veW91ci1uZXB0dW5lLWNsdXN0ZXItaWQucmVnaW9uLm5lcHR1bmUuYW1hem9uYXdzLmNvbTo4MTgyIiwiQVdTX1BST0ZJTEUiOiJ5b3VyLWF3cy1wcm9maWxlIiwiQVdTX1JFR0lPTiI6InVzLWVhc3QtMSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Amazon%20Neptune%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.amazon-neptune-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22NEPTUNE_ENDPOINT%22%3A%22https%3A%2F%2Fyour-neptune-cluster-id.region.neptune.amazonaws.com%3A8182%22%2C%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Keyspaces MCP Server](src/amazon-keyspaces-mcp-server) | Apache Cassandra-compatible operations | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.amazon-keyspaces-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYW1hem9uLWtleXNwYWNlcy1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUFJPRklMRSI6InlvdXItYXdzLXByb2ZpbGUiLCJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIiwiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Amazon%20Keyspaces%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.amazon-keyspaces-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Timestream for InfluxDB MCP Server](src/timestream-for-influxdb-mcp-server) | Time-series database operations and InfluxDB compatibility | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.timestream-for-influxdb-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMudGltZXN0cmVhbS1mb3ItaW5mbHV4ZGItbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJ5b3VyLWF3cy1wcm9maWxlIiwiQVdTX1JFR0lPTiI6InVzLWVhc3QtMSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Timestream%20for%20InfluxDB%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.timestream-for-influxdb-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon MSK MCP Server](src/aws-msk-mcp-server) | Managed Kafka cluster operations and streaming | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-msk-mcp-server&config=JTdCJTIyY29tbWFuZCUyMiUzQSUyMnV2eCUyMGF3c2xhYnMuYXdzLW1zay1tY3Atc2VydmVyJTQwbGF0ZXN0JTIwLS1hbGxvdy13cml0ZXMlMjIlMkMlMjJlbnYlMjIlM0ElN0IlMjJGQVNUTUNQX0xPR19MRVZFTCUyMiUzQSUyMkVSUk9SJTIyJTdEJTJDJTIyZGlzYWJsZWQlMjIlM0FmYWxzZSUyQyUyMmF1dG9BcHByb3ZlJTIyJTNBJTVCJTVEJTdE) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20MSK%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-msk-mcp-server%40latest%22%2C%22--allow-writes%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS S3 Tables MCP Server](src/s3-tables-mcp-server) | Manage S3 Tables for optimized analytics | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.s3-tables-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuczMtdGFibGVzLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEifX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=S3%20Tables%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.s3-tables-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%7D%7D) |\n| [Amazon Redshift MCP Server](src/redshift-mcp-server) | Data warehouse operations and analytics queries | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.redshift-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMucmVkc2hpZnQtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJkZWZhdWx0IiwiQVdTX1JFR0lPTiI6InVzLWVhc3QtMSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiSU5GTyJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Redshift%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.redshift-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22default%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22INFO%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS IoT SiteWise MCP Server](src/aws-iot-sitewise-mcp-server) | Industrial IoT asset management, data ingestion, and analytics | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-iot-sitewise-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWlvdC1zaXRld2lzZS1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUFJPRklMRSI6InlvdXItYXdzLXByb2ZpbGUiLCJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIiwiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20IoT%20SiteWise%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-iot-sitewise-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n##### Search & Analytics\n\n- **[Amazon OpenSearch MCP Server](https://github.com/opensearch-project/opensearch-mcp-server-py)** - OpenSearch powered search, Analytics, and Observability\n\n#### Backend API Providers\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [AWS AppSync MCP Server](src/aws-appsync-mcp-server) | Manage and Interact with application backends powered by AWS AppSync | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-appsync-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWFwcHN5bmMtbWNwLXNlcnZlckBsYXRlc3QgLS1hbGxvdy13cml0ZSIsImVudiI6eyJBV1NfUFJPRklMRSI6ImRlZmF1bHQiLCJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIiwiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0=) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20AppSync%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-appsync-mcp-server%40latest%22%2C%20%22--allow-write%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22default%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n#### Caching & Performance\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [Amazon ElastiCache MCP Server](src/elasticache-mcp-server) | Complete ElastiCache control plane operations | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.elasticache-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuZWxhc3RpY2FjaGUtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJkZWZhdWx0IiwiQVdTX1JFR0lPTiI6InVzLXdlc3QtMiIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=ElastiCache%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.elasticache-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22default%22%2C%22AWS_REGION%22%3A%22us-west-2%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon ElastiCache / MemoryDB for Valkey MCP Server](src/valkey-mcp-server) | Advanced data structures and caching with Valkey | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.valkey-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMudmFsa2V5LW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IlZBTEtFWV9IT1NUIjoiMTI3LjAuMC4xIiwiVkFMS0VZX1BPUlQiOiI2Mzc5IiwiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJhdXRvQXBwcm92ZSI6W10sImRpc2FibGVkIjpmYWxzZX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Valkey%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.valkey-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22VALKEY_HOST%22%3A%22127.0.0.1%22%2C%22VALKEY_PORT%22%3A%226379%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22autoApprove%22%3A%5B%5D%2C%22disabled%22%3Afalse%7D) |\n| [Amazon ElastiCache for Memcached MCP Server](src/memcached-mcp-server) | High-speed caching with Memcached protocol | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.memcached-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMubWVtY2FjaGVkLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IiLCJNRU1DQUNIRURfSE9TVCI6InlvdXItbWVtY2FjaGVkLWhvc3QiLCJNRU1DQUNIRURfUE9SVCI6IjExMjExIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Memcached%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.memcached-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%2C%22MEMCACHED_HOST%22%3A%22your-memcached-host%22%2C%22MEMCACHED_PORT%22%3A%2211211%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n\n### 🛠️ Developer Tools & Support\nAccelerate development with code analysis, documentation, and testing utilities.\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [AWS IAM MCP Server](src/iam-mcp-server) | Comprehensive IAM user, role, group, and policy management with security best practices | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.iam-mcp-server&config=eyJjb21tYW5kIjoidXZ4IiwiYXJncyI6WyJhd3NsYWJzLmlhbS1tY3Atc2VydmVyQGxhdGVzdCJdLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJ5b3VyLWF3cy1wcm9maWxlIiwiQVdTX1JFR0lPTiI6InVzLWVhc3QtMSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20IAM%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.iam-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%7D) |\n| [Git Repo Research MCP Server](src/git-repo-research-mcp-server) | Semantic code search and repository analysis | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.git-repo-research-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuZ2l0LXJlcG8tcmVzZWFyY2gtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJ5b3VyLXByb2ZpbGUtbmFtZSIsIkFXU19SRUdJT04iOiJ1cy13ZXN0LTIiLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIiwiR0lUSFVCX1RPS0VOIjoieW91ci1naXRodWItdG9rZW4ifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Git%20Repo%20Research%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.git-repo-research-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-profile-name%22%2C%22AWS_REGION%22%3A%22us-west-2%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%2C%22GITHUB_TOKEN%22%3A%22your-github-token%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Code Documentation Generator MCP Server](src/code-doc-gen-mcp-server) | Automated documentation from code analysis | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.code-doc-gen-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuY29kZS1kb2MtZ2VuLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Code%20Documentation%20Generator%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.code-doc-gen-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS Diagram MCP Server](src/aws-diagram-mcp-server) | Generate architecture diagrams and technical illustrations | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-diagram-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWRpYWdyYW0tbWNwLXNlcnZlciIsImVudiI6eyJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImF1dG9BcHByb3ZlIjpbXSwiZGlzYWJsZWQiOmZhbHNlfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Diagram%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-diagram-mcp-server%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22autoApprove%22%3A%5B%5D%2C%22disabled%22%3Afalse%7D) |\n| [Frontend MCP Server](src/frontend-mcp-server) | React and modern web development guidance | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.frontend-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuZnJvbnRlbmQtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Frontend%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.frontend-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Synthetic Data MCP Server](src/syntheticdata-mcp-server) | Generate realistic test data for development and ML | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.syntheticdata-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuc3ludGhldGljZGF0YS1tY3Atc2VydmVyIiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IiLCJBV1NfUFJPRklMRSI6InlvdXItYXdzLXByb2ZpbGUiLCJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIn0sImF1dG9BcHByb3ZlIjpbXSwiZGlzYWJsZWQiOmZhbHNlfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Synthetic%20Data%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.syntheticdata-mcp-server%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%2C%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%7D%2C%22autoApprove%22%3A%5B%5D%2C%22disabled%22%3Afalse%7D) |\n| [OpenAPI MCP Server](src/openapi-mcp-server) | Dynamic API integration through OpenAPI specifications | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.openapi-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMub3BlbmFwaS1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBUElfTkFNRSI6InlvdXItYXBpLW5hbWUiLCJBUElfQkFTRV9VUkwiOiJodHRwczovL2FwaS5leGFtcGxlLmNvbSIsIkFQSV9TUEVDX1VSTCI6Imh0dHBzOi8vYXBpLmV4YW1wbGUuY29tL29wZW5hcGkuanNvbiIsIkxPR19MRVZFTCI6IkVSUk9SIiwiRU5BQkxFX1BST01FVEhFVVMiOiJmYWxzZSIsIkVOQUJMRV9PUEVSQVRJT05fUFJPTVBUUyI6InRydWUiLCJVVklDT1JOX1RJTUVPVVRfR1JBQ0VGVUxfU0hVVERPV04iOiI1LjAiLCJVVklDT1JOX0dSQUNFRlVMX1NIVVRET1dOIjoidHJ1ZSJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=OpenAPI%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.openapi-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22API_NAME%22%3A%22your-api-name%22%2C%22API_BASE_URL%22%3A%22https%3A%2F%2Fapi.example.com%22%2C%22API_SPEC_URL%22%3A%22https%3A%2F%2Fapi.example.com%2Fopenapi.json%22%2C%22LOG_LEVEL%22%3A%22ERROR%22%2C%22ENABLE_PROMETHEUS%22%3A%22false%22%2C%22ENABLE_OPERATION_PROMPTS%22%3A%22true%22%2C%22UVICORN_TIMEOUT_GRACEFUL_SHUTDOWN%22%3A%225.0%22%2C%22UVICORN_GRACEFUL_SHUTDOWN%22%3A%22true%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n\n### 📡 Integration & Messaging\n\nConnect systems with messaging, workflows, and location services.\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [Amazon SNS / SQS MCP Server](src/amazon-sns-sqs-mcp-server) | Event-driven messaging and queue management | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.amazon-sns-sqs-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYW1hem9uLXNucy1zcXMtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJ5b3VyLWF3cy1wcm9maWxlIiwiQVdTX1JFR0lPTiI6InVzLWVhc3QtMSJ9fQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Amazon%20SNS%2FSQS%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.amazon-sns-sqs-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%7D%7D) |\n| [Amazon MQ MCP Server](src/amazon-mq-mcp-server) | Message broker management for RabbitMQ and ActiveMQ | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.amazon-mq-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYW1hem9uLW1xLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Amazon%20MQ%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.amazon-mq-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS MSK MCP Server](src/aws-msk-mcp-server) | Managed Kafka cluster operations and streaming | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-msk-mcp-server&config=JTdCJTIyY29tbWFuZCUyMiUzQSUyMnV2eCUyMGF3c2xhYnMuYXdzLW1zay1tY3Atc2VydmVyJTQwbGF0ZXN0JTIwLS1hbGxvdy13cml0ZXMlMjIlMkMlMjJlbnYlMjIlM0ElN0IlMjJGQVNUTUNQX0xPR19MRVZFTCUyMiUzQSUyMkVSUk9SJTIyJTdEJTJDJTIyZGlzYWJsZWQlMjIlM0FmYWxzZSUyQyUyMmF1dG9BcHByb3ZlJTIyJTNBJTVCJTVEJTdE) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20MSK%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-msk-mcp-server%40latest%22%2C%22--allow-writes%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS Step Functions Tool MCP Server](src/stepfunctions-tool-mcp-server) | Execute complex workflows and business processes | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.stepfunctions-tool-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuc3RlcGZ1bmN0aW9ucy10b29sLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJTVEFURV9NQUNISU5FX1BSRUZJWCI6InlvdXItc3RhdGUtbWFjaGluZS1wcmVmaXgiLCJTVEFURV9NQUNISU5FX0xJU1QiOiJ5b3VyLWZpcnN0LXN0YXRlLW1hY2hpbmUsIHlvdXItc2Vjb25kLXN0YXRlLW1hY2hpbmUiLCJTVEFURV9NQUNISU5FX1RBR19LRVkiOiJ5b3VyLXRhZy1rZXkiLCJTVEFURV9NQUNISU5FX1RBR19WQUxVRSI6InlvdXItdGFnLXZhbHVlIiwiU1RBVEVfTUFDSElORV9JTlBVVF9TQ0hFTUFfQVJOX1RBR19LRVkiOiJ5b3VyLXN0YXRlLW1hY2hpbmUtdGFnLWZvci1pbnB1dC1zY2hlbWEifX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Step%20Functions%20Tool%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.stepfunctions-tool-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22STATE_MACHINE_PREFIX%22%3A%22your-state-machine-prefix%22%2C%22STATE_MACHINE_LIST%22%3A%22your-first-state-machine%2C%20your-second-state-machine%22%2C%22STATE_MACHINE_TAG_KEY%22%3A%22your-tag-key%22%2C%22STATE_MACHINE_TAG_VALUE%22%3A%22your-tag-value%22%2C%22STATE_MACHINE_INPUT_SCHEMA_ARN_TAG_KEY%22%3A%22your-state-machine-tag-for-input-schema%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Location Service MCP Server](src/aws-location-mcp-server) | Place search, geocoding, and route optimization | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-location-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWxvY2F0aW9uLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Location%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-location-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [OpenAPI MCP Server](src/openapi-mcp-server) | Dynamic API integration through OpenAPI specifications | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.openapi-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMub3BlbmFwaS1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBUElfTkFNRSI6InlvdXItYXBpLW5hbWUiLCJBUElfQkFTRV9VUkwiOiJodHRwczovL2FwaS5leGFtcGxlLmNvbSIsIkFQSV9TUEVDX1VSTCI6Imh0dHBzOi8vYXBpLmV4YW1wbGUuY29tL29wZW5hcGkuanNvbiIsIkxPR19MRVZFTCI6IkVSUk9SIiwiRU5BQkxFX1BST01FVEhFVVMiOiJmYWxzZSIsIkVOQUJMRV9PUEVSQVRJT05fUFJPTVBUUyI6InRydWUiLCJVVklDT1JOX1RJTUVPVVRfR1JBQ0VGVUxfU0hVVERPV04iOiI1LjAiLCJVVklDT1JOX0dSQUNFRlVMX1NIVVRET1dOIjoidHJ1ZSJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=OpenAPI%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.openapi-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22API_NAME%22%3A%22your-api-name%22%2C%22API_BASE_URL%22%3A%22https%3A%2F%2Fapi.example.com%22%2C%22API_SPEC_URL%22%3A%22https%3A%2F%2Fapi.example.com%2Fopenapi.json%22%2C%22LOG_LEVEL%22%3A%22ERROR%22%2C%22ENABLE_PROMETHEUS%22%3A%22false%22%2C%22ENABLE_OPERATION_PROMPTS%22%3A%22true%22%2C%22UVICORN_TIMEOUT_GRACEFUL_SHUTDOWN%22%3A%225.0%22%2C%22UVICORN_GRACEFUL_SHUTDOWN%22%3A%22true%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n### 💰 Cost & Operations\n\nMonitor, optimize, and manage your AWS infrastructure and costs.\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [AWS Pricing MCP Server](src/aws-pricing-mcp-server) | AWS service pricing and cost estimates | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-pricing-mcp-server&config=ewogICAgImNvbW1hbmQiOiAidXZ4IGF3c2xhYnMuYXdzLXByaWNpbmctbWNwLXNlcnZlckBsYXRlc3QiLAogICAgImVudiI6IHsKICAgICAgIkZBU1RNQ1BfTE9HX0xFVkVMIjogIkVSUk9SIiwKICAgICAgIkFXU19QUk9GSUxFIjogInlvdXItYXdzLXByb2ZpbGUiLAogICAgICAiQVdTX1JFR0lPTiI6ICJ1cy1lYXN0LTEiCiAgICB9LAogICAgImRpc2FibGVkIjogZmFsc2UsCiAgICAiYXV0b0FwcHJvdmUiOiBbXQogIH0K) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Pricing%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-pricing-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%2C%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS Cost Explorer MCP Server](src/cost-explorer-mcp-server) | Detailed cost analysis and reporting | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.cost-explorer-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuY29zdC1leHBsb3Jlci1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUFJPRklMRSI6InlvdXItYXdzLXByb2ZpbGUiLCJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIiwiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Cost%20Explorer%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.cost-explorer-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon CloudWatch MCP Server](src/cloudwatch-mcp-server) | Metrics, Alarms, and Logs analysis and operational troubleshooting | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.cloudwatch-mcp-server&config=ewogICAgImF1dG9BcHByb3ZlIjogW10sCiAgICAiZGlzYWJsZWQiOiBmYWxzZSwKICAgICJjb21tYW5kIjogInV2eCBhd3NsYWJzLmNsb3Vkd2F0Y2gtbWNwLXNlcnZlckBsYXRlc3QiLAogICAgImVudiI6IHsKICAgICAgIkFXU19QUk9GSUxFIjogIltUaGUgQVdTIFByb2ZpbGUgTmFtZSB0byB1c2UgZm9yIEFXUyBhY2Nlc3NdIiwKICAgICAgIkZBU1RNQ1BfTE9HX0xFVkVMIjogIkVSUk9SIgogICAgfSwKICAgICJ0cmFuc3BvcnRUeXBlIjogInN0ZGlvIgp9) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=CloudWatch%20MCP%20Server&config=%7B%22autoApprove%22%3A%5B%5D%2C%22disabled%22%3Afalse%2C%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.cloudwatch-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22%5BThe%20AWS%20Profile%20Name%20to%20use%20for%20AWS%20access%5D%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22transportType%22%3A%22stdio%22%7D) |\n| [Amazon CloudWatch Logs MCP Server (deprecated)](src/cloudwatch-logs-mcp-server) | CloudWatch Logs analysis and monitoring | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.cloudwatch-logs-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuY2xvdWR3YXRjaC1sb2dzLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Amazon%20CloudWatch%20Logs%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.cloudwatch-logs-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS Managed Prometheus MCP Server](src/prometheus-mcp-server) | Prometheus-compatible operations | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.prometheus-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMucHJvbWV0aGV1cy1tY3Atc2VydmVyQGxhdGVzdCAtLXVybCBodHRwczovL2Fwcy13b3Jrc3BhY2VzLnVzLWVhc3QtMS5hbWF6b25hd3MuY29tL3dvcmtzcGFjZXMvd3MtPFdvcmtzcGFjZSBJRD4gLS1yZWdpb24gPFlvdXIgQVdTIFJlZ2lvbj4gLS1wcm9maWxlIDxZb3VyIENMSSBQcm9maWxlIFtkZWZhdWx0XSBpZiBubyBwcm9maWxlIGlzIHVzZWQ%2BIiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0xFVkVMIjoiREVCVUciLCJBV1NfUFJPRklMRSI6IjxZb3VyIENMSSBQcm9maWxlIFtkZWZhdWx0XSBpZiBubyBwcm9maWxlIGlzIHVzZWQ%2BIn19) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Prometheus%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.prometheus-mcp-server%40latest%22%2C%22--url%22%2C%22https%3A%2F%2Faps-workspaces.us-east-1.amazonaws.com%2Fworkspaces%2Fws-%3CWorkspace%20ID%3E%22%2C%22--region%22%2C%22%3CYour%20AWS%20Region%3E%22%2C%22--profile%22%2C%22%3CYour%20CLI%20Profile%20%5Bdefault%5D%20if%20no%20profile%20is%20used%3E%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22DEBUG%22%2C%22AWS_PROFILE%22%3A%22%3CYour%20CLI%20Profile%20%5Bdefault%5D%20if%20no%20profile%20is%20used%3E%22%7D%7D) |\n| [AWS Billing and Cost Management MCP Server](src/billing-cost-management-mcp-server/) | Billing and cost management | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.billing-cost-management-mcp-server&config=ewogICAgImNvbW1hbmQiOiAidXZ4IGF3c2xhYnMuYmlsbGluZy1jb3N0LW1hbmFnZW1lbnQtbWNwLXNlcnZlckBsYXRlc3QiLAogICAgImVudiI6IHsKICAgICAgIkZBU1RNQ1BfTE9HX0xFVkVMIjogIkVSUk9SIiwKICAgICAgIkFXU19QUk9GSUxFIjogInlvdXItYXdzLXByb2ZpbGUiLAogICAgICAiQVdTX1JFR0lPTiI6ICJ1cy1lYXN0LTEiCiAgICB9LAogICAgImRpc2FibGVkIjogZmFsc2UsCiAgICAiYXV0b0FwcHJvdmUiOiBbXQogIH0K) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Billing%20and%20Cost%20Management%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.billing-cost-management-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%2C%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n### 🧬 Healthcare & Lifesciences\nInteract with AWS HealthAI services.\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [AWS HealthOmics MCP Server](src/aws-healthomics-mcp-server) | Generate, run, debug and optimize lifescience workflows | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-healthomics-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWhlYWx0aG9taWNzLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJBV1NfUFJPRklMRSI6InlvdXItcHJvZmlsZSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiV0FSTklORyJ9fQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20HealthOmics%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-healthomics-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_REGION%22%3A%22us-east-1%22%2C%22AWS_PROFILE%22%3A%22your-profile%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22WARNING%22%7D%7D) |\n| [AWS HealthLake MCP Server](src/healthlake-mcp-server) | Create, manage, search, and optimize FHIR healthcare data workflows with comprehensive AWS HealthLake integration, featuring automated resource discovery, advanced search capabilities, patient record management, and seamless import/export operations. | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.healthlake-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuaGVhbHRobGFrZS1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIiwiQVdTX1BST0ZJTEUiOiJ5b3VyLXByb2ZpbGUiLCJGQVNUTUNQX0xPR19MRVZFTCI6IldBUk5JTkcifX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=HealthLake%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.healthlake-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_REGION%22%3A%22us-east-1%22%2C%22AWS_PROFILE%22%3A%22your-profile%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22WARNING%22%7D%7D) |\n\n---\n---\n\n### Browse by How You're Working\n\n#### 👨‍💻 Vibe Coding & Development\n\n*AI coding assistants like Amazon Q Developer CLI, Cline, Cursor, and Claude Code helping you build faster*\n\n##### Core Development Workflow\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [AWS API MCP Server](src/aws-api-mcp-server) | Start here for general AWS interactions! Comprehensive AWS API support with command validation, security controls, and access to all AWS services. Perfect for managing infrastructure, exploring resources, and executing AWS operations through natural language. | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-api-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWFwaS1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D)<br/>[![Install VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20API%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-api-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_REGION%22%3A%22us-east-1%22%7D%2C%22type%22%3A%22stdio%22%7D) |\n| [Core MCP Server](src/core-mcp-server) | Start here: intelligent planning and MCP server orchestration | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.core-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuY29yZS1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImF1dG9BcHByb3ZlIjpbXSwiZGlzYWJsZWQiOmZhbHNlfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Core%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.core-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22autoApprove%22%3A%5B%5D%2C%22disabled%22%3Afalse%7D) |\n| [AWS Knowledge MCP Server](src/aws-knowledge-mcp-server) | A remote, fully-managed MCP server hosted by AWS that provides access to the latest AWS docs, API references, What's New Posts, Getting Started information, Builder Center, Blog posts, Architectural references, and Well-Architected guidance. | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-knowledge-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWtub3dsZWRnZS1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUFJPRklMRSI6InlvdXItYXdzLXByb2ZpbGUiLCJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIiwiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D)<br/>[![Install VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Knowledge%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-knowledge-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS Documentation MCP Server](src/aws-documentation-mcp-server) | Get latest AWS docs and API references | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-documentation-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWRvY3VtZW50YXRpb24tbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiIsIkFXU19ET0NVTUVOVEFUSU9OX1BBUlRJVElPTiI6ImF3cyJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Documentation%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-documentation-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%2C%22AWS_DOCUMENTATION_PARTITION%22%3A%22aws%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Git Repo Research MCP Server](src/git-repo-research-mcp-server) | Semantic search through codebases and repositories | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.git-repo-research-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuZ2l0LXJlcG8tcmVzZWFyY2gtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJ5b3VyLXByb2ZpbGUtbmFtZSIsIkFXU19SRUdJT04iOiJ1cy13ZXN0LTIiLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIiwiR0lUSFVCX1RPS0VOIjoieW91ci1naXRodWItdG9rZW4ifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Git%20Repo%20Research%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.git-repo-research-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-profile-name%22%2C%22AWS_REGION%22%3A%22us-west-2%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%2C%22GITHUB_TOKEN%22%3A%22your-github-token%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n##### Infrastructure as Code\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [AWS CDK MCP Server](src/cdk-mcp-server) | CDK development with security best practices and compliance | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.cdk-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuY2RrLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=CDK%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.cdk-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS Terraform MCP Server](src/terraform-mcp-server) | Terraform with integrated security scanning and best practices | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.terraform-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMudGVycmFmb3JtLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Terraform%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.terraform-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS CloudFormation MCP Server](src/cfn-mcp-server) | Direct AWS resource management through Cloud Control API | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.cfn-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuY2ZuLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1uYW1lZC1wcm9maWxlIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=CloudFormation%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.cfn-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-named-profile%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS Cloud Control API MCP Server](src/ccapi-mcp-server) | Direct AWS resource management with security scanning and best practices | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.ccapi-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuY2NhcGktbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJ5b3VyLWF3cy1wcm9maWxlIiwiQVdTX1JFR0lPTiI6InVzLWVhc3QtMSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Cloud%20Control%20API%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.ccapi-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n##### Application Development\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [Frontend MCP Server](src/frontend-mcp-server) | React and modern web development patterns with AWS integration | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.frontend-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuZnJvbnRlbmQtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Frontend%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.frontend-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS Diagram MCP Server](src/aws-diagram-mcp-server) | Generate architecture diagrams as you design | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-diagram-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWRpYWdyYW0tbWNwLXNlcnZlciIsImVudiI6eyJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImF1dG9BcHByb3ZlIjpbXSwiZGlzYWJsZWQiOmZhbHNlfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Diagram%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-diagram-mcp-server%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22autoApprove%22%3A%5B%5D%2C%22disabled%22%3Afalse%7D) |\n| [Code Documentation Generation MCP Server](src/code-doc-gen-mcp-server) | Auto-generate docs from your codebase | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.code-doc-gen-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuY29kZS1kb2MtZ2VuLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Code%20Documentation%20Generator%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.code-doc-gen-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [OpenAPI MCP Server](src/openapi-mcp-server) | Dynamic API integration through OpenAPI specifications | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.openapi-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMub3BlbmFwaS1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBUElfTkFNRSI6InlvdXItYXBpLW5hbWUiLCJBUElfQkFTRV9VUkwiOiJodHRwczovL2FwaS5leGFtcGxlLmNvbSIsIkFQSV9TUEVDX1VSTCI6Imh0dHBzOi8vYXBpLmV4YW1wbGUuY29tL29wZW5hcGkuanNvbiIsIkxPR19MRVZFTCI6IkVSUk9SIiwiRU5BQkxFX1BST01FVEhFVVMiOiJmYWxzZSIsIkVOQUJMRV9PUEVSQVRJT05fUFJPTVBUUyI6InRydWUiLCJVVklDT1JOX1RJTUVPVVRfR1JBQ0VGVUxfU0hVVERPV04iOiI1LjAiLCJVVklDT1JOX0dSQUNFRlVMX1NIVVRET1dOIjoidHJ1ZSJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=OpenAPI%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.openapi-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22API_NAME%22%3A%22your-api-name%22%2C%22API_BASE_URL%22%3A%22https%3A%2F%2Fapi.example.com%22%2C%22API_SPEC_URL%22%3A%22https%3A%2F%2Fapi.example.com%2Fopenapi.json%22%2C%22LOG_LEVEL%22%3A%22ERROR%22%2C%22ENABLE_PROMETHEUS%22%3A%22false%22%2C%22ENABLE_OPERATION_PROMPTS%22%3A%22true%22%2C%22UVICORN_TIMEOUT_GRACEFUL_SHUTDOWN%22%3A%225.0%22%2C%22UVICORN_GRACEFUL_SHUTDOWN%22%3A%22true%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n##### Container & Serverless Development\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [Amazon EKS MCP Server](src/eks-mcp-server) | Kubernetes cluster management and app deployment | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.eks-mcp-server&config=eyJhdXRvQXBwcm92ZSI6W10sImRpc2FibGVkIjpmYWxzZSwiY29tbWFuZCI6InV2eCBhd3NsYWJzLmVrcy1tY3Atc2VydmVyQGxhdGVzdCAtLWFsbG93LXdyaXRlIC0tYWxsb3ctc2Vuc2l0aXZlLWRhdGEtYWNjZXNzIiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwidHJhbnNwb3J0VHlwZSI6InN0ZGlvIn0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=EKS%20MCP%20Server&config=%7B%22autoApprove%22%3A%5B%5D%2C%22disabled%22%3Afalse%2C%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.eks-mcp-server%40latest%22%2C%22--allow-write%22%2C%22--allow-sensitive-data-access%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22transportType%22%3A%22stdio%22%7D) |\n| [Amazon ECS MCP Server](src/ecs-mcp-server) | Containerize and deploy applications to ECS | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.ecs-mcp-server&config=eyJjb21tYW5kIjoidXZ4IC0tZnJvbSBhd3NsYWJzLWVjcy1tY3Atc2VydmVyIGVjcy1tY3Atc2VydmVyIiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ5b3VyLWF3cy1yZWdpb24iLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIiwiRkFTVE1DUF9MT0dfRklMRSI6Ii9wYXRoL3RvL2Vjcy1tY3Atc2VydmVyLmxvZyIsIkFMTE9XX1dSSVRFIjoiZmFsc2UiLCJBTExPV19TRU5TSVRJVkVfREFUQSI6ImZhbHNlIn19) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=ECS%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22--from%22%2C%22awslabs-ecs-mcp-server%22%2C%22ecs-mcp-server%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22your-aws-region%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%2C%22FASTMCP_LOG_FILE%22%3A%22%2Fpath%2Fto%2Fecs-mcp-server.log%22%2C%22ALLOW_WRITE%22%3A%22false%22%2C%22ALLOW_SENSITIVE_DATA%22%3A%22false%22%7D%7D) |\n| [Finch MCP Server](src/finch-mcp-server) | Local container building with ECR push | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.finch-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuZmluY2gtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJkZWZhdWx0IiwiQVdTX1JFR0lPTiI6InVzLXdlc3QtMiIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiSU5GTyJ9LCJ0cmFuc3BvcnRUeXBlIjoic3RkaW8iLCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Finch%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.finch-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22default%22%2C%22AWS_REGION%22%3A%22us-west-2%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22INFO%22%7D%2C%22transportType%22%3A%22stdio%22%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS Serverless MCP Server](src/aws-serverless-mcp-server) | Full serverless app lifecycle with SAM CLI | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-serverless-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLXNlcnZlcmxlc3MtbWNwLXNlcnZlckBsYXRlc3QgLS1hbGxvdy13cml0ZSAtLWFsbG93LXNlbnNpdGl2ZS1kYXRhLWFjY2VzcyIsImVudiI6eyJBV1NfUFJPRklMRSI6InlvdXItYXdzLXByb2ZpbGUiLCJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Serverless%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-serverless-mcp-server%40latest%22%2C%22--allow-write%22%2C%22--allow-sensitive-data-access%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n\n##### Testing & Data\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [Synthetic Data MCP Server](src/syntheticdata-mcp-server) | Generate realistic test data for development and ML | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.syntheticdata-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuc3ludGhldGljZGF0YS1tY3Atc2VydmVyIiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IiLCJBV1NfUFJPRklMRSI6InlvdXItYXdzLXByb2ZpbGUiLCJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIn0sImF1dG9BcHByb3ZlIjpbXSwiZGlzYWJsZWQiOmZhbHNlfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Synthetic%20Data%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.syntheticdata-mcp-server%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%2C%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%7D%2C%22autoApprove%22%3A%5B%5D%2C%22disabled%22%3Afalse%7D) |\n\n##### Lifesciences Workflow Development\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [AWS HealthOmics MCP Server](src/aws-healthomics-mcp-server) | Generate, run, debug and optimize lifescience workflows | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-healthomics-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWhlYWx0aG9taWNzLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJBV1NfUFJPRklMRSI6InlvdXItcHJvZmlsZSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiV0FSTklORyJ9fQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20HealthOmics%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-healthomics-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_REGION%22%3A%22us-east-1%22%2C%22AWS_PROFILE%22%3A%22your-profile%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22WARNING%22%7D%7D) |\n\n##### Healthcare Data Management\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [AWS HealthLake MCP Server](src/healthlake-mcp-server) | Create, manage, search, and optimize FHIR healthcare data workflows with comprehensive AWS HealthLake integration, featuring automated resource discovery, advanced search capabilities, patient record management, and seamless import/export operations. | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.healthlake-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuaGVhbHRobGFrZS1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIiwiQVdTX1BST0ZJTEUiOiJ5b3VyLXByb2ZpbGUiLCJGQVNUTUNQX0xPR19MRVZFTCI6IldBUk5JTkcifX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=HealthLake%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.healthlake-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_REGION%22%3A%22us-east-1%22%2C%22AWS_PROFILE%22%3A%22your-profile%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22WARNING%22%7D%7D) |\n\n\n#### 💬 Conversational Assistants\n\n*Customer-facing chatbots, business agents, and interactive Q&A systems*\n\n##### Knowledge & Search\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [Amazon Bedrock Knowledge Bases Retrieval MCP Server](src/bedrock-kb-retrieval-mcp-server) | Query enterprise knowledge bases with citation support | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.bedrock-kb-retrieval-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYmVkcm9jay1rYi1yZXRyaWV2YWwtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJ5b3VyLXByb2ZpbGUtbmFtZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIiwiS0JfSU5DTFVTSU9OX1RBR19LRVkiOiJvcHRpb25hbC10YWcta2V5LXRvLWZpbHRlci1rYnMiLCJCRURST0NLX0tCX1JFUkFOS0lOR19FTkFCTEVEIjoiZmFsc2UifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Bedrock%20KB%20Retrieval%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.bedrock-kb-retrieval-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-profile-name%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%2C%22KB_INCLUSION_TAG_KEY%22%3A%22optional-tag-key-to-filter-kbs%22%2C%22BEDROCK_KB_RERANKING_ENABLED%22%3A%22false%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Kendra Index MCP Server](src/amazon-kendra-index-mcp-server) | Enterprise search and RAG enhancement | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.amazon-kendra-index-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYW1hem9uLWtlbmRyYS1pbmRleC1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIiwiS0VORF9JTkRFWF9JRCI6InlvdXIta2VuZHJhLWluZGV4LWlkIiwiS0VORF9ST0xFX0FSTiI6InlvdXIta2VuZHJhLXJvbGUtYXJuIiwiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Amazon%20Kendra%20Index%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.amazon-kendra-index-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_REGION%22%3A%22us-east-1%22%2C%22KEND_INDEX_ID%22%3A%22your-kendra-index-id%22%2C%22KEND_ROLE_ARN%22%3A%22your-kendra-role-arn%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Q Business MCP Server](src/amazon-qbusiness-anonymous-mcp-server) | AI assistant for your ingested content with anonymous access | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.amazon-qbusiness-anonymous-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYW1hem9uLXFidXNpbmVzcy1hbm9ueW1vdXMtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiUUJVU0lORVNTX0FQUF9JRCI6InlvdXItcWJ1c2luZXNzLWFwcC1pZCIsIlFCVVNJTkVTU19VU0VSX0lEIjoieW91ci11c2VyLWlkIiwiQVdTX1BST0ZJTEUiOiJ5b3VyLWF3cy1wcm9maWxlIiwiQVdTX1JFR0lPTiI6InVzLWVhc3QtMSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Amazon%20Q%20Business%20Anonymous%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.amazon-qbusiness-anonymous-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22QBUSINESS_APP_ID%22%3A%22your-qbusiness-app-id%22%2C%22QBUSINESS_USER_ID%22%3A%22your-user-id%22%2C%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Q Index MCP Server](src/amazon-qindex-mcp-server) | Data accessors to search through enterprise's Q index | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.amazon-qindex-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYW1hem9uLXFpbmRleC1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIiwiUUlOREVYX0lEIjoieW91ci1xaW5kZXgtaWQiLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Amazon%20Q%20Index%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.amazon-qindex-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_REGION%22%3A%22us-east-1%22%2C%22QINDEX_ID%22%3A%22your-qindex-id%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS Documentation MCP Server](src/aws-documentation-mcp-server) | Get latest AWS docs and API references | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-documentation-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWRvY3VtZW50YXRpb24tbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiIsIkFXU19ET0NVTUVOVEFUSU9OX1BBUlRJVElPTiI6ImF3cyJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Documentation%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-documentation-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%2C%22AWS_DOCUMENTATION_PARTITION%22%3A%22aws%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n##### Content Processing & Generation\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [Amazon Nova Canvas MCP Server](src/nova-canvas-mcp-server) | Generate images from text descriptions and color palettes | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.nova-canvas-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMubm92YS1jYW52YXMtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJ5b3VyLWF3cy1wcm9maWxlIiwiQVdTX1JFR0lPTiI6InVzLWVhc3QtMSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Nova%20Canvas%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.nova-canvas-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Rekognition MCP Server (deprecated)](src/amazon-rekognition-mcp-server) | Analyze images using computer vision capabilities | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.amazon-rekognition-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYW1hem9uLXJla29nbml0aW9uLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Amazon%20Rekognition%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.amazon-rekognition-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Bedrock Data Automation MCP Server](src/aws-bedrock-data-automation-mcp-server) | Analyze uploaded documents, images, and media | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=bedrock-data-automation-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWJlZHJvY2stZGF0YS1hdXRvbWF0aW9uLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJBV1NfQlVDS0VUX05BTUUiOiJ5b3VyLXMzLWJ1Y2tldC1uYW1lIiwiQkFTRV9ESVIiOiIvcGF0aC90by9iYXNlL2RpcmVjdG9yeSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Bedrock%20Data%20Automation%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-bedrock-data-automation-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22AWS_BUCKET_NAME%22%3A%22your-s3-bucket-name%22%2C%22BASE_DIR%22%3A%22%2Fpath%2Fto%2Fbase%2Fdirectory%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n##### Business Services\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [Amazon Location Service MCP Server](src/aws-location-mcp-server) | Location search, geocoding, and business hours | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-location-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWxvY2F0aW9uLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Location%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-location-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS Pricing MCP Server](src/aws-pricing-mcp-server) | AWS service pricing and cost estimates | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-pricing-mcp-server&config=ewogICAgImNvbW1hbmQiOiAidXZ4IGF3c2xhYnMuYXdzLXByaWNpbmctbWNwLXNlcnZlckBsYXRlc3QiLAogICAgImVudiI6IHsKICAgICAgIkZBU1RNQ1BfTE9HX0xFVkVMIjogIkVSUk9SIiwKICAgICAgIkFXU19QUk9GSUxFIjogInlvdXItYXdzLXByb2ZpbGUiLAogICAgICAiQVdTX1JFR0lPTiI6ICJ1cy1lYXN0LTEiCiAgICB9LAogICAgImRpc2FibGVkIjogZmFsc2UsCiAgICAiYXV0b0FwcHJvdmUiOiBbXQogIH0K) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Pricing%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-pricing-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%2C%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS Cost Explorer MCP Server](src/cost-explorer-mcp-server) | Detailed cost analysis and spend reports | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.cost-explorer-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuY29zdC1leHBsb3Jlci1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUFJPRklMRSI6InlvdXItYXdzLXByb2ZpbGUiLCJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIiwiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Cost%20Explorer%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.cost-explorer-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n#### 🤖 Autonomous Background Agents\n\n*Headless automation, ETL pipelines, and operational systems*\n\n##### Data Operations & ETL\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [AWS Data Processing MCP Server](src/aws-dataprocessing-mcp-server) | Comprehensive data processing tools and real-time pipeline visibility across AWS Glue and Amazon EMR-EC2 | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-dataprocessing-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWRhdGFwcm9jZXNzaW5nLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Data%20Processing%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-dataprocessing-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon DynamoDB MCP Server](src/dynamodb-mcp-server) | Complete DynamoDB operations and table management | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.dynamodb-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuZHluYW1vZGItbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiRERCLU1DUC1SRUFET05MWSI6InRydWUiLCJBV1NfUFJPRklMRSI6ImRlZmF1bHQiLCJBV1NfUkVHSU9OIjoidXMtd2VzdC0yIiwiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=DynamoDB%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.dynamodb-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22DDB-MCP-READONLY%22%3A%22true%22%2C%22AWS_PROFILE%22%3A%22default%22%2C%22AWS_REGION%22%3A%22us-west-2%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Aurora PostgreSQL MCP Server](src/postgres-mcp-server) | PostgreSQL database operations via RDS Data API | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.postgres-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMucG9zdGdyZXMtbWNwLXNlcnZlckBsYXRlc3QgLS1jb25uZWN0aW9uLXN0cmluZyBwb3N0Z3Jlc3FsOi8vW3VzZXJuYW1lXTpbcGFzc3dvcmRdQFtob3N0XTpbcG9ydF0vW2RhdGFiYXNlXSIsImVudiI6eyJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdLCJ0cmFuc3BvcnRUeXBlIjoic3RkaW8iLCJhdXRvU3RhcnQiOnRydWV9) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=PostgreSQL%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.postgres-mcp-server%40latest%22%2C%22--connection-string%22%2C%22postgresql%3A%2F%2F%5Busername%5D%3A%5Bpassword%5D%40%5Bhost%5D%3A%5Bport%5D%2F%5Bdatabase%5D%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%2C%22transportType%22%3A%22stdio%22%2C%22autoStart%22%3Atrue%7D) |\n| [Amazon Aurora MySQL MCP Server](src/mysql-mcp-server) | MySQL database operations via RDS Data API | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.mysql-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMubXlzcWwtbWNwLXNlcnZlckBsYXRlc3QgLS1yZXNvdXJjZV9hcm4gW3lvdXIgZGF0YV0gLS1zZWNyZXRfYXJuIFt5b3VyIGRhdGFdIC0tZGF0YWJhc2UgW3lvdXIgZGF0YV0gLS1yZWdpb24gW3lvdXIgZGF0YV0gLS1yZWFkb25seSBUcnVlIiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=MySQL%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.mysql-mcp-server%40latest%22%2C%22--resource_arn%22%2C%22%5Byour%20data%5D%22%2C%22--secret_arn%22%2C%22%5Byour%20data%5D%22%2C%22--database%22%2C%22%5Byour%20data%5D%22%2C%22--region%22%2C%22%5Byour%20data%5D%22%2C%22--readonly%22%2C%22True%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Aurora DSQL MCP Server](src/aurora-dsql-mcp-server) | Distributed SQL with PostgreSQL compatibility | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aurora-dsql-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXVyb3JhLWRzcWwtbWNwLXNlcnZlckBsYXRlc3QgLS1jbHVzdGVyX2VuZHBvaW50IFt5b3VyIGRzcWwgY2x1c3RlciBlbmRwb2ludF0gLS1yZWdpb24gW3lvdXIgZHNxbCBjbHVzdGVyIHJlZ2lvbiwgZS5nLiB1cy1lYXN0LTFdIC0tZGF0YWJhc2VfdXNlciBbeW91ciBkc3FsIHVzZXJuYW1lXSAtLXByb2ZpbGUgZGVmYXVsdCIsImVudiI6eyJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Aurora%20DSQL%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aurora-dsql-mcp-server%40latest%22%2C%22--cluster_endpoint%22%2C%22%5Byour%20dsql%20cluster%20endpoint%5D%22%2C%22--region%22%2C%22%5Byour%20dsql%20cluster%20region%2C%20e.g.%20us-east-1%5D%22%2C%22--database_user%22%2C%22%5Byour%20dsql%20username%5D%22%2C%22--profile%22%2C%22default%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon DocumentDB MCP Server](src/documentdb-mcp-server) | MongoDB-compatible document database operations | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.documentdb-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuZG9jdW1lbnRkYi1tY3Atc2VydmVAbGF0ZXN0IiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IiLCJBV1NfUFJPRklMRSI6InlvdXItYXdzLXByb2ZpbGUifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=DocumentDB%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.documentdb-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%2C%22AWS_PROFILE%22%3A%22your-aws-profile%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Neptune MCP Server](src/amazon-neptune-mcp-server) | Graph database queries with openCypher and Gremlin | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.amazon-neptune-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYW1hem9uLW5lcHR1bmUtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiTkVQVFVORV9FTkRQT0lOVCI6Imh0dHBzOi8veW91ci1uZXB0dW5lLWNsdXN0ZXItaWQucmVnaW9uLm5lcHR1bmUuYW1hem9uYXdzLmNvbTo4MTgyIiwiQVdTX1BST0ZJTEUiOiJ5b3VyLWF3cy1wcm9maWxlIiwiQVdTX1JFR0lPTiI6InVzLWVhc3QtMSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Amazon%20Neptune%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.amazon-neptune-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22NEPTUNE_ENDPOINT%22%3A%22https%3A%2F%2Fyour-neptune-cluster-id.region.neptune.amazonaws.com%3A8182%22%2C%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Keyspaces MCP Server](src/amazon-keyspaces-mcp-server) | Apache Cassandra-compatible operations | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.amazon-keyspaces-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYW1hem9uLWtleXNwYWNlcy1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUFJPRklMRSI6InlvdXItYXdzLXByb2ZpbGUiLCJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIiwiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Amazon%20Keyspaces%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.amazon-keyspaces-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Timestream for InfluxDB MCP Server](src/timestream-for-influxdb-mcp-server) | Time-series database operations and InfluxDB compatibility | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.timestream-for-influxdb-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMudGltZXN0cmVhbS1mb3ItaW5mbHV4ZGItbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJ5b3VyLWF3cy1wcm9maWxlIiwiQVdTX1JFR0lPTiI6InVzLWVhc3QtMSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Timestream%20for%20InfluxDB%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.timestream-for-influxdb-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon MSK MCP Server](src/aws-msk-mcp-server) | Managed Kafka cluster operations and streaming | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-msk-mcp-server&config=JTdCJTIyY29tbWFuZCUyMiUzQSUyMnV2eCUyMGF3c2xhYnMuYXdzLW1zay1tY3Atc2VydmVyJTQwbGF0ZXN0JTIwLS1hbGxvdy13cml0ZXMlMjIlMkMlMjJlbnYlMjIlM0ElN0IlMjJGQVNUTUNQX0xPR19MRVZFTCUyMiUzQSUyMkVSUk9SJTIyJTdEJTJDJTIyZGlzYWJsZWQlMjIlM0FmYWxzZSUyQyUyMmF1dG9BcHByb3ZlJTIyJTNBJTVCJTVEJTdE) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20MSK%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-msk-mcp-server%40latest%22%2C%22--allow-writes%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n##### Caching & Performance\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [Amazon ElastiCache / MemoryDB for Valkey MCP Server](src/valkey-mcp-server) | Advanced data structures and caching with Valkey | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.valkey-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMudmFsa2V5LW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IlZBTEtFWV9IT1NUIjoiMTI3LjAuMC4xIiwiVkFMS0VZX1BPUlQiOiI2Mzc5IiwiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJhdXRvQXBwcm92ZSI6W10sImRpc2FibGVkIjpmYWxzZX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Valkey%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.valkey-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22VALKEY_HOST%22%3A%22127.0.0.1%22%2C%22VALKEY_PORT%22%3A%226379%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22autoApprove%22%3A%5B%5D%2C%22disabled%22%3Afalse%7D) |\n| [Amazon ElastiCache for Memcached MCP Server ](src/memcached-mcp-server) | High-speed caching with Memcached protocol | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.memcached-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMubWVtY2FjaGVkLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IiLCJNRU1DQUNIRURfSE9TVCI6InlvdXItbWVtY2FjaGVkLWhvc3QiLCJNRU1DQUNIRURfUE9SVCI6IjExMjExIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Memcached%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.memcached-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%2C%22MEMCACHED_HOST%22%3A%22your-memcached-host%22%2C%22MEMCACHED_PORT%22%3A%2211211%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n##### Workflow & Integration\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [AWS Lambda Tool MCP Server](src/lambda-tool-mcp-server) | Execute Lambda functions as AI tools for private resource access | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.lambda-tool-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMubGFtYmRhLXRvb2wtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJ5b3VyLWF3cy1wcm9maWxlIiwiQVdTX1JFR0lPTiI6InVzLWVhc3QtMSIsIkZVTkNUSU9OX1BSRUZJWCI6InlvdXItZnVuY3Rpb24tcHJlZml4IiwiRlVOQ1RJT05fTElTVCI6InlvdXItZmlyc3QtZnVuY3Rpb24sIHlvdXItc2Vjb25kLWZ1bmN0aW9uIiwiRlVOQ1RJT05fVEFHX0tFWSI6InlvdXItdGFnLWtleSIsIkZVTkNUSU9OX1RBR19WQUxVRSI6InlvdXItdGFnLXZhbHVlIiwiRlVOQ1RJT05fSU5QVVRfU0NIRU1BX0FSTl9UQUdfS0VZIjoieW91ci1mdW5jdGlvbi10YWctZm9yLWlucHV0LXNjaGVtYSJ9fQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Lambda%20Tool%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.lambda-tool-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FUNCTION_PREFIX%22%3A%22your-function-prefix%22%2C%22FUNCTION_LIST%22%3A%22your-first-function%2C%20your-second-function%22%2C%22FUNCTION_TAG_KEY%22%3A%22your-tag-key%22%2C%22FUNCTION_TAG_VALUE%22%3A%22your-tag-value%22%2C%22FUNCTION_INPUT_SCHEMA_ARN_TAG_KEY%22%3A%22your-function-tag-for-input-schema%22%7D%7D) |\n| [AWS Step Functions Tool MCP Server](src/stepfunctions-tool-mcp-server) | Execute complex workflows and business processes | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.stepfunctions-tool-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuc3RlcGZ1bmN0aW9ucy10b29sLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJTVEFURV9NQUNISU5FX1BSRUZJWCI6InlvdXItc3RhdGUtbWFjaGluZS1wcmVmaXgiLCJTVEFURV9NQUNISU5FX0xJU1QiOiJ5b3VyLWZpcnN0LXN0YXRlLW1hY2hpbmUsIHlvdXItc2Vjb25kLXN0YXRlLW1hY2hpbmUiLCJTVEFURV9NQUNISU5FX1RBR19LRVkiOiJ5b3VyLXRhZy1rZXkiLCJTVEFURV9NQUNISU5FX1RBR19WQUxVRSI6InlvdXItdGFnLXZhbHVlIiwiU1RBVEVfTUFDSElORV9JTlBVVF9TQ0hFTUFfQVJOX1RBR19LRVkiOiJ5b3VyLXN0YXRlLW1hY2hpbmUtdGFnLWZvci1pbnB1dC1zY2hlbWEifX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Step%20Functions%20Tool%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.stepfunctions-tool-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22STATE_MACHINE_PREFIX%22%3A%22your-state-machine-prefix%22%2C%22STATE_MACHINE_LIST%22%3A%22your-first-state-machine%2C%20your-second-state-machine%22%2C%22STATE_MACHINE_TAG_KEY%22%3A%22your-tag-key%22%2C%22STATE_MACHINE_TAG_VALUE%22%3A%22your-tag-value%22%2C%22STATE_MACHINE_INPUT_SCHEMA_ARN_TAG_KEY%22%3A%22your-state-machine-tag-for-input-schema%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon SNS/SQS MCP Server](src/amazon-sns-sqs-mcp-server) | Event-driven messaging and queue management | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.amazon-sns-sqs-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYW1hem9uLXNucy1zcXMtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJ5b3VyLWF3cy1wcm9maWxlIiwiQVdTX1JFR0lPTiI6InVzLWVhc3QtMSJ9fQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Amazon%20SNS%2FSQS%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.amazon-sns-sqs-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%7D%7D) |\n| [Amazon MQ MCP Server](src/amazon-mq-mcp-server) | Message broker management for RabbitMQ and ActiveMQ | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.amazon-mq-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYW1hem9uLW1xLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Amazon%20MQ%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.amazon-mq-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS MSK MCP Server](src/aws-msk-mcp-server) | Managed Kafka cluster operations and streaming | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-msk-mcp-server&config=JTdCJTIyY29tbWFuZCUyMiUzQSUyMnV2eCUyMGF3c2xhYnMuYXdzLW1zay1tY3Atc2VydmVyJTQwbGF0ZXN0JTIwLS1hbGxvdy13cml0ZXMlMjIlMkMlMjJlbnYlMjIlM0ElN0IlMjJGQVNUTUNQX0xPR19MRVZFTCUyMiUzQSUyMkVSUk9SJTIyJTdEJTJDJTIyZGlzYWJsZWQlMjIlM0FmYWxzZSUyQyUyMmF1dG9BcHByb3ZlJTIyJTNBJTVCJTVEJTdE) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20MSK%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-msk-mcp-server%40latest%22%2C%22--allow-writes%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n##### Operations & Monitoring\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [Amazon CloudWatch MCP Server](src/cloudwatch-mcp-server) | Metrics, Alarms, and Logs analysis and operational troubleshooting | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.cloudwatch-mcp-server&config=ewogICAgImF1dG9BcHByb3ZlIjogW10sCiAgICAiZGlzYWJsZWQiOiBmYWxzZSwKICAgICJjb21tYW5kIjogInV2eCBhd3NsYWJzLmNsb3Vkd2F0Y2gtbWNwLXNlcnZlckBsYXRlc3QiLAogICAgImVudiI6IHsKICAgICAgIkFXU19QUk9GSUxFIjogIltUaGUgQVdTIFByb2ZpbGUgTmFtZSB0byB1c2UgZm9yIEFXUyBhY2Nlc3NdIiwKICAgICAgIkZBU1RNQ1BfTE9HX0xFVkVMIjogIkVSUk9SIgogICAgfSwKICAgICJ0cmFuc3BvcnRUeXBlIjogInN0ZGlvIgp9) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=CloudWatch%20MCP%20Server&config=%7B%22autoApprove%22%3A%5B%5D%2C%22disabled%22%3Afalse%2C%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.cloudwatch-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22%5BThe%20AWS%20Profile%20Name%20to%20use%20for%20AWS%20access%5D%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22transportType%22%3A%22stdio%22%7D) |\n| [Amazon CloudWatch Logs MCP Server (deprecated)](src/cloudwatch-logs-mcp-server) | CloudWatch Logs analysis and monitoring | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.cloudwatch-logs-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuY2xvdWR3YXRjaC1sb2dzLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Amazon%20CloudWatch%20Logs%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.cloudwatch-logs-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon CloudWatch Application Signals MCP Server](src/cloudwatch-appsignals-mcp-server) | Application monitoring and performance insights | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.cloudwatch-appsignals-mcp-server&config=eyJhdXRvQXBwcm92ZSI6W10sImRpc2FibGVkIjpmYWxzZSwidGltZW91dCI6NjAsImNvbW1hbmQiOiJ1dnggYXdzbGFicy5jbG91ZHdhdGNoLWFwcHNpZ25hbHMtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJbVGhlIEFXUyBQcm9maWxlIE5hbWUgdG8gdXNlIGZvciBBV1MgYWNjZXNzXSIsIkFXU19SRUdJT04iOiJbVGhlIEFXUyByZWdpb24gdG8gcnVuIGluXSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwidHJhbnNwb3J0VHlwZSI6InN0ZGlvIn0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=CloudWatch%20Application%20Signals%20MCP%20Server&config=%7B%22autoApprove%22%3A%5B%5D%2C%22disabled%22%3Afalse%2C%22timeout%22%3A60%2C%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.cloudwatch-appsignals-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22%5BThe%20AWS%20Profile%20Name%20to%20use%20for%20AWS%20access%5D%22%2C%22AWS_REGION%22%3A%22%5BThe%20AWS%20region%20to%20run%20in%5D%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22transportType%22%3A%22stdio%22%7D) |\n| [AWS Cost Explorer MCP Server](src/cost-explorer-mcp-server) | Detailed cost analysis and reporting | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.cost-explorer-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuY29zdC1leHBsb3Jlci1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUFJPRklMRSI6InlvdXItYXdzLXByb2ZpbGUiLCJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIiwiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Cost%20Explorer%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.cost-explorer-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS Managed Prometheus MCP Server](src/prometheus-mcp-server) | Prometheus-compatible operations and monitoring | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.prometheus-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMucHJvbWV0aGV1cy1tY3Atc2VydmVyQGxhdGVzdCAtLXVybCBodHRwczovL2Fwcy13b3Jrc3BhY2VzLnVzLWVhc3QtMS5hbWF6b25hd3MuY29tL3dvcmtzcGFjZXMvd3MtPFdvcmtzcGFjZSBJRD4gLS1yZWdpb24gPFlvdXIgQVdTIFJlZ2lvbj4gLS1wcm9maWxlIDxZb3VyIENMSSBQcm9maWxlIFtkZWZhdWx0XSBpZiBubyBwcm9maWxlIGlzIHVzZWQ%2BIiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0xFVkVMIjoiREVCVUciLCJBV1NfUFJPRklMRSI6IjxZb3VyIENMSSBQcm9maWxlIFtkZWZhdWx0XSBpZiBubyBwcm9maWxlIGlzIHVzZWQ%2BIn19) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Prometheus%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.prometheus-mcp-server%40latest%22%2C%22--url%22%2C%22https%3A%2F%2Faps-workspaces.us-east-1.amazonaws.com%2Fworkspaces%2Fws-%3CWorkspace%20ID%3E%22%2C%22--region%22%2C%22%3CYour%20AWS%20Region%3E%22%2C%22--profile%22%2C%22%3CYour%20CLI%20Profile%20%5Bdefault%5D%20if%20no%20profile%20is%20used%3E%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22DEBUG%22%2C%22AWS_PROFILE%22%3A%22%3CYour%20CLI%20Profile%20%5Bdefault%5D%20if%20no%20profile%20is%20used%3E%22%7D%7D) |\n| [AWS Well-Architected Security Assessment Tool MCP Server](src/well-architected-security-mcp-server) | Assess AWS environments against the Well-Architected Framework Security Pillar | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.well-architected-security-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMud2VsbC1hcmNoaXRlY3RlZC1zZWN1cml0eS1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUFJPRklMRSI6InlvdXItYXdzLXByb2ZpbGUiLCJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIiwiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0K) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Well-Architected%20Security%20Assessment%20Tool%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.well-architected-security-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS CloudTrail MCP Server](src/cloudtrail-mcp-server/) | CloudTrail events querying and analysis | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://www.cursor.com/install-mcp?name=awslabs.cloudtrail-mcp-server&config=ewogICAgICAgICJjb21tYW5kIjogImRvY2tlciIsCiAgICAgICAgImFyZ3MiOiBbCiAgICAgICAgICAicnVuIiwKICAgICAgICAgICItLXJtIiwKICAgICAgICAgICItLWludGVyYWN0aXZlIiwKICAgICAgICAgICItZSBBV1NfUFJPRklMRT1bVGhlIEFXUyBQcm9maWxlIE5hbWVdIiwKICAgICAgICAgICJhd3NsYWJzL2Nsb3VkdHJhaWwtbWNwLXNlcnZlcjpsYXRlc3QiCiAgICAgICAgXSwKICAgICAgICAiZW52Ijoge30sCiAgICAgICAgImRpc2FibGVkIjogZmFsc2UsCiAgICAgICAgImF1dG9BcHByb3ZlIjogW10KfQ==) <br/>[![Install on VS Code](https://img.shields.io/badge/Install_on-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=CloudTrail%20MCP%20Server&config=%7B%22autoApprove%22%3A%5B%5D%2C%22disabled%22%3Afalse%2C%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.cloudtrail-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22%5BThe%20AWS%20Profile%20Name%20to%20use%20for%20AWS%20access%5D%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22transportType%22%3A%22stdio%22%7D) |\n\n## MCP AWS Lambda Handler Module\n\nA Python library for creating serverless HTTP handlers for the Model Context Protocol (MCP) using AWS Lambda. This module provides a flexible framework for building MCP HTTP endpoints with pluggable session management, including built-in DynamoDB support.\n\n**Features:**\n\n- Easy serverless MCP HTTP handler creation using AWS Lambda\n- Pluggable session management system\n- Built-in DynamoDB session backend support\n- Customizable authentication and authorization\n- Example implementations and tests\n\nSee [`src/mcp-lambda-handler/README.md`](src/mcp-lambda-handler/README.md) for full usage, installation, and development instructions.\n\n## When to use Local vs Remote MCP Servers?\n\nAWS MCP servers can be run either locally on your development machine or remotely on the cloud. Here's when to use each approach:\n\n### Local MCP Servers\n- **Development & Testing**: Perfect for local development, testing, and debugging\n- **Offline Work**: Continue working when internet connectivity is limited\n- **Data Privacy**: Keep sensitive data and credentials on your local machine\n- **Low Latency**: Minimal network overhead for faster response times\n- **Resource Control**: Direct control over server resources and configuration\n\n### Remote MCP Servers\n- **Team Collaboration**: Share consistent server configurations across your team\n- **Resource Intensive Tasks**: Offload heavy processing to dedicated cloud resources\n- **Always Available**: Access your MCP servers from anywhere, any device\n- **Automatic Updates**: Get the latest features and security patches automatically\n- **Scalability**: Easily handle varying workloads without local resource constraints\n\n> **Note**: Some MCP servers, like AWS Knowledge MCP, are provided as fully managed services by AWS. These AWS-managed remote servers require no setup or infrastructure management on your part - just connect and start using them.\n\n## Use Cases for the Servers\n\nFor example, you can use the **AWS Documentation MCP Server** to help your AI assistant research and generate up-to-date code for any AWS service, like Amazon Bedrock Inline agents. Alternatively, you could use the **CDK MCP Server** or the **Terraform MCP Server** to have your AI assistant create infrastructure-as-code implementations that use the latest APIs and follow AWS best practices. With the **AWS Pricing MCP Server**, you could ask \"What would be the estimated monthly cost for this CDK project before I deploy it?\" or \"Can you help me understand the potential AWS service expenses for this infrastructure design?\" and receive detailed cost estimations and budget planning insights. The **Valkey MCP Server** enables natural language interaction with Valkey data stores, allowing AI assistants to efficiently manage data operations through a simple conversational interface.\n\n## Installation and Setup\n\nEach server has specific installation instructions with one-click installs for Cursor and VSCode. Generally, you can:\n\n1. Install `uv` from [Astral](https://docs.astral.sh/uv/getting-started/installation/)\n2. Install Python using `uv python install 3.10`\n3. Configure AWS credentials with access to required services\n4. Add the server to your MCP client configuration\n\nExample configuration for Amazon Q CLI MCP (`~/.aws/amazonq/mcp.json`):\n\n### For macOS/Linux\n\n```json\n{\n  \"mcpServers\": {\n    \"awslabs.core-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"awslabs.core-mcp-server@latest\"\n      ],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      }\n    }\n  }\n}\n```\n\nSee individual server READMEs for specific requirements and configuration options.\n\n### For Windows\n\nWhen configuring MCP servers on Windows, you'll need to use a slightly different configuration format:\n\n```json\n{\n  \"mcpServers\": {\n    \"awslabs.core-mcp-server\": {\n      \"disabled\": false,\n      \"timeout\": 60,\n      \"type\": \"stdio\",\n      \"command\": \"uv\",\n      \"args\": [\n        \"tool\",\n        \"run\",\n        \"--from\",\n        \"awslabs.core-mcp-server@latest\",\n        \"awslabs.core-mcp-server.exe\"\n      ],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      }\n    }\n  }\n}\n```\n\nIf you have problems with MCP configuration or want to check if the appropriate parameters are in place, you can try the following:\n\n```shell\n# Run MCP server manually with timeout 15s\n$ timeout 15s uv tool run <MCP Name> <args> 2>&1 || echo \"Command completed or timed out\"\n\n# Example (Aurora MySQL MCP Server)\n$ timeout 15s uv tool run awslabs.mysql-mcp-server --resource_arn <Your Resource ARN> --secret_arn <Your Secret ARN> ... 2>&1 || echo \"Command completed or timed out\"\n\n# If the arguments are not set appropriately, you may see the following message:\nusage: awslabs.mysql-mcp-server [-h] --resource_arn RESOURCE_ARN --secret_arn SECRET_ARN --database DATABASE\n                                --region REGION --readonly READONLY\nawslabs.mysql-mcp-server: error: the following arguments are required: --resource_arn, --secret_arn, --database, --region, --readonly\n```\n\n**Note about performance when using `uvx` *\"@latest\"* suffix:**\n\nUsing the *\"@latest\"* suffix checks and downloads the latest MCP server package from pypi every time you start your MCP clients, but it comes with a cost of increased initial load times. If you want to minimize the initial load time, remove *\"@latest\"* and manage your uv cache yourself using one of these approaches:\n\n- `uv cache clean <tool>`: where {tool} is the mcp server you want to delete from cache and install again (e.g.: \"awslabs.lambda-tool-mcp-server\") (remember to remove the '<>').\n- `uvx <tool>@latest`: this will refresh the tool with the latest version and add it to the uv cache.\n\n### Running MCP servers in containers\n\nDocker images for each MCP server are published to the [public AWS ECR registry](https://gallery.ecr.aws/awslabs-mcp).\n\n*This example uses docker with the \"awslabs.nova-canvas-mcp-server and can be repeated for each MCP server*\n\n- Optionally save sensitive environmental variables in a file:\n\n  ```.env\n  # contents of a .env file with fictitious AWS temporary credentials\n  AWS_ACCESS_KEY_ID=ASIAIOSFODNN7EXAMPLE\n  AWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\n  AWS_SESSION_TOKEN=AQoEXAMPLEH4aoAH0gNCAPy...truncated...zrkuWJOgQs8IZZaIv2BXIa2R4Olgk\n  ```\n\n- Use the docker options: `--env`, `--env-file`, and `--volume` as needed because the `\"env\": {}` are not available within the container.\n\n  ```json\n  {\n    \"mcpServers\": {\n      \"awslabs.nova-canvas-mcp-server\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"--rm\",\n          \"--interactive\",\n          \"--env\",\n          \"FASTMCP_LOG_LEVEL=ERROR\",\n          \"--env\",\n          \"AWS_REGION=us-east-1\",\n          \"--env-file\",\n          \"/full/path/to/.env\",\n          \"--volume\",\n          \"/full/path/to/.aws:/app/.aws\",\n          \"public.ecr.aws/awslabs-mcp/awslabs/nova-canvas-mcp-server:latest\"\n        ],\n        \"env\": {}\n      }\n    }\n  }\n  ```\n\n- For testing local changes you can build and tag the image. You have to update the MCP configuration to use this tag instead of the ECR image.\n\n  ```base\n  cd src/nova-canvas-mcp-server\n  docker build -t awslabs/nova-canvas-mcp-server .\n  ```\n\n### Getting Started with Amazon Q Developer CLI\n\n<details>\n<summary>Install in Amazon Q Developer CLI</summary>\n\nSee [Amazon Q Developer CLI documentation](https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-mcp-config-CLI.html) for details.\n\n\n1. **Access MCP Settings**\n   - Open the Q Developer panel and open the **Chat** panel.\n   - Choose the tools icon to access to MCP configuration.\n\n2. **Add MCP Servers**\n   - Choose the plus (+) symbol.\n   - Select the scope: global or local.\n    If you select global scope, the MCP server configuration is stored in ~/.aws/amazonq/mcp.json and available across all your projects. If you select local scope, the configuration is stored in .amazonq/mcp.json within your current project.\n   - Fill in values as applicable.\n\n3. **Manual Configuration**\n   - You can also manually edit the MCP configuration file located at `~/.aws/amazonq/mcp.json` globally or `.amazonq/mcp.json` locally.\n\n#### `~/.aws/amazonq/mcp.json`\n\nFor macOS/Linux:\n\n```json\n{\n  \"mcpServers\": {\n    \"awslabs.core-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.core-mcp-server@latest\"],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      }\n    }\n  }\n}\n```\n\nFor Windows:\n\n```json\n{\n  \"mcpServers\": {\n    \"awslabs.core-mcp-server\": {\n      \"disabled\": false,\n      \"timeout\": 60,\n      \"type\": \"stdio\",\n      \"command\": \"uv\",\n      \"args\": [\n        \"tool\",\n        \"run\",\n        \"--from\",\n        \"awslabs.core-mcp-server@latest\",\n        \"awslabs.core-mcp-server.exe\"\n      ],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      }\n    }\n  }\n}\n```\n</details>\n\n\n### Getting Started with Kiro\n\n<details>\n<summary>Install in Kiro</summary>\n\nSee [Kiro Model Context Protocol Documentation](https://kiro.dev/docs/mcp/configuration/) for details.\n\n1. Navigate `Kiro` > `MCP Servers`\n2. Add a new MCP server by clicking the `+ Add` button.\n3. Paste the configuration given below:\n\n#### `kiro_mcp_settings.json`\n\nFor macOS/Linux:\n\n```json\n{\n  \"mcpServers\": {\n    \"awslabs.core-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.core-mcp-server@latest\"],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      }\n    }\n  }\n}\n```\n\nFor Windows:\n\n```json\n{\n  \"mcpServers\": {\n    \"awslabs.core-mcp-server\": {\n      \"disabled\": false,\n      \"timeout\": 60,\n      \"type\": \"stdio\",\n      \"command\": \"uv\",\n      \"args\": [\n        \"tool\",\n        \"run\",\n        \"--from\",\n        \"awslabs.core-mcp-server@latest\",\n        \"awslabs.core-mcp-server.exe\"\n      ],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      }\n    }\n  }\n}\n```\n\n</details>\n\n### Getting Started with Cline and Amazon Bedrock\n\n<details>\n<summary>Getting Started with Cline and Amazon Bedrock</summary>\n\n**IMPORTANT:** Following these instructions may incur costs and are subject to the [Amazon Bedrock Pricing](https://aws.amazon.com/bedrock/pricing/). You are responsible for any associated costs. In addition to selecting the desired model in the Cline settings, ensure you have your selected model (e.g. `anthropic.claude-3-7-sonnet`) also enabled in Amazon Bedrock. For more information on this, see [these AWS docs](https://docs.aws.amazon.com/bedrock/latest/userguide/model-access-modify.html) on enabling model access to Amazon Bedrock Foundation Models (FMs).\n\n1. Follow the steps above in the **Installation and Setup** section to install `uv` from [Astral](https://docs.astral.sh/uv/getting-started/installation/), install Python, and configure AWS credentials with the required services.\n\n2. If using Visual Studio Code, install the [Cline VS Code Extension](https://marketplace.visualstudio.com/items?itemName=saoudrizwan.claude-dev) (or equivalent extension for your preferred IDE). Once installed, click the extension to open it. When prompted, select the tier that you wish. In this case, we will be using Amazon Bedrock, so the free tier of Cline is fine as we will be sending requests using the Amazon Bedrock API instead of the Cline API.\n\n<p align=\"center\">\n  \n<p>\n\n3. Select the **MCP Servers** button.\n\n<p align=\"center\">\n  \n<p>\n\n4. Select the **Installed** tab, then click **Configure MCP Servers** to open the `cline_mcp_settings.json` file.\n\n <p align=\"center\">\n   \n <p>\n\n 5. In the `cline_mcp_settings.json` file, add your desired MCP servers in the `mcpServers` object. See the following example that will use some of the current AWS MCP servers that are available in this repository. Ensure you save the file to install the MCP servers.\n\n#### `cline_mcp_settings.json`\n\nFor macOS/Linux:\n\n ```json\n {\n   \"mcpServers\": {\n     \"awslabs.core-mcp-server\": {\n       \"command\": \"uvx\",\n       \"args\": [\"awslabs.core-mcp-server@latest\"],\n       \"env\": {\n         \"FASTMCP_LOG_LEVEL\": \"ERROR\",\n         \"MCP_SETTINGS_PATH\": \"path to your mcp settings file\"\n       }\n     }\n    }\n  }\n ```\n\nFor Windows:\n\n```json\n{\n  \"mcpServers\": {\n    \"awslabs.core-mcp-server\": {\n      \"disabled\": false,\n      \"timeout\": 60,\n      \"type\": \"stdio\",\n      \"command\": \"uv\",\n      \"args\": [\n        \"tool\",\n        \"run\",\n        \"--from\",\n        \"awslabs.core-mcp-server@latest\",\n        \"awslabs.core-mcp-server.exe\"\n      ],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\",\n        \"MCP_SETTINGS_PATH\": \"path to your mcp settings file\"\n      }\n    }\n  }\n}\n```\n\n6. Once installed, you should see a list of your MCP Servers under the MCP Server Installed tab, and they should have a green slider to show that they are enabled. See the following for an example with two of the possible AWS MCP Servers. Click **Done** when finished. You should now see the Cline chat interface.\n\n<p align=\"center\">\n  \n<p>\n\n<p align=\"center\">\n  \n<p>\n\n7. By default, Cline will be set as the API provider, which has limits for the free tier. Next, let's update the API provider to be AWS Bedrock, so we can use the LLMs through Bedrock, which would have billing go through your connected AWS account.\n\n8. Click the settings gear to open up the Cline settings. Then under **API Provider**, switch this from `Cline` to `AWS Bedrock` and select `AWS Profile` for the authentication type. As a note, the `AWS Credentials` option works as well, however it uses a static credentials (Access Key ID and Secret Access Key) instead of temporary credentials that are automatically redistributed when the token expires, so the temporary credentials with an AWS Profile is the more secure and recommended method.\n\n<p align=\"center\">\n  \n<p>\n\n9. Fill out the configuration based on the existing AWS Profile you wish to use, select the desired AWS Region, and enable cross-region inference.\n\n<p align=\"center\">\n  \n<p>\n\n<p align=\"center\">\n  \n<p>\n\n10. Next, scroll down on the settings page until you reach the text box that says Custom Instructions. Paste in the following snippet to ensure the `mcp-core` server is used as the starting point for every prompt:\n\n```\nFor every new project, always look at your MCP servers and use mcp-core as the starting point every time. Also after a task completion include the list of MCP servers used in the operation.\n```\n\n<p align=\"center\">\n  \n<p>\n\n11. Once the custom prompt is pasted in, click **Done** to return to the chat interface.\n\n12. Now you can begin asking questions and testing out the functionality of your installed AWS MCP Servers. The default option in the chat interface is is `Plan` which will provide the output for you to take manual action on (e.g. providing you a sample configuration that you copy and paste into a file). However, you can optionally toggle this to `Act` which will allow Cline to act on your behalf (e.g. searching for content using a web browser, cloning a repository, executing code, etc). You can optionally toggle on the \"Auto-approve\" section to avoid having to click to approve the suggestions, however we recommend leaving this off during testing, especially if you have the Act toggle selected.\n\n**Note:** For the best results, please prompt Cline to use the desired AWS MCP Server you wish to use. For example, `Using the Terraform MCP Server, do...`\n</details>\n\n### Getting Started with Cursor\n\n<details>\n<summary>Getting Started with Cursor</summary>\n\n1. Follow the steps above in the **Installation and Setup** section to install `uv` from [Astral](https://docs.astral.sh/uv/getting-started/installation/), install Python, and configure AWS credentials with the required services.\n\n2. You can place MCP configuration in two locations, depending on your use case:\n\n  A. **Project Configuration**\n    - For tools specific to a project, create a `.cursor/mcp.json` file in your project directory.\n    - This allows you to define MCP servers that are only available within that specific project.\n\n  B. **Global Configuration**\n    - For tools that you want to use across all projects, create a `~/.cursor/mcp.json` file in your home directory.\n    - This makes MCP servers available in all your Cursor workspaces.\n\n#### `.cursor/mcp.json`\n\nFor macOS/Linux:\n\n```json\n {\n  \"mcpServers\": {\n    \"awslabs.core-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.core-mcp-server@latest\"],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      }\n    }\n  }\n}\n```\n\nFor Windows:\n\n```json\n{\n  \"mcpServers\": {\n    \"awslabs.core-mcp-server\": {\n      \"disabled\": false,\n      \"timeout\": 60,\n      \"type\": \"stdio\",\n      \"command\": \"uv\",\n      \"args\": [\n        \"tool\",\n        \"run\",\n        \"--from\",\n        \"awslabs.core-mcp-server@latest\",\n        \"awslabs.core-mcp-server.exe\"\n      ],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      }\n    }\n  }\n}\n```\n\n3. **Using MCP in Chat** The Composer Agent will automatically use any MCP tools that are listed under Available Tools on the MCP settings page if it determines them to be relevant. To prompt tool usage intentionally, please prompt Cursor to use the desired AWS MCP Server you wish to use. For example, `Using the Terraform MCP Server, do...`\n\n4. **Tool Approval** By default, when Agent wants to use an MCP tool, it will display a message asking for your approval. You can use the arrow next to the tool name to expand the message and see what arguments the Agent is calling the tool with.\n\n</details>\n\n### Getting Started with Windsurf\n\n<details>\n<summary>Getting Started with Windsurf</summary>\n\n1. Follow the steps above in the **Installation and Setup** section to install `uv` from [Astral](https://docs.astral.sh/uv/getting-started/installation/), install Python, and configure AWS credentials with the required services.\n\n2. **Access MCP Settings**\n   - Navigate to Windsurf - Settings > Advanced Settings or use the Command Palette > Open Windsurf Settings Page\n   - Look for the \"Model Context Protocol (MCP) Servers\" section\n\n3. **Add MCP Servers**\n   - Click \"Add Server\" to add a new MCP server\n   - You can choose from available templates like GitHub, Puppeteer, PostgreSQL, etc.\n   - Alternatively, click \"Add custom server\" to configure your own server\n\n4. **Manual Configuration**\n   - You can also manually edit the MCP configuration file located at `~/.codeium/windsurf/mcp_config.json`\n\n#### `~/.codeium/windsurf/mcp_config.json`\n\nFor macOS/Linux:\n\n ```json\n {\n   \"mcpServers\": {\n     \"awslabs.core-mcp-server\": {\n       \"command\": \"uvx\",\n       \"args\": [\"awslabs.core-mcp-server@latest\"],\n       \"env\": {\n         \"FASTMCP_LOG_LEVEL\": \"ERROR\",\n         \"MCP_SETTINGS_PATH\": \"path to your mcp settings file\"\n       }\n     }\n    }\n  }\n ```\n\nFor Windows:\n\n```json\n{\n  \"mcpServers\": {\n    \"awslabs.core-mcp-server\": {\n      \"disabled\": false,\n      \"timeout\": 60,\n      \"type\": \"stdio\",\n      \"command\": \"uv\",\n      \"args\": [\n        \"tool\",\n        \"run\",\n        \"--from\",\n        \"awslabs.core-mcp-server@latest\",\n        \"awslabs.core-mcp-server.exe\"\n      ],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\",\n        \"MCP_SETTINGS_PATH\": \"path to your mcp settings file\"\n      }\n    }\n  }\n}\n```\n\n</details>\n\n### Getting Started with VS Code\n\n<details>\n<summary>Install in VS Code</summary>\n\nConfigure MCP servers in VS Code settings or in `.vscode/mcp.json` (see [VS Code MCP docs](https://code.visualstudio.com/docs/copilot/chat/mcp-servers) for more info.):\n\n#### `.vscode/mcp.json`\n\nFor macOS/Linux:\n\n```json\n{\n  \"mcpServers\": {\n    \"awslabs.core-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.core-mcp-server@latest\"],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      }\n    }\n  }\n}\n```\n\nFor Windows:\n\n```json\n{\n  \"mcpServers\": {\n    \"awslabs.core-mcp-server\": {\n      \"disabled\": false,\n      \"timeout\": 60,\n      \"type\": \"stdio\",\n      \"command\": \"uv\",\n      \"args\": [\n        \"tool\",\n        \"run\",\n        \"--from\",\n        \"awslabs.core-mcp-server@latest\",\n        \"awslabs.core-mcp-server.exe\"\n      ],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      }\n    }\n  }\n}\n```\n</details>\n\n### Getting Started with Claude Code\n\n<details>\n<summary>Install in Claude Code</summary>\n\nConfigure MCP servers in Claude Code through the CLI or in `.mcp.json`\n\n1. Follow the steps above in the **Installation and Setup** section to install `uv` from [Astral](https://docs.astral.sh/uv/getting-started/installation/), install Python, and configure AWS credentials with the required services.\n\n2. **Using Claude Code CLI Commands**\n\n   Claude Code CLI commands to add MCP servers:\n\n   ```bash\n   # Add core AWS services\n   claude mcp add aws-api uvx awslabs.aws-api-mcp-server@latest\n   claude mcp add aws-cdk uvx awslabs.cdk-mcp-server@latest\n   claude mcp add aws-docs uvx awslabs.aws-documentation-mcp-server@latest\n   claude mcp add aws-support uvx awslabs.aws-support-mcp-server@latest\n   claude mcp add aws-pricing uvx awslabs.aws-pricing-mcp-server@latest\n\n   # Add AI/ML and Bedrock services\n   claude mcp add bedrock-kb uvx awslabs.bedrock-kb-retrieval-mcp-server@latest\n   claude mcp add nova-canvas uvx awslabs.nova-canvas-mcp-server@latest\n   claude mcp add synthetic-data uvx awslabs.syntheticdata-mcp-server@latest\n\n   # Add data and analytics services\n   claude mcp add aws-dataprocessing uvx awslabs.aws-dataprocessing-mcp-server@latest\n   claude mcp add aurora-dsql uvx awslabs.aurora-dsql-mcp-server@latest\n   claude mcp add valkey uvx awslabs.valkey-mcp-server@latest\n\n   # List installed servers\n   claude mcp list\n   ```\n\n3. **Manual Configuration (Alternative)**\n\n   You can also manually configure MCP servers by creating a `.mcp.json` file in your project root:\n\n#### `.mcp.json`\n\nFor macOS/Linux:\n\n```json\n{\n  \"mcpServers\": {\n    \"awslabs.cdk-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.cdk-mcp-server@latest\"],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      }\n    },\n    \"awslabs.aws-documentation-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.aws-documentation-mcp-server@latest\"],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\",\n        \"AWS_DOCUMENTATION_PARTITION\": \"aws\"\n      }\n    }\n  }\n}\n```\n</details>\n\n## Samples\n\nReady-to-use examples of AWS MCP Servers in action are available in the [samples](samples/) directory. These samples provide working code and step-by-step guides to help you get started with each MCP server.\n\n## Vibe coding\n\nYou can use these MCP servers with your AI coding assistant to [vibe code](https://en.wikipedia.org/wiki/Vibe_coding). For tips and tricks on how to improve your vibe coding experience, please refer to our [guide](./VIBE_CODING_TIPS_TRICKS.md).\n\n## Additional Resources\n\n- [Introducing AWS MCP Servers for code assistants](https://aws.amazon.com/blogs/machine-learning/introducing-aws-mcp-servers-for-code-assistants-part-1/)\n- [Vibe coding with AWS MCP Servers | AWS Show & Tell](https://www.youtube.com/watch?v=qXGQQRMrcz0)\n- [Supercharging AWS database development with AWS MCP servers](https://aws.amazon.com/blogs/database/supercharging-aws-database-development-with-aws-mcp-servers/)\n- [AWS costs estimation using Amazon Q CLI and AWS Pricing MCP Server](https://aws.amazon.com/blogs/machine-learning/aws-costs-estimation-using-amazon-q-cli-and-aws-cost-analysis-mcp/)\n- [Introducing AWS Serverless MCP Server: AI-powered development for modern applications](https://aws.amazon.com/blogs/compute/introducing-aws-serverless-mcp-server-ai-powered-development-for-modern-applications/)\n- [Announcing new Model Context Protocol (MCP) Servers for AWS Serverless and Containers](https://aws.amazon.com/about-aws/whats-new/2025/05/new-model-context-protocol-servers-aws-serverless-containers/)\n- [Accelerating application development with the Amazon EKS MCP server](https://aws.amazon.com/blogs/containers/accelerating-application-development-with-the-amazon-eks-model-context-protocol-server/)\n- [Amazon Neptune announces MCP (Model Context Protocol) Server](https://aws.amazon.com/about-aws/whats-new/2025/05/amazon-neptune-mcp-server/)\n- [Terraform MCP Server Vibe Coding](https://youtu.be/i2nBD65md0Y)\n- [How to Generate AWS Architecture Diagrams Using Amazon Q CLI and MCP](https://community.aws/content/2vPiiPiBSdRalaEax2rVDtshpf3/how-to-generate-aws-architecture-diagrams-using-amazon-q-cli-and-mcp)\n- [Harness the power of MCP servers with Amazon Bedrock Agents](https://aws.amazon.com/blogs/machine-learning/harness-the-power-of-mcp-servers-with-amazon-bedrock-agents/)\n- [Unlocking the power of Model Context Protocol (MCP) on AWS](https://aws.amazon.com/blogs/machine-learning/unlocking-the-power-of-model-context-protocol-mcp-on-aws/)\n- [AWS Price List Gets a Natural Language Upgrade: Introducing the AWS Pricing MCP Server](https://aws.amazon.com/blogs/aws-cloud-financial-management/aws-price-list-gets-a-natural-language-upgrade-introducing-the-aws-pricing-mcp-server/)\n- [AWS SheBuilds: AWS Team's Journey from Internal Tools to Open Source AI Infrastructure](https://www.youtube.com/watch?v=DZFgufNCvAo)\n\n## Security\n\nSee [CONTRIBUTING](CONTRIBUTING.md#security-issue-notifications) for more information.\n\n## Contributing\n\nBig shout out to our awesome contributors! Thank you for making this project better!\n\n[![contributors](https://contrib.rocks/image?repo=awslabs/mcp&max=2000)](https://github.com/awslabs/mcp/graphs/contributors)\n\nContributions of all kinds are welcome! Check out our [contributor guide](CONTRIBUTING.md) for more information.\n\n## Developer guide\n\nIf you want to add a new MCP Server to the library, check out our [development guide](DEVELOPER_GUIDE.md) and be sure to follow our [design guidelines](DESIGN_GUIDELINES.md).\n\n## License\n\nThis project is licensed under the Apache-2.0 License.\n\n## Disclaimer\n\nBefore using an MCP Server, you should consider conducting your own independent assessment to ensure that your use would comply with your own specific security and quality control practices and standards, as well as the laws, rules, and regulations that govern you and your content.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "awslabs",
        "images",
        "mcp",
        "awslabs mcp",
        "generates images",
        "generation awslabs"
      ],
      "category": "image-and-video-generation"
    },
    "bendusy--pollinations-mcp": {
      "owner": "bendusy",
      "name": "pollinations-mcp",
      "url": "https://github.com/bendusy/pollinations-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/bendusy.webp",
      "description": "Connects AI models to Pollinations.ai's services for generating images and text via the MCP protocol. Facilitates seamless interaction with Pollinations.ai's API for image generation, downloading images, and text generation.",
      "stars": 8,
      "forks": 5,
      "license": "Apache License 2.0",
      "language": "JavaScript",
      "updated_at": "2025-09-04T11:40:45Z",
      "readme_content": "# Pollinations MCP 服务器\n\n<div align=\"center\">\n  \n</div>\n\n这是一个基于[Model Context Protocol (MCP)](https://github.com/microsoft/modelcontextprotocol)的服务器实现，用于连接[Pollinations.ai](https://pollinations.ai)服务的API接口。该服务器允许AI模型通过MCP协议调用Pollinations.ai的图像和文本生成功能。\n\n## 功能特点\n\n- 支持通过MCP协议与Pollinations.ai服务交互\n- 提供三个主要工具：\n  - `generate_image`: 使用Pollinations.ai生成图像并返回URL（默认无水印）\n  - `download_image`: 下载生成的图像到本地文件\n  - `generate_text`: 使用Pollinations.ai生成文本\n- 基于TypeScript实现，支持类型安全\n- 使用stdio传输机制，便于与AI模型集成\n\n## 安装\n\n1. 克隆仓库：\n\n```bash\ngit clone https://github.com/bendusy/pollinations-mcp.git\ncd pollinations-mcp\n```\n\n2. 安装依赖：\n\n```bash\nnpm install\n```\n\n3. 构建项目：\n\n```bash\nnpm run build\n```\n\n## 使用方法\n\n### 作为MCP服务器运行\n\n```bash\nnpm start\n```\n\n服务器将通过标准输入/输出(stdio)启动，等待MCP客户端连接。\n\n### 在Cursor中使用（当前可能无法正常工作）\n\n**注意：** 目前在Cursor中配置此服务器可能不会成功。如果您需要使用此功能，建议使用Cline（见下文）。\n\n### 在Cline中使用（推荐）\n\n[Cline](https://cline.app)是一个支持MCP协议的AI终端，可以成功使用本服务器提供的图像生成功能。设置步骤如下：\n\n1. 安装并启动Cline\n2. 打开Cline的设置文件，通常位于：\n   - Windows: `%APPDATA%\\Cline\\config.json`\n   - Mac: `~/Library/Application Support/Cline/config.json`\n   - Linux: `~/.config/Cline/config.json`\n\n3. 在配置文件中找到或添加`mcpServers`部分，然后添加以下配置：\n\n```json\n\"mcpServers\": {\n  \"pollinations-mcp\": {\n    \"command\": \"node\",\n    \"args\": [\n      \"完整路径/到您的/pollinations-mcp/dist/index.js\"\n    ],\n    \"disabled\": false,\n    \"autoApprove\": [\n      \"download_image\",\n      \"generate_image\",\n      \"generate_text\"\n    ]\n  }\n}\n```\n\n例如，Windows系统上的完整配置可能如下：\n\n```json\n\"mcpServers\": {\n  \"pollinations-mcp\": {\n    \"command\": \"node\",\n    \"args\": [\n      \"C:\\\\Users\\\\用户名\\\\路径\\\\到\\\\pollinations-mcp\\\\dist\\\\index.js\"\n    ],\n    \"disabled\": false,\n    \"autoApprove\": [\n      \"download_image\",\n      \"generate_image\",\n      \"generate_text\"\n    ]\n  }\n}\n```\n\n4. 保存配置文件并重启Cline\n5. 现在您可以在Cline中使用Pollinations图像生成功能了，例如：\n\n```\n使用Pollinations生成图像：beautiful sunset over ocean with palm trees\n```\n\n### 与AI模型集成\n\n本服务器设计用于与支持MCP协议的AI模型集成，使其能够生成图像。\n\n### 支持的工具\n\n#### generate_image\n\n使用Pollinations.ai生成图像并返回URL。\n\n参数：\n- `prompt` (必需): 图像描述提示词\n- `width` (可选): 图像宽度（像素），默认为1024\n- `height` (可选): 图像高度（像素），默认为1024\n- `seed` (可选): 随机种子值（用于生成一致的图像）\n- `model` (可选): 要使用的模型，默认为'flux'\n- `nologo` (可选): 设置为true可去除水印，默认为true\n- `enhance` (可选): 提高图像质量（应用增强滤镜），默认为false\n- `safe` (可选): 启用安全过滤（过滤不适内容），默认为false\n- `private` (可选): 设置为true可使图像私有（不在公共feed中显示），默认为false\n\n**提示词最佳实践：**\n- 尽量使用英文编写提示词，Pollinations.ai对英文的理解更好\n- 保持提示词简短精确，避免过长或模糊的描述\n- 使用具体的形容词和名词，而非抽象概念\n- 例如：\"beautiful sunset over ocean with palm trees\"比\"一张日落的图片\"效果更好\n\n#### download_image\n\n下载Pollinations.ai生成的图像到本地文件。\n\n参数：\n- `url` (必需): 要下载的图像URL\n- `output_path` (可选): 保存图像的路径（包括文件名），默认为'image.jpg'\n\n#### generate_text\n\n使用Pollinations.ai生成文本。\n\n参数：\n- `prompt` (必需): 文本提示词\n- `model` (可选): 要使用的模型（如openai、mistral等），默认为'openai'\n- `seed` (可选): 随机种子值（用于生成一致的结果）\n- `system` (可选): 系统提示词（设置AI行为）\n- `json` (可选): 是否返回JSON格式的响应，默认为false\n- `private` (可选): 设置为true可使响应私有，默认为false\n\n## API参考\n\n本项目使用Pollinations.ai的官方API。完整的API文档请参考：[Pollinations API文档](https://github.com/pollinations/pollinations/blob/master/APIDOCS.md)\n\n### 图像生成API\n\n基本格式：`https://image.pollinations.ai/prompt/{prompt}?{参数}`\n\n示例：\n```\nhttps://image.pollinations.ai/prompt/beautiful%20sunset?width=1024&height=1024&nologo=true\n```\n\n### 可用的图像模型\n\n- `flux` (默认): 主流文生图模型，功能全面\n- `variation`: 图像变体生成\n- `dreamshaper`: 梦幻风格\n- `anything`: 动漫风格图像\n- `pixart`: 高质量插图风格\n\n### 文本生成API\n\n基本格式：`https://text.pollinations.ai/{prompt}?{参数}`\n\n示例：\n```\nhttps://text.pollinations.ai/Tell%20me%20about%20artificial%20intelligence?model=openai\n```\n\n### 可用的文本模型\n\n- `openai` (默认): OpenAI模型\n- `mistral`: Mistral模型\n- `gemini`: Google Gemini模型\n\n## 开发\n\n### 项目结构\n\n- `src/index.ts`: 主服务器实现\n- `dist/`: 编译后的JavaScript文件\n- `package.json`: 项目配置和依赖\n\n### 依赖\n\n- `@modelcontextprotocol/sdk`: MCP协议SDK\n- `axios`: HTTP客户端，用于下载图像\n- `typescript`: TypeScript编译器\n\n## 许可\n\n本项目采用ISC许可证。详情请参阅[LICENSE](LICENSE)文件。\n\n## 相关链接\n\n- [Pollinations.ai](https://pollinations.ai)\n- [Model Context Protocol](https://github.com/microsoft/modelcontextprotocol)",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ai",
        "pollinations",
        "images",
        "pollinations ai",
        "generating images",
        "ai api"
      ],
      "category": "image-and-video-generation"
    },
    "beordle--tinypng-mcp-server": {
      "owner": "beordle",
      "name": "tinypng-mcp-server",
      "url": "https://github.com/beordle/tinypng-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/beordle.webp",
      "description": "Compress images efficiently using the TinyPNG API. Supports both local and remote image compression with minimal setup required.",
      "stars": 0,
      "forks": 0,
      "license": "Apache License 2.0",
      "language": "",
      "updated_at": "2025-03-31T16:01:05Z",
      "readme_content": "## MCP server for TinyPNG\n\n### Usage\n\n### Use `bun` or `node` to run the server\n\n1. Install dependencies and build\n\n```bash\npnpm i\npnpm build\n```\n\n2. Edit the `mcp.json` file\n\n```json\n{\n  \"mcpServers\": {\n    \"tinypng\": {\n      \"command\": \"bun\", // or \"node\"\n      \"args\": [\"/path/to/tinypng-mcp-server/src/index.ts\"], // or \"dist/index.js\"\n      \"env\": {\n        \"TINYPNG_API_KEY\": \"your-tinypng-api-key\"\n      }\n    }\n  }\n}\n```\n\n### Tools\n\n1. Compress local image\n\n```js\n{\n  name: 'compress_local_image',\n  description: 'Compress a local image file',\n  inputSchema: {\n    type: 'object',\n    properties: {\n      imagePath: {\n        type: 'string',\n        description: 'The ABSOLUTE path to the image file to compress',\n        example: '/Users/user/Downloads/image.jpg',\n      },\n      outputPath: {\n        type: 'string',\n        description: 'The ABSOLUTE path to save the compressed image file',\n        example: '/Users/user/Downloads/image_compressed.jpg',\n      },\n      outputFormat: {\n        type: 'string',\n        description: 'The format to save the compressed image file',\n        enum: SUPPORTED_IMAGE_TYPES,\n        example: 'image/jpeg',\n      },\n    },\n    required: ['imagePath'],\n  },\n}\n```\n\n2. Compress remote image\n\n```js\n{\n  name: 'compress_remote_image',\n  description: 'Compress a remote image file by giving the URL of the image',\n  inputSchema: {\n    type: 'object',\n    properties: {\n      imageUrl: {\n        type: 'string',\n        description: 'The URL of the image file to compress',\n        example: 'https://example.com/image.jpg',\n      },\n      outputPath: {\n        type: 'string',\n        description: 'The ABSOLUTE path to save the compressed image file',\n        example: '/Users/user/Downloads/image_compressed.jpg',\n      },\n      outputFormat: {\n        type: 'string',\n        description: 'The format to save the compressed image file',\n        enum: SUPPORTED_IMAGE_TYPES,\n        example: 'image/jpeg',\n      },\n    },\n    required: ['imageUrl'],\n  },\n}\n```\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "tinypng",
        "compression",
        "compress",
        "compress images",
        "tinypng mcp",
        "beordle tinypng"
      ],
      "category": "image-and-video-generation"
    },
    "bitscorp-mcp--mcp-ffmpeg": {
      "owner": "bitscorp-mcp",
      "name": "mcp-ffmpeg",
      "url": "https://github.com/bitscorp-mcp/mcp-ffmpeg",
      "imageUrl": "/freedevtools/mcp/pfp/bitscorp-mcp.webp",
      "description": "Manipulate video files by resizing them to various resolutions and extracting audio in multiple formats. Interact with video processing capabilities using natural language requests via API calls.",
      "stars": 35,
      "forks": 13,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-09-28T04:42:34Z",
      "readme_content": "# MCP FFmpeg Video Processor\n[![smithery badge](https://smithery.ai/badge/@bitscorp-mcp/mcp-ffmpeg)](https://smithery.ai/server/@bitscorp-mcp/mcp-ffmpeg)\n\nA Node.js server that uses FFmpeg to manipulate video files. This server provides APIs to:\n\n- Resize videos to different resolutions (360p, 480p, 720p, 1080p)\n- Extract audio from videos in various formats (MP3, AAC, WAV, OGG)\n\n## Prerequisites\n\nBefore running this application, you need to have the following installed:\n\n1. **Node.js** (v14 or higher)\n2. **FFmpeg** - This is required for video processing\n\n### Installing FFmpeg\n\n#### On macOS:\n```bash\nbrew install ffmpeg\n```\n\n#### On Ubuntu/Debian:\n```bash\nsudo apt update\nsudo apt install ffmpeg\n```\n\n#### On Windows:\n1. Download FFmpeg from the [official website](https://ffmpeg.org/download.html)\n2. Extract the files to a folder (e.g., `C:\\ffmpeg`)\n3. Add the `bin` folder to your PATH environment variable\n\n## Installation\n\n1. Clone this repository:\n```bash\ngit clone https://github.com/bitscorp-mcp/mcp-ffmpeg.git\ncd mcp-ffmpeg\n```\n\n2. Install dependencies:\n```bash\nnpm install\n```\n\n### Installing via Smithery\n\nTo install mcp-ffmpeg for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@bitscorp-mcp/mcp-ffmpeg):\n\n```bash\nnpx -y @smithery/cli install @bitscorp-mcp/mcp-ffmpeg --client claude\n```\n\n## Running the Server\n\nStart the server with:\n\n```bash\nnpm start\n```\n\nFor development with auto-restart on file changes:\n\n```bash\nnpm run dev\n```\n\n### Installing via Smithery\n\nTo install mcp-ffmpeg for Claude Desktop automatically via [Smithery](https://smithery.ai/server/bitscorp-mcp/mcp-ffmpeg):\n\n```bash\nnpx -y @smithery/cli install @bitscorp-mcp/mcp-ffmpeg --client claude\n```\n\nTo install mcp-ffmpeg for Cursor, go to Settings -> Cursor Settings -> Features -> MCP Servers -> + Add\n\nSelect Type: command and paste the below, using your API key from Adjust\n```\nnpx -y @smithery/cli@latest run @bitscorp/mcp-ffmpeg\n```\n\n## Using with Claude Desktop\n\nThis MCP FFmpeg server can be integrated with Claude Desktop to process videos through natural language requests.\n\n### Running with npx\n\nYou can run the server directly with npx:\n\n```bash\nnpx /path/to/mcp-ffmpeg\n```\n\nOr if you've published the package to npm:\n\n```bash\nnpx mcp-ffmpeg\n```\n\n### Configuring Claude Desktop\n\nTo add this server to Claude Desktop, update your Claude Desktop configuration file:\n\n1. Locate your Claude Desktop config file:\n   - macOS: `~/.config/claude-desktop/config.json` or `~/Library/Application Support/Claude Desktop/config.json`\n   - Windows: `%APPDATA%\\Claude Desktop\\config.json`\n   - Linux: `~/.config/claude-desktop/config.json`\n\n2. Add the FFmpeg MCP server to the `mcpServers` section:\n\n```json\n{\n    \"mcpServers\": {\n        \"ffmpeg\": {\n            \"command\": \"npx\",\n            \"args\": [\n                \"--yes\",\n                \"/absolute/path/to/mcp-ffmpeg\"\n            ]\n        }\n    }\n}\n```\n\nIf you've published the package to npm:\n\n```json\n{\n    \"mcpServers\": {\n        \"ffmpeg\": {\n            \"command\": \"npx\",\n            \"args\": [\n                \"--yes\",\n                \"mcp-ffmpeg\"\n            ]\n        }\n    }\n}\n```\n\n3. Restart Claude Desktop for the changes to take effect.\n\n### Example Prompts for Claude\n\nOnce configured, you can use prompts like:\n\n```\nUsing the ffmpeg MCP server, please resize the video at /path/to/video.mp4 to 720p resolution.\n```\n\n## Notes\n\n- Uploaded videos are stored temporarily in the `uploads` directory\n- Processed videos and audio files are stored in the `output` directory\n- The server has a file size limit of 500MB for uploads\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ffmpeg",
        "audio",
        "formats",
        "mcp ffmpeg",
        "video generation",
        "video processing"
      ],
      "category": "image-and-video-generation"
    },
    "bobtista--luma-ai-mcp-server": {
      "owner": "bobtista",
      "name": "luma-ai-mcp-server",
      "url": "https://github.com/bobtista/luma-ai-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/bobtista.webp",
      "description": "Integrates with Luma AI's Dream Machine API to facilitate the generation and manipulation of AI-generated videos and images. Offers tools for text-to-video generation, image processing, and audio integration to enhance creative projects.",
      "stars": 3,
      "forks": 4,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-07-23T00:09:33Z",
      "readme_content": "# Luma AI MCP Server 🎥\n\nA Model Context Protocol server for Luma AI's Dream Machine API.\n\n## Overview\n\nThis MCP server integrates with Luma AI's Dream Machine API (v1) to provide tools for generating, managing, and manipulating AI-generated videos and images via Large Language Models. It implements the Model Context Protocol (MCP) to enable seamless interaction between AI assistants and Luma's creative tools.\n\n## Features ✨\n\n- Text-to-video generation\n- Advanced video generation with keyframes\n- Image-to-video conversion\n- Video extension and interpolation\n- Image generation with reference images\n- Audio addition to videos\n- Video upscaling\n- Credit management\n- Generation tracking and status checking\n\n## Tools 🛠️\n\n1. `ping`\n\n   - Check if the Luma API is running\n   - No parameters required\n\n2. `create_generation`\n\n   - Creates a new video generation\n   - Input:\n     - `prompt` (string, required): Text description of the video to generate\n     - `model` (string, optional): Model to use (default: \"ray-2\")\n       - Available models: \"ray-1-6\", \"ray-2\", \"ray-flash-2\"\n     - `resolution` (string, optional): Video resolution (choices: \"540p\", \"720p\", \"1080p\", \"4k\")\n     - `duration` (string, optional): Video duration (only \"5s\" and \"9s\" are currently supported)\n     - `aspect_ratio` (string, optional): Video aspect ratio (e.g., \"16:9\", \"1:1\", \"9:16\", \"4:3\", \"3:4\", \"21:9\", \"9:21\")\n     - `loop` (boolean, optional): Whether to make the video loop\n     - `keyframes` (object, optional): Start and end frames for advanced video generation:\n       - `frame0` and/or `frame1` with either:\n         - `{\"type\": \"image\", \"url\": \"image_url\"}` for image keyframes\n         - `{\"type\": \"generation\", \"id\": \"generation_id\"}` for video keyframes\n\n3. `get_generation`\n\n   - Gets the status of a generation\n   - Input:\n     - `generation_id` (string, required): ID of the generation to check\n   - Output includes:\n     - Generation ID\n     - State (queued, dreaming, completed, failed)\n     - Failure reason (if failed)\n     - Video URL (if completed)\n\n4. `list_generations`\n\n   - Lists all generations\n   - Input:\n     - `limit` (number, optional): Maximum number of generations to return (default: 10)\n     - `offset` (number, optional): Number of generations to skip\n\n5. `delete_generation`\n\n   - Deletes a generation\n   - Input:\n     - `generation_id` (string, required): ID of the generation to delete\n\n6. `upscale_generation`\n\n   - Upscales a video generation to higher resolution\n   - Input:\n     - `generation_id` (string, required): ID of the generation to upscale\n     - `resolution` (string, required): Target resolution for the upscaled video (one of \"540p\", \"720p\", \"1080p\", or \"4k\")\n   - Note:\n     - The generation must be in a completed state to be upscaled\n     - The target resolution must be higher than the original generation's resolution\n     - Each generation can only be upscaled once\n\n7. `add_audio`\n\n   - Adds AI-generated audio to a video generation\n   - Input:\n     - `generation_id` (required): The ID of the generation to add audio to\n     - `prompt` (required): The prompt for the audio generation\n     - `negative_prompt` (optional): The negative prompt for the audio generation\n     - `callback_url` (optional): URL to notify when the audio processing is complete\n\n8. `generate_image`\n\n   - Generates an image from a text prompt with optional reference images\n   - Input:\n     - `prompt` (string, required): Text description of the image to generate\n     - `model` (string, optional): Model to use for image generation (default: \"photon-1\")\n       - Available models: \"photon-1\", \"photon-flash-1\"\n     - `aspect_ratio` (string, optional): Image aspect ratio (same options as video)\n     - `image_ref` (array, optional): Reference images to guide generation\n       - Each ref: `{\"url\": \"image_url\", \"weight\": optional_float}`\n     - `style_ref` (array, optional): Style reference images\n       - Each ref: `{\"url\": \"image_url\", \"weight\": optional_float}`\n     - `character_ref` (object, optional): Character reference images\n       - Format: `{\"identity_name\": {\"images\": [\"url1\", \"url2\", ...]}}`\n     - `modify_image_ref` (object, optional): Image to modify\n       - Format: `{\"url\": \"image_url\", \"weight\": optional_float}`\n\n9. `get_credits`\n\n   - Gets credit information for the current user\n   - No parameters required\n   - Returns available credit balance in USD cents\n\n10. `get_camera_motions`\n    - Gets all supported camera motions\n    - No parameters required\n    - Returns: List of available camera motion strings\n\n## Setup for Claude Desktop 🖥️\n\n1. Get your Luma API key from [Luma AI](https://lumalabs.ai) (sign up or log in to get your API key)\n\n2. Add this to your Claude Desktop configuration file:\n\n   - On macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - On Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n\n   ```json\n   {\n     \"mcpServers\": {\n       \"luma\": {\n         \"command\": \"uv\",\n         \"args\": [\n           \"run\",\n           \"--project\",\n           \"/path/to/your/luma-ai-mcp-server\",\n           \"-m\",\n           \"luma_ai_mcp_server\"\n         ],\n         \"env\": {\n           \"LUMA_API_KEY\": \"your-luma-api-key-here\"\n         }\n       }\n     }\n   }\n   ```\n\n   Replace:\n\n   - `/path/to/your/luma-ai-mcp-server` with the actual path to your server directory\n   - `your-luma-api-key-here` with your actual Luma API key\n\n3. Restart Claude Desktop\n\n4. That's it! You can now use Luma AI tools directly in Claude Desktop conversations.\n\n## Quick Troubleshooting 🛠️\n\nIf you're having issues:\n\n1. Check your API key is correct\n2. Make sure the path to the server is correct\n3. View logs with: `tail -n 20 -f ~/Library/Logs/Claude/mcp*.log`\n\n## Advanced Video Generation Types 🎬\n\nThe Luma API supports various types of advanced video generation through keyframes:\n\n1. **Starting from an image**: Provide `frame0` with `type: \"image\"` and an image URL\n2. **Ending with an image**: Provide `frame1` with `type: \"image\"` and an image URL\n3. **Extending a video**: Provide `frame0` with `type: \"generation\"` and a generation ID\n4. **Reverse extending a video**: Provide `frame1` with `type: \"generation\"` and a generation ID\n5. **Interpolating between videos**: Provide both `frame0` and `frame1` with `type: \"generation\"` and generation IDs\n\n## API Limitations and Notes 📝\n\n- **Duration**: Currently, the API only supports durations of \"5s\" or \"9s\"\n- **Resolution**: Valid values are \"540p\", \"720p\", \"1080p\", and \"4k\"\n- **Models**:\n  - Video generation:\n    - \"ray-2\" (default) - Best quality, slower\n    - \"ray-flash-2\" - Faster generation\n    - \"ray-1-6\" - Legacy model\n  - Image generation:\n    - \"photon-1\" (default) - Best quality, slower\n    - \"photon-flash-1\" - Faster generation\n- **Generation types**: Video, image, and advanced (with keyframes)\n- **Aspect Ratios**: \"1:1\" (square), \"16:9\" (landscape), \"9:16\" (portrait), \"4:3\" (standard), \"3:4\" (standard portrait), \"21:9\" (ultrawide), \"9:21\" (ultrawide portrait)\n- **States**: \"queued\", \"dreaming\", \"completed\", \"failed\"\n- **Upscaling**:\n  - Video generations can only be upscaled when they're in a \"complete\" state\n  - Target resolution must be higher than the original generation's resolution\n  - Each generation can only be upscaled once\n- **API Key**: Required in environment variables\n- **API Version**: Uses Dream Machine API v1\n\n## License 📄\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "luma",
        "ai",
        "bobtista",
        "ai dream",
        "dream machine",
        "luma ai"
      ],
      "category": "image-and-video-generation"
    },
    "breezedeus--CnOCR": {
      "owner": "breezedeus",
      "name": "CnOCR",
      "url": "https://github.com/breezedeus/CnOCR",
      "imageUrl": "/freedevtools/mcp/pfp/breezedeus.webp",
      "description": "Enables optical character recognition for Chinese, English, and numbers using pre-trained models or custom training. Provides powerful text recognition capabilities for a variety of applications.",
      "stars": 3659,
      "forks": 528,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-10-03T14:15:19Z",
      "readme_content": "<div align=\"center\">\n  \n  <div>&nbsp;</div>\n\n[![Discord](https://img.shields.io/discord/1200765964434821260?label=Discord)](https://discord.gg/GgD87WM8Tf)\n[![Downloads](https://static.pepy.tech/personalized-badge/cnocr?period=total&units=international_system&left_color=grey&right_color=orange&left_text=Downloads)](https://pepy.tech/project/cnocr)\n[](https://visitorbadge.io/status?path=https%3A%2F%2Fgithub.com%2Fbreezedeus%2FCnOCR)\n[![license](https://img.shields.io/github/license/breezedeus/cnocr)](./LICENSE)\n[![Docs](https://readthedocs.org/projects/cnocr/badge/?version=latest)](https://cnocr.readthedocs.io/zh-cn/stable/?badge=latest)\n[![PyPI version](https://badge.fury.io/py/cnocr.svg)](https://badge.fury.io/py/cnocr)\n[![forks](https://img.shields.io/github/forks/breezedeus/cnocr)](https://github.com/breezedeus/cnocr)\n[![stars](https://img.shields.io/github/stars/breezedeus/cnocr)](https://github.com/breezedeus/cnocr)\n![last-releast](https://img.shields.io/github/release-date/breezedeus/cnocr)\n![last-commit](https://img.shields.io/github/last-commit/breezedeus/cnocr)\n[![Twitter](https://img.shields.io/twitter/url?url=https%3A%2F%2Ftwitter.com%2Fbreezedeus)](https://twitter.com/breezedeus)\n\n[📖 文档](https://cnocr.readthedocs.io/zh-cn/stable/) |\n[🛠️ 安装](https://cnocr.readthedocs.io/zh-cn/stable/install/) |\n[🧳 可用模型](https://cnocr.readthedocs.io/zh-cn/stable/models/) |\n[🕹 模型训练](https://cnocr.readthedocs.io/zh-cn/stable/train/) |\n[🛀🏻 在线Demo](https://huggingface.co/spaces/breezedeus/CnOCR-Demo) |\n[💬 交流群](https://www.breezedeus.com/article/join-group)\n\n</div>\n\n<div align=\"center\">\n\n[English](./README_en.md) | 中文\n\n</div>\n\n# CnOCR\n\n<div align=\"center\">\n<strong>Tech should serve the people, not enslave them!</strong>\n<br>\n<strong>请勿将此项目用于文字审查！</strong>\n<br>\n---\n</div>\n\n### Update 2025.06.26：发布 V2.3.2\n\n主要变更：\n\n* 集成 PPOCRv5 最新版 OCR 模型\n  * 新增支持 PP-OCRv5 识别模型：`ch_PP-OCRv5` 和 `ch_PP-OCRv5_server`\n\n\n### [Update 2024.11.30]：发布 V2.3.1\n\n主要变更：\n\n* 基于 RapidOCR 集成 PPOCRv4 最新版 OCR 模型，提供更多的模型选择\n  * 新增支持 PP-OCRv4  识别模型，包括标准版和服务器版\n* 修改读文件实现方式，支持 Windows 的中文路径\n* 修复Bug：当使用多个进程时，transform_func 无法序列化\n* 修复Bug：与 albumentations=1.4.* 兼容\n\n### [Update 2023.12.24]：发布 V2.3\n\n主要变更：\n\n* 重新训练了所有的模型，比上一版精度更高。\n* 按使用场景把模型分为几大类场景（见 [识别模型列表](#可使用的识别模型)）：\n  * `scene`：场景图片，适合识别一般拍照图片中的文字。此类模型以 `scene-` 开头，如模型 `scene-densenet_lite_136-gru`。\n  * `doc`：文档图片，适合识别规则文档的截图图片，如书籍扫描件等。此类模型以 `doc-` 开头，如模型 `doc-densenet_lite_136-gru`。\n  * `number`：仅识别**纯数字**（只能识别 `0~9` 十个数字）图片，适合银行卡号、身份证号等场景。此类模型以 `number-` 开头，如模型 `number-densenet_lite_136-gru`。\n  * `general`: 通用场景，适合图片无明显倾向的一般图片。此类模型无特定开头，与旧版模型名称保持一致，如模型 `densenet_lite_136-gru`。\n  > 注意 ⚠️：以上说明仅为参考，具体选择模型时建议以实际效果为准。\n* 加入了两个更大的系列模型：\n  * `*-densenet_lite_246-gru_base`：优先供 **知识星球** [**CnOCR/CnSTD私享群**](https://t.zsxq.com/FEYZRJQ) 会员使用，一个月后会免费开源。\n  * `*-densenet_lite_666-gru_large`：Pro 模型，购买后可使用。\n  \n更多细节请参考：[CnOCR V2.3 新版发布：模型更好、更多、更大 | Breezedeus.com](https://www.breezedeus.com/article/cnocr-v2.3-better-more)。\n\n\n\n[**CnOCR**](https://github.com/breezedeus/cnocr) 是 **Python 3** 下的**文字识别**（**Optical Character Recognition**，简称**OCR**）工具包，支持**简体中文**、**繁体中文**（部分模型）、**英文**和**数字**的常见字符识别，支持竖排文字的识别。自带了**20+个** [训练好的模型](https://cnocr.readthedocs.io/zh-cn/stable/models/)，适用于不同应用场景，安装后即可直接使用。同时，CnOCR也提供简单的[训练命令](https://cnocr.readthedocs.io/zh-cn/stable/train/)供使用者训练自己的模型。欢迎扫码加小助手为好友，备注 `ocr`，小助手会定期统一邀请大家入群：\n\n<div align=\"center\">\n  <img src=\"https://huggingface.co/datasets/breezedeus/cnocr-wx-qr-code/resolve/main/wx-qr-code.JPG\" alt=\"微信群二维码\" width=\"300px\"/>\n</div>\n\n\n作者也维护 **知识星球** [**CnOCR/CnSTD私享群**](https://t.zsxq.com/FEYZRJQ) ，这里面的提问会较快得到作者的回复，欢迎加入。**知识星球会员** 可享受以下福利：\n\n- 可免费下载部分**未开源的付费模型**；\n- 购买其他所有的付费模型一律八折优化；\n- 作者快速回复使用过程中遇到的各种困难；\n- 作者每月提供两次免费特有数据的训练服务。\n- 星球会陆续发布一些CnOCR/CnSTD相关的私有资料；\n- 星球会持续发布 OCR/STD/CV 等相关的最新研究资料。\n\n\n\n## 详细文档\n\n见 [CnOCR在线文档](https://cnocr.readthedocs.io/) 。\n\n## 使用说明\n\n**CnOCR** 从 **V2.2** 开始，内部自动调用文字检测引擎 **[CnSTD](https://github.com/breezedeus/cnstd)** 进行文字检测和定位。所以 **CnOCR** V2.2 不仅能识别排版简单的印刷体文字图片，如截图图片，扫描件等，也能识别**一般图片中的场景文字**。\n\n以下是一些不同场景的调用示例。\n\n\n\n## 不同场景的调用示例\n\n### 常见的图片识别\n\n所有参数都使用默认值即可。如果发现效果不够好，多调整下各个参数看效果，最终往往能获得比较理想的精度。\n\n```python\nfrom cnocr import CnOcr\n\nimg_fp = './docs/examples/huochepiao.jpeg'\nocr = CnOcr()  # 所有参数都使用默认值\nout = ocr.ocr(img_fp)\n\nprint(out)\n```\n\n识别结果：\n\n<div align=\"center\">\n  \n</div>\n\n\n### 排版简单的印刷体截图图片识别\n\n针对 **排版简单的印刷体文字图片**，如截图图片，扫描件图片等，可使用 `det_model_name='naive_det'`，相当于不使用文本检测模型，而使用简单的规则进行分行。\n\n> **Note**\n>\n>  `det_model_name='naive_det'` 的效果相当于 `V2.2` 之前（`V2.0.*`, `V2.1.*`）的 CnOCR 版本。\n\n使用 `det_model_name='naive_det'` 的最大优势是**速度快**，劣势是对图片比较挑剔。如何判断是否该使用此检测模型呢？最简单的方式就是拿应用图片试试效果，效果好就用，不好就不用。\n\n```python\nfrom cnocr import CnOcr\n\nimg_fp = './docs/examples/multi-line_cn1.png'\nocr = CnOcr(det_model_name='naive_det') \nout = ocr.ocr(img_fp)\n\nprint(out)\n```\n\n识别结果：\n\n<div align=\"center\">\n\n| 图片                                                                      | OCR结果                                                                                                                         |\n| ----------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------- |\n|  | 网络支付并无本质的区别，因为<br />每一个手机号码和邮件地址背后<br />都会对应着一个账户--这个账<br />户可以是信用卡账户、借记卡账<br />户，也包括邮局汇款、手机代<br />收、电话代收、预付费卡和点卡<br />等多种形式。 |\n\n</div>\n\n\n### 竖排文字识别\n\n采用来自 [**PaddleOCR**](https://github.com/PaddlePaddle/PaddleOCR)（之后简称 **ppocr**）的中文识别模型 `rec_model_name='ch_PP-OCRv3'` 进行识别。\n\n```python\nfrom cnocr import CnOcr\n\nimg_fp = './docs/examples/shupai.png'\nocr = CnOcr(rec_model_name='ch_PP-OCRv3')\nout = ocr.ocr(img_fp)\n\nprint(out)\n```\n\n识别结果：\n<div align=\"center\">\n  \n</div>\n\n\n### 英文识别\n\n虽然中文检测和识别模型也能识别英文，但**专为英文文字训练的检测器和识别器往往精度更高**。如果是纯英文的应用场景，建议使用来自 **ppocr** 的英文检测模型 `det_model_name='en_PP-OCRv3_det'`， 和英文识别模型 `rec_model_name='en_PP-OCRv3'` 。\n\n```python\nfrom cnocr import CnOcr\n\nimg_fp = './docs/examples/en_book1.jpeg'\nocr = CnOcr(det_model_name='en_PP-OCRv3_det', rec_model_name='en_PP-OCRv3')\nout = ocr.ocr(img_fp)\n\nprint(out)\n```\n\n识别结果：\n\n<div align=\"center\">\n  \n</div>\n\n\n### 繁体中文识别\n\n采用来自ppocr的繁体识别模型 `rec_model_name='chinese_cht_PP-OCRv3'` 进行识别。\n\n```python\nfrom cnocr import CnOcr\n\nimg_fp = './docs/examples/fanti.jpg'\nocr = CnOcr(rec_model_name='chinese_cht_PP-OCRv3')  # 识别模型使用繁体识别模型\nout = ocr.ocr(img_fp)\n\nprint(out)\n```\n\n使用此模型时请注意以下问题：\n\n* 识别精度一般，不是很好；\n\n* 除了繁体字，对标点、英文、数字的识别都不好；\n\n* 此模型不支持竖排文字的识别。\n\n识别结果：\n<div align=\"center\">\n  \n</div>\n\n\n### 单行文字的图片识别\n\n如果明确知道待识别的图片是单行文字图片（如下图），可以使用类函数 `CnOcr.ocr_for_single_line()` 进行识别。这样就省掉了文字检测的时间，速度会快一倍以上。\n\n<div align=\"center\">\n  \n</div>\n调用代码如下：\n\n```python\nfrom cnocr import CnOcr\n\nimg_fp = './docs/examples/helloworld.jpg'\nocr = CnOcr()\nout = ocr.ocr_for_single_line(img_fp)\nprint(out)\n```\n\n\n\n### 更多应用示例\n\n* **核酸疫苗截图识别**\n<div align=\"center\">\n  \n</div>\n\n* **身份证识别**\n<div align=\"center\">\n  \n</div>\n\n* **饭店小票识别**\n<div align=\"center\">\n  \n</div>\n  \n\n  \n\n## 安装\n\n嗯，顺利的话一行命令即可。\n\n```bash\n$ pip install cnocr[ort-cpu]\n```\n\n如果是 **GPU** 环境使用 ONNX 模型，请使用以下命令进行安装：\n\n```bash\n$ pip install cnocr[ort-gpu]\n```\n\n\n\n如果要训练自己的模型，，可以使用以下命令安装：\n\n```bash\n$ pip install cnocr[dev]\n```\n\n\n\n安装速度慢的话，可以指定国内的安装源，如使用阿里云的安装源：\n\n```bash\n$ pip install cnocr[ort-cpu] -i https://mirrors.aliyun.com/pypi/simple\n```\n\n> **Note** \n>\n> 请使用 **Python3**（3.7.\\*~3.10.\\*之间的版本应该都行），没测过Python2下是否ok。\n\n更多说明可见 [安装文档](https://cnocr.readthedocs.io/zh-cn/stable/install/)。\n\n> **Warning** \n>\n> 如果电脑中从未安装过 `PyTorch`，`OpenCV` python包，初次安装可能会遇到问题，但一般都是常见问题，可以自行百度/Google解决。\n\n\n\n### Docker Image\n\n可以从 [Docker Hub](https://hub.docker.com/u/breezedeus) 直接拉取已安装好 CnOCR 的镜像使用。\n\n```bash\n$ docker pull breezedeus/cnocr:latest\n```\n\n更多说明可见 [安装文档](https://cnocr.readthedocs.io/zh-cn/stable/install/)。\n\n\n\n## HTTP服务\n\nCnOCR **V2.2.1** 加入了基于 FastAPI 的HTTP服务。开启服务需要安装几个额外的包，可以使用以下命令安装：\n\n```bash\npip install cnocr[serve]\n```\n\n\n\n安装完成后，可以通过以下命令启动HTTP服务（**`-p`** 后面的数字是**端口**，可以根据需要自行调整）：\n\n```bash\ncnocr serve -p 8501\n```\n\n\n\n服务开启后，可以使用以下方式调用服务。\n\n\n\n### 命令行\n\n比如待识别文件为 `docs/examples/huochepiao.jpeg`，如下使用 curl 调用服务：\n\n```bash\n> curl -F image=@docs/examples/huochepiao.jpeg http://0.0.0.0:8501/ocr\n```\n\n\n\n### Python\n\n使用如下方式调用服务：\n\n```python\nimport requests\n\nimage_fp = 'docs/examples/huochepiao.jpeg'\nr = requests.post(\n    'http://0.0.0.0:8501/ocr', files={'image': (image_fp, open(image_fp, 'rb'), 'image/png')},\n)\nocr_out = r.json()['results']\nprint(ocr_out)\n```\n\n\n\n具体也可参考文件 [scripts/screenshot_daemon_with_server.py](scripts/screenshot_daemon_with_server.py) 。 \n\n\n\n### 其他语言\n\n请参照 curl 的调用方式自行实现。\n\n\n\n\n\n## 可使用的模型\n\n### 可使用的检测模型\n\n具体参考 [CnSTD的下载说明](https://github.com/breezedeus/CnSTD?tab=readme-ov-file#%E5%B7%B2%E6%9C%89std%E6%A8%A1%E5%9E%8B)。\n\n| `det_model_name`                                             | PyTorch 版本 | ONNX 版本 | 模型原始来源 | 模型文件大小 | 支持语言                       | 是否支持竖排文字识别 |\n| ------------------------------------------------------------ | ------------ | --------- | ------------ | ------------ | ------------------------------ | -------------------- |\n| db_shufflenet_v2                                             | √            | X         | cnocr        | 18 M         | 简体中文、繁体中文、英文、数字 | √                    |\n| **db_shufflenet_v2_small**                                   | √            | X         | cnocr        | 12 M         | 简体中文、繁体中文、英文、数字 | √                    |\n| db_mobilenet_v3                                              | √            | X         | cnocr        | 16 M         | 简体中文、繁体中文、英文、数字 | √                    |\n| db_mobilenet_v3_small                                        | √            | X         | cnocr        | 7.9 M        | 简体中文、繁体中文、英文、数字 | √                    |\n| db_resnet34                                                  | √            | X         | cnocr        | 86 M         | 简体中文、繁体中文、英文、数字 | √                    |\n| db_resnet18                                                  | √            | X         | cnocr        | 47 M         | 简体中文、繁体中文、英文、数字 | √                    |\n| ch_PP-OCRv5_det                                              | X            | √         | ppocr        | 4.6 M        | 简体中文、繁体中文、英文、数字 | √                    |\n| ch_PP-OCRv5_det_server                                       | X            | √         | ppocr        | 84 M        | 简体中文、繁体中文、英文、数字 | √                    |\n| ch_PP-OCRv4_det                                              | X            | √         | ppocr        | 4.5 M        | 简体中文、繁体中文、英文、数字 | √                    |\n| ch_PP-OCRv4_det_server                                       | X            | √         | ppocr        | 108 M        | 简体中文、繁体中文、英文、数字 | √                    |\n| ch_PP-OCRv3_det                                              | X            | √         | ppocr        | 2.3 M        | 简体中文、繁体中文、英文、数字 | √                    |\n| **en_PP-OCRv3_det**                                          | X            | √         | ppocr        | 2.3 M        | **英文**、数字                 | √                    |\n\n\n\n### 可使用的识别模型\n\n相比于 CnOCR V2.2.* 版本，**V2.3** 中的大部分模型都经过了重新训练和精调，精度比旧版模型更高。同时，加入了两个参数量更多的模型系列：\n\n  * `*-densenet_lite_246-gru_base`：优先供 **知识星球** [**CnOCR/CnSTD私享群**](https://t.zsxq.com/FEYZRJQ) 会员使用，后续会免费开源。\n  * `*-densenet_lite_666-gru_large`：**Pro 模型**，购买后可使用。购买链接见文档：\n\n**V2.3** 中的模型按使用场景可以分为以下几大类：\n\n* `scene`：场景图片，适合识别一般拍照图片中的文字。此类模型以 `scene-` 开头，如模型 `scene-densenet_lite_136-gru`。\n* `doc`：文档图片，适合识别规则文档的截图图片，如书籍扫描件等。此类模型以 `doc-` 开头，如模型 `doc-densenet_lite_136-gru`。\n* `number`：仅识别**纯数字**（只能识别 `0~9` 十个数字）图片，适合银行卡号、身份证号等场景。此类模型以 `number-` 开头，如模型 `number-densenet_lite_136-gru`。\n* `general`: 通用场景，适合图片无明显倾向的一般图片。此类模型无特定开头，与旧版模型名称保持一致，如模型 `densenet_lite_136-gru`。\n\n> 注意 ⚠️：以上说明仅供参考，具体选择模型时建议以实际效果为准。\n\n更多说明见：[可用模型](https://cnocr.readthedocs.io/zh-cn/stable/models/)。\n\n| `rec_model_name`                                             | PyTorch 版本 | ONNX 版本 | 模型原始来源 | 模型文件大小 | 支持语言                            | 是否支持竖排文字识别 |\n| ------------------------------------------------------------ | ------------ | --------- | ------------ | ------------ | ----------------------------------- | -------------------- |\n| **densenet_lite_136-gru** 🆕                                  | √            | √         | cnocr        | 12 M         | 简体中文、英文、数字                | X                    |\n| **scene-densenet_lite_136-gru** 🆕                            | √            | √         | cnocr        | 12 M         | 简体中文、英文、数字                | X                    |\n| **doc-densenet_lite_136-gru** 🆕                              | √            | √         | cnocr        | 12 M         | 简体中文、英文、数字                | X                    |\n| **densenet_lite_246-gru_base** 🆕 <br /> ([星球会员](https://t.zsxq.com/FEYZRJQ)专享) | √            | √         | cnocr        | 25 M         | 简体中文、英文、数字                | X                    |\n| **scene-densenet_lite_246-gru_base** 🆕 <br /> ([星球会员](https://t.zsxq.com/FEYZRJQ)专享) | √            | √         | cnocr        | 25 M         | 简体中文、英文、数字                | X                    |\n| **doc-densenet_lite_246-gru_base** 🆕 <br /> ([星球会员](https://t.zsxq.com/FEYZRJQ)专享) | √            | √         | cnocr        | 25 M         | 简体中文、英文、数字                | X                    |\n| **densenet_lite_666-gru_large** 🆕 <br />（购买链接：[B站](https://mall.bilibili.com/neul-next/detailuniversal/detail.html?isMerchant=1&page=detailuniversal_detail&saleType=10&itemsId=11884138&loadingShow=1&noTitleBar=1&msource=merchant_share)、[Lemon Squeezy](https://ocr.lemonsqueezy.com/)） | √            | √         | cnocr        | 82 M         | 简体中文、英文、数字                | X                    |\n| **scene-densenet_lite_666-gru_large** 🆕 <br />（购买链接：[B站](https://mall.bilibili.com/neul-next/detailuniversal/detail.html?isMerchant=1&page=detailuniversal_detail&saleType=10&itemsId=11883935&loadingShow=1&noTitleBar=1&msource=merchant_share)、[Lemon Squeezy](https://ocr.lemonsqueezy.com/)） | √            | √         | cnocr        | 82 M         | 简体中文、英文、数字                | X                    |\n| **doc-densenet_lite_666-gru_large** 🆕 <br />（购买链接：[B站](https://mall.bilibili.com/neul-next/detailuniversal/detail.html?isMerchant=1&page=detailuniversal_detail&saleType=10&itemsId=11883965&loadingShow=1&noTitleBar=1&msource=merchant_share)、[Lemon Squeezy](https://ocr.lemonsqueezy.com/)） | √            | √         | cnocr        | 82 M         | 简体中文、英文、数字                | X                    |\n| **number-densenet_lite_136-fc** 🆕                            | √            | √         | cnocr        | 2.7 M        | **纯数字**（仅包含 `0~9` 十个数字） | X                    |\n| **number-densenet_lite_136-gru**  🆕 <br /> ([星球会员](https://t.zsxq.com/FEYZRJQ)专享) | √            | √         | cnocr        | 5.5 M        | **纯数字**（仅包含 `0~9` 十个数字） | X                    |\n| **number-densenet_lite_666-gru_large** 🆕 <br />（购买链接：[B站](https://mall.bilibili.com/neul-next/detailuniversal/detail.html?isMerchant=1&page=detailuniversal_detail&saleType=10&itemsId=11884155&loadingShow=1&noTitleBar=1&msource=merchant_share)、[Lemon Squeezy](https://ocr.lemonsqueezy.com/)） | √            | √         | cnocr        | 55 M         | **纯数字**（仅包含 `0~9` 十个数字） | X                    |\n| ch_PP-OCRv5                                                  | X            | √         | ppocr        | 16 M         | 简体中文、英文、数字                | √                    |\n| ch_PP-OCRv5_server                                           | X            | √         | ppocr        | 81 M         | 简体中文、英文、数字                | √                    |\n| ch_PP-OCRv4                                                  | X            | √         | ppocr        | 10 M         | 简体中文、英文、数字                | √                    |\n| ch_PP-OCRv4_server                                           | X            | √         | ppocr        | 86 M         | 简体中文、英文、数字                | √                    |\n| ch_PP-OCRv3                                                  | X            | √         | ppocr        | 10 M         | 简体中文、英文、数字                | √                    |\n| ch_ppocr_mobile_v2.0                                         | X            | √         | ppocr        | 4.2 M        | 简体中文、英文、数字                | √                    |\n| en_PP-OCRv4                                                  | X            | √         | ppocr        | 8.6 M        | **英文**、数字                      | √                    |\n| en_PP-OCRv3                                                  | X            | √         | ppocr        | 8.5 M        | **英文**、数字                      | √                    |\n| en_number_mobile_v2.0                                        | X            | √         | ppocr        | 1.8 M        | **英文**、数字                      | √                    |\n| chinese_cht_PP-OCRv3                                         | X            | √         | ppocr        | 11 M         | **繁体中文**、英文、数字            | X                    |\n| japan_PP-OCRv3                                               | X            | √         | ppocr        | 9.6 M         | **日文**、英文、数字                | √                    |\n| korean_PP-OCRv3                                              | X            | √         | ppocr        | 9.4 M         | **韩文**、英文、数字                | √                    |\n| latin_PP-OCRv3                                               | X            | √         | ppocr        | 8.6 M         | **拉丁文**、英文、数字              | √                    |\n| arabic_PP-OCRv3                                              | X            | √         | ppocr        | 8.6 M         | **阿拉伯文**、英文、数字            | √                    |\n\n\n\n## 未来工作\n\n* [x] 支持图片包含多行文字 (`Done`)\n* [x] crnn模型支持可变长预测，提升灵活性 (since `V1.0.0`)\n* [x] 完善测试用例 (`Doing`)\n* [x] 修bugs（目前代码还比较凌乱。。） (`Doing`)\n* [x] 支持`空格`识别（since `V1.1.0`）\n* [x] 尝试新模型，如 DenseNet，进一步提升识别准确率（since `V1.1.0`）\n* [x] 优化训练集，去掉不合理的样本；在此基础上，重新训练各个模型\n* [x] 由 MXNet 改为 PyTorch 架构（since `V2.0.0`）\n* [x] 基于 PyTorch 训练更高效的模型\n* [x] 支持列格式的文字识别\n* [x] 打通与 [CnSTD](https://github.com/breezedeus/cnstd) 的无缝衔接（since `V2.2`）\n* [ ] 模型精度进一步优化\n* [ ] 支持更多的应用场景\n\n\n\n## 给作者来杯咖啡\n\n开源不易，如果此项目对您有帮助，可以考虑 [给作者加点油🥤，鼓鼓气💪🏻](https://cnocr.readthedocs.io/zh-cn/stable/buymeacoffee/) 。\n\n---\n\n官方代码库：[https://github.com/breezedeus/cnocr](https://github.com/breezedeus/cnocr)。",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "cnocr",
        "recognition",
        "text",
        "character recognition",
        "text recognition",
        "recognition chinese"
      ],
      "category": "image-and-video-generation"
    },
    "burningion--video-editing-mcp": {
      "owner": "burningion",
      "name": "video-editing-mcp",
      "url": "https://github.com/burningion/video-editing-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/burningion.webp",
      "description": "Upload, edit, search, and generate videos using large language models and Video Jungle's tools. The server enables interaction with videos through a custom URI scheme for managing individual videos and projects.",
      "stars": 214,
      "forks": 29,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-09-25T07:41:40Z",
      "readme_content": "# Video Editor MCP server\n\n[](https://www.video-jungle.com)\n\nSee a demo here: [https://www.youtube.com/watch?v=KG6TMLD8GmA](https://www.youtube.com/watch?v=KG6TMLD8GmA)\n\nUpload, edit, search, and generate videos from everyone's favorite LLM and [Video Jungle](https://www.video-jungle.com/).\n\nYou'll need to sign up for an account at [Video Jungle](https://app.video-jungle.com/register) in order to use this tool, and add your API key.\n\n[![PyPI version](https://badge.fury.io/py/video-editor-mcp.svg)](https://badge.fury.io/py/video-editor-mcp)\n\n## Components\n\n### Resources\n\nThe server implements an interface to upload, generate, and edit videos with:\n- Custom vj:// URI scheme for accessing individual videos and projects\n- Each project resource has a name, description\n- Search results are returned with metadata about what is in the video, and when, allowing for edit generation directly\n\n### Prompts\n\nComing soon.\n\n### Tools\n\nThe server implements a few tools:\n- add-video\n  - Add a Video File for analysis from a URL. Returns an vj:// URI to reference the Video file\n- create-videojungle-project\n  - Creates a Video Jungle project to contain generative scripts, analyzed videos, and images for video edit generation\n- edit-locally\n  - Creates an OpenTimelineIO project and downloads it to your machine to open in a Davinci Resolve Studio instance (Resolve Studio _must_ already be running before calling this tool.) \n- generate-edit-from-videos\n  - Generates a rendered video edit from a set of video files\n- generate-edit-from-single-video\n  - Generate an edit from a single input video file\n- get-project-assets\n  - Get assets within a project for video edit generation.\n- search-videos\n  - Returns video matches based upon embeddings and keywords\n- update-video-edit\n  - Live update a video edit's information. If Video Jungle is open, edit will be updated in real time.\n\n### Using Tools in Practice\n\nIn order to use the tools, you'll need to sign up for Video Jungle and add your API key.\n\n**add-video**\n\nHere's an example prompt to invoke the `add-video` tool:\n\n```\ncan you download the video at https://www.youtube.com/shorts/RumgYaH5XYw and name it fly traps?\n```\n\nThis will download a video from a URL, add it to your library, and analyze it for retrieval later. Analysis is multi-modal, so both audio and visual components can be queried against.\n\n**search-videos**\n\nOnce you've got a video downloaded and analyzed, you can then do queries on it using the `search-videos` tool:\n\n```\ncan you search my videos for fly traps?\n```\n\nSearch results contain relevant metadata for generating a video edit according to details discovered in the initial analysis.\n\n**search-local-videos**\n\nYou must set the environment variable `LOAD_PHOTOS_DB=1` in order to use this tool, as it will make Claude prompt to access your files on your local machine.\n\nOnce that's done, you can search through your Photos app for videos that exist on your phone, using Apple's tags.\n\nIn my case, when I search for \"Skateboard\", I get 1903 video files.\n\n```\ncan you search my local video files for Skateboard?\n```\n\n**generate-edit-from-videos**\n\nFinally, you can use these search results to generate an edit:\n\n```\ncan you create an edit of all the times the video says \"fly trap\"?\n```\n\n(Currently), the video edits tool relies on the context within the current chat. \n\n**generate-edit-from-single-video**\n\nFinally, you can cut down an edit from a single, existing video:\n\n```\ncan you create an edit of all the times this video says the word \"fly trap\"?\n```\n\n## Configuration\n\nYou must login to [Video Jungle settings](https://app.video-jungle.com/profile/settings), and get your [API key](https://app.video-jungle.com/profile/settings). Then, use this to start Video Jungle MCP:\n\n```bash\n$ uv run video-editor-mcp YOURAPIKEY\n```\n\nTo allow this MCP server to search your Photos app on MacOS:\n\n```\n$ LOAD_PHOTOS_DB=1 uv run video-editor-mcp YOURAPIKEY\n```\n## Quickstart\n\n### Install\n\n#### Installing via Smithery\n\nTo install Video Editor for Claude Desktop automatically via [Smithery](https://smithery.ai/server/video-editor-mcp):\n\n```bash\nnpx -y @smithery/cli install video-editor-mcp --client claude\n```\n\n#### Claude Desktop\n\nYou'll need to adjust your `claude_desktop_config.json` manually:\n\nOn MacOS: `~/Library/Application\\ Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n<details>\n<details>\n  <summary>Published Server Configuration</summary>\n  \n ```json\n  \"mcpServers\": {\n    \"video-editor-mcp\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"video-editor-mcp\",\n        \"YOURAPIKEY\"\n      ]\n    }\n  }\n  ```\n</details>\n  <summary>Development/Unpublished Servers Configuration</summary>\n  \n ```json\n  \"mcpServers\": {\n    \"video-editor-mcp\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/Users/YOURDIRECTORY/video-editor-mcp\",\n        \"run\",\n        \"video-editor-mcp\",\n        \"YOURAPIKEY\"\n      ]\n    }\n  }\n  ```\n\n  With local Photos app access enabled (search your Photos app):\n\n  ```json\n    \"video-jungle-mcp\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/Users/<PATH_TO>/video-jungle-mcp\",\n        \"run\",\n        \"video-editor-mcp\",\n        \"<YOURAPIKEY>\"\n      ],\n     \"env\": {\n\t      \"LOAD_PHOTOS_DB\": \"1\"\n      }\n    },\n  ```\n\n</details>\n\nBe sure to replace the directories with the directories you've placed the repository in on **your** computer.\n\n## Development\n\n### Building and Publishing\n\nTo prepare the package for distribution:\n\n1. Sync dependencies and update lockfile:\n```bash\nuv sync\n```\n\n2. Build package distributions:\n```bash\nuv build\n```\n\nThis will create source and wheel distributions in the `dist/` directory.\n\n3. Publish to PyPI:\n```bash\nuv publish\n```\n\nNote: You'll need to set PyPI credentials via environment variables or command flags:\n- Token: `--token` or `UV_PUBLISH_TOKEN`\n- Or username/password: `--username`/`UV_PUBLISH_USERNAME` and `--password`/`UV_PUBLISH_PASSWORD`\n\n### MCP Server Registry\n\n```\nmcp-name: io.github.burningion/video-editing-mcp\n```\n\n### Debugging\n\nSince MCP servers run over stdio, debugging can be challenging. For the best debugging\nexperience, we strongly recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector).\n\n\nYou can launch the MCP Inspector via [`npm`](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm) with this command:\n\n(Be sure to replace `YOURDIRECTORY` and `YOURAPIKEY` with the directory this repo is in, and your Video Jungle API key, found in the settings page.)\n\n```bash\nnpx @modelcontextprotocol/inspector uv run --directory /Users/YOURDIRECTORY/video-editor-mcp video-editor-mcp YOURAPIKEY\n```\n\n\nUpon launching, the Inspector will display a URL that you can access in your browser to begin debugging.\n\nAdditionally, I've added logging to `app.log` in the project directory. You can add logging to diagnose API calls via a:\n\n```\nlogging.info(\"this is a test log\")\n```\n\nA reasonable way to follow along as you're workin on the project is to open a terminal session and do a:\n\n```bash\n$ tail -n 90 -f app.log\n```",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "videos",
        "editing",
        "upload",
        "video generation",
        "generate videos",
        "video editing"
      ],
      "category": "image-and-video-generation"
    },
    "bytefer--mcp-flux-schnell": {
      "owner": "bytefer",
      "name": "mcp-flux-schnell",
      "url": "https://github.com/bytefer/mcp-flux-schnell",
      "imageUrl": "/freedevtools/mcp/pfp/bytefer.webp",
      "description": "Generate images from text descriptions using the Flux Schnell model through an MCP interface. This server connects with Cloudflare's Flux Schnell worker API to deliver image generation capabilities.",
      "stars": 5,
      "forks": 3,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-04-20T04:32:23Z",
      "readme_content": "# mcp-flux-schnell MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@bytefer/mcp-flux-schnell)](https://smithery.ai/server/@bytefer/mcp-flux-schnell)\n\nA TypeScript-based MCP server that implements a text-to-image generation tool using the Flux Schnell model. This server integrates with Cloudflare's Flux Schnell worker API to provide image generation capabilities through MCP.\n\n- [Creating your own Flux Schnell MCP Server is so easy! — Part 1](https://medium.com/@bytefer/creating-your-own-flux-schnell-mcp-server-is-so-easy-part-1-4b9a5b3fb14f)\n- [Creating your own Flux Schnell MCP Server is so easy! — Part 2](https://medium.com/@bytefer/creating-your-own-flux-schnell-mcp-server-is-so-easy-part-2-bd711836a493)\n\n## Features\n\n### Tools\n- `generate_image` - Generate images from text descriptions\n  - Takes a text prompt as input (1-2048 characters)\n  - Returns the path to the generated image file\n\n## Environment Variables\n\nThe following environment variables must be configured:\n\n- `FLUX_API_URL` - The URL of the Flux Schnell API endpoint\n- `FLUX_API_TOKEN` - Your authentication token for the Flux Schnell API\n- `WORKING_DIR` (optional) - Directory where generated images will be saved (defaults to current working directory)\n\n## Development\n\nInstall dependencies:\n```bash\nnpm install\n# or\npnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n# or\npnpm build\n```\n\n## Installation\n\n### Installing via Smithery\n\nTo install Flux Schnell Image Generator for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@bytefer/mcp-flux-schnell):\n\n```bash\nnpx -y @smithery/cli install @bytefer/mcp-flux-schnell --client claude\n```\n\n### Cursor Configuration\n\nThere are two ways to configure the MCP server in Cursor:\n\n#### Project Configuration\n\nFor tools specific to a project, create a `.cursor/mcp.json` file in your project directory:\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-flux-schnell\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/mcp-flux-schnell/build/index.js\"],\n      \"env\": {\n        \"FLUX_API_URL\": \"your flux api url\",\n        \"FLUX_API_TOKEN\": \"your flux api token\",\n        \"WORKING_DIR\": \"your working directory\"\n      }\n    }\n  }\n}\n```\n\nThis configuration will only be available within the specific project.\n\n#### Global Configuration\n\nFor tools that you want to use across all projects, create a `~/.cursor/mcp.json` file in your home directory with the same configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-flux-schnell\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/mcp-flux-schnell/build/index.js\"],\n      \"env\": {\n        \"FLUX_API_URL\": \"your flux api url\",\n        \"FLUX_API_TOKEN\": \"your flux api token\",\n        \"WORKING_DIR\": \"your working directory\"\n      }\n    }\n  }\n}\n```\n\nThis makes the MCP server available in all your Cursor workspaces.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "flux",
        "images",
        "bytefer",
        "flux schnell",
        "mcp flux",
        "image generation"
      ],
      "category": "image-and-video-generation"
    },
    "c-rick--jimeng-mcp": {
      "owner": "c-rick",
      "name": "jimeng-mcp",
      "url": "https://github.com/c-rick/jimeng-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/c-rick.webp",
      "description": "Integrates with the Jimeng AI service to generate images from text prompts. Supports customization of image parameters such as size, quality, and negative prompts without the need for third-party APIs.",
      "stars": 40,
      "forks": 12,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-09-18T10:20:11Z",
      "readme_content": "# Jimeng MCP 服务器\n\n\n使用TypeScript实现的Model Context Protocol (MCP) 服务器项目，集成了即梦AI图像生成服务，通过逆向工程直接调用即梦官方API。\n\n\n## 功能\n\n- 基于TypeScript构建\n- 使用tsup作为构建工具\n- 实现了MCP协议，支持标准的stdio通信\n- 直接调用即梦AI图像生成服务，无需第三方API\n- 提供多种即梦模型的图像生成工具\n- 支持多种图像参数调整，如尺寸、精细度、负面提示词等\n- 支持图片混合/参考图生成（通过filePath参数，支持本地图片和网络图片）\n- 支持视频生成，支持添加参考图片（首尾帧通过filePath参数设置）\n\n## 安装\n\n### 通过Smithery安装\n\n要通过 [Smithery](https://smithery.ai/server/@c-rick/jimeng-mcp) 自动为Claude Desktop安装jimeng-mcp，请执行以下命令：\n\n```bash\nnpx -y @smithery/cli install @c-rick/jimeng-mcp --client claude\n```\n\n### 手动安装\n```bash\n# 使用yarn安装依赖\nyarn install\n\n# 或使用npm安装依赖\nnpm install\n```\n\n## 环境配置\n\n在MCP客户端配置（如Claude Desktop）中设置以下环境变量：\n\n进入[Smithery托管项目](https://smithery.ai/server/@c-rick/jimeng-mcp)，点击json, 填入JIMENG_API_TOKEN， 点击connect, 生成下面mcpServers config json\n\n```json\n{\n  \"mcpServers\": {\n    \"jimeng-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@smithery/cli@latest\",\n        \"run\",\n        \"@c-rick/jimeng-mcp\",\n        \"--key\",\n        \"[Smithery生成]\",\n        \"--profile\",\n        \"[Smithery生成]\"\n      ]\n    }\n  }\n}\n```\n\n### 获取JIMENG_API_TOKEN\n\n1. 访问 [即梦AI官网](https://jimeng.jianying.com) 并登录账号\n2. 按F12打开浏览器开发者工具\n3. 在Application > Cookies中找到`sessionid`的值\n4. 将找到的sessionid值配置为JIMENG_API_TOKEN环境变量\n\n## 开发\n\n```bash\n# 开发模式运行\nyarn dev\n\n# 使用nodemon开发并自动重启\nyarn start:dev\n```\n\n## 构建\n\n```bash\n# 构建项目\nyarn build\n```\n\n## 运行\n\n```bash\n# 启动服务器\nyarn start\n\n# 测试MCP服务器\nyarn test\n```\n\n## Claude Desktop 配置示例\n\n以下是在Claude Desktop中配置此MCP服务器的完整示例:\n\n```json\n{\n  \"mcpServers\": {\n    \"jimeng\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/jimeng-mcp/lib/index.js\"],\n      \"env\": {\n        \"JIMENG_API_TOKEN\": \"your_jimeng_session_id_here\"\n      }\n    }\n  }\n}\n```\n\n## 即梦AI图像生成\n\n本MCP服务器直接调用即梦AI图像生成API，提供图像生成工具：\n\n`generateImage` - 提交图像生成请求并返回图像URL列表\n- 参数：\n  - `prompt`：生成图像的文本描述（必填）\n  - `filePath`：本地图片路径或图片URL（可选，若填写则为图片混合/参考图生成功能）\n  - `model`：模型名称，可选值: jimeng-3.0, jimeng-2.1, jimeng-2.0-pro, jimeng-2.0, jimeng-1.4, jimeng-xl-pro（可选，默认为jimeng-2.1，图片混合时自动切换为jimeng-2.0-pro）\n  - `width`：图像宽度，默认值：1024（可选）\n  - `height`：图像高度，默认值：1024（可选）\n  - `sample_strength`：精细度，默认值：0.5，范围0-1（可选）\n  - `negative_prompt`：反向提示词，告诉模型不要生成什么内容（可选）\n\n> **注意：**\n> - `filePath` 支持本地绝对/相对路径和图片URL。\n> - 若指定 `filePath`，将自动进入图片混合/参考图生成模式，底层模型自动切换为 `jimeng-2.0-pro`。\n> - 网络图片需保证可公开访问。\n\n### 图片混合/参考图生成功能\n\n如需基于图片进行混合生成，只需传入`filePath`参数（支持本地路径或图片URL），即可实现图片风格融合、参考图生成等高级玩法。\n\n#### 示例：\n\n```javascript\n// 参考图片混合生成\nclient.callTool({\n  name: \"generateImage\",\n  arguments: {\n    prompt: \"梵高风格的猫\",\n    filePath: \"./test.png\", // 本地图片路径\n    sample_strength: 0.6\n  }\n});\n```\n\n或\n\n```javascript\n// 使用网络图片作为参考\nclient.callTool({\n  name: \"generateImage\",\n  arguments: {\n    prompt: \"未来城市\",\n    filePath: \"https://example.com/your-image.png\"\n  }\n});\n```\n\n### 支持的模型\n\n服务器支持以下即梦AI模型：\n\n- 图片模型\n- `jimeng-3.1`：即梦第三代模型，丰富的美学多样性，画面更鲜明生动 （默认）\n- `jimeng-3.0`：即梦第三代模型，效果更好，支持更强的图像生成能力\n- `jimeng-2.1`：即梦2.1版本模型，默认模型\n- `jimeng-2.0-pro`：即梦2.0 Pro版本\n- `jimeng-2.0`：即梦2.0标准版本\n- `jimeng-1.4`：即梦1.4版本\n- `jimeng-xl-pro`：即梦XL Pro特殊版本\n- 视频模型\n- `jimeng-video-3.0-pro`：即梦视频3.0 Pro模型，适合高质量视频生成\n- `jimeng-video-3.0`：即梦视频3.0标准模型，主力视频生成模型（默认）\n- `jimeng-video-2.0-pro`：即梦视频2.0 Pro模型，兼容性好，适合多场景\n- `jimeng-video-2.0`：即梦视频2.0标准模型，适合基础视频生成\n\n### 技术实现\n\n- 直接调用即梦官方API，无需第三方服务\n- 逆向工程API调用流程，实现完整的图像生成过程\n- 支持积分自动领取和使用\n- 基于面向对象设计，将API实现封装为类\n- 返回高质量图像URL列表\n- 支持图片上传，自动处理本地/网络图片，自动切换混合模型\n- 图片混合时自动上传图片到即梦云端，流程全自动\n\n### 使用示例\n\n通过MCP协议调用图像生成功能：\n\n```javascript\n// 生成图像（文本生成）\nclient.callTool({\n  name: \"generateImage\",\n  arguments: {\n    prompt: \"一只可爱的猫咪在草地上\",\n    model: \"jimeng-3.0\",\n    width: 1024,\n    height: 1024,\n    sample_strength: 0.7,\n    negative_prompt: \"模糊，扭曲，低质量\"\n  }\n});\n\n// 生成图像（图片混合/参考图生成）\nclient.callTool({\n  name: \"generateImage\",\n  arguments: {\n    prompt: \"未来城市\",\n    filePath: \"https://example.com/your-image.png\"\n  }\n});\n```\n\n## 响应格式\n\nAPI将返回生成的图像URL数组，可以直接在各类客户端中显示：\n\n```javascript\n[\n  \"https://example.com/generated-image-1.jpg\",\n  \"https://example.com/generated-image-2.jpg\",\n  \"https://example.com/generated-image-3.jpg\",\n  \"https://example.com/generated-image-4.jpg\"\n]\n```\n\n## 资源\n\n服务器还提供了以下信息资源：\n\n- `greeting://{name}` - 提供个性化问候\n- `info://server` - 提供服务器基本信息\n- `jimeng-ai://info` - 提供即梦AI图像生成服务的使用说明\n\n## Cursor或Claude使用提示\n\n在Cursor或Claude中，你可以这样使用Jimeng图像生成服务：\n\n1. 确保已经配置了MCP服务器\n2. 提示Claude/Cursor生成图像，例如：\n   ```\n   请生成一张写实风格的日落下的山脉图片\n   ```\n3. Claude/Cursor会调用Jimeng MCP服务器生成图像并显示\n\n## 常见问题\n\n1. **图像生成失败**\n   - 检查JIMENG_API_TOKEN是否正确配置\n   - 登录即梦官网检查账号积分是否充足\n   - 尝试更换提示词，避免敏感内容\n   - 若为图片混合，检查filePath路径/URL是否有效、图片是否可访问\n   - 网络图片建议使用https直链，避免防盗链/权限问题\n\n2. **服务器无法启动**\n   - 确保已安装所有依赖\n   - 确保环境变量正确设置\n   - 检查Node.js版本是否为14.0或更高\n\n## 许可证\n\nMIT \n\n## 即梦AI视频生成\n\n本MCP服务器集成了即梦AI视频生成API，提供视频生成工具：\n\n`generateVideo` - 提交视频生成请求并返回视频URL\n- 参数：\n  - `prompt`：生成视频的文本描述（必填）\n  - `filePath`：首帧和尾帧图片路径，支持数组，最多2个元素，分别为首帧和尾帧（可选）\n  - `model`：模型名称，默认jimeng-video-3.0（可选）\n  - `resolution`：分辨率，可选720p或1080p，默认720p（可选）\n  - `width`：视频宽度，默认值：1024（可选）\n  - `height`：视频高度，默认值：1024（可选）\n  - `refresh_token`：即梦API令牌（可选，通常从环境变量读取）\n  - `req_key`：自定义参数，兼容旧接口（可选）\n\n> **注意：**\n> - `filePath` 支持本地绝对/相对路径和图片URL。\n> - 若指定 `filePath`，可实现首帧/尾帧定制的视频生成。\n> - 网络图片需保证可公开访问。\n\n### 使用示例\n\n通过MCP协议调用视频生成功能：\n\n```javascript\n// 生成视频（文本生成）\nclient.callTool({\n  name: \"generateVideo\",\n  arguments: {\n    prompt: \"一只小狗在草地上奔跑，阳光明媚，高清\",\n    model: \"jimeng-video-3.0\",\n    resolution: \"720p\",\n    width: 1024,\n    height: 1024\n  }\n});\n\n// 生成视频（首帧/尾帧定制）\nclient.callTool({\n  name: \"generateVideo\",\n  arguments: {\n    prompt: \"城市夜景延时摄影\",\n    filePath: [\"./first.png\", \"./last.png\"],\n    resolution: \"1080p\"\n  }\n});\n```\n\n## 视频响应格式\n\nAPI将返回生成的视频URL字符串，可以直接在各类客户端中播放：\n\n```javascript\n\"https://example.com/generated-video.mp4\"\n``` \n\n\n## 支持api服务启动\n\n如需以API服务方式启动（适合HTTP接口调用）：\n\n```bash\ncp .env.example .env   # 复制环境变量模板\n# 根据需要编辑.env，填写JIMENG_API_TOKEN等配置\n\n# 启动API服务\nyarn start:api\n```\n\nAPI服务启动后将监听配置端口，支持通过HTTP接口调用即梦AI图像和视频生成功能。 \n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "jimeng",
        "mcp",
        "images",
        "generate images",
        "jimeng mcp",
        "jimeng ai"
      ],
      "category": "image-and-video-generation"
    },
    "catalystneuro--mcp_read_images": {
      "owner": "catalystneuro",
      "name": "mcp_read_images",
      "url": "https://github.com/catalystneuro/mcp_read_images",
      "imageUrl": "/freedevtools/mcp/pfp/catalystneuro.webp",
      "description": "Analyze images using OpenRouter vision models like Claude-3.5-sonnet and Claude-3-opus through a simple API interface.",
      "stars": 8,
      "forks": 2,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-07-14T12:27:13Z",
      "readme_content": "# MCP Read Images\n\nAn MCP server for analyzing images using OpenRouter vision models. This server provides a simple interface to analyze images using various vision models like Claude-3.5-sonnet and Claude-3-opus through the OpenRouter API.\n\n## Installation\n\n```bash\nnpm install @catalystneuro/mcp_read_images\n```\n\n## Configuration\n\nThe server requires an OpenRouter API key. You can get one from [OpenRouter](https://openrouter.ai/keys).\n\nAdd the server to your MCP settings file (usually located at `~/Library/Application Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json` for VSCode):\n\n```json\n{\n  \"mcpServers\": {\n    \"read_images\": {\n      \"command\": \"read_images\",\n      \"env\": {\n        \"OPENROUTER_API_KEY\": \"your-api-key-here\",\n        \"OPENROUTER_MODEL\": \"anthropic/claude-3.5-sonnet\"  // optional, defaults to claude-3.5-sonnet\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\n## Usage\n\nThe server provides a single tool `analyze_image` that can be used to analyze images:\n\n```typescript\n// Basic usage with default model\nuse_mcp_tool({\n  server_name: \"read_images\",\n  tool_name: \"analyze_image\",\n  arguments: {\n    image_path: \"/path/to/image.jpg\",\n    question: \"What do you see in this image?\"  // optional\n  }\n});\n\n// Using a specific model for this call\nuse_mcp_tool({\n  server_name: \"read_images\",\n  tool_name: \"analyze_image\",\n  arguments: {\n    image_path: \"/path/to/image.jpg\",\n    question: \"What do you see in this image?\",\n    model: \"anthropic/claude-3-opus-20240229\"  // overrides default and settings\n  }\n});\n```\n\n### Model Selection\n\nThe model is selected in the following order of precedence:\n1. Model specified in the tool call (`model` argument)\n2. Model specified in MCP settings (`OPENROUTER_MODEL` environment variable)\n3. Default model (anthropic/claude-3.5-sonnet)\n\n### Supported Models\n\nThe following OpenRouter models have been tested:\n- anthropic/claude-3.5-sonnet\n- anthropic/claude-3-opus-20240229\n\n## Features\n\n- Automatic image resizing and optimization\n- Configurable model selection\n- Support for custom questions about images\n- Detailed error messages\n- Automatic JPEG conversion and quality optimization\n\n## Error Handling\n\nThe server handles various error cases:\n- Invalid image paths\n- Missing API keys\n- Network errors\n- Invalid model selections\n- Image processing errors\n\nEach error will return a descriptive message to help diagnose the issue.\n\n## Development\n\nTo build from source:\n\n```bash\ngit clone https://github.com/catalystneuro/mcp_read_images.git\ncd mcp_read_images\nnpm install\nnpm run build\n```\n\n## License\n\nMIT License. See [LICENSE](LICENSE) for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcp_read_images",
        "catalystneuro",
        "vision",
        "catalystneuro mcp_read_images",
        "mcp_read_images analyze",
        "analyze images"
      ],
      "category": "image-and-video-generation"
    },
    "champierre--image-mcp-server": {
      "owner": "champierre",
      "name": "image-mcp-server",
      "url": "https://github.com/champierre/image-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/champierre.webp",
      "description": "Analyzes images by accepting URLs or local file paths, providing detailed insights through advanced image recognition powered by the GPT-4o-mini model. Validates image URLs and supports loading images from local files and Base64 encoding.",
      "stars": 6,
      "forks": 5,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-08-09T18:23:14Z",
      "readme_content": "# image-mcp-server\n\n[日本語の README](README.ja.md)\n\n<a href=\"https://glama.ai/mcp/servers/@champierre/image-mcp-server\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@champierre/image-mcp-server/badge\" alt=\"Image Analysis MCP Server\" />\n</a>\n\n[![smithery badge](https://smithery.ai/badge/@champierre/image-mcp-server)](https://smithery.ai/server/@champierre/image-mcp-server)\nAn MCP server that receives image URLs or local file paths and analyzes image content using the GPT-4o-mini model.\n\n## Features\n\n- Receives image URLs or local file paths as input and provides detailed analysis of the image content\n- High-precision image recognition and description using the GPT-4o-mini model\n- Image URL validity checking\n- Image loading from local files and Base64 encoding\n\n## Installation\n\n### Installing via Smithery\n\nTo install Image Analysis Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@champierre/image-mcp-server):\n\n```bash\nnpx -y @smithery/cli install @champierre/image-mcp-server --client claude\n```\n\n### Manual Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/champierre/image-mcp-server.git # or your forked repository\ncd image-mcp-server\n\n# Install dependencies\nnpm install\n\n# Compile TypeScript\nnpm run build\n```\n\n## Configuration\n\nTo use this server, you need an OpenAI API key. Set the following environment variable:\n\n```\nOPENAI_API_KEY=your_openai_api_key\n```\n\n## MCP Server Configuration\n\nTo use with tools like Cline, add the following settings to your MCP server configuration file:\n\n### For Cline\n\nAdd the following to `cline_mcp_settings.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"image-analysis\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/image-mcp-server/dist/index.js\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"your_openai_api_key\"\n      }\n    }\n  }\n}\n```\n\n### For Claude Desktop App\n\nAdd the following to `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"image-analysis\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/image-mcp-server/dist/index.js\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"your_openai_api_key\"\n      }\n    }\n  }\n}\n```\n\n## Usage\n\nOnce the MCP server is configured, the following tools become available:\n\n- `analyze_image`: Receives an image URL and analyzes its content.\n- `analyze_image_from_path`: Receives a local file path and analyzes its content.\n\n### Usage Examples\n\n**Analyzing from URL:**\n\n```\nPlease analyze this image URL: https://example.com/image.jpg\n```\n\n**Analyzing from local file path:**\n\n```\nPlease analyze this image: /path/to/your/image.jpg\n```\n\n### Note: Specifying Local File Paths\n\nWhen using the `analyze_image_from_path` tool, the AI assistant (client) must specify a **valid file path in the environment where this server is running**.\n\n- **If the server is running on WSL:**\n  - If the AI assistant has a Windows path (e.g., `C:\\...`), it needs to convert it to a WSL path (e.g., `/mnt/c/...`) before passing it to the tool.\n  - If the AI assistant has a WSL path, it can pass it as is.\n- **If the server is running on Windows:**\n  - If the AI assistant has a WSL path (e.g., `/home/user/...`), it needs to convert it to a UNC path (e.g., `\\\\wsl$\\Distro\\...`) before passing it to the tool.\n  - If the AI assistant has a Windows path, it can pass it as is.\n\n**Path conversion is the responsibility of the AI assistant (or its execution environment).** The server will try to interpret the received path as is.\n\n### Note: Type Errors During Build\n\nWhen running `npm run build`, you may see an error (TS7016) about missing TypeScript type definitions for the `mime-types` module.\n\n```\nsrc/index.ts:16:23 - error TS7016: Could not find a declaration file for module 'mime-types'. ...\n```\n\nThis is a type checking error, and since the JavaScript compilation itself succeeds, it **does not affect the server's execution**. If you want to resolve this error, install the type definition file as a development dependency.\n\n```bash\nnpm install --save-dev @types/mime-types\n# or\nyarn add --dev @types/mime-types\n```\n\n## Development\n\n```bash\n# Run in development mode\nnpm run dev\n```\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "images",
        "image",
        "encoding",
        "image mcp",
        "image urls",
        "analyzes images"
      ],
      "category": "image-and-video-generation"
    },
    "chenyeju295--mcp_generate_images": {
      "owner": "chenyeju295",
      "name": "mcp_generate_images",
      "url": "https://github.com/chenyeju295/mcp_generate_images",
      "imageUrl": "/freedevtools/mcp/pfp/chenyeju295.webp",
      "description": "An image generation service that integrates with Cursor IDE, offering features such as customizable image aspect ratios, high-quality image generation, and batch processing capabilities.",
      "stars": 21,
      "forks": 3,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-08-29T07:27:23Z",
      "readme_content": "# AI 图像生成服务\n\n基于火山引擎（抖音豆包）的图像生成服务，专门设计用于与 Cursor MCP 服务集成。支持自定义图片宽高比、保存路径等功能，提供高质量图像生成能力。\n\n## 功能特点\n\n- 支持高质量图像生成\n- 多种常见宽高比支持（1:1、4:3、16:9、3:4、9:16）\n- 火山引擎豆包模型（doubao-seedream-3-0-t2i-250415）\n- 自动重试和详细错误处理\n- 完整的路径和权限验证\n- 详细的错误提示和日志\n- 异步处理支持\n\n## 环境准备\n\n### 1. Python 环境\n\n- Python 3.10+\n- 下载地址： <https://www.python.org/downloads/>\n\n- 推荐使用 pyenv 管理 Python 版本：\n\n```bash\n# macOS 安装 pyenv\nbrew install pyenv\n\n# 安装 Python\npyenv install 3.13.2\npyenv global 3.13.2\n```\n\n### 2. Nodejs 环境\n\n- 下载地址： <https://nodejs.org/zh-cn>  \n\n### 3. uv 包管理工具\n\nuv 是一个快速的 Python 包管理器，需要先安装：\n\n```bash\n# macOS 安装 uv\nbrew install uv\n\n# 或者使用 pip 安装\npip install uv\n```\n\n### 4. 火山引擎 API 密钥\n\n1. 访问 [火山引擎方舟大模型服务](https://console.volcengine.com/ark)\n2. 注册/登录账号\n3. 创建新的 API 密钥\n4. 复制密钥并保存，格式如：`YOUR_API_KEY`\n\n### 5. Cursor\n\n- 下载并安装 [Cursor IDE](https://cursor.sh/)\n- 确保 Cursor 已正确配置 Python 环境\n\n## 安装配置\n\n### 1. 克隆项目\n\n```bash\ngit clone https://github.com/chenyeju295/mcp_generate_images.git\ncd mcp_generate_images\n```\n\n### 2. 安装依赖(cd 到mcp_generate_images 安装)\n \n```bash\npython3 -m pip install fastmcp requests 'volcengine-python-sdk[ark]'\n```\n\n或者使用requirements.txt文件：\n\n```bash\npip install -r requirements.txt\n```\n\n出现证书问题可以使用：\n\n```bash\npython3 -m pip install fastmcp requests 'volcengine-python-sdk[ark]' --trusted-host pypi.org --trusted-host files.pythonhosted.org --upgrade --force-reinstall --no-cache-dir\n```\n\ntips: 需确保安装成功，否则配置MCP 服务会报红。\n\n### 3. 配置 API 密钥\n\n设置环境变量（推荐方式）：\n\n```bash\nexport ARK_API_KEY=your_api_key_here\n```\n\n或者在 ~/.bashrc 或 ~/.zshrc 中添加：\n\n```bash\necho 'export ARK_API_KEY=your_api_key_here' >> ~/.zshrc\nsource ~/.zshrc\n```\n\n验证环境变量已设置：\n\n```bash\necho $ARK_API_KEY\n```\n\n### 4. 配置服务\n\n在 `mcp_server.py` 中可以修改以下配置：\n\n```python\nCONFIG = {\n    \"api\": {\n        \"base_url\": \"https://ark.cn-beijing.volces.com/api/v3\",\n        \"model\": \"doubao-seedream-3-0-t2i-250415\",\n        \"timeout\": 120,\n        \"max_retries\": 3,\n        \"retry_delay\": 5\n    },\n    \"image\": {\n        \"max_width\": 1024,   \n        \"max_height\": 1024, \n        \"default_width\": 1024,\n        \"default_height\": 1024,\n        \"max_batch_size\": 1\n    },\n    \"output\": {\n        \"base_folder\": \"你的默认保存路径\",\n        \"allowed_extensions\": [\".png\", \".jpg\", \".jpeg\"],\n        \"default_extension\": \".png\"\n    }\n}\n```\n\n## 运行服务\n\n开发模式运行（带调试界面）：\n\n```bash\nuv run --with fastmcp fastmcp dev /Users/username/Documents/mcp_generate_images/mcp_server.py\n```\n\n## 在 Cursor 中使用\n \n### 1. 在 Cursor 中引入 MCP 服务\n\n在 Cursor 的 MCP 配置中添加：\n\n```json\n{\n  \"mcpServers\": {\n    \"generate_images\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"run\",\n        \"--with\",\n        \"fastmcp\",\n        \"fastmcp\",\n        \"run\",\n        \"/Users/chenyeju/Documents/github/mcp_generate_images/mcp_server.py\"\n      ]\n    } \n  }\n}\n```\n\n### 3. 服务运行成功示例\n\n\n\n### 4. 在 Cursor Composer 的 agent 模式下使用\n\n\n\n## 参数说明\n\n图像生成工具支持以下参数：\n\n| 参数名 | 类型 | 必填 | 说明 |\n|-------|------|------|------|\n| prompt | 字符串 | 是 | 图片生成提示词，建议不超过500字符 |\n| file_name | 字符串 | 是 | 保存的文件名(不含路径，如果没有后缀则默认使用.png) |\n| save_folder | 字符串 | 是 | 保存目录的绝对路径 |\n| aspect_ratio | 字符串 | 否 | 图片的宽高比，支持 '1:1', '4:3', '16:9', '3:4', '9:16'。默认为'1:1' |\n\n\n## 使用示例\n\n```\n生成一张宽高比为16:9的风景图片：\n\ngenerate_image(\n  prompt=\"A beautiful mountain landscape with sunset\", \n  file_name=\"landscape.png\", \n  save_folder=\"/Users/username/Documents/images\", \n  aspect_ratio=\"16:9\"\n)\n```\n\n## 使用注意事项\n\n1. **模型**：使用火山引擎豆包模型（doubao-seedream-3-0-t2i-250415），支持最大1024x1024的尺寸。\n2. **长宽比**：建议使用1:1的宽高比（正方形图片），例如512x512或1024x1024，以获得最佳效果和生成速度。\n3. **提示词**：简洁明了的提示词通常能获得更好的结果，尽量不超过500字符。支持中文提示词。\n4. **超时问题**：对于复杂提示词或非正方形图片，生成可能需要更长时间，有时会导致超时错误。\n5. **API限制**：火山引擎API每次只生成一张图片，相比之前的批量生成有所不同。\n\n## 错误排查\n\n如果遇到问题，请检查：\n\n1. 服务是否正常运行\n2. 保存路径是否正确（必须是绝对路径）\n3. 目录权限是否正确\n4. 网络连接是否正常\n5. API 密钥是否有效\n6. Python 环境是否正确配置\n7. uv 是否正确安装\n8. 依赖包是否完整安装\n\n## 常见错误及解决方案\n\n| 错误信息 | 可能原因 | 解决方案 |\n|---------|---------|---------|\n| \"未能生成图片: API 请求超时\" | 网络问题或请求耗时过长 | 使用更简单的提示词，检查网络连接 |\n| \"未能生成图片: API 调用频率受限\" | 火山引擎API频率限制 | 等待几分钟后再试 |\n| \"未能生成图片: API 认证失败\" | API密钥无效 | 检查并更新火山引擎API密钥 |\n| \"没有权限保存图片到...\" | 目录权限问题 | 确保目录存在且有写入权限 |\n| \"不支持的宽高比\" | 使用了不支持的宽高比 | 使用支持的宽高比：'1:1', '4:3', '16:9', '3:4', '9:16' |\n| \"Failed to download generated images\" | 图片下载失败 | 检查网络连接，确保能访问火山引擎的图片URL |",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcp_generate_images",
        "image",
        "cursor",
        "chenyeju295 mcp_generate_images",
        "mcp_generate_images image",
        "image generation"
      ],
      "category": "image-and-video-generation"
    },
    "ckz--flux-img-mcp": {
      "owner": "ckz",
      "name": "flux-img-mcp",
      "url": "https://github.com/ckz/flux-img-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/ckz.webp",
      "description": "Utilize advanced AI models to generate images from textual prompts, enabling users to convert their ideas into visual art. This server facilitates effortless image creation through simple command inputs.",
      "stars": 1,
      "forks": 4,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-03-12T05:08:24Z",
      "readme_content": "# Flux Image MCP Server\n\nThis MCP server provides image generation capabilities using the Flux Schnell model on Replicate.\n\n## Installation\n\n0. Install the MCP SDK globally:\n```bash\nnpm install -g @modelcontextprotocol/sdk@latest\n```\n\n1. Clone this repository to your MCP servers directory:\n```bash\ncd ~/Documents/Cline/MCP\ngit clone https://github.com/yourusername/flux-img-mcp.git\ncd flux-img-mcp\nnpm install\n```\n\n\n\n2. Build the server:\n```bash\nnpm run build\n```\n\n3. Add the server configuration to your MCP settings file (either global or workspace):\n\n```json\n{\n  \"mcpServers\": {\n    \"flux-img\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/flux-img-mcp/build/index.js\"],\n      \"env\": {\n        \"REPLICATE_API_TOKEN\": \"your-replicate-api-token\"\n      },\n      \"disabled\": false,\n      \"alwaysAllow\": []\n    }\n  }\n}\n```\n\n## Configuration\n\nThe server requires the following environment variable:\n\n- `REPLICATE_API_TOKEN`: Your Replicate API token. You can get this from your [Replicate account settings](https://replicate.com/account).\n\n## Usage\n\nOnce installed and configured, the server provides the following tool:\n\n### generate_image\n\nGenerates an image using the Flux Schnell model based on a text prompt.\n\nParameters:\n- `prompt` (string, required): Text description of the desired image\n\nExample usage:\n```typescript\n<use_mcp_tool>\n<server_name>flux-img</server_name>\n<tool_name>generate_image</tool_name>\n<arguments>\n{\n  \"prompt\": \"A beautiful sunset over mountains\"\n}\n</arguments>\n</use_mcp_tool>\n```\n\nThe tool will return a JSON response containing:\n- `status`: The status of the generation request\n- `output`: The URL of the generated image (if successful)\n- `error`: Any error message (if failed)\n\n## Development\n\nTo make changes to the server:\n\n1. Modify the source code in `src/index.ts`\n2. Rebuild the server: `npm run build`\n3. Restart the MCP server for changes to take effect\n\n## Error Handling\n\nThe server includes comprehensive error handling for:\n- Missing API token\n- Invalid parameters\n- API request failures\n- Network issues\n\n## Security\n\n- Never commit your Replicate API token to version control\n- Always provide the token through environment variables\n- The server validates all input parameters before making API requests\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ai",
        "images",
        "img",
        "generate images",
        "image creation",
        "video generation"
      ],
      "category": "image-and-video-generation"
    },
    "ckz--flux-schnell-mcp": {
      "owner": "ckz",
      "name": "flux-schnell-mcp",
      "url": "https://github.com/ckz/flux-schnell-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/ckz.webp",
      "description": "Generate images from text prompts using the Replicate API, enabling users to create customized visuals based on detailed descriptions. The server manages the communication with the API and handles errors effectively.",
      "stars": 3,
      "forks": 6,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-04-12T09:44:48Z",
      "readme_content": "# Flux Schnell MCP Server\n\n一个基于MCP（Model Context Protocol）的服务器，用于通过Replicate API调用Flux Schnell模型生成图片。\n\n## 功能特点\n\n- 提供`generate_image`工具用于生成图片\n- 支持自定义文本提示词\n- 自动处理与Replicate API的通信\n- 完整的错误处理和响应\n\n## 前置要求\n\n1. Node.js (v14或更高版本)\n2. Replicate API Token\n3. MCP兼容的环境（如Claude Desktop）\n\n## 获取Replicate API Token\n\n1. 访问 [Replicate官网](https://replicate.com/) 并注册账号\n2. 登录后访问 [API Tokens页面](https://replicate.com/account/api-tokens)\n3. 点击\"Create API token\"创建新的token\n4. 复制生成的token（格式如：r8_xxxxxx）\n\n## 安装\n\n1. 克隆项目并安装依赖：\n```bash\ngit clone [repository-url]\ncd flux-schnell-mcp\nnpm install\n```\n\n2. 构建服务器：\n```bash\nnpm run build\n```\n\n## 配置\n\n### Claude Desktop配置\n\n1. 打开配置文件：\n   - MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n2. 添加服务器配置：\n```json\n{\n  \"mcpServers\": {\n    \"flux-schnell\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/flux-schnell-mcp/build/index.js\"],\n      \"env\": {\n        \"REPLICATE_API_TOKEN\": \"your-replicate-api-token\"\n      },\n      \"disabled\": false,\n      \"alwaysAllow\": []\n    }\n  }\n}\n```\n\n### VSCode Roo配置\n\n1. 打开配置文件：\n   - Linux: `~/.vscode-remote/data/User/globalStorage/rooveterinaryinc.roo-cline/settings/cline_mcp_settings.json`\n   - MacOS: `~/Library/Application Support/Code/User/globalStorage/rooveterinaryinc.roo-cline/settings/cline_mcp_settings.json`\n   - Windows: `%APPDATA%/Code/User/globalStorage/rooveterinaryinc.roo-cline/settings/cline_mcp_settings.json`\n\n2. 添加与上述相同的服务器配置。\n\n## 使用方法\n\n服务器提供了一个名为`generate_image`的工具，可以通过MCP调用：\n\n```typescript\n<use_mcp_tool>\n<server_name>flux-schnell</server_name>\n<tool_name>generate_image</tool_name>\n<arguments>\n{\n  \"prompt\": \"a beautiful sunset over the ocean, digital art style\"\n}\n</arguments>\n</use_mcp_tool>\n```\n\n### 参数说明\n\n- `prompt`: 用于生成图片的文本描述（必填）\n  - 建议使用详细的描述来获得更好的生成结果\n  - 可以包含风格、场景、细节等信息\n\n### 响应格式\n\n服务器将返回Replicate API的完整响应，包含生成的图片URL和其他元数据。\n\n## 调试\n\n由于MCP服务器通过stdio通信，调试可能比较困难。推荐使用[MCP Inspector](https://github.com/modelcontextprotocol/inspector)：\n\n```bash\nnpm run inspector\n```\n\nInspector将提供一个URL，可以在浏览器中访问调试工具。\n\n## 注意事项\n\n1. 请妥善保管您的Replicate API Token，不要将其分享给他人\n2. 确保在配置文件中使用正确的文件路径\n3. 生成图片可能需要一些时间，请耐心等待响应\n4. 如遇到错误，请检查API Token是否正确，以及网络连接是否正常\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "replicate",
        "generate",
        "visuals",
        "generate images",
        "video generation",
        "ckz flux"
      ],
      "category": "image-and-video-generation"
    },
    "coderjun--shaka-packager-mcp-server": {
      "owner": "coderjun",
      "name": "shaka-packager-mcp-server",
      "url": "https://github.com/coderjun/shaka-packager-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/coderjun.webp",
      "description": "Supports advanced video transcoding, packaging, and analysis using Shaka Packager. Facilitates format conversion, DRM application, and content preparation for streaming, featuring intelligent path handling and error management.",
      "stars": 3,
      "forks": 2,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-06-19T18:32:59Z",
      "readme_content": "# Shaka Packager MCP Server\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Python Version](https://img.shields.io/badge/python-3.10%2B-blue)](https://www.python.org/downloads/)\n[![Status: Alpha](https://img.shields.io/badge/Status-Alpha%20%7C%20Experimental-red)](https://github.com/coderjun/shaka-packager-mcp)\n\n> **⚠️ EXPERIMENTAL STATUS DISCLAIMER**\n> \n> This project is in early alpha stage and is highly experimental. It is not recommended for production use. It is also likely **MESSY!**\n> \n> **Current limitations:**\n> - You may run into inconsistent behavior\n> - Advanced features (packaging, conversion, etc.) are still under active development\n> - Path translation between Docker and host environments may require manual configuration\n> - Expect frequent breaking changes and potential instability\n>\n> Please report any issues you encounter to help improve the project.\n\nAn MCP (Model Context Protocol) server that integrates [Shaka Packager](https://shaka-project.github.io/shaka-packager/) with Claude AI applications for video transcoding, packaging, and analysis.\n\nThis server works with the [Filesystem MCP Server](https://github.com/modelcontextprotocol/servers/tree/main/src/filesystem) to enable Claude Desktop to access and process video files on your computer, turning Claude into a powerful assistant for media processing tasks.\n\n## Features\n\n- **Video Analysis**: Analyze video files to extract detailed stream information, codecs, bitrates, and more\n- **Media Packaging**: Convert videos for streaming in HLS and DASH formats with support for VOD and live streaming\n- **Advanced Options**: \n  - Apply DRM encryption (Widevine, PlayReady, FairPlay)\n  - Configure ad insertion markers\n  - Convert between formats (MP4, TS, etc.)\n- **Intelligent Path Handling**: Automatically translates paths between Docker and host environments\n- **Robust Error Management**: Provides meaningful error analysis with suggestions for resolution\n- **Command Assistance**: Helps correctly format Shaka Packager commands for optimal results\n- **Interactive Documentation**: Built-in help and examples to guide users through complex operations\n- **Detailed Outputs**: Comprehensive summaries and execution details for all operations\n\n## Prerequisites\n\n- Python 3.10 or higher\n- Shaka Packager installed and available in your PATH\n  - [Download from GitHub](https://github.com/shaka-project/shaka-packager/releases)\n  - Or build from source following [these instructions](https://shaka-project.github.io/shaka-packager/html/build_instructions.html)\n- An MCP-compatible client (like Claude Desktop)\n\n## Installation\n\n### Using pip or uv (coming soon)\n\nInstall the package with pip:\n\n```bash\npip install shaka-packager-mcp\n```\n\nOr with uv:\n\n```bash\nuv pip install shaka-packager-mcp\n```\n\n### From source (recommended)\n\n```bash\ngit clone https://github.com/coderjun/shaka-packager-mcp.git\ncd shaka-packager-mcp\npip install -e .\n```\n\nOr with uv:\n\n```bash\ngit clone https://github.com/coderjun/shaka-packager-mcp.git\ncd shaka-packager-mcp\nuv pip install -e .\n```\n\n## Claude Desktop Integration\n\nSince Claude Desktop doesn't directly support uploading video files, we'll use a two-server approach:\n1. A simplified **filesystem MCP server** to access video files on your computer\n2. The **Shaka Packager MCP server** to analyze and process those videos\n\n### Step 1: Set Up the MCP Filesystem Server\n\nUse the official MCP filesystem server to allow Claude to access your video files:\n\n1. Install the official filesystem server with Docker:\n   ```bash\n   docker pull mcp/filesystem\n   ```\n\n2. Alternatively, you can build it from source following the instructions in the [Filesystem MCP Server repository](https://github.com/modelcontextprotocol/servers/tree/main/src/filesystem)\n\n### Step 2: Find the Configuration File\n\nLocate your Claude Desktop configuration file:\n\n- **macOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`\n- **Windows**: `%APPDATA%\\Claude\\claude_desktop_config.json`\n\nIf the file doesn't exist, create it.\n\n### Step 3: Add Both Servers to the Configuration\n\nAdd the following configuration, making sure to use absolute paths:\n\n```json\n{\n  \"mcpServers\": {\n    \"filesystem\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"--mount\", \"type=bind,src=/PATH/TO/VIDEOS/DIRECTORY,dst=/projects/video-drop\",\n        \"mcp/filesystem\",\n        \"/projects\"\n      ]\n    },\n    \"shaka-packager\": {\n      \"command\": \"/ABSOLUTE/PATH/TO/uv\",\n      \"args\": [\n        \"run\",\n        \"--with\",\n        \"mcp[cli]\",\n        \"/ABSOLUTE/PATH/TO/shaka_packager_mcp.py\"\n      ],\n      \"env\": {\n        \"VIDEO_PATH\": \"/PATH/TO/VIDEOS/DIRECTORY\",\n        \"SHAKA_PACKAGER_PATH\": \"/PATH/TO/PACKAGER\"\n      }\n    }\n  }\n}\n```\n\nReplace:\n- `/PATH/TO/VIDEOS/DIRECTORY` with the path to the directory containing your video files\n- `/ABSOLUTE/PATH/TO/uv` with the full path to your uv executable\n- `/ABSOLUTE/PATH/TO/shaka_packager_mcp.py` with the full path to the script file\n- `/PATH/TO/PACKAGER` with the full path to your Shaka Packager executable\n\nFor example:\n\n```json\n{\n  \"mcpServers\": {\n    \"filesystem\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"--mount\", \"type=bind,src=/Users/username/Videos,dst=/projects/video-drop\",\n        \"mcp/filesystem\",\n        \"/projects\"\n      ]\n    },\n    \"shaka-packager\": {\n      \"command\": \"/Users/username/.local/bin/uv\",\n      \"args\": [\n        \"run\",\n        \"--with\",\n        \"mcp[cli]\",\n        \"/Users/username/Development/shaka-packager-mcp/shaka_packager_mcp.py\"\n      ],\n      \"env\": {\n        \"VIDEO_PATH\": \"/Users/username/Videos\",\n        \"SHAKA_PACKAGER_PATH\": \"/Users/username/.shaka/packager\"\n      }\n    }\n  }\n}\n```\n\n### Step 4: Restart Claude Desktop\n\nAfter editing the configuration file, restart Claude Desktop to apply the changes.\n\n### How to Use the Two-Server Approach\n\n1. First, browse your video files using the simplified filesystem server:\n   - Ask Claude to \"List the files in my video directory\"\n   - Navigate to the video file you want to analyze or process\n\n2. Once you've found your video file, use its path with the Shaka Packager tools:\n   - For analysis: \"Please analyze this video: /Users/username/Videos/example.mp4\"\n   - For processing: \"Please package this video for HLS: /Users/username/Videos/example.mp4\"\n\n### Troubleshooting\n\nIf you encounter any issues:\n\n1. Make sure both servers are properly configured with absolute paths\n2. Verify that Shaka Packager is installed and accessible\n3. Ensure the directory specified for the filesystem server exists and contains videos\n4. Check Claude Desktop logs for errors at:\n   - macOS: `~/Library/Logs/Claude/mcp*.log`\n   - Windows: `%APPDATA%\\Claude\\logs\\mcp*.log`\n\n## Usage\n\nOnce both the Filesystem MCP server and the Shaka Packager MCP server are running in Claude Desktop:\n\n1. **Access your video files**:\n   ```\n   Please show me the files in my Videos directory\n   ```\n\n2. **Navigate to your video file**:\n   ```\n   Please show me the files in the Movies subdirectory\n   ```\n\n3. **Copy the file:// URI path of the video** you want to process\n\n4. **Use the Shaka Packager tools with the file path**:\n   ```\n   Please analyze this video: file:///Users/username/Videos/my_video.mp4\n   ```\n   or\n   ```\n   Please package this video for HLS and DASH streaming: file:///Users/username/Videos/my_video.mp4\n   ```\n\n5. The server will execute the appropriate Shaka Packager command and provide a detailed summary of the results\n\nYou can also use direct file paths if you know the exact location of your video files:\n```\nPlease analyze this video: /Users/username/Videos/my_video.mp4\n```\n\n## Tools\n\nThe server provides these tools:\n\n1. **analyze_video**: Examines a video file and provides detailed stream information with intelligent error handling\n2. **run_shaka_packager**: Executes any Shaka Packager command with custom arguments and proper path handling\n3. **get_shaka_options**: Retrieves available command options and version information\n4. **get_shaka_documentation**: Provides comprehensive documentation and examples for using Shaka Packager\n\n## Prompts\n\nThe server includes these prompt templates:\n\n- MP4 to TS conversion\n- VOD packaging in HLS and DASH\n- Live streaming packaging\n- Content encryption\n- Ad insertion preparation\n- Video analysis\n- Command format reminder\n- Error interpretation guidance\n\n## Configuration\n\nThe server can be configured using environment variables:\n\n- `SHAKA_PACKAGER_PATH`: Path to the Shaka Packager executable (highly recommended for Claude Desktop)\n- `VIDEO_PATH`: Path to your local video directory (used for translating paths between Docker and host)\n- `DOCKER_PATH`: Docker container mount path (default: \"/projects/video-drop\")\n- `TEMP_DIR`: Custom temporary directory for file uploads\n- `LOG_LEVEL`: Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)\n- `COMMAND_TIMEOUT`: Timeout in seconds for Shaka Packager commands (default: 300)\n\nYou can set these in:\n1. Your Claude Desktop configuration file (preferred for `SHAKA_PACKAGER_PATH` and `VIDEO_PATH`)\n2. Your environment variables\n3. A `.env` file in the same directory as the script\n\nExample `.env` file:\n```\nSHAKA_PACKAGER_PATH=/usr/local/bin/packager\nVIDEO_PATH=/Users/yourusername/Videos\nLOG_LEVEL=DEBUG\n```\n\n## Development\n\n### Setting up a development environment\n\n```bash\n# Clone the repository\ngit clone https://github.com/coderjun/shaka-packager-mcp.git\ncd shaka-packager-mcp\n\n# Install development dependencies with pip\npip install -e \".[dev]\"\n\n# Or with uv\nuv pip install -e \".[dev]\"\n```\n\n### Running tests\n\n```bash\npytest\n```\n\n### Code formatting\n\n```bash\nblack .\nisort .\n```\n\n### Understanding the Code Structure\n\nThe main components of the Shaka Packager MCP server are:\n\n- `shaka_packager_mcp.py`: Main server implementation with MCP tools and prompts\n- `tests/`: Test suite for verifying functionality\n\nThis server is designed to work with the official MCP filesystem server for accessing video files.\n\n### Key Features in the Implementation\n\n- **Robust path handling**: Automatically translates paths between Docker and host environments\n- **Smart error handling**: Provides meaningful error messages and suggestions\n- **Command syntax assistance**: Helps correctly format Shaka Packager commands\n- **Documentation integration**: Provides comprehensive documentation and examples\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Getting Help\n\nFeel free to use an AI code copilot, the author does.\n\nIf you encounter any issues or have questions:\n\n1. Check the troubleshooting section in this README\n2. Review the [Shaka Packager documentation](https://shaka-project.github.io/shaka-packager/html/index.html)\n3. Use the `get_shaka_documentation` tool for interactive help within Claude\n4. [Open an issue](https://github.com/coderjun/shaka-packager-mcp/issues) on GitHub\n\n## Acknowledgements\n\n- [Shaka Packager](https://github.com/shaka-project/shaka-packager) for the powerful video processing capabilities\n- [Model Context Protocol (MCP)](https://modelcontextprotocol.io/) for the communication framework\n- [Claude](https://claude.ai) for the AI assistant capabilities\n- [Anthropic](https://www.anthropic.com/) for developing Claude and the MCP standard",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "packager",
        "coderjun",
        "streaming",
        "shaka packager",
        "video transcoding",
        "packager mcp"
      ],
      "category": "image-and-video-generation"
    },
    "dangtanloc--ComfyUI": {
      "owner": "dangtanloc",
      "name": "ComfyUI",
      "url": "https://github.com/dangtanloc/ComfyUI",
      "imageUrl": "/freedevtools/mcp/pfp/dangtanloc.webp",
      "description": "A visual graph-based interface for designing and executing advanced stable diffusion pipelines, enabling users to create complex workflows without coding. It features smart memory management and asynchronous processing, supporting both GPU and CPU usage for offline functionality.",
      "stars": 0,
      "forks": 0,
      "license": "GNU General Public License v3.0",
      "language": "",
      "updated_at": "2024-10-10T06:48:42Z",
      "readme_content": "<div align=\"center\">\n\n# ComfyUI\n**The most powerful and modular diffusion model GUI and backend.**\n\n\n[![Website][website-shield]][website-url]\n[![Dynamic JSON Badge][discord-shield]][discord-url]\n[![Matrix][matrix-shield]][matrix-url]\n<br>\n[![][github-release-shield]][github-release-link]\n[![][github-release-date-shield]][github-release-link]\n[![][github-downloads-shield]][github-downloads-link]\n[![][github-downloads-latest-shield]][github-downloads-link]\n\n[matrix-shield]: https://img.shields.io/badge/Matrix-000000?style=flat&logo=matrix&logoColor=white\n[matrix-url]: https://app.element.io/#/room/%23comfyui_space%3Amatrix.org\n[website-shield]: https://img.shields.io/badge/ComfyOrg-4285F4?style=flat\n[website-url]: https://www.comfy.org/\n<!-- Workaround to display total user from https://github.com/badges/shields/issues/4500#issuecomment-2060079995 -->\n[discord-shield]: https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fdiscord.com%2Fapi%2Finvites%2Fcomfyorg%3Fwith_counts%3Dtrue&query=%24.approximate_member_count&logo=discord&logoColor=white&label=Discord&color=green&suffix=%20total\n[discord-url]: https://www.comfy.org/discord\n\n[github-release-shield]: https://img.shields.io/github/v/release/comfyanonymous/ComfyUI?style=flat&sort=semver\n[github-release-link]: https://github.com/comfyanonymous/ComfyUI/releases\n[github-release-date-shield]: https://img.shields.io/github/release-date/comfyanonymous/ComfyUI?style=flat\n[github-downloads-shield]: https://img.shields.io/github/downloads/comfyanonymous/ComfyUI/total?style=flat\n[github-downloads-latest-shield]: https://img.shields.io/github/downloads/comfyanonymous/ComfyUI/latest/total?style=flat&label=downloads%40latest\n[github-downloads-link]: https://github.com/comfyanonymous/ComfyUI/releases\n\n\n</div>\n\nThis ui will let you design and execute advanced stable diffusion pipelines using a graph/nodes/flowchart based interface. For some workflow examples and see what ComfyUI can do you can check out:\n### [ComfyUI Examples](https://comfyanonymous.github.io/ComfyUI_examples/)\n\n### [Installing ComfyUI](#installing)\n\n## Features\n- Nodes/graph/flowchart interface to experiment and create complex Stable Diffusion workflows without needing to code anything.\n- Fully supports SD1.x, SD2.x, [SDXL](https://comfyanonymous.github.io/ComfyUI_examples/sdxl/), [Stable Video Diffusion](https://comfyanonymous.github.io/ComfyUI_examples/video/), [Stable Cascade](https://comfyanonymous.github.io/ComfyUI_examples/stable_cascade/), [SD3](https://comfyanonymous.github.io/ComfyUI_examples/sd3/) and [Stable Audio](https://comfyanonymous.github.io/ComfyUI_examples/audio/)\n- [Flux](https://comfyanonymous.github.io/ComfyUI_examples/flux/)\n- Asynchronous Queue system\n- Many optimizations: Only re-executes the parts of the workflow that changes between executions.\n- Smart memory management: can automatically run models on GPUs with as low as 1GB vram.\n- Works even if you don't have a GPU with: ```--cpu``` (slow)\n- Can load ckpt, safetensors and diffusers models/checkpoints. Standalone VAEs and CLIP models.\n- Embeddings/Textual inversion\n- [Loras (regular, locon and loha)](https://comfyanonymous.github.io/ComfyUI_examples/lora/)\n- [Hypernetworks](https://comfyanonymous.github.io/ComfyUI_examples/hypernetworks/)\n- Loading full workflows (with seeds) from generated PNG, WebP and FLAC files.\n- Saving/Loading workflows as Json files.\n- Nodes interface can be used to create complex workflows like one for [Hires fix](https://comfyanonymous.github.io/ComfyUI_examples/2_pass_txt2img/) or much more advanced ones.\n- [Area Composition](https://comfyanonymous.github.io/ComfyUI_examples/area_composition/)\n- [Inpainting](https://comfyanonymous.github.io/ComfyUI_examples/inpaint/) with both regular and inpainting models.\n- [ControlNet and T2I-Adapter](https://comfyanonymous.github.io/ComfyUI_examples/controlnet/)\n- [Upscale Models (ESRGAN, ESRGAN variants, SwinIR, Swin2SR, etc...)](https://comfyanonymous.github.io/ComfyUI_examples/upscale_models/)\n- [unCLIP Models](https://comfyanonymous.github.io/ComfyUI_examples/unclip/)\n- [GLIGEN](https://comfyanonymous.github.io/ComfyUI_examples/gligen/)\n- [Model Merging](https://comfyanonymous.github.io/ComfyUI_examples/model_merging/)\n- [LCM models and Loras](https://comfyanonymous.github.io/ComfyUI_examples/lcm/)\n- [SDXL Turbo](https://comfyanonymous.github.io/ComfyUI_examples/sdturbo/)\n- [AuraFlow](https://comfyanonymous.github.io/ComfyUI_examples/aura_flow/)\n- [HunyuanDiT](https://comfyanonymous.github.io/ComfyUI_examples/hunyuan_dit/)\n- Latent previews with [TAESD](#how-to-show-high-quality-previews)\n- Starts up very fast.\n- Works fully offline: will never download anything.\n- [Config file](extra_model_paths.yaml.example) to set the search paths for models.\n\nWorkflow examples can be found on the [Examples page](https://comfyanonymous.github.io/ComfyUI_examples/)\n\n## Shortcuts\n\n| Keybind                            | Explanation                                                                                                        |\n|------------------------------------|--------------------------------------------------------------------------------------------------------------------|\n| Ctrl + Enter                       | Queue up current graph for generation                                                                              |\n| Ctrl + Shift + Enter               | Queue up current graph as first for generation                                                                     |\n| Ctrl + Alt + Enter                 | Cancel current generation                                                                                          |\n| Ctrl + Z/Ctrl + Y                  | Undo/Redo                                                                                                          |\n| Ctrl + S                           | Save workflow                                                                                                      |\n| Ctrl + O                           | Load workflow                                                                                                      |\n| Ctrl + A                           | Select all nodes                                                                                                   |\n| Alt + C                            | Collapse/uncollapse selected nodes                                                                                 |\n| Ctrl + M                           | Mute/unmute selected nodes                                                                                         |\n| Ctrl + B                           | Bypass selected nodes (acts like the node was removed from the graph and the wires reconnected through)            |\n| Delete/Backspace                   | Delete selected nodes                                                                                              |\n| Ctrl + Backspace                   | Delete the current graph                                                                                           |\n| Space                              | Move the canvas around when held and moving the cursor                                                             |\n| Ctrl/Shift + Click                 | Add clicked node to selection                                                                                      |\n| Ctrl + C/Ctrl + V                  | Copy and paste selected nodes (without maintaining connections to outputs of unselected nodes)                     |\n| Ctrl + C/Ctrl + Shift + V          | Copy and paste selected nodes (maintaining connections from outputs of unselected nodes to inputs of pasted nodes) |\n| Shift + Drag                       | Move multiple selected nodes at the same time                                                                      |\n| Ctrl + D                           | Load default graph                                                                                                 |\n| Alt + `+`                          | Canvas Zoom in                                                                                                     |\n| Alt + `-`                          | Canvas Zoom out                                                                                                    |\n| Ctrl + Shift + LMB + Vertical drag | Canvas Zoom in/out                                                                                                 |\n| P                                  | Pin/Unpin selected nodes                                                                                           |\n| Ctrl + G                           | Group selected nodes                                                                                               |\n| Q                                  | Toggle visibility of the queue                                                                                     |\n| H                                  | Toggle visibility of history                                                                                       |\n| R                                  | Refresh graph                                                                                                      |\n| Double-Click LMB                   | Open node quick search palette                                                                                     |\n| Shift + Drag                       | Move multiple wires at once                                                                                        |\n| Ctrl + Alt + LMB                   | Disconnect all wires from clicked slot                                                                             |\n\nCtrl can also be replaced with Cmd instead for macOS users\n\n# Installing\n\n## Windows\n\nThere is a portable standalone build for Windows that should work for running on Nvidia GPUs or for running on your CPU only on the [releases page](https://github.com/comfyanonymous/ComfyUI/releases).\n\n### [Direct link to download](https://github.com/comfyanonymous/ComfyUI/releases/latest/download/ComfyUI_windows_portable_nvidia.7z)\n\nSimply download, extract with [7-Zip](https://7-zip.org) and run. Make sure you put your Stable Diffusion checkpoints/models (the huge ckpt/safetensors files) in: ComfyUI\\models\\checkpoints\n\nIf you have trouble extracting it, right click the file -> properties -> unblock\n\n#### How do I share models between another UI and ComfyUI?\n\nSee the [Config file](extra_model_paths.yaml.example) to set the search paths for models. In the standalone windows build you can find this file in the ComfyUI directory. Rename this file to extra_model_paths.yaml and edit it with your favorite text editor.\n\n## Jupyter Notebook\n\nTo run it on services like paperspace, kaggle or colab you can use my [Jupyter Notebook](notebooks/comfyui_colab.ipynb)\n\n## Manual Install (Windows, Linux)\n\nGit clone this repo.\n\nPut your SD checkpoints (the huge ckpt/safetensors files) in: models/checkpoints\n\nPut your VAE in: models/vae\n\n\n### AMD GPUs (Linux only)\nAMD users can install rocm and pytorch with pip if you don't have it already installed, this is the command to install the stable version:\n\n```pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.1```\n\nThis is the command to install the nightly with ROCm 6.2 which might have some performance improvements:\n\n```pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/rocm6.2```\n\n### NVIDIA\n\nNvidia users should install stable pytorch using this command:\n\n```pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu124```\n\nThis is the command to install pytorch nightly instead which might have performance improvements:\n\n```pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu124```\n\n#### Troubleshooting\n\nIf you get the \"Torch not compiled with CUDA enabled\" error, uninstall torch with:\n\n```pip uninstall torch```\n\nAnd install it again with the command above.\n\n### Dependencies\n\nInstall the dependencies by opening your terminal inside the ComfyUI folder and:\n\n```pip install -r requirements.txt```\n\nAfter this you should have everything installed and can proceed to running ComfyUI.\n\n### Others:\n\n#### Intel GPUs\n\nIntel GPU support is available for all Intel GPUs supported by Intel's Extension for Pytorch (IPEX) with the support requirements listed in the [Installation](https://intel.github.io/intel-extension-for-pytorch/index.html#installation?platform=gpu) page. Choose your platform and method of install and follow the instructions. The steps are as follows:\n\n1. Start by installing the drivers or kernel listed or newer in the Installation page of IPEX linked above for Windows and Linux if needed.\n1. Follow the instructions to install [Intel's oneAPI Basekit](https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit-download.html) for your platform.\n1. Install the packages for IPEX using the instructions provided in the Installation page for your platform.\n1. Follow the [ComfyUI manual installation](#manual-install-windows-linux) instructions for Windows and Linux and run ComfyUI normally as described above after everything is installed.\n\nAdditional discussion and help can be found [here](https://github.com/comfyanonymous/ComfyUI/discussions/476).\n\n#### Apple Mac silicon\n\nYou can install ComfyUI in Apple Mac silicon (M1 or M2) with any recent macOS version.\n\n1. Install pytorch nightly. For instructions, read the [Accelerated PyTorch training on Mac](https://developer.apple.com/metal/pytorch/) Apple Developer guide (make sure to install the latest pytorch nightly).\n1. Follow the [ComfyUI manual installation](#manual-install-windows-linux) instructions for Windows and Linux.\n1. Install the ComfyUI [dependencies](#dependencies). If you have another Stable Diffusion UI [you might be able to reuse the dependencies](#i-already-have-another-ui-for-stable-diffusion-installed-do-i-really-have-to-install-all-of-these-dependencies).\n1. Launch ComfyUI by running `python main.py`\n\n> **Note**: Remember to add your models, VAE, LoRAs etc. to the corresponding Comfy folders, as discussed in [ComfyUI manual installation](#manual-install-windows-linux).\n\n#### DirectML (AMD Cards on Windows)\n\n```pip install torch-directml``` Then you can launch ComfyUI with: ```python main.py --directml```\n\n# Running\n\n```python main.py```\n\n### For AMD cards not officially supported by ROCm\n\nTry running it with this command if you have issues:\n\nFor 6700, 6600 and maybe other RDNA2 or older: ```HSA_OVERRIDE_GFX_VERSION=10.3.0 python main.py```\n\nFor AMD 7600 and maybe other RDNA3 cards: ```HSA_OVERRIDE_GFX_VERSION=11.0.0 python main.py```\n\n# Notes\n\nOnly parts of the graph that have an output with all the correct inputs will be executed.\n\nOnly parts of the graph that change from each execution to the next will be executed, if you submit the same graph twice only the first will be executed. If you change the last part of the graph only the part you changed and the part that depends on it will be executed.\n\nDragging a generated png on the webpage or loading one will give you the full workflow including seeds that were used to create it.\n\nYou can use () to change emphasis of a word or phrase like: (good code:1.2) or (bad code:0.8). The default emphasis for () is 1.1. To use () characters in your actual prompt escape them like \\\\( or \\\\).\n\nYou can use {day|night}, for wildcard/dynamic prompts. With this syntax \"{wild|card|test}\" will be randomly replaced by either \"wild\", \"card\" or \"test\" by the frontend every time you queue the prompt. To use {} characters in your actual prompt escape them like: \\\\{ or \\\\}.\n\nDynamic prompts also support C-style comments, like `// comment` or `/* comment */`.\n\nTo use a textual inversion concepts/embeddings in a text prompt put them in the models/embeddings directory and use them in the CLIPTextEncode node like this (you can omit the .pt extension):\n\n```embedding:embedding_filename.pt```\n\n\n## How to show high-quality previews?\n\nUse ```--preview-method auto``` to enable previews.\n\nThe default installation includes a fast latent preview method that's low-resolution. To enable higher-quality previews with [TAESD](https://github.com/madebyollin/taesd), download the [taesd_decoder.pth, taesdxl_decoder.pth, taesd3_decoder.pth and taef1_decoder.pth](https://github.com/madebyollin/taesd/) and place them in the `models/vae_approx` folder. Once they're installed, restart ComfyUI and launch it with `--preview-method taesd` to enable high-quality previews.\n\n## How to use TLS/SSL?\nGenerate a self-signed certificate (not appropriate for shared/production use) and key by running the command: `openssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -sha256 -days 3650 -nodes -subj \"/C=XX/ST=StateName/L=CityName/O=CompanyName/OU=CompanySectionName/CN=CommonNameOrHostname\"`\n\nUse `--tls-keyfile key.pem --tls-certfile cert.pem` to enable TLS/SSL, the app will now be accessible with `https://...` instead of `http://...`.\n\n> Note: Windows users can use [alexisrolland/docker-openssl](https://github.com/alexisrolland/docker-openssl) or one of the [3rd party binary distributions](https://wiki.openssl.org/index.php/Binaries) to run the command example above. \n<br/><br/>If you use a container, note that the volume mount `-v` can be a relative path so `... -v \".\\:/openssl-certs\" ...` would create the key & cert files in the current directory of your command prompt or powershell terminal.\n\n## Support and dev channel\n\n[Matrix space: #comfyui_space:matrix.org](https://app.element.io/#/room/%23comfyui_space%3Amatrix.org) (it's like discord but open source).\n\nSee also: [https://www.comfy.org/](https://www.comfy.org/)\n\n## Frontend Development\n\nAs of August 15, 2024, we have transitioned to a new frontend, which is now hosted in a separate repository: [ComfyUI Frontend](https://github.com/Comfy-Org/ComfyUI_frontend). This repository now hosts the compiled JS (from TS/Vue) under the `web/` directory.\n\n### Reporting Issues and Requesting Features\n\nFor any bugs, issues, or feature requests related to the frontend, please use the [ComfyUI Frontend repository](https://github.com/Comfy-Org/ComfyUI_frontend). This will help us manage and address frontend-specific concerns more efficiently.\n\n### Using the Latest Frontend\n\nThe new frontend is now the default for ComfyUI. However, please note:\n\n1. The frontend in the main ComfyUI repository is updated weekly.\n2. Daily releases are available in the separate frontend repository.\n\nTo use the most up-to-date frontend version:\n\n1. For the latest daily release, launch ComfyUI with this command line argument:\n\n   ```\n   --front-end-version Comfy-Org/ComfyUI_frontend@latest\n   ```\n\n2. For a specific version, replace `latest` with the desired version number:\n\n   ```\n   --front-end-version Comfy-Org/ComfyUI_frontend@1.2.2\n   ```\n\nThis approach allows you to easily switch between the stable weekly release and the cutting-edge daily updates, or even specific versions for testing purposes.\n\n### Accessing the Legacy Frontend\n\nIf you need to use the legacy frontend for any reason, you can access it using the following command line argument:\n\n```\n--front-end-version Comfy-Org/ComfyUI_legacy_frontend@latest\n```\n\nThis will use a snapshot of the legacy frontend preserved in the [ComfyUI Legacy Frontend repository](https://github.com/Comfy-Org/ComfyUI_legacy_frontend).\n\n# QA\n\n### Which GPU should I buy for this?\n\n[See this page for some recommendations](https://github.com/comfyanonymous/ComfyUI/wiki/Which-GPU-should-I-buy-for-ComfyUI)",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "visual",
        "processing",
        "pipelines",
        "diffusion pipelines",
        "visual graph",
        "comfyui visual"
      ],
      "category": "image-and-video-generation"
    },
    "dasheck0--face-generator": {
      "owner": "dasheck0",
      "name": "face-generator",
      "url": "https://github.com/dasheck0/face-generator",
      "imageUrl": "/freedevtools/mcp/pfp/dasheck0.webp",
      "description": "Generate realistic human face images with customizable shapes, sizes, and backgrounds. Supports batch generation for multiple images and offers transparent backgrounds for non-square outputs.",
      "stars": 5,
      "forks": 4,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-10-03T22:32:05Z",
      "readme_content": "# Face Generator MCP Server: Generate Human Faces with Ease\n\n[![Smithery badge](https://smithery.ai/badge/@dasheck0/face-generator)](https://smithery.ai/server/@dasheck0/face-generator)\n\n<a href=\"https://glama.ai/mcp/servers/0v6oomxing\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/0v6oomxing/badge\" alt=\"Face Generator Server MCP server\" />\n</a>\n\n## Features\nThis project provides a Model Context Protocol (MCP) server for generating human face images using https://thispersondoesnotexist.com. Think of it as a tool that lets other applications, like Cline, generate realistic-looking faces on demand.\n\nThis guide is designed for beginners, so we'll walk through everything step-by-step. We'll cover:\n\n1.  **Prerequisites:** What you need before you start.\n2.  **Installation and Setup:** Getting everything up and running.\n3.  **Running the Server:** Starting the server.\n4.  **Integrating with Cline:** Connecting this server to the Cline VS Code extension.\n5.  **Troubleshooting:** Common problems and solutions.\n6.  **Tool Parameters:** A list of the parameters you can use with the `generate_face` tool.\n\n## 1. Prerequisites\n\nBefore you begin, you'll need a few things:\n\n*   **Node.js and npm:** Node.js is a JavaScript runtime that lets you run JavaScript code outside of a web browser. npm (Node Package Manager) is included with Node.js and is used to install packages (libraries of code).\n    *   [Download Node.js](https://nodejs.org/en/download/). **Choose the LTS (Long Term Support) version.** This is the most stable version. Follow the installation instructions for your operating system. Make sure to include npm in the installation (it's usually included by default).\n    *   **Verify Installation:** After installing Node.js, open a new terminal (command prompt on Windows, Terminal on macOS/Linux) and type:\n        ```bash\n        node -v\n        npm -v\n        ```\n        You should see version numbers for both Node.js and npm. If you see an error, Node.js might not be installed correctly, or it might not be in your system's PATH. (See Troubleshooting below).\n\n## 2. Installation and Setup\n\nLet's get the project code and set it up:\n\n1.  **Clone the Repository:**\n    *   **Using Git (command line):**\n        1.  Open a terminal (command prompt or Terminal).\n        2.  Navigate to the directory where you want to store the project. For example, to put it on your Desktop:\n            ```bash\n            cd Desktop\n            ```\n        3.  Clone the repository:\n            ```bash\n            git clone https://github.com/Moe/mcp-face-generator\n            ```\n        4.  Change into the project directory:\n            ```bash\n            cd mcp-face-generator\n            ```\n    *   **Using GitHub Desktop:**\n        1.  Open GitHub Desktop.\n        2.  Click \"File\" -> \"Clone Repository...\".\n        3.  In the \"URL\" tab, paste the repository URL.\n        4.  Choose a local path (where you want to save the project on your computer).\n        5.  Click \"Clone\".\n\n2.  **Install Dependencies:** This downloads all the necessary libraries the project needs. In the terminal, inside the project directory, run:\n    ```bash\n    npm install\n    ```\n    This might take a few minutes.\n\n3.  **Build the Project:** This compiles the code into an executable format.\n    ```bash\n    npm run build\n    ```\n\n## 3. Running the Server\n\nYou can run the server in two main ways:\n\n*   **Standalone Mode:** This runs the server directly, and it will output messages to the terminal.\n*   **Development/Debug Mode:** This runs the server with the MCP Inspector. You can open the URL that it outputs in your browser and start playing around.\n\n### 3.1 Standalone Mode\n\nTo run the server in standalone mode, use the following command in the terminal (from the project directory):\n\n```bash\nnpm run start\n```\n\nYou should see messages in the terminal indicating that the server is running. It will listen for connections from MCP clients. The server will keep running until you stop it (usually with Ctrl+C).\n\n### 3.2 Development/Debug Mode (with Inspector)\n\nThis mode is useful for debugging.\n\n1.  **Start the server in debug mode:**\n    ```bash\n    npm run dev\n    ```\n    This will start the server and output a message like: `🔍 MCP Inspector is up and running at http://localhost:5173 🚀`. This is the URL you'll use to open the MCP inspector in your Browser.\n\n## 4. Integrating with Cline\n\nCline is a VS Code extension that uses MCP servers to provide language support. Here's how to connect this face generator server to Cline:\n\n1.  **Install Cline:** If you haven't already, install the \"Cline\" extension in VS Code.\n\n2.  **Open Cline Settings:**\n    *   Open the VS Code settings (File -> Preferences -> Settings, or Ctrl+,).\n    *   Search for \"Cline MCP Settings\".\n    *   Click \"Edit in settings.json\". This will open the `cline_mcp_settings.json` file.\n\n3.  **Add the Server Configuration:** You'll need to add an entry to the `servers` array in the `cline_mcp_settings.json` file. Here's an example:\n\n    ```json\n    {\n      \"mcpServers\": {\n        \"face-generator\": {\n          \"command\": \"node\",\n          \"args\": [\n            \"C:/PATH_TO/mcp-face-generator/build/index.js\"\n          ],\n          \"disabled\": false,\n          \"autoApprove\": []\n        }\n      }\n    }\n    ```\n    *   Replace `\"C:/PATH_TO/mcp-face-generator/build/index.js\"` with the actual path to the `index.js` file in your project directory.  Use forward slashes (/) or double backslashes (\\\\\\\\) for the path on Windows.\n\n4.  **Test the Connection:**\n    *   Cline should automatically connect to the server. You will see the Server appear in the \"MCP Servers\" Panel (in the Cline extension, you'll find different buttons on the top.)\n    *   Ask Cline to generate a face and it should mention the MCP Server and should try to use the corresponding tools\n\n## 5. Troubleshooting\n\n*   **`node -v` or `npm -v` gives an error:**\n    *   Make sure Node.js is installed correctly. Try reinstalling it.\n    *   Ensure that the Node.js installation directory is in your system's PATH environment variable. On Windows, you can edit environment variables through the System Properties (search for \"environment variables\" in the Start Menu).\n*   **`npm install` fails:**\n    *   Make sure you have an internet connection.\n    *   Try deleting the `node_modules` folder and running `npm install` again.\n    *   If you're behind a proxy, you might need to configure npm to use the proxy. Search online for \"npm proxy settings\".\n*   **Cline doesn't connect to the server:**\n    *   Double-check the settings in `cline_mcp_settings.json`. It *must* be the correct path to the `index.js` file.\n    *   Make sure the server is running (use `npm run start` to check).\n    *   Restart VS Code.\n\n## 6. Tool Parameters\n\nThe `generate_face` tool accepts the following parameters:\n\n*   `outputDir`: (required) Directory to save the images\n*   `fileName`: Optional file name (defaults to timestamp)\n*   `count`: Number of images to generate (default: 1)\n*   `width`: Image width in pixels (default: 256)\n*   `height`: Image height in pixels (default: 256)\n*   `shape`: Image shape (square|circle|rounded, default: square)\n*   `borderRadius`: Border radius for rounded shape (default: 32)\n*   `returnImageContent`: Return image as base64 encoded content instead of file path (default: false)\n\n## Example\n\n```json\n{\n  \"outputDir\": \"./output\",\n  \"count\": 3,\n  \"width\": 512,\n  \"height\": 512,\n  \"shape\": \"circle\",\n  \"returnImageContent\": true\n}\n```\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "generate",
        "dasheck0",
        "backgrounds",
        "face generator",
        "face images",
        "dasheck0 face"
      ],
      "category": "image-and-video-generation"
    },
    "deepfates--mcp-replicate": {
      "owner": "deepfates",
      "name": "mcp-replicate",
      "url": "https://github.com/deepfates/mcp-replicate",
      "imageUrl": "/freedevtools/mcp/pfp/deepfates.webp",
      "description": "Access Replicate models to run predictions through a tool-based interface, facilitating interactions with various AI models hosted on Replicate's platform.",
      "stars": 84,
      "forks": 19,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-24T19:15:13Z",
      "readme_content": "# Replicate MCP Server\n\nA [Model Context Protocol](https://github.com/mcp-sdk/mcp) server implementation for Replicate. Run Replicate models through a simple tool-based interface.\n\n## NOT IN ACTIVE DEVELOPMENT\n\nThis repo was an experiment in MCP tooling for Replicate. The company now offers an [official MCP server](https://replicate.com/docs/reference/mcp). This repo will stay up for those who find it useful or want to fork it, but it's not in active development and issues won't be addressed. Contributions might be folded in but no promises. Enjoy at your own risk.\n\n## Quickstart\n\n1. Install the server:\n\n```bash\nnpm install -g mcp-replicate\n```\n\n2. Get your Replicate API token:\n\n   - Go to [Replicate API tokens page](https://replicate.com/account/api-tokens)\n   - Create a new token if you don't have one\n   - Copy the token for the next step\n\n3. Configure Claude Desktop:\n   - Open Claude Desktop Settings (<kbd>⌘</kbd><kbd>,</kbd>)\n   - Select the \"Developer\" section in the sidebar\n   - Click \"Edit Config\" to open the configuration file\n   - Add the following configuration, replacing `your_token_here` with your actual Replicate API token:\n\n```json\n{\n  \"mcpServers\": {\n    \"replicate\": {\n      \"command\": \"mcp-replicate\",\n      \"env\": {\n        \"REPLICATE_API_TOKEN\": \"your_token_here\"\n      }\n    }\n  }\n}\n```\n\n4. Start Claude Desktop. You should see a 🔨 hammer icon in the bottom right corner of new chat windows, indicating the tools are available.\n\n(You can also use any other MCP client, such as Cursor, Cline, or Continue.)\n\n## Alternative Installation Methods\n\n### Install from source\n\n```bash\ngit clone https://github.com/deepfates/mcp-replicate\ncd mcp-replicate\nnpm install\nnpm run build\nnpm start\n```\n\n### Run with npx\n\n```bash\nnpx mcp-replicate\n```\n\n## Features\n\n### Models\n\n- Search models using semantic search\n- Browse models and collections\n- Get detailed model information and versions\n\n### Predictions\n\n- Create predictions with text or structured input\n- Track prediction status\n- Cancel running predictions\n- List your recent predictions\n\n### Image Handling\n\n- View generated images in your browser\n- Manage image cache for better performance\n\n## Configuration\n\nThe server needs a Replicate API token to work. You can get one at [Replicate](https://replicate.com/account/api-tokens).\n\nThere are two ways to provide the token:\n\n### 1. In Claude Desktop Config (Recommended)\n\nAdd it to your Claude Desktop configuration as shown in the Quickstart section:\n\n```json\n{\n  \"mcpServers\": {\n    \"replicate\": {\n      \"command\": \"mcp-replicate\",\n      \"env\": {\n        \"REPLICATE_API_TOKEN\": \"your_token_here\"\n      }\n    }\n  }\n}\n```\n\n### 2. As Environment Variable\n\nAlternatively, you can set it as an environment variable if you're using another MCP client:\n\n```bash\nexport REPLICATE_API_TOKEN=your_token_here\n```\n\n## Available Tools\n\n### Model Tools\n\n- `search_models`: Find models using semantic search\n- `list_models`: Browse available models\n- `get_model`: Get details about a specific model\n- `list_collections`: Browse model collections\n- `get_collection`: Get details about a specific collection\n\n### Prediction Tools\n\n- `create_prediction`: Run a model with your inputs\n- `create_and_poll_prediction`: Run a model with your inputs and wait until it's completed\n- `get_prediction`: Check a prediction's status\n- `cancel_prediction`: Stop a running prediction\n- `list_predictions`: See your recent predictions\n\n### Image Tools\n\n- `view_image`: Open an image in your browser\n- `clear_image_cache`: Clean up cached images\n- `get_image_cache_stats`: Check cache usage\n\n## Troubleshooting\n\n### Server is running but tools aren't showing up\n\n1. Check that Claude Desktop is properly configured with the MCP server settings\n2. Ensure your Replicate API token is set correctly\n3. Try restarting both the server and Claude Desktop\n4. Check the server logs for any error messages\n\n### Tools are visible but not working\n\n1. Verify your Replicate API token is valid\n2. Check your internet connection\n3. Look for any error messages in the server output\n\n## Development\n\n1. Install dependencies:\n\n```bash\nnpm install\n```\n\n2. Start development server (with auto-reload):\n\n```bash\nnpm run dev\n```\n\n3. Check code style:\n\n```bash\nnpm run lint\n```\n\n4. Format code:\n\n```bash\nnpm run format\n```\n\n## Requirements\n\n- Node.js >= 18.0.0\n- TypeScript >= 5.0.0\n- [Claude Desktop](https://claude.ai/download) for using the tools\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "replicate",
        "deepfates",
        "ai",
        "mcp replicate",
        "deepfates mcp",
        "generation deepfates"
      ],
      "category": "image-and-video-generation"
    },
    "douglarek--unsplash-mcp-server": {
      "owner": "douglarek",
      "name": "unsplash-mcp-server",
      "url": "https://github.com/douglarek/unsplash-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/douglarek.webp",
      "description": "Access a vast library of high-quality images from Unsplash through a simplified API integration. Fetch stunning images on demand to enhance visual content in applications.",
      "stars": 10,
      "forks": 2,
      "license": "MIT License",
      "language": "Go",
      "updated_at": "2025-08-25T02:26:41Z",
      "readme_content": "# Unsplash MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@douglarek/unsplash-mcp-server)](https://smithery.ai/server/@douglarek/unsplash-mcp-server)\n\nA rewrite of the [Unsplash MCP Server](https://github.com/hellokaton/unsplash-mcp-server) using the [mark3labs/mcp-go](https://github.com/mark3labs/mcp-go) library.\n\n## Usage\n\nBefore building, you must install go 1.24+ first.\n\n```bash\ngit clone https://github.com/douglarek/unsplash-mcp-server.git\ncd unsplash-mcp-server\nmake build\n```\n\n### Cursor Editor Integration\n\nTo use this server in Cursor, you can add the following to your `mcp.json` file:\n\n```json\n{\n  \"mcpServers\": {\n    \"unsplash\": {\n      \"command\": \"<source_dir>/cmd/server/unsplash-mcp-server\",\n      \"args\": [],\n      \"env\": {\n        \"UNSPLASH_ACCESS_KEY\": \"<your_unsplash_access_key>\"\n      }\n    }\n  }\n}\n```\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "unsplash",
        "images",
        "mcp",
        "stunning images",
        "images unsplash",
        "unsplash mcp"
      ],
      "category": "image-and-video-generation"
    },
    "drumnation--unsplash-smart-mcp-server": {
      "owner": "drumnation",
      "name": "unsplash-smart-mcp-server",
      "url": "https://github.com/drumnation/unsplash-smart-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/drumnation.webp",
      "description": "Connects AI models to Unsplash for searching and delivering stock photos with context-aware selection and automatic attribution management.",
      "stars": 47,
      "forks": 6,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-02T20:15:22Z",
      "readme_content": "# 🖼️ Unsplash Smart MCP Server\n\n> **Empower your AI agents with stunning visuals, zero hassle.**\n\nA powerful FastMCP server that enables AI agents to seamlessly search, recommend, and deliver professional stock photos from Unsplash with intelligent context awareness and automated attribution management.\n\n![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)\n![Node.js Version](https://img.shields.io/badge/node-%3E%3D18.x-brightgreen)\n![TypeScript Ready](https://img.shields.io/badge/TypeScript-Ready-blue)\n[![smithery badge](https://smithery.ai/badge/@drumnation/unsplash-smart-mcp-server)](https://smithery.ai/server/@drumnation/unsplash-smart-mcp-server)\n[![npm version](https://img.shields.io/npm/v/@drumnation/unsplash-smart-mcp-server.svg)](https://www.npmjs.com/package/@drumnation/unsplash-smart-mcp-server)\n\n## 🚀 Why Choose This Unsplash Integration\n\nIn the landscape of visual content integration, our Unsplash Smart MCP Server stands out as the **definitive solution** for AI-powered image acquisition:\n\n- **🧠 AI-Agent Optimized**: Purpose-built for AI agents like Claude in Cursor, streamlining image requests with natural language\n- **🔍 Context-Aware Image Selection**: Interprets vague requests intelligently, delivering relevant images even from abstract prompts\n- **⚡ Single Tool Efficiency**: Eliminates tool spam with a unified `stock_photo` tool that handles the entire image workflow\n- **📊 Resource Optimization**: URL-first approach conserves bandwidth and storage while maintaining flexibility\n- **✅ Automatic Attribution**: Built-in compliance with Unsplash's Terms of Service with zero developer effort\n- **📁 Project-Aware Organization**: Intelligently organizes images based on your project structure (Next.js, React, Vue, etc.)\n- **🧩 Seamless Integration**: Designed for minimal setup and maximum compatibility with your existing workflow\n\n## ✨ Features Beyond Comparison\n\n### For AI Agent Developers\n\n- **Smart Contextual Search**: Find the perfect image through natural language requests\n- **Automatic Subject Selection**: AI determines optimal image subjects from your purpose description\n- **Intent-Driven Results**: Get images that match not just keywords, but the underlying intent\n- **Seamless Agent Integration**: Works out-of-the-box with Claude in Cursor and other MCP-compatible agents\n\n### For Project Efficiency\n\n- **Two-Step Workflow**: Get URLs for controlled downloads, avoiding permission issues and unnecessary storage\n- **Project-Aware File Management**: Auto-organizes images based on framework conventions\n- **Intelligent Directory Creation**: Creates appropriate folder structures based on your project type\n- **Progressive Enhancement**: Works with any project size, from quick prototypes to enterprise applications\n\n### For Compliance Peace of Mind\n\n- **Complete Attribution Management**:\n  - Local attribution database tracks all image usage\n  - Automatic embedding of photographer metadata in images (EXIF, IPTC, XMP)\n  - One-click generation of attribution pages in multiple formats\n  - Comprehensive API for attribution data\n\n## 🛠️ Installation\n\n### Prerequisites\n\n- Node.js 18.x or higher\n- An Unsplash API access key ([get one here](https://unsplash.com/developers))\n\n### Local Installation (Recommended)\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/drumnation/unsplash-smart-mcp-server.git\ncd unsplash-smart-mcp-server\n```\n\n2. Install dependencies:\n```bash\nnpm install\n```\n\n3. Configure your Cursor MCP settings:\n   - macOS: Edit `~/.cursor/mcp.json`\n   - Windows: Edit `%USERPROFILE%\\.cursor\\mcp.json`\n   - Linux: Edit `~/.cursor/mcp.json`\n\n4. Add the following configuration:\n```json\n{\n  \"servers\": {\n    \"unsplash\": {\n      \"command\": \"npx\",\n      \"args\": [\"tsx\", \"src/server.ts\"],\n      \"cwd\": \"/absolute/path/to/unsplash-smart-mcp-server\",\n      \"env\": {\n        \"UNSPLASH_ACCESS_KEY\": \"your_api_key_here\"\n      }\n    }\n  }\n}\n```\n\n5. Replace:\n   - `/absolute/path/to/unsplash-smart-mcp-server` with the actual path where you cloned the repo\n   - `your_api_key_here` with your Unsplash API key\n\n6. Save the file and restart Cursor.\n\n> **Important:** Unlike many MCP servers, this server requires direct process piping and cannot be accessed via TCP ports or through npm directly due to how it handles FastMCP's I/O interactions. The local installation method is the most reliable approach.\n\n### Cursor CLI Alternative\n\nIf you prefer using Cursor's CLI:\n\n```bash\nclaude mcp add unsplash npx tsx /path/to/unsplash-smart-mcp-server/src/server.ts --cwd /path/to/unsplash-smart-mcp-server\nclaude mcp config set unsplash UNSPLASH_ACCESS_KEY=your_api_key_here\n```\n\nReplace the paths and API key with your actual values.\n\n### Via Docker (Most Reliable Method)\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/drumnation/unsplash-smart-mcp-server.git\ncd unsplash-smart-mcp-server\n```\n\n2. Create a `docker-compose.yml` file:\n```yaml\nservices:\n  unsplash-mcp:\n    build: .\n    image: unsplash-mcp-server\n    restart: always\n    stdin_open: true\n    tty: true\n    environment:\n      - UNSPLASH_ACCESS_KEY=your_api_key_here\n```\n\n3. Build and start the container:\n```bash\ndocker-compose up -d\n```\n\n4. Configure your Cursor MCP settings:\n   - macOS: Edit `~/.cursor/mcp.json`\n   - Windows: Edit `%USERPROFILE%\\.cursor\\mcp.json`\n   - Linux: Edit `~/.cursor/mcp.json`\n\n5. Add the following configuration:\n```json\n{\n  \"servers\": {\n    \"unsplash\": {\n      \"command\": \"docker\",\n      \"args\": [\"exec\", \"-i\", \"unsplash-mcp-unsplash-mcp-1\", \"tsx\", \"src/server.ts\"],\n      \"env\": {}\n    }\n  }\n}\n```\n\n6. Save the file and restart Cursor.\n\nThis setup will:\n- Start the server automatically when Docker starts\n- Restart the server if it crashes\n- Run in the background without terminal windows\n- Provide a reliable connection to Cursor\n\n### Via Smithery (Cloud Deployment)\n\nIf you prefer cloud deployment, you can use Smithery:\n\n1. Install the server in Cursor via Smithery:\n\n```bash\nnpx @smithery/cli install @drumnation/unsplash-smart-mcp-server --client cursor --key your_api_key_here\n```\n\n2. Alternatively, you can log in to [Smithery.ai](https://smithery.ai) and deploy it through their web interface.\n\n> **Note for Windows users:** Smithery deployment includes special handling for Windows compatibility.\n\nFor detailed instructions and troubleshooting, see the [Smithery Deployment Guide](./docs/smithery-deployment.md).\n\n## 🧩 Integration with AI Agents\n\n### Step-by-Step Guide for Claude in Cursor\n\nOur Unsplash Smart MCP Server is designed to make image acquisition through AI agents effortless and intuitive:\n\n1. **Initiate a request**: Simply ask Claude for an image in natural language\n2. **AI interpretation**: Claude understands your needs and calls the `stock_photo` tool with optimized parameters\n3. **Smart image selection**: The server interprets context and finds the most relevant images\n4. **Presentation of options**: Claude presents you with the best matches and download commands\n5. **Seamless download**: Execute the suggested commands to place images exactly where you need them\n6. **Automatic attribution**: All attribution data is stored and can be accessed whenever needed\n\nThis process eliminates the traditional workflow of:\n1. ~~Searching Unsplash manually~~\n2. ~~Scrolling through hundreds of results~~\n3. ~~Downloading images to random locations~~\n4. ~~Moving files to the correct project folders~~\n5. ~~Manually tracking attribution data~~\n6. ~~Creating attribution pages~~\n\n### Example Prompts for AI Agents\n\nAsk Claude in Cursor for images using natural language prompts like these:\n\n```\n\"Find a professional image for a tech startup landing page hero section\"\n```\n\n## 🪟 Windows Compatibility\n\nIf you're using Windows and experiencing the \"Client closed\" error when running the MCP server in Cursor, follow these special configuration steps:\n\n### Windows-specific MCP Configuration\n\nCreate a file named `mcp.json` in your `.cursor` directory (typically at `%USERPROFILE%\\.cursor\\mcp.json`) with one of these configurations:\n\n#### Option 1: Direct Node Execution (Recommended)\n\n```json\n{\n  \"mcpServers\": {\n    \"stock_photo\": {\n      \"command\": \"node\",\n      \"args\": [\"./node_modules/.bin/tsx\", \"path/to/unsplash-mcp/src/server.ts\"],\n      \"disabled\": false,\n      \"env\": {\n        \"UNSPLASH_ACCESS_KEY\": \"your_api_key_here\"\n      },\n      \"shell\": false\n    }\n  }\n}\n```\n\n#### Option 2: PowerShell Approach\n\n```json\n{\n  \"mcpServers\": {\n    \"stock_photo\": {\n      \"command\": \"powershell\",\n      \"args\": [\"-Command\", \"npx tsx path/to/unsplash-mcp/src/server.ts\"],\n      \"disabled\": false,\n      \"env\": {\n        \"UNSPLASH_ACCESS_KEY\": \"your_api_key_here\"\n      }\n    }\n  }\n}\n```\n\nFor complete documentation on Windows compatibility, see [Windows Compatibility Guide](./docs/windows-compatibility.md).\n\n## 🛠️ API Reference\n\n### URL-First Approach: The Smart Choice\n\nOur architecture uses a URL-first approach rather than direct image embedding for several critical reasons:\n\n1. **Storage Efficiency**: Prevents AI agents from unnecessarily storing large binary data in their context\n2. **Bandwidth Conservation**: Reduces data transfer between services, improving response times\n3. **Placement Flexibility**: Allows developers to download images exactly where they're needed\n4. **Permission Management**: Avoids filesystem permission issues in restricted environments\n5. **Workflow Integration**: Seamlessly integrates with existing development pipelines\n\nThis strategy enables AI agents to intelligently suggest the optimal download location based on project context, without being constrained by their own environment limitations.\n\n### Minimizing Tool Spam and API Calls\n\nUnlike other solutions that require multiple tool calls for searching, filtering, downloading, and attributing images, our server:\n\n- **Unifies the entire image workflow** into a single `stock_photo` tool\n- **Optimizes result retrieval** by requesting more images upfront to enable better filtering\n- **Eliminates ping-pong interactions** between the agent and services\n- **Reduces agent token usage** by streamlining request and response formats\n\nThis design significantly reduces the number of API calls and tool invocations, leading to faster results and lower operational costs.\n\n## 🔄 Automatic Attribution and Compliance\n\n### Unsplash Terms of Service: Effortless Compliance\n\nUsing images from Unsplash requires adherence to their [Terms of Service](https://unsplash.com/license). Our server handles this automatically:\n\n1. **Attribution Data Capture**: Every image download automatically stores photographer information\n2. **Metadata Embedding**: Photographer details are embedded directly into image files\n3. **Attribution Database**: A local database maintains a record of all image usage\n4. **Attribution Generators**: Built-in tools create HTML and React attribution components\n5. **API Access**: Simple endpoints to retrieve attribution data for any project\n\nBy using our Unsplash Smart MCP Server, you are automatically compliant with Unsplash's requirements without any additional effort.\n\n### Attribution Management System\n\nThe server includes a comprehensive attribution management system:\n\n```javascript\n// Retrieve attribution data for your project\nconst attributions = await fetch('http://localhost:3000/api/unsplash', {\n  method: 'POST',\n  headers: { 'Content-Type': 'application/json' },\n  body: JSON.stringify({\n    method: 'get_attributions',\n    params: {\n      format: 'json',  // Options: json, html, react\n      projectPath: '/path/to/your/project'\n    }\n  })\n}).then(res => res.json());\n\n// attributions contains complete data about every image used\n```\n\nThe API can generate three types of attribution files:\n\n1. **JSON**: Structured data for custom implementations\n2. **HTML**: Ready-to-use HTML page for website footer or credits section\n3. **React**: Drop-in React component for modern web applications\n\n## 💼 Developer Workflow Integration\n\n### Real-World Use Cases\n\nOur Unsplash Smart MCP Server seamlessly integrates into your development workflow:\n\n#### UI Development\n- Instantly populate mockups with relevant placeholder images\n- Maintain consistent image dimensions across components\n- Organize images logically within your project structure\n\n#### Documentation\n- Enhance technical documentation with explanatory visuals\n- Create visually appealing tutorials and guides\n- Maintain proper attribution for all visual assets\n\n#### Content Creation\n- Quickly find images for blog posts and articles\n- Generate visuals for social media content\n- Access consistent imagery for product marketing\n\n#### Application Development\n- Populate e-commerce sites with product imagery\n- Create visually rich user experiences\n- Maintain separate image collections for different sections\n\n### Framework-Specific Organization\n\nImages are automatically organized based on your project type:\n\n| Framework | Default Image Path | Alternate Paths |\n|-----------|-------------------|----------------|\n| Next.js   | `/public/images/` | `/public/assets/images/` |\n| React     | `/src/assets/images/` | `/assets/images/` |\n| Vue       | `/src/assets/images/` | `/public/images/` |\n| Angular   | `/src/assets/images/` | `/assets/images/` |\n| Generic   | `/assets/images/` | `~/Downloads/stock-photos/` |\n\n## 🥇 Competitive Differentiation\n\n### Why Choose Our Unsplash Integration?\n\n| Feature | Unsplash Smart MCP Server | Alternatives |\n|---------|--------------|--------------|\n| **AI Agent Integration** | ✅ Purpose-built for AI agent workflow | ❌ Typically requires manual parameter setting |\n| **Context Awareness** | ✅ Interprets vague requests intelligently | ❌ Relies on exact keyword matching |\n| **Tool Efficiency** | ✅ Single tool handles entire workflow | ❌ Often requires multiple separate tools |\n| **Attribution Management** | ✅ Comprehensive system with multiple formats | ❌ Manual tracking or basic text output |\n| **Project Organization** | ✅ Framework-aware folder structures | ❌ Generic downloads to a single location |\n| **Installation Complexity** | ✅ Simple one-line command | ❌ Often requires multiple configuration steps |\n| **Response Format** | ✅ AI-optimized with relevant context | ❌ Generic JSON requiring further processing |\n| **Download Flexibility** | ✅ URL-first with intelligent suggestions | ❌ Either direct downloads or just URLs |\n\n## ⚙️ Configuration\n\n### Environment Variables\n\n| Variable | Description | Default |\n|----------|-------------|---------|\n| `UNSPLASH_ACCESS_KEY` | Your Unsplash API access key | - |\n| `PORT` | Port for the server to listen on | `3000` |\n| `HOST` | Host for the server | `localhost` |\n| `ATTRIBUTION_DB_PATH` | Path to store attribution database | `~/.unsplash-mcp` |\n\n### Tool Parameters\n\n#### stock_photo\n\n| Parameter | Type | Description | Default |\n|-----------|------|-------------|---------|\n| `query` | string | What to search for (AI will choose if not specified) | - |\n| `purpose` | string | Where the image will be used (e.g., hero, background) | - |\n| `count` | number | Number of images to return | `1` |\n| `orientation` | string | Preferred orientation (any, landscape, portrait, square) | `any` |\n| `width` | number | Target width in pixels | - |\n| `height` | number | Target height in pixels | - |\n| `minWidth` | number | Minimum width for filtering results | - |\n| `minHeight` | number | Minimum height for filtering results | - |\n| `outputDir` | string | Directory to save photos | `~/Downloads/stock-photos` |\n| `projectType` | string | Project type for folder structure (next, react, vue, angular) | - |\n| `category` | string | Category for organizing images (e.g., heroes, backgrounds) | - |\n| `downloadMode` | string | Whether to download images or return URLs | `urls_only` |\n\n#### get_attributions\n\n| Parameter | Type | Description | Default |\n|-----------|------|-------------|---------|\n| `format` | string | Output format (json, html, react) | `json` |\n| `projectPath` | string | Filter attributions to a specific project path | - |\n| `outputPath` | string | Where to save attribution files | - |\n\n## 🔧 Troubleshooting\n\n### Common Issues and Solutions\n\n| Issue | Solution |\n|-------|----------|\n| **Connection Refused** | Ensure the server is running on the configured port |\n| **Authentication Error** | Verify your Unsplash API key is correctly set |\n| **No Images Found** | Try broader search terms or check your search query |\n| **Download Permission Issues** | Use `downloadMode: 'urls_only'` and manual download commands |\n| **Docker Container Exits Prematurely** | Ensure you're using `CMD [\"npm\", \"start\"]` in your Dockerfile instead of directly running the TypeScript file with tsx. This ensures the server stays running in a Docker environment. |\n| **Timeout Errors** | The default MCP timeout is 60 seconds, which may be insufficient for downloading larger images or processing multiple images. For image-heavy operations: 1) Process fewer images per request, 2) Use smaller image dimensions, 3) Consider using `urls_only` mode instead of auto-download, 4) Check network connectivity |\n| **Attribution Not Found** | Verify the image was downloaded through the MCP server |\n| **Unhandled MCP Errors** | If you see `\"McpError: MCP error -32001: Request timed out\"` errors, your request is likely taking too long. Break it into smaller operations or use the URLs-only approach |\n\n## 🤝 Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n### Development Workflow\n\n1. Clone the repository\n2. Install dependencies with `npm install`\n3. Create a `.env` file with your Unsplash API key\n4. Run in development mode with `npm run dev`\n5. Run tests with `npm test`\n\n## 🗺️ Roadmap\n\nHere's what we're planning for future releases:\n\n- **Image Editing Capabilities**: Basic resizing, cropping, and adjustment tools\n- **Advanced Search Filters**: More granular control over image selection\n- **Batch Processing**: Handle multiple image requests efficiently\n- **Custom Collections**: Save and manage groups of images for projects\n- **Team Collaboration**: Share attribution and image collections\n- **Usage Analytics**: Track image usage across projects\n- **Additional Image Sources**: Integration with other stock photo providers\n- **Improved Timeout Handling**: Enhanced timeout configuration and recovery mechanisms\n\n## 📄 License\n\nMIT License\n\n## 📚 Attribution Requirements\n\nWhen using images from Unsplash, you must comply with the [Unsplash License](https://unsplash.com/license):\n\n- Attribution is not required but appreciated\n- You cannot sell unaltered copies of the photos\n- You cannot compile photos from Unsplash to create a competing service\n\nOur server's attribution system makes it easy to provide proper credit to photographers.\n\n## 📞 Contact\n\nFor issues or questions, please [open an issue](https://github.com/drumnation/unsplash-smart-mcp-server/issues) on GitHub.\n\n## 🧰 Development and Testing\n\n### Running the Server Locally\n\n```bash\n# Clone the repository\ngit clone https://github.com/drumnation/unsplash-smart-mcp-server.git\ncd unsplash-smart-mcp-server\n\n# Install dependencies\nnpm install\n\n# Set up your environment variables\ncp .env.example .env\n# Edit .env to add your UNSPLASH_ACCESS_KEY\n\n# Start the development server\nnpm run dev\n```\n\n### Testing\n\nThe package includes a comprehensive test suite:\n\n```bash\n# Run core tests\nnpm test\n\n# Run all tests and get a summary report\nnpm run test:all\n```\n\nThe test suite includes:\n- Unit and integration tests\n- Manual tool testing\n- Docker container tests\n- Smithery.ai integration tests\n\nFor detailed information about testing, see [docs/testing.md](docs/testing.md).\n\n---\n\n<p align=\"center\">\n  <strong>Empower your AI agents with the perfect images, every time.</strong><br>\n  Built with ❤️ for developers and AI enthusiasts.\n</p>\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ai",
        "mcp",
        "attribution",
        "smart mcp",
        "automatic attribution",
        "photos context"
      ],
      "category": "image-and-video-generation"
    },
    "dvejsada--mcp_media_generator": {
      "owner": "dvejsada",
      "name": "mcp_media_generator",
      "url": "https://github.com/dvejsada/mcp_media_generator",
      "imageUrl": "/freedevtools/mcp/pfp/dvejsada.webp",
      "description": "Create images using the Amazon Nova Canvas model and videos using the Amazon Nova Reel model. Connects to existing tools for media generation and storage.",
      "stars": 3,
      "forks": 3,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-09-16T11:26:11Z",
      "readme_content": "# What is it?\n\nA [Model Context Protocol](https://modelcontextprotocol.io/) Server running over SSE\n\n# What it offers?\n\nTools to create images using Amazon Nova Canvas model and videos using Amazon Nova Reel model.\n\n# What do I need?\n\n- Amazon Bedrock account with access to Amazon Nova Canvas and Amazon Nova Reel models.\n- Amazon S3 bucket to store the video\n- MCP Client, such is Claude Desktop or [LibreChat](https://github.com/danny-avila/LibreChat)\n\n# How to run this?\n\nUsing Docker with precompiled image as per docker-compose.yml. App is listening on port 8961.\n\n## How to add to LibreChat\n\nIn your librechat.yaml file, add the following section:\n\n```yaml\nmcpServers:\n  media-creator:\n    type: sse # type can optionally be omitted\n    url: URL of your docker container # e.g. http://localhost:8961/sse\n```\n\n## How to use in LibreChat\n\nAfter the server is added to LibreChat as per above, restart LibreChat to connect to MCP server and discover tools. Then, create an agent and add the respective tools to agent.\n\nWhen the agent is created, you may ask the agent to create image or video which should invoke the provided tools.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcp_media_generator",
        "dvejsada",
        "videos",
        "dvejsada mcp_media_generator",
        "video generation",
        "generation dvejsada"
      ],
      "category": "image-and-video-generation"
    },
    "el-el-san--vidu-mcp-server": {
      "owner": "el-el-san",
      "name": "vidu-mcp-server",
      "url": "https://github.com/el-el-san/vidu-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/el-el-san.webp",
      "description": "Generate videos from static images using advanced AI models, while monitoring the status of video generation tasks and uploading images for processing.",
      "stars": 3,
      "forks": 2,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-09T11:11:26Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/el-el-san-vidu-mcp-server-badge.png)](https://mseep.ai/app/el-el-san-vidu-mcp-server)\n\n# Vidu MCP Server\n[![smithery badge](https://smithery.ai/badge/@el-el-san/vidu-mcp-server)](https://smithery.ai/server/@el-el-san/vidu-mcp-server)\n\nVidu動画生成APIと連携するためのModel Context Protocol (MCP) サーバーです。Viduの強力なAIモデルを使用して、画像から動画を生成するツールを提供します。\n\n## 機能\n\n- **画像から動画への変換**: カスタマイズ可能な設定で静止画から動画を生成\n  - 複数モデル対応: viduq1、vidu1.5、vidu2.0\n  - モデル固有の時間・解像度制約\n  - 4秒動画向けのBGM対応\n  - 非同期通知用のコールバックURL対応\n- **生成状況の確認**: クレジット使用量情報付きで動画生成タスクの進捗を監視\n- **画像アップロード**: Vidu APIで使用する画像を簡単にアップロード（最大10MB）\n\n## 前提条件\n\n- Node.js (v14以上)\n- Vidu APIキー（[Viduウェブサイト](https://vidu.com)から取得可能）\n- TypeScript（開発用）\n\n## インストール\n\n### Smithery経由でのインストール\n\n[Smithery](https://smithery.ai/server/@el-el-san/vidu-mcp-server)を使用してClaude Desktop用のVidu Video Generation Serverを自動インストール:\n\n```bash\nnpx -y @smithery/cli install @el-el-san/vidu-mcp-server --client claude\n```\n\n### Gemini CLI設定\n\nGemini CLIで使用するには、`~/.gemini/settings.json`にサーバー設定を追加してください:\n\n```json\n{\n  \"mcpServers\": {\n    \"vidu\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"your_path/vidu-mcp-server/build/index.js\"\n      ],\n      \"env\": {\n        \"VIDU_API_KEY\": \"your_api_key_here\"\n      }\n    }\n  }\n}\n```\n\n**注意**: `your_path`を実際のインストールディレクトリのパスに、`your_api_key_here`をあなたのVidu APIキーに置き換えてください。\n\n### 手動インストール\n1. このリポジトリをクローン:\n```bash\ngit clone https://github.com/el-el-san/vidu-mcp-server.git\ncd vidu-mcp-server\n```\n\n2. 依存関係をインストール:\n```bash\nnpm install\n```\n\n3. `.env.template`を基に`.env`ファイルを作成し、Vidu APIキーを追加:\n```\nVIDU_API_KEY=your_api_key_here\n```\n\n## 使用方法\n\n### Gemini CLI用\n\n1. TypeScriptコードをビルド:\n```bash\nnpm run build\n```\n\n2. Gemini CLI設定で設定（上記のGemini CLI設定セクションを参照）\n\n3. Gemini CLIを再起動してMCPを読み込み\n\n## ツール\n\n### 1. 画像から動画への変換\n\nカスタマイズ可能なパラメータで静止画を動画に変換します。\n\nパラメータ:\n- `image_url` (必須): 動画に変換する画像のURL\n- `prompt` (オプション): 動画生成用のテキストプロンプト（最大1500文字）\n- `duration` (オプション): 出力動画の時間（秒）（モデル固有）\n  - **viduq1**: 5秒のみ\n  - **vidu1.5/vidu2.0**: 4秒または8秒（デフォルト4秒）\n- `model` (オプション): 生成用モデル名（\"viduq1\", \"vidu1.5\", \"vidu2.0\", デフォルト \"vidu2.0\"）\n- `resolution` (オプション): 出力動画の解像度（モデル/時間固有）\n  - **viduq1 (5s)**: 1080pのみ\n  - **vidu1.5/vidu2.0 (4s)**: \"360p\", \"720p\", \"1080p\"（デフォルト \"360p\"）\n  - **vidu1.5/vidu2.0 (8s)**: \"720p\"のみ\n- `movement_amplitude` (オプション): フレーム内オブジェクトの動きの振幅（\"auto\", \"small\", \"medium\", \"large\", デフォルト \"auto\"）\n- `seed` (オプション): 再現性のためのランダムシード\n- `bgm` (オプション): 動画にBGMを追加（boolean, デフォルト false, 4秒動画のみ）\n- `callback_url` (オプション): 生成状況変更時の非同期通知用URL\n\nリクエスト例:\n```json\n{\n  \"image_url\": \"https://example.com/image.jpg\",\n  \"prompt\": \"山を背景にした静かな湖\",\n  \"duration\": 8,\n  \"model\": \"vidu2.0\",\n  \"resolution\": \"720p\",\n  \"movement_amplitude\": \"medium\",\n  \"seed\": 12345,\n  \"bgm\": false\n}\n```\n\n### 2. 生成状況の確認\n\n実行中の動画生成タスクの状況を確認します。\n\nパラメータ:\n- `task_id` (必須): 画像から動画への変換ツールで返されたタスクID\n\nリクエスト例:\n```json\n{\n  \"task_id\": \"12345abcde\"\n}\n```\n\n### 3. 画像アップロード\n\nVidu APIで使用する画像をアップロードします。\n\nパラメータ:\n- `image_path` (必須): 画像ファイルのローカルパス\n- `image_type` (必須): 画像ファイルタイプ（\"png\", \"webp\", \"jpeg\", \"jpg\"）\n\nリクエスト例:\n```json\n{\n  \"image_path\": \"/path/to/your/image.jpg\",\n  \"image_type\": \"jpg\"\n}\n```\n\n## トラブルシューティング\n\n- **APIキーの問題**: Vidu APIキーが`.env`ファイル（手動設定の場合）またはGemini CLI設定（Gemini CLI設定の場合）で正しく設定されていることを確認してください\n- **ファイルアップロードエラー**: 画像ファイルが有効で、サイズ制限内（upload-imageツールは10MB、直接URL画像は最大50MB）であることを確認してください\n- **接続問題**: インターネットアクセスがあり、Vidu APIサーバーに到達できることを確認してください\n- **Gemini CLIの問題**: \n  - Gemini CLIで設定する前にサーバーがビルドされている（`npm run build`）ことを確認してください\n  - settings.jsonのパスが正しい`build/index.js`ファイルを指していることを確認してください\n  - 設定変更後にGemini CLIを再起動してください\n  - サーバー設定で`\"disabled\": false`に設定してください\n\n\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ai",
        "videos",
        "vidu",
        "generate videos",
        "video generation",
        "image video"
      ],
      "category": "image-and-video-generation"
    },
    "evalstate--mcp-hfspace": {
      "owner": "evalstate",
      "name": "mcp-hfspace",
      "url": "https://github.com/evalstate/mcp-hfspace",
      "imageUrl": "/freedevtools/mcp/pfp/evalstate.webp",
      "description": "Connects to Hugging Face Spaces to access various AI models for tasks including image generation, text-to-speech, speech-to-text, and chat functionalities, requiring minimal setup.",
      "stars": 360,
      "forks": 57,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T22:31:58Z",
      "readme_content": "# mcp-hfspace MCP Server 🤗\n\n> [!TIP]\n>\n> You can access and configure Hugging Face MCP services directly at https://hf.co/mcp, including Gradio spaces.\n>\n> This project has been superceded by the official [Hugging Face MCP Server](https://github.com/evalstate/hf-mcp-server) and [Gradio MCP Endpoints](https://huggingface.co/blog/gradio-mcp).\n> \n> Alternatively you can run hf-mcp-server locally as a STDIO Server, or with robust support for SSE, Streaming HTTP and Streaming HTTP JSON Mode. This also runs a local UI for selecting tools and endpoints and supports `ToolListChangedNotifications` too.\n\n## hf.co/mcp\n\n![image](https://github.com/user-attachments/assets/9cbf407b-2330-4330-8274-e47305a555b9)\n\n## mcp-hfspace\n\nRead the introduction here [llmindset.co.uk/resources/mcp-hfspace/](https://llmindset.co.uk/resources/mcp-hfspace/)\n\nConnect to [Hugging Face Spaces](https://huggingface.co/spaces) with minimal setup needed - simply add your spaces and go!\n\nBy default, it connects to `black-forest-labs/FLUX.1-schnell` providing Image Generation capabilities to Claude Desktop.\n\n\n\n\n\n\n\n## Gradio MCP Support\n\n> [!TIP]\n> Gradio 5.28 now has integrated MCP Support via SSE: https://huggingface.co/blog/gradio-mcp. Check out whether your target Space is MCP Enabled!\n\n## Installation\n\nNPM Package is `@llmindset/mcp-hfspace`.\n\nInstall a recent version of [NodeJS](https://nodejs.org/en/download) for your platform, then add the following to the `mcpServers` section of your `claude_desktop_config.json` file:\n\n```json\n    \"mcp-hfspace\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@llmindset/mcp-hfspace\"\n      ]\n    }\n```\n\nPlease make sure you are using Claude Desktop 0.78 or greater.\n\nThis will get you started with an Image Generator.\n\n### Basic setup\n\nSupply a list of HuggingFace spaces in the arguments. mcp-hfspace will find the most appropriate endpoint and automatically configure it for usage. An example `claude_desktop_config.json` is supplied [below](#installation).\n\nBy default the current working directory is used for file upload/download. On Windows this is a read/write folder at `\\users\\<username>\\AppData\\Roaming\\Claude\\<version.number\\`, and on MacOS it is the is the read-only root: `/`.\n\nIt is recommended to override this and set a Working Directory for handling the upload and download of images and other file-based content. Specify either the `--work-dir=/your_directory` argument or `MCP_HF_WORK_DIR` environment variable.\n\nAn example configuration for using a modern image generator, vision model and text to speech, with a working directory set is below:\n\n```json\n    \"mcp-hfspace\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@llmindset/mcp-hfspace\",\n        \"--work-dir=/Users/evalstate/mcp-store\",\n        \"shuttleai/shuttle-jaguar\",\n        \"styletts2/styletts2\",\n        \"Qwen/QVQ-72B-preview\"\n      ]\n    }\n```\n\nTo use private spaces, supply your Hugging Face Token with either the `--hf-token=hf_...` argument or `HF_TOKEN` environment variable.\n\nIt's possible to run multiple server instances to use different working directories and tokens if needed.\n\n## File Handling and Claude Desktop Mode\n\nBy default, the Server operates in _Claude Desktop Mode_. In this mode, Images are returned in the tool responses, while other files are saved in the working folder, their file path is returned as a message. This will usually give the best experience if using Claude Desktop as the client.\n\nURLs can also be supplied as inputs: the content gets passed to the Space.\n\nThere is an \"Available Resources\" prompt that gives Claude the available files and mime types from your working directory. This is currently the best way to manage files.\n\n### Example 1 - Image Generation (Download Image / Claude Vision)\n\nWe'll use Claude to compare images created by `shuttleai/shuttle-3.1-aesthetic` and `FLUX.1-schnell`. The images gets saved to the Work Directory, as well as included in Claude's context window - so Claude can use its vision capabilities.\n\n\n\n### Example 2 - Vision Model (Upload Image)\n\nWe'll use `merve/paligemma2-vqav2` [space link](https://huggingface.co/spaces/merve/paligemma2-vqav2) to query an image. In this case, we specify the filename which is available in the Working Directory: we don't want to upload the Image directly to Claude's context window. So, we can prompt Claude:\n\n`use paligemma to find out who is in \"test_gemma.jpg\"` -> `Text Output: david bowie`\n\n\n_If you are uploading something to Claude's context use the Paperclip Attachment button, otherwise specify the filename for the Server to send directly._\n\nWe can also supply a URL. For example : `use paligemma to detect humans in https://e3.365dm.com/24/12/1600x900/skynews-taylor-swift-eras-tour_6771083.jpg?20241209000914` -> `One person is detected in the image - Taylor Swift on stage.`\n\n### Example 3 - Text-to-Speech (Download Audio)\n\nIn _Claude Desktop Mode_, the audio file is saved in the WORK_DIR, and Claude is notified of the creation. If not in desktop mode, the file is returned as a base64 encoded resource to the Client (useful if it supports embedded Audio attachments).\n\n\n\n### Example 4 - Speech-to-Text (Upload Audio)\n\nHere, we use `hf-audio/whisper-large-v3-turbo` to transcribe some audio, and make it available to Claude.\n\n\n\n### Example 5 - Image-to-Image\n\nIn this example, we specify the filename for `microsoft/OmniParser` to use, and get returned an annotated Image and 2 separate pieces of text: descriptions and coordinates. The prompt used was `use omniparser to analyse ./screenshot.png` and `use the analysis to produce an artifact that reproduces that screen`. `DawnC/Pawmatch` is also good at this.\n\n\n\n### Example 6 - Chat\n\nIn this example, Claude sets a number of reasoning puzzles for Qwen, and asks follow-up questions for clarification.\n\n\n\n### Specifying API Endpoint\n\nIf you need, you can specify a specific API Endpoint by adding it to the spacename. So rather than passing in `Qwen/Qwen2.5-72B-Instruct` you would use `Qwen/Qwen2.5-72B-Instruct/model_chat`.\n\n### Claude Desktop Mode\n\nThis can be disabled with the option --desktop-mode=false or the environment variable CLAUDE_DESKTOP_MODE=false. In this case, content as returned as an embedded Base64 encoded Resource.\n\n## Recommended Spaces\n\nSome recommended spaces to try:\n\n### Image Generation\n\n- shuttleai/shuttle-3.1-aesthetic\n- black-forest-labs/FLUX.1-schnell\n- yanze/PuLID-FLUX\n- gokaygokay/Inspyrenet-Rembg (Background Removal)\n- diyism/Datou1111-shou_xin - [Beautiful Pencil Drawings](https://x.com/ClementDelangue/status/1867318931502895358)\n\n### Chat\n\n- Qwen/Qwen2.5-72B-Instruct\n- prithivMLmods/Mistral-7B-Instruct-v0.3\n\n### Text-to-speech / Audio Generation\n\n- fantaxy/Sound-AI-SFX\n- parler-tts/parler_tts\n\n### Speech-to-text\n\n- hf-audio/whisper-large-v3-turbo\n- (the openai models use unnamed parameters so will not work)\n\n### Text-to-music\n\n- haoheliu/audioldm2-text2audio-text2music\n\n### Vision Tasks\n\n- microsoft/OmniParser\n- merve/paligemma2-vqav2\n- merve/paligemma-doc\n- DawnC/PawMatchAI\n- DawnC/PawMatchAI/on_find_match_click - for interactive dog recommendations\n\n## Other Features\n\n### Prompts\n\nPrompts for each Space are generated, and provide an opportunity to input. Bear in mind that often Spaces aren't configured with particularly helpful labels etc. Claude is actually very good at figuring this out, and the Tool description is quite rich (but not visible in Claude Desktop).\n\n### Resources\n\nA list of files in the WORK_DIR is returned, and as a convenience returns the name as \"Use the file...\" text. If you want to add something to Claude's context, use the paperclip - otherwise specify the filename for the MCP Server. Claude does not support transmitting resources from within Context.\n\n### Private Spaces\n\nPrivate Spaces are supported with a HuggingFace token. The Token is used to download and save generated content.\n\n### Using Claude Desktop\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-hfspace\": {\n      \"command\": \"npx\"\n      \"args\": [\n        \"-y\",\n        \"@llmindset/mcp-hfspace\",\n        \"--work-dir=~/mcp-files/ or x:/temp/mcp-files/\",\n        \"--HF_TOKEN=HF_{optional token}\"\n        \"Qwen/Qwen2-72B-Instruct\",\n        \"black-forest-labs/FLUX.1-schnell\",\n        \"space/example/specific-endpint\"\n        (... and so on)\n        ]\n    }\n  }\n}\n```\n\n## Known Issues and Limitations\n\n### mcp-hfspace\n\n- Endpoints with unnamed parameters are unsupported for the moment.\n- Full translation from some complex Python types to suitable MCP formats.\n\n### Claude Desktop\n\n- Claude Desktop 0.75 doesn't seem to respond to errors from the MCP Server, timing out instead. For persistent issues, use the MCP Inspector to get a better look at diagnosing what's going wrong. If something suddenly stops working, it's probably due to exhausting your HuggingFace ZeroGPU quota - try again after a short period, or set up your own Space for hosting.\n- Claude Desktop seems to use a hard timeout value of 60s, and doesn't appear to use Progress Notifications to manage UX or keep-alive. If you are using ZeroGPU spaces, large/heavy jobs may timeout. Check the WORK_DIR for results though; the MCP Server will still capture and save the result if it was produced.\n- Claude Desktops reporting of Server Status, logging etc. isn't great - use [@modelcontextprotocol/inspector](https://github.com/modelcontextprotocol/inspector) to help diagnose issues.\n\n### HuggingFace Spaces\n\n- If ZeroGPU quotas or queues are too long, try duplicating the space. If your job takes less than sixty seconds, you can usually change the function decorator `@spaces.GPU(duration=20)` in `app.py` to request less quota when running the job.\n- Passing HF_TOKEN will make ZeroGPU quotas apply to your (Pro) HF account\n- If you have a private space, and dedicated hardware your HF_TOKEN will give you direct access to that - no quota's apply. I recommend this if you are using for any kind of Production task.\n\n## Third Party MCP Services\n\n<a href=\"https://glama.ai/mcp/servers/s57c80wvgq\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/s57c80wvgq/badge\" alt=\"mcp-hfspace MCP server\" /></a>",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "hfspace",
        "ai",
        "mcp",
        "mcp hfspace",
        "face spaces",
        "image generation"
      ],
      "category": "image-and-video-generation"
    },
    "evalstate--mcp-webcam": {
      "owner": "evalstate",
      "name": "mcp-webcam",
      "url": "https://github.com/evalstate/mcp-webcam",
      "imageUrl": "/freedevtools/mcp/pfp/evalstate.webp",
      "description": "Streams live images from a webcam to an MCP Client, supporting both capturing frames and taking screenshots.",
      "stars": 90,
      "forks": 10,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T23:37:10Z",
      "readme_content": "# ⭐⭐ mcp-webcam 0.2.0 - the 50 Star Update ⭐⭐ \n\nIn celebration of getting 52 GitHub stars, `mcp-webcam 0.2.0` is here! Now supports streamable-http!! No installation required! - try it now at [`https://webcam.fast-agent.ai/`](https://webcam.fast-agent.ai/). You can specify your own UserID by adding `?user=<YOUR_USER_ID>` after the URL. Note this shared instance is for fun, not security - see below for instructions how to run your own copy locally.\n\nIn streamable-http mode multiple clients can connect simultaneously, and you can choose which is used for Sampling.\n\n![mcp_webcam_020_thumb](https://github.com/user-attachments/assets/041e3091-71e5-4aa1-9170-ee20177485ef)\n\nIf we get to 100 stars I'll add another feature 😊.\n\n## Multi-user Mode\n\nWhen run in Streaming mode, if you set an MCP_HOST environment variable the host name is used as a prefix in URL construction, and 5 character UserIDs are automatically generated when the User lands on the webpage. \n\n![image](https://github.com/user-attachments/assets/30d06cc2-59b6-485b-989d-7030b39c287d)\n\n\n## mcp-webcam\n\nMCP Server that provides access to your WebCam. Provides `capture` and `screenshot` tools to take an image from the Webcam, or take a screenshot. The current image is also available as a Resource.\n\n### MCP Sampling\n\n`mcp-webcam` supports \"sampling\"! Press the \"Sample\" button to send a sampling request to the Client along with your entered message. \n\n> [!TIP]\n> Claude Desktop does not currently support Sampling. If you want a Client that can handle multi-modal sampling request, try https://github.com/evalstate/fast-agent/ or VSCode (more details below).\n\n## Installation and Running\n\n### NPX\n\nInstall a recent version of [NodeJS](https://nodejs.org/en/download) for your platform. The NPM package is `@llmindset/mcp-webcam`. \n\nTo start in **STDIO** mode: `npx @llmindset/mcp-webcam`. This starts the `mcp-webcam` UI on port 3333. Point your browser at `http://localhost:3333` to get started.\n\nTo change the port: `npx @llmindset/mcp-webcam 9999`. This starts `mcp-webcam` the UI on port 9999.\n\nFor **Streaming HTTP** mode: `npx @llmindset/mcp-webcam --streaming`. This will make the UI available at `http://localhost:3333` and the MCP Server available at `http://localhost:3333/mcp`.\n\n### Docker\n\nYou can run `mcp-webcam` using Docker. By default, it starts in **streaming mode**:\n\n```bash\ndocker run -p 3333:3333 ghcr.io/evalstate/mcp-webcam:latest\n```\n\n#### Environment Variables\n\n- `MCP_TRANSPORT_MODE` - Set to `stdio` for STDIO mode, defaults to `streaming`\n- `PORT` - The port to run on (default: `3333`)\n- `BIND_HOST` - Network interface to bind the server to (default: `localhost`)\n- `MCP_HOST` - Public-facing URL for user instructions and MCP client connections (default: `http://localhost:3333`)\n\n#### Examples\n\n```bash\n# STDIO mode\ndocker run -p 3333:3333 -e MCP_TRANSPORT_MODE=stdio ghcr.io/evalstate/mcp-webcam:latest\n\n# Custom port\ndocker run -p 8080:8080 -e PORT=8080 ghcr.io/evalstate/mcp-webcam:latest\n\n# For cloud deployments with custom domain (e.g., Hugging Face Spaces)\ndocker run -p 3333:3333 -e MCP_HOST=https://evalstate-mcp-webcam.hf.space ghcr.io/evalstate/mcp-webcam:latest\n\n# Complete cloud deployment example\ndocker run -p 3333:3333 -e MCP_HOST=https://your-domain.com ghcr.io/evalstate/mcp-webcam:latest\n```\n\n## Clients\n\nIf you want a Client that supports sampling try:\n\n### fast-agent\n\nStart the `mcp-webcam` in streaming mode, install [`uv`](https://docs.astral.sh/uv/) and connect with:\n\n`uvx fast-agent-mcp go --url http://localhost:3333/mcp`\n\n`fast-agent` currently uses Haiku as its default model, so set an `ANTHROPIC_API_KEY`. If you want to use a different model, you can add `--model` on the command line. More instructions for installation and configuration are available here: https://fast-agent.ai/models/.\n\nTo start the server in STDIO mode, add the following to your `fastagent.config.yaml`\n\n```yaml\nwebcam_local:\n   command: \"npx\"\n   args: [\"@llmindset/mcp-webcam\"]\n```\n\n### VSCode\n\nVSCode versions 1.101.0 and above support MCP Sampling. Simply start `mcp-webcam` in streaming mode, and add `http://localhost:3333/mcp` as an MCP Server to get started.\n\n### Claude Desktop\n\nClaude Desktop does **NOT** support Sampling. To run `mcp-webcam` from Claude Desktop, add the following to the `mcpServers` section of your `claude_desktop_config.json` file:\n\n```json\n    \"webcam\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@llmindset/mcp-webcam\"\n      ]\n    }\n```\n\nStart Claude Desktop, and connect to `http://localhost:3333`. You can then ask Claude to `get the latest picture from my webcam`, or `Claude, take a look at what I'm holding` or `what colour top am i wearing?`. You can \"freeze\" the current image and that will be returned to Claude rather than a live capture. \n\nYou can ask for Screenshots - navigate to the browser so that you can guide the capture area when the request comes in. Screenshots are automatically resized to be manageable for Claude (useful if you have a 4K Screen). The button is there to allow testing of your platform specific Screenshot UX - it doesn't do anything other than prepare you for a Claude intiated request. NB this does not **not** work on Safari as it requires human initiation.\n\n## Other notes\n\nThat's it really. \n\nThis MCP Server was built to demonstrate exposing a User Interface on an MCP Server, and serving live resources back to Claude Desktop.\n\nThis project might prove useful if you want to build a local, interactive MCP Server.\n\nThanks to  https://github.com/tadasant for help with testing and setup. \n\nPlease read the article at [https://llmindset.co.uk/posts/2025/01/resouce-handling-mcp](https://llmindset.co.uk/posts/2025/01/mcp-files-resources-part1/) for more details about handling files and resources in LLM / MCP Chat Applications, and why you might want to do this.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "webcam",
        "mcp",
        "capturing",
        "mcp webcam",
        "webcam mcp",
        "images webcam"
      ],
      "category": "image-and-video-generation"
    },
    "falahgs--MCP-Storybook-Image-Generator": {
      "owner": "falahgs",
      "name": "MCP-Storybook-Image-Generator",
      "url": "https://github.com/falahgs/MCP-Storybook-Image-Generator",
      "imageUrl": "/freedevtools/mcp/pfp/falahgs.webp",
      "description": "Generates high-quality storybook images and matching children's stories using Google's Gemini AI, offering multiple art styles such as 3D cartoon, watercolor, and pixel art. It allows instant previewing of creations and saves them locally in an organized manner.",
      "stars": 3,
      "forks": 2,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-08-12T03:16:03Z",
      "readme_content": "# MCP Storybook Image Generator\n\nA professional-grade server that generates beautiful storybook images with matching children's stories using Google's Gemini AI.\n\n## 🎬 Demo\n\n\n\n## 🌟 Features\n\n- **Storybook Image Generation**: Creates high-quality images in various art styles for children's stories\n- **Automatic Story Creation**: Generates engaging children's stories to match the images\n- **Multiple Art Styles**: Choose from 3D cartoon, watercolor, pixel art, hand drawn, or claymation styles\n- **Instant Preview**: Automatically opens generated images and stories in your browser\n- **Local Storage**: Saves images and stories in an organized output directory\n\n## 🛠️ Technical Stack\n\n- **Core Framework**: Model Context Protocol (MCP) SDK\n- **AI Integration**: Google Generative AI (Gemini)\n- **Runtime**: Node.js v14+\n- **Language**: TypeScript\n- **Package Manager**: npm\n\n## 📋 Prerequisites\n\n- Node.js (v14 or higher)\n- Google Gemini API key\n- TypeScript\n\n## ⚙️ Installation\n\n1. Install dependencies:\n```bash\nnpm install\n```\n\n3. Configure environment:\nCreate a `.env` file in the root directory:\n```env\nGEMINI_API_KEY=your_api_key_here\n```\n\n4. Build the project:\n```bash\nnpm run build\n```\n\n## 🚀 Using the CLI\n\nYou can use the storybook generator directly from the command line:\n\n```bash\n# Using npx (after publishing to npm)\nnpx mcp-storybook-image-generator --api-key your_api_key_here --save-to-desktop\n\n# Or run locally\nnode build/cli.js --api-key your_api_key_here --save-to-desktop\n```\n\n### Command Line Options\n\n| Option | Description |\n|--------|-------------|\n| `--api-key <key>` | Set your Gemini API key |\n| `--save-to-desktop` | Save generated files to desktop |\n| `--debug` | Enable debug logging |\n| `--help` | Show help information |\n\n## 🔧 Configuring Claude Desktop with MCP Server\n\nTo integrate this server with Claude Desktop:\n\n1. Locate the Claude Desktop Configuration File:\n   - Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n   - macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - Linux: `~/.config/Claude/claude_desktop_config.json`\n\n2. Add the following configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"storybook-generator\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"mcp-storybook-image-generator@latest\",\n        \"--api-key\",\n        \"your_gemini_api_key_here\"\n      ],\n      \"env\": {\n        \"SAVE_TO_DESKTOP\": \"true\",\n        \"DEBUG\": \"false\"\n      }\n    }\n  }\n}\n```\n\n## 🚀 Available Tool\n\n### Storybook Image Generator Tool\n\n```json\n{\n  \"name\": \"generate_storybook_image\",\n  \"description\": \"Generates a 3D style cartoon image with a children's story based on the given prompt\",\n  \"inputSchema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"prompt\": {\n        \"type\": \"string\",\n        \"description\": \"The prompt describing the storybook scene to generate\"\n      },\n      \"fileName\": {\n        \"type\": \"string\",\n        \"description\": \"Base name for the output files (without extension)\"\n      },\n      \"artStyle\": {\n        \"type\": \"string\",\n        \"description\": \"The art style for the image (default: '3d cartoon')\",\n        \"enum\": [\"3d cartoon\", \"watercolor\", \"pixel art\", \"hand drawn\", \"claymation\"]\n      }\n    },\n    \"required\": [\"prompt\", \"fileName\"]\n  }\n}\n```\n\n## 📄 Example Usage\n\n### Storybook Generation Examples\n\n```javascript\n// Generate a storybook with a 3D cartoon style\n{\n  \"name\": \"generate_storybook_image\",\n  \"arguments\": {\n    \"prompt\": \"A friendly dragon teaching kids how to fly\",\n    \"fileName\": \"dragon_flight_lesson\",\n    \"artStyle\": \"3d cartoon\"\n  }\n}\n\n// Generate a storybook with a watercolor style\n{\n  \"name\": \"generate_storybook_image\",\n  \"arguments\": {\n    \"prompt\": \"A rabbit and turtle having a tea party in the forest\",\n    \"fileName\": \"forest_tea_party\",\n    \"artStyle\": \"watercolor\"\n  }\n}\n\n// Generate a storybook with pixel art style\n{\n  \"name\": \"generate_storybook_image\",\n  \"arguments\": {\n    \"prompt\": \"A space adventure with a kid astronaut meeting friendly aliens\",\n    \"fileName\": \"space_adventure\",\n    \"artStyle\": \"pixel art\"\n  }\n}\n```\n\n## ⚙️ Configuration Options\n\n### Environment Variables\n\n| Variable | Description | Default |\n|----------|-------------|---------|\n| `GEMINI_API_KEY` | Google Gemini API key for AI generation | (Required) |\n| `SAVE_TO_DESKTOP` | Force saving to desktop directory | false |\n| `DEBUG` | Enable verbose debug logging | false |\n\n## 📝 Output Files\n\nFor each storybook generation request, the server produces:\n\n1. **PNG Image**: The generated illustration matching your prompt in the requested art style\n2. **Text File**: The matching children's story in plain text format\n3. **HTML Preview**: A combined view showing both the image and story together\n\nThese files are saved to either:\n- Your desktop in a folder called \"storybook-images\" (if `SAVE_TO_DESKTOP=true`)\n- The server's directory in a folder called \"storybook-images\"\n\n## 🤝 Contributing\n\nContributions, issues, and feature requests are welcome! Feel free to check issues page.\n\n## 📄 License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "storybook",
        "images",
        "image",
        "storybook images",
        "storybook image",
        "image generator"
      ],
      "category": "image-and-video-generation"
    },
    "falahgs--flux-imagegen-mcp-server": {
      "owner": "falahgs",
      "name": "flux-imagegen-mcp-server",
      "url": "https://github.com/falahgs/flux-imagegen-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/falahgs.webp",
      "description": "Generates and manipulates images using advanced AI models, offering functionalities such as image URL generation, direct image creation from text prompts, and management of multiple image generation models.",
      "stars": 3,
      "forks": 5,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-18T19:58:34Z",
      "readme_content": "# Flux ImageGen MCP Server\r\n\r\nA specialized Model Context Protocol (MCP) server for image generation and manipulation, powered by Pollinations AI.\r\n\r\n## Developer\r\n- **Author**: Falah.G.Salieh\r\n- **Copyright**: © 2025 All rights reserved\r\n\r\n## Overview\r\n\r\nImageGen MCP Server is a streamlined server implementation that provides powerful image generation capabilities through the Model Context Protocol (MCP). This server specializes in three core functionalities:\r\n\r\n1. Image URL Generation\r\n2. Direct Image Generation\r\n3. Model Listing and Management\r\n\r\n## Features\r\n\r\n- 🖼️ **Image Generation**: Create stunning images from text prompts\r\n- 🎨 **Multiple Models**: Support for various image generation models\r\n- 🔧 **Flexible Configuration**: Easy to set up and customize\r\n- 🚀 **High Performance**: Optimized for quick response times\r\n- 🔄 **MCP Compatible**: Fully compliant with Model Context Protocol\r\n\r\n## Installation\r\n\r\n```bash\r\n# Clone the repository\r\ngit clone https://github.com/yourusername/flux-imagegen-mcp-server.git\r\n\r\n# Install dependencies\r\nnpm install\r\n```\r\n\r\n## Configuration\r\n\r\n### Claude Desktop Configuration\r\n\r\nTo use this server with Claude Desktop, update your configuration file at:\r\n`C:\\Users\\[YourUsername]\\AppData\\Roaming\\Claude\\claude_desktop_config.json`\r\n\r\n```json\r\n{\r\n  \"mcpServers\": {\r\n    \"mcpollinations\": {\r\n      \"command\": \"cmd\",\r\n      \"args\": [\r\n        \"/c\",\r\n        \"node\",\r\n        \"PATH_TO_YOUR_SERVER\\\\server.js\"\r\n      ],\r\n      \"tools\": [\r\n        \"generateImageUrl\",\r\n        \"generateImage\",\r\n        \"listImageModels\"\r\n      ]\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nReplace `PATH_TO_YOUR_SERVER` with your actual server path.\r\n\r\n## Available Tools\r\n\r\n### 1. Generate Image URL (`generateImageUrl`)\r\nGenerates a URL for an image based on a text prompt.\r\n\r\n```javascript\r\n{\r\n  \"prompt\": \"A beautiful sunset over mountains\",\r\n  \"model\": \"flux\",  // optional, defaults to 'flux'\r\n  \"width\": 1024,    // optional\r\n  \"height\": 1024,   // optional\r\n  \"enhance\": true,  // optional\r\n  \"safe\": false     // optional\r\n}\r\n```\r\n\r\n### 2. Generate Image (`generateImage`)\r\nGenerates and saves an image directly from a text prompt.\r\n\r\n```javascript\r\n{\r\n  \"prompt\": \"A serene lake reflecting mountains\",\r\n  \"model\": \"flux\",\r\n  \"width\": 1024,\r\n  \"height\": 1024,\r\n  \"enhance\": true,\r\n  \"safe\": false,\r\n  \"outputPath\": \"./output\",\r\n  \"fileName\": \"mountain_lake\",\r\n  \"format\": \"png\"\r\n}\r\n```\r\n\r\n### 3. List Image Models (`listImageModels`)\r\nReturns a list of available image generation models.\r\n\r\n```javascript\r\n// Example response:\r\n{\r\n  \"models\": [\r\n    {\r\n      \"id\": \"flux\",\r\n      \"name\": \"Flux\",\r\n      \"description\": \"Default image generation model\"\r\n    },\r\n    // ... other models\r\n  ]\r\n}\r\n```\r\n## Running the Server\r\n\r\n```bash\r\n# Start the server\r\nnode server.js\r\n```\r\n\r\n## Environment Requirements\r\n\r\n- Node.js >= 16.0.0\r\n- NPM >= 7.0.0\r\n- Windows/Linux/MacOS compatible\r\n\r\n## Development\r\n\r\nTo contribute or modify the server:\r\n\r\n1. Fork the repository\r\n2. Create your feature branch\r\n3. Make your changes\r\n4. Submit a pull request\r\n\r\n## Error Handling\r\n\r\nThe server provides detailed error messages for common issues:\r\n\r\n```javascript\r\n{\r\n  \"error\": {\r\n    \"code\": \"ERROR_CODE\",\r\n    \"message\": \"Human-readable error message\",\r\n    \"details\": { /* Additional error details */ }\r\n  }\r\n}\r\n```\r\n\r\n## Examples\r\n\r\n### Basic Image Generation\r\n```javascript\r\n// Generate an image URL\r\nconst response = await generateImageUrl({\r\n  prompt: \"A futuristic city at night\",\r\n  model: \"flux\",\r\n  width: 1024,\r\n  height: 1024\r\n});\r\n\r\n// Generate and save an image\r\nconst image = await generateImage({\r\n  prompt: \"A peaceful garden with butterflies\",\r\n  outputPath: \"./images\",\r\n  fileName: \"garden_scene\"\r\n});\r\n```\r\n\r\n### Download Image Example\r\n```javascript\r\n// Download an image from URL\r\nconst downloadResult = await downloadImage({\r\n  imageUrl: \"https://example.com/image.jpg\",\r\n  fileName: \"downloaded-image\",\r\n  format: \"png\"\r\n});\r\n```\r\n\r\n## Support\r\n\r\nFor issues and feature requests, please create an issue in the repository or contact the developer:\r\n- Email: [Your contact email]\r\n- GitHub: [Your GitHub profile]\r\n\r\n## License\r\n\r\nThis project is licensed under the MIT License - see the LICENSE file for details.\r\n\r\n---\r\nMade with ❤️ by Falah.G.Salieh\r\n© 2025 All rights reserved\r\n\r\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "imagegen",
        "images",
        "ai",
        "image generation",
        "image creation",
        "imagegen mcp"
      ],
      "category": "image-and-video-generation"
    },
    "falahgs--imagen-3.0-generate-google-mcp-server": {
      "owner": "falahgs",
      "name": "imagen-3.0-generate-google-mcp-server",
      "url": "https://github.com/falahgs/imagen-3.0-generate-google-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/falahgs.webp",
      "description": "Generates high-quality images using Google's Imagen 3.0 model via the Gemini API, manages image files with intelligent naming, and creates HTML previews for local viewing. Integrates seamlessly with MCP-compatible hosts for enhanced AI capabilities.",
      "stars": 3,
      "forks": 8,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-08-10T13:44:15Z",
      "readme_content": "# Gemini Imagen 3.0 MCP Server\r\n\r\n![License](https://img.shields.io/badge/license-MIT-blue.svg)\r\n![Node](https://img.shields.io/badge/node-%3E%3D18.0.0-brightgreen)\r\n![TypeScript](https://img.shields.io/badge/typescript-%5E5.3.3-blue)\r\n\r\nA professional Model Context Protocol (MCP) server implementation that harnesses Google's Imagen 3.0 model through the Gemini API for high-quality image generation. Built with TypeScript and designed for seamless integration with Claude Desktop and other MCP-compatible hosts.\r\n\r\n## 🌟 Features\r\n\r\n- Leverage Google's state-of-the-art Imagen 3.0 model via Gemini API\r\n- Generate up to 4 high-quality images per request\r\n- Automatic file management with intelligent naming\r\n- HTML preview generation with file:// protocol support\r\n- Built on MCP protocol for AI agent compatibility\r\n- TypeScript implementation with robust error handling\r\n\r\n## 🚀 Quick Start\r\n\r\n### Prerequisites\r\n\r\n- Node.js 18 or higher\r\n- Google Gemini API key\r\n- Claude Desktop or another MCP-compatible host\r\n\r\n### Installation\r\n\r\n1. Clone the repository:\r\n```bash\r\ngit clone https://github.com/yourusername/gemini-imagen-mcp-server.git\r\ncd gemini-imagen-mcp-server\r\n```\r\n\r\n2. Install dependencies:\r\n```bash\r\nnpm install\r\n```\r\n\r\n3. Build the TypeScript code:\r\n```bash\r\nnpm run build\r\n```\r\n\r\n## ⚙️ Configuration\r\n\r\n1. Configure Claude Desktop by adding to `claude_desktop_config.json`:\r\n```json\r\n{\r\n  \"mcpServers\": {\r\n    \"gemini-image-gen\": {\r\n      \"command\": \"node\",\r\n      \"args\": [\"./build/index.js\"],\r\n      \"cwd\": \"<path-to-project-directory>\",\r\n      \"env\": {\r\n        \"GEMINI_API_KEY\": \"your-gemini-api-key\"\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n2. Replace placeholders:\r\n   - `<path-to-project-directory>`: Your project path\r\n   - `your-gemini-api-key`: Your Gemini API key\r\n\r\n## 🛠️ Available Tools\r\n\r\n### 1. generate_images\r\nGenerates images using Google's Imagen 3.0 model.\r\n\r\nParameters:\r\n- `prompt` (required): Text description of the image to generate\r\n- `numberOfImages` (optional): Number of images (1-4, default: 1)\r\n\r\nFile Management:\r\n- Images are automatically saved in `G:\\image-gen3-google-mcp-server\\images`\r\n- Filenames follow the pattern: `{sanitized-prompt}-{timestamp}-{index}.png`\r\n- Timestamps ensure unique filenames\r\n- Prompts are sanitized for safe filesystem usage\r\n\r\nExample:\r\n```\r\nGenerate an image of a futuristic city at night\r\n```\r\n\r\n### 2. create_image_html\r\nCreates HTML preview tags for generated images.\r\n\r\nParameters:\r\n- `imagePaths` (required): Array of image file paths\r\n- `width` (optional): Image width in pixels (default: 512)\r\n- `height` (optional): Image height in pixels (default: 512)\r\n\r\nReturns HTML tags with absolute file:// URLs for local viewing.\r\n\r\nExample:\r\n```\r\nCreate HTML tags for the generated images with width=400\r\n```\r\n\r\n## 🔧 Development\r\n\r\n```bash\r\n# Install dependencies\r\nnpm install\r\n\r\n# Build TypeScript\r\nnpm run build\r\n\r\n# Run tests (when available)\r\nnpm test\r\n```\r\n\r\n## 🤝 Contributing\r\n\r\nContributions are welcome! Please feel free to submit a Pull Request. For major changes:\r\n\r\n1. Fork the repository\r\n2. Create your feature branch (`git checkout -b feature/AmazingFeature`)\r\n3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)\r\n4. Push to the branch (`git push origin feature/AmazingFeature`)\r\n5. Open a Pull Request\r\n\r\n## 📝 Error Handling\r\n\r\nThe server implements two main error codes:\r\n- `tool_not_found` (1): When the requested tool is not available\r\n- `execution_error` (2): When image generation or HTML creation fails\r\n\r\n## 📄 License\r\n\r\nMIT License - see the [LICENSE](LICENSE) file for details.\r\n\r\n## ✨ Author\r\n\r\n**Falah G. Salieh**\r\n- Copyright © 2025\r\n- GitHub: [@yourgithubhandle](https://github.com/yourgithubhandle)\r\n- Email: [your.email@example.com](mailto:your.email@example.com)\r\n\r\n## 🙏 Acknowledgments\r\n\r\n- Google Gemini API and Imagen 3.0 model\r\n- Model Context Protocol (MCP) by Anthropic\r\n- Claude Desktop team for MCP host implementation\r\n\r\n## 📌 Tags\r\n\r\n`#MCP` `#Gemini` `#Imagen3` `#AI` `#ImageGeneration` `#TypeScript` `#NodeJS` `#GoogleAI` `#ClaudeDesktop`\r\n\r\n---\r\nMade with ❤️ by Falah G. Salieh ",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "imagen",
        "images",
        "mcp",
        "imagen generate",
        "google imagen",
        "imagen model"
      ],
      "category": "image-and-video-generation"
    },
    "falahgs--mcp-3d-style-cartoon-gen-server": {
      "owner": "falahgs",
      "name": "mcp-3d-style-cartoon-gen-server",
      "url": "https://github.com/falahgs/mcp-3d-style-cartoon-gen-server",
      "imageUrl": "/freedevtools/mcp/pfp/falahgs.webp",
      "description": "Generates high-quality 3D-style cartoon images from text prompts using Google's Gemini AI, with child-friendly designs for engaging visuals. Offers secure file system operations for managing files, including reading and writing capabilities.",
      "stars": 3,
      "forks": 2,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-09-11T21:40:56Z",
      "readme_content": "# MCP Combined Server: 3D Cartoon Generator & File System Tools\n\nA professional-grade server that provides two major capabilities: \n1. High-quality 3D-style cartoon image generation using Google's Gemini AI\n2. Secure file system operations for reading, writing, and managing files\n\n\n\n## 🌟 Features\n\n### Image Generation\n- **3D Cartoon Generation**: Creates high-quality 3D-style cartoon images\n- **Child-Friendly Design**: Focuses on colorful, playful, and engaging visuals\n- **Instant Preview**: Automatically opens generated images in your default browser\n- **Local Storage**: Saves images and previews in an organized output directory\n\n### File System Operations\n- **Secure File Access**: Path validation and security checks\n- **Read/Write Files**: Read and write text file contents\n- **Directory Operations**: List, create, and navigate directories\n- **File Search**: Find files matching patterns\n\n### System Features\n- **Professional Configuration**: Robust error handling and controlled logging\n- **Cross-Platform Support**: Intelligent file path handling for Windows, macOS, and Linux\n- **Smart OS Detection**: Automatically finds the best save location for each operating system\n- **Security Controls**: Restricted directory access through configuration\n\n## 🛠️ Technical Stack\n\n- **Core Framework**: Model Context Protocol (MCP) SDK\n- **AI Integration**: Google Generative AI (Gemini)\n- **Runtime**: Node.js v14+\n- **Language**: TypeScript\n- **Package Manager**: npm\n\n## 📋 Prerequisites\n\n- Node.js (v14 or higher)\n- Google Gemini API key\n- TypeScript\n\n## ⚙️ Installation\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/falahgs/mcp-3d-style-cartoon-gen-server.git\ncd mcp-3d-style-cartoon-gen-server\n```\n\n2. Install dependencies:\n```bash\nnpm install\n```\n\n3. Configure environment:\nCreate a `.env` file in the root directory:\n```env\nGEMINI_API_KEY=your_api_key_here\nALLOWED_DIRECTORIES=/path/to/allowed/dir1,/path/to/allowed/dir2\n```\n\n4. Build the project:\n```bash\nnpm run build\n```\n\n## 🔧 Configuring Claude Desktop with MCP Server\n\nTo integrate this combined server with Claude Desktop:\n\n1. Locate the Configuration File:\n   - Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n   - macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - Linux: `~/.config/Claude/claude_desktop_config.json`\n\n2. Add the following configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-3d-cartoon-generator\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"path/to/your/build/index.js\"\n      ],\n      \"env\": {\n        \"GEMINI_API_KEY\": \"your_gemini_api_key_here\",\n        \"IS_REMOTE\": \"true\",\n        \"SAVE_TO_DESKTOP\": \"true\",\n        \"DETECT_OS_PATHS\": \"true\",\n        \"ALLOWED_DIRECTORIES\": \"C:\\\\Users\\\\YourUsername\\\\Desktop,C:\\\\Users\\\\YourUsername\\\\Documents\",\n        \"DEBUG\": \"false\"\n      }\n    }\n  }\n}\n```\n\n### Windows PowerShell Helper Script\n\nFor Windows users, you can use the included `fix_claude_config.ps1` script to automatically configure Claude Desktop:\n\n1. Edit the script to update the path to your server build and your Gemini API key\n2. Run the script in PowerShell:\n```powershell\npowershell -ExecutionPolicy Bypass -File .\\fix_claude_config.ps1\n```\n\nThis will create or update the configuration file with proper encoding and settings.\n\n## 🚀 Available Tools\n\n### 1. Image Generation Tool\n\n```json\n{\n  \"name\": \"generate_3d_cartoon\",\n  \"description\": \"Generates a 3D style cartoon image for kids based on the given prompt\",\n  \"inputSchema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"prompt\": {\n        \"type\": \"string\",\n        \"description\": \"The prompt describing the 3D cartoon image to generate\"\n      },\n      \"fileName\": {\n        \"type\": \"string\",\n        \"description\": \"The name of the output file (without extension)\"\n      }\n    },\n    \"required\": [\"prompt\", \"fileName\"]\n  }\n}\n```\n\n### 2. File System Tools\n\n#### Read File\n```json\n{\n  \"name\": \"read_file\",\n  \"description\": \"Read the contents of a file\",\n  \"inputSchema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"path\": {\n        \"type\": \"string\",\n        \"description\": \"Path to the file to read\"\n      }\n    },\n    \"required\": [\"path\"]\n  }\n}\n```\n\n#### Write File\n```json\n{\n  \"name\": \"write_file\",\n  \"description\": \"Write content to a file\",\n  \"inputSchema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"path\": {\n        \"type\": \"string\",\n        \"description\": \"Path to the file to write\"\n      },\n      \"content\": {\n        \"type\": \"string\",\n        \"description\": \"Content to write to the file\"\n      }\n    },\n    \"required\": [\"path\", \"content\"]\n  }\n}\n```\n\n#### List Directory\n```json\n{\n  \"name\": \"list_directory\",\n  \"description\": \"List the contents of a directory\",\n  \"inputSchema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"path\": {\n        \"type\": \"string\",\n        \"description\": \"Path to the directory to list\"\n      }\n    },\n    \"required\": [\"path\"]\n  }\n}\n```\n\n#### Create Directory\n```json\n{\n  \"name\": \"create_directory\",\n  \"description\": \"Create a new directory\",\n  \"inputSchema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"path\": {\n        \"type\": \"string\",\n        \"description\": \"Path to the directory to create\"\n      }\n    },\n    \"required\": [\"path\"]\n  }\n}\n```\n\n#### Search Files\n```json\n{\n  \"name\": \"search_files\",\n  \"description\": \"Search for files matching a pattern\",\n  \"inputSchema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"path\": {\n        \"type\": \"string\",\n        \"description\": \"Base directory to search from\"\n      },\n      \"pattern\": {\n        \"type\": \"string\",\n        \"description\": \"Search pattern (glob format)\"\n      },\n      \"excludePatterns\": {\n        \"type\": \"array\",\n        \"items\": {\n          \"type\": \"string\"\n        },\n        \"description\": \"Patterns to exclude from search (glob format)\"\n      }\n    },\n    \"required\": [\"path\", \"pattern\"]\n  }\n}\n```\n\n## 📄 Example Usage\n\n### Image Generation Examples\n\n```javascript\n// Generate a 3D cartoon\n{\n  \"name\": \"generate_3d_cartoon\",\n  \"arguments\": {\n    \"prompt\": \"A friendly robot playing with a cat\",\n    \"fileName\": \"robot_cat_play\"\n  }\n}\n```\n\n### File System Examples\n\n```javascript\n// Read a file\n{\n  \"name\": \"read_file\",\n  \"arguments\": {\n    \"path\": \"C:/Users/YourUsername/Documents/example.txt\"\n  }\n}\n\n// Write a file\n{\n  \"name\": \"write_file\",\n  \"arguments\": {\n    \"path\": \"C:/Users/YourUsername/Documents/new-file.txt\",\n    \"content\": \"This is the content of the file.\"\n  }\n}\n\n// List directory contents\n{\n  \"name\": \"list_directory\",\n  \"arguments\": {\n    \"path\": \"C:/Users/YourUsername/Documents\"\n  }\n}\n\n// Create a directory\n{\n  \"name\": \"create_directory\",\n  \"arguments\": {\n    \"path\": \"C:/Users/YourUsername/Documents/new-folder\"\n  }\n}\n\n// Search for files\n{\n  \"name\": \"search_files\",\n  \"arguments\": {\n    \"path\": \"C:/Users/YourUsername/Documents\",\n    \"pattern\": \"*.txt\",\n    \"excludePatterns\": [\"temp*\", \"*.tmp\"]\n  }\n}\n```\n\n## 🔒 Security Features\n\nThe server implements several security measures:\n\n1. **Path Validation**: All file paths are validated to ensure they are within allowed directories.\n2. **Allowed Directories**: Only directories explicitly set in the `ALLOWED_DIRECTORIES` environment variable can be accessed.\n3. **Symlink Protection**: Prevents access to directories outside the allowed scope via symlinks.\n4. **Controlled Logging**: Debug logs are disabled by default to prevent information leakage.\n\n## ⚙️ Configuration Options\n\n### Environment Variables\n\n| Variable | Description | Default |\n|----------|-------------|---------|\n| `GEMINI_API_KEY` | Google Gemini API key for image generation | (Required) |\n| `ALLOWED_DIRECTORIES` | Comma-separated list of allowed file system paths | User's home dir, current dir |\n| `IS_REMOTE` | Run in remote mode without browser opening | false |\n| `SAVE_TO_DESKTOP` | Force saving to desktop directory | false |\n| `DETECT_OS_PATHS` | Enable OS-specific path detection | true |\n| `DEBUG` | Enable verbose debug logging | false |\n\n## 🛠️ Troubleshooting\n\n### Common Issues:\n\n1. **JSON Parsing Errors in Claude**:\n   - Ensure `DEBUG` is set to \"false\" to prevent logs from interfering with JSON communication\n   - Check for proper JSON formatting in the Claude configuration\n\n2. **File Access Denied**:\n   - Verify that the paths you're trying to access are included in `ALLOWED_DIRECTORIES`\n   - Check file permissions on the target files/directories\n\n3. **Images Not Saving**:\n   - Set `SAVE_TO_DESKTOP` to \"true\" to ensure images save to the desktop\n   - Check desktop path detection in the server logs (enable DEBUG temporarily)\n\n## 📄 License\n\n[MIT License](LICENSE)\n\n## 🤝 Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcp",
        "images",
        "cartoon",
        "mcp 3d",
        "cartoon images",
        "cartoon gen"
      ],
      "category": "image-and-video-generation"
    },
    "felores--cloudinary-mcp-server": {
      "owner": "felores",
      "name": "cloudinary-mcp-server",
      "url": "https://github.com/felores/cloudinary-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/felores.webp",
      "description": "Upload images and videos to Cloudinary via MCP clients. Integrates with Claude Desktop for media management.",
      "stars": 9,
      "forks": 8,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-12T10:23:47Z",
      "readme_content": "# Cloudinary MCP Server\n\nThis MCP server provides tools for uploading images and videos to Cloudinary through Claude Desktop and compatible MCP clients.\n\n<a href=\"https://glama.ai/mcp/servers/zjiw1ry8ly\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/zjiw1ry8ly/badge\" alt=\"Cloudinary Server MCP server\" /></a>\n\n## Installation\n\n### Requirements: Node.js\n\n1. Install Node.js (version 18 or higher) and npm from [nodejs.org](https://nodejs.org/)\n2. Verify installation:\n   ```bash\n   node --version\n   npm --version\n   ```\n\n### Install using npx (Recommended)\n1. Navigate to the Claude configuration directory:\n\n   - Windows: `C:\\Users\\NAME\\AppData\\Roaming\\Claude`\n   - macOS: `~/Library/Application Support/Claude/`\n   \n   You can also find these directories inside the Claude Desktop app: Claude Desktop > Settings > Developer > Edit Config\n\n2. Add the following configuration to your MCP settings file:\n\n```json\n{\n  \"mcpServers\": {\n    \"cloudinary\": {\n      \"command\": \"npx\",\n      \"args\": [\"@felores/cloudinary-mcp-server@latest\"],\n      \"env\": {\n        \"CLOUDINARY_CLOUD_NAME\": \"your_cloud_name\",\n        \"CLOUDINARY_API_KEY\": \"your_api_key\",\n        \"CLOUDINARY_API_SECRET\": \"your_api_secret\"\n      }\n    }\n  }\n}\n```\n\n3. Make sure to replace the environment variables with your Cloudinary credentials from the [Cloudinary Console](https://console.cloudinary.com/settings/api-keys).\n\n### Developer Installation\nIf you want to modify the server or contribute to development:\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/felores/cloudinary-mcp-server.git\ncd cloudinary-mcp-server\n```\n\n2. Install dependencies and build:\n```bash\nnpm install\nnpm run build\n```\n\n## Setup Instructions\n\n1. First, ensure you have a Cloudinary account and get your credentials from the [Cloudinary Console](https://console.cloudinary.com/settings/api-keys):\n   - Cloud Name\n   - API Key\n   - API Secret\n\n2. Add the server configuration to your Claude/Cline MCP settings file:\n\n```json\n{\n  \"mcpServers\": {\n    \"cloudinary\": {\n      \"command\": \"node\",\n      \"args\": [\"c:/path/to/cloudinary-mcp-server/dist/index.js\"],\n      \"env\": {\n        \"CLOUDINARY_CLOUD_NAME\": \"your_cloud_name\",\n        \"CLOUDINARY_API_KEY\": \"your_api_key\",\n        \"CLOUDINARY_API_SECRET\": \"your_api_secret\"\n      }\n    }\n  }\n}\n```\n\nFor Claude desktop app, edit the configuration file at the appropriate location for your OS.\n\n3. Install dependencies and build the server:\n```bash\nnpm install\nnpm run build\n```\n\n## Available Tools\n\n### upload\n\nUpload images and videos to Cloudinary.\n\nParameters:\n- `file` (required): Path to file, URL, or base64 data URI to upload\n- `resource_type` (optional): Type of resource ('image', 'video', or 'raw')\n- `public_id` (optional): Custom public ID for the uploaded asset\n- `overwrite` (optional): Whether to overwrite existing assets with the same public ID\n- `tags` (optional): Array of tags to assign to the uploaded asset\n\nExample usage in Claude/Cline:\n```typescript\nuse_mcp_tool({\n  server_name: \"cloudinary\",\n  tool_name: \"upload\",\n  arguments: {\n    file: \"path/to/image.jpg\",\n    resource_type: \"image\",\n    public_id: \"my-custom-id\"\n  }\n});\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "cloudinary",
        "upload",
        "mcp",
        "cloudinary mcp",
        "videos cloudinary",
        "mcp server"
      ],
      "category": "image-and-video-generation"
    },
    "felores--placid-mcp-server": {
      "owner": "felores",
      "name": "placid-mcp-server",
      "url": "https://github.com/felores/placid-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/felores.webp",
      "description": "Integrates with Placid.app to list available templates and generate images and videos using dynamic content. Provides secure API token management and robust error handling.",
      "stars": 14,
      "forks": 7,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-02T13:59:52Z",
      "readme_content": "# Placid.app MCP Server\n[![smithery badge](https://smithery.ai/badge/@felores/placid-mcp-server)](https://smithery.ai/server/@felores/placid-mcp-server)\n\nAn MCP server implementation for integrating with Placid.app's API. This server provides tools for listing templates and generating images and videos through the Model Context Protocol.\n\n<a href=\"https://glama.ai/mcp/servers/xeklsydon0\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/xeklsydon0/badge\" />\n</a>\n\n## Features\n\n- List available Placid templates with filtering options\n- Generate images and videos using templates and dynamic content\n- Secure API token management\n- Error handling and validation\n- Type-safe implementation\n\n## Requirements: Node.js\n\n1. Install Node.js (version 18 or higher) and npm from [nodejs.org](https://nodejs.org/)\n2. Verify installation:\n   ```bash\n   node --version\n   npm --version\n   ```\n\n## Installation\n\n### Quick Start (Recommended)\n\nThe easiest way to get started is using Smithery, which will automatically configure everything for you:\n\n```bash\nnpx -y @smithery/cli install @felores/placid-mcp-server --client claude\n```\n\n### Manual Configuration\n\nIf you prefer to configure manually, add this to your Claude Desktop or Cline settings:\n\n```json\n{\n  \"mcpServers\": {\n    \"placid\": {\n      \"command\": \"npx\",\n      \"args\": [\"@felores/placid-mcp-server\"],\n      \"env\": {\n        \"PLACID_API_TOKEN\": \"your-api-token\"\n      }\n    }\n  }\n}\n```\n\n## Getting Your Placid API Token\n\n1. Log in to your [Placid.app](https://placid.app/) account\n2. Go to Settings > API\n3. Click on \"Create API Token\"\n4. Give your token a name (e.g., \"MCP Server\")\n5. Copy the generated token\n6. Add the token to your configuration as shown above\n\n## Development\n\n```bash\n# Run in development mode with hot reload\nnpm run dev\n\n# Run tests\nnpm test\n```\n\n## Tools\n\n### placid_list_templates\nLists available Placid templates with filtering options. Each template includes its title, ID, preview image URL, available layers, and tags.\n\n#### Parameters\n- `collection_id` (optional): Filter templates by collection ID\n- `custom_data` (optional): Filter by custom reference data\n- `tags` (optional): Array of tags to filter templates by\n\n#### Response\nReturns an array of templates, each containing:\n- `uuid`: Unique identifier for the template\n- `title`: Template name\n- `thumbnail`: Preview image URL (if available)\n- `layers`: Array of available layers with their names and types\n- `tags`: Array of template tags\n\n### placid_generate_video\nGenerate videos by combining Placid templates with dynamic content like videos, images, and text. For longer videos (>60 seconds processing time), you'll receive a job ID to check status in your Placid dashboard.\n\n#### Parameters\n- `template_id` (required): UUID of the template to use\n- `layers` (required): Object containing dynamic content for template layers\n  - For video layers: `{ \"layerName\": { \"video\": \"https://video-url.com\" } }`\n  - For image layers: `{ \"layerName\": { \"image\": \"https://image-url.com\" } }`\n  - For text layers: `{ \"layerName\": { \"text\": \"Your content\" } }`\n- `audio` (optional): URL to an mp3 audio file\n- `audio_duration` (optional): Set to 'auto' to trim audio to video length\n- `audio_trim_start` (optional): Timestamp of trim start point (e.g. '00:00:45' or '00:00:45.25')\n- `audio_trim_end` (optional): Timestamp of trim end point (e.g. '00:00:55' or '00:00:55.25')\n\n#### Response\nReturns an object containing:\n- `status`: Current status (\"finished\", \"queued\", or \"error\")\n- `video_url`: URL to download the generated video (when status is \"finished\")\n- `job_id`: ID for checking status in Placid dashboard (for longer videos)\n\n#### Example Usage for LLM models\n```json\n{\n  \"template_id\": \"template-uuid\",\n  \"layers\": {\n    \"MEDIA\": { \"video\": \"https://example.com/video.mp4\" },\n    \"PHOTO\": { \"image\": \"https://example.com/photo.jpg\" },\n    \"LOGO\": { \"image\": \"https://example.com/logo.png\" },\n    \"HEADLINE\": { \"text\": \"My Video Title\" }\n  },\n  \"audio\": \"https://example.com/background.mp3\",\n  \"audio_duration\": \"auto\"\n}\n```\n\n### placid_generate_image\nGenerate static images by combining Placid templates with dynamic content like text and images.\n\n#### Parameters\n- `template_id` (required): UUID of the template to use\n- `layers` (required): Object containing dynamic content for template layers\n  - For text layers: `{ \"layerName\": { \"text\": \"Your content\" } }`\n  - For image layers: `{ \"layerName\": { \"image\": \"https://image-url.com\" } }`\n\n#### Response\nReturns an object containing:\n- `status`: \"finished\" when complete\n- `image_url`: URL to download the generated image\n\n#### Example Usage for LLM models\n```json\n{\n  \"template_id\": \"template-uuid\",\n  \"layers\": {\n    \"headline\": { \"text\": \"Welcome to My App\" },\n    \"background\": { \"image\": \"https://example.com/bg.jpg\" }\n  }\n}\n```\n\n## Documentation\n\nFor more detailed information about the Placid API, visit the [Placid API Documentation](https://placid.app/docs/api/).\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "placid",
        "mcp",
        "server",
        "placid app",
        "placid mcp",
        "mcp server"
      ],
      "category": "image-and-video-generation"
    },
    "fengin--image-gen-server": {
      "owner": "fengin",
      "name": "image-gen-server",
      "url": "https://github.com/fengin/image-gen-server",
      "imageUrl": "/freedevtools/mcp/pfp/fengin.webp",
      "description": "Generate images from text descriptions and save them, seamlessly integrated with Cursor IDE. Users can create multiple image outputs simultaneously and specify custom save paths.",
      "stars": 205,
      "forks": 25,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-28T14:14:49Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/fengin-image-gen-server-badge.png)](https://mseep.ai/app/fengin-image-gen-server)\n\n# Image-Gen-Server\n\n<div align=\"center\">\n  \n</div>\n\n[![smithery badge](https://smithery.ai/badge/@fengin/image-gen-server)](https://smithery.ai/server/@fengin/image-gen-server)\n\n基于即梦AI的图像生成服务，专门设计用于与Cursor IDE集成。它接收来自Cursor的文本描述，生成相应的图像，并提供图片下载和保存功能。\n\n此插件的开发过程可以看我的网站：[开发一个MCP Server与Cursor集成，给Cursor插上翅膀！](https://aibook.ren/archives/mcp-server-for-cursor)\n\n更多AI知识，见AI全书(https://aibook.ren)\n\n<div align=\"center\">\n  \n</div>\n\n## 特性\n\n- 与Cursor IDE完美集成\n- 支持文本到图像的生成\n- 自动保存生成的图像\n- 支持自定义保存路径\n- 一次生成四张图，供更多选择\n\n## 安装\n\n### Installing via Smithery\n\nTo install Image-Gen-Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@fengin/image-gen-server):\n\n```bash\nnpx -y @smithery/cli install @fengin/image-gen-server --client claude\n```\n\n1. 环境准备，MCP比较新的东西，依赖环境版本都比较新\n- python 3.10+\n\n- 安装npm\n\n- 安装nodejs（实测v15 v16都不行，开发环境验证v20可以，其他未验证）\n\n- 安装 pip install uv\n\n- 如果要调试，还需要安装这个：npm install -g @modelcontextprotocol/inspector@0.4.0\n2. 克隆项目\n   \n   ```bash\n   git clone https://github.com/fengin/image-gen-server.git\n   cd image-gen-server\n   ```\n\n3. 安装依赖\n   \n   ```bash\n   pip install -r requirements.txt\n   pip install uv\n   ```\n\n4. 设置即梦Token和图片默认保存地址\n   修改server.py文件里面这两个配置\n   \n   ```bash\n   # API配置\n   JIMENG_API_TOKEN = \"057f7addf85dxxxxxxxxxxxxx\" # 你登录即梦获得的session_id，支持多个，在后面用逗号分隔   \n   IMG_SAVA_FOLDER = \"D:/code/image-gen-server/images\" # 图片默认保存路径\n   ```\n\n    \n\n## Cursor集成\n\n<div align=\"center\">\n  \n</div>\n\n1. 打开Cursor设置\n   \n   - 点击左下角的设置图标\n   - 选择 Features > MCP Servers\n   - 点击 \"Add new MCP server\"\n\n2. 填写服务器配置\n   \n   - Name: `image-gen-server`（或其他你喜欢的名称）\n   \n   - Type: `command`\n   \n   - Command: \n     \n     ```bash\n     uv run --with fastmcp fastmcp run D:\\code\\image-gen-service\\server.py\n     ```\n     \n     注意：将路径替换为你的实际项目路径\n     \n     - Windows示例: ` uv run --with fastmcp fastmcp run D:/code/image-gen-service/server.py`\n     - macOS/Linux示例: ` uv run --with fastmcp fastmcp run /Users/username/code/image-gen-server/server.py`\n     \n     windows路径问题比较多，D:/code/image-gen-server/server.py 各种斜杠都试下\n     \n     填写完后，会弹出一个黑窗口，然后你就可以叫Cursor给你生成需要的图片了，目前黑窗口会一直运行，目前还没办法解决弹出这个的问题\n\n## 使用方法\n\n在Cursor中，你要让cursor生成图片，在agent模式下，你提示它了解下图片工具使用方法，然后直接提你要生成的图片要求，保存位置就行了\n\n## 获取即梦Token\n\n1. 访问 [即梦](https://jimeng.jianying.com/)\n2. 登录账号\n3. 按F12打开开发者工具\n4. 在Application > Cookies中找到`sessionid`\n5. 将找到的sessionid设置到server.py的JIMENG_API_TOKEN中\n\n## 工具函数说明\n\n### generate_image\n\n```python\nasync def generate_image(prompt: str, file_name: str, save_folder: str = None, sample_strength: float = 0.5, width: int = 1024, height: int = 1024) -> list[types.TextContent | types.ImageContent | types.EmbeddedResource]:\n    \"\"\"根据文本描述生成图片\n\n    Args:\n        prompt: 图片的文本prompt描述\n        file_name: 生成图片的文件名(不含路径，如果没有后缀则默认使用.jpg)\n        save_folder: 图片保存绝对地址目录(可选,默认使用IMG_SAVA_FOLDER)\n        sample_strength: 生成图片的精细度(可选,范围0-1,默认0.5)\n        width: 生成图片的宽度(可选,默认1024)\n        height: 生成图片的高度(可选,默认1024)\n\n    Returns:\n        List: 包含生成结果的JSON字符串\n    \"\"\"\n```\n\n### 技术实现\n\n1. server.py采用了fastmcp实现了mcp sever的能力，提供给cursor/claude使用\n\n   2.sever.py调用了proxy.jimeng模块逆向与即梦AI进行交互。\nproxy.jimeng逆向模块也可以单独install使用，主要提供了以下主要功能：\n\n- 图像生成（generate_images）\n- 同步对话补全（create_completion）\n- 流式对话补全（create_completion_stream）\n- 多账号token支持\n- 完整的错误处理\n\n更多详细信息请参考`proxy/jimeng/README.md`。\n\n### 使用示例\n\n```cmd\n# cursor agent模式下\n#例子一\n根据提供过你的项目需求，帮我生成一张产品logo，放在项目目录images下面\n\n#例子二\n根据项目需求，帮我制作网站的首页，头部需要有banner图片。\n```\n\n## 许可证\n\nMIT License \n作者：凌封\n\n## 故障排除\n\n1.配置完后跳出黑窗口，很快消失，工具状态变成No tools found\n\n  原因：没有正常启动，一般有以下原因\n\n- 配置命令不对，检查命令是否正确，一般是server.py路径不对，或者路径中包含中文，或者正反斜杠不对\n- 依赖的环境没准备好\n- 依赖运行的终端不对，像我windows的，终端有git bash，cmd，powershell，wsl等，这些终端都试下，cursor配置我这默认终端是cmd，如果你在这对应终端运行报错，一般是环境没装好，安装环境就可以\n\n2.正常运行后，想看调用日志，或者调试怎么弄\n\n  命令改成以下：\n\n```\nuv run --with fastmcp fastmcp dev D:/code/image-gen-service/server.py\n```\n\n\n  即把最后一个run 改成 dev。\n\n  或者找个终端运行以下命令进入调试模式：\n\n```\nfastmcp dev D:/code/image-gen-service/server.py\n```\n\n会有一个调试地址输出：http://localhost:5173/，你可以浏览器打开这地址MCP Inspector进行调试，具体MCP Inspector怎么使用，可以看官方文档",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "fengin",
        "generate",
        "images",
        "generate images",
        "image gen",
        "fengin image"
      ],
      "category": "image-and-video-generation"
    },
    "hamflx--imagen3-mcp": {
      "owner": "hamflx",
      "name": "imagen3-mcp",
      "url": "https://github.com/hamflx/imagen3-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/hamflx.webp",
      "description": "Generate high-quality images using Google's Imagen 3.0 model through an MCP interface, facilitating integration with tools like Cherry Studio or Cursor. Supports configurable deployment options using a Google Gemini API key.",
      "stars": 43,
      "forks": 7,
      "license": "No License",
      "language": "Rust",
      "updated_at": "2025-09-20T19:36:59Z",
      "readme_content": "# Imagen3-MCP\n\n[English Version](#imagen3-mcp-english)\n\n基于 Google 的 Imagen 3.0 的图像生成工具，通过 MCP（Model Control Protocol）提供服务。\n\n## 效果\n\n画一只奔跑的杰克罗素犬，长焦镜头，阳光透过狗狗的毛发，照片级画质\n\n\n\n画一个科技感十足的苹果\n\n\n\n## 安装要求\n\n- 有效的 [Google Gemini API 密钥](https://aistudio.google.com/apikey)\n\n## 安装步骤——Cherry Studio\n\n1. 从 [GitHub Releases](https://github.com/hamflx/imagen3-mcp/releases) 下载最新版本的可执行文件\n2. 将下载的可执行文件放置在系统中的任意位置，例如 `C:\\bin\\imagen3-mcp.exe`\n3. 在 Cherry Studio 中配置：\n   - Command 字段填写可执行文件路径，例如 `C:\\bin\\imagen3-mcp.exe`\n   - 环境变量 `GEMINI_API_KEY` 中填写你的 Gemini API 密钥\n   - [可选] 环境变量 `BASE_URL` 中填写代理地址，例如 `https://lingxi-proxy.hamflx.dev/api/provider/google`（这个地址可以解决 GFW 的问题，但是解决不了 Google 对 IP 的限制问题，因此还是得挂梯子）。\n   - [可选] 环境变量 `SERVER_LISTEN_ADDR`：设置服务器监听的 IP 地址（默认为 `127.0.0.1`）。\n   - [可选] 环境变量 `SERVER_PORT`：设置服务器监听的端口和图片 URL 使用的端口（默认为 `9981`）。\n   - [可选] 环境变量 `IMAGE_RESOURCE_SERVER_ADDR`：设置图片 URL 中使用的服务器地址（默认为 `127.0.0.1`）。这在服务器运行在容器或远程机器上时很有用。\n\n\n\n## 安装步骤——Cursor\n\n```json\n{\n  \"mcpServers\": {\n    \"imagen3\": {\n      \"command\": \"C:\\\\bin\\\\imagen3-mcp.exe\",\n      \"env\": {\n        \"GEMINI_API_KEY\": \"<GEMINI_API_KEY>\"\n        // Optional environment variables:\n        // \"BASE_URL\": \"<PROXY_URL>\",\n        // \"SERVER_LISTEN_ADDR\": \"0.0.0.0\", // Example: Listen on all interfaces\n        // \"SERVER_PORT\": \"9981\",\n        // \"IMAGE_RESOURCE_SERVER_ADDR\": \"your.domain.com\" // Example: Use a domain name for image URLs\n      }\n    }\n  }\n}\n```\n\n## 许可证\n\nMIT\n\n---\n\n# Imagen3-MCP (English)\n\nAn image generation tool based on Google's Imagen 3.0, providing services through MCP (Model Control Protocol).\n\n## Examples\n\nA running Jack Russell Terrier, telephoto lens, sunlight filtering through the dog's fur, photorealistic quality\n\n\n\nA high-tech apple\n\n\n\n## Requirements\n\n- Valid [Google Gemini API key](https://aistudio.google.com/apikey)\n\n## Installation Steps—Cherry Studio\n\n1. Download the latest executable from [GitHub Releases](https://github.com/hamflx/imagen3-mcp/releases)\n2. Place the downloaded executable anywhere in your system, e.g., `C:\\bin\\imagen3-mcp.exe`\n3. Configure in Cherry Studio:\n   - Fill in the Command field with the executable path, e.g., `C:\\bin\\imagen3-mcp.exe`\n   - Enter your Gemini API key in the `GEMINI_API_KEY` environment variable\n   - [Optional] Enter a proxy URL in the `BASE_URL` environment variable, e.g., `https://your-proxy.com`.\n   - [Optional] Set the `SERVER_LISTEN_ADDR` environment variable: The IP address the server listens on (defaults to `127.0.0.1`).\n   - [Optional] Set the `SERVER_PORT` environment variable: The port the server listens on and uses for image URLs (defaults to `9981`).\n   - [Optional] Set the `IMAGE_RESOURCE_SERVER_ADDR` environment variable: The server address used in the image URLs (defaults to `127.0.0.1`). Useful if the server runs in a container or remote machine.\n\n\n\n## Installation Steps—Cursor\n\n```json\n{\n  \"mcpServers\": {\n    \"imagen3\": {\n      \"command\": \"C:\\\\bin\\\\imagen3-mcp.exe\",\n      \"env\": {\n        \"GEMINI_API_KEY\": \"<GEMINI_API_KEY>\"\n        // Optional environment variables:\n        // \"BASE_URL\": \"<PROXY_URL>\",\n        // \"SERVER_LISTEN_ADDR\": \"0.0.0.0\", // Example: Listen on all interfaces\n        // \"SERVER_PORT\": \"9981\",\n        // \"IMAGE_RESOURCE_SERVER_ADDR\": \"your.domain.com\" // Example: Use a domain name for image URLs\n      }\n    }\n  }\n}\n```\n\n## License\n\nMIT",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "imagen3",
        "imagen",
        "hamflx",
        "imagen3 mcp",
        "hamflx imagen3",
        "google imagen"
      ],
      "category": "image-and-video-generation"
    },
    "hellokaton--unsplash-mcp-server": {
      "owner": "hellokaton",
      "name": "unsplash-mcp-server",
      "url": "https://github.com/hellokaton/unsplash-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/hellokaton.webp",
      "description": "Connects to Unsplash's image library to perform advanced searches and apply filters on keywords for rich, high-quality image retrieval.",
      "stars": 174,
      "forks": 19,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-03T22:30:58Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/hellokaton-unsplash-mcp-server-badge.png)](https://mseep.ai/app/hellokaton-unsplash-mcp-server)\n\n# Unsplash MCP Server\n\nEnglish | [简体中文](README_zh.md)\n\n> A simple MCP server for seamless Unsplash image integration and search capabilities.\n\n[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![smithery badge](https://smithery.ai/badge/@hellokaton/unsplash-mcp-server)](https://smithery.ai/server/@hellokaton/unsplash-mcp-server)\n\n## 📋 Overview\n\nUnsplash MCP Server is used for searching rich, high-quality images. It's ideal for developers who want to integrate Unsplash functionality into their own applications.\n\n## ✨ Features\n\n- **Advanced Image Search**: Search Unsplash's extensive photo library with filters for:\n  - Keyword relevance\n  - Color schemes\n  - Orientation options\n  - Custom sorting and pagination\n\n## 🔑 Obtaining Unsplash Access Key\n\nBefore installing this server, you'll need to obtain an Unsplash API Access Key:\n\n1. Create a developer account at [Unsplash](https://unsplash.com/developers)\n2. Register a new application\n3. Get your Access Key from the application details page\n4. Use this key in the configuration steps below\n\nFor more details, refer to the [official Unsplash API documentation](https://unsplash.com/documentation).\n\n## 🚀 Installation\n\nTo install Unsplash Image Integration Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@hellokaton/unsplash-mcp-server):\n\n### IDE Setup\n\n**Cursor IDE**\n\n```bash\nnpx -y @smithery/cli@latest install @hellokaton/unsplash-mcp-server --client cursor --key 7558c683-****-****\n```\n\n**Windsurf**\n\n```bash\nnpx -y @smithery/cli@latest install @hellokaton/unsplash-mcp-server --client windsurf --key 7558c683-****-****\n```\n\n**Cline**\n\n```bash\nnpx -y @smithery/cli@latest install @hellokaton/unsplash-mcp-server --client cline --key 7558c683-****-****\n```\n\n### Manual Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/hellokaton/unsplash-mcp-server.git\n\n# Navigate to project directory\ncd unsplash-mcp-server\n\n# Create virtual environment\nuv venv\n\n# Install dependencies\nuv pip install .\n```\n\n**Cursor Editor Integration**\n\nAdd the following configuration to your Cursor editor's `settings.json`:\n\n⚠️ **Note:** Please adjust the following configuration according to your actual installation:\n\n- If `uv` is not in your system PATH, use an absolute path (e.g., `/path/to/uv`)\n- `./server.py` should be modified to the actual location of your server script (can use absolute path or path relative to workspace)\n\n\n\n```json\n{\n  \"mcpServers\": {\n    \"unsplash\": {\n      \"command\": \"uv\",\n      \"args\": [\"run\", \"--with\", \"fastmcp\", \"fastmcp\", \"run\", \"./server.py\"],\n      \"env\": {\n        \"UNSPLASH_ACCESS_KEY\": \"${YOUR_ACCESS_KEY}\"\n      }\n    }\n  }\n}\n```\n\n### Using in Cursor\n\n\n\n## 🛠️ Available Tools\n\n### Search Photos\n\n```json\n{\n  \"tool\": \"search_photos\",\n  \"query\": \"mountain\",\n  \"per_page\": 5,\n  \"orientation\": \"landscape\"\n}\n```\n\n## 🔄 Other Implementations\n\n- Golang: [unsplash-mcp-server](https://github.com/douglarek/unsplash-mcp-server)\n- Java: [unsplash-mcp-server](https://github.com/JavaProgrammerLB/unsplash-mcp-server)\n\n## 📄 License\n\n[MIT License](LICENSE)\n\n## 📬 Contact\n\n- [Twitter/X](https://x.com/hellokaton)\n- [GitHub Issues](https://github.com/hellokaton/unsplash-mcp-server/issues)",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "unsplash",
        "mcp",
        "image",
        "unsplash image",
        "unsplash mcp",
        "image retrieval"
      ],
      "category": "image-and-video-generation"
    },
    "htessaro--mcp-test-deploy-2": {
      "owner": "htessaro",
      "name": "mcp-test-deploy-2",
      "url": "https://github.com/htessaro/mcp-test-deploy-2",
      "imageUrl": "/freedevtools/mcp/pfp/htessaro.webp",
      "description": "Access a wide array of cat images and detailed breed information through a TypeScript SDK, enabling image uploads, retrieval of breed data, and user interactions such as favoriting or voting on images.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-04-28T17:24:43Z",
      "readme_content": "",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "htessaro",
        "breed",
        "images",
        "htessaro mcp",
        "cat images",
        "breed information"
      ],
      "category": "image-and-video-generation"
    },
    "huangmiuXyz--jimeng-mcp": {
      "owner": "huangmiuXyz",
      "name": "jimeng-mcp",
      "url": "https://github.com/huangmiuXyz/jimeng-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/huangmiuXyz.webp",
      "description": "Integrate AI-powered image generation capabilities into applications using the Jimeng AI model. Generate high-quality images through a simple MCP interface for advanced AI image synthesis.",
      "stars": 2,
      "forks": 2,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-06-20T02:13:23Z",
      "readme_content": "{\n  \"mcpServers\": {\n    \"jimeng\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"jimeng\",\n        \"-y\"\n      ],\n      \"env\": {\n        \"VOLCENGINE_ACCESS_KEY\": \"your_access_key_here\",\n        \"VOLCENGINE_SECRET_KEY\": \"your_secret_key_here\"\n      }\n    }\n  }\n}\n\nhttps://console.volcengine.com/iam/keymanage/ 获取Access Key ID和Secret Access Key\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ai",
        "jimeng",
        "generate",
        "image generation",
        "image synthesis",
        "ai image"
      ],
      "category": "image-and-video-generation"
    },
    "husniadil--mcp-image-placeholder": {
      "owner": "husniadil",
      "name": "mcp-image-placeholder",
      "url": "https://github.com/husniadil/mcp-image-placeholder",
      "imageUrl": "/freedevtools/mcp/pfp/husniadil.webp",
      "description": "Generates placeholder images from multiple providers, supporting both simple and real images as placeholders. Validates input parameters and returns image URLs for immediate use.",
      "stars": 8,
      "forks": 3,
      "license": "MIT License",
      "language": "HTML",
      "updated_at": "2025-06-17T08:32:20Z",
      "readme_content": "# MCP Image Placeholder Server\n\nThis is a Model Context Protocol (MCP) server that provides a tool for generating placeholder images from different providers.\n\n## Features\n\n- Generates placeholder images from supported providers\n- Supports two image providers:\n  - [`placehold`](https://placehold.co/): Provides simple placeholder images\n  - [`lorem-picsum`](https://picsum.photos/): Provides real images as placeholder images\n- Validates input parameters\n- Returns image URLs for immediate use\n\n## Requirements\n\n- Python 3.9+\n- `uv` package manager\n\n## Installation\n\n1. Clone this repository\n2. [Set up the configuration for MCP server](#configuration)\n\n## Usage\n\nThe server exposes one tool:\n\n### `image_placeholder`\n\nGenerate a placeholder image URL based on specified parameters.\n\n**Parameters:**\n- `provider`: The image provider to use (`placehold` or `lorem-picsum`)\n- `width`: The width of the image (1-10000)\n- `height`: The height of the image (1-10000)\n\n**Returns:**\n- URL string of the generated image\n\n**Example Usage:**\n```python\n# Generate a 300x200 placeholder image\nurl = image_placeholder(provider=\"placehold\", width=300, height=200)\n\n# Generate a 500px square lorem-picsum image\nurl = image_placeholder(provider=\"lorem-picsum\", width=500)\n```\n\n## Configuration\n\n### To connect this server to Claude for Desktop:\n\n1. Add the following to your `claude_desktop_config.json`:\n   ```json\n   {\n       \"mcpServers\": {\n           \"image-placeholder\": {\n               \"command\": \"uv\",\n               \"args\": [\n                   \"--directory\",\n                   \"/ABSOLUTE/PATH/TO/PROJECT\",\n                   \"run\",\n                   \"main.py\"\n               ]\n           }\n       }\n   }\n   ```\n2. Restart Claude for Desktop\n\n### To connect this server to Cursor:\n\n1. Open Cursor Settings\n2. Head to the `Features` section\n3. Scroll down to the `MCP Servers` section\n4. Click on the `Add new MCP server` button\n5. Enter the following information:\n   - Name: `image-placeholder`\n   - Type: `command`\n   - Server URL: `uv --directory /ABSOLUTE/PATH/TO/PROJECT run main.py`\n6. Click on the `Add ↵` button\n\n\n## Troubleshooting\n\nIf the tool is not detected, use absolute path of the `uv` command, e.g.\n```\n/ABSOLUTE/PATH/TO/uv --directory /ABSOLUTE/PATH/TO/PROJECT run main.py\n```\n\n## Example Usage and Output (Cursor)\n\nPrompt:\n```\nCreate a new directory named \"example\" and a file named output.html.\n\nThen create a single modern looking page using tailwindcss: https://unpkg.com/@tailwindcss/browser@4\n\nShow a nice header, content, and footer, showing a photo gallery.\n\nSave this into output.html\n```\n\n\n\nOutput:\n[Example Output (Cursor)](example/output.html)\n\n## License\n\n[MIT License](LICENSE)",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "placeholder",
        "images",
        "mcp",
        "placeholder images",
        "image placeholder",
        "mcp image"
      ],
      "category": "image-and-video-generation"
    },
    "ifmelate--mcp-image-extractor": {
      "owner": "ifmelate",
      "name": "mcp-image-extractor",
      "url": "https://github.com/ifmelate/mcp-image-extractor",
      "imageUrl": "/freedevtools/mcp/pfp/ifmelate.webp",
      "description": "Extracts images from local files and URLs, processing them into base64 format for analysis by large language models (LLMs). Suitable for analyzing image-based data, such as screenshots from tests.",
      "stars": 14,
      "forks": 4,
      "license": "MIT License",
      "language": "HTML",
      "updated_at": "2025-09-21T00:31:03Z",
      "readme_content": "# MCP Image Extractor\n\nMCP server for extracting and converting images to base64 for LLM analysis.\n\nThis MCP server provides tools for AI assistants to:\n- Extract images from local files\n- Extract images from URLs\n- Process base64-encoded images\n\n<a href=\"https://glama.ai/mcp/servers/@ifmelate/mcp-image-extractor\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@ifmelate/mcp-image-extractor/badge\" alt=\"Image Extractor MCP server\" />\n</a>\n\nHow it looks in Cursor:\n\n<img width=\"687\" alt=\"image\" src=\"https://github.com/user-attachments/assets/8954dbbd-7e7a-4f27-82a7-b251bd3c5af2\" />\n\nSuitable cases:\n- analyze playwright test results: screenshots\n\n## Installation\n\n### Recommended: Using npx in mcp.json (Easiest)\n\nThe recommended way to install this MCP server is using npx directly in your `.cursor/mcp.json` file:\n\n```json\n{\n  \"mcpServers\": {\n    \"image-extractor\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"mcp-image-extractor\"\n      ]\n    }\n  }\n}\n```\n\nThis approach:\n- Automatically installs the latest version\n- Does not require global installation\n- Works reliably across different environments\n\n### Alternative: Local Path Installation\n\nIf you prefer to use a local installation of the package, you can clone the repository and point to the built files:\n\n```json\n{\n  \"mcpServers\": {\n    \"image-extractor\": {\n      \"command\": \"node\",\n      \"args\": [\"/full/path/to/mcp-image-extractor/dist/index.js\"],\n      \"disabled\": false\n    }\n  }\n}\n```\n\n### Manual Installation\n\n```bash\n# Clone and install \ngit clone https://github.com/ifmelate/mcp-image-extractor.git\ncd mcp-image-extractor\nnpm install\nnpm run build\nnpm link\n```\n\nThis will make the `mcp-image-extractor` command available globally.\n\nThen configure in `.cursor/mcp.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"image-extractor\": {\n      \"command\": \"mcp-image-extractor\",\n      \"disabled\": false\n    }\n  }\n}\n```\n\n> **Troubleshooting for Cursor Users**: If you see \"Failed to create client\" error, try the local path installation method above or ensure you're using the correct path to the executable.\n\n## Available Tools\n\n### extract_image_from_file\n\nExtracts an image from a local file and converts it to base64.\n\nParameters:\n- `file_path` (required): Path to the local image file\n\n**Note:** All images are automatically resized to optimal dimensions (max 512x512) for LLM analysis to limit the size of the base64 output and optimize context window usage.\n\n### extract_image_from_url\n\nExtracts an image from a URL and converts it to base64.\n\nParameters:\n- `url` (required): URL of the image to extract\n\n**Note:** All images are automatically resized to optimal dimensions (max 512x512) for LLM analysis to limit the size of the base64 output and optimize context window usage.\n\n### extract_image_from_base64\n\nProcesses a base64-encoded image for LLM analysis.\n\nParameters:\n- `base64` (required): Base64-encoded image data\n- `mime_type` (optional, default: \"image/png\"): MIME type of the image\n\n**Note:** All images are automatically resized to optimal dimensions (max 512x512) for LLM analysis to limit the size of the base64 output and optimize context window usage.\n\n## Example Usage\n\nHere's an example of how to use the tools from Claude:\n\n```\nPlease extract the image from this local file: images/photo.jpg\n```\n\nClaude will automatically use the `extract_image_from_file` tool to load and analyze the image content.\n\n```\nPlease extract the image from this URL: https://example.com/image.jpg\n```\n\nClaude will automatically use the `extract_image_from_url` tool to fetch and analyze the image content.\n\n## Docker\n\nBuild and run with Docker:\n\n```bash\ndocker build -t mcp-image-extractor .\ndocker run -p 8000:8000 mcp-image-extractor\n```\n\n## License\n\nMIT",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "images",
        "base64",
        "image",
        "image extractor",
        "mcp image",
        "extracts images"
      ],
      "category": "image-and-video-generation"
    },
    "jaokuohsuan--draw-things-mcp-cursor": {
      "owner": "jaokuohsuan",
      "name": "draw-things-mcp-cursor",
      "url": "https://github.com/jaokuohsuan/draw-things-mcp-cursor",
      "imageUrl": "/freedevtools/mcp/pfp/jaokuohsuan.webp",
      "description": "Generates images based on text prompts using AI, integrating seamlessly within workflows. The server utilizes the Draw Things API to transform user-defined prompts into visual creations.",
      "stars": 12,
      "forks": 4,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-08-16T06:00:20Z",
      "readme_content": "# Draw Things MCP\n\nDraw Things API integration for Cursor using Model Context Protocol (MCP).\n\n## Prerequisites\n\n- Node.js >= 14.0.0\n- Draw Things API running on http://127.0.0.1:7888\n\n## Installation\n\n```bash\n# Install globally\nnpm install -g draw-things-mcp-cursor\n\n# Or run directly\nnpx draw-things-mcp-cursor\n```\n\n## Cursor Integration\n\nTo set up this tool in Cursor, see the detailed guide in [cursor-setup.md](./cursor-setup.md).\n\nQuick setup:\n\n1. Create or edit `~/.cursor/claude_desktop_config.json`:\n```json\n{\n  \"mcpServers\": {\n    \"draw-things\": {\n      \"command\": \"draw-things-mcp-cursor\",\n      \"args\": []\n    }\n  }\n}\n```\n\n2. Restart Cursor\n3. Use in Cursor: `generateImage({\"prompt\": \"a cute cat\"})`\n\n## CLI Usage\n\n### Generate Image\n\n```bash\necho '{\"prompt\": \"your prompt here\"}' | npx draw-things-mcp-cursor\n```\n\n### Parameters\n\n- `prompt`: The text prompt for image generation (required)\n- `negative_prompt`: The negative prompt for image generation\n- `width`: Image width (default: 360)\n- `height`: Image height (default: 360)\n- `steps`: Number of steps for generation (default: 8)\n- `model`: Model to use for generation (default: \"flux_1_schnell_q5p.ckpt\")\n- `sampler`: Sampling method (default: \"DPM++ 2M AYS\")\n\nExample:\n\n```bash\necho '{\n  \"prompt\": \"a happy smiling dog, professional photography\",\n  \"negative_prompt\": \"ugly, deformed, blurry\",\n  \"width\": 360,\n  \"height\": 360,\n  \"steps\": 4\n}' | npx draw-things-mcp-cursor\n```\n\n### MCP Tool Integration\n\nWhen used as an MCP tool in Cursor, the tool will be registered as `generateImage` with the following parameters:\n\n```typescript\n{\n  prompt: string;       // Required - The prompt to generate the image from\n  negative_prompt?: string;  // Optional - The negative prompt\n  width?: number;       // Optional - Image width (default: 360)\n  height?: number;      // Optional - Image height (default: 360)\n  model?: string;       // Optional - Model name\n  steps?: number;       // Optional - Number of steps (default: 8)\n}\n```\n\nThe generated images will be saved in the `images` directory with a filename format of:\n`<sanitized_prompt>_<timestamp>.png`\n\n## Response Format\n\nSuccess:\n```json\n{\n  \"type\": \"success\",\n  \"content\": [{\n    \"type\": \"image\",\n    \"data\": \"base64 encoded image data\",\n    \"mimeType\": \"image/png\"\n  }],\n  \"metadata\": {\n    \"parameters\": { ... }\n  }\n}\n```\n\nError:\n```json\n{\n  \"type\": \"error\",\n  \"error\": \"error message\",\n  \"code\": 500\n}\n```\n\n## Troubleshooting\n\nIf you encounter issues:\n\n- Ensure Draw Things API is running at http://127.0.0.1:7888\n- Check log files in `~/.cursor/logs` if using with Cursor\n- Make sure src/index.js has execution permissions: `chmod +x src/index.js`\n\n## License\n\nMIT ",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "visual",
        "cursor",
        "draw",
        "visual creations",
        "generates images",
        "utilizes draw"
      ],
      "category": "image-and-video-generation"
    },
    "jbrower95--mcp-asset-gen": {
      "owner": "jbrower95",
      "name": "mcp-asset-gen",
      "url": "https://github.com/jbrower95/mcp-asset-gen",
      "imageUrl": "/freedevtools/mcp/pfp/jbrower95.webp",
      "description": "Generate high-quality image assets for game or web development by providing descriptive prompts. Streamline asset creation workflows with automated image generation through AI.",
      "stars": 3,
      "forks": 5,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-08-05T20:41:33Z",
      "readme_content": "# mcp-asset-gen\n[![npm version](https://badge.fury.io/js/mcp-asset-gen.svg)](https://badge.fury.io/js/mcp-asset-gen)\n\n\nThis tool allows Claude to speak to OpenAI, and use `gpt-image-1` to generate image assets. This can be pretty useful for game or web development, when you need to print individual assets.\n\n# Requirements\n\n- Node \n- An OpenAI [API Key](https://platform.openai.com/settings/organization/api-keys)\n    - Note that this requires an organization, with ID verification at the moment.\n\n# Installation\n\n1. Get an API KEY from the [OpenAI website](https://platform.openai.com/settings/organization/api-keys).\n\n2. Export it in your shell as API_KEY.\n\n```bash\nexport API_KEY=sk-proj-....\n```\n\n3. Then, paste this into that same shell:\n\n```bash\njq --arg apiKey \"$API_KEY\" \\\n'.mcpServers = (.mcpServers // {}) | \n .mcpServers[\"mcp-asset-gen\"] = {\n   type: \"stdio\",\n   command: \"npx\",\n   args: [\"mcp-asset-gen\"],\n   env: { API_KEY: $apiKey }\n }' ~/.claude.json > ~/.claude.tmp && mv ~/.claude.tmp ~/.claude.json\n```\n\n4. You're done! Ask Claude to generate you an image for something, and you'll see\n\n```\n> generate a small logo image that i could use for my arcade game\n\n I'll generate a logo for your arcade game. Please provide a more specific description of what you'd like to see in the logo (colors, style,\n  game theme, etc.) for better results.\n\n> It should look like an old school pacman machine (liek a wooden arcade machine)\n\n⏺ mcp-asset-gen:generateImag(outputPathAbsolute: \"/Users/jbrower/projects/mcp-asset-gen/arcade-logo.png\", prompt: \"An old school wooden arcade…\n   (MCP)                    machine logo in the style of Pacman, with retro colors and pixelated elements, top-down view of the cabinet,\n                            nostalgic arcade gaming feel, vibrant colors against dark background\", quality: \"high\", size: \"1024x1024\")\n  ⎿  The image is now available at /Users/jbrower/projects/mcp-asset-gen/arcade-logo.png.\n\n⏺ Generated arcade logo saved to /Users/jbrower/projects/mcp-asset-gen/arcade-logo.png\n```\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcp",
        "generate",
        "image",
        "image generation",
        "video generation",
        "image assets"
      ],
      "category": "image-and-video-generation"
    },
    "jezweb--openai-mcp": {
      "owner": "jezweb",
      "name": "openai-mcp",
      "url": "https://github.com/jezweb/openai-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/jezweb.webp",
      "description": "Connect to OpenAI's DALL-E API for image generation with support for various options, enabling seamless integration into MCP-compatible AI assistants like Roo Code.",
      "stars": 1,
      "forks": 3,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-04-24T08:28:31Z",
      "readme_content": "# OpenAI MCP - DALL-E API Integration for Roo Code\n\nThis project provides a Model Context Protocol (MCP) server for connecting to OpenAI's DALL-E API for image generation with full support for all available options. It's specifically designed to work with Roo Code and other MCP-compatible AI assistants.\n\n## Overview\n\nThis MCP server provides a tool for DALL-E image generation with comprehensive support for all DALL-E API options. It allows AI assistants like Roo Code to generate images through the Model Context Protocol (MCP) with fine-grained control over the generation process.\n\n## Project Structure\n\n- `src/` - Source code for the MCP server\n  - `dalle.ts` - Implementation of the DALL-E API integration with all options\n  - `index.ts` - Main server file with the DALL-E tool and input schema\n  - `install.ts` - Installation script for Roo Code and Claude Desktop\n- `build/` - Compiled JavaScript files\n- `dalle-test.html` - HTML page to display the generated image and document available options\n- `test-dalle.js` - Direct test script for the DALL-E API with examples of different options\n\n## Setup Instructions for Roo Code\n\n### Installation\n\n1. Install the package globally:\n   ```\n   npm install -g openai-mcp\n   ```\n\n2. Run the setup command to configure Roo Code:\n   ```\n   openai-mcp install\n   ```\n\n3. Set your OpenAI API key in Roo Code settings:\n   - Open Roo Code\n   - Go to Settings\n   - Add the following environment variable to the MCP server configuration:\n     ```json\n     \"openai-mcp\": {\n       \"env\": {\n         \"OPENAI_API_KEY\": \"your-openai-api-key\"\n       }\n     }\n     ```\n\n4. Restart Roo Code",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "openai",
        "mcp",
        "ai",
        "openai mcp",
        "image generation",
        "video generation"
      ],
      "category": "image-and-video-generation"
    },
    "jhacksman--OpenSCAD-MCP-Server": {
      "owner": "jhacksman",
      "name": "OpenSCAD-MCP-Server",
      "url": "https://github.com/jhacksman/OpenSCAD-MCP-Server",
      "imageUrl": "/freedevtools/mcp/pfp/jhacksman.webp",
      "description": "Generates 3D models from text descriptions or images, focusing on parametric model creation through multi-view reconstruction and integration with OpenSCAD. Facilitates remote processing and includes an image approval workflow for model generation.",
      "stars": 84,
      "forks": 17,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-10-03T04:21:59Z",
      "readme_content": "# OpenSCAD MCP Server\n\nA Model Context Protocol (MCP) server that enables users to generate 3D models from text descriptions or images, with a focus on creating parametric 3D models using multi-view reconstruction and OpenSCAD.\n\n## Features\n\n- **AI Image Generation**: Generate images from text descriptions using Google Gemini or Venice.ai APIs\n- **Multi-View Image Generation**: Create multiple views of the same 3D object for reconstruction\n- **Image Approval Workflow**: Review and approve/deny generated images before reconstruction\n- **3D Reconstruction**: Convert approved multi-view images into 3D models using CUDA Multi-View Stereo\n- **Remote Processing**: Process computationally intensive tasks on remote servers within your LAN\n- **OpenSCAD Integration**: Generate parametric 3D models using OpenSCAD\n- **Parametric Export**: Export models in formats that preserve parametric properties (CSG, AMF, 3MF, SCAD)\n- **3D Printer Discovery**: Optional network printer discovery and direct printing\n\n## Architecture\n\nThe server is built using the Python MCP SDK and follows a modular architecture:\n\n```\nopenscad-mcp-server/\n├── src/\n│   ├── main.py                  # Main application\n│   ├── main_remote.py           # Remote CUDA MVS server\n│   ├── ai/                      # AI integrations\n│   │   ├── gemini_api.py        # Google Gemini API for image generation\n│   │   └── venice_api.py        # Venice.ai API for image generation (optional)\n│   ├── models/                  # 3D model generation\n│   │   ├── cuda_mvs.py          # CUDA Multi-View Stereo integration\n│   │   └── code_generator.py    # OpenSCAD code generation\n│   ├── workflow/                # Workflow components\n│   │   ├── image_approval.py    # Image approval mechanism\n│   │   └── multi_view_to_model_pipeline.py  # Complete pipeline\n│   ├── remote/                  # Remote processing\n│   │   ├── cuda_mvs_client.py   # Client for remote CUDA MVS processing\n│   │   ├── cuda_mvs_server.py   # Server for remote CUDA MVS processing\n│   │   ├── connection_manager.py # Remote connection management\n│   │   └── error_handling.py    # Error handling for remote processing\n│   ├── openscad_wrapper/        # OpenSCAD CLI wrapper\n│   ├── visualization/           # Preview generation and web interface\n│   ├── utils/                   # Utility functions\n│   └── printer_discovery/       # 3D printer discovery\n├── scad/                        # Generated OpenSCAD files\n├── output/                      # Output files (models, previews)\n│   ├── images/                  # Generated images\n│   ├── multi_view/              # Multi-view images\n│   ├── approved_images/         # Approved images for reconstruction\n│   └── models/                  # Generated 3D models\n├── templates/                   # Web interface templates\n└── static/                      # Static files for web interface\n```\n\n## Installation\n\n1. Clone the repository:\n   ```\n   git clone https://github.com/jhacksman/OpenSCAD-MCP-Server.git\n   cd OpenSCAD-MCP-Server\n   ```\n\n2. Create a virtual environment:\n   ```\n   python -m venv venv\n   source venv/bin/activate  # On Windows: venv\\Scripts\\activate\n   ```\n\n3. Install dependencies:\n   ```\n   pip install -r requirements.txt\n   ```\n\n4. Install OpenSCAD:\n   - Ubuntu/Debian: `sudo apt-get install openscad`\n   - macOS: `brew install openscad`\n   - Windows: Download from [openscad.org](https://openscad.org/downloads.html)\n\n5. Install CUDA Multi-View Stereo:\n   ```\n   git clone https://github.com/fixstars/cuda-multi-view-stereo.git\n   cd cuda-multi-view-stereo\n   mkdir build && cd build\n   cmake ..\n   make\n   ```\n\n6. Set up API keys:\n   - Create a `.env` file in the root directory\n   - Add your API keys:\n     ```\n     GEMINI_API_KEY=your-gemini-api-key\n     VENICE_API_KEY=your-venice-api-key  # Optional\n     REMOTE_CUDA_MVS_API_KEY=your-remote-api-key  # For remote processing\n     ```\n\n## Remote Processing Setup\n\nThe server supports remote processing of computationally intensive tasks, particularly CUDA Multi-View Stereo reconstruction. This allows you to offload processing to more powerful machines within your LAN.\n\n### Server Setup (on the machine with CUDA GPU)\n\n1. Install CUDA Multi-View Stereo on the server machine:\n   ```\n   git clone https://github.com/fixstars/cuda-multi-view-stereo.git\n   cd cuda-multi-view-stereo\n   mkdir build && cd build\n   cmake ..\n   make\n   ```\n\n2. Start the remote CUDA MVS server:\n   ```\n   python src/main_remote.py\n   ```\n\n3. The server will automatically advertise itself on the local network using Zeroconf.\n\n### Client Configuration\n\n1. Configure remote processing in your `.env` file:\n   ```\n   REMOTE_CUDA_MVS_ENABLED=True\n   REMOTE_CUDA_MVS_USE_LAN_DISCOVERY=True\n   REMOTE_CUDA_MVS_API_KEY=your-shared-secret-key\n   ```\n\n2. Alternatively, you can specify a server URL directly:\n   ```\n   REMOTE_CUDA_MVS_ENABLED=True\n   REMOTE_CUDA_MVS_USE_LAN_DISCOVERY=False\n   REMOTE_CUDA_MVS_SERVER_URL=http://server-ip:8765\n   REMOTE_CUDA_MVS_API_KEY=your-shared-secret-key\n   ```\n\n### Remote Processing Features\n\n- **Automatic Server Discovery**: Find CUDA MVS servers on your local network\n- **Job Management**: Upload images, track job status, and download results\n- **Fault Tolerance**: Automatic retries, circuit breaker pattern, and error tracking\n- **Authentication**: Secure API key authentication for all remote operations\n- **Health Monitoring**: Continuous server health checks and status reporting\n\n## Usage\n\n1. Start the server:\n   ```\n   python src/main.py\n   ```\n\n2. The server will start on http://localhost:8000\n\n3. Use the MCP tools to interact with the server:\n\n   - **generate_image_gemini**: Generate an image using Google Gemini API\n     ```json\n     {\n       \"prompt\": \"A low-poly rabbit with black background\",\n       \"model\": \"gemini-2.0-flash-exp-image-generation\"\n     }\n     ```\n\n   - **generate_multi_view_images**: Generate multiple views of the same 3D object\n     ```json\n     {\n       \"prompt\": \"A low-poly rabbit\",\n       \"num_views\": 4\n     }\n     ```\n\n   - **create_3d_model_from_images**: Create a 3D model from approved multi-view images\n     ```json\n     {\n       \"image_ids\": [\"view_1\", \"view_2\", \"view_3\", \"view_4\"],\n       \"output_name\": \"rabbit_model\"\n     }\n     ```\n\n   - **create_3d_model_from_text**: Complete pipeline from text to 3D model\n     ```json\n     {\n       \"prompt\": \"A low-poly rabbit\",\n       \"num_views\": 4\n     }\n     ```\n\n   - **export_model**: Export a model to a specific format\n     ```json\n     {\n       \"model_id\": \"your-model-id\",\n       \"format\": \"obj\"  // or \"stl\", \"ply\", \"scad\", etc.\n     }\n     ```\n\n   - **discover_remote_cuda_mvs_servers**: Find CUDA MVS servers on your network\n     ```json\n     {\n       \"timeout\": 5\n     }\n     ```\n\n   - **get_remote_job_status**: Check the status of a remote processing job\n     ```json\n     {\n       \"server_id\": \"server-id\",\n       \"job_id\": \"job-id\"\n     }\n     ```\n\n   - **download_remote_model_result**: Download a completed model from a remote server\n     ```json\n     {\n       \"server_id\": \"server-id\",\n       \"job_id\": \"job-id\",\n       \"output_name\": \"model-name\"\n     }\n     ```\n\n   - **discover_printers**: Discover 3D printers on the network\n     ```json\n     {}\n     ```\n\n   - **print_model**: Print a model on a connected printer\n     ```json\n     {\n       \"model_id\": \"your-model-id\",\n       \"printer_id\": \"your-printer-id\"\n     }\n     ```\n\n## Image Generation Options\n\nThe server supports multiple image generation options:\n\n1. **Google Gemini API** (Default): Uses the Gemini 2.0 Flash Experimental model for high-quality image generation\n   - Supports multi-view generation with consistent style\n   - Requires a Google Gemini API key\n\n2. **Venice.ai API** (Optional): Alternative image generation service\n   - Supports various models including flux-dev and fluently-xl\n   - Requires a Venice.ai API key\n\n3. **User-Provided Images**: Skip image generation and use your own images\n   - Upload images directly to the server\n   - Useful for working with existing photographs or renders\n\n## Multi-View Workflow\n\nThe server implements a multi-view workflow for 3D reconstruction:\n\n1. **Image Generation**: Generate multiple views of the same 3D object\n2. **Image Approval**: Review and approve/deny each generated image\n3. **3D Reconstruction**: Convert approved images into a 3D model using CUDA MVS\n   - Can be processed locally or on a remote server within your LAN\n4. **Model Refinement**: Optionally refine the model using OpenSCAD\n\n## Remote Processing Workflow\n\nThe remote processing workflow allows you to offload computationally intensive tasks to more powerful machines:\n\n1. **Server Discovery**: Automatically discover CUDA MVS servers on your network\n2. **Image Upload**: Upload approved multi-view images to the remote server\n3. **Job Processing**: Process the images on the remote server using CUDA MVS\n4. **Status Tracking**: Monitor the job status and progress\n5. **Result Download**: Download the completed 3D model when processing is finished\n\n## Supported Export Formats\n\nThe server supports exporting models in various formats:\n\n- **OBJ**: Wavefront OBJ format (standard 3D model format)\n- **STL**: Standard Triangle Language (for 3D printing)\n- **PLY**: Polygon File Format (for point clouds and meshes)\n- **SCAD**: OpenSCAD source code (for parametric models)\n- **CSG**: OpenSCAD CSG format (preserves all parametric properties)\n- **AMF**: Additive Manufacturing File Format (preserves some metadata)\n- **3MF**: 3D Manufacturing Format (modern replacement for STL with metadata)\n\n## Web Interface\n\nThe server provides a web interface for:\n\n- Generating and approving multi-view images\n- Previewing 3D models from different angles\n- Downloading models in various formats\n\nAccess the interface at http://localhost:8000/ui/\n\n## License\n\nMIT\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "openscad",
        "3d",
        "mcp",
        "openscad mcp",
        "openscad facilitates",
        "jhacksman openscad"
      ],
      "category": "image-and-video-generation"
    },
    "jmanhype--mcp-flux-studio": {
      "owner": "jmanhype",
      "name": "mcp-flux-studio",
      "url": "https://github.com/jmanhype/mcp-flux-studio",
      "imageUrl": "/freedevtools/mcp/pfp/jmanhype.webp",
      "description": "Integrates advanced image generation capabilities from Flux into AI coding assistants, enabling seamless text-to-image generation and manipulation within development environments.",
      "stars": 20,
      "forks": 6,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-08-11T12:07:21Z",
      "readme_content": "# MCP Flux Studio\n\n[![smithery badge](https://smithery.ai/badge/@jmanhype/mcp-flux-studio)](https://smithery.ai/server/@jmanhype/mcp-flux-studio)\n\nA powerful Model Context Protocol (MCP) server that brings Flux's advanced image generation capabilities to your AI coding assistants. This server enables direct integration of Flux's image generation, manipulation, and control features into Cursor and Windsurf (Codeium) IDEs.\n\n## Overview\n\nMCP Flux Studio bridges the gap between AI coding assistants and Flux's powerful image generation API, allowing seamless integration of image generation capabilities directly into your development workflow.\n\n### Features\n\n- **Image Generation**\n  - Text-to-image generation with precise control\n  - Multiple model support (flux.1.1-pro, flux.1-pro, flux.1-dev, flux.1.1-ultra)\n  - Customizable aspect ratios and dimensions\n\n- **Image Manipulation**\n  - Image-to-image transformation\n  - Inpainting with customizable masks\n  - Resolution upscaling and enhancement\n\n- **Advanced Controls**\n  - Edge-based generation (canny)\n  - Depth-aware generation\n  - Pose-guided generation\n\n- **IDE Integration**\n  - Full support for Cursor (v0.45.7+)\n  - Compatible with Windsurf/Codeium Cascade (Wave 3+)\n  - Seamless tool invocation through AI assistants\n\n## Quick Start\n\n1. **Prerequisites**\n   - Node.js 18+\n   - Python 3.12+\n   - Flux API key\n   - Compatible IDE (Cursor or Windsurf)\n\n2. **Installation**\n\n### Installing via Smithery\n\nTo install Flux Studio for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@jmanhype/mcp-flux-studio):\n\n```bash\nnpx -y @smithery/cli install @jmanhype/mcp-flux-studio --client claude\n```\n\n### Manual Installation\n   ```bash\n   git clone https://github.com/jmanhype/mcp-flux-studio.git\n   cd mcp-flux-studio\n   npm install\n   npm run build\n   ```\n\n3. **Basic Configuration**\n   ```env\n   BFL_API_KEY=your_flux_api_key\n   FLUX_PATH=/path/to/flux/installation\n   ```\n\nFor detailed setup instructions, including IDE-specific configuration and troubleshooting, see our [Installation Guide](docs/INSTALLATION.md).\n\n## Documentation\n\n- [Installation Guide](docs/INSTALLATION.md) - Comprehensive setup instructions\n- [API Documentation](docs/API.md) - Detailed tool documentation\n- [Example Usage](examples/tool-examples.md) - Real-world usage examples\n- [Contributing Guidelines](docs/CONTRIBUTING.md) - How to contribute\n\n## IDE Integration\n\n### Cursor (v0.45.7+)\n\nMCP Flux Studio integrates seamlessly with Cursor's AI assistant:\n\n1. **Configuration**\n   - Configure via Settings > Features > MCP\n   - Supports both stdio and SSE connections\n   - Environment variables can be set via wrapper scripts\n\n2. **Usage**\n   - Tools automatically available to Cursor's AI assistant\n   - Tool invocations require user approval\n   - Real-time feedback on generation progress\n\n### Windsurf/Codeium (Wave 3+)\n\nIntegration with Windsurf's Cascade AI:\n\n1. **Configuration**\n   - Edit `~/.codeium/windsurf/mcp_config.json`\n   - Supports process-based tool execution\n   - Environment variables configured in JSON\n\n2. **Usage**\n   - Access tools through Cascade's MCP toolbar\n   - Automatic tool discovery and loading\n   - Integrated with Cascade's AI capabilities\n\nFor detailed IDE-specific setup instructions, see the [Installation Guide](docs/INSTALLATION.md).\n\n## Usage\n\nThe server provides the following tools:\n\n### generate\nGenerate an image from a text prompt.\n```json\n{\n  \"prompt\": \"A photorealistic cat\",\n  \"model\": \"flux.1.1-pro\",\n  \"aspect_ratio\": \"1:1\",\n  \"output\": \"generated.jpg\"\n}\n```\n\n### img2img\nGenerate an image using another image as reference.\n```json\n{\n  \"image\": \"input.jpg\",\n  \"prompt\": \"Convert to oil painting\",\n  \"model\": \"flux.1.1-pro\",\n  \"strength\": 0.85,\n  \"output\": \"output.jpg\",\n  \"name\": \"oil_painting\"\n}\n```\n\n### inpaint\nInpaint an image using a mask.\n```json\n{\n  \"image\": \"input.jpg\",\n  \"prompt\": \"Add flowers\",\n  \"mask_shape\": \"circle\",\n  \"position\": \"center\",\n  \"output\": \"inpainted.jpg\"\n}\n```\n\n### control\nGenerate an image using structural control.\n```json\n{\n  \"type\": \"canny\",\n  \"image\": \"control.jpg\",\n  \"prompt\": \"A realistic photo\",\n  \"output\": \"controlled.jpg\"\n}\n```\n\n## Development\n\n### Project Structure\n\n```\nflux-mcp-server/\n├── src/\n│   ├── index.ts          # Main server implementation\n│   └── types.ts          # TypeScript type definitions\n├── tests/\n│   └── server.test.ts    # Server tests\n├── docs/\n│   ├── API.md           # API documentation\n│   └── CONTRIBUTING.md  # Contribution guidelines\n├── examples/\n│   ├── generate.json    # Example tool usage\n│   └── config.json      # Example configuration\n├── package.json\n├── tsconfig.json\n└── README.md\n```\n\n### Running Tests\n\n```bash\nnpm test\n```\n\n### Building\n\n```bash\nnpm run build\n```\n\n## Contributing\n\nPlease read [CONTRIBUTING.md](docs/CONTRIBUTING.md) for details on our code of conduct and the process for submitting pull requests.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Acknowledgments\n\n- [Model Context Protocol](https://github.com/modelcontextprotocol/mcp) - The protocol specification\n- [Flux API](https://flux.ai) - The underlying image generation API\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ai",
        "flux",
        "studio",
        "image generation",
        "flux studio",
        "flux ai"
      ],
      "category": "image-and-video-generation"
    },
    "joshmouch--mcp-image-generator": {
      "owner": "joshmouch",
      "name": "mcp-image-generator",
      "url": "https://github.com/joshmouch/mcp-image-generator",
      "imageUrl": "/freedevtools/mcp/pfp/null.webp",
      "description": "Generate, edit, and create variations of images using OpenAI's DALL-E API, supporting multiple DALL-E models with customizable parameters. Validate OpenAI API keys for seamless operation.",
      "stars": 0,
      "forks": 0,
      "license": "Unknown",
      "language": "Unknown",
      "updated_at": "",
      "readme_content": "",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "openai",
        "images",
        "dall",
        "image generator",
        "mcp image",
        "video generation"
      ],
      "category": "image-and-video-generation"
    },
    "jyjune--mcp_vms": {
      "owner": "jyjune",
      "name": "mcp_vms",
      "url": "https://github.com/jyjune/mcp_vms",
      "imageUrl": "/freedevtools/mcp/pfp/jyjune.webp",
      "description": "Connects to CCTV recording software to retrieve live and recorded video streams, manage video channel information, and control VMS features like PTZ camera presets and playback dialogs.",
      "stars": 10,
      "forks": 3,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-03T17:24:47Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/jyjune-mcp-vms-badge.png)](https://mseep.ai/app/jyjune-mcp-vms)\n\n[![Trust Score](https://archestra.ai/mcp-catalog/api/badge/quality/jyjune/mcp_vms)](https://archestra.ai/mcp-catalog/jyjune__mcp_vms)\n\n# MCP Server - VMS Integration\n\nA Model Context Protocol (MCP) server designed to connect to a CCTV recording program (VMS) to retrieve recorded and live video streams. It also provides tools to control the VMS software, such as showing live or playback dialogs for specific channels at specified times.\n\n![diagram](https://github.com/jyjune/mcp_vms/blob/main/mcp_vms_diagram.png?raw=true)\n\n## Features\n\n- Retrieve video channel information, including connection and recording status.\n- Fetch recording dates and times for specific channels.\n- Fetch live or recorded images from video channels.\n- Show live video streams or playback dialogs for specific channels and timestamps.\n- Control PTZ (Pan-Tilt-Zoom) cameras by moving them to preset positions.\n- Comprehensive error handling and logging.\n\n## Prerequisites\n\n- Python 3.12+\n- `vmspy` library (for VMS integration)\n- `Pillow` library (for image processing)\n\n## MCP-server Configuration\n\nIf you want to use `mcp-vms` with Claude desktop, you need to set up the `claude_desktop_config.json` file as follows:\n\n```json\n{\n  \"mcpServers\": {\n\t\"vms\": {\n\t  \"command\": \"uv\",\n\t  \"args\": [\n\t\t\"--directory\",\n\t\t\"X:\\\\path\\\\to\\\\mcp-vms\",\n\t\t\"run\",\n\t\t\"mcp_vms.py\"\n\t  ]\n\t}\n  }\n}\n```\n\n## VMS Connection Configuration\n\nThe server uses the following default configuration for connecting to the VMS:\n- mcp_vms_config.py\n```python\nvms_config = {\n    'img_width': 320,\n    'img_height': 240,\n    'pixel_format': 'RGB',\n    'url': '127.0.0.1',\n    'port': 3300,\n    'access_id': 'admin',\n    'access_pw': 'admin',\n}\n```\n\n## Installation\n\n### 1. Install UV Package Manager\nRun the following command in PowerShell to install `UV`:\n\n```shell\npowershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n```\n\nFor alternative installation methods, see the [official UV documentation](https://docs.astral.sh/uv/getting-started/installation/).\n\n### 2.Install VMS Server\n   Download and install the VMS server from:  \n   [http://surveillance-logic.com/en/download.html](http://surveillance-logic.com/en/download.html)\n   (Required before using this MCP server)\n\n### 3.Install Python Dependencies\n   Download the vmspy library:  \n   [vmspy1.4-python3.12-x64.zip](https://sourceforge.net/projects/security-vms/files/vmspy1.4-python3.12-x64.zip/download)\n   Extract the contents into your `mcp_vms` directory\n\nThe mcp-vms directory should look like this:\n\n```shell\nmcp-vms/\n├── .gitignore\n├── .python-version\n├── LICENSE\n├── README.md\n├── pyproject.toml\n├── uv.lock\n├── mcp_vms.py            # Main server implementation\n├── mcp_vms_config.py     # VMS connection configuration\n├── vmspy.pyd             # VMS Python library\n├── avcodec-61.dll        # FFmpeg libraries\n├── avutil-59.dll\n├── swresample-5.dll\n├── swscale-8.dll\n```\n[![Verified on MseeP](https://mseep.ai/badge.svg)](https://mseep.ai/app/7027c4cd-a9c1-43dd-9e74-771fc7cc42da)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcp_vms",
        "cctv",
        "vms",
        "jyjune mcp_vms",
        "cctv recording",
        "connects cctv"
      ],
      "category": "image-and-video-generation"
    },
    "kazuph--mcp-fetch": {
      "owner": "kazuph",
      "name": "mcp-fetch",
      "url": "https://github.com/kazuph/mcp-fetch",
      "imageUrl": "/freedevtools/mcp/pfp/kazuph.webp",
      "description": "Fetch web content and process images to facilitate efficient interaction with online resources. Supports integration with MCP clients like Claude Desktop for seamless content management.",
      "stars": 30,
      "forks": 18,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-29T16:56:16Z",
      "readme_content": "# MCP Fetch\n\nModel Context Protocol server for fetching web content and processing images. This allows Claude Desktop (or any MCP client) to fetch web content and handle images appropriately.\n\n<a href=\"https://glama.ai/mcp/servers/5mknfdhyrg\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/5mknfdhyrg/badge\" alt=\"@kazuph/mcp-fetch MCP server\" /></a>\n\n## Quick Start (For Users)\n\nTo use this tool with Claude Desktop, simply add the following to your Claude Desktop configuration (`~/Library/Application Support/Claude/claude_desktop_config.json`):\n\n```json\n{\n  \"tools\": {\n    \"imageFetch\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@kazuph/mcp-fetch\"]\n    }\n  }\n}\n```\n\nThis will automatically download and run the latest version of the tool when needed.\n\n### Required Setup\n\n1. Enable Accessibility for Claude:\n   - Open System Settings\n   - Go to Privacy & Security > Accessibility\n   - Click the \"+\" button\n   - Add Claude from your Applications folder\n   - Turn ON the toggle for Claude\n\nThis accessibility setting is required for automated clipboard operations (Cmd+V) to work properly.\n\n## Features\n\n- **Web Content Extraction**: Automatically extracts and formats web content as markdown\n- **Article Title Extraction**: Extracts and displays the title of the article\n- **Image Processing**: Optional processing of images from web pages with optimization (disabled by default, enable with `enableFetchImages: true`)\n- **File Saving**: Images are automatically saved to `~/Downloads/mcp-fetch/YYYY-MM-DD/` directory when processed\n- **Dual Output**: Both file saving and optional Base64 encoding for AI display\n- **Pagination Support**: Supports pagination for both text and images\n- **JPEG Optimization**: Automatically optimizes images as JPEG for better performance\n- **GIF Support**: Extracts first frame from animated GIFs\n\n## For Developers\n\nThe following sections are for those who want to develop or modify the tool.\n\n## Prerequisites\n\n- Node.js 18+\n- macOS (for clipboard operations)\n- Claude Desktop (install from https://claude.ai/desktop)\n- tsx (install via `npm install -g tsx`)\n\n## Installation\n\n```bash\ngit clone https://github.com/kazuph/mcp-fetch.git\ncd mcp-fetch\nnpm install\nnpm run build\n```\n\n## Image Processing Specifications\n\nWhen processing images from web content, the following optimizations are applied:\n\n- Images are converted to JPEG format with quality control\n- Maximum width limited to 1200px by default\n- Maximum height limited to 1600px by default\n- Chroma subsampling (4:2:0) for better compression\n- MozJPEG optimization for smaller file sizes\n\n## Configuration\n\n1. Make sure Claude Desktop is installed and running.\n\n2. Install tsx globally if you haven't:\n```bash\nnpm install -g tsx\n# or\npnpm add -g tsx\n```\n\n3. Modify your Claude Desktop config located at:\n`~/Library/Application Support/Claude/claude_desktop_config.json`\n\nYou can easily find this through the Claude Desktop menu:\n1. Open Claude Desktop\n2. Click Claude on the Mac menu bar\n3. Click \"Settings\"\n4. Click \"Developer\"\n\nAdd the following to your MCP client's configuration:\n\n```json\n{\n  \"tools\": {\n    \"imageFetch\": {\n      \"args\": [\"tsx\", \"/path/to/mcp-fetch/index.ts\"]\n    }\n  }\n}\n```\n\n## Available Parameters\n\n- `url` (required): The URL to fetch\n- `maxLength` (default: 20000): Maximum length of content to return\n- `startIndex` (default: 0): Starting position in content\n- `imageStartIndex` (default: 0): Starting position for image collection\n- `raw` (default: false): Return raw content instead of processed markdown\n- `imageMaxCount` (default: 3): Maximum number of images to process per request\n- `imageMaxHeight` (default: 4000): Maximum height of merged image\n- `imageMaxWidth` (default: 1000): Maximum width of merged image\n- `imageQuality` (default: 80): JPEG quality (1-100)\n- `enableFetchImages` (default: false): Enable fetching and processing of images. FOR CLAUDE USERS ONLY: YOU ARE ALLOWED TO ENABLE THIS FEATURE!!! CLAUDE CAN FETCH AND PROCESS IMAGES!!! ENJOY THIS CAPABILITY!!!!!\n- `allowCrossOriginImages` (default: true): When true, also fetch images hosted on different origins from the page\n- `saveImages` (default: true): Save processed images to local files\n- `returnBase64` (default: false): Return base64 encoded images for AI display\n- `ignoreRobotsTxt` (default: false): Ignore robots.txt restrictions\n\n### Security Hardening (v1.5.1)\n\n- Only `http://` and `https://` URLs are allowed for page and image fetches\n- Blocks private/loopback/link-local IPs and local hostnames (e.g., `localhost`, `.local`)\n- Manual redirect handling with validation (max 3 hops)\n- Request timeouts (default 12s, configurable via `MCP_FETCH_TIMEOUT_MS`)\n- Response size limits: HTML up to 2MB, images up to 10MB (tunable via env)\n\nEnvironment variables:\n\n- `MCP_FETCH_TIMEOUT_MS` (default: 12000)\n- `MCP_FETCH_MAX_REDIRECTS` (default: 3)\n- `MCP_FETCH_MAX_HTML_BYTES` (default: 2000000)\n- `MCP_FETCH_MAX_IMAGE_BYTES` (default: 10000000)\n\n## Examples\n\n### Basic Content Fetching (No Images)\n```json\n{\n  \"url\": \"https://example.com\"\n}\n```\n\n### Fetching with Images (File Saving Only)\n```json\n{\n  \"url\": \"https://example.com\",\n  \"enableFetchImages\": true,\n  \"imageMaxCount\": 3\n}\n```\n\n### Fetching with Images for AI Display\n```json\n{\n  \"url\": \"https://example.com\",\n  \"enableFetchImages\": true,\n  \"returnBase64\": true,\n  \"imageMaxCount\": 3\n}\n```\n\n### Paginating Through Images\n```json\n{\n  \"url\": \"https://example.com\",\n  \"enableFetchImages\": true,\n  \"imageStartIndex\": 3,\n  \"imageMaxCount\": 3\n}\n```\n\n## Notes\n\n- This tool is designed for macOS only due to its dependency on macOS-specific clipboard operations.\n- Images are processed using Sharp for optimal performance and quality.\n- When multiple images are found, they are merged vertically with consideration for size limits.\n- Animated GIFs are automatically handled by extracting their first frame.\n- **File Saving**: Images are automatically saved to `~/Downloads/mcp-fetch/YYYY-MM-DD/` with filename format `hostname_HHMMSS_index.jpg`\n- **Tool Name**: The tool name has been changed from `fetch` to `imageFetch` to avoid conflicts with native fetch functions.\n\n## Changelog\n\n### v1.2.0\n- **BREAKING CHANGE**: Tool name changed from `fetch` to `imageFetch` to avoid conflicts\n- **NEW**: Automatic file saving - Images are now saved to `~/Downloads/mcp-fetch/YYYY-MM-DD/` by default\n- **NEW**: Added `saveImages` parameter (default: true) to control file saving\n- **NEW**: Added `returnBase64` parameter (default: false) for AI image display\n- **BEHAVIOR CHANGE**: Default behavior now saves files instead of only returning base64\n- Improved AI assistant integration with clear instructions for base64 option\n- Enhanced file organization with date-based directories and structured naming\n\n### v1.1.3\n- Changed default behavior: Images are not fetched by default (`enableFetchImages: false`)\n- Removed `disableImages` in favor of `enableFetchImages` parameter\n\n### v1.1.0\n- Added article title extraction feature\n- Improved response formatting to include article titles\n- Fixed type issues with MCP response content\n\n### v1.0.0\n- Initial release\n- Web content extraction\n- Image processing and optimization\n- Pagination support\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "kazuph",
        "mcp",
        "fetch",
        "mcp fetch",
        "kazuph mcp",
        "content management"
      ],
      "category": "image-and-video-generation"
    },
    "kazuph--mcp-screenshot": {
      "owner": "kazuph",
      "name": "mcp-screenshot",
      "url": "https://github.com/kazuph/mcp-screenshot",
      "imageUrl": "/freedevtools/mcp/pfp/kazuph.webp",
      "description": "Captures screenshots and performs OCR text recognition on macOS. Supports both Japanese and English text, offering multiple output formats.",
      "stars": 21,
      "forks": 6,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-10-03T22:32:03Z",
      "readme_content": "# MCP Screenshot\n\nAn MCP server that captures screenshots and performs OCR text recognition.\n\n<a href=\"https://glama.ai/mcp/servers/vcnmmaejv8\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/vcnmmaejv8/badge\" alt=\"mcp-screenshot MCP server\" /></a>\n\n## Features\n\n- Screenshot capture (left half, right half, full screen)\n- OCR text recognition (supports Japanese and English)\n- Multiple output formats (JSON, Markdown, vertical, horizontal)\n\n## OCR Engines\n\nThis server uses two OCR engines:\n\n1. [yomitoku](https://github.com/kazuph/yomitoku)\n   - Primary OCR engine\n   - High-accuracy Japanese text recognition\n   - Runs as an API server\n\n2. [Tesseract.js](https://github.com/naptha/tesseract.js)\n   - Fallback OCR engine\n   - Used when yomitoku is unavailable\n   - Supports both Japanese and English recognition\n\n## Installation\n\n```bash\nnpx -y @kazuph/mcp-screenshot\n```\n\n## Claude Desktop Configuration\n\nAdd the following configuration to your `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"screenshot\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@kazuph/mcp-screenshot\"],\n      \"env\": {\n        \"OCR_API_URL\": \"http://localhost:8000\"  // yomitoku API base URL\n      }\n    }\n  }\n}\n```\n\n## Environment Variables\n\n| Variable Name | Description | Default Value |\n|--------------|-------------|---------------|\n| OCR_API_URL | yomitoku API base URL | http://localhost:8000 |\n\n## Usage Example\n\nYou can use it by instructing Claude like this:\n\n```\nPlease take a screenshot of the left half of the screen and recognize the text in it.\n```\n\n## Tool Specification\n\n### capture\n\nTakes a screenshot and performs OCR.\n\nOptions:\n- `region`: Screenshot area ('left'/'right'/'full', default: 'left')\n- `format`: Output format ('json'/'markdown'/'vertical'/'horizontal', default: 'markdown')\n\n## License\n\nMIT\n\n## Author\n\nkazuph\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "kazuph",
        "macos",
        "ocr",
        "mcp screenshot",
        "recognition macos",
        "kazuph mcp"
      ],
      "category": "image-and-video-generation"
    },
    "kshern--image-tools-mcp": {
      "owner": "kshern",
      "name": "image-tools-mcp",
      "url": "https://github.com/kshern/image-tools-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/kshern.webp",
      "description": "Retrieve image dimensions, compress images, and convert images to various formats using local files or URLs. Supports image processing with detailed output on dimensions, types, and compression information.",
      "stars": 6,
      "forks": 3,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-10-03T22:32:19Z",
      "readme_content": "# Image Tools MCP\n\n[![smithery badge](https://smithery.ai/badge/@kshern/image-tools-mcp)](https://smithery.ai/server/@kshern/image-tools-mcp)\n\nA Model Context Protocol (MCP) service for retrieving image dimensions and compressing images, supporting both URL and local file sources.\n\n_[中文文档](./README_zh.md)_\n\n## Features\n\n- Retrieve image dimensions from URLs\n- Get image dimensions from local files\n- Compress images from URLs using TinyPNG API\n- Compress local images using TinyPNG API\n- Convert images to different formats (webp, jpeg/jpg, png)\n- Returns width, height, type, MIME type, and compression information\n\n### Example Results\n\n\n\n\n\n\n\ndownload from figma url and compress\n\n\n## Usage\n\n### Using as an MCP Service\n\nThis service provides five tool functions:\n\n1. `get_image_size` - Get dimensions of remote images\n2. `get_local_image_size` - Get dimensions of local images\n3. `compress_image_from_url` - Compress remote images using TinyPNG API\n4. `compress_local_image` - Compress local images using TinyPNG API\n5. `figma` - Fetch image links from Figma API and compress them using TinyPNG API\n\n### Client Integration\n\nTo use this MCP service, you need to connect to it from an MCP client. Here are examples of how to integrate with different clients:\n\n#### Usage\n\n```json\n{\n  \"mcpServers\": {\n    \"image-tools\": {\n      \"command\": \"npx\",\n      \"args\": [\"image-tools-mcp\"],\n      \"env\": {\n        \"TINIFY_API_KEY\": \"<YOUR_TINIFY_API_KEY>\",\n        \"FIGMA_API_TOKEN\": \"<YOUR_FIGMA_API_TOKEN>\"\n      }\n    }\n  }\n}\n```\n\n#### Using with MCP Client Library\n\n````typescript\nimport { McpClient } from \"@modelcontextprotocol/client\";\n\n// Initialize the client\nconst client = new McpClient({\n  transport: \"stdio\" // or other transport options\n});\n\n// Connect to the server\nawait client.connect();\n\n// Get image dimensions from URL\nconst urlResult = await client.callTool(\"get_image_size\", {\n  options: {\n    imageUrl: \"https://example.com/image.jpg\"\n  }\n});\nconsole.log(JSON.parse(urlResult.content[0].text));\n// Output: { width: 800, height: 600, type: \"jpg\", mime: \"image/jpeg\" }\n\n// Get image dimensions from local file\nconst localResult = await client.callTool(\"get_local_image_size\", {\n  options: {\n    imagePath: \"D:/path/to/image.png\"\n  }\n});\nconsole.log(JSON.parse(localResult.content[0].text));\n// Output: { width: 1024, height: 768, type: \"png\", mime: \"image/png\", path: \"D:/path/to/image.png\" }\n\n// Compress image from URL\nconst compressUrlResult = await client.callTool(\"compress_image_from_url\", {\n  options: {\n    imageUrl: \"https://example.com/image.jpg\",\n    outputFormat: \"webp\" // Optional: convert to webp, jpeg/jpg, or png\n  }\n});\nconsole.log(JSON.parse(compressUrlResult.content[0].text));\n// Output: { originalSize: 102400, compressedSize: 51200, compressionRatio: \"50.00%\", tempFilePath: \"/tmp/compressed_1615456789.webp\", format: \"webp\" }\n\n// Compress local image\nconst compressLocalResult = await client.callTool(\"compress_local_image\", {\n  options: {\n    imagePath: \"D:/path/to/image.png\",\n    outputPath: \"D:/path/to/compressed.webp\", // Optional\n    outputFormat: \"image/webp\" // Optional: convert to image/webp, image/jpeg, or image/png\n  }\n});\nconsole.log(JSON.parse(compressLocalResult.content[0].text));\n// Output: { originalSize: 102400, compressedSize: 51200, compressionRatio: \"50.00%\", outputPath: \"D:/path/to/compressed.webp\", format: \"webp\" }\n\n// Fetch image links from Figma API\n\nconst figmaResult = await client.callTool(\"figma\", {\n  options: {\n    figmaUrl: \"https://www.figma.com/file/XXXXXXX\"\n  }\n});\nconsole.log(JSON.parse(figmaResult.content[0].text));\n// Output: { imageLinks: [\"https://example.com/image1.jpg\", \"https://example.com/image2.jpg\"] }\n\n### Tool Schemas\n\n#### get_image_size\n\n```typescript\n{\n  options: {\n    imageUrl: string // URL of the image to retrieve dimensions for\n  }\n}\n````\n\n#### get_local_image_size\n\n```typescript\n{\n  options: {\n    imagePath: string; // Absolute path to the local image file\n  }\n}\n```\n\n#### compress_image_from_url\n\n```typescript\n{\n  options: {\n    imageUrl: string // URL of the image to compress\n    outputFormat?: \"image/webp\" | \"image/jpeg\" | \"image/jpg\" | \"image/png\" // Optional output format\n  }\n}\n```\n\n#### compress_local_image\n\n```typescript\n{\n  options: {\n    imagePath: string // Absolute path to the local image file\n    outputPath?: string // Optional absolute path for the compressed output image\n    outputFormat?: \"image/webp\" | \"image/jpeg\" | \"image/jpg\" | \"image/png\" // Optional output format\n  }\n}\n```\n\n#### figma\n\n```typescript\n{\n  options: {\n    figmaUrl: string; // URL of the Figma file to fetch image links from\n  }\n}\n```\n\n## Changelog\n\n- **2025-05-12:** Updated Figma API to support additional parameters, including 2x image scaling.\n\n## Technical Implementation\n\nThis project is built on the following libraries:\n\n- [probe-image-size](https://github.com/nodeca/probe-image-size) - For image dimension detection\n- [tinify](https://github.com/tinify/tinify-nodejs) - For image compression via the TinyPNG API\n- [figma-api](https://github.com/figma/api) - For fetching image links from Figma API\n\n## Environment Variables\n\n- `TINIFY_API_KEY` - Required for image compression functionality. Get your API key from [TinyPNG](https://tinypng.com/developers)\n  - When not provided, the compression tools (`compress_image_from_url` and `compress_local_image`) will not be registered\n- `FIGMA_API_TOKEN` - Required for fetching image links from Figma API. Get your API token from [Figma](https://www.figma.com/developers)\n  - When not provided, the Figma tool (`figma`) will not be registered\n\nNote: The basic image dimension tools (`get_image_size` and `get_local_image_size`) are always available regardless of API keys.\n\n## License\n\nMIT",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "images",
        "mcp",
        "compression",
        "image tools",
        "convert images",
        "images convert"
      ],
      "category": "image-and-video-generation"
    },
    "lalanikarim--comfy-mcp-server": {
      "owner": "lalanikarim",
      "name": "comfy-mcp-server",
      "url": "https://github.com/lalanikarim/comfy-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/lalanikarim.webp",
      "description": "Generates images based on user prompts by interacting with a remote Comfy server. Utilizes the FastMCP framework to manage image generation workflows.",
      "stars": 31,
      "forks": 12,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-01T17:04:48Z",
      "readme_content": "# Comfy MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@lalanikarim/comfy-mcp-server)](https://smithery.ai/server/@lalanikarim/comfy-mcp-server)\n\n> A server using FastMCP framework to generate images based on prompts via a remote Comfy server.\n\n## Overview\n\nThis script sets up a server using the FastMCP framework to generate images based on prompts using a specified workflow. It interacts with a remote Comfy server to submit prompts and retrieve generated images.\n\n## Prerequisites\n\n- [uv](https://docs.astral.sh/uv/) package and project manager for Python.\n- Workflow file exported from Comfy UI. This code includes a sample `Flux-Dev-ComfyUI-Workflow.json` which is only used here as reference. You will need to export from your workflow and set the environment variables accordingly.\n\nYou can install the required packages for local development:\n\n```bash\nuvx mcp[cli]\n```\n\n## Configuration\n\nSet the following environment variables:\n\n- `COMFY_URL` to point to your Comfy server URL.\n- `COMFY_WORKFLOW_JSON_FILE` to point to the absolute path of the API export json file for the comfyui workflow.\n- `PROMPT_NODE_ID` to the id of the text prompt node.\n- `OUTPUT_NODE_ID` to the id of the output node with the final image.\n- `OUTPUT_MODE` to either `url` or `file` to select desired output.\n\nOptionally, if you have an [Ollama](https://ollama.com) server running, you can connect to it for prompt generation.\n\n- `OLLAMA_API_BASE` to the url where ollama is running.\n- `PROMPT_LLM` to the name of the model hosted on ollama for prompt generation.\n\nExample:\n\n```bash\nexport COMFY_URL=http://your-comfy-server-url:port\nexport COMFY_WORKFLOW_JSON_FILE=/path/to/the/comfyui_workflow_export.json\nexport PROMPT_NODE_ID=6 # use the correct node id here\nexport OUTPUT_NODE_ID=9 # use the correct node id here\nexport OUTPUT_MODE=file\n```\n\n## Usage\n\nComfy MCP Server can be launched by the following command:\n\n```bash\nuvx comfy-mcp-server\n```\n\n### Example Claude Desktop Config\n\n```json\n{\n  \"mcpServers\": {\n    \"Comfy MCP Server\": {\n      \"command\": \"/path/to/uvx\",\n      \"args\": [\n        \"comfy-mcp-server\"\n      ],\n      \"env\": {\n        \"COMFY_URL\": \"http://your-comfy-server-url:port\",\n        \"COMFY_WORKFLOW_JSON_FILE\": \"/path/to/the/comfyui_workflow_export.json\",\n        \"PROMPT_NODE_ID\": \"6\",\n        \"OUTPUT_NODE_ID\": \"9\",\n        \"OUTPUT_MODE\": \"file\",\n      }\n    }\n  }\n}\n\n```\n\n## Functionality\n\n### `generate_image(prompt: str, ctx: Context) -> Image | str`\n\nThis function generates an image using a specified prompt. It follows these steps:\n\n1. Checks if all the environment variable are set.\n2. Loads a prompt template from a JSON file.\n3. Submits the prompt to the Comfy server.\n4. Polls the server for the status of the prompt processing.\n5. Retrieves and returns the generated image once it's ready.\n\n### `generate_prompt(topic: str, ctx: Context) -> str`\n\nThis function generates a comprehensive image generation prompt from specified topic.\n\n## Dependencies\n\n- `mcp`: For setting up the FastMCP server.\n- `json`: For handling JSON data.\n- `urllib`: For making HTTP requests.\n- `time`: For adding delays in polling.\n- `os`: For accessing environment variables.\n- `langchain`: For creating simple LLM Prompt chain to generate image generation prompt from topic.\n- `langchain-ollama`: For ollama specific modules for LangChain.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](https://github.com/lalanikarim/comfy-mcp-server/blob/main/LICENSE) file for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "fastmcp",
        "mcp",
        "lalanikarim",
        "utilizes fastmcp",
        "mcp server",
        "fastmcp framework"
      ],
      "category": "image-and-video-generation"
    },
    "laosu888--tupianyasuo": {
      "owner": "laosu888",
      "name": "tupianyasuo",
      "url": "https://github.com/laosu888/tupianyasuo",
      "imageUrl": "/freedevtools/mcp/pfp/laosu888.webp",
      "description": "A front-end image compression tool supporting various formats like PNG and JPG, enabling users to customize compression ratios and preview results in real-time. The application allows users to download optimized images with comparisons of file sizes before and after compression.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2024-12-25T19:15:50Z",
      "readme_content": "# 图片压缩工具\n\n一个简单易用的在线图片压缩工具，具有精美的苹果风格界面设计。\n\n## 功能特点\n\n- 支持PNG、JPG等格式图片上传\n- 支持自定义压缩比例\n- 实时预览压缩前后的图片效果\n- 显示压缩前后文件大小对比\n- 支持压缩后图片下载\n- 纯前端实现，无需后端服务\n\n## 项目结构\n\n```\n├── index.html          # 主页面\n├── css/               \n│   └── style.css      # 样式文件\n├── js/\n│   └── main.js        # 主要功能实现\n└── assets/\n    └── icons/         # SVG图标\n```\n\n## 技术栈\n\n- HTML5\n- CSS3 (Flexbox & Grid)\n- Vanilla JavaScript\n- 浏览器原生图片压缩API ",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "compression",
        "png",
        "images",
        "image compression",
        "compression tool",
        "video generation"
      ],
      "category": "image-and-video-generation"
    },
    "luojunhui1--ImageOnC": {
      "owner": "luojunhui1",
      "name": "ImageOnC",
      "url": "https://github.com/luojunhui1/ImageOnC",
      "imageUrl": "/freedevtools/mcp/pfp/luojunhui1.webp",
      "description": "Implement vehicle license plate recognition using C/C++ on FPGA, utilizing OpenCV for image display and Eigen for optimized matrix operations. The project includes code for training neural networks and processing license plate images.",
      "stars": 1,
      "forks": 0,
      "license": "No License",
      "language": "C++",
      "updated_at": "2024-05-17T18:19:28Z",
      "readme_content": "# ImageOnC\n## 1.介绍\n本仓库为实现在FPGA上的车牌识别而创建，但本仓库只保有C/C++部分的代码，并未保存使用HLS工具后的代码。要特别说明的是，本项目中的代码均用C实现，其中出现的C++主要为便于OpenCV进行图像显示或者Eigen库加速矩阵运算，但均可删除或改成C中的数组而不影响其正常功能。\n## 2.文件组成\n```\n.\n├── build\n├── cmake-build-debug\n├── CMakeLists.txt\n├── database\n├── Fit.cpp\n├── Han\n├── include\n├── Letters\n├── main.cpp\n├── paramLetters.txt\n├── param.txt\n├── README.md\n└── Train.cpp\n```\n\n其中build和cmake-build-debug文件均为编译执行过程产生的文件；CMakeLists.txt用于指导编译方式；database为车牌图片文件夹；Fit.cpp原作测试网络准确性，但其内容在测试后被整合到main.cpp中，故该文件无实际意义；Han文件夹保存了用于训练汉字识别的图像；Letters中则保存了用于训练字母和数字识别的代码；main.cpp为执行的识别车牌的主函数；Train.cpp用于训练神经网络；param.txt及paramLetters.txt则保存了网络参数；include文件中保存了一写自定义的功能函数，其文件树如下：\n```\n.\n├── Config.h\n├── Eigen\n├── FileProcess.h\n├── ModelTrans.h\n├── Net.h\n├── Process.h\n├── SaveLoad.h\n└── unsupported\n```\n**Config.h**: 用于约定网络参数和一些全局变量，便于项目代码组织\n\n**Eigen**: Eigen库代码\n\n**unsupported**: Eigen库代码,原为使用Tensor类表示高维矩阵，但Tensor使用不便，实际未使用\n\n**FileProcess**: 用于系统文件操作，主要是查询文件夹下的所有文件并遍历\n\n**ModelTrans**: 用于从图像的数据矩阵中读取BGR图像并将其分割、保存\n\n**Net.h**: 神经网络的定义、训练及使用部分\n\n**SaveLoad**: 用于从图像路径读取bmp图像并分通道保存图像数据部分\n\n## 3. 实际效果\n数据集比较简单，能做到100%。\n\n\n\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "opencv",
        "recognition",
        "imageonc",
        "opencv image",
        "plate recognition",
        "license plate"
      ],
      "category": "image-and-video-generation"
    },
    "luoshui-coder--image-generator-mcp-server": {
      "owner": "luoshui-coder",
      "name": "image-generator-mcp-server",
      "url": "https://github.com/luoshui-coder/image-generator-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/luoshui-coder.webp",
      "description": "Generates images based on prompts using OpenAI's DALL-E model, saving them in a specified directory on the user's desktop.",
      "stars": 1,
      "forks": 0,
      "license": "No License",
      "language": "",
      "updated_at": "2025-03-14T04:57:37Z",
      "readme_content": "# image-generator MCP Server\n\nAn mcp server that generates images based on image prompts\n\nThis is a TypeScript-based MCP server that implements image generation using **OPENAI**'s `dall-e-3` image generation model.\n\n## Features\n\n### Tools\n- `generate_image` - Generate an image for given prompt\n  - Takes `prompt` as a required parameter\n  - Takes `imageName` as a required parameter to save the generated image in a `generated-images` directory on your desktop\n\n## Development\n\nInstall dependencies:\n```bash\nnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n```bash\nnpm run watch\n```\n\n## Installation\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"command\": \"image-generator\",\n      \"env\": {\n        \"OPENAI_API_KEY\": \"<your-openai-api-key>\"\n    }\n  }\n}\n```\nMake sure to replace `<your-openai-api-key>` with your actual **OPENAI** Api Key.\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcp",
        "generates",
        "images",
        "generates images",
        "image generator",
        "video generation"
      ],
      "category": "image-and-video-generation"
    },
    "m-mcp--flux-schnell-server": {
      "owner": "m-mcp",
      "name": "flux-schnell-server",
      "url": "https://github.com/m-mcp/flux-schnell-server",
      "imageUrl": "/freedevtools/mcp/pfp/m-mcp.webp",
      "description": "Provides an MCP protocol-based API for generating images from text prompts with customizable dimensions and reproducible results using a specified random seed. Supports asynchronous streaming responses and integration with Hugging Face model services.",
      "stars": 1,
      "forks": 2,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-05-29T09:05:08Z",
      "readme_content": "# Flux Schnell Server\n\n[![smithery badge](https://smithery.ai/badge/@m-mcp/flux-schnell-server)](https://smithery.ai/server/@m-mcp/flux-schnell-server)\n\n基于[Flux Schnell](https://huggingface.co/spaces/black-forest-labs/flux-1-schnell)模型的MCP图像生成服务器。\n\n## 功能特点\n\n- 提供基于MCP协议的图像生成API\n- 支持自定义图片尺寸（宽度和高度）\n- 支持设置随机种子以复现特定生成结果\n- 支持异步流式响应\n- 提供HTTP接口调用Hugging Face的模型服务\n\n## 安装要求\n\n- Python >= 3.10\n- 依赖包：\n  - httpx >= 0.28.1\n  - mcp[cli] >= 1.3.0\n\n## 使用方法\n### 开发环境设置\n\n1. 创建并激活 Python 虚拟环境\n```bash\nuv venv && source .venv/bin/activate  # Unix/macOS\n# 或\n.venv\\Scripts\\activate  # Windows\n```\n\n2. 安装开发依赖\n```bash\nuv sync  # 以可编辑模式安装项目\n```\n\n### 调试方法\n\n1. 启用调试\n```bash\nmcp dev main.py\n或者\nnpx -y @modelcontextprotocol/inspector uv run main.py\n```\n\n2. 调用图像生成工具：\n```python\n# 示例代码\nasync def test_main():\n    img_url = await image_generation(\n        prompt=\"your prompt here\",\n        image_width=512,  # 可选，默认512\n        image_height=512, # 可选，默认512\n        seed=3           # 可选，默认3\n    )\n    print(img_url)\n```\n\n## API参数说明\n\n- `prompt` (str): 图像生成提示词\n- `image_width` (int, optional): 生成图片宽度，默认512\n- `image_height` (int, optional): 生成图片高度，默认512\n- `seed` (int, optional): 随机种子，默认3\n\n## 示例\n\n### 春天的生机\n\n![春天的生机](https://black-forest-labs-flux-1-schnell.hf.space/file=/tmp/gradio/45d6489d73142fa77851d8985bb1010572433d6a/image.webp)\n\n> 春天来了，大地苏醒，万物复苏。花儿竞相开放，嫩绿的叶子在微风中轻轻摇曳。空气中弥漫着泥土的芬芳和花儿的香气。小鸟在枝头欢快地歌唱，蝴蝶在花丛中翩翩起舞。阳光洒在大地上，温暖而明亮。春天的生机勃勃，让人心旷神怡。\n\n这个示例展示了使用服务生成的图片效果。您可以在demo目录中找到完整的网页展示代码。\n\n生成的图片URL可以直接用于：\n1. 网页图片展示\n2. 社交媒体分享\n3. 应用程序界面\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcp",
        "images",
        "image",
        "generating images",
        "provides mcp",
        "video generation"
      ],
      "category": "image-and-video-generation"
    },
    "madhusudan-kulkarni--mcp-fal-ai-image": {
      "owner": "madhusudan-kulkarni",
      "name": "mcp-fal-ai-image",
      "url": "https://github.com/madhusudan-kulkarni/mcp-fal-ai-image",
      "imageUrl": "/freedevtools/mcp/pfp/madhusudan-kulkarni.webp",
      "description": "Generate images from text prompts using various fal.ai models through the Model Context Protocol (MCP), enabling seamless integration with AI IDEs. Save generated images locally with customizable output paths and robust error handling.",
      "stars": 2,
      "forks": 1,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-07-25T04:25:20Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/madhusudan-kulkarni-mcp-fal-ai-image-badge.png)](https://mseep.ai/app/madhusudan-kulkarni-mcp-fal-ai-image)\n\n[![npm version](https://img.shields.io/npm/v/mcp-fal-ai-image.svg)](https://www.npmjs.com/package/mcp-fal-ai-image) [![Node.js Version](https://img.shields.io/node/v/mcp-fal-ai-image)](https://nodejs.org/) [![TypeScript](https://img.shields.io/badge/TypeScript-5.8-blue.svg)](https://www.typescriptlang.org/) [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)\n\n# MCP fal.ai Image Server\n\nEffortlessly generate images from text prompts using [fal.ai](https://fal.ai) and the Model Context Protocol (MCP). Integrates directly with AI IDEs like Cursor and Windsurf.\n\n## When and Why to Use\n\nThis tool is designed for:\n- Developers and designers who want to generate images from text prompts without leaving their IDE.\n- Rapid prototyping of UI concepts, marketing assets, or creative ideas.\n- Content creators needing unique visuals for blogs, presentations, or social media.\n- AI researchers and tinkerers experimenting with the latest fal.ai models.\n- Automating workflows that require programmatic image generation via MCP.\n\nKey features:\n- Supports any valid fal.ai model and all major image parameters.\n- Works out of the box with Node.js and a fal.ai API key.\n- Saves images locally with accessible file paths.\n- Simple configuration and robust error handling.\n\n## Quick Start\n\n1. **Requirements:** Node.js 18+, [fal.ai API key](https://fal.ai)\n2. **Configure MCP:**\n   ```json\n   {\n     \"mcpServers\": {\n       \"fal-ai-image\": {\n         \"command\": \"npx\",\n         \"args\": [\"-y\", \"mcp-fal-ai-image\"],\n         \"env\": { \"FAL_KEY\": \"YOUR-FAL-AI-API-KEY\" }\n       }\n     }\n   }\n   ```\n3. **Run:** Use the `generate-image` tool from your IDE.\n\n> **💡 Typical Workflow:**\n> Describe the image you want (e.g., “generate a landscape with flying cars using model fal-ai/kolors, 2 images, landscape_16_9”) and get instant results in your IDE.\n\n### 🗨️ Example Prompts\n\n- `generate an image of a red apple`\n- `generate an image of a red apple using model fal-ai/kolors`\n- `generate 3 images of a glowing red apple in a futuristic city using model fal-ai/recraft-v3, square_hd, 40 inference steps, guidance scale 4.0, safety checker on`\n\n**Supported parameters:** prompt, model ID (any fal.ai model), number of images, image size, inference steps, guidance scale, safety checker.\n\nImages are saved locally; file paths are shown in the response. For model IDs, see [fal.ai/models](https://fal.ai/models).\n\n## Troubleshooting\n\n- `FAL_KEY environment variable is not set`: Set your fal.ai API key as above.\n- `npx` not found: Install Node.js 18+ and npm.\n\n<details>\n<summary>Advanced: Example MCP Request/Response</summary>\n\n```json\n{\n  \"tool\": \"generate-image\",\n  \"args\": {\n    \"prompt\": \"A futuristic cityscape at sunset\",\n    \"model\": \"fal-ai/kolors\"\n  }\n}\n\n// Example response\n{\n  \"images\": [\n    { \"url\": \"file:///path/to/generated_image1.png\" },\n    { \"url\": \"file:///path/to/generated_image2.png\" }\n  ]\n}\n```\n\n</details>\n\n## 📁 Image Output Directory\n\nGenerated images are saved to your local system:\n\n- **By default:** `~/Downloads/fal_ai` (on Linux/macOS; uses XDG standard if available)\n- **Custom location:** Set the environment variable `FAL_IMAGES_OUTPUT_DIR` to your desired folder. Images will be saved in `<your-folder>/fal_ai`.\n\nThe full file path for each image is included in the tool's response.\n\n## ⚠️ Error Handling & Troubleshooting\n\n- If you specify a model ID that is not supported by fal.ai, you will receive an error from the backend. Double-check for typos or visit [fal.ai/models](https://fal.ai/models) to confirm the model ID.\n- For the latest list of models and their capabilities, refer to the [fal.ai model catalog](https://fal.ai/models) or [API docs](https://fal.ai/docs/api).\n- For other errors, consult your MCP client logs or open an issue on GitHub.\n\n## 🤝 Contributing\n\nContributions and suggestions are welcome! Please open issues or pull requests on [GitHub](https://github.com/madhusudan-kulkarni/mcp-fal-ai-image).\n\n## 🔒 Security\n\n- Your API key is only used locally to authenticate with fal.ai.\n- No user data is stored or transmitted except as required by fal.ai API.\n\n## 🔗 Links\n\n- [NPM](https://www.npmjs.com/package/mcp-fal-ai-image)\n- [GitHub](https://github.com/madhusudan-kulkarni/mcp-fal-ai-image)\n- [fal.ai](https://fal.ai)\n\n## 🛡 License\n\nMIT License © 2025 Madhusudan Kulkarni\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "images",
        "image",
        "ai",
        "image generate",
        "generate images",
        "generated images"
      ],
      "category": "image-and-video-generation"
    },
    "manascb1344--together-mcp-server": {
      "owner": "manascb1344",
      "name": "together-mcp-server",
      "url": "https://github.com/manascb1344/together-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/manascb1344.webp",
      "description": "Generate high-quality images using the Flux.1 Schnell model by specifying customizable parameters such as width and height, while ensuring clear error handling for prompt validation and API interactions.",
      "stars": 9,
      "forks": 5,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-07-30T19:28:08Z",
      "readme_content": "# Image Generation MCP Server\n\nA Model Context Protocol (MCP) server that enables seamless generation of high-quality images using the Flux.1 Schnell model via Together AI. This server provides a standardized interface to specify image generation parameters.\n<div align=\"center\">\n  \n[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/manascb1344/together-mcp-server)\n\n</div>\n\n<div align=\"center\">\n\n<a href=\"https://glama.ai/mcp/servers/y6qfizhsja\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/y6qfizhsja/badge\" alt=\"Image Generation Server MCP server\" />\n</a>\n</div>\n\n## Features\n\n- High-quality image generation powered by the Flux.1 Schnell model\n- Support for customizable dimensions (width and height)\n- Clear error handling for prompt validation and API issues\n- Easy integration with MCP-compatible clients\n- Optional image saving to disk in PNG format\n\n## Installation\n\n```bash\nnpm install together-mcp\n```\n\nOr run directly:\n\n```bash\nnpx together-mcp@latest\n```\n\n### Configuration\n\nAdd to your MCP server configuration:\n\n<summary>Configuration Example</summary>\n\n```json\n{\n  \"mcpServers\": {\n    \"together-image-gen\": {\n      \"command\": \"npx\",\n      \"args\": [\"together-mcp@latest -y\"],\n      \"env\": {\n        \"TOGETHER_API_KEY\": \"<API KEY>\"\n      }\n    }\n  }\n}\n```\n\n## Usage\n\nThe server provides one tool: `generate_image`\n\n### Using generate_image\n\nThis tool has only one required parameter - the prompt. All other parameters are optional and use sensible defaults if not provided.\n\n#### Parameters\n\n```typescript\n{\n  // Required\n  prompt: string;          // Text description of the image to generate\n\n  // Optional with defaults\n  model?: string;          // Default: \"black-forest-labs/FLUX.1-schnell-Free\"\n  width?: number;          // Default: 1024 (min: 128, max: 2048)\n  height?: number;         // Default: 768 (min: 128, max: 2048)\n  steps?: number;          // Default: 1 (min: 1, max: 100)\n  n?: number;             // Default: 1 (max: 4)\n  response_format?: string; // Default: \"b64_json\" (options: [\"b64_json\", \"url\"])\n  image_path?: string;     // Optional: Path to save the generated image as PNG\n}\n```\n\n#### Minimal Request Example\n\nOnly the prompt is required:\n\n```json\n{\n  \"name\": \"generate_image\",\n  \"arguments\": {\n    \"prompt\": \"A serene mountain landscape at sunset\"\n  }\n}\n```\n\n#### Full Request Example with Image Saving\n\nOverride any defaults and specify a path to save the image:\n\n```json\n{\n  \"name\": \"generate_image\",\n  \"arguments\": {\n    \"prompt\": \"A serene mountain landscape at sunset\",\n    \"width\": 1024,\n    \"height\": 768,\n    \"steps\": 20,\n    \"n\": 1,\n    \"response_format\": \"b64_json\",\n    \"model\": \"black-forest-labs/FLUX.1-schnell-Free\",\n    \"image_path\": \"/path/to/save/image.png\"\n  }\n}\n```\n\n#### Response Format\n\nThe response will be a JSON object containing:\n\n```json\n{\n  \"id\": string,        // Generation ID\n  \"model\": string,     // Model used\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"timings\": {\n        \"inference\": number  // Time taken for inference\n      },\n      \"index\": number,      // Image index\n      \"b64_json\": string    // Base64 encoded image data (if response_format is \"b64_json\")\n      // OR\n      \"url\": string        // URL to generated image (if response_format is \"url\")\n    }\n  ]\n}\n```\n\nIf image_path was provided and the save was successful, the response will include confirmation of the save location.\n\n### Default Values\n\nIf not specified in the request, these defaults are used:\n\n- model: \"black-forest-labs/FLUX.1-schnell-Free\"\n- width: 1024\n- height: 768\n- steps: 1\n- n: 1\n- response_format: \"b64_json\"\n\n### Important Notes\n\n1. Only the `prompt` parameter is required\n2. All optional parameters use defaults if not provided\n3. When provided, parameters must meet their constraints (e.g., width/height ranges)\n4. Base64 responses can be large - use URL format for larger images\n5. When saving images, ensure the specified directory exists and is writable\n\n## Prerequisites\n\n- Node.js >= 16\n- Together AI API key\n  1. Sign in at [api.together.xyz](https://api.together.xyz/)\n  2. Navigate to [API Keys settings](https://api.together.xyz/settings/api-keys)\n  3. Click \"Create\" to generate a new API key\n  4. Copy the generated key for use in your MCP configuration\n\n## Dependencies\n\n```json\n{\n  \"@modelcontextprotocol/sdk\": \"0.6.0\",\n  \"axios\": \"^1.6.7\"\n}\n```\n\n## Development\n\nClone and build the project:\n\n```bash\ngit clone https://github.com/manascb1344/together-mcp-server\ncd together-mcp-server\nnpm install\nnpm run build\n```\n\n### Available Scripts\n\n- `npm run build` - Build the TypeScript project\n- `npm run watch` - Watch for changes and rebuild\n- `npm run inspector` - Run MCP inspector\n\n## Contributing\n\nContributions are welcome! Please follow these steps:\n\n1. Fork the repository\n2. Create a new branch (`feature/my-new-feature`)\n3. Commit your changes\n4. Push the branch to your fork\n5. Open a Pull Request\n\nFeature requests and bug reports can be submitted via GitHub Issues. Please check existing issues before creating a new one.\n\nFor significant changes, please open an issue first to discuss your proposed changes.\n\n## License\n\nThis project is licensed under the MIT License. See the LICENSE file for details.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcp",
        "images",
        "flux",
        "video generation",
        "quality images",
        "manascb1344 mcp"
      ],
      "category": "image-and-video-generation"
    },
    "maoxiaoke--mcp-media-processor": {
      "owner": "maoxiaoke",
      "name": "mcp-media-processor",
      "url": "https://github.com/maoxiaoke/mcp-media-processor",
      "imageUrl": "/freedevtools/mcp/pfp/maoxiaoke.webp",
      "description": "A Node.js server for executing various media processing tasks, including video and image manipulation. It supports operations like video conversion, image effects, and media compression.",
      "stars": 24,
      "forks": 5,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-09-16T09:41:08Z",
      "readme_content": "# MCP Media Processing Server\n\n[![smithery badge](https://smithery.ai/badge/@maoxiaoke/mcp-media-processor)](https://smithery.ai/server/@maoxiaoke/mcp-media-processor)\n\nA Node.js server implementing Model Context Protocol (MCP) for media processing operations, providing powerful video and image manipulation capabilities.\n\n## Features\n\n* Video processing and conversion\n* Image processing and manipulation\n* Media compression\n* Video trimming and editing\n* Image effects and watermarking\n\n## Prerequisites\n\nBefore using this server, make sure you have the following dependencies installed on your system:\n\n* **FFmpeg**: Required for video processing operations\n  * macOS: `brew install ffmpeg`\n  * Ubuntu/Debian: `sudo apt-get install ffmpeg`\n  * Windows: Download from [FFmpeg official website](https://ffmpeg.org/download.html)\n\n* **ImageMagick**: Required for image processing operations\n  * macOS: `brew install imagemagick`\n  * Ubuntu/Debian: `sudo apt-get install imagemagick`\n  * Windows: Download from [ImageMagick official website](https://imagemagick.org/script/download.php)\n\n## How to use\n\nAdd this to your `claude_desktop_config.json`:\n\n### NPX\n\n```json\n{\n  \"mcpServers\": {\n    \"mediaProcessor\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"mcp-media-processor@latest\"\n      ]\n    }\n  }\n}\n```\n\n## API\n\n### Tools\n\n#### Video Operations\n\n* **execute-ffmpeg**\n  * Execute any FFmpeg command with custom options\n  * Inputs:\n    * `inputPath` (string): Absolute path to input video file\n    * `options` (string[]): Array of FFmpeg command options\n    * `outputPath` (string, optional): Absolute path for output file\n    * `outputFilename` (string, optional): Output filename\n\n* **convert-video**\n  * Convert video to different format\n  * Inputs:\n    * `inputPath` (string): Absolute path to input video file\n    * `outputFormat` (string): Desired output format (e.g., mp4, mkv, avi)\n    * `outputPath` (string, optional): Custom output path\n    * `outputFilename` (string, optional): Custom output filename\n\n* **compress-video**\n  * Compress video file\n  * Inputs:\n    * `inputPath` (string): Absolute path to input video file\n    * `quality` (number, optional): Compression quality (1-51, lower is better quality)\n    * `outputPath` (string, optional): Custom output path\n    * `outputFilename` (string, optional): Custom output filename\n\n* **trim-video**\n  * Trim video to specified duration\n  * Inputs:\n    * `inputPath` (string): Absolute path to input video file\n    * `startTime` (string): Start time in format HH:MM:SS\n    * `duration` (string): Duration in format HH:MM:SS\n    * `outputPath` (string, optional): Custom output path\n    * `outputFilename` (string, optional): Custom output filename\n\n#### Image Operations\n\n* **compress-image**\n  * Compress PNG image using ImageMagick\n  * Inputs:\n    * `inputPath` (string): Absolute path to input PNG image\n    * `quality` (number, optional): Compression quality (1-100)\n    * `outputPath` (string, optional): Custom output path\n    * `outputFilename` (string, optional): Custom output filename\n\n* **convert-image**\n  * Convert image to different format\n  * Inputs:\n    * `inputPath` (string): Absolute path to input image file\n    * `outputFormat` (string): Desired output format (e.g., jpg, png, webp, gif)\n    * `outputPath` (string, optional): Custom output path\n    * `outputFilename` (string, optional): Custom output filename\n\n* **resize-image**\n  * Resize image to specified dimensions\n  * Inputs:\n    * `inputPath` (string): Absolute path to input image file\n    * `width` (number, optional): Target width in pixels\n    * `height` (number, optional): Target height in pixels\n    * `maintainAspectRatio` (boolean, optional): Whether to maintain aspect ratio\n    * `outputPath` (string, optional): Custom output path\n    * `outputFilename` (string, optional): Custom output filename\n\n* **rotate-image**\n  * Rotate image by specified degrees\n  * Inputs:\n    * `inputPath` (string): Absolute path to input image file\n    * `degrees` (number): Rotation angle in degrees\n    * `outputPath` (string, optional): Custom output path\n    * `outputFilename` (string, optional): Custom output filename\n\n* **add-watermark**\n  * Add watermark to image\n  * Inputs:\n    * `inputPath` (string): Absolute path to input image file\n    * `watermarkPath` (string): Absolute path to watermark image file\n    * `position` (string, optional): Position of watermark (default: \"southeast\")\n    * `opacity` (number, optional): Watermark opacity (0-100)\n    * `outputPath` (string, optional): Custom output path\n    * `outputFilename` (string, optional): Custom output filename\n\n* **apply-effect**\n  * Apply visual effect to image\n  * Inputs:\n    * `inputPath` (string): Absolute path to input image file\n    * `effect` (string): Effect to apply (blur, sharpen, edge, emboss, grayscale, sepia, negate)\n    * `intensity` (number, optional): Effect intensity (0-100)\n    * `outputPath` (string, optional): Custom output path\n    * `outputFilename` (string, optional): Custom output filename\n\n\n## License\n\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "processor",
        "node",
        "mcp",
        "media processor",
        "media processing",
        "mcp media"
      ],
      "category": "image-and-video-generation"
    },
    "mario-andreschak--mcp-image-recognition": {
      "owner": "mario-andreschak",
      "name": "mcp-image-recognition",
      "url": "https://github.com/mario-andreschak/mcp-image-recognition",
      "imageUrl": "/freedevtools/mcp/pfp/mario-andreschak.webp",
      "description": "Leverages image recognition capabilities to analyze and describe images using advanced vision APIs. Supports multiple formats and allows for optional text extraction from images.",
      "stars": 26,
      "forks": 8,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-03T22:32:16Z",
      "readme_content": "# MCP Image Recognition Server\n\nAn MCP server that provides image recognition capabilities using Anthropic and OpenAI vision APIs. Version 0.1.2.\n\n## Features\n\n- Image description using Anthropic Claude Vision or OpenAI GPT-4 Vision\n- Support for multiple image formats (JPEG, PNG, GIF, WebP)\n- Configurable primary and fallback providers\n- Base64 and file-based image input support\n- Optional text extraction using Tesseract OCR\n\n## Requirements\n\n- Python 3.8 or higher\n- Tesseract OCR (optional) - Required for text extraction feature\n  - Windows: Download and install from [UB-Mannheim/tesseract](https://github.com/UB-Mannheim/tesseract/wiki)\n  - Linux: `sudo apt-get install tesseract-ocr`\n  - macOS: `brew install tesseract`\n\n## Installation\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/mario-andreschak/mcp-image-recognition.git\ncd mcp-image-recognition\n```\n\n2. Create and configure your environment file:\n```bash\ncp .env.example .env\n# Edit .env with your API keys and preferences\n```\n\n3. Build the project:\n```bash\nbuild.bat\n```\n\n## Usage\n\n### Running the Server\nSpawn the server using python:\n```bash\npython -m image_recognition_server.server\n```\n\nStart the server using batch instead:\n```bash\nrun.bat server\n```\n\nStart the server in development mode with the MCP Inspector:\n```bash\nrun.bat debug\n```\n\n### Available Tools\n\n1. `describe_image`\n   - Input: Base64-encoded image data and MIME type\n   - Output: Detailed description of the image\n\n2. `describe_image_from_file`\n   - Input: Path to an image file\n   - Output: Detailed description of the image\n\n### Environment Configuration\n\n- `ANTHROPIC_API_KEY`: Your Anthropic API key.\n- `OPENAI_API_KEY`: Your OpenAI API key.\n- `VISION_PROVIDER`: Primary vision provider (`anthropic` or `openai`).\n- `FALLBACK_PROVIDER`: Optional fallback provider.\n- `LOG_LEVEL`: Logging level (DEBUG, INFO, WARNING, ERROR).\n- `ENABLE_OCR`: Enable Tesseract OCR text extraction (`true` or `false`).\n- `TESSERACT_CMD`: Optional custom path to Tesseract executable.\n- `OPENAI_MODEL`: OpenAI Model (default: `gpt-4o-mini`). Can use OpenRouter format for other models (e.g., `anthropic/claude-3.5-sonnet:beta`).\n- `OPENAI_BASE_URL`: Optional custom base URL for the OpenAI API.  Set to `https://openrouter.ai/api/v1` for OpenRouter.\n- `OPENAI_TIMEOUT`: Optional custom timeout (in seconds) for the OpenAI API.\n\n### Using OpenRouter\n\nOpenRouter allows you to access various models using the OpenAI API format. To use OpenRouter, follow these steps:\n\n1.  Obtain an OpenAI API key from OpenRouter.\n2.  Set `OPENAI_API_KEY` in your `.env` file to your OpenRouter API key.\n3.  Set `OPENAI_BASE_URL` to `https://openrouter.ai/api/v1`.\n4.  Set `OPENAI_MODEL` to the desired model using the OpenRouter format (e.g., `anthropic/claude-3.5-sonnet:beta`).\n5. Set `VISION_PROVIDER` to `openai`.\n\n### Default Models\n\n- Anthropic: `claude-3.5-sonnet-beta`\n- OpenAI: `gpt-4o-mini`\n- OpenRouter: Use the `anthropic/claude-3.5-sonnet:beta` format in `OPENAI_MODEL`.\n\n## Development\n\n### Running Tests\n\nRun all tests:\n```bash\nrun.bat test\n```\n\nRun specific test suite:\n```bash\nrun.bat test server\nrun.bat test anthropic\nrun.bat test openai\n```\n\n### Docker Support\n\nBuild the Docker image:\n```bash\ndocker build -t mcp-image-recognition .\n```\n\nRun the container:\n```bash\ndocker run -it --env-file .env mcp-image-recognition\n```\n\n## License\n\nMIT License - see LICENSE file for details.\n\n## Release History\n\n- **0.1.2** (2025-02-20): Improved OCR error handling and added comprehensive test coverage for OCR functionality\n- **0.1.1** (2025-02-19): Added Tesseract OCR support for text extraction from images (optional feature)\n- **0.1.0** (2025-02-19): Initial release with Anthropic and OpenAI vision support\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "recognition",
        "images",
        "vision",
        "extraction images",
        "image recognition",
        "analyze images"
      ],
      "category": "image-and-video-generation"
    },
    "mario-andreschak--mcp-veo2": {
      "owner": "mario-andreschak",
      "name": "mcp-veo2",
      "url": "https://github.com/mario-andreschak/mcp-veo2",
      "imageUrl": "/freedevtools/mcp/pfp/mario-andreschak.webp",
      "description": "Generates high-quality videos from text prompts or images using Google's Veo2 model and provides access to these generated videos through MCP resources.",
      "stars": 30,
      "forks": 17,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T22:32:31Z",
      "readme_content": "# MCP Video Generation with Veo2\n\n[![smithery badge](https://smithery.ai/badge/@mario-andreschak/mcp-video-generation-veo2)](https://smithery.ai/server/@mario-andreschak/mcp-video-generation-veo2)\n\nThis project implements a Model Context Protocol (MCP) server that exposes Google's Veo2 video generation capabilities. It allows clients to generate videos from text prompts or images, and access the generated videos through MCP resources.\n\n<a href=\"https://glama.ai/mcp/servers/@mario-andreschak/mcp-veo2\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@mario-andreschak/mcp-veo2/badge\" alt=\"Video Generation with Veo2 MCP server\" />\n</a>\n\n## Features\n\n- Generate **videos from text** prompts\n- Generate **videos from images**\n- Access generated videos through MCP resources\n- Example video generation templates\n- Support for both stdio and SSE transports\n\n## Example Images\n![1dec9c71-07dc-4a6e-9e17-8da355d72ba1](https://github.com/user-attachments/assets/ba987d14-dd46-49ac-9b31-1ce398e86c6f)\n\n\n## Example Image to Video\n[Image to Video - from Grok generated puppy](https://github.com/mario-andreschak/mcp-veo2/raw/refs/heads/main/example-files/2a6a0807-d323-4424-a48a-e40a82b883bb.mp4)\n\n[Image to Video - from real cat](https://github.com/mario-andreschak/mcp-veo2/raw/refs/heads/main/example-files/55b9f28b-61a6-423e-bb86-f3791c639177.mp4)\n\n\n## Prerequisites\n\n- Node.js 18 or higher\n- Google API key with access to Gemini API and Veo2 model (= You need to set up a credit card with your API key! -> Go to aistudio.google.com )\n\n## Installation\n\n### Installing in [FLUJO](https://github.com/mario-andreschak/FLUJO/)\n1. Click Add Server\n2. Copy & Paste Github URL into FLUJO\n3. Click Parse, Clone, Install, Build and Save.\n\n### Installing via Smithery\n\nTo install mcp-video-generation-veo2 for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@mario-andreschak/mcp-veo2):\n\n```bash\nnpx -y @smithery/cli install @mario-andreschak/mcp-veo2 --client claude\n```\n\n### Manual Installation\n1. Clone the repository:\n   ```bash\n   git clone https://github.com/yourusername/mcp-video-generation-veo2.git\n   cd mcp-video-generation-veo2\n   ```\n\n2. Install dependencies:\n   ```bash\n   npm install\n   ```\n\n3. Create a `.env` file with your Google API key:\n   ```bash\n   cp .env.example .env\n   # Edit .env and add your Google API key\n   ```\n\n   The `.env` file supports the following variables:\n   - `GOOGLE_API_KEY`: Your Google API key (required)\n   - `PORT`: Server port (default: 3000)\n   - `STORAGE_DIR`: Directory for storing generated videos (default: ./generated-videos)\n   - `LOG_LEVEL`: Logging level (default: fatal)\n     - Available levels: verbose, debug, info, warn, error, fatal, none\n     - For development, set to `debug` or `info` for more detailed logs\n     - For production, keep as `fatal` to minimize console output\n\n4. Build the project:\n   ```bash\n   npm run build\n   ```\n\n## Usage\n\n### Starting the Server\n\nYou can start the server with either stdio or SSE transport:\n\n#### stdio Transport (Default)\n\n```bash\nnpm start\n# or\nnpm start stdio\n```\n\n#### SSE Transport\n\n```bash\nnpm start sse\n```\n\nThis will start the server on port 3000 (or the port specified in your `.env` file).\n\n### MCP Tools\n\nThe server exposes the following MCP tools:\n\n#### generateVideoFromText\n\nGenerates a video from a text prompt.\n\nParameters:\n- `prompt` (string): The text prompt for video generation\n- `config` (object, optional): Configuration options\n  - `aspectRatio` (string, optional): \"16:9\" or \"9:16\"\n  - `personGeneration` (string, optional): \"dont_allow\" or \"allow_adult\"\n  - `numberOfVideos` (number, optional): 1 or 2\n  - `durationSeconds` (number, optional): Between 5 and 8\n  - `enhancePrompt` (boolean, optional): Whether to enhance the prompt\n  - `negativePrompt` (string, optional): Text describing what not to generate\n\nExample:\n```json\n{\n  \"prompt\": \"Panning wide shot of a serene forest with sunlight filtering through the trees, cinematic quality\",\n  \"config\": {\n    \"aspectRatio\": \"16:9\",\n    \"personGeneration\": \"dont_allow\",\n    \"durationSeconds\": 8\n  }\n}\n```\n\n#### generateVideoFromImage\n\nGenerates a video from an image.\n\nParameters:\n- `image` (string): Base64-encoded image data\n- `prompt` (string, optional): Text prompt to guide the video generation\n- `config` (object, optional): Configuration options (same as above, but personGeneration only supports \"dont_allow\")\n\n#### listGeneratedVideos\n\nLists all generated videos.\n\n### MCP Resources\n\nThe server exposes the following MCP resources:\n\n#### videos://{id}\n\nAccess a generated video by its ID.\n\n#### videos://templates\n\nAccess example video generation templates.\n\n## Development\n\n### Project Structure\n\n- `src/`: Source code\n  - `index.ts`: Main entry point\n  - `server.ts`: MCP server configuration\n  - `config.ts`: Configuration handling\n  - `tools/`: MCP tool implementations\n  - `resources/`: MCP resource implementations\n  - `services/`: External service integrations\n  - `utils/`: Utility functions\n\n### Building\n\n```bash\nnpm run build\n```\n\n### Development Mode\n\n```bash\nnpm run dev\n```\n\n## License\n\nMIT",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "veo2",
        "videos",
        "mcp",
        "mcp veo2",
        "google veo2",
        "generated videos"
      ],
      "category": "image-and-video-generation"
    },
    "mikeyny--ai-image-gen-mcp": {
      "owner": "mikeyny",
      "name": "ai-image-gen-mcp",
      "url": "https://github.com/mikeyny/ai-image-gen-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/mikeyny.webp",
      "description": "Generate images from text prompts using Replicate's flux-schnell model, with configurable image parameters and the ability to save generated images to a specified directory.",
      "stars": 126,
      "forks": 15,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-09-11T02:43:44Z",
      "readme_content": "# Image Generation MCP Server\n\nAn [MCP (Model Context Protocol)](https://modelcontextprotocol.io/) server implementation for generating images using Replicate's [`black-forest-labs/flux-schnell`](https://replicate.com/black-forest-labs/flux-schnell) model.\n\nIdeally to be used with Cursor's MCP feature, but can be used with any MCP client.\n\n## Features\n\n- Generate images from text prompts\n- Configurable image parameters (resolution, aspect ratio, quality)\n- Save generated images to specified directory\n- Full MCP protocol compliance\n- Error handling and validation\n\n## Prerequisites\n\n- Node.js 16+\n- Replicate API token\n- TypeScript SDK for MCP\n\n## Setup\n\n1. Clone the repository\n2. Install dependencies:\n   ```bash\n   npm install\n   ```\n3. Add your Replicate API token directly in the code at `src/imageService.ts` by updating the `apiToken` constant:\n   ```bash\n   // No environment variables are used since they can't be easily set in cursor\n   const apiToken = \"your-replicate-api-token-here\";\n   ```\n\n   > **Note:** If using with Claude, you can create a `.env` file in the root directory and set your API token there:\n   ```bash\n   REPLICATE_API_TOKEN=your-replicate-api-token-here\n   ```\n\n   Then build the project:\n   ```bash\n   npm run build\n   ```\n\n## Usage\n\nTo use with cursor:\n1. Go to Settings\n2. Select Features\n3. Scroll down to \"MCP Servers\"\n4. Click \"Add new MCP Server\"\n5. Set Type to \"Command\"\n6. Set Command to: `node ./path/to/dist/server.js`\n\n## API Parameters\n\n| Parameter           | Type    | Required | Default | Description                                     |\n|--------------------|---------|----------|---------|------------------------------------------------|\n| `prompt`           | string  | Yes      | -       | Text prompt for image generation               |\n| `output_dir`       | string  | Yes      | -       | Server directory path to save generated images |\n| `go_fast`          | boolean | No       | false   | Enable faster generation mode                  |\n| `megapixels`       | string  | No       | \"1\"     | Resolution quality (\"1\", \"2\", \"4\")            |\n| `num_outputs`      | number  | No       | 1       | Number of images to generate (1-4)            |\n| `aspect_ratio`     | string  | No       | \"1:1\"   | Aspect ratio (\"1:1\", \"4:3\", \"16:9\")          |\n| `output_format`    | string  | No       | \"webp\"  | Image format (\"webp\", \"png\", \"jpeg\")         |\n| `output_quality`   | number  | No       | 80      | Compression quality (1-100)                   |\n| `num_inference_steps`| number| No       | 4       | Number of denoising steps (4-20)             |\n\n## Example Request\n\n```json\n{\n  \"prompt\": \"black forest gateau cake spelling out 'FLUX SCHNELL'\",\n  \"output_dir\": \"/var/output/images\",\n  \"filename\": \"black_forest_cake\",\n  \"output_format\": \"webp\"\n  \"go_fast\": true,\n  \"megapixels\": \"1\",\n  \"num_outputs\": 2,\n  \"aspect_ratio\": \"1:1\"\n}\n```\n\n## Example Response\n\n```json\n{\n  \"image_paths\": [\n    \"/var/output/images/output_0.webp\",\n    \"/var/output/images/output_1.webp\"\n  ],\n  \"metadata\": {\n    \"model\": \"black-forest-labs/flux-schnell\",\n    \"inference_time_ms\": 2847\n  }\n}\n```\n\n## Error Handling\n\nThe server handles the following error types:\n\n- Validation errors (invalid parameters)\n- API errors (Replicate API issues)\n- Server errors (filesystem, permissions)\n- Unknown errors (unexpected issues)\n\nEach error response includes:\n- Error code\n- Human-readable message\n- Detailed error information\n\n## License\n\nISC ",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "generate",
        "images",
        "mcp",
        "generate images",
        "generated images",
        "image gen"
      ],
      "category": "image-and-video-generation"
    },
    "murataskin--image-mcp-server-gemini": {
      "owner": "murataskin",
      "name": "image-mcp-server-gemini",
      "url": "https://github.com/murataskin/image-mcp-server-gemini",
      "imageUrl": "/freedevtools/mcp/pfp/murataskin.webp",
      "description": "Analyzes images and videos by providing URLs or local file paths, allowing for detailed insights and descriptions of the content. Uses the Gemini 2.0 Flash model for high-precision recognition and can evaluate relationships between multiple visual inputs.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-04-10T03:32:38Z",
      "readme_content": "\n# image-mcp-server-gemini\n\n\n\n\n[![smithery badge](https://smithery.ai/badge/@Rentapad/image-mcp-server-gemini)](https://smithery.ai/server/@Rentapad/image-mcp-server-gemini)\nAn MCP server that receives image/video URLs or local file paths and analyzes their content using the Gemini 2.0 Flash model.(forked from github.com/champierre/image-mcp-server)\n\n## Features\n\n- Analyzes content from one or more image/video URLs or local file paths.\n- Analyzes videos directly from YouTube URLs.\n- Can analyze relationships between multiple images or videos provided together.\n- Supports optional text prompts to guide the analysis.\n- High-precision recognition and description using the Gemini 2.0 Flash model.\n- URL validity checking and local file loading with Base64 encoding.\n- Basic security checks for local file paths.\n- Handles various image and video MIME types (see Usage section for details).\n\n## Installation\n\n### Installing via Smithery\n\nTo install Image Analysis Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@Rentapad/image-mcp-server-gemini):\n\n```bash\nnpx -y @smithery/cli install @Rentapad/image-mcp-server --client claude\n```\n\n### Manual Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/Rentapad/image-mcp-server-gemini.git \ncd image-mcp-server-gemini\n\n# Install dependencies\nnpm install\n\n# Compile TypeScript\nnpm run build\n```\n\n## Configuration\n\nTo use this server, you need a Gemini API key. Set the following environment variable:\n\n```\nGEMINI_API_KEY=your_gemini_api_key\n```\n\n## MCP Server Configuration\n\nTo use with tools like Cline, add the following settings to your MCP server configuration file:\n\n### For Cline\n\nAdd the following to `cline_mcp_settings.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"image-video-analysis\": { // Consider renaming for clarity\n      \"command\": \"node\",\n      \"args\": [\"/path/to/image-mcp-server/dist/index.js\"],\n      \"env\": {\n        \"GEMINI_API_KEY\": \"your_gemini_api_key\"\n      }\n    }\n  }\n}\n```\n\n### For Claude Desktop App\n\nAdd the following to `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"image-video-analysis\": { // Consider renaming for clarity\n      \"command\": \"node\",\n      \"args\": [\"/path/to/image-mcp-server/dist/index.js\"],\n      \"env\": {\n        \"GEMINI_API_KEY\": \"your_gemini_api_key\"\n      }\n    }\n  }\n}\n```\n\n## Usage\n\nOnce the MCP server is configured, the following tools become available:\n\n- `analyze_image`: Receives one or more image URLs and analyzes their content.\n  - Arguments: `imageUrls` (array of strings, required), `prompt` (string, optional).\n- `analyze_image_from_path`: Receives one or more local image file paths and analyzes their content.\n  - Arguments: `imagePaths` (array of strings, required), `prompt` (string, optional).\n- `analyze_video`: Receives one or more video URLs and analyzes their content. Best for smaller videos (see Video Notes).\n  - Arguments: `videoUrls` (array of strings, required), `prompt` (string, optional).\n- `analyze_video_from_path`: Receives one or more local video file paths and analyzes their content. Best for smaller videos (see Video Notes).\n  - Arguments: `videoPaths` (array of strings, required), `prompt` (string, optional).\n- `analyze_youtube_video`: Receives a single YouTube video URL and analyzes its content.\n  - Arguments: `youtubeUrl` (string, required), `prompt` (string, optional).\n\n### Usage Examples\n\n**Analyzing a single image from URL:**\n```\nPlease analyze this image: https://example.com/image.jpg\n```\n\n**Analyzing multiple images from local paths and comparing them:**\n```\nAnalyze these images: /path/to/your/image1.png, /path/to/your/image2.jpeg. Which one contains a cat?\n```\n*(The client would call `analyze_image_from_path` with `imagePaths: [\"/path/to/your/image1.png\", \"/path/to/your/image2.jpeg\"]` and `prompt: \"Which one contains a cat?\"`)*\n\n**Analyzing a video from URL with a specific prompt:**\n```\nSummarize the content of this video: https://example.com/video.mp4\n```\n*(The client would call `analyze_video` with `videoUrls: [\"https://example.com/video.mp4\"]` and `prompt: \"Summarize the content of this video\"`)*\n\n**Analyzing a YouTube video:**\n```\nWhat is the main topic of this YouTube video? https://www.youtube.com/watch?v=dQw4w9WgXcQ\n```\n*(The client would call `analyze_youtube_video` with `youtubeUrl: \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\"` and `prompt: \"What is the main topic of this YouTube video?\"`)*\n\n### Video Notes\n\n- **Size Limit:** For videos provided via URL (`analyze_video`) or path (`analyze_video_from_path`), Gemini currently has limitations on the size of video data that can be processed directly (typically around 20MB after Base64 encoding). Larger videos may fail. YouTube analysis does not have this same client-side download limit.\n- **Supported MIME Types:** The server attempts to map and use MIME types supported by Gemini for video. Officially supported types include: `video/mp4`, `video/mpeg`, `video/mov`, `video/avi`, `video/x-flv`, `video/mpg`, `video/webm`, `video/wmv`, `video/3gpp`. Files with other MIME types might be skipped. YouTube videos are handled separately.\n\n### Note: Specifying Local File Paths\n\nWhen using the `..._from_path` tools, the AI assistant (client) must specify **valid file paths in the environment where this server is running**.\n\n- **If the server is running on WSL:**\n  - If the AI assistant has a Windows path (e.g., `C:\\...`), it needs to convert it to a WSL path (e.g., `/mnt/c/...`) before passing it to the tool.\n  - If the AI assistant has a WSL path, it can pass it as is.\n- **If the server is running on Windows:**\n  - If the AI assistant has a WSL path (e.g., `/home/user/...`), it needs to convert it to a UNC path (e.g., `\\\\wsl$\\Distro\\...`) before passing it to the tool.\n  - If the AI assistant has a Windows path, it can pass it as is.\n\n**Path conversion is the responsibility of the AI assistant (or its execution environment).** The server will try to interpret the received path as is, applying basic security checks.\n\n### Note: Type Errors During Build\n\nWhen running `npm run build`, you may see an error (TS7016) about missing TypeScript type definitions for the `mime-types` module.\n\n```\nsrc/index.ts:16:23 - error TS7016: Could not find a declaration file for module 'mime-types'. ...\n```\n\nThis is a type checking error, and since the JavaScript compilation itself succeeds, it **does not affect the server's execution**. If you want to resolve this error, install the type definition file as a development dependency.\n\n```bash\nnpm install --save-dev @types/mime-types\n# or\nyarn add --dev @types/mime-types\n```\n\n## Development\n\n```bash\n# Run in development mode\nnpm run dev\n```\n\n## License\n\nMIT\n```\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "flash",
        "images",
        "gemini",
        "gemini flash",
        "server gemini",
        "image mcp"
      ],
      "category": "image-and-video-generation"
    },
    "nansasuke--GarbageSorting": {
      "owner": "nansasuke",
      "name": "GarbageSorting",
      "url": "https://github.com/nansasuke/GarbageSorting",
      "imageUrl": "/freedevtools/mcp/pfp/nansasuke.webp",
      "description": "Identify and classify waste using image and voice recognition techniques to streamline the recycling process and enhance environmental awareness.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "",
      "updated_at": "2025-03-11T13:08:27Z",
      "readme_content": "# GarbageSorting\n图片识别、语音识别、垃圾分类\n\n一个完整的垃圾分类的app\n \n\n![image](https://github.com/hyyz3293/GarbageSorting/blob/master/Images/a.png) ![image](https://github.com/hyyz3293/GarbageSorting/blob/master/Images/b.png)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "recycling",
        "garbagesorting",
        "waste",
        "classify waste",
        "nansasuke garbagesorting",
        "garbagesorting identify"
      ],
      "category": "image-and-video-generation"
    },
    "nickbaumann98--everart-forge-mcp": {
      "owner": "nickbaumann98",
      "name": "everart-forge-mcp",
      "url": "https://github.com/nickbaumann98/everart-forge-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/nickbaumann98.webp",
      "description": "Generates and converts vector and raster images using advanced AI models with support for multiple formats. Provides flexible storage options and automatic formatting for efficient image processing.",
      "stars": 10,
      "forks": 7,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-07-10T04:55:11Z",
      "readme_content": "# EverArt Forge MCP for Cline\n\n\n\nAn advanced Model Context Protocol (MCP) server for [Cline](https://github.com/cline/cline) that integrates with EverArt's AI models to generate both vector and raster images. This server provides powerful image generation capabilities with flexible storage options and format conversion.\n\n## Features\n\n- **Vector Graphics Generation**\n  - Create SVG vector graphics using Recraft-Vector model\n  - Automatic SVG optimization\n  - Perfect for logos, icons, and scalable graphics\n\n- **Raster Image Generation**\n  - Support for PNG, JPEG, and WebP formats\n  - Multiple AI models for different styles\n  - High-quality image processing\n\n- **Flexible Storage**\n  - Custom output paths and filenames\n  - Automatic directory creation\n  - Format validation and extension handling\n  - Web project integration\n\n## Available Models\n\n- **5000:FLUX1.1**: Standard quality, general-purpose image generation\n- **9000:FLUX1.1-ultra**: Ultra high quality for detailed images\n- **6000:SD3.5**: Stable Diffusion 3.5 for diverse styles\n- **7000:Recraft-Real**: Photorealistic style\n- **8000:Recraft-Vector**: Vector art style (SVG output)\n\n## Installation\n\n1. Clone the repository:\n   ```bash\n   git clone https://github.com/nickbaumann98/everart-forge-mcp.git\n   cd everart-forge-mcp\n   ```\n\n2. Install dependencies:\n   ```bash\n   npm install\n   ```\n\n3. Build the project:\n   ```bash\n   npm run build\n   ```\n\n4. Get your EverArt API key:\n   - Sign up at [EverArt](https://everart.ai/) \n   - Navigate to your account settings\n   - Create or copy your API key\n\n5. Add the server to your Cline MCP settings file:\n\n   **For VS Code Extension**:  \n   Edit `~/Library/Application Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json`:\n\n   ```json\n   {\n     \"mcpServers\": {\n       \"everart-forge\": {\n         \"command\": \"node\",\n         \"args\": [\"/absolute/path/to/everart-forge-mcp/build/index.js\"],\n         \"env\": {\n           \"EVERART_API_KEY\": \"your_api_key_here\"\n         },\n         \"disabled\": false,\n         \"autoApprove\": []\n       }\n     }\n   }\n   ```\n\n   **For Claude Desktop App**:  \n   Edit `~/Library/Application Support/Claude/claude_desktop_config.json` (macOS) or appropriate location for your OS\n\n6. Restart Cline to load the new MCP server\n\n## Usage Examples\n\nOnce configured, you can use Cline to generate images with prompts like:\n\n- \"Generate a minimalist tech logo in SVG format using the Recraft-Vector model\"\n- \"Create a photorealistic landscape image with the FLUX1.1-ultra model\"\n- \"Make me a vector icon for my project that represents artificial intelligence\"\n- \"Generate a professional company logo as an SVG file and save it to my desktop\"\n\n### Tool Capabilities\n\nThe server provides these tools:\n\n#### generate_image\n\nGenerate images with extensive customization options:\n\n```\nParameters:\n- prompt (required): Text description of desired image\n- model: Model ID (5000:FLUX1.1, 9000:FLUX1.1-ultra, 6000:SD3.5, 7000:Recraft-Real, 8000:Recraft-Vector)\n- format: Output format (svg, png, jpg, webp)\n- output_path: Custom output path for the image\n- web_project_path: Path to web project root for proper asset organization\n- project_type: Web project type (react, vue, html, next, etc.)\n- asset_path: Subdirectory within the web project assets\n- image_count: Number of images to generate (1-10)\n```\n\nNotes:\n- SVG format is only available with Recraft-Vector (8000) model\n- Default format is \"svg\" for model 8000, \"png\" for others\n- You can specify combined model IDs (e.g., \"8000:Recraft-Vector\")\n\n#### list_images\n\nList all previously generated images stored by the server.\n\n#### view_image\n\nOpen a specific image in the default image viewer:\n\n```\nParameters:\n- filename: Name of the image file to view\n```\n\n## Troubleshooting\n\n- **Error: Invalid model ID**: Make sure you're using one of the supported model IDs (5000, 6000, 7000, 8000, 9000)\n- **Format not compatible with model**: SVG format is only available with Recraft-Vector (8000) model\n- **Image not found**: Use the list_images tool to see available images\n- **API authentication failed**: Check your EverArt API key\n- **Images not appearing**: Check file permissions and paths\n\n## License\n\nMIT License - see LICENSE file for details.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "images",
        "raster",
        "ai",
        "video generation",
        "raster images",
        "image processing"
      ],
      "category": "image-and-video-generation"
    },
    "noeltg77--Replicate-Designer": {
      "owner": "noeltg77",
      "name": "Replicate-Designer",
      "url": "https://github.com/noeltg77/Replicate-Designer",
      "imageUrl": "/freedevtools/mcp/pfp/noeltg77.webp",
      "description": "Generate images from text descriptions using Replicate's Flux 1.1 Pro model. Designed for seamless integration in projects requiring high-quality image generation capabilities.",
      "stars": 0,
      "forks": 1,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-03-31T20:07:00Z",
      "readme_content": "# Replicate Designer MCP\n\nAn MCP server for generating images using Replicate's Flux 1.1 Pro model.\n\n## Installation\n\n### Using Directly from GitHub\n\nYou can use the MCP server directly from GitHub in several ways:\n\n#### Option 1: Install directly with pip\n\n```bash\npip install git+https://github.com/yourusername/replicate-designer.git\n```\n\nThen run it with:\n```bash\nmcp-replicate-designer\n```\n\n#### Option 2: Use npx with GitHub repository\n\nCreate a configuration file (e.g., `mcps.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"replicateDesigner\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\", \n        \"github:yourusername/replicate-designer\"\n      ],\n      \"env\": {\n        \"REPLICATE_API_TOKEN\": \"your_replicate_api_token_here\"\n      }\n    }\n  }\n}\n```\n\nThen use it with Claude or another assistant:\n```bash\nnpx @anthropic-ai/assistant --mcps-json mcps.json\n```\n\nThis method allows you to include your Replicate API token directly in the configuration file, which is more convenient than setting environment variables separately.\n\n#### Option 3: Local Installation\n\nClone the repository and install from the local directory:\n\n```bash\ngit clone https://github.com/yourusername/replicate-designer.git\ncd replicate-designer\npip install -e .\n```\n\n### Publishing and Using via npm\n\nTo make your MCP available via npm (for easier distribution):\n\n1. Package and publish your MCP:\n```bash\n# Build a wheel\npip install build\npython -m build\n\n# Publish to npm (after setting up an npm account)\nnpm init\nnpm publish\n```\n\n2. Then users can install and use it directly:\n```bash\nnpx -y mcp-replicate-designer\n```\n\n## Usage\n\n### Setting the API Token\n\nThere are several ways to provide your Replicate API token:\n\n1. **Environment variable** (for command line usage):\n   ```bash\n   export REPLICATE_API_TOKEN=your_api_token_here\n   ```\n\n2. **In the MCP configuration file** (as shown in Option 2 above):\n   ```json\n   {\n     \"mcpServers\": {\n       \"replicateDesigner\": {\n         \"command\": \"...\",\n         \"args\": [\"...\"],\n         \"env\": {\n           \"REPLICATE_API_TOKEN\": \"your_replicate_api_token_here\"\n         }\n       }\n     }\n   }\n   ```\n\n3. **Using a .env file** in your project directory:\n   ```\n   REPLICATE_API_TOKEN=your_api_token_here\n   ```\n   \n   Then, install the python-dotenv package:\n   ```bash\n   pip install python-dotenv\n   ```\n\n> **Security Note**: Be careful with your API tokens. Never commit them to public repositories, and use environment variables or secure secret management when possible.\n\n### Running the MCP server\n\n```bash\nmcp-replicate-designer\n```\n\nBy default, it runs in stdio mode which is compatible with npx use. You can also run it in SSE mode:\n\n```bash\nmcp-replicate-designer --transport sse --port 8000\n```\n\n## Using with npx\n\nThis MCP can be used with an AI agent using npx in two ways:\n\n### Direct command line\n\n```bash\nnpx @anthropic-ai/assistant --mcp mcp-replicate-designer\n```\n\n### As a configuration object\n\nIn your configuration JSON:\n\n```json\n{\n  \"mcpServers\": {\n    \"replicateDesigner\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"mcp-replicate-designer\"\n      ]\n    }\n  }\n}\n```\n\nThen use it with:\n\n```bash\nnpx @anthropic-ai/assistant --mcps-json /path/to/your/config.json\n```\n\n## Tool\n\nThis MCP exposes a single tool:\n\n### generate_image\n\nGenerates an image using Replicate's Flux 1.1 Pro model.\n\n**Parameters:**\n\n- `prompt` (string, required): Text description of the image to generate\n- `aspect_ratio` (string, optional, default: \"1:1\"): Aspect ratio for the generated image\n- `output_format` (string, optional, default: \"webp\"): Format of the output image\n- `output_quality` (integer, optional, default: 80): Quality of the output image (1-100)\n- `safety_tolerance` (integer, optional, default: 2): Safety tolerance level (0-3)\n- `prompt_upsampling` (boolean, optional, default: true): Whether to use prompt upsampling\n\n**Example:**\n\n```json\n{\n  \"prompt\": \"A photograph of an humanoid AI agent looking sad and in disrepair, the agent is sat at a workbench getting fixed by a human male\",\n  \"aspect_ratio\": \"1:1\",\n  \"output_format\": \"webp\"\n}\n```",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "replicate",
        "generate",
        "images",
        "image generation",
        "generate images",
        "video generation"
      ],
      "category": "image-and-video-generation"
    },
    "nota--gyazo-mcp-server": {
      "owner": "nota",
      "name": "gyazo-mcp-server",
      "url": "https://github.com/nota/gyazo-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/nota.webp",
      "description": "Access and manage Gyazo images and their associated metadata, including OCR data, through a standardized protocol. Enables full-text search and retrieval of images using URIs.",
      "stars": 24,
      "forks": 8,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T07:37:31Z",
      "readme_content": "# gyazo-mcp-server\n\nA Model Context Protocol server for Gyazo image integration\n\nThis is a TypeScript-based MCP server that provides access to Gyazo images. It allows AI assistants to access and interact with Gyazo images through the Model Context Protocol, providing:\n\n- Resources representing Gyazo images with URIs and metadata\n- Tools for searching, fetching, and uploading images\n- Image content and metadata access via the Gyazo API\n\n## Features\n\n### Resources\n\n- List and access Gyazo images via `gyazo-mcp://` URIs\n- Each image includes:\n  - Original image content\n  - Metadata (title, description, app, URL)\n  - OCR data (if available)\n- Supports various image formats (JPEG, PNG, etc.)\n\n### Tools\n\n- `gyazo_search` - Full-text search for captures uploaded by users on Gyazo\n\n  - Search by keyword, title, app, URL, or date range\n  - Supports pagination for browsing multiple results\n  - Returns matching image URIs and metadata\n\n- `gyazo_image` - Fetch image content and metadata from Gyazo\n\n  - Retrieve specific images by ID or URL\n  - Returns both image content and detailed metadata\n\n- `gyazo_latest_image` - Fetch the most recent image from Gyazo\n\n  - Returns both image content and metadata\n  - Includes OCR text if available\n\n- `gyazo_upload` - Upload an image to Gyazo\n  - Upload images with base64 encoded image data\n  - Add optional metadata like title, description, referer URL, and app name\n  - Returns the uploaded image's permalink URL and ID\n\n## Installation\n\n### NPM Package\n\nThe easiest way to install the Gyazo MCP server is via npm:\n\n```bash\nnpm install -g @notainc/gyazo-mcp-server\n```\n\n### Prerequisites\n\n- Create a Gyazo account if you don't have one: https://gyazo.com\n- Get your Gyazo API access token from: https://gyazo.com/api\n  - Click \"Register applications\" button\n  - Click \"New Application\" button\n  - Fill in the form with your app name and description\n    - Name and Callback URL are required\n    - You can use `http://localhost` for the Callback URL\n  - Click \"Submit\" button\n  - Click application name to view details\n  - Scroll down to \"Your Access Token\"\n  - Click \"Generate\" button\n  - Copy \"Your access token\" value\n- Set the `GYAZO_ACCESS_TOKEN` environment variable with your token\n\n### Claude Desktop Integration\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n#### Using NPM package (recommended)\n\n```json\n{\n  \"mcpServers\": {\n    \"gyazo-mcp-server\": {\n      \"command\": \"npx\",\n      \"args\": [\"@notainc/gyazo-mcp-server\"],\n      \"env\": {\n        \"GYAZO_ACCESS_TOKEN\": \"your-access-token-here\"\n      }\n    }\n  }\n}\n```\n\n#### Using Docker (optional)\n\n```json\n{\n  \"mcpServers\": {\n    \"gyazo-mcp-server\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-e\",\n        \"GYAZO_ACCESS_TOKEN\",\n        \"gyazo-mcp-server\"\n      ],\n      \"env\": {\n        \"GYAZO_ACCESS_TOKEN\": \"your-access-token-here\"\n      }\n    }\n  }\n}\n```\n\n## Development\n\nInstall dependencies:\n\n```bash\nnpm ci\n```\n\nBuild the server:\n\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n\n```bash\nnpm run watch\n```\n\n### Docker Build (optional)\n\n```bash\nnpm run image:build\n```\n\n---\n\n<a href=\"https://glama.ai/mcp/servers/bhrk879agk\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/bhrk879agk/badge\" />\n</a>\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "gyazo",
        "ocr",
        "images",
        "gyazo images",
        "ocr data",
        "gyazo mcp"
      ],
      "category": "image-and-video-generation"
    },
    "peng-shawn--mermaid-mcp-server": {
      "owner": "peng-shawn",
      "name": "mermaid-mcp-server",
      "url": "https://github.com/peng-shawn/mermaid-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/peng-shawn.webp",
      "description": "Converts Mermaid diagram descriptions into high-quality PNG images using the Mermaid markdown syntax. Supports customizable themes and backgrounds for visual representations of data and processes.",
      "stars": 185,
      "forks": 21,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-10-03T22:32:19Z",
      "readme_content": "# Mermaid MCP Server\n\nA Model Context Protocol (MCP) server that converts Mermaid diagrams to PNG images or SVG files. This server allows AI assistants and other applications to generate visual diagrams from textual descriptions using the Mermaid markdown syntax.\n\n## Features\n\n- Converts Mermaid diagram code to PNG images or SVG files\n- Supports multiple diagram themes (default, forest, dark, neutral)\n- Customizable background colors\n- Uses Puppeteer for high-quality headless browser rendering\n- Implements the MCP protocol for seamless integration with AI assistants\n- Flexible output options: return images/SVG directly or save to disk\n- Error handling with detailed error messages\n\n## How It Works\n\nThe server uses Puppeteer to launch a headless browser, render the Mermaid diagram to SVG, and optionally capture a screenshot of the rendered diagram. The process involves:\n\n1. Launching a headless browser instance\n2. Creating an HTML template with the Mermaid code\n3. Loading the Mermaid.js library\n4. Rendering the diagram to SVG\n5. Either saving the SVG directly or taking a screenshot as PNG\n6. Either returning the image/SVG directly or saving it to disk\n\n## Build\n\n```bash\nnpx tsc\n```\n\n## Usage\n\n### Use with Claude desktop\n\n```json\n{\n  \"mcpServers\": {\n    \"mermaid\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@peng-shawn/mermaid-mcp-server\"]\n    }\n  }\n}\n```\n\n### Use with Cursor and Cline\n\n```bash\nenv CONTENT_IMAGE_SUPPORTED=false npx -y @peng-shawn/mermaid-mcp-server\n```\n\nYou can find a list of mermaid diagrams under `./diagrams`, they are created using Cursor agent with prompt: \"generate mermaid diagrams and save them in a separate diagrams folder explaining how renderMermaidPng work\"\n\n### Run with inspector\n\nRun the server with inspector for testing and debugging:\n\n```bash\nnpx @modelcontextprotocol/inspector node dist/index.js\n```\n\nThe server will start and listen on stdio for MCP protocol messages.\n\nLearn more about inspector [here](https://modelcontextprotocol.io/docs/tools/inspector).\n\n### Installing via Smithery\n\nTo install Mermaid Diagram Generator for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@peng-shawn/mermaid-mcp-server):\n\n```bash\nnpx -y @smithery/cli install @peng-shawn/mermaid-mcp-server --client claude\n```\n\n### Docker and Smithery Environments\n\nWhen running in Docker containers (including via Smithery), you may need to handle Chrome dependencies:\n\n1. The server now attempts to use Puppeteer's bundled browser by default\n2. If you encounter browser-related errors, you have two options:\n\n   **Option 1: During Docker image build:**\n\n   - Set `PUPPETEER_SKIP_CHROMIUM_DOWNLOAD=true` when installing Puppeteer\n   - Install Chrome/Chromium in your Docker container\n   - Set `PUPPETEER_EXECUTABLE_PATH` at runtime to point to the Chrome installation\n\n   **Option 2: Use Puppeteer's bundled Chrome:**\n\n   - Ensure your Docker container has the necessary dependencies for Chrome\n   - No need to set `PUPPETEER_SKIP_CHROMIUM_DOWNLOAD`\n   - The code will use the bundled browser automatically\n\nFor Smithery users, the latest version should work without additional configuration.\n\n## API\n\nThe server exposes a single tool:\n\n- `generate`: Converts Mermaid diagram code to a PNG image or SVG file\n  - Parameters:\n    - `code`: The Mermaid diagram code to render\n    - `theme`: (optional) Theme for the diagram. Options: \"default\", \"forest\", \"dark\", \"neutral\"\n    - `backgroundColor`: (optional) Background color for the diagram, e.g. 'white', 'transparent', '#F0F0F0'\n    - `outputFormat`: (optional) Output format for the diagram. Options: \"png\", \"svg\" (defaults to \"png\")\n    - `name`: Name for the generated file (required when CONTENT_IMAGE_SUPPORTED=false)\n    - `folder`: Absolute path to save the image/SVG to (required when CONTENT_IMAGE_SUPPORTED=false)\n\nThe behavior of the `generate` tool depends on the `CONTENT_IMAGE_SUPPORTED` environment variable:\n\n- When `CONTENT_IMAGE_SUPPORTED=true` (default): The tool returns the image/SVG directly in the response\n- When `CONTENT_IMAGE_SUPPORTED=false`: The tool saves the image/SVG to the specified folder and returns the file path\n\n## Environment Variables\n\n- `CONTENT_IMAGE_SUPPORTED`: Controls whether images are returned directly in the response or saved to disk\n  - `true` (default): Images are returned directly in the response\n  - `false`: Images are saved to disk, requiring `name` and `folder` parameters\n\n## Examples\n\n### Basic Usage\n\n```javascript\n// Generate a flowchart with default settings\n{\n  \"code\": \"flowchart TD\\n    A[Start] --> B{Is it?}\\n    B -->|Yes| C[OK]\\n    B -->|No| D[End]\"\n}\n```\n\n### With Theme and Background Color\n\n```javascript\n// Generate a sequence diagram with forest theme and light gray background\n{\n  \"code\": \"sequenceDiagram\\n    Alice->>John: Hello John, how are you?\\n    John-->>Alice: Great!\",\n  \"theme\": \"forest\",\n  \"backgroundColor\": \"#F0F0F0\"\n}\n```\n\n### Saving to Disk (when CONTENT_IMAGE_SUPPORTED=false)\n\n```javascript\n// Generate a class diagram and save it to disk as PNG\n{\n  \"code\": \"classDiagram\\n    Class01 <|-- AveryLongClass\\n    Class03 *-- Class04\\n    Class05 o-- Class06\",\n  \"theme\": \"dark\",\n  \"name\": \"class_diagram\",\n  \"folder\": \"/path/to/diagrams\"\n}\n```\n\n### Generating SVG Output\n\n```javascript\n// Generate a state diagram as SVG\n{\n  \"code\": \"stateDiagram-v2\\n    [*] --> Still\\n    Still --> [*]\\n    Still --> Moving\\n    Moving --> Still\\n    Moving --> Crash\\n    Crash --> [*]\",\n  \"outputFormat\": \"svg\",\n  \"name\": \"state_diagram\",\n  \"folder\": \"/path/to/diagrams\"\n}\n```\n\n## FAQ\n\n### Doesn't Claude desktop already support mermaid via canvas?\n\nYes, but it doesn't support the `theme` and `backgroundColor` options. Plus, having a dedicated server makes it easier to create mermaid diagrams with different MCP clients.\n\n### Why do I need to specify CONTENT_IMAGE_SUPPORTED=false when using with Cursor?\n\nCursor doesn't support inline images in responses yet.\n\n## Publishing\n\nThis project uses GitHub Actions to automate the publishing process to npm.\n\n### Method 1: Using the Release Script (Recommended)\n\n1. Make sure all your changes are committed and pushed\n2. Run the release script with either a specific version number or a semantic version increment:\n\n   ```bash\n   # Using a specific version number\n   npm run release 0.1.4\n\n   # Using semantic version increments\n   npm run release patch  # Increments the patch version (e.g., 0.1.3 → 0.1.4)\n   npm run release minor  # Increments the minor version (e.g., 0.1.3 → 0.2.0)\n   npm run release major  # Increments the major version (e.g., 0.1.3 → 1.0.0)\n   ```\n\n3. The script will:\n   - Validate the version format or semantic increment\n   - Check if you're on the main branch\n   - Detect and warn about version mismatches between files\n   - Update all version references consistently (package.json, package-lock.json, and index.ts)\n   - Create a single commit with all version changes\n   - Create and push a git tag\n   - The GitHub workflow will then automatically build and publish to npm\n\n### Method 2: Manual Process\n\n1. Update your code and commit the changes\n2. Create and push a new tag with the version number:\n   ```bash\n   git tag v0.1.4  # Use the appropriate version number\n   git push origin v0.1.4\n   ```\n3. The GitHub workflow will automatically:\n   - Build the project\n   - Publish to npm with the version from the tag\n\nNote: You need to set up the `NPM_TOKEN` secret in your GitHub repository settings. To do this:\n\n1. Generate an npm access token with publish permissions\n2. Go to your GitHub repository → Settings → Secrets and variables → Actions\n3. Create a new repository secret named `NPM_TOKEN` with your npm token as the value\n\n## Badges\n\n[![smithery badge](https://smithery.ai/badge/@peng-shawn/mermaid-mcp-server)](https://smithery.ai/server/@peng-shawn/mermaid-mcp-server)\n\n<a href=\"https://glama.ai/mcp/servers/lzjlbitkzr\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/lzjlbitkzr/badge\" alt=\"mermaid-mcp-server MCP server\" />\n</a>\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mermaid",
        "png",
        "images",
        "mermaid diagram",
        "mermaid markdown",
        "mermaid mcp"
      ],
      "category": "image-and-video-generation"
    },
    "philipp-eisen--modal-mcp-toolbox": {
      "owner": "philipp-eisen",
      "name": "modal-mcp-toolbox",
      "url": "https://github.com/philipp-eisen/modal-mcp-toolbox",
      "imageUrl": "/freedevtools/mcp/pfp/philipp-eisen.webp",
      "description": "A collection of tools that provides a sandboxed environment for executing Python code and generating images using the FLUX model.",
      "stars": 22,
      "forks": 3,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-08-12T21:44:25Z",
      "readme_content": "# Modal MCP Toolbox 🛠️\n\n[![smithery badge](https://smithery.ai/badge/@philipp-eisen/modal-mcp-toolbox)](https://smithery.ai/server/@philipp-eisen/modal-mcp-toolbox)\n\nA collection of Model Context Protocol (MCP) tools that run on Modal.\nThis let's you extend the capabilities of your LLM in tools such as [Goose](https://block.github.io/goose/) or the [Claude Desktop App](https://claude.ai/download).\n\n<a href=\"https://glama.ai/mcp/servers/ai78w0p5mc\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/ai78w0p5mc/badge\" alt=\"Modal Toolbox MCP server\" /></a>\n\n## Tools\n\n- `run_python_code_in_sandbox`: Let's you run python code in a sandboxed environment.\n- `generate_flux_image`: Generate an image using the FLUX model.\n\n## Demo\n\n### Flux Image Generation\n\n\n\n### Python Code Execution\n\n\n\n## Prerequisites\n\n- A [modal account](https://modal.com/signup) and a configured modal CLI.\n- [UV](https://github.com/astral-sh/uv?tab=readme-ov-file#installation)\n- A client that supports MCP. Such as the [Claude Desktop App](https://claude.ai/download) or [Goose](https://block.github.io/goose/)\n\nThis runs against your modal account, so you will need to have a modal account and be logged in.\n\n## Installation\n\nInstallation depends on the client that uses the MCP. Here is instructions for Claude and Goose.\n\n### Claude\n\nGot to `Settings > Developer` in the Claude Desktop App. And click on Edit Config.\n\n\nAdd the config for the mcp server. My config looks like this:\n\n```json\n{\n  \"mcpServers\": {\n    \"modal-toolbox\": {\n      \"command\": \"uvx\",\n      \"args\": [\"modal-mcp-toolbox\"]\n    }\n  }\n}\n```\n\n### Goose\n\nGo to `Settings` and Click on Add.\n\n\n\nThen add an extension like in the screenshot below.\nThe important part is to set command to:\n\n```\nuvx modal-mcp-toolbox\n```\n\nThe rest you can fill in as you like.\n\n\n\n### Installing via Smithery (not working currently)\n\nTo install Modal MCP Toolbox for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@philipp-eisen/modal-mcp-toolbox):\n\n```bash\nnpx -y @smithery/cli install @philipp-eisen/modal-mcp-toolbox --client claude\n```",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "python",
        "toolbox",
        "modal",
        "modal mcp",
        "generating images",
        "video generation"
      ],
      "category": "image-and-video-generation"
    },
    "pinkpixel-dev--MCPollinations": {
      "owner": "pinkpixel-dev",
      "name": "MCPollinations",
      "url": "https://github.com/pinkpixel-dev/MCPollinations",
      "imageUrl": "/freedevtools/mcp/pfp/pinkpixel-dev.webp",
      "description": "Generates images, text, and audio from prompts using the Pollinations APIs. It supports returning images as base64-encoded data and allows listing available models for image and text generation.",
      "stars": 34,
      "forks": 10,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-26T03:37:33Z",
      "readme_content": "# MCPollinations Multimodal MCP Server\nA Model Context Protocol (MCP) server that enables AI assistants to generate images, text, and audio through the Pollinations APIs\n\n[![smithery badge](https://smithery.ai/badge/@pinkpixel-dev/mcpollinations)](https://smithery.ai/server/@pinkpixel-dev/mcpollinations) [![Verified on MseeP](https://mseep.ai/badge.svg)](https://mseep.ai/app/8448e4ec-c863-476a-8adb-aed3cf16ea2b)\n\n## Features\n\n- Generate image URLs from text prompts\n- Generate images and return them as base64-encoded data AND save as png, jpeg, jpg, or webp (default: png)\n- Generate text responses from text prompts\n- Generate audio responses from text prompts\n- List available image and text generation models\n- No authentication required\n- Simple and lightweight\n- Compatible with the Model Context Protocol (MCP)\n\n## System Requirements\n\n- **Node.js**: Version 14.0.0 or higher\n  - For best performance, we recommend Node.js 16.0.0 or higher\n  - Node.js versions below 16 use an AbortController polyfill\n\n## Quick Start\n\n### Installing via Smithery\n\nTo install mcpollinations for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@pinkpixel-dev/mcpollinations):\n\n```bash\nnpx -y @smithery/cli install @pinkpixel-dev/mcpollinations --client claude\n```\n\nThe easiest way to use the MCP server:\n\n```bash\n# Run directly with npx (no installation required)\nnpx @pinkpixel/mcpollinations\n```\n\nIf you prefer to install it globally:\n\n```bash\n# Install globally\nnpm install -g @pinkpixel/mcpollinations\n\n# Run the server\nmcpollinations\n# or\nnpx @pinkpixel/mcpollinations\n\n```\n\nOr clone the repository:\n\n```bash\n# Clone the git repository\ngit clone https://github.com/pinkpixel-dev/mcpollinations.git\n# Run the server\nmcpollinations\n# or\nnpx @pinkpixel/mcpollinations\n# or run directly\nnode /path/to/MCPollinations/pollinations-mcp-server.js\n\n```\n\n## MCP Integration\n\nTo integrate the server with applications that support the Model Context Protocol (MCP):\n\n1. Generate an MCP configuration file:\n\n```bash\n# If installed globally\nnpx @pinkpixel/mcpollinations generate-config\n\n# Or run directly\nnode /path/to/MCPollinations/generate-mcp-config.js\n```\n\n### Quick MCP Config (env)\nIf you prefer to skip the generator, copy this into your MCP client config:\n\n```json\n{\n  \"mcpollinations\": {\n    \"command\": \"npx\",\n    \"args\": [\"-y\", \"@pinkpixel/mcpollinations\"],\n    \"env\": {\n      \"token\": \"YOUR_TOKEN_OPTIONAL\",\n      \"referrer\": \"your-app-or-domain-optional\",\n      \"IMAGE_MODEL\": \"flux\",\n      \"IMAGE_WIDTH\": \"1024\",\n      \"IMAGE_HEIGHT\": \"1024\",\n      \"IMAGE_ENHANCE\": \"true\",\n      \"IMAGE_SAFE\": \"false\",\n      \"TEXT_MODEL\": \"openai\",\n      \"TEXT_TEMPERATURE\": \"0.7\",\n      \"TEXT_TOP_P\": \"0.9\",\n      \"TEXT_SYSTEM\": \"\",\n      \"AUDIO_VOICE\": \"alloy\",\n      \"OUTPUT_DIR\": \"./mcpollinations-output\"\n    }\n  }\n}\n```\n\n2. Follow the prompts to customize your configuration or use the defaults.\n   - Set an output directory (relative paths recommended for portability)\n     - **Windows users**: Consider using absolute paths (e.g., `C:\\Users\\YourName\\Pictures\\MCPollinations`) for more reliable file saving\n   - Configure optional authentication (token, referrer) under `env`\n   - Configure default parameters for image generation (with a list of available models, dimensions, etc.)\n   - Configure default parameters for text generation (with a list of available models)\n   - Configure default parameters for audio generation (voice)\n\n\n3. Copy the generated `mcp.json` file to your application's MCP settings .json file.\n4. Restart your application.\n\nAfter integration, you can use commands like:\n\n\"Generate an image of a sunset over the ocean using MCPollinations\"\n\n## Authentication (Optional)\n\nMCPollinations supports optional authentication to provide access to more models and better rate limits. The server works perfectly without authentication (free tier), but users with API tokens can get enhanced access.\n\n### Configuration Methods\n\n**Method 1: Environment Variables (Recommended for security)**\n```bash\n# Set environment variables before running the server\nexport POLLINATIONS_TOKEN=\"your-api-token\"\nexport POLLINATIONS_REFERRER=\"https://your-domain.com\"\n\n# Then run the server\nnpx @pinkpixel/mcpollinations\n```\n\n**Method 2: MCP Configuration File (env)**\nWhen generating your MCP configuration, place auth inside `env` so your MCP client passes them as environment variables to the server process:\n```json\n{\n  \"mcpollinations\": {\n    \"command\": \"npx\",\n    \"args\": [\"-y\", \"@pinkpixel/mcpollinations\"],\n    \"env\": {\n      \"token\": \"your-api-token\",\n      \"referrer\": \"your-app-or-domain\"\n    }\n  }\n}\n```\n\nYou can also provide `POLLINATIONS_TOKEN` and `POLLINATIONS_REFERRER` instead; the server recognizes both forms. Using `token` and `referrer` inside `env` is recommended for MCP configs.\n\n### Authentication Parameters\n\n- **`token`** (optional): Your Pollinations API token for enhanced access\n- **`referrer`** (optional): Your domain/application referrer URL\n\nBoth parameters are completely optional. Leave them empty or unset to use the free tier.\n\n## Using Your Configuration Settings\n\nMCPollinations respects your MCP configuration settings placed in `env` as defaults. When you ask an AI assistant to generate content:\n\n- **Your configured models, output directories, and parameters are used automatically**\n- **To override**: Specifically instruct the AI to use different settings\n  - \"Generate an image using the kontext model\"\n  - \"Save this image to my Desktop folder\"\n  - \"Use a temperature of 1.2 for this text generation\"\n\n**Example Instructions:**\n- ✅ \"Generate a sunset image\" → Uses your configured model and output directory\n- ✅ \"Generate a sunset image with the flux model\" → Overrides model only\n- ✅ \"Generate a sunset image and save it to C:\\Pictures\" → Overrides output path only\n\nThis ensures your preferences are always respected unless you specifically want different settings for a particular request.\n\n## Troubleshooting\n\n### \"AbortController is not defined\" Error\n\nIf you encounter this error when running the MCP server:\n\n```\nReferenceError: AbortController is not defined\n```\n\nThis is usually caused by running on an older version of Node.js (below version 16.0.0). Try one of these solutions:\n\n1. **Update Node.js** (recommended):\n   - Update to Node.js 16.0.0 or newer\n\n2. **Use Global Installation**\n   - Update to the latest version of the package:\n   ```bash\n   npm install -g @pinkpixel/mcpollinations\n   # Run with npx\n   npx @pinkpixel/mcpollinations\n   ```\n\n3. **Install AbortController manually**:\n   - If for some reason the polyfill doesn't work:\n   ```bash\n   npm install node-abort-controller\n   ```\n\n### Check Your Node.js Version\n\nTo check your current Node.js version:\n\n```bash\nnode --version\n```\n\nIf it shows a version lower than 16.0.0, consider upgrading for best compatibility.\n\n## Available Tools\n\nThe MCP server provides the following tools:\n\n### **Image Generation Tools**\n1. `generateImageUrl` - Generates an image URL from a text prompt\n2. `generateImage` - Generates an image, returns it as base64-encoded data, and saves it to a file by default (PNG format)\n3. `editImage` - **NEW!** Edit or modify existing images based on text prompts\n4. `generateImageFromReference` - **NEW!** Generate new images using existing images as reference\n5. `listImageModels` - Lists available models for image generation\n\n### **Text & Audio Tools**\n6. `respondText` - Responds with text to a prompt using text models (customizable parameters)\n7. `respondAudio` - Generates an audio response to a text prompt (customizable voice parameter)\n8. `listTextModels` - Lists available models for text generation\n9. `listAudioVoices` - Lists all available voices for audio generation\n\n## Text Generation Details\n\n### Available Parameters\n\nThe `respondText` tool supports several parameters for fine-tuning text generation:\n\n- **`model`**: Choose from available text models (use `listTextModels` to see current options)\n- **`temperature`** (0.0-2.0): Controls randomness in the output\n  - Lower values (0.1-0.7) = more focused and deterministic\n  - Higher values (0.8-2.0) = more creative and random\n- **`top_p`** (0.0-1.0): Controls diversity via nucleus sampling\n  - Lower values = more focused on likely tokens\n  - Higher values = considers more token possibilities\n- **`system`**: System prompt to guide the model's behavior and personality\n\n### Customizing Text Generation\n\n```javascript\n// Example options for respondText\nconst options = {\n  model: \"openai\",           // Model selection\n  temperature: 0.7,          // Balanced creativity\n  top_p: 0.9,               // High diversity\n  system: \"You are a helpful assistant that explains things clearly and concisely.\"\n};\n```\n\n### Configuration Examples\n\nIn your MCP configuration, set defaults under `env` so the server uses them automatically:\n\n```json\n{\n  \"mcpollinations\": {\n    \"env\": {\n      \"TEXT_MODEL\": \"openai\",\n      \"TEXT_TEMPERATURE\": \"0.7\",\n      \"TEXT_TOP_P\": \"0.9\",\n      \"TEXT_SYSTEM\": \"You are a helpful coding assistant.\"\n    }\n  }\n}\n```\n\n## Image-to-Image Generation (NEW!)\n\nMCPollinations now supports powerful image-to-image generation with two specialized tools:\n\n### **editImage Tool**\nPerfect for modifying existing images:\n- **Remove objects**: \"remove the cat from this image\"\n- **Add elements**: \"add a dog to this scene\"\n- **Change backgrounds**: \"replace the background with mountains\"\n- **Style modifications**: \"make the lighting more dramatic\"\n\n### **generateImageFromReference Tool**\nPerfect for creating variations and new styles:\n- **Style transfer**: \"make this photo look like a painting\"\n- **Format changes**: \"convert this to a cartoon style\"\n- **Creative variations**: \"create a futuristic version of this\"\n- **Artistic interpretations**: \"make this look like a sketch\"\n\n### **Supported Models**\n- **`kontext`**: Specialized model optimized for image-to-image tasks\n- **`nanobanana`**: New Google model supporting both text-to-image and image-to-image generation\n- **`seedream`**: New ByteDance model supporting both text-to-image and image-to-image generation\n\nMulti-reference images: `editImage` and `generateImageFromReference` accept `imageUrl` as a single URL or an array of URLs. The server encodes arrays as the comma-separated `image` parameter used by the API. Ordering matters; kontext uses only the first image, nanobanana is safe up to ~4 refs, and seedream supports up to 10.\n\nImportant: URLs only. The image-to-image tools require publicly accessible HTTP(S) URLs. Local file paths, file uploads, and base64/data URLs are not supported by this MCP server (it does not upload files). If you need to work from a local image, host it somewhere accessible (e.g., a temporary file host, object storage, or a raw link in a repo) and pass the URL.\n\n### **Example Usage**\n```javascript\n// Edit an existing image\nconst editResult = await editImage(\n  \"change the background to a sunset beach\",\n  \"https://example.com/photo.jpg\",\n  \"nanobanana\"  // or \"kontext\", \"seedream\"\n);\n\n// Generate from reference\nconst referenceResult = await generateImageFromReference(\n  \"make this into a watercolor painting\",\n  \"https://example.com/photo.jpg\",\n  \"seedream\"  // or \"kontext\", \"nanobanana\"\n);\n```\n\n## Image Generation Details\n\n### Default Behavior\n\nWhen using the `generateImage` tool:\n\n- Images are saved to disk by default as PNG files\n- The default save location is the current working directory where the MCP server is running\n- The 'flux' model is used by default\n- A random seed is generated by default for each image (ensuring variety)\n- Base64-encoded image data is always returned, regardless of whether the image is saved to a file\n\n### Customizing Image Generation\n\n```javascript\n// Example options for generateImage\nconst options = {\n  // Model selection (defaults to 'flux')\n  // Available models: \"flux\", \"turbo\", \"kontext\", \"nanobanana\", \"seedream\"\n  model: \"flux\",\n\n  // Image dimensions\n  width: 1024,\n  height: 1024,\n\n  // Generation options\n  seed: 12345,  // Specific seed for reproducibility (defaults to random)\n  enhance: true,  // Enhance the prompt using an LLM before generating (defaults to true)\n  safe: false,  // Content filtering (defaults to false)\n\n  // File saving options\n  saveToFile: true,  // Set to false to skip saving to disk\n  outputPath: \"/path/to/save/directory\",  // Custom save location\n  fileName: \"my_custom_name\",  // Without extension\n  format: \"png\"  // png, jpeg, jpg, or webp\n};\n```\n\n### Where Images Are Saved\n\nWhen using Claude or another application with the MCP server:\n\n1. **Images are saved in the current working directory of where the MCP server is running**, not where Claude or the client application is installed.\n\n2. If you start the MCP server manually from a specific directory, images will be saved there by default.\n\n3. If Claude Desktop launches the MCP server automatically, images will be saved in Claude Desktop's working directory (typically in an application data folder).\n\n**💡 Windows Users**: For reliable file saving on Windows, use absolute paths in your MCP configuration instead of relative paths (e.g., `C:\\Users\\YourName\\Pictures\\MCPollinations` instead of `./mcpollinations-output`). Relative paths may not resolve as expected depending on the working directory context.\n\n### Finding Your Generated Images\n\n- The response from Claude after generating an image includes the full file path where the image was saved\n- You can specify a familiar location using the `outputPath` parameter\n- Best practice: Ask Claude to save images to an easily accessible folder like your Pictures or Downloads directory\n\n### Unique Filenames\n\nThe MCP server ensures that generated images always have unique filenames and will never overwrite existing files:\n\n1. **Default filenames** include:\n   - A sanitized version of the prompt (first 20 characters)\n   - A timestamp\n   - A random suffix\n\n2. **Custom filenames** are also protected:\n   - If you specify a filename and a file with that name already exists, a numeric suffix will be added automatically\n   - For example: `sunset.png`, `sunset_1.png`, `sunset_2.png`, etc.\n\nThis means you can safely generate multiple images with the same prompt or filename without worrying about overwriting previous images.\n\n### Accessing Base64 Data\n\nEven when saving to a file, the base64-encoded image data is always returned and can be used for:\n\n- Embedding in web pages (`<img src=\"data:image/png;base64,...\" />`)\n- Passing to other services or APIs\n- Processing in memory without filesystem operations\n- Displaying in applications that support data URIs\n\n## For Developers\n\nIf you want to use the package in your own projects:\n\n```bash\n# Install as a dependency\nnpm install @pinkpixel/mcpollinations\n\n# Import in your code\nimport { generateImageUrl, generateImage, repsondText, respondAudio, listTextModels, listImageModels, listAudioVoices } from '@pinkpixel/mcpollinations';\n```\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "pinkpixel",
        "images",
        "image",
        "pinkpixel dev",
        "generation pinkpixel",
        "generates images"
      ],
      "category": "image-and-video-generation"
    },
    "qhdrl12--mcp-server-gemini-image-generator": {
      "owner": "qhdrl12",
      "name": "mcp-server-gemini-image-generator",
      "url": "https://github.com/qhdrl12/mcp-server-gemini-image-generator",
      "imageUrl": "/freedevtools/mcp/pfp/qhdrl12.webp",
      "description": "Generate high-quality images from text prompts using the Gemini AI model, manage local image storage, and facilitate creative modifications of existing images.",
      "stars": 23,
      "forks": 17,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-25T16:39:30Z",
      "readme_content": "[![MseeP Badge](https://mseep.net/pr/qhdrl12-mcp-server-gemini-image-generator-badge.jpg)](https://mseep.ai/app/qhdrl12-mcp-server-gemini-image-generator)\n[![smithery badge](https://smithery.ai/badge/@qhdrl12/mcp-server-gemini-image-gen)](https://smithery.ai/server/@qhdrl12/mcp-server-gemini-image-gen)\n\n<a href=\"https://glama.ai/mcp/servers/@qhdrl12/mcp-server-gemini-image-generator\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@qhdrl12/mcp-server-gemini-image-generator/badge\" alt=\"Gemini Image Generator Server MCP server\" />\n</a>\n\n# Gemini Image Generator MCP Server\n\nGenerate high-quality images from text prompts using Google's Gemini model through the MCP protocol.\n\n## Overview\n\nThis MCP server allows any AI assistant to generate images using Google's Gemini AI model. The server handles prompt engineering, text-to-image conversion, filename generation, and local image storage, making it easy to create and manage AI-generated images through any MCP client.\n\n## Features\n\n- Text-to-image generation using Gemini 2.0 Flash\n- Image-to-image transformation based on text prompts\n- Support for both file-based and base64-encoded images\n- Automatic intelligent filename generation based on prompts\n- Automatic translation of non-English prompts\n- Local image storage with configurable output path\n- Strict text exclusion from generated images\n- High-resolution image output\n- Direct access to both image data and file path\n\n## Available MCP Tools\n\nThe server provides the following MCP tools for AI assistants:\n\n### 1. `generate_image_from_text`\n\nCreates a new image from a text prompt description.\n\n```\ngenerate_image_from_text(prompt: str) -> Tuple[bytes, str]\n```\n\n**Parameters:**\n- `prompt`: Text description of the image you want to generate\n\n**Returns:**\n- A tuple containing:\n  - Raw image data (bytes)\n  - Path to the saved image file (str)\n\nThis dual return format allows AI assistants to either work with the image data directly or reference the saved file path.\n\n**Examples:**\n- \"Generate an image of a sunset over mountains\"\n- \"Create a photorealistic flying pig in a sci-fi city\"\n\n#### Example Output\n\nThis image was generated using the prompt:\n\n```\n\"Hi, can you create a 3d rendered image of a pig with wings and a top hat flying over a happy futuristic scifi city with lots of greenery?\"\n```\n\n\n\n*A 3D rendered pig with wings and a top hat flying over a futuristic sci-fi city filled with greenery*\n\n### Known Issues\n\nWhen using this MCP server with Claude Desktop Host:\n\n1. **Performance Issues**: Using `transform_image_from_encoded` may take significantly longer to process compared to other methods. This is due to the overhead of transferring large base64-encoded image data through the MCP protocol.\n\n2. **Path Resolution Problems**: There may be issues with correctly resolving image paths when using Claude Desktop Host. The host application might not properly interpret the returned file paths, making it difficult to access the generated images.\n\nFor the best experience, consider using alternative MCP clients or the `transform_image_from_file` method when possible. \n\n### 2. `transform_image_from_encoded`\n\nTransforms an existing image based on a text prompt using base64-encoded image data.\n\n```\ntransform_image_from_encoded(encoded_image: str, prompt: str) -> Tuple[bytes, str]\n```\n\n**Parameters:**\n- `encoded_image`: Base64 encoded image data with format header (must be in format: \"data:image/[format];base64,[data]\")\n- `prompt`: Text description of how you want to transform the image\n\n**Returns:**\n- A tuple containing:\n  - Raw transformed image data (bytes)\n  - Path to the saved transformed image file (str)\n\n**Example:**\n- \"Add snow to this landscape\"\n- \"Change the background to a beach\"\n\n### 3. `transform_image_from_file`\n\nTransforms an existing image file based on a text prompt.\n\n```\ntransform_image_from_file(image_file_path: str, prompt: str) -> Tuple[bytes, str]\n```\n\n**Parameters:**\n- `image_file_path`: Path to the image file to be transformed\n- `prompt`: Text description of how you want to transform the image\n\n**Returns:**\n- A tuple containing:\n  - Raw transformed image data (bytes)\n  - Path to the saved transformed image file (str)\n\n**Examples:**\n- \"Add a llama next to the person in this image\"\n- \"Make this daytime scene look like night time\"\n\n#### Example Transformation\n\nUsing the flying pig image created above, we applied a transformation with the following prompt:\n\n```\n\"Add a cute baby whale flying alongside the pig\"\n```\n\n**Before:**\n\n\n**After:**\n\n\n*The original flying pig image with a cute baby whale added flying alongside it*\n\n## Setup\n\n### Prerequisites\n\n- Python 3.11+\n- Google AI API key (Gemini)\n- MCP host application (Claude Desktop App, Cursor, or other MCP-compatible clients)\n\n### Getting a Gemini API Key\n\n1. Visit [Google AI Studio API Keys page](https://aistudio.google.com/apikey)\n2. Sign in with your Google account\n3. Click \"Create API Key\"\n4. Copy your new API key for use in the configuration\n5. Note: The API key provides a certain quota of free usage per month. You can check your usage in the Google AI Studio\n\n### Installation\n\n### Installing via Smithery\n\nTo install Gemini Image Generator MCP for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@qhdrl12/mcp-server-gemini-image-gen):\n\n```bash\nnpx -y @smithery/cli install @qhdrl12/mcp-server-gemini-image-gen --client claude\n```\n\n### Manual Installation\n1. Clone the repository:\n```bash\ngit clone https://github.com/your-username/mcp-server-gemini-image-generator.git\ncd mcp-server-gemini-image-generator\n```\n\n2. Create a virtual environment and install dependencies:\n```bash\n# Using uv (recommended)\nuv venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\nuv pip install -e .\n\n# Or using regular venv\npython -m venv .venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\npip install -e .\n```\n\n3. Set up environment variables (choose one method):\n\n**Method A: Using .env file (optional)**\n```bash\n# Create .env file in the project root\ncat > .env << 'EOF'\nGEMINI_API_KEY=your-gemini-api-key-here\nOUTPUT_IMAGE_PATH=/path/to/save/images\nEOF\n```\n\n**Method B: Set directly in Claude Desktop config (recommended)**\n- Set environment variables directly in the `claude_desktop_config.json` (shown in configuration section below)\n\n### Configure Claude Desktop\n\nAdd the following to your `claude_desktop_config.json`:\n\n- **macOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`\n- **Windows**: `%APPDATA%\\Claude\\claude_desktop_config.json`\n\n```json\n{\n    \"mcpServers\": {\n        \"gemini-image-generator\": {\n            \"command\": \"uv\",\n            \"args\": [\n                \"--directory\",\n                \"/absolute/path/to/mcp-server-gemini-image-generator\",\n                \"run\",\n                \"mcp-server-gemini-image-generator\"\n            ],\n            \"env\": {\n                \"GEMINI_API_KEY\": \"your-actual-gemini-api-key-here\",\n                \"OUTPUT_IMAGE_PATH\": \"/absolute/path/to/your/images/directory\"\n            }\n        }\n    }\n}\n```\n\n**Important Configuration Notes:**\n\n1. **Replace paths with your actual paths:**\n   - Change `/absolute/path/to/mcp-server-gemini-image-generator` to the actual location where you cloned this repository\n   - Change `/absolute/path/to/your/images/directory` to where you want generated images to be saved\n\n2. **Environment Variables:**\n   - Replace `your-actual-gemini-api-key-here` with your real Gemini API key from Google AI Studio\n   - Use absolute paths for `OUTPUT_IMAGE_PATH` to ensure images are saved correctly\n\n3. **Example with real paths:**\n```json\n{\n    \"mcpServers\": {\n        \"gemini-image-generator\": {\n            \"command\": \"uv\",\n            \"args\": [\n                \"--directory\",\n                \"/Users/username/Projects/mcp-server-gemini-image-generator\",\n                \"run\",\n                \"mcp-server-gemini-image-generator\"\n            ],\n            \"env\": {\n                \"GEMINI_API_KEY\": \"GEMINI_API_KEY\",\n                \"OUTPUT_IMAGE_PATH\": \"OUTPUT_IMAGE_PATH\"\n            }\n        }\n    }\n}\n```\n\n## Usage\n\nOnce installed and configured, you can ask Claude to generate or transform images using prompts like:\n\n### Generating New Images\n- \"Generate an image of a sunset over mountains\"\n- \"Create an illustration of a futuristic cityscape\"\n- \"Make a picture of a cat wearing sunglasses\"\n\n### Transforming Existing Images\n- \"Transform this image by adding snow to the scene\"\n- \"Edit this photo to make it look like it was taken at night\"\n- \"Add a dragon flying in the background of this picture\"\n\nThe generated/transformed images will be saved to your configured output path and displayed in Claude. With the updated return types, AI assistants can also work directly with the image data without needing to access the saved files.\n\n## Testing\n\nYou can test the application by running the FastMCP development server:\n\n```\nfastmcp dev server.py\n```\n\nThis command starts a local development server and makes the MCP Inspector available at http://localhost:5173/. \nThe MCP Inspector provides a convenient web interface where you can directly test the image generation tool without needing to use Claude or another MCP client. \nYou can enter text prompts, execute the tool, and see the results immediately, which is helpful for development and debugging.\n\n## License\n\nMIT License",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "images",
        "image",
        "qhdrl12",
        "image generator",
        "gemini image",
        "video generation"
      ],
      "category": "image-and-video-generation"
    },
    "qpd-v--mcp-image-downloader": {
      "owner": "qpd-v",
      "name": "mcp-image-downloader",
      "url": "https://github.com/qpd-v/mcp-image-downloader",
      "imageUrl": "/freedevtools/mcp/pfp/qpd-v.webp",
      "description": "Provides tools for downloading images from URLs and performing basic image optimization tasks such as resizing, quality adjustment, and format conversion.",
      "stars": 11,
      "forks": 5,
      "license": "Apache License 2.0",
      "language": "JavaScript",
      "updated_at": "2025-10-03T22:32:03Z",
      "readme_content": "# MCP Image Downloader\n\nAn MCP server that provides tools for downloading and optimizing images. Built using the Model Context Protocol (MCP), this server enables AI assistants to download images from URLs and perform basic image optimization tasks.\n\n## Features\n\n- Download images from URLs with proper error handling\n- Optimize images with options for:\n  - Resizing (maintaining aspect ratio)\n  - Quality adjustment (JPEG/WebP)\n  - Format conversion\n\n## Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/qpd-v/mcp-image-downloader.git\ncd mcp-image-downloader\n\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n```\n\n## Usage\n\n### As an MCP Server\n\nAdd the server to your MCP configuration (e.g., in Claude Desktop's config):\n\n```json\n{\n  \"mcpServers\": {\n    \"image-downloader\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/mcp-image-downloader/build/index.js\"]\n    }\n  }\n}\n```\n\n### Available Tools\n\n#### download_image\nDownloads an image from a URL to a specified path.\n\nParameters:\n- `url`: URL of the image to download\n- `outputPath`: Path where to save the image\n\n#### optimize_image\nCreates an optimized version of an image.\n\nParameters:\n- `inputPath`: Path to the input image\n- `outputPath`: Path where to save the optimized image\n- `width` (optional): Target width (maintains aspect ratio if only width is specified)\n- `height` (optional): Target height (maintains aspect ratio if only height is specified)\n- `quality` (optional): JPEG/WebP quality (1-100)\n\n## Development\n\n```bash\n# Run in development mode\nnpm run start\n\n# Build the project\nnpm run build\n```\n\n## Requirements\n\n- Node.js 16 or higher\n- NPM or compatible package manager\n\n## License\n\nMIT License - see the [LICENSE](LICENSE) file for details.\n\n## Author\n\nqpd-v\n\n## Version\n\n0.1.0 - Initial release",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "qpd",
        "mcp",
        "downloader",
        "image downloader",
        "mcp image",
        "downloading images"
      ],
      "category": "image-and-video-generation"
    },
    "rmcendarfer2017--MCP-image-gen": {
      "owner": "rmcendarfer2017",
      "name": "MCP-image-gen",
      "url": "https://github.com/rmcendarfer2017/MCP-image-gen",
      "imageUrl": "/freedevtools/mcp/pfp/rmcendarfer2017.webp",
      "description": "Generate stunning images using advanced AI models with a built-in storage system for managing and accessing creations. Users can customize image styles and utilize a prompt-based interface for generating images.",
      "stars": 0,
      "forks": 3,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-03-08T16:13:41Z",
      "readme_content": "# Image Generator MCP Server\n\nAn MCP server that uses Replicate to generate images and allows users to save them.\n\n## Components\n\n### Resources\n\nThe server implements an image storage system with:\n- Custom image:// URI scheme for accessing individual generated images\n- Each image resource has a name based on its prompt, description with creation date, and image/png mimetype\n\n### Prompts\n\nThe server provides a single prompt:\n- generate-image: Creates prompts for generating images using Stable Diffusion\n  - Optional \"style\" argument to control the image style (realistic/artistic/abstract)\n  - Generates a prompt template with style-specific guidance\n\n### Tools\n\nThe server implements three tools:\n- generate-image: Generates an image using Replicate's Stable Diffusion model\n  - Takes \"prompt\" as a required string argument\n  - Optional parameters include \"negative_prompt\", \"width\", \"height\", \"num_inference_steps\", and \"guidance_scale\"\n  - Returns the generated image and its URL\n- save-image: Saves a generated image to the local filesystem\n  - Takes \"image_url\" and \"prompt\" as required string arguments\n  - Generates a unique ID for the image and saves it to the \"generated_images\" directory\n- list-saved-images: Lists all saved images\n  - Returns a list of all saved images with their metadata and thumbnails\n\n## Configuration\n\n### Replicate API Token\n\nTo use this image generator, you need a Replicate API token:\n\n1. Create an account at [Replicate](https://replicate.com/)\n2. Get your API token from [https://replicate.com/account](https://replicate.com/account)\n3. Create a `.env` file based on the provided `.env.example` template:\n\n```\nREPLICATE_API_TOKEN=your_replicate_api_token_here\n```\n\n> **Important:** The `.env` file is excluded from version control via `.gitignore` to prevent accidentally exposing your API token. Never commit sensitive information to your repository.\n\n### Environment Setup\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/yourusername/image-generator.git\ncd image-generator\n```\n\n2. Create and activate a virtual environment:\n```bash\n# Using venv\npython -m venv .venv\n# On Windows\n.venv\\Scripts\\activate\n# On macOS/Linux\nsource .venv/bin/activate\n```\n\n3. Install dependencies:\n```bash\npip install -r requirements.txt\n```\n\n4. Set up your `.env` file as described above\n\n## Quickstart\n\n### Install\n\n#### Claude Desktop\n\nOn MacOS: `~/Library/Application\\ Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n<details>\n  <summary>Development/Unpublished Servers Configuration</summary>\n  ```\n  \"mcpServers\": {\n    \"image-generator\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"B:\\NEWTEST\\image-generator\",\n        \"run\",\n        \"image-generator\"\n      ]\n    }\n  }\n  ```\n</details>\n\n<details>\n  <summary>Published Servers Configuration</summary>\n  ```\n  \"mcpServers\": {\n    \"image-generator\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"image-generator\"\n      ]\n    }\n  }\n  ```\n</details>\n\n### Usage\n\nOnce the server is running, you can:\n\n1. Generate an image by using the \"generate-image\" tool with a descriptive prompt\n2. Save the generated image using the \"save-image\" tool with the image URL and prompt\n3. View all saved images using the \"list-saved-images\" tool\n4. Access saved images through the resource list\n\n## Development\n\n### Building and Publishing\n\nTo prepare the package for distribution:\n\n1. Sync dependencies and update lockfile:\n```bash\nuv sync\n```\n\n2. Build package distributions:\n```bash\nuv build\n```\n\nThis will create source and wheel distributions in the `dist/` directory.\n\n3. Publish to PyPI:\n```bash\nuv publish\n```\n\nNote: You'll need to set PyPI credentials via environment variables or command flags:\n- Token: `--token` or `UV_PUBLISH_TOKEN`\n- Or username/password: `--username`/`UV_PUBLISH_USERNAME` and `--password`/`UV_PUBLISH_PASSWORD`\n\n### Debugging\n\nSince MCP servers run over stdio, debugging can be challenging. For the best debugging\nexperience, we strongly recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector).\n\nYou can launch the MCP Inspector via [`npm`](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm) with this command:\n\n```bash\nnpx @modelcontextprotocol/inspector uv --directory B:\\NEWTEST\\image-generator run image-generator\n```\n\nUpon launching, the Inspector will display a URL that you can access in your browser to begin debugging.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "generate",
        "images",
        "mcp",
        "generating images",
        "mcp image",
        "image gen"
      ],
      "category": "image-and-video-generation"
    },
    "rsagacom--chatgpt-on-wechat": {
      "owner": "rsagacom",
      "name": "chatgpt-on-wechat",
      "url": "https://github.com/rsagacom/chatgpt-on-wechat",
      "imageUrl": "/freedevtools/mcp/pfp/rsagacom.webp",
      "description": "A multi-platform intelligent dialogue service that supports text, voice, and image interactions. It can connect to various AI models and allows for custom enterprise AI applications through plugin extensions.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2024-01-28T14:00:49Z",
      "readme_content": "# 简介\n\n> 本项目是基于大模型的智能对话机器人，支持微信、企业微信、公众号、飞书、钉钉接入，可选择GPT3.5/GPT4.0/Claude/文心一言/讯飞星火/通义千问/Gemini/LinkAI，能处理文本、语音和图片，通过插件访问操作系统和互联网等外部资源，支持基于自有知识库定制企业AI应用。\n\n最新版本支持的功能如下：\n\n- [x] **多端部署：** 有多种部署方式可选择且功能完备，目前已支持个人微信、微信公众号和、企业微信、飞书、钉钉等部署方式\n- [x] **基础对话：** 私聊及群聊的消息智能回复，支持多轮会话上下文记忆，支持 GPT-3.5, GPT-4, claude, Gemini, 文心一言, 讯飞星火, 通义千问\n- [x] **语音能力：** 可识别语音消息，通过文字或语音回复，支持 azure, baidu, google, openai(whisper/tts) 等多种语音模型\n- [x] **图像能力：** 支持图片生成、图片识别、图生图（如照片修复），可选择 Dall-E-3, stable diffusion, replicate, midjourney, vision模型\n- [x] **丰富插件：** 支持个性化插件扩展，已实现多角色切换、文字冒险、敏感词过滤、聊天记录总结、文档总结和对话、联网搜索等插件\n- [x] **知识库：** 通过上传知识库文件自定义专属机器人，可作为数字分身、智能客服、私域助手使用，基于 [LinkAI](https://link-ai.tech) 实现\n\n# 演示\n\nhttps://github.com/zhayujie/chatgpt-on-wechat/assets/26161723/d5154020-36e3-41db-8706-40ce9f3f1b1e\n\nDemo made by [Visionn](https://www.wangpc.cc/)\n\n# 商业支持\n\n> 我们还提供企业级的 **AI应用平台**，包含知识库、Agent插件、应用管理等能力，支持多平台聚合的应用接入、客户端管理、对话管理，以及提供\nSaaS服务、私有化部署、稳定托管接入 等多种模式。\n>\n> 目前已在私域运营、智能客服、企业效率助手等场景积累了丰富的 AI 解决方案， 在电商、文教、健康、新消费等各行业沉淀了 AI 落地的最佳实践，致力于打造助力中小企业拥抱 AI 的一站式平台。\n\n企业服务和商用咨询可联系产品顾问：\n\n<img width=\"240\" src=\"https://img-1317903499.cos.ap-guangzhou.myqcloud.com/docs/product-manager-qrcode.jpg\">\n\n# 开源社区\n\n添加小助手微信加入开源项目交流群：\n\n\n\n# 更新日志\n\n>**2023.11.11：** [1.5.3版本](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.5.3) 和 [1.5.4版本](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.5.4)，新增Google Gemini、通义千问模型\n\n>**2023.11.10：** [1.5.2版本](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.5.2)，新增飞书通道、图像识别对话、黑名单配置\n\n>**2023.11.10：** [1.5.0版本](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.5.0)，新增 `gpt-4-turbo`, `dall-e-3`, `tts` 模型接入，完善图像理解&生成、语音识别&生成的多模态能力\n\n>**2023.10.16：** 支持通过意图识别使用LinkAI联网搜索、数学计算、网页访问等插件，参考[插件文档](https://docs.link-ai.tech/platform/plugins)\n\n>**2023.09.26：** 插件增加 文件/文章链接 一键总结和对话的功能，使用参考：[插件说明](https://github.com/zhayujie/chatgpt-on-wechat/tree/master/plugins/linkai#3%E6%96%87%E6%A1%A3%E6%80%BB%E7%BB%93%E5%AF%B9%E8%AF%9D%E5%8A%9F%E8%83%BD)\n\n>**2023.08.08：** 接入百度文心一言模型，通过 [插件](https://github.com/zhayujie/chatgpt-on-wechat/tree/master/plugins/linkai) 支持 Midjourney 绘图\n\n>**2023.06.12：** 接入 [LinkAI](https://link-ai.tech/console) 平台，可在线创建领域知识库，并接入微信、公众号及企业微信中，打造专属客服机器人。使用参考 [接入文档](https://link-ai.tech/platform/link-app/wechat)。\n\n>**2023.04.26：** 支持企业微信应用号部署，兼容插件，并支持语音图片交互，私人助理理想选择，[使用文档](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/channel/wechatcom/README.md)。(contributed by [@lanvent](https://github.com/lanvent) in [#944](https://github.com/zhayujie/chatgpt-on-wechat/pull/944))\n\n>**2023.04.05：** 支持微信公众号部署，兼容插件，并支持语音图片交互，[使用文档](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/channel/wechatmp/README.md)。(contributed by [@JS00000](https://github.com/JS00000) in [#686](https://github.com/zhayujie/chatgpt-on-wechat/pull/686))\n\n>**2023.04.05：** 增加能让ChatGPT使用工具的`tool`插件，[使用文档](https://github.com/goldfishh/chatgpt-on-wechat/blob/master/plugins/tool/README.md)。工具相关issue可反馈至[chatgpt-tool-hub](https://github.com/goldfishh/chatgpt-tool-hub)。(contributed by [@goldfishh](https://github.com/goldfishh) in [#663](https://github.com/zhayujie/chatgpt-on-wechat/pull/663))\n\n>**2023.03.25：** 支持插件化开发，目前已实现 多角色切换、文字冒险游戏、管理员指令、Stable Diffusion等插件，使用参考 [#578](https://github.com/zhayujie/chatgpt-on-wechat/issues/578)。(contributed by [@lanvent](https://github.com/lanvent) in [#565](https://github.com/zhayujie/chatgpt-on-wechat/pull/565))\n\n>**2023.03.09：** 基于 `whisper API`(后续已接入更多的语音`API`服务) 实现对微信语音消息的解析和回复，添加配置项 `\"speech_recognition\":true` 即可启用，使用参考 [#415](https://github.com/zhayujie/chatgpt-on-wechat/issues/415)。(contributed by [wanggang1987](https://github.com/wanggang1987) in [#385](https://github.com/zhayujie/chatgpt-on-wechat/pull/385))\n\n>**2023.02.09：** 扫码登录存在账号限制风险，请谨慎使用，参考[#58](https://github.com/AutumnWhj/ChatGPT-wechat-bot/issues/158)\n\n# 快速开始\n\n快速开始文档：[项目搭建文档](https://docs.link-ai.tech/cow/quick-start)\n\n## 准备\n\n### 1. 账号注册\n\n项目默认使用OpenAI接口，需前往 [OpenAI注册页面](https://beta.openai.com/signup) 创建账号，创建完账号则前往 [API管理页面](https://beta.openai.com/account/api-keys) 创建一个 API Key 并保存下来，后面需要在项目中配置这个key。接口需要海外网络访问及绑定信用卡支付。\n\n> 默认对话模型是 openai 的 gpt-3.5-turbo，计费方式是约每 1000tokens (约750个英文单词 或 500汉字，包含请求和回复) 消耗 $0.002，图片生成是Dell E模型，每张消耗 $0.016。\n\n项目同时也支持使用 LinkAI 接口，无需代理，可使用 文心、讯飞、GPT-3、GPT-4 等模型，支持 定制化知识库、联网搜索、MJ绘图、文档总结和对话等能力。修改配置即可一键切换，参考 [接入文档](https://link-ai.tech/platform/link-app/wechat)。\n\n### 2.运行环境\n\n支持 Linux、MacOS、Windows 系统（可在Linux服务器上长期运行)，同时需安装 `Python`。\n> 建议Python版本在 3.7.1~3.9.X 之间，推荐3.8版本，3.10及以上版本在 MacOS 可用，其他系统上不确定能否正常运行。\n\n> 注意：Docker 或 Railway 部署无需安装python环境和下载源码，可直接快进到下一节。\n\n**(1) 克隆项目代码：**\n\n```bash\ngit clone https://github.com/zhayujie/chatgpt-on-wechat\ncd chatgpt-on-wechat/\n```\n\n注: 如遇到网络问题可选择国内镜像 https://gitee.com/zhayujie/chatgpt-on-wechat\n\n**(2) 安装核心依赖 (必选)：**\n> 能够使用`itchat`创建机器人，并具有文字交流功能所需的最小依赖集合。\n```bash\npip3 install -r requirements.txt\n```\n\n**(3) 拓展依赖 (可选，建议安装)：**\n\n```bash\npip3 install -r requirements-optional.txt\n```\n> 如果某项依赖安装失败可注释掉对应的行再继续\n\n## 配置\n\n配置文件的模板在根目录的`config-template.json`中，需复制该模板创建最终生效的 `config.json` 文件：\n\n```bash\n  cp config-template.json config.json\n```\n\n然后在`config.json`中填入配置，以下是对默认配置的说明，可根据需要进行自定义修改（请去掉注释）：\n\n```bash\n# config.json文件内容示例\n{\n  \"open_ai_api_key\": \"YOUR API KEY\",                          # 填入上面创建的 OpenAI API KEY\n  \"model\": \"gpt-3.5-turbo\",                                   # 模型名称, 支持 gpt-3.5-turbo, gpt-3.5-turbo-16k, gpt-4, wenxin, xunfei\n  \"proxy\": \"\",                                                # 代理客户端的ip和端口，国内环境开启代理的需要填写该项，如 \"127.0.0.1:7890\"\n  \"single_chat_prefix\": [\"bot\", \"@bot\"],                      # 私聊时文本需要包含该前缀才能触发机器人回复\n  \"single_chat_reply_prefix\": \"[bot] \",                       # 私聊时自动回复的前缀，用于区分真人\n  \"group_chat_prefix\": [\"@bot\"],                              # 群聊时包含该前缀则会触发机器人回复\n  \"group_name_white_list\": [\"ChatGPT测试群\", \"ChatGPT测试群2\"], # 开启自动回复的群名称列表\n  \"group_chat_in_one_session\": [\"ChatGPT测试群\"],              # 支持会话上下文共享的群名称  \n  \"image_create_prefix\": [\"画\", \"看\", \"找\"],                   # 开启图片回复的前缀\n  \"conversation_max_tokens\": 1000,                            # 支持上下文记忆的最多字符数\n  \"speech_recognition\": false,                                # 是否开启语音识别\n  \"group_speech_recognition\": false,                          # 是否开启群组语音识别\n  \"use_azure_chatgpt\": false,                                 # 是否使用Azure ChatGPT service代替openai ChatGPT service. 当设置为true时需要设置 open_ai_api_base，如 https://xxx.openai.azure.com/\n  \"azure_deployment_id\": \"\",                                  # 采用Azure ChatGPT时，模型部署名称\n  \"azure_api_version\": \"\",                                    # 采用Azure ChatGPT时，API版本\n  \"character_desc\": \"你是ChatGPT, 一个由OpenAI训练的大型语言模型, 你旨在回答并解决人们的任何问题，并且可以使用多种语言与人交流。\",  # 人格描述\n  # 订阅消息，公众号和企业微信channel中请填写，当被订阅时会自动回复，可使用特殊占位符。目前支持的占位符有{trigger_prefix}，在程序中它会自动替换成bot的触发词。\n  \"subscribe_msg\": \"感谢您的关注！\\n这里是ChatGPT，可以自由对话。\\n支持语音对话。\\n支持图片输出，画字开头的消息将按要求创作图片。\\n支持角色扮演和文字冒险等丰富插件。\\n输入{trigger_prefix}#help 查看详细指令。\",\n  \"use_linkai\": false,                                        # 是否使用LinkAI接口，默认关闭，开启后可国内访问，使用知识库和MJ\n  \"linkai_api_key\": \"\",                                       # LinkAI Api Key\n  \"linkai_app_code\": \"\"                                       # LinkAI 应用code\n}\n```\n**配置说明：**\n\n**1.个人聊天**\n\n+ 个人聊天中，需要以 \"bot\"或\"@bot\" 为开头的内容触发机器人，对应配置项 `single_chat_prefix` (如果不需要以前缀触发可以填写  `\"single_chat_prefix\": [\"\"]`)\n+ 机器人回复的内容会以 \"[bot] \" 作为前缀， 以区分真人，对应的配置项为 `single_chat_reply_prefix` (如果不需要前缀可以填写 `\"single_chat_reply_prefix\": \"\"`)\n\n**2.群组聊天**\n\n+ 群组聊天中，群名称需配置在 `group_name_white_list ` 中才能开启群聊自动回复。如果想对所有群聊生效，可以直接填写 `\"group_name_white_list\": [\"ALL_GROUP\"]`\n+ 默认只要被人 @ 就会触发机器人自动回复；另外群聊天中只要检测到以 \"@bot\" 开头的内容，同样会自动回复（方便自己触发），这对应配置项 `group_chat_prefix`\n+ 可选配置: `group_name_keyword_white_list`配置项支持模糊匹配群名称，`group_chat_keyword`配置项则支持模糊匹配群消息内容，用法与上述两个配置项相同。（Contributed by [evolay](https://github.com/evolay))\n+ `group_chat_in_one_session`：使群聊共享一个会话上下文，配置 `[\"ALL_GROUP\"]` 则作用于所有群聊\n\n**3.语音识别**\n\n+ 添加 `\"speech_recognition\": true` 将开启语音识别，默认使用openai的whisper模型识别为文字，同时以文字回复，该参数仅支持私聊 (注意由于语音消息无法匹配前缀，一旦开启将对所有语音自动回复，支持语音触发画图)；\n+ 添加 `\"group_speech_recognition\": true` 将开启群组语音识别，默认使用openai的whisper模型识别为文字，同时以文字回复，参数仅支持群聊 (会匹配group_chat_prefix和group_chat_keyword, 支持语音触发画图)；\n+ 添加 `\"voice_reply_voice\": true` 将开启语音回复语音（同时作用于私聊和群聊），但是需要配置对应语音合成平台的key，由于itchat协议的限制，只能发送语音mp3文件，若使用wechaty则回复的是微信语音。\n\n**4.其他配置**\n\n+ `model`: 模型名称，目前支持 `gpt-3.5-turbo`, `text-davinci-003`, `gpt-4`, `gpt-4-32k`, `wenxin` , `claude` ,  `xunfei`(其中gpt-4 api暂未完全开放，申请通过后可使用)\n+ `temperature`,`frequency_penalty`,`presence_penalty`: Chat API接口参数，详情参考[OpenAI官方文档。](https://platform.openai.com/docs/api-reference/chat)\n+ `proxy`：由于目前 `openai` 接口国内无法访问，需配置代理客户端的地址，详情参考  [#351](https://github.com/zhayujie/chatgpt-on-wechat/issues/351)\n+ 对于图像生成，在满足个人或群组触发条件外，还需要额外的关键词前缀来触发，对应配置 `image_create_prefix `\n+ 关于OpenAI对话及图片接口的参数配置（内容自由度、回复字数限制、图片大小等），可以参考 [对话接口](https://beta.openai.com/docs/api-reference/completions) 和 [图像接口](https://beta.openai.com/docs/api-reference/completions)  文档，在[`config.py`](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/config.py)中检查哪些参数在本项目中是可配置的。\n+ `conversation_max_tokens`：表示能够记忆的上下文最大字数（一问一答为一组对话，如果累积的对话字数超出限制，就会优先移除最早的一组对话）\n+ `rate_limit_chatgpt`，`rate_limit_dalle`：每分钟最高问答速率、画图速率，超速后排队按序处理。\n+ `clear_memory_commands`: 对话内指令，主动清空前文记忆，字符串数组可自定义指令别名。\n+ `hot_reload`: 程序退出后，暂存微信扫码状态，默认关闭。\n+ `character_desc` 配置中保存着你对机器人说的一段话，他会记住这段话并作为他的设定，你可以为他定制任何人格      (关于会话上下文的更多内容参考该 [issue](https://github.com/zhayujie/chatgpt-on-wechat/issues/43))\n+ `subscribe_msg`：订阅消息，公众号和企业微信channel中请填写，当被订阅时会自动回复， 可使用特殊占位符。目前支持的占位符有{trigger_prefix}，在程序中它会自动替换成bot的触发词。\n\n**5.LinkAI配置 (可选)**\n\n+ `use_linkai`: 是否使用LinkAI接口，开启后可国内访问，使用知识库和 `Midjourney` 绘画, 参考 [文档](https://link-ai.tech/platform/link-app/wechat)\n+ `linkai_api_key`: LinkAI Api Key，可在 [控制台](https://link-ai.tech/console/interface) 创建\n+ `linkai_app_code`: LinkAI 应用code，选填\n\n**本说明文档可能会未及时更新，当前所有可选的配置项均在该[`config.py`](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/config.py)中列出。**\n\n## 运行\n\n### 1.本地运行\n\n如果是开发机 **本地运行**，直接在项目根目录下执行：\n\n```bash\npython3 app.py                                    # windows环境下该命令通常为 python app.py\n```\n\n终端输出二维码后，使用微信进行扫码，当输出 \"Start auto replying\" 时表示自动回复程序已经成功运行了（注意：用于登录的微信需要在支付处已完成实名认证）。扫码登录后你的账号就成为机器人了，可以在微信手机端通过配置的关键词触发自动回复 (任意好友发送消息给你，或是自己发消息给好友)，参考[#142](https://github.com/zhayujie/chatgpt-on-wechat/issues/142)。\n\n### 2.服务器部署\n\n使用nohup命令在后台运行程序：\n\n```bash\nnohup python3 app.py & tail -f nohup.out          # 在后台运行程序并通过日志输出二维码\n```\n扫码登录后程序即可运行于服务器后台，此时可通过 `ctrl+c` 关闭日志，不会影响后台程序的运行。使用 `ps -ef | grep app.py | grep -v grep` 命令可查看运行于后台的进程，如果想要重新启动程序可以先 `kill` 掉对应的进程。日志关闭后如果想要再次打开只需输入 `tail -f nohup.out`。此外，`scripts` 目录下有一键运行、关闭程序的脚本供使用。\n\n> **多账号支持：** 将项目复制多份，分别启动程序，用不同账号扫码登录即可实现同时运行。\n\n> **特殊指令：** 用户向机器人发送 **#reset** 即可清空该用户的上下文记忆。\n\n\n### 3.Docker部署\n\n> 使用docker部署无需下载源码和安装依赖，只需要获取 docker-compose.yml 配置文件并启动容器即可。\n\n> 前提是需要安装好 `docker` 及 `docker-compose`，安装成功的表现是执行 `docker -v` 和 `docker-compose version` (或 docker compose version) 可以查看到版本号，可前往 [docker官网](https://docs.docker.com/engine/install/) 进行下载。\n\n#### (1) 下载 docker-compose.yml 文件\n\n```bash\nwget https://open-1317903499.cos.ap-guangzhou.myqcloud.com/docker-compose.yml\n```\n\n下载完成后打开 `docker-compose.yml` 修改所需配置，如 `OPEN_AI_API_KEY` 和 `GROUP_NAME_WHITE_LIST` 等。\n\n#### (2) 启动容器\n\n在 `docker-compose.yml` 所在目录下执行以下命令启动容器：\n\n```bash\nsudo docker compose up -d\n```\n\n运行 `sudo docker ps` 能查看到 NAMES 为 chatgpt-on-wechat 的容器即表示运行成功。\n\n注意：\n\n - 如果 `docker-compose` 是 1.X 版本 则需要执行 `sudo  docker-compose up -d` 来启动容器\n - 该命令会自动去 [docker hub](https://hub.docker.com/r/zhayujie/chatgpt-on-wechat) 拉取 latest 版本的镜像，latest 镜像会在每次项目 release 新的版本时生成\n\n最后运行以下命令可查看容器运行日志，扫描日志中的二维码即可完成登录：\n\n```bash\nsudo docker logs -f chatgpt-on-wechat\n```\n\n#### (3) 插件使用\n\n如果需要在docker容器中修改插件配置，可通过挂载的方式完成，将 [插件配置文件](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/plugins/config.json.template)\n重命名为 `config.json`，放置于 `docker-compose.yml` 相同目录下，并在 `docker-compose.yml` 中的 `chatgpt-on-wechat` 部分下添加 `volumes` 映射:\n\n```\nvolumes:\n  - ./config.json:/app/plugins/config.json\n```\n\n### 4. Railway部署\n\n> Railway 每月提供5刀和最多500小时的免费额度。 (07.11更新: 目前大部分账号已无法免费部署)\n\n1. 进入 [Railway](https://railway.app/template/qApznZ?referralCode=RC3znh)\n2. 点击 `Deploy Now` 按钮。\n3. 设置环境变量来重载程序运行的参数，例如`open_ai_api_key`, `character_desc`。\n\n**一键部署:**\n  \n  [![Deploy on Railway](https://railway.app/button.svg)](https://railway.app/template/qApznZ?referralCode=RC3znh)\n\n## 常见问题\n\nFAQs： <https://github.com/zhayujie/chatgpt-on-wechat/wiki/FAQs>\n\n或直接在线咨询 [项目小助手](https://link-ai.tech/app/Kv2fXJcH)  (beta版本，语料完善中，回复仅供参考)\n\n## 开发\n\n欢迎接入更多应用，参考 [Terminal代码](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/channel/terminal/terminal_channel.py) 实现接收和发送消息逻辑即可接入。 同时欢迎增加新的插件，参考 [插件说明文档](https://github.com/zhayujie/chatgpt-on-wechat/tree/master/plugins)。\n\n## 联系\n\n欢迎提交PR、Issues，以及Star支持一下。程序运行遇到问题可以查看 [常见问题列表](https://github.com/zhayujie/chatgpt-on-wechat/wiki/FAQs) ，其次前往 [Issues](https://github.com/zhayujie/chatgpt-on-wechat/issues) 中搜索。个人开发者可加入开源交流群参与更多讨论，企业用户可联系[产品顾问](https://img-1317903499.cos.ap-guangzhou.myqcloud.com/docs/product-manager-qrcode.jpg)咨询。",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "chatgpt",
        "dialogue",
        "wechat",
        "dialogue service",
        "rsagacom chatgpt",
        "chatgpt wechat"
      ],
      "category": "image-and-video-generation"
    },
    "sammyl720--image-generator-mcp-server": {
      "owner": "sammyl720",
      "name": "image-generator-mcp-server",
      "url": "https://github.com/sammyl720/image-generator-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/sammyl720.webp",
      "description": "Connects to OpenAI's DALL-E 3 model to generate images based on user prompts, saving the results to a specified directory on the user's desktop.",
      "stars": 10,
      "forks": 7,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-05-24T09:22:57Z",
      "readme_content": "# image-generator MCP Server\n\nAn mcp server that generates images based on image prompts\n\nThis is a TypeScript-based MCP server that implements image generation using **OPENAI**'s `dall-e-3` image generation model.\n\n## Features\n\n### Tools\n- `generate_image` - Generate an image for given prompt\n  - Takes `prompt` as a required parameter\n  - Takes `imageName` as a required parameter to save the generated image in a `generated-images` directory on your desktop\n\n## Development\n\nInstall dependencies:\n```bash\nnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n```bash\nnpm run watch\n```\n\n## Installation\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"command\": \"image-generator\",\n      \"env\": {\n        \"OPENAI_API_KEY\": \"<your-openai-api-key>\"\n    }\n  }\n}\n```\nMake sure to replace `<your-openai-api-key>` with your actual **OPENAI** Api Key.\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcp",
        "openai",
        "generate",
        "generate images",
        "image generator",
        "mcp server"
      ],
      "category": "image-and-video-generation"
    },
    "sarthakkimtani--mcp-image-gen": {
      "owner": "sarthakkimtani",
      "name": "mcp-image-gen",
      "url": "https://github.com/sarthakkimtani/mcp-image-gen",
      "imageUrl": "/freedevtools/mcp/pfp/sarthakkimtani.webp",
      "description": "Generates high-quality images from textual prompts with customizable dimensions using the Flux.1 Schnell model. Provides standardized interfaces for specifying image generation parameters and includes error handling features.",
      "stars": 15,
      "forks": 6,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-08-05T13:37:04Z",
      "readme_content": "# Image Generation MCP Server\n\nA Model Context Protocol (MCP) server that enables seamless generation of high-quality images via Together AI. This server provides a standardized interface to specify image generation parameters.\n\n<a href=\"https://glama.ai/mcp/servers/o0137xiz62\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/o0137xiz62/badge\" alt=\"Image Generation Server MCP server\" />\n</a>\n\n## Features\n\n- High-quality image generation powered by the Flux.1 Schnell model\n- Support for customizable dimensions (width and height)\n- Clear error handling for prompt validation and API issues\n- Easy integration with MCP-compatible clients\n\n## Installation\n\n#### Claude Desktop\n\n- On MacOS: `~/Library/Application\\ Support/Claude/claude_desktop_config.json`\n- On Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n<summary>Development/Unpublished Servers Configuration</summary>\n\n```json\n{\n  \"mcpServers\": {\n    \"image-gen\": {\n      \"command\": \"uv\",\n      \"args\": [\"--directory\", \"/ABSOLUTE/PATH/TO/image-gen/\", \"run\", \"image-gen\"],\n      \"env\": {\n        \"TOGETHER_AI_API_KEY\": \"<API KEY>\"\n      }\n    }\n  }\n}\n```\n\n## Available Tools\n\nThe server implements one tool:\n\n### generate_image\n\nGenerates an image based on the given textual prompt and optional dimensions.\n\n**Input Schema:**\n\n```json\n{\n  \"prompt\": {\n    \"type\": \"string\",\n    \"description\": \"A descriptive prompt for generating the image (e.g., 'a futuristic cityscape at sunset')\"\n  },\n  \"width\": {\n    \"type\": \"integer\",\n    \"description\": \"Width of the generated image in pixels (optional)\"\n  },\n  \"height\": {\n    \"type\": \"integer\",\n    \"description\": \"Height of the generated image in pixels (optional)\"\n  },\n  \"model\": {\n    \"type\": \"string\",\n    \"description\": \"The exact model name as it appears in Together AI. If incorrect, it will fallback to the default model (black-forest-labs/FLUX.1-schnell).\"\n  }\n}\n```\n\n## Prerequisites\n\n- Python 3.12 or higher\n- httpx\n- mcp\n\n## Contributing\n\nContributions are welcome! Please follow these steps to contribute:\n\n1. Fork the repository\n2. Create a new branch (`feature/my-new-feature`)\n3. Commit your changes\n4. Push the branch to your fork\n5. Open a Pull Request\n\nFor significant changes, please open an issue first to discuss your proposed changes.\n\n## License\n\nThis project is licensed under the MIT License. See the LICENSE file for details.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "generates",
        "images",
        "mcp",
        "image generation",
        "mcp image",
        "image gen"
      ],
      "category": "image-and-video-generation"
    },
    "sshtunnelvision--MCP-LOGO-GEN": {
      "owner": "sshtunnelvision",
      "name": "MCP-LOGO-GEN",
      "url": "https://github.com/sshtunnelvision/MCP-LOGO-GEN",
      "imageUrl": "/freedevtools/mcp/pfp/sshtunnelvision.webp",
      "description": "Logo generation using AI tools, including features for image creation, background removal, and automatic scaling for high-quality outputs in various sizes.",
      "stars": 171,
      "forks": 17,
      "license": "GNU General Public License v3.0",
      "language": "Python",
      "updated_at": "2025-08-18T06:34:36Z",
      "readme_content": "# MCP Tool Server for Logo Generation\n\nThis server provides logo generation capabilities using FAL AI, with tools for image generation, background removal, and automatic scaling.\n\n## Demo\n\n[![MCP Tool Server Demo](https://img.youtube.com/vi/Miemu1xEZng/0.jpg)](https://www.youtube.com/watch?v=Miemu1xEZng)\n\n## Installation\n\n1. Install `uv` (Universal Virtualenv):\n\n```bash\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n```\n\n2. Create and activate a virtual environment:\n\n```bash\nuv venv\nsource .venv/bin/activate  # On Unix/macOS\n# or\n.venv\\Scripts\\activate     # On Windows\n```\n\n3. Install dependencies:\n\n```bash\nuv pip install -r requirements.txt\n```\n\n4. Set up your environment variables:\n   - Create a `.env` file in the root directory\n   - Add your FAL AI API key:\n\n```bash\nFAL_KEY=your_fal_ai_key_here\n```\n\n## Running the Server\n\nStart the server with:\n\n```bash\npython run_server.py\n```\n\nThe server will be available at `http://127.0.0.1:7777`\n\n### Troubleshooting\n\nIf you encounter a `FileNotFoundError` on Windows when running the server, make sure you're running the command from the root directory of the project. If the issue persists, try updating to the latest version of the repository which includes fixes for Windows compatibility.\n\nFor Windows users specifically:\n\n1. Make sure you've activated your virtual environment with `.venv\\Scripts\\activate`\n2. Run the server from the root directory of the project with `python run_server.py`\n3. If you see any path-related errors, please report them in the issues section of the repository\n\n## Cursor IDE Configuration\n\n1. Open Cursor Settings\n2. Navigate to the MCP section\n3. Add the following configuration:\n   - URL: `http://127.0.0.1:7777/sse`\n   - Connection Type: `SSE`\n   - Enable the connection\n\n## Notes\n\n- Always reference `@logo-creation.mdc` in your Cursor Composer for consistent results\n- Steps are defined in `@logo-creation.mdc` but tools can be used independently\n- All generated logos will be saved in the `downloads` directory\n- Each logo is automatically generated in three sizes:\n  - Original size\n  - 32x32 pixels\n  - 128x128 pixels\n- All logos maintain transparency in their final PNG format\n- Prompts created by agent are informed by examples and prompt structure seen in server.py. You can customize the prompt structure by editing the server.py file.\n- You can use the generate_image tool to generate any image you want, not just logos\n\n## Requirements\n\n- Python 3.8+\n- FAL AI API key (required for image generation)\n- Active internet connection\n\n## References\n\n- [Cursor MCP Documentation](https://docs.cursor.com/context/model-context-protocol)\n- [Model Context Protocol Introduction](https://modelcontextprotocol.io/introduction)\n- [FAL AI Dashboard](https://fal.ai/dashboard)\n\n---\n\nIf you find this tool helpful, you can [buy me a coffee](https://buymeacoffee.com/sshtunnelvision) ☕️ to support development!\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "logo",
        "mcp",
        "sshtunnelvision",
        "logo generation",
        "mcp logo",
        "logo gen"
      ],
      "category": "image-and-video-generation"
    },
    "stabgan--openrouter-mcp-multimodal": {
      "owner": "stabgan",
      "name": "openrouter-mcp-multimodal",
      "url": "https://github.com/stabgan/openrouter-mcp-multimodal",
      "imageUrl": "/freedevtools/mcp/pfp/stabgan.webp",
      "description": "Combines text chat and image analysis capabilities to conduct multimodal conversations and handle custom queries seamlessly. Optimizes workflows with intelligent model selection and performance improvements.",
      "stars": 10,
      "forks": 4,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-09-05T07:28:32Z",
      "readme_content": "# OpenRouter MCP Multimodal Server\n\n[![Build Status](https://github.com/stabgan/openrouter-mcp-multimodal/actions/workflows/publish.yml/badge.svg)](https://github.com/stabgan/openrouter-mcp-multimodal/actions/workflows/publish.yml)\n[![npm version](https://img.shields.io/npm/v/@stabgan/openrouter-mcp-multimodal.svg)](https://www.npmjs.com/package/@stabgan/openrouter-mcp-multimodal)\n[![Docker Pulls](https://img.shields.io/docker/pulls/stabgandocker/openrouter-mcp-multimodal.svg)](https://hub.docker.com/r/stabgandocker/openrouter-mcp-multimodal)\n\nAn MCP (Model Context Protocol) server that provides chat and image analysis capabilities through OpenRouter.ai's diverse model ecosystem. This server combines text chat functionality with powerful image analysis capabilities.\n\n## Features\n\n- **Text Chat:**\n  - Direct access to all OpenRouter.ai chat models\n  - Support for simple text and multimodal conversations\n  - Configurable temperature and other parameters\n\n- **Image Analysis:**\n  - Analyze single images with custom questions\n  - Process multiple images simultaneously \n  - Automatic image resizing and optimization\n  - Support for various image sources (local files, URLs, data URLs)\n\n- **Model Selection:**\n  - Search and filter available models\n  - Validate model IDs\n  - Get detailed model information\n  - Support for default model configuration\n\n- **Performance Optimization:**\n  - Smart model information caching\n  - Exponential backoff for retries\n  - Automatic rate limit handling\n\n## What's New in 1.5.0\n\n- **Improved OS Compatibility:**\n  - Enhanced path handling for Windows, macOS, and Linux\n  - Better support for Windows-style paths with drive letters\n  - Normalized path processing for consistent behavior across platforms\n\n- **MCP Configuration Support:**\n  - Cursor MCP integration without requiring environment variables\n  - Direct configuration via MCP parameters\n  - Flexible API key and model specification options\n\n- **Robust Error Handling:**\n  - Improved fallback mechanisms for image processing\n  - Better error reporting with specific diagnostics\n  - Multiple backup strategies for file reading\n\n- **Image Processing Enhancements:**\n  - More reliable base64 encoding for all image types\n  - Fallback options when Sharp module is unavailable\n  - Better handling of large images with automatic optimization\n\n## Installation\n\n### Option 1: Install via npm\n\n```bash\nnpm install -g @stabgan/openrouter-mcp-multimodal\n```\n\n### Option 2: Run via Docker\n\n```bash\ndocker run -i -e OPENROUTER_API_KEY=your-api-key-here stabgandocker/openrouter-mcp-multimodal:latest\n```\n\n## Quick Start Configuration\n\n### Prerequisites\n\n1. Get your OpenRouter API key from [OpenRouter Keys](https://openrouter.ai/keys)\n2. Choose a default model (optional)\n\n### MCP Configuration Options\n\nAdd one of the following configurations to your MCP settings file (e.g., `cline_mcp_settings.json` or `claude_desktop_config.json`):\n\n#### Option 1: Using npx (Node.js)\n\n```json\n{\n  \"mcpServers\": {\n    \"openrouter\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@stabgan/openrouter-mcp-multimodal\"\n      ],\n      \"env\": {\n        \"OPENROUTER_API_KEY\": \"your-api-key-here\",\n        \"DEFAULT_MODEL\": \"qwen/qwen2.5-vl-32b-instruct:free\"\n      }\n    }\n  }\n}\n```\n\n#### Option 2: Using uv (Python Package Manager)\n\n```json\n{\n  \"mcpServers\": {\n    \"openrouter\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"run\",\n        \"-m\",\n        \"openrouter_mcp_multimodal\"\n      ],\n      \"env\": {\n        \"OPENROUTER_API_KEY\": \"your-api-key-here\",\n        \"DEFAULT_MODEL\": \"qwen/qwen2.5-vl-32b-instruct:free\"\n      }\n    }\n  }\n}\n```\n\n#### Option 3: Using Docker\n\n```json\n{\n  \"mcpServers\": {\n    \"openrouter\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"-i\",\n        \"-e\", \"OPENROUTER_API_KEY=your-api-key-here\",\n        \"-e\", \"DEFAULT_MODEL=qwen/qwen2.5-vl-32b-instruct:free\",\n        \"stabgandocker/openrouter-mcp-multimodal:latest\"\n      ]\n    }\n  }\n}\n```\n\n#### Option 4: Using Smithery (recommended)\n\n```json\n{\n  \"mcpServers\": {\n    \"openrouter\": {\n      \"command\": \"smithery\",\n      \"args\": [\n        \"run\",\n        \"stabgan/openrouter-mcp-multimodal\"\n      ],\n      \"env\": {\n        \"OPENROUTER_API_KEY\": \"your-api-key-here\",\n        \"DEFAULT_MODEL\": \"qwen/qwen2.5-vl-32b-instruct:free\"\n      }\n    }\n  }\n}\n```\n\n## Examples\n\nFor comprehensive examples of how to use this MCP server, check out the [examples directory](./examples/). We provide:\n\n- JavaScript examples for Node.js applications\n- Python examples with interactive chat capabilities\n- Code snippets for integrating with various applications\n\nEach example comes with clear documentation and step-by-step instructions.\n\n## Dependencies\n\nThis project uses the following key dependencies:\n\n- `@modelcontextprotocol/sdk`: ^1.8.0 - Latest MCP SDK for tool implementation\n- `openai`: ^4.89.1 - OpenAI-compatible API client for OpenRouter\n- `sharp`: ^0.33.5 - Fast image processing library\n- `axios`: ^1.8.4 - HTTP client for API requests\n- `node-fetch`: ^3.3.2 - Modern fetch implementation\n\nNode.js 18 or later is required. All dependencies are regularly updated to ensure compatibility and security.\n\n## Available Tools\n\n### mcp_openrouter_chat_completion\n\nSend text or multimodal messages to OpenRouter models:\n\n```javascript\nuse_mcp_tool({\n  server_name: \"openrouter\",\n  tool_name: \"mcp_openrouter_chat_completion\",\n  arguments: {\n    model: \"google/gemini-2.5-pro-exp-03-25:free\", // Optional if default is set\n    messages: [\n      {\n        role: \"system\",\n        content: \"You are a helpful assistant.\"\n      },\n      {\n        role: \"user\",\n        content: \"What is the capital of France?\"\n      }\n    ],\n    temperature: 0.7 // Optional, defaults to 1.0\n  }\n});\n```\n\nFor multimodal messages with images:\n\n```javascript\nuse_mcp_tool({\n  server_name: \"openrouter\",\n  tool_name: \"mcp_openrouter_chat_completion\",\n  arguments: {\n    model: \"anthropic/claude-3.5-sonnet\",\n    messages: [\n      {\n        role: \"user\",\n        content: [\n          {\n            type: \"text\",\n            text: \"What's in this image?\"\n          },\n          {\n            type: \"image_url\",\n            image_url: {\n              url: \"https://example.com/image.jpg\"\n            }\n          }\n        ]\n      }\n    ]\n  }\n});\n```",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "multimodal",
        "conversations",
        "chat",
        "multimodal conversations",
        "mcp multimodal",
        "chat image"
      ],
      "category": "image-and-video-generation"
    },
    "surferdot--mcp-svg-converter": {
      "owner": "surferdot",
      "name": "mcp-svg-converter",
      "url": "https://github.com/surferdot/mcp-svg-converter",
      "imageUrl": "/freedevtools/mcp/pfp/surferdot.webp",
      "description": "Converts SVG code to high-quality PNG and JPG images while providing options for transparency and image quality customization. Enhances image processing by allowing transformation of vector graphics into raster formats with detailed settings.",
      "stars": 3,
      "forks": 2,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-17T13:58:17Z",
      "readme_content": "# MCP SVG Converter\n\n[![npm version](https://img.shields.io/npm/v/mcp-svg-converter.svg)](https://www.npmjs.com/package/mcp-svg-converter)\n[![Downloads](https://img.shields.io/npm/dt/mcp-svg-converter.svg)](https://www.npmjs.com/package/mcp-svg-converter)\n[![License](https://img.shields.io/npm/l/mcp-svg-converter.svg)](https://github.com/surferdot/mcp-svg-converter/blob/main/LICENSE)\n\n[English](#english) | [中文](#中文)\n\n<a name=\"english\"></a>\n## English\n\nA Model Context Protocol (MCP) server that provides tools for converting SVG code to high-quality PNG and JPG images with detailed customization options.\n\n### Features\n\n- Convert SVG code to high-quality PNG images with transparency support\n- Convert SVG code to high-quality JPG images with customizable quality settings\n- Automatic dimension detection and preservation from original SVG\n- Support for scaling to higher resolutions\n- Background color customization\n- Intelligent path handling with automatic redirection to allowed directories\n- Secure file system access with configurable permissions\n\n### Installation\n\n#### Quick Install with npx\n\n```bash\nnpx mcp-svg-converter /path/to/allowed/directory\n```\n\n#### Global Installation\n\n```bash\nnpm install -g mcp-svg-converter\nmcp-svg-converter /path/to/allowed/directory\n```\n\n#### From Source\n\n##### Prerequisites\n\n- Node.js 16 or higher\n- npm or yarn\n\n##### Installation Steps\n\n1. Clone this repository\n   ```bash\n   git clone https://github.com/surferdot/mcp-svg-converter.git\n   cd mcp-svg-converter\n   ```\n\n2. Install dependencies\n   ```bash\n   npm install\n   ```\n\n3. Build the project\n   ```bash\n   npm run build\n   ```\n\n### Usage\n\n#### As a standalone server\n\nRun the server by specifying one or more allowed directories where the converted images can be saved:\n\n```bash\nnode build/index.js /path/to/allowed/directory1 /path/to/allowed/directory2\n```\n\n#### With Claude Desktop\n\n1. Download and install [Claude Desktop](https://claude.ai/download)\n2. Create or confirm you have access to an output directory:\n   ```bash\n   # macOS/Linux\n   mkdir -p ~/Desktop/svg-output\n   \n   # Windows\n   mkdir \"%USERPROFILE%\\Desktop\\svg-output\"\n   ```\n\n3. Configure Claude Desktop by editing the configuration file:\n   - macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n\n4. Open the Claude app, click on the Claude menu in your system menu bar and select \"Settings...\"\n5. Click on \"Developer\" in the left sidebar\n6. Click \"Edit Config\" to open the configuration file\n\n7. Add this server configuration:\n\n##### Using npm package with npx (recommended)\n\n```json\n{\n  \"mcpServers\": {\n    \"svg-converter\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"mcp-svg-converter\",\n        \"/absolute/path/to/output/directory\"\n      ]\n    }\n  }\n}\n```\n\n##### Using global installation\n\nIf you've installed the package globally:\n\n```json\n{\n  \"mcpServers\": {\n    \"svg-converter\": {\n      \"command\": \"mcp-svg-converter\",\n      \"args\": [\n        \"/absolute/path/to/output/directory\"\n      ]\n    }\n  }\n}\n```\n\n##### Using local build\n\nIf you've built from source:\n\n```json\n{\n  \"mcpServers\": {\n    \"svg-converter\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/absolute/path/to/mcp-svg-converter/build/index.js\",\n        \"/absolute/path/to/output/directory\"\n      ]\n    }\n  }\n}\n```\n\n8. Save the file and restart Claude Desktop\n\n#### Verifying the Setup\n\nWhen Claude Desktop restarts, if configured correctly:\n\n1. You should see a hammer icon <img src=\"https://mintlify.s3.us-west-1.amazonaws.com/mcp/images/claude-desktop-mcp-hammer-icon.svg\" style=\"display: inline; height: 1.3em; vertical-align: middle\"> at the bottom right of the input box indicating MCP tools are available.\n2. Clicking the hammer icon should show the `svg-to-png` and `svg-to-jpg` tools.\n\n### Examples in Claude Desktop\n\n#### Example 1: Converting a Simple SVG to PNG\n\nIn Claude Desktop, send a message like:\n\n```\nPlease convert this SVG to PNG and save it to my output directory:\n\n<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 200 100\" width=\"200\" height=\"100\">\n  <rect x=\"10\" y=\"10\" width=\"80\" height=\"80\" fill=\"#4285f4\" />\n  <circle cx=\"140\" cy=\"50\" r=\"40\" fill=\"#ea4335\" />\n  <path d=\"M10 50 L90 50 L50 90 Z\" fill=\"#fbbc05\" />\n  <text x=\"100\" y=\"20\" font-family=\"Arial\" font-size=\"12\" text-anchor=\"middle\" fill=\"#34a853\">SVG Example</text>\n</svg>\n```\n\n#### Example 2: High-Quality JPG Conversion\n\n```\nPlease convert this SVG to a JPG with 95% quality and 2x scaling:\n\n<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 200 200\">\n  <rect width=\"200\" height=\"200\" fill=\"#f0f0f0\" />\n  <circle cx=\"100\" cy=\"100\" r=\"80\" fill=\"#ff6b6b\" />\n  <path d=\"M100 50 L130 150 L70 150 Z\" fill=\"white\" />\n</svg>\n```\n\n### Tools\n\n#### svg-to-png\n\nConverts SVG code to a high-quality PNG image with transparency support.\n\n**Parameters:**\n- `svgCode` (string, required): The SVG code to convert\n- `outputPath` (string, required): Path where the PNG file should be saved\n- `backgroundColor` (string, optional): Background color (default: transparent)\n- `scale` (number, optional): Scale factor for higher resolution (default: 1)\n\n#### svg-to-jpg\n\nConverts SVG code to a high-quality JPG image.\n\n**Parameters:**\n- `svgCode` (string, required): The SVG code to convert\n- `outputPath` (string, required): Path where the JPG file should be saved\n- `backgroundColor` (string, optional): Background color (default: white)\n- `quality` (number, optional): JPEG quality from 1-100 (default: 90)\n- `scale` (number, optional): Scale factor for higher resolution (default: 1)\n\n### Advanced Usage Tips\n\n#### Specifying Multiple Output Directories\n\nYou can specify multiple allowed output directories for more flexible file saving:\n\n```json\n{\n  \"mcpServers\": {\n    \"svg-converter\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"mcp-svg-converter\",\n        \"/Users/yourusername/Desktop/svg-output\",\n        \"/Users/yourusername/Documents/svg-images\",\n        \"/Users/yourusername/Downloads\"\n      ]\n    }\n  }\n}\n```\n\n#### Using Custom Output Filenames\n\nSpecify detailed file paths in your request:\n\n```\nPlease convert this SVG to PNG, and save it as \"colorful_shapes.png\" in my output directory.\n\n<svg>...</svg>\n```\n\n#### Automatic Path Redirection\n\nIf you request saving to a non-allowed directory, the converter automatically redirects to an allowed directory and informs you of the actual save location.\n\n### Troubleshooting\n\n#### Claude Doesn't Show MCP Tools Icon\n1. Verify the configuration file has correct JSON syntax\n2. Ensure all paths are absolute paths\n3. Make sure output directories exist and are writable\n4. Completely exit and restart Claude Desktop\n5. Check Claude logs:\n   - macOS: `~/Library/Logs/Claude/mcp*.log`\n   - Windows: `%APPDATA%\\Claude\\logs\\mcp*.log`\n\n#### Tool Execution Fails\n1. Ensure `mcp-svg-converter` is correctly installed\n2. Check output directory permissions\n3. Verify the SVG code is valid\n4. Check Claude logs for detailed error messages\n\n#### \"Command Not Found\" Error\n1. Ensure `mcp-svg-converter` is globally installed or correctly reference `npx`\n2. Confirm npm's global bin directory is in your PATH\n3. Try using full paths in configuration\n\n### Debugging\n\nYou can use the MCP Inspector to debug and test the server directly:\n\n```bash\nnpx @modelcontextprotocol/inspector npx mcp-svg-converter /path/to/allowed/directory\n```\n\nThis opens an interactive interface where you can test all available tools without going through Claude Desktop.\n\n### Security Considerations\n\n- The server will only write files to the directories specified when starting the server\n- If a user attempts to save to a non-allowed directory, the file will be automatically redirected to an allowed directory\n- Path traversal attacks are prevented by proper path validation\n\n### License\n\nMIT\n\n---\n\n<a name=\"中文\"></a>\n## 中文\n\nMCP SVG 转换器是一个基于模型上下文协议 (MCP) 的服务器，提供将 SVG 代码转换为高质量 PNG 和 JPG 图像的工具，支持详细的自定义选项。\n\n### 特点\n\n- 将 SVG 代码转换为支持透明度的高质量 PNG 图像\n- 将 SVG 代码转换为可定制质量设置的高质量 JPG 图像\n- 自动检测并保留原始 SVG 的尺寸\n- 支持缩放到更高分辨率\n- 可自定义背景颜色\n- 智能路径处理，自动重定向到允许的目录\n- 可配置权限的安全文件系统访问\n\n### 安装\n\n#### 使用 npx 快速安装\n\n```bash\nnpx mcp-svg-converter /path/to/allowed/directory\n```\n\n#### 全局安装\n\n```bash\nnpm install -g mcp-svg-converter\nmcp-svg-converter /path/to/allowed/directory\n```\n\n#### 从源代码安装\n\n##### 前提条件\n\n- Node.js 16 或更高版本\n- npm 或 yarn\n\n##### 安装步骤\n\n1. 克隆此仓库\n   ```bash\n   git clone https://github.com/surferdot/mcp-svg-converter.git\n   cd mcp-svg-converter\n   ```\n\n2. 安装依赖\n   ```bash\n   npm install\n   ```\n\n3. 构建项目\n   ```bash\n   npm run build\n   ```\n\n### 使用方法\n\n#### 作为独立服务器运行\n\n通过指定一个或多个允许存储转换后图像的目录来运行服务器：\n\n```bash\nnode build/index.js /path/to/allowed/directory1 /path/to/allowed/directory2\n```\n\n#### 与 Claude Desktop 一起使用\n\n1. 下载并安装 [Claude Desktop](https://claude.ai/download)\n2. 创建或确认你有权限访问的输出目录：\n   ```bash\n   # macOS/Linux\n   mkdir -p ~/Desktop/svg-output\n   \n   # Windows\n   mkdir \"%USERPROFILE%\\Desktop\\svg-output\"\n   ```\n\n3. 配置 Claude Desktop：\n   - 打开 Claude 应用程序\n   - 点击系统菜单栏中的 Claude 图标\n   - 选择\"Settings...\"（设置）\n   - 在左侧菜单中选择\"Developer\"（开发者）\n   - 点击\"Edit Config\"（编辑配置）按钮\n\n4. 编辑配置文件：\n   - macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n\n5. 添加服务器配置：\n\n##### 使用 npm 包与 npx（推荐）\n\n```json\n{\n  \"mcpServers\": {\n    \"svg-converter\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"mcp-svg-converter\",\n        \"/absolute/path/to/output/directory\"\n      ]\n    }\n  }\n}\n```\n\n##### 使用全局安装\n\n如果你已全局安装了此包：\n\n```json\n{\n  \"mcpServers\": {\n    \"svg-converter\": {\n      \"command\": \"mcp-svg-converter\",\n      \"args\": [\n        \"/absolute/path/to/output/directory\"\n      ]\n    }\n  }\n}\n```\n\n##### 使用本地构建\n\n如果你从源代码构建：\n\n```json\n{\n  \"mcpServers\": {\n    \"svg-converter\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/absolute/path/to/mcp-svg-converter/build/index.js\",\n        \"/absolute/path/to/output/directory\"\n      ]\n    }\n  }\n}\n```\n\n6. 保存文件并重启 Claude Desktop\n\n#### 验证设置\n\n当 Claude Desktop 重启后，如果配置正确：\n\n1. 你应该在输入框右下角看到一个锤子图标 <img src=\"https://mintlify.s3.us-west-1.amazonaws.com/mcp/images/claude-desktop-mcp-hammer-icon.svg\" style=\"display: inline; height: 1.3em; vertical-align: middle\">，表示 MCP 工具可用。\n2. 点击锤子图标应显示 `svg-to-png` 和 `svg-to-jpg` 工具。\n\n### Claude Desktop 中的使用示例\n\n#### 示例 1：将简单 SVG 转换为 PNG\n\n在 Claude Desktop 中发送以下消息：\n\n```\n请将这个 SVG 转换为 PNG 并保存到我的输出目录：\n\n<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 200 100\" width=\"200\" height=\"100\">\n  <rect x=\"10\" y=\"10\" width=\"80\" height=\"80\" fill=\"#4285f4\" />\n  <circle cx=\"140\" cy=\"50\" r=\"40\" fill=\"#ea4335\" />\n  <path d=\"M10 50 L90 50 L50 90 Z\" fill=\"#fbbc05\" />\n  <text x=\"100\" y=\"20\" font-family=\"Arial\" font-size=\"12\" text-anchor=\"middle\" fill=\"#34a853\">SVG 示例</text>\n</svg>\n```\n\n#### 示例 2：高质量 JPG 转换\n\n```\n请将这个 SVG 转换为 95% 质量和 2 倍缩放的 JPG 图像：\n\n<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 200 200\">\n  <rect width=\"200\" height=\"200\" fill=\"#f0f0f0\" />\n  <circle cx=\"100\" cy=\"100\" r=\"80\" fill=\"#ff6b6b\" />\n  <path d=\"M100 50 L130 150 L70 150 Z\" fill=\"white\" />\n</svg>\n```\n\n### 工具\n\n#### svg-to-png\n\n将 SVG 代码转换为支持透明度的高质量 PNG 图像。\n\n**参数：**\n- `svgCode` (字符串，必需)：要转换的 SVG 代码\n- `outputPath` (字符串，必需)：PNG 文件的保存路径\n- `backgroundColor` (字符串，可选)：背景颜色 (默认：透明)\n- `scale` (数字，可选)：更高分辨率的缩放因子 (默认：1)\n\n#### svg-to-jpg\n\n将 SVG 代码转换为高质量 JPG 图像。\n\n**参数：**\n- `svgCode` (字符串，必需)：要转换的 SVG 代码\n- `outputPath` (字符串，必需)：JPG 文件的保存路径\n- `backgroundColor` (字符串，可选)：背景颜色 (默认：白色)\n- `quality` (数字，可选)：JPEG 质量，范围从 1 到 100 (默认：90)\n- `scale` (数字，可选)：更高分辨率的缩放因子 (默认：1)\n\n### 高级使用技巧\n\n#### 指定多个输出目录\n\n你可以指定多个允许的输出目录，以提供更灵活的文件保存选项：\n\n```json\n{\n  \"mcpServers\": {\n    \"svg-converter\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"mcp-svg-converter\",\n        \"/Users/yourusername/Desktop/svg-output\",\n        \"/Users/yourusername/Documents/svg-images\",\n        \"/Users/yourusername/Downloads\"\n      ]\n    }\n  }\n}\n```\n\n#### 使用自定义输出文件名\n\n在请求中指定详细的文件路径：\n\n```\n请将这个 SVG 转换为 PNG，并以文件名 \"colorful_shapes.png\" 保存到输出目录。\n\n<svg>...</svg>\n```\n\n#### 自动路径重定向\n\n如果你请求保存到一个不允许的目录，转换器会自动将文件重定向到允许的目录，并在响应中告知你实际的保存位置。\n\n### 故障排除\n\n#### Claude 没有显示 MCP 工具图标\n1. 确认配置文件格式正确（JSON 语法）\n2. 检查所有路径是否为绝对路径\n3. 确保输出目录存在且可写\n4. 完全退出并重启 Claude Desktop\n5. 检查 Claude 日志：\n   - macOS: `~/Library/Logs/Claude/mcp*.log`\n   - Windows: `%APPDATA%\\Claude\\logs\\mcp*.log`\n\n#### 工具执行失败\n1. 确保已正确安装 `mcp-svg-converter`\n2. 检查输出目录的权限\n3. 验证 SVG 代码是否有效\n4. 检查 Claude 日志了解详细错误信息\n\n#### \"command not found\" 错误\n1. 确保已全局安装 `mcp-svg-converter` 或正确引用 `npx`\n2. 确认 npm 的全局 bin 目录在系统 PATH 中\n3. 尝试在配置中使用完整路径\n\n### 调试\n\n您可以使用 MCP Inspector 直接调试和测试服务器：\n\n```bash\nnpx @modelcontextprotocol/inspector npx mcp-svg-converter /path/to/allowed/directory\n```\n\n这将打开一个交互式界面，你可以在其中测试所有可用工具，而无需通过 Claude Desktop。\n\n### 安全考虑\n\n- 服务器只会将文件写入启动服务器时指定的目录\n- 如果用户尝试保存到非允许目录，文件将自动重定向到允许的目录\n- 通过适当的路径验证防止路径遍历攻击\n\n### 许可证\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "svg",
        "png",
        "surferdot",
        "svg converter",
        "converts svg",
        "mcp svg"
      ],
      "category": "image-and-video-generation"
    },
    "techkwon--mcp-gemini": {
      "owner": "techkwon",
      "name": "mcp-gemini",
      "url": "https://github.com/techkwon/mcp-gemini",
      "imageUrl": "/freedevtools/mcp/pfp/techkwon.webp",
      "description": "Leverages Google's Gemini API to generate text, create and analyze images, perform video analysis on YouTube content, and conduct web searches. Provides a range of advanced AI functionalities for various applications.",
      "stars": 4,
      "forks": 2,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-07-23T14:36:23Z",
      "readme_content": "# MCP Gemini API 서버\n\nCursor와 Claude를 위한 Google Gemini API 서버입니다. 텍스트 생성, 이미지 분석, 비디오 분석 등 Gemini의 다양한 기능을 제공합니다.\n\n## 주요 기능\n\n- 텍스트 생성 (gemini-2.0-flash 모델 사용)\n- 이미지 생성 및 분석\n- YouTube 비디오 분석\n- 웹 검색\n\n## 시작하기\n\n### 필수 요구사항\n\n- Node.js 18.0.0 이상\n- npm 또는 yarn\n- Google API 키 (Gemini API 접근용)\n\n### 설치\n\n```bash\n# 저장소 클론\ngit clone https://github.com/techkwon/mcp-gemini.git\ncd mcp-gemini\n\n# 의존성 설치\nnpm install\n```\n\n### 환경 설정\n\n1. `config.ts` 파일에 Google API 키 설정:\n\n```typescript\nexport default {\n  googleApiKey: \"your_api_key_here\",\n  // 기타 설정...\n};\n```\n\n### 빌드 및 실행\n\n```bash\n# TypeScript 빌드\nnpm run build\n\n# 서버 시작 (PM2 사용)\nnpm start\n\n# 개발 모드로 실행\nnpm run dev\n```\n\n### PM2 서버 관리\n\n서버는 PM2를 통해 자동으로 관리됩니다. 다음 명령어로 서버를 관리할 수 있습니다:\n\n```bash\n# 서버 상태 확인\nnpm run status\n\n# 서버 로그 확인\nnpm run logs\n\n# 서버 중지\nnpm run stop\n\n# 서버 재시작\nnpm run restart\n\n# 시스템 재시작 시 자동 실행 설정\npm2 startup\npm2 save\n```\n\n## Cursor/Claude 연동\n\n### MCP 설정\n\n`~/.cursor/mcp.json` 파일에 다음 설정을 추가하세요:\n\n```json\n{\n  \"github.com/techkwon/mcp-gemini\": {\n    \"command\": \"npm\",\n    \"args\": [\"start\"],\n    \"cwd\": \"<프로젝트_경로>\",\n    \"env\": {\n      \"NODE_ENV\": \"production\"\n    },\n    \"disabled\": false,\n    \"autoStart\": true,\n    \"autoApprove\": [\n      \"gem-generate\",\n      \"gem-generate-image\",\n      \"gem-analyze-video\",\n      \"gem-search\"\n    ]\n  }\n}\n```\n\n### API 엔드포인트\n\n- `/gem-generate`: 텍스트 생성\n- `/gem-generate-image`: 이미지 생성/분석\n- `/gem-analyze-video`: YouTube 비디오 분석\n- `/gem-search`: 웹 검색\n\n## 주요 업데이트\n\n### 최신 버전 (2024-03)\n- PM2를 통한 서버 자동화 구현\n- gemini-2.0-flash 모델로 통일\n- 자동 재시작 및 오류 복구 기능 추가\n- 환경 설정 개선\n\n### 이전 버전\n- YouTube 비디오 분석 기능 추가\n- 이미지 생성/분석 기능 개선\n- 웹 검색 기능 추가\n\n## 문제 해결\n\n### 일반적인 문제\n\n1. **서버가 시작되지 않는 경우**\n   ```bash\n   # PM2 로그 확인\n   npm run logs\n   \n   # PM2 프로세스 상태 확인\n   npm run status\n   ```\n\n2. **API 키 오류**\n   - `config.ts` 파일에서 API 키가 올바르게 설정되었는지 확인\n   - Gemini API 할당량 및 권한 확인\n\n3. **메모리 사용량 문제**\n   - `ecosystem.config.js`에서 메모리 제한 설정 확인\n   - PM2 모니터링으로 메모리 사용량 추적\n\n## 기여하기\n\n1. Fork the Project\n2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)\n3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)\n4. Push to the Branch (`git push origin feature/AmazingFeature`)\n5. Open a Pull Request\n\n## 라이선스\n\n이 프로젝트는 MIT 라이선스를 따릅니다. 자세한 내용은 [LICENSE](LICENSE) 파일을 참조하세요.\n\n## 연락처\n\n프로젝트 관리자: techkwon\n이메일: techkwon@example.com\n프로젝트 링크: [https://github.com/techkwon/mcp-gemini](https://github.com/techkwon/mcp-gemini)\n\n## 주요 의존성\n\n- @google/generative-ai: ^0.1.3 (Gemini API SDK)\n- @fastify/cors: ^8.5.0 (CORS 지원)\n- fastify: ^4.29.0 (웹 서버 프레임워크)\n- googleapis: ^148.0.0 (Google API 지원)\n- typescript: ^5.0.0\n- zod: ^3.24.2 (데이터 검증)\n- pino: ^8.21.0 (로깅)\n\n## Claude 데스크톱 앱 통합 가이드\n\n### 설정 파일 위치\nClaude 데스크톱 앱의 설정 파일은 다음 경로에 위치합니다:\n- Windows: `%APPDATA%/Claude/config.json`\n- macOS: `~/Library/Application Support/Claude/config.json`\n\n### JSON 설정 예시\n\n```json\n{\n  \"apis\": [\n    {\n      \"name\": \"MCP Gemini\",\n      \"url\": \"http://localhost:8000\",\n      \"methods\": [\n        {\n          \"name\": \"텍스트 생성\",\n          \"method\": \"gem-generate\",\n          \"template\": {\n            \"jsonrpc\": \"2.0\",\n            \"id\": \"{uuid}\",\n            \"method\": \"gem-generate\",\n            \"params\": {\n              \"prompt\": \"{input}\"\n            }\n          }\n        },\n        {\n          \"name\": \"이미지 생성\",\n          \"method\": \"gem-generate-image\",\n          \"template\": {\n            \"jsonrpc\": \"2.0\",\n            \"id\": \"{uuid}\",\n            \"method\": \"gem-generate-image\",\n            \"params\": {\n              \"prompt\": \"{input}\"\n            }\n          }\n        },\n        {\n          \"name\": \"비디오 분석\",\n          \"method\": \"gem-analyze-video\",\n          \"template\": {\n            \"jsonrpc\": \"2.0\",\n            \"id\": \"{uuid}\",\n            \"method\": \"gem-analyze-video\",\n            \"params\": {\n              \"videoUrl\": \"{input}\",\n              \"query\": \"이 영상의 주요 내용을 요약해주세요\"\n            }\n          }\n        },\n        {\n          \"name\": \"웹 검색\",\n          \"method\": \"gem-search\",\n          \"template\": {\n            \"jsonrpc\": \"2.0\",\n            \"id\": \"{uuid}\",\n            \"method\": \"gem-search\",\n            \"params\": {\n              \"query\": \"{input}\"\n            }\n          }\n        }\n      ]\n    }\n  ]\n}\n```\n\n### 변수 설명\n\n- `{uuid}`: 자동으로 생성되는 고유 요청 ID\n- `{input}`: Claude 채팅창에 입력한 텍스트\n\n### 사용 방법\n\n1. Claude 데스크톱 앱의 설정 파일을 엽니다.\n2. 위의 JSON 설정을 기존 설정에 추가합니다.\n3. Claude 데스크톱 앱을 재시작합니다.\n4. 채팅창에서 다음과 같이 사용할 수 있습니다:\n\n```\n@MCP Gemini.텍스트 생성 한국의 전통 음식에 대해 설명해주세요\n@MCP Gemini.이미지 생성 한옥마을의 아름다운 풍경\n@MCP Gemini.비디오 분석 https://youtube.com/watch?v=VIDEO_ID\n@MCP Gemini.웹 검색 최신 인공지능 기술 동향\n```\n\n### 응답 형식\n\n모든 API 응답은 다음 형식을 따릅니다:\n\n```json\n{\n  \"jsonrpc\": \"2.0\",\n  \"id\": \"요청에서 보낸 ID\",\n  \"result\": {\n    \"content\": \"응답 내용\"\n  }\n}\n```\n\n### 오류 응답\n\n오류가 발생한 경우 다음 형식으로 응답합니다:\n\n```json\n{\n  \"jsonrpc\": \"2.0\",\n  \"id\": \"요청에서 보낸 ID\",\n  \"error\": {\n    \"code\": 오류코드,\n    \"message\": \"오류 메시지\",\n    \"data\": {\n      \"details\": \"상세 오류 정보\"\n    }\n  }\n}\n```\n\n## 오류 처리\n\n서버는 다음과 같은 상황에서 적절한 오류 응답을 반환합니다:\n\n- 400: 잘못된 요청 형식\n- 401: 인증 오류 (API 키 관련)\n- 500: 서버 내부 오류\n\n## 보안 고려사항\n\n- API 키는 반드시 환경 변수로 관리하세요\n- 프로덕션 환경에서는 적절한 보안 설정을 추가하세요\n- 민감한 정보는 로그에 기록하지 않도록 주의하세요\n\n## 문제 해결\n\n### 포트 충돌\n이미 8000번 포트가 사용 중인 경우:\n```bash\n# 기존 Node.js 프로세스 종료\npkill -f \"node\"\n```\n\n### 서버 안정성\n서버가 예기치 않게 종료되는 경우:\n- PM2나 다른 프로세스 관리자 사용을 고려하세요\n- 로그를 확인하여 종료 원인을 파악하세요\n\n## 개발 가이드\n\n### 로깅\n- Pino 로거를 사용하여 구조화된 로깅을 구현했습니다\n- 개발 환경에서는 pino-pretty를 통해 가독성 있는 로그가 출력됩니다\n\n### 타입 안정성\n- TypeScript와 Zod를 사용하여 런타임 타입 안정성을 보장합니다\n- API 요청/응답에 대한 스키마 검증이 구현되어 있습니다\n\n## CLINE MCP 마켓플레이스 등록 가이드\n\n### 사전 준비사항\n\n1. GitHub 저장소가 공개되어 있어야 합니다\n2. README.md 파일에 명확한 설치 및 설정 방법이 포함되어 있어야 합니다\n3. (선택사항) `llms-install.md` 파일을 통해 AI 에이전트를 위한 추가 설치 가이드를 제공할 수 있습니다\n\n### 등록 절차\n\n1. [CLINE MCP 마켓플레이스 저장소](https://github.com/cline/mcp-marketplace)에 새로운 이슈를 생성합니다\n\n2. 이슈에 다음 정보를 포함합니다:\n   - **GitHub 저장소 URL:** https://github.com/techkwon/mcp-gemini\n   - **로고 이미지:** 400×400 크기의 PNG 파일\n   - **추가 이유:** 이 MCP 서버가 CLINE 사용자들에게 제공할 수 있는 가치\n   예시:\n   ```markdown\n   ## MCP Gemini 서버 등록 요청\n   \n   ### GitHub 저장소\n   https://github.com/techkwon/mcp-gemini\n   \n   ### 주요 기능\n   - Gemini API를 활용한 텍스트 생성\n   - 이미지 생성 및 편집 (gemini-2.0-flash-exp 모델 사용)\n   - YouTube 비디오 콘텐츠 분석\n   - 웹 검색 기능\n   \n   ### 사용자 이점\n   - 최신 Gemini 모델을 MCP 프로토콜을 통해 쉽게 활용\n   - 다양한 미디어 형식(텍스트, 이미지, 비디오) 처리 가능\n   - 명확한 JSON-RPC 인터페이스로 쉬운 통합\n   - 상세한 문서화와 예제 제공\n   ```\n\n3. CLINE이 README.md만으로 서버를 성공적으로 설치할 수 있는지 테스트합니다\n\n### 승인 절차\n\n1. CLINE 팀이 제출된 MCP 서버를 검토합니다\n2. 보안 및 안정성 검증을 진행합니다\n3. 승인되면 마켓플레이스에 등록되어 모든 CLINE 사용자가 접근할 수 있게 됩니다\n\n### 설치 가이드 최적화\n\n`llms-install.md` 파일을 생성하여 AI 에이전트를 위한 추가 설치 가이드를 제공할 수 있습니다:\n\n```markdown\n# MCP Gemini 서버 설치 가이드 (AI 에이전트용)\n\n## 환경 요구사항\n- Node.js 18.0.0 이상\n- npm 또는 yarn\n- Google AI Studio API 키\n\n## 설치 단계\n1. 저장소 클론\n2. 의존성 설치: `npm install`\n3. 환경 변수 설정: GOOGLE_API_KEY 추가\n4. 빌드: `npm run build`\n5. 서버 실행: `npm run start`\n\n## 설정 검증\n- 8000번 포트 사용 가능 여부 확인\n- API 키 유효성 검증\n- CORS 설정 확인\n\n## 문제 해결\n- 포트 충돌 시 해결 방법\n- API 키 오류 해결 방법\n- 일반적인 설치 문제 해결 가이드\n``` ",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ai",
        "gemini",
        "youtube",
        "google gemini",
        "gemini api",
        "mcp gemini"
      ],
      "category": "image-and-video-generation"
    },
    "tuki0918--eagle-mcp-server": {
      "owner": "tuki0918",
      "name": "eagle-mcp-server",
      "url": "https://github.com/tuki0918/eagle-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/tuki0918.webp",
      "description": "Integrates with the Eagle app to manage and interact with digital assets through a standardized MCP interface, enabling operations such as folder and item management, metadata retrieval, and media handling.",
      "stars": 3,
      "forks": 1,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-22T11:24:54Z",
      "readme_content": "# Eagle MCP Server (Unofficial)\n\n> [!NOTE]\n> [Official MCP support is planned for Eagle v5 (public beta in Q1 2026)](https://eagle.cool/blog/post/eagle5-teaser)\n\n\n\nA Model Context Protocol (MCP) server for Eagle.\n\n<details>\n\n<summary>Supported file formats:</summary>\n\n- `JPG` / `JPEG`\n- `PNG`\n- `PDF`\n- `SVG`\n- `MP4`\n- `MP3`\n- `FBX`\n- `OBJ`\n- `EPS`\n- `TIF` / `TIFF`\n- `WebP`\n- `BMP`\n- `ICO`\n- `RAW`\n- etc\n\n</details>\n\n- Eagle: https://eagle.cool/<br />\n- Eagle API docs: https://api.eagle.cool/<br />\n\n## Requirements\n\n- Python 3.13\n- [uv](https://docs.astral.sh/uv/)\n\n## Prerequisites\n\nInstall the required dependencies:\n\n```bash\nuv sync\n```\n\n## Usage\n\n1. Launch the [Eagle](https://eagle.cool/) app.\n2. Launch this MCP server by running the following command:\n\n```bash\nuv run main.py\n```\n\n\n## Connecting to the MCP Server using Streamable HTTP\n\nExample config (Cursor editor recommended):\n\n```\n{\n  \"mcpServers\": {\n    \"eagle-mcp-server\": {\n      \"url\": \"http://localhost:8000/mcp\"\n    }\n  }\n}\n```\n\n## Tools\n\n| Supported | Eagle API endpoint | Operation ID | Enabled (default) | Category |\n|:----:|:---------------------------|:-------------------------|:----:|:------------|\n| ✅ | -               | `connect`                |  | MCP         |\n| ✅ | /api/application/info      | `get_application_info`   | ⚫︎ | Application |\n| ✅ | /api/folder/create         | `create_folder`          | ⚫︎ | Folder      |\n| ✅ | /api/folder/rename         | `rename_folder`          |  | Folder      |\n| ✅ | /api/folder/update         | `update_folder`          | ⚫︎ | Folder      |\n| ✅ | /api/folder/list           | `get_folder_list`        | ⚫︎ | Folder      |\n| ✅ | /api/folder/listRecent     | `get_folder_list_recent` |  | Folder      |\n| ✅ | /api/item/addFromURL       | `add_item_from_url`      |  | Item        |\n| ✅ | /api/item/addFromURLs      | `add_items_from_urls`    |  | Item        |\n| ✅ | /api/item/addFromPath      | `add_item_from_path`     | ⚫︎ | Item        |\n| ✅ | /api/item/addFromPaths     | `add_items_from_paths`   |  | Item        |\n| ✅ | /api/item/addBookmark      | `add_bookmark`           |  | Item        |\n| ✅ | /api/item/info             | `get_item_info`          | ⚫︎ | Item        |\n| ✅ | -           | `get_item_source`        | ⚫︎ | Item        |\n| ✅ | /api/item/thumbnail        | `get_item_thumbnail`     |  | Item        |\n| ✅ | /api/item/list             | `get_item_list`          | ⚫︎ | Item        |\n| ✅ | /api/item/moveToTrash      | `move_item_to_trash`     | ⚫︎ | Item        |\n| ✅ | /api/item/refreshPalette   | `refresh_item_palette`   |  | Item        |\n| ✅ | /api/item/refreshThumbnail | `refresh_item_thumbnail` |  | Item        |\n| ✅ | /api/item/update           | `update_item`            | ⚫︎ | Item        |\n| ✅ | /api/library/info          | `get_library_info`       | ⚫︎ | Library     |\n| ✅ | /api/library/history       | `get_library_history`    |  | Library     |\n| ✅ | /api/library/switch        | `switch_library`         |  | Library     |\n| ✅ | /api/library/icon          | `get_library_icon`       |  | Library     |\n\nMCP Server API docs: \n- https://tuki0918.github.io/eagle-mcp-server/\n- http://localhost:8000/redoc\n\n## Enabling Disabled Tools\n\nSome tools are disabled by default (shown as empty cells in the \"Enabled (default)\" column above). To enable these disabled tools:\n\n1. Locate the tool definition in the source code\n2. Remove the `tags=[\"Disabled\"]` line from the tool configuration\n3. Restart the MCP server\n\nThis will make the previously disabled tools available for use.\n\n## Use Cases\n\n### 1) Same Host (Recommended)\n\n```mermaid\nflowchart LR\n\n    subgraph 192.168.1.100\n        direction LR\n        \n        subgraph FileSystem [File System]\n        end\n        subgraph EagleApp [Eagle App<br/>localhost:41595]\n        end\n        subgraph MCPServer [MCP Server<br/>localhost:8000]\n        end\n        subgraph MCPClient [MCP Client]\n        end\n    end\n\n    EagleApp ==> MCPServer e1@==> MCPClient\n    MCPClient e2@==> MCPServer ==> EagleApp\n    EagleApp ==> FileSystem\n    FileSystem ==> EagleApp\n\n    e1@{ animate: true }\n    e2@{ animate: true }\n```\n\n> [!TIP]\n> You have direct access to the filesystem.\n\n### 2) Other Host (MCP Client) + Same Host (MCP Server, Eagle App)\n\n```mermaid\nflowchart LR\n  \n    subgraph 192.168.1.100\n        subgraph FileSystem [File System]\n        end\n        subgraph EagleApp [Eagle App<br/>localhost:41595]\n        end\n        subgraph MCPServer [MCP Server<br/>localhost:8000]\n        end\n    end\n\n    subgraph 192.168.1.xxx\n        subgraph MCPClient [MCP Client]\n        end\n    end\n\n    EagleApp ==> MCPServer e1@==> MCPClient\n    MCPClient e2@==> MCPServer ==> EagleApp\n    EagleApp ==> FileSystem\n    FileSystem ==> EagleApp\n\n    e1@{ animate: true }\n    e2@{ animate: true }\n```\n\n> [!WARNING]\n> You don't have access to the filesystem.\n\n### 3) Other Host\n\n```mermaid\nflowchart LR\n\n    subgraph 192.168.1.100\n        subgraph FileSystem [File System]\n        end\n        subgraph EagleApp [Eagle App<br/>localhost:41595]\n        end\n    end\n\n    subgraph 192.168.1.101\n        subgraph MCPServer [MCP Server<br/>localhost:8000]\n        end\n    end\n\n    subgraph 192.168.1.xxx\n        subgraph MCPClient [MCP Client]\n        end\n    end\n\n    EagleApp ==> MCPServer e1@==> MCPClient\n    MCPClient e2@==> MCPServer ==> EagleApp\n    EagleApp ==> FileSystem\n    FileSystem ==> EagleApp\n\n    e1@{ animate: true }\n    e2@{ animate: true }\n```\n\n> [!WARNING]\n> You don't have access to the filesystem.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcp",
        "eagle",
        "server",
        "eagle mcp",
        "mcp server",
        "eagle app"
      ],
      "category": "image-and-video-generation"
    },
    "tzafrir--mcp-server-replicate": {
      "owner": "tzafrir",
      "name": "mcp-server-replicate",
      "url": "https://github.com/tzafrir/mcp-server-replicate",
      "imageUrl": "/freedevtools/mcp/pfp/tzafrir.webp",
      "description": "Access various AI models hosted on Replicate through a standardized interface for image generation with customizable parameters, enabling output resizing and optimization. Future enhancements will include text and video generation features.",
      "stars": 3,
      "forks": 1,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-05-05T06:38:38Z",
      "readme_content": "# MCP Server for Replicate\n\nA FastMCP server implementation for interfacing with Replicate's API. This server provides tools for accessing various AI models hosted on Replicate through a standardized interface.\n\n## Current Status: Early Alpha\n\nThis project is in early alpha development. Features and APIs may change significantly.\n\n### Currently Supported\n- Image generation models with:\n  - Model schema inspection\n  - Image generation with customizable parameters\n  - Output resizing and optimization\n\n## Roadmap\n\n### Planned Features\n1. Text Generation\n   - Support for text completion models\n   - Chat model integration\n   - Streaming support for real-time responses\n\n2. Video Generation\n   - Support for video generation models\n   - Video output handling and optimization\n   - Progress tracking for long-running generations\n\n3. Additional Features\n   - Model version management\n   - Better error handling and retries\n   - Caching for frequently used models\n   - Rate limiting and queue management\n\n## Setup\n\n1. Install dependencies:\n```bash\npip install -r requirements.txt\n```\n\n2. Set up your Replicate API token in `.env`:\n```\nREPLICATE_API_TOKEN=your_token_here\n```\n\n3. Run the server:\n```bash\nfastmcp dev server.py\n```\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "replicate",
        "ai",
        "mcp",
        "video generation",
        "server replicate",
        "image generation"
      ],
      "category": "image-and-video-generation"
    },
    "video-creator--ffmpeg-mcp": {
      "owner": "video-creator",
      "name": "ffmpeg-mcp",
      "url": "https://github.com/video-creator/ffmpeg-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/video-creator.webp",
      "description": "Enables local video search, trimming, stitching, and playback through conversational commands using ffmpeg. Provides tools for finding, clipping, concatenating, and playing video files on macOS platforms.",
      "stars": 84,
      "forks": 14,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-04T04:24:05Z",
      "readme_content": "# FFmpeg-MCP\nUsing ffmpeg command line to achieve an mcp server, can be very convenient, through the dialogue to achieve the local video search, tailoring, stitching, playback and other functions\n\n<a href=\"https://glama.ai/mcp/servers/@video-creator/ffmpeg-mcp\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@video-creator/ffmpeg-mcp/badge\" alt=\"FFmpeg-Server MCP server\" />\n</a>\n\n## Support Tools\nThe server implements the following tools: <br/>\n- `find_video_path`\n  The parameters are directory and file name, file name can be complete, or is not suffixed, recursive search in the directory, return the full path\n- `get_video_info`\n  The parameters are video path, return the video info, linkes duration/fps/codec/width/height.\n- `clip_video`\n  The parameter is the file path, start time, end time or duration, and returns the trimmed file path\n- `concat_videos`\n  The parameters are the list of files, the output path, and if the video elements in the list of files, such as width, height, frame rate, etc., are consistent, quick mode synthesis is automatically used\n- `play_video`\n  Play video/audio with ffplay, support many format, like mov/mp4/avi/mkv/3gp, video_path: video path speed: play rate loop: play count\n- `overlay_video`\n  Two video overlay. <br/>\n  background_video: backgroud video path <br/>\n  overlay_video: front video path <br/>\n  output_path: output video path<br/>\n  position: relative location<br/>\n  dx: x offset<br/>\n  dy: y offset<br/>\n- `scale_video`\n  Video scale. <br/>\n  video_path: in video path <br/>\n  width: out video width, -2 keep aspect <br/>\n  height: out video height, -2 keep aspect <br/>\n  output_path: output video path <br/>\n- `extract_frames_from_video`\n  Extract images from a video.<br/>\n  Parameters: <br/>\n  video_path (str): The path to the video.<br/>\n  fps (int): Extract one frame every specified number of seconds. If set to 0, extract all frames; if set to 1, extract one frame per second.<br/>\n  output_folder (str): The directory where the images will be saved.<br/>\n  format (int): The format of the extracted images; 0: PNG, 1: JPG, 2: WEBP.<br/>\n  total_frames (int): The maximum number of frames to extract. If set to 0, there is no limit<br/>\n<br/>\nMore features are coming\n\n## Installation procedure\n1. Download project\n```\ngit clone  https://github.com/video-creator/ffmpeg-mcp.git\ncd ffmpeg-mcp\nuv sync\n```\n\n2. Configuration in Cline\n```\n{\n  \"mcpServers\": {\n    \"ffmpeg-mcp\": {\n      \"autoApprove\": [],\n      \"disabled\": false,\n      \"timeout\": 60,\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/Users/xxx/Downloads/ffmpeg-mcp\",\n        \"run\",\n        \"ffmpeg-mcp\"\n      ],\n      \"transportType\": \"stdio\"\n    }\n  }\n}\n```\nNote: the value:`/Users/XXX/Downloads/ffmpeg` in args  need to replace the actual download ffmpeg-mcp directory\n\n## Supported platforms\nCurrently, only macos platforms are supported, including ARM64 or x86_64",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ffmpeg",
        "mcp",
        "macos",
        "ffmpeg mcp",
        "ffmpeg provides",
        "creator ffmpeg"
      ],
      "category": "image-and-video-generation"
    },
    "vishwa684--unet": {
      "owner": "vishwa684",
      "name": "unet",
      "url": "https://github.com/vishwa684/unet",
      "imageUrl": "/freedevtools/mcp/pfp/vishwa684.webp",
      "description": "Train and deploy U-Net models for biomedical image segmentation using the Medical Decathlon dataset, with support for both 2D and 3D U-Net scripts. Visualize predictions and assess model performance through comprehensive demos and visual outputs.",
      "stars": 0,
      "forks": 0,
      "license": "Apache License 2.0",
      "language": "",
      "updated_at": "2024-05-11T00:13:12Z",
      "readme_content": "# Deep Learning Medical Decathlon Demos for Python*\n### U-Net Biomedical Image Segmentation with Medical Decathlon Dataset.\n\nThis repository contains [2D](https://github.com/IntelAI/unet/tree/master/2D) and [3D](https://github.com/IntelAI/unet/tree/master/3D) U-Net scripts for training models using the [Medical Decathlon](http://medicaldecathlon.com/) dataset (http://medicaldecathlon.com/).\n\n![pred152_3D](https://github.com/IntelAI/unet/blob/master/3D/images/BRATS_152_img3D.gif\n\"BRATS image #152:  Purple voxels indicate a perfect prediction by the model. Red are false positives. Blue are false negatives\").  ![pred195](https://github.com/IntelAI/unet/blob/master/3D/images/BRATS_195_img.gif \"BRATS image #195:  Purple voxels indicate a perfect prediction by the model. Red are false positives. Blue are false negatives\")\n\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "segmentation",
        "biomedical",
        "dataset",
        "biomedical image",
        "models biomedical",
        "decathlon dataset"
      ],
      "category": "image-and-video-generation"
    },
    "wheattoast11--mcp-video-gen": {
      "owner": "wheattoast11",
      "name": "mcp-video-gen",
      "url": "https://github.com/wheattoast11/mcp-video-gen",
      "imageUrl": "/freedevtools/mcp/pfp/wheattoast11.webp",
      "description": "Generate videos and images from text prompts or existing images using advanced AI models, with capabilities for audio addition, content upscaling, and prompt enhancement. Manage and refine AI-generated content through API interactions with RunwayML and Luma AI.",
      "stars": 11,
      "forks": 2,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-09-24T02:58:53Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/wheattoast11-mcp-video-gen-badge.png)](https://mseep.ai/app/wheattoast11-mcp-video-gen)\n\n# RunwayML + Luma AI MCP Server\n\nThis MCP server provides tools to interact with the RunwayML and Luma AI APIs for video and image generation tasks.\n\n## Features\n\n*   Generate videos from text prompts (RunwayML or Luma AI).\n*   Generate videos from images (RunwayML or Luma AI).\n*   Generate images from text prompts (Luma AI).\n*   Manage Luma AI generations (list, get, delete).\n*   Add audio to Luma AI generations.\n*   Upscale Luma AI generations.\n*   Enhance prompts using OpenRouter LLMs before generation.\n\n## Prerequisites\n\n*   Node.js (v18 LTS or later recommended)\n*   npm (usually included with Node.js)\n*   API Keys:\n    *   RunwayML API Secret\n    *   Luma AI API Key\n    *   OpenRouter API Key (for the `enhance_prompt` tool)\n\n## Installation\n\n1.  **Clone or Download:** Obtain the server code.\n2.  **Navigate to Directory:** Open a terminal in the server's root directory (`runwayml-mcp-server`).\n3.  **Install Dependencies:**\n    ```bash\n    npm install\n    ```\n\n## Configuration\n\n1.  **Create `.env` file:** In the server's root directory, create a file named `.env`.\n2.  **Add API Keys:** Add your API keys to the `.env` file:\n    ```dotenv\n    RUNWAYML_API_SECRET=your_runwayml_api_secret_here\n    LUMAAI_API_KEY=your_luma_api_key_here\n    OPENROUTER_API_KEY=your_openrouter_api_key_here\n    ```\n    Replace the placeholder values with your actual keys.\n\n## Running the Server\n\n1.  **Build the Server:** Compile the TypeScript code:\n    ```bash\n    npm run build\n    ```\n2.  **Start the Server:**\n    ```bash\n    npm start\n    ```\n    You should see a message like `RunwayML MCP server running on stdio` in your terminal's error output (stderr).\n\n## MCP Client Setup (e.g., Claude Desktop App, Cline)\n\nConfigure your MCP client to connect to this server. The exact steps depend on the client, but you'll typically need to provide:\n\n*   **Name:** A descriptive name (e.g., `runway-luma-server`)\n*   **Command:** `node`\n*   **Arguments:** The full path to the compiled server index file (e.g., `/path/to/your/runwayml-mcp-server/build/server-index.js`)\n*   **Environment Variables:**\n    *   `RUNWAYML_API_SECRET`: Your RunwayML API Secret\n    *   `LUMAAI_API_KEY`: Your Luma AI API Key\n    *   `OPENROUTER_API_KEY`: Your OpenRouter API Key\n\n**Example Configuration (Conceptual):**\n\n```json\n{\n  \"mcpServers\": {\n    \"runway-luma-server\": {\n      \"command\": \"node\",\n      \"args\": [\"/full/path/to/runwayml-mcp-server/build/server-index.js\"],\n      \"env\": {\n        \"RUNWAYML_API_SECRET\": \"your_runwayml_api_secret_here\",\n        \"LUMAAI_API_KEY\": \"your_luma_api_key_here\",\n        \"OPENROUTER_API_KEY\": \"your_openrouter_api_key_here\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n*(Remember to replace `/full/path/to/` with the actual path on your system)*\n\n## Available Tools\n\n*   **`generate_text_to_video`**: Generates video from text.\n    *   `provider`: (Optional) `runwayml` (default) or `lumaai`.\n    *   `promptText`: (Required) The text prompt.\n    *   `runway_model`: (Optional) Runway model (e.g., \"gen-2\").\n    *   `runway_resolution`: (Optional) Runway resolution (`1280:768` or `768:1280`).\n    *   `runway_watermark`: (Optional) Boolean, default `false`.\n    *   `luma_model`: (Optional) Luma model (`ray-flash-2`, `ray-2` (default), `ray-1-6`).\n    *   `luma_aspect_ratio`: (Optional) Luma aspect ratio (e.g., `16:9` (default), `1:1`).\n    *   `luma_loop`: (Optional) Boolean.\n    *   `duration`: (Optional) Video duration in seconds (number).\n    *   `seed`: (Optional) Generation seed (number).\n*   **`generate_image_to_video`**: Generates video from an image.\n    *   `provider`: (Optional) `runwayml` (default) or `lumaai`.\n    *   `promptImage`: (Required) URL of the input image, or for Runway, an array `[{uri: \"url\", position: \"first\" | \"last\"}]`.\n    *   `promptText`: (Optional) Text prompt to accompany the image.\n    *   `runway_model`: (Optional) Runway model (`gen3a_turbo` (default)).\n    *   `runway_duration`: (Optional) Runway duration (`5` (default) or `10`).\n    *   `runway_ratio`: (Optional) Runway resolution (`1280:768` or `768:1280`).\n    *   `runway_watermark`: (Optional) Boolean, default `false`.\n    *   `luma_model`: (Optional) Luma model (`ray-flash-2`, `ray-2` (default), `ray-1-6`).\n    *   `luma_aspect_ratio`: (Optional) Luma aspect ratio (e.g., `16:9` (default)).\n    *   `luma_loop`: (Optional) Boolean.\n    *   `seed`: (Optional) Generation seed (number).\n*   **`enhance_prompt`**: Refines a prompt using OpenRouter.\n    *   `original_prompt`: (Required) The prompt to enhance.\n    *   `model`: (Optional) OpenRouter model name (defaults to a capable model like `anthropic/claude-3.5-sonnet`).\n    *   `instructions`: (Optional) Specific instructions for the enhancement.\n*   **`luma_generate_image`**: Generates an image using Luma AI.\n    *   `prompt`: (Required) Text prompt.\n    *   `aspect_ratio`: (Optional) Luma aspect ratio (`16:9` (default)).\n    *   `model`: (Optional) Luma image model (`photon-1` (default), `photon-flash-1`).\n    *   `image_ref`: (Optional) Array of image reference objects (`{url: string, weight?: number}`). Max 4.\n    *   `style_ref`: (Optional) Array of style reference objects (`{url: string, weight?: number}`). Max 1.\n    *   `character_ref`: (Optional) Character reference object (`{ identity0: { images: [url1, ...] } }`).\n    *   `modify_image_ref`: (Optional) Modify image reference object (`{url: string, weight?: number}`).\n*   **`luma_list_generations`**: Lists previous Luma AI generations.\n    *   `limit`: (Optional) Number of results (default 10).\n    *   `offset`: (Optional) Offset for pagination (default 0).\n*   **`luma_get_generation`**: Gets details for a specific Luma AI generation.\n    *   `generation_id`: (Required) UUID of the generation.\n*   **`luma_delete_generation`**: Deletes a specific Luma AI generation.\n    *   `generation_id`: (Required) UUID of the generation.\n*   **`luma_get_camera_motions`**: Lists supported camera motions for Luma AI prompts. (No parameters).\n*   **`luma_add_audio`**: Adds audio to a Luma generation.\n    *   `generation_id`: (Required) UUID of the generation.\n    *   `prompt`: (Required) Prompt for the audio.\n    *   `negative_prompt`: (Optional) Negative prompt for audio.\n*   **`luma_upscale`**: Upscales a Luma generation.\n    *   `generation_id`: (Required) UUID of the generation.\n    *   `resolution`: (Optional) Target resolution (`1080p` (default) or `4k`).\n\n*(Note: For tools involving generation (`generate_*`, `luma_upscale`), the server initiates the task and returns immediately. Progress updates and the final result URL will be sent via MCP progress notifications.)*\n\n## Example Workflows\n\nHere are examples of how to combine the server's tools for common use cases:\n\n### 1. Music Video Snippet (Cyberpunk Noir)\n\n**Goal:** Create a 5-second cyberpunk noir video clip for the lyric \"Neon rivers flowing through a city of chrome\".\n\n**Steps:**\n\n1.  **Generate Base Image (Luma):**\n    ```json\n    {\n      \"tool_name\": \"luma_generate_image\",\n      \"arguments\": {\n        \"prompt\": \"Overhead shot of a dark, rainy cyberpunk city street at night. Bright neon signs reflect on wet pavement, resembling rivers of light flowing between towering chrome skyscrapers. Film noir aesthetic, photorealistic.\",\n        \"aspect_ratio\": \"16:9\"\n      }\n    }\n    ```\n    *(Wait for image generation to complete and get the image URL)*\n\n2.  **Animate Image (Luma):**\n    ```json\n    {\n      \"tool_name\": \"generate_image_to_video\",\n      \"arguments\": {\n        \"provider\": \"lumaai\",\n        \"promptImage\": \"{IMAGE_URL_FROM_STEP_1}\",\n        \"promptText\": \"Slow pan left across the rainy cyberpunk cityscape, neon lights flickering subtly.\",\n        \"luma_aspect_ratio\": \"16:9\",\n        \"duration\": 5\n      }\n    }\n    ```\n    *(Wait for video generation to complete)*\n\n### 2. Product Ad Concept (Floating Earbud)\n\n**Goal:** Create a 5-second video showing a futuristic earbud floating in a minimalist environment.\n\n**Steps:**\n\n1.  **Generate Scene with Product Reference (Luma):**\n    ```json\n    {\n      \"tool_name\": \"luma_generate_image\",\n      \"arguments\": {\n        \"prompt\": \"A single, sleek futuristic wireless earbud floats weightlessly in the center of a bright, minimalist white room with soft, diffused ambient light. Zero gravity effect.\",\n        \"aspect_ratio\": \"1:1\",\n        \"image_ref\": [{ \"url\": \"{PRODUCT_IMAGE_URL}\", \"weight\": 0.8 }]\n      }\n    }\n    ```\n    *(Wait for image generation to complete and get the image URL)*\n\n2.  **Animate Scene (Luma):**\n    ```json\n    {\n      \"tool_name\": \"generate_image_to_video\",\n      \"arguments\": {\n        \"provider\": \"lumaai\",\n        \"promptImage\": \"{IMAGE_URL_FROM_STEP_1}\",\n        \"promptText\": \"The earbud slowly rotates and drifts gently in zero gravity.\",\n        \"luma_aspect_ratio\": \"1:1\",\n        \"duration\": 5\n      }\n    }\n    ```\n    *(Wait for video generation to complete)*\n\n### 3. Image Animation (RunwayML Gen3a)\n\n**Goal:** Animate an existing image using RunwayML's Gen3a model.\n\n**Steps:**\n\n1.  **(Optional) Generate Base Image (Luma):** Use `luma_generate_image` if you don't have an image.\n2.  **Animate Image (RunwayML):**\n    ```json\n    {\n      \"tool_name\": \"generate_image_to_video\",\n      \"arguments\": {\n        \"provider\": \"runwayml\",\n        \"promptImage\": \"{YOUR_IMAGE_URL}\",\n        \"promptText\": \"Subtle zoom in, cinematic lighting.\",\n        \"runway_model\": \"gen3a_turbo\",\n        \"runway_duration\": \"5\",\n        \"runway_ratio\": \"1280:768\" // Or \"768:1280\"\n      }\n    }\n    ```\n    *(Wait for video generation to complete)*\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ai",
        "videos",
        "runwayml",
        "video generation",
        "generate videos",
        "ai generated"
      ],
      "category": "image-and-video-generation"
    },
    "whiteking64--macos-ocr-mcp": {
      "owner": "whiteking64",
      "name": "macos-ocr-mcp",
      "url": "https://github.com/whiteking64/macos-ocr-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/whiteking64.webp",
      "description": "Perform Optical Character Recognition (OCR) on images with the help of macOS's Vision framework, extracting recognized text segments, confidence scores, and bounding box coordinates. Suitable for applications that require text extraction from image files.",
      "stars": 1,
      "forks": 1,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-06-07T18:16:13Z",
      "readme_content": "# macOS OCR MCP Tool\n\nThis project provides a MetaCall Protocol (MCP) tool to perform Optical Character Recognition (OCR) on images using macOS's built-in Vision framework. It exposes an `ocr_image` tool that takes an image file path and returns the recognized text along with confidence scores and bounding boxes.\n\n## Project Setup\n\n### Dependencies\nThis project relies on Python 3.13+ and the following main dependencies:\n- `ocrmac`: For accessing macOS OCR capabilities. See [ocrmac](https://github.com/straussmaximilian/ocrmac).\n- `Pillow`: For image manipulation.\n- `mcp[cli]>=1.7.1`: For the MetaCall Protocol server and client.\n\n### Installation\nIt is recommended to use a virtual environment.\n\n1.  **Create and activate a virtual environment:**\n    ```bash\n    python -m venv .venv\n    source .venv/bin/activate\n    ```\n\n2.  **Install dependencies using `uv`:**\n    ```bash\n    uv sync\n    ```\n\n## Running the MCP Server\n\nTo start the MCP server, run `main.py`:\n```bash\nuv run main.py\n```\nThis will start the MCP server, making the `ocr_image` tool available.\n\n## Available MCP Tools\n\n### `ocr_image`\n-   **Description:** Conducts OCR on the provided image file using macOS's built-in capabilities. Returns recognized text segments, their confidence scores, and bounding box coordinates.\n-   **Input:** `file_path: str` - The absolute or relative path to the image file.\n-   **Output (Example Success):**\n    ```json\n    {\n      \"filename\": \"path/to/your/image.png\",\n      \"annotations\": [\n        {\n          \"text\": \"Hello World\",\n          \"confidence\": 0.95,\n          \"bounding_box\": [0.1, 0.1, 0.5, 0.05] \n        },\n        // ... more annotations\n      ]\n    }\n    ```\n-   **Output (Example Error):**\n    ```json\n    {\n      \"error\": \"OCR functionality is only available on macOS.\"\n    }\n    ```\n    or\n    ```json\n    {\n      \"error\": \"File not found: path/to/nonexistent/image.png\"\n    }\n    ```\n\n**Note:** This tool will only function correctly on a macOS system due to its reliance on the Vision framework.\n\n## Testing with MCP Inspector\n\nYou can use the [MCP Inspector](https://github.com/modelcontextprotocol/inspector) to connect to the running MCP server and test the tool.\n\n## Cursor MCP Configuration\n\nTo configure this MCP server in Cursor, you can add the following to your MCP JSON configuration file (e.g., `~/.cursor/mcp.json` or project-specific `.cursor/mcp.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"ocrmac\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/path/to/macos-ocr-mcp\",\n        \"run\",\n        \"main.py\"\n      ]\n    }\n  }\n}\n```\n\nThis configuration tells Cursor how to start your MCP server. You can then call the `ocrmac.ocr_image` tool from within Cursor.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ocr",
        "macos",
        "recognition",
        "macos ocr",
        "ocr mcp",
        "ocr images"
      ],
      "category": "image-and-video-generation"
    },
    "xenoailimited--mcp-mavae": {
      "owner": "xenoailimited",
      "name": "mcp-mavae",
      "url": "https://github.com/xenoailimited/mcp-mavae",
      "imageUrl": "/freedevtools/mcp/pfp/xenoailimited.webp",
      "description": "A Model Context Protocol (MCP) server for interacting with image media tools, providing capabilities for image generation, editing, and management of collections and models.",
      "stars": 0,
      "forks": 1,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-04-24T16:15:59Z",
      "readme_content": "# MAVAE - IMAGE TOOLBOX\nA powerful creative and editing toolkit designed for AI Agents.\n\n[![smithery badge](https://smithery.ai/badge/@xenoailimited/mavae-image-toolbox)](https://smithery.ai/server/@xenoailimited/mavae-image-toolbox)\n[![TypeScript](https://img.shields.io/badge/TypeScript-007ACC?style=for-the-badge&logo=typescript&logoColor=white)](https://www.typescriptlang.org/)\n[![Node.js](https://img.shields.io/badge/Node.js-339933?style=for-the-badge&logo=nodedotjs&logoColor=white)](https://nodejs.org/)\n[![MCP](https://img.shields.io/badge/MCP-Model_Context_Protocol-blue?style=for-the-badge)](https://github.com/anthropics/model-context-protocol)\n[![Docker](https://img.shields.io/badge/Docker-2CA5E0?style=for-the-badge&logo=docker&logoColor=white)](https://www.docker.com/)\n\nMAVAE is a Model Context Protocol (MCP) server for interacting with image media tools. It provides a standardized interface for AI Agents to generate and manipulate images.\n\n## 🚀 Features\n\n- **Image Generation**: Generate images using both raw configurations and predefined collections\n- **Image Editing**: Compress, crop, and resize images with proportional or fixed dimensions\n- **Collection Management**: Create, manage, and share configurations for consistent image generation\n- **Model & Lora Management**: List and utilize available models and Loras\n- **API Token Management**: Handle authentication for secure interaction with Mavae services\n\n## 📋 Prerequisites\n\n- Node.js (v16 or higher)\n- MAVAE API Key (set as environment variable, [Apply here](https://mcp.mavae.ai/))\n\n## 🛠️ Installation\n\n```bash\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n\n# Start the server\nnpm start\n```\n\n## MCP Json\n```json\n{\n  \"mcpServers\": {\n      \"mavae\": {\n          \"command\": \"node\",\n          \"args\": [\n              \"***/dist/index.js\"\n          ],\n          \"env\": {\n              \"MAVAE_API_KEY\": MAVAE_API_KEY\n          }\n      }\n  }\n}\n```\nWhen using MAVAE MCP locally, this path is an absolute path 👉🏻 \"***/dist/index.js\"\n\n## 🐳 Docker Support\n\n```bash\n# Build Docker image\ndocker build -t mavae-mcp-server .\n\n# Run Docker container\ndocker run -e MAVAE_API_KEY=your_api_key mavae-mcp-server\n```\n\n## 📁 Project Structure\n\n```\nmavae/\n├── src/                  # Source code\n│   ├── actions/          # API endpoint implementation handlers\n│   │   ├── aigc.ts       # Image generation operations\n│   │   ├── collection.ts # Collection management operations\n│   │   ├── edit.ts       # Image editing operations\n│   │   └── token.ts      # API token operations\n│   ├── tools/            # MCP tool definitions\n│   │   ├── aigc.ts       # Image generation tool definitions\n│   │   ├── collection.ts # Collection management tool definitions\n│   │   └── edit.ts       # Image editing tool definitions\n│   ├── types/            # TypeScript type definitions\n│   │   ├── aigc.ts       # Image generation types\n│   │   ├── collection.ts # Collection types\n│   │   ├── edit.ts       # Image editing types\n│   │   └── response.ts   # API response types\n│   ├── utils/            # Utility functions\n│   │   └── constants.ts  # Constant values\n│   └── index.ts          # Server entry point\n├── dist/                 # Compiled JavaScript files\n├── package.json          # Project dependencies and scripts\n└── tsconfig.json         # TypeScript configuration\n```\n\n## 🛍️ Available Tools\n\n### Image Generation\n- `image_raw_generate` - Generate an image using raw AIGC configuration\n- `image_collection_generate` - Generate an image using a collection's AIGC configuration\n- `image_retry_generate` - Retry a failed image generation\n- `image_state` - Get the details of an owned image\n- `generate_task_state` - Get the generation state of an image by task id\n\n### Collection Management\n- `collection_create` - Create a new collection\n- `collection_delete` - Delete a collection\n- `collection_toggle_public` - Toggle the public status of a collection\n- `collection_list` - Get the list of owned collections\n- `collection_state` - Get the details of an owned collection\n\n### Image Editing\n- `compress_image` - Lossless compression of images\n- `crop_image` - Crop images with local path and URL support\n- `resize_image` - Resize images with proportional or fixed dimensions\n\n### Model & Resources\n- `list_images` - Get the list of owned images\n- `list_loras` - Get the list of available loras\n- `list_models` - Get the list of available models\n\n### Authentication\n- `token_state` - Get the x-api-token state\n\n\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcp",
        "mavae",
        "protocol",
        "mcp mavae",
        "xenoailimited mcp",
        "mcp server"
      ],
      "category": "image-and-video-generation"
    },
    "xixilidao--osgearth": {
      "owner": "xixilidao",
      "name": "osgearth",
      "url": "https://github.com/xixilidao/osgearth",
      "imageUrl": "/freedevtools/mcp/pfp/xixilidao.webp",
      "description": "Add geospatially accurate 3D maps to C++ applications, enabling developers to integrate and display complex geographical data visually.",
      "stars": 0,
      "forks": 0,
      "license": "Other",
      "language": "",
      "updated_at": "2024-10-07T03:14:53Z",
      "readme_content": "![Windows](https://github.com/gwaldron/osgearth/actions/workflows/windows.yml/badge.svg)\n![Linux](https://github.com/gwaldron/osgearth/actions/workflows/linux.yml/badge.svg)\n![OSX](https://github.com/gwaldron/osgearth/actions/workflows/macos.yml/badge.svg)\n\n\n## Welcome to osgEarth!\n\nosgEarth adds geospatially accurate 3D maps to your C++ application.\n\n<img src=\"https://github.com/user-attachments/assets/a0b1c650-442a-4e6d-88e6-42a5c92083b8\" width=\"200\" height=\"140\"/>\n<img src=\"https://github.com/user-attachments/assets/08d0f8c0-49e1-41a8-8b97-d663337f1cbb\" width=\"200\" height=\"140\"/>\n<img src=\"https://github.com/user-attachments/assets/575315e1-e2ae-43ec-8a97-83bafcfa9131\" width=\"200\" height=\"140\"/>\n<img src=\"https://github.com/user-attachments/assets/24971c79-f93c-48eb-ab79-161bb35beae4\" width=\"200\" height=\"140\"/>\n<img src=\"https://github.com/user-attachments/assets/cf40e4a9-429d-4cac-9464-f9825149e7f2\" width=\"200\" height=\"140\"/>\n<img src=\"https://github.com/user-attachments/assets/1cd49290-9b2d-42ec-a8c3-9c1c38eb673c\" width=\"200\" height=\"140\"/>\n<img src=\"https://github.com/user-attachments/assets/bfd869fd-32b5-48b5-a037-4951f812b757\" width=\"200\" height=\"140\"/>\n<img src=\"https://github.com/user-attachments/assets/1876fffb-e683-4fa9-9521-cdd9795dea85\" width=\"200\" height=\"140\"/>\n\nosgEarth builds on trusted open source technologies like OpenSceneGraph and GDAL to give you high-performance, accurate terrain and map rendering. It supports a myriad of geospatial data formats and map projections.\n\n## Install the SDK\n\nWindows users can install the latest version of osgEarth through `vcpkg`:\n```bat\ngit clone https://github.com/microsoft/vcpkg.git\ncd vcpkg && bootstrap-vcpkg.bat\nvcpkg install osgearth:x64-windows\n```\nThis will take a while the first time as vcpkg builds osgEarth and its dependencies.\n\n## Check out some examples\n\n`osgearth_imgui` is the main command-line viewer. `osgearth_viewer` is a stripped-down viewer without any GUI.\nBoth of these read \"earth files\", XML files that describe the contents of a map.\n\nYou can find example earth files in the `tests` folder of the repo.\n\n```bat\n:: Online imagery and elevation:\nosgearth_imgui tests\\readymap.earth\n\n:: OpenStreetMap:\nosgearth_imgui tests\\osm.earth\n\n:: Local GeoTIFFs:\nosgearth_imgui tests\\simple.earth \n```\n\n## Integrate it into your project\n\nCMakeLists.txt\n```cmake\ncmake_minimum_required(VERSION 3.20)\nproject(myApp)\nfind_package(osgEarth CONFIG REQUIRED)\nadd_executable(myApp main.cpp)\ntarget_link_libraries(myApp PRIVATE osgEarth::osgEarth)\ninstall(TARGETS myApp RUNTIME DESTINATION bin)\n```\nmain.cpp\n```c++\n#include <osgEarth/MapNode>\n#include <osgEarth/TMS>\n#include <osgEarth/EarthManipulator>\n#include <osg/ArgumentParser>\n#include <osgViewer/Viewer>\n\nint main(int argc, char** argv)\n{\n    osgEarth::initialize();\n    \n    osg::ArgumentParser args(&argc, argv);\n    osgViewer::Viewer viewer(args);\n    \n    auto imagery = new osgEarth::TMSImageLayer();\n    imagery->setURL(\"https://readymap.org/readymap/tiles/1.0.0/7/\");\n    \n    auto mapNode = new osgEarth::MapNode();\n    mapNode->getMap()->addLayer(imagery);\n    \n    viewer.setSceneData(mapNode);\n    viewer.setCameraManipulator(new osgEarth::EarthManipulator(args));\n    \n    return viewer.run();\n}\n```\n\n## Resources\n\n* [Documentation](http://docs.osgearth.org/en/latest/)\n* [Gallery](https://www.pelicanmapping.com/home-1/opensource)\n* [Custom Software Development](https://www.pelicanmapping.com/software)\n\n---\n© Copyright [Pelican Mapping](http://pelicanmapping.com)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "3d",
        "maps",
        "geospatially",
        "3d maps",
        "maps applications",
        "accurate 3d"
      ],
      "category": "image-and-video-generation"
    },
    "xiyuefox--mcp-hfspace": {
      "owner": "xiyuefox",
      "name": "mcp-hfspace",
      "url": "https://github.com/xiyuefox/mcp-hfspace",
      "imageUrl": "/freedevtools/mcp/pfp/xiyuefox.webp",
      "description": "Connect to Hugging Face Spaces to access various AI models for tasks like image generation and text-to-speech with minimal setup. Leverage the default model for seamless integration into applications.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "",
      "updated_at": "2025-03-10T03:52:55Z",
      "readme_content": "# mcp-hfspace MCP Server 🤗\n\nRead the introduction here [llmindset.co.uk/resources/mcp-hfspace/](https://llmindset.co.uk/resources/mcp-hfspace/)\n\nConnect to [Hugging Face Spaces](https://huggingface.co/spaces)  with minimal setup needed - simply add your spaces and go!\n\nBy default, it connects to `evalstate/FLUX.1-schnell` providing Image Generation capabilities to Claude Desktop.\n\n\n\n## Installation\n\nNPM Package is `@llmindset/mcp-hfspsace`.\n\nInstall a recent version of [NodeJS](https://nodejs.org/en/download) for your platform, then add the following to the `mcpServers` section of your `claude_desktop_config.json` file:\n\n```json\n    \"mcp=hfspace\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@llmindset/mcp-hfspace\"\n      ]\n    }\n```\n\nPlease make sure you are using Claude Desktop 0.78 or greater.\n\nThis will get you started with an Image Generator.\n\n### Basic setup\n\nSupply a list of HuggingFace spaces in the arguments. mcp-hfspace will find the most appropriate endpoint and automatically configure it for usage. An example `claude_desktop_config.json` is supplied [below](#installation).\n\nBy default the current working directory is used for file upload/download. On Windows this is a read/write folder at `\\users\\<username>\\AppData\\Roaming\\Claude\\<version.number\\`, and on MacOS it is the is the read-only root: `/`.\n\nIt is recommended to override this and set a Working Directory for handling the upload and download of images and other file-based content. Specify either the `--work-dir=/your_directory` argument or `MCP_HF_WORK_DIR` environment variable.\n\nAn example configuration for using a modern image generator, vision model and text to speech is below with a working directory set is below:\n\n```json\n    \"mcp-hfspace\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@llmindset/mcp-hfspace\",\n        \"--work-dir=/Users/evalstate/mcp-store\",\n        \"shuttleai/shuttle-jaguar\",\n        \"styletts2/styletts2\",\n        \"Qwen/QVQ-72B-preview\"\n      ]\n    }\n```\n\n\nTo use private spaces, supply your Hugging Face Token with either the  `--hf-token=hf_...` argument or `HF_TOKEN` environment variable.\n\nIt's possible to run multiple server instances to use different working directories and tokens if needed.\n\n## File Handling and Claude Desktop Mode\n\nBy default, the Server operates in _Claude Desktop Mode_. In this mode, Images are returned in the tool responses, while other files are saved in the working folder, their file path is returned as a message. This will usually give the best experience if using Claude Desktop as the client.\n\nURLs can also be supplied as inputs: the content gets passed to the Space.\n\nThere is an \"Available Resources\" prompt that gives Claude the available files and mime types from your working directory. This is currently the best way to manage files.\n\n### Example 1 - Image Generation (Download Image / Claude Vision)\n\nWe'll use Claude to compare images created by `shuttleai/shuttle-3.1-aesthetic` and `FLUX.1-schnell`. The images gets saved to the Work Directory, as well as included in Claude's context window - so Claude can use its vision capabilities.\n\n\n\n### Example 2 - Vision Model (Upload Image)\n\nWe'll use `merve/paligemma2-vqav2` [space link](https://huggingface.co/spaces/merve/paligemma2-vqav2) to query an image. In this case, we specify the filename which is available in the Working Directory: we  don't want to upload the Image directly to Claude's context window. So, we can prompt Claude:\n\n`use paligemma to find out who is in \"test_gemma.jpg\"` -> `Text Output: david bowie`\n\n\n_If you are uploading something to Claude's context use the Paperclip Attachment button, otherwise specify the filename for the Server to send directly._\n\nWe can also supply a URL. For example : `use paligemma to detect humans in https://e3.365dm.com/24/12/1600x900/skynews-taylor-swift-eras-tour_6771083.jpg?20241209000914` -> `One person is detected in the image - Taylor Swift on stage.`\n\n### Example 3 - Text-to-Speech (Download Audio)\n\nIn _Claude Desktop Mode_, the audio file is saved in the WORK_DIR, and Claude is notified of the creation. If not in desktop mode, the file is returned as a base64 encoded resource to the Client (useful if it supports embedded Audio attachments).\n\n\n\n### Example 4 - Speech-to-Text (Upload Audio)\n\nHere, we use `hf-audio/whisper-large-v3-turbo` to transcribe some audio, and make it available to Claude.\n\n\n\n### Example 5 - Image-to-Image\n\nIn this example, we specify the filename for `microsoft/OmniParser` to use, and get returned an annotated Image and 2 separate pieces of text: descriptions and coordinates. The prompt used was `use omniparser to analyse ./screenshot.png` and `use the analysis to produce an artifact that reproduces that screen`. `DawnC/Pawmatch` is also good at this.\n\n\n\n### Example 6 - Chat\n\nIn this example, Claude sets a number of reasoning puzzles for Qwen, and asks follow-up questions for clarification.\n\n\n\n### Specifying API Endpoint\n\nIf you need, you can specify a specific API Endpoint by adding it to the spacename. So rather than passing in `Qwen/Qwen2.5-72B-Instruct` you would use `Qwen/Qwen2.5-72B-Instruct/model_chat`.\n\n### Claude Desktop Mode\n\nThis can be disabled with the option --desktop-mode=false or the environment variable CLAUDE_DESKTOP_MODE=false. In this case, content as returned as an embedded Base64 encoded Resource.\n\n## Recommended Spaces\n\nSome recommended spaces to try:\n\n### Image Generation\n\n- shuttleai/shuttle-3.1-aesthetic\n- black-forest-labs/FLUX.1-schnell\n- yanze/PuLID-FLUX\n- Inspyrenet-Rembg (Background Removal)\n- diyism/Datou1111-shou_xin - [Beautiful Pencil Drawings](https://x.com/ClementDelangue/status/1867318931502895358) \n\n### Chat\n\n- Qwen/Qwen2.5-72B-Instruct\n- prithivMLmods/Mistral-7B-Instruct-v0.3\n\n### Text-to-speech / Audio Generation\n\n- fantaxy/Sound-AI-SFX\n- parler-tts/parler_tts\n\n### Speech-to-text\n\n- hf-audio/whisper-large-v3-turbo\n- (the openai models use unnamed parameters so will not work)\n\n### Text-to-music\n\n- haoheliu/audioldm2-text2audio-text2music\n\n### Vision Tasks\n\n- microsoft/OmniParser\n- merve/paligemma2-vqav2\n- merve/paligemma-doc\n- DawnC/PawMatchAI \n- DawnC/PawMatchAI/on_find_match_click - for interactive dog recommendations\n\n## Other Features\n\n### Prompts\n\nPrompts for each Space are generated, and provide an opportunity to input. Bear in mind that often Spaces aren't configured with particularly helpful labels etc. Claude is actually very good at figuring this out, and the Tool description is quite rich (but not visible in Claude Desktop).\n\n### Resources\n\nA list of files in the WORK_DIR is returned, and as a convenience returns the name as \"Use the file...\" text. If you want to add something to Claude's context, use the paperclip - otherwise specify the filename for the MCP Server. Claude does not support transmitting resources from within Context.\n\n### Private Spaces\n\nPrivate Spaces are supported with a HuggingFace token. The Token is used to download and save generated content.\n\n### Using Claude Desktop\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-hfspace\": {\n      \"command\": \"npx\"\n      \"args:\" [\n        \"-y\",\n        \"@llmindset/mcp-hfspace\",\n        \"--work-dir=~/mcp-files/ or x:/temp/mcp-files/\",\n        \"--HF_TOKEN=HF_{optional token}\"\n        \"Qwen/Qwen2-72B-Instruct\",\n        \"black-forest-labs/FLUX.1-schnell\",\n        \"space/example/specific-endpint\"\n        (... and so on)\n        ]\n    }\n  }\n}\n```\n\n## Known Issues and Limitations\n\n### mcp-hfspace\n\n- Endpoints with unnamed parameters are unsupported for the moment.\n- Full translation from some complex Python types to suitable MCP formats.\n\n### Claude Desktop\n\n- Claude Desktop 0.75 doesn't seem to respond to errors from the MCP Server, timing out instead. For persistent issues, use the MCP Inspector to get a better look at diagnosing what's going wrong. If something suddenly stops working, it's probably due to exhausting your HuggingFace ZeroGPU quota - try again after a short period, or set up your own Space for hosting.\n- Claude Desktop seems to use a hard timeout value of 60s, and doesn't appear  to use Progress Notifications to manage UX or keep-alive. If you are using ZeroGPU spaces, large/heavy jobs may timeout. Check the WORK_DIR for results though; the MCP Server will still capture and save the result if it was produced.\n- Claude Desktops reporting of Server Status, logging etc. isn't great - use [@modelcontextprotocol/inspector](https://github.com/modelcontextprotocol/inspector) to help diagnose issues.\n\n### HuggingFace Spaces\n\n- If ZeroGPU quotas or queues are too long, try duplicating the space. If your job takes less than sixty seconds, you can usually change the function decorator `@spaces.GPU(duration=20)` in `app.py` to request less quota when running the job.\n- If you have a HuggingFace Pro account, please note that The Gradio API does not your additional quote for ZeroGPU jobs - you will need to set an `X-IP-Token` header to achieve that.\n- If you have a private space, and dedicated hardware your HF_TOKEN will give you direct access to that - no quota's apply. I recommend this if you are using for any kind of Production task.\n\n## Third Party MCP Services\n\n<a href=\"https://glama.ai/mcp/servers/s57c80wvgq\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/s57c80wvgq/badge\" alt=\"mcp-hfspace MCP server\" /></a>",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "hfspace",
        "xiyuefox",
        "ai",
        "xiyuefox mcp",
        "mcp hfspace",
        "image generation"
      ],
      "category": "image-and-video-generation"
    },
    "xoy8n--webp-converter": {
      "owner": "xoy8n",
      "name": "webp-converter",
      "url": "https://github.com/xoy8n/webp-converter",
      "imageUrl": "/freedevtools/mcp/pfp/xoy8n.webp",
      "description": "A server that converts image files such as PNG, JPG, and JPEG to WebP format, supporting both single and batch conversions. It allows configuration of quality settings and provides detailed conversion reports.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-06-19T01:34:07Z",
      "readme_content": "# WebP Conversion MCP Server\n\nThis project is a Model Context Protocol (MCP) server that converts image files to WebP format.\n\n## Features\n\n- Convert PNG, JPG, and JPEG files to WebP\n- Support for single image or batch image conversion\n- Option to configure quality and lossless compression\n- Option to keep original files\n- Provides a detailed report of the conversion result\n\n### Installation & Execution\n\n```bash\nnpx -y @xoy8n/webp-converter@latest\n```\n\n### Cursor mcp.json Configuration\n\n```json\n{\n  \"mcpServers\": {\n    \"webp-converter\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@xoy8n/webp-converter@latest\"]\n    }\n  }\n}\n```\n\n## MCP Tool List\n\n### 1. convert_to_webp\n\nConverts a single image file to WebP format.\n\n**Parameters:**\n\n- `image_path`: Path to the image file to convert\n- `base_path`: Base directory path\n- `quality`: WebP quality setting (default: 95)\n- `lossless`: Whether to use lossless compression (default: false)\n- `keep_original`: Whether to retain the original file (default: false)\n\n**Returns:**\n\n- Conversion success status\n- Input/output file paths\n- File size before/after conversion\n- Applied quality and compression settings\n\n### 2. batch_convert_to_webp\n\nConverts multiple image files to WebP format in one go.\n\n**Parameters:**\n\n- `image_paths`: Array of paths to image files to convert\n- `base_path`: Base directory path (optional)\n- `quality`: WebP quality setting (default: 95)\n- `lossless`: Whether to use lossless compression (default: false)\n- `keep_original`: Whether to retain the original files (default: false)\n\n**Returns:**\n\n- Array of conversion results for each image file\n\n## How to Use\n\n1. Select the image files you want to convert.\n2. Run the `convert_to_webp` or `batch_convert_to_webp` command via the MCP tools.\n3. Check the conversion results.\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "webp",
        "jpeg",
        "converter",
        "webp converter",
        "jpeg webp",
        "xoy8n webp"
      ],
      "category": "image-and-video-generation"
    },
    "yanjunz--mcp_search_images": {
      "owner": "yanjunz",
      "name": "mcp_search_images",
      "url": "https://github.com/yanjunz/mcp_search_images",
      "imageUrl": "/freedevtools/mcp/pfp/yanjunz.webp",
      "description": "Search for high-quality images from sources like Unsplash, Pexels, and Pixabay, and generate custom icons based on text descriptions, facilitating visual enhancements for projects.",
      "stars": 10,
      "forks": 1,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-15T13:46:13Z",
      "readme_content": "# MCP 图像搜索与图标生成服务\n\n基于多个图片API的搜索服务和图标生成功能，专门设计用于与 Cursor MCP 服务集成。支持图片搜索、下载和AI生成图标。\n\n\n\n## 工作原理\n\n本工具通过MCP (Model Control Protocol) 为Cursor IDE提供图像搜索和图标生成功能：\n\n1. **搜索图片**: 连接Unsplash、Pexels和Pixabay等图片源，根据关键词搜索高质量图片\n2. **下载图片**: 将搜索到的图片下载到指定位置，方便直接在项目中使用\n3. **生成图标**: 基于文本描述生成自定义图标，满足项目UI需求\n\n### 系统工作流程\n\n```\n用户 (在Cursor中) → 向Claude/大模型提问 → 大模型调用MCP工具 → 工具处理请求 → 返回结果 → 大模型展示结果\n```\n\n比如，你可以在Cursor中向Claude询问\"帮我找5张关于太空的图片\"，Claude会通过MCP工具搜索并展示图片，然后你可以进一步要求下载或生成特定图标。\n\n## 功能特点\n\n* 支持多个图片源搜索 (Unsplash, Pexels, Pixabay)\n* 高质量图标生成 (基于Together AI)\n* 简单易用的API\n* 完整的错误处理\n* 自定义保存路径和文件名\n* 可调整图片尺寸\n\n## 环境准备\n\n### 1. Python 环境\n\n* Python 3.10+\n* 下载地址： https://www.python.org/downloads/\n* 推荐使用 pyenv 管理 Python 版本：\n\n```bash\n# macOS 安装 pyenv\nbrew install pyenv\n\n# 安装 Python\npyenv install 3.13.2\npyenv global 3.13.2\n```\n\n### 2. uv 包管理工具\n\nuv 是一个快速的 Python 包管理器，需要先安装：\n\n```bash\n# macOS 安装 uv\nbrew install uv\n\n# 或者使用 pip 安装\npip install uv\n```\n\n### 3. 图片API密钥\n\n#### Unsplash API 密钥\n1. 访问 [Unsplash Developers](https://unsplash.com/developers)\n2. 注册/登录账号\n3. 创建新的应用程序\n4. 获取 Access Key\n\n#### Pexels API 密钥\n1. 访问 [Pexels API](https://www.pexels.com/api/)\n2. 注册/登录账号\n3. 请求API密钥\n\n#### Pixabay API 密钥\n1. 访问 [Pixabay API](https://pixabay.com/api/docs/)\n2. 注册/登录账号\n3. 获取API密钥\n\n#### Together AI API 密钥\n1. 访问 [Together AI API Keys](https://api.together.xyz/keys)\n2. 注册/登录账号\n3. 创建新的 API 密钥\n\n### 4. Cursor\n\n* 下载并安装 [Cursor IDE](https://cursor.sh/)\n* 确保 Cursor 已正确配置 Python 环境\n\n## 安装配置\n\n1. 克隆项目：\n\n```bash\ngit clone https://github.com/yanjunz/mcp_search_images.git\n```\n\n2. 安装依赖：\n\n```bash\npython3 -m pip install fastmcp requests\n```\n\n出现证书问题可以使用：\n\n```bash\npython3 -m pip install fastmcp requests --trusted-host pypi.org --trusted-host files.pythonhosted.org --upgrade --force-reinstall --no-cache-dir\n```\n\n3. 配置 API 密钥：\n\n从模板创建配置文件：\n\n```bash\n# 复制模板文件作为配置文件\ncp config.json.template config.json\n\n# 编辑配置文件，设置API密钥\nnano config.json  # 或使用其他编辑器\n```\n\n在 `config.json` 中修改以下配置：\n\n```json\n{\n    \"api\": {\n        \"unsplash_access_key\": \"你的Unsplash访问密钥\",\n        \"pexels_api_key\": \"你的Pexels API密钥\",\n        \"pixabay_api_key\": \"你的Pixabay API密钥\",\n        \"together_api_key\": \"你的Together API密钥\",\n        \"timeout\": 30,\n        \"max_retries\": 3,\n        \"retry_delay\": 5\n    },\n    // ...其他配置...\n}\n```\n\n> **注意**：请确保不要将包含API密钥的配置文件提交到版本控制系统中。\n> 项目中的 `.gitignore` 文件已配置为忽略 `config.json`，但保留 `config.json.template`。\n\n## 运行服务\n\n### 方法一：直接使用Python运行\n\n这是最简单的方式，直接使用Python运行服务：\n\n```bash\npython3.11 main.py\n```\n\n服务启动后会显示以下信息:\n```\n启动图片搜索服务 - 端口: 5173\n提供的工具: search_images, download_image, generate_icon\nINFO:     Started server process [xxxxx]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://0.0.0.0:5173 (Press CTRL+C to quit)\n```\n\n### 方法二：使用fastmcp命令运行\n\n如果您安装了fastmcp包，也可以使用fastmcp命令运行：\n\n1. 开发模式运行（带调试界面）：\n\n```bash\nfastmcp dev main.py\n```\n\n2. 生产模式运行：\n\n```bash\nfastmcp run main.py\n```\n\n3. 如果端口被占用，可以指定其他端口：\n\n```bash\nPORT=5174 fastmcp dev main.py\n```\n\n### 方法三：使用uv运行\n\n如果您使用uv作为包管理器：\n\n```bash\nuv run --with fastmcp fastmcp run main.py\n```\n\n或者在开发模式下：\n\n```bash\nuv run --with fastmcp fastmcp dev main.py\n```\n\n### Cursor与MCP的工作原理\n\n为了更好地理解和解决连接问题，以下是Cursor与MCP服务交互的基本工作原理：\n\n1. **MCP服务启动流程**：\n   * 当运行`python3.11 main.py`时，服务初始化并创建SSE（Server-Sent Events）应用\n   * 服务在指定端口（默认5173）开始监听请求\n   * 服务注册工具函数（search_images, download_image, generate_icon）\n   * 对于使用ServerLink方式的连接，服务需要在`/sse`路径上正确处理SSE请求\n\n2. **Cursor连接流程**：\n   * 当在Cursor设置中添加MCP工具时，Cursor尝试与提供的URL建立连接\n   * Cursor发送初始化请求，检查服务是否正常响应\n   * 服务需要返回正确的MCP协议响应，包括可用工具列表\n   * 连接成功后，Cursor会将该工具添加到可用工具列表\n   \n3. **诊断连接问题**：\n   * 检查服务是否在运行：`lsof -i :5173`\n   * 检查网络连接：`curl http://localhost:5173`\n   * 检查服务是否正确实现MCP协议：服务启动日志应显示注册的工具\n   * 检查防火墙和网络权限：本地服务有时可能被防火墙阻止\n   \n4. **完整的测试流程**：\n   ```bash\n   # 1. 停止任何可能正在运行的服务\n   pkill -f \"python.*main.py\"\n   \n   # 2. 启动服务（在前台运行以查看日志）\n   python3.11 main.py\n   \n   # 3. 在新的终端窗口中，测试连接\n   curl http://localhost:5173\n   \n   # 4. 测试SSE端点（用于ServerLink方式）\n   curl http://localhost:5173/sse\n   \n   # 5. 在Cursor中添加MCP工具并测试\n   ```\n\n如果按照以上步骤操作后仍然无法连接，可能需要检查Python版本兼容性或依赖包是否正确安装。有时重新安装依赖包也有帮助：\n\n```bash\npython3.11 -m pip uninstall fastmcp mcp uvicorn starlette -y\npython3.11 -m pip install fastmcp mcp uvicorn starlette\n```\n\n## 使用说明\n\n### 在 Cursor IDE 中使用\n\n1. 确保服务正在运行\n   ```bash\n   # 直接运行Python脚本\n   python3.11 main.py\n   ```\n   服务启动后会显示以下信息:\n   ```\n   启动图片搜索服务 - 端口: 5173\n   提供的工具: search_images, download_image, generate_icon\n   INFO:     Started server process [xxxxx]\n   INFO:     Waiting for application startup.\n   INFO:     Application startup complete.\n   INFO:     Uvicorn running on http://0.0.0.0:5173 (Press CTRL+C to quit)\n   ```\n\n2. 在Cursor中添加MCP服务:\n   * 打开Cursor IDE\n   * 点击左下角的齿轮图标，打开设置\n   * 选择\"AI & Copilot\"设置\n   * 在\"MCP工具\"部分点击\"添加MCP工具\"\n   * 填写以下信息:\n     - 名称: 图片搜索服务\n     - 类型: SSE (Server-Sent Events)\n     - URL: http://localhost:5173\n     - 点击\"保存\"\n     \n   **备选配置方法**:\n   * 某些版本的Cursor可能需要使用ServerLink配置:\n     - 名称: 图片搜索服务\n     - 类型: sse\n     - ServerLink: http://localhost:5173/sse\n     - 点击\"保存\"\n\n   > **注意**: 如果出现\"Fail to create client\"错误，请检查以下几点:\n   > 1. 确认服务正在运行 (通过`lsof -i :5173`检查端口是否被监听)\n   > 2. 尝试在浏览器中访问`http://localhost:5173`测试连接性\n   > 3. 确保URL没有多余的斜杠或空格\n   > 4. 对于ServerLink方式，确保使用正确的端点路径`/sse`\n   > 5. 重启服务后再次尝试添加\n   > 6. 有时需要重启Cursor IDE以清除之前的连接缓存\n\n3. 开始使用MCP工具:\n   * 在Cursor中打开包含Claude或其他支持工具调用的大模型对话窗口\n   * 当服务正在运行时，大模型可以自动发现并使用该工具\n   * 如果大模型未自动发现工具，可以提示它:\"请使用图片搜索服务来查找图片\"\n\n4. 在开发过程中随时使用:\n   * 编写代码时需要图标素材，可以直接向大模型描述需求\n   * 例如:\"帮我找一些适合作为登录按钮的图标\"\n   * 大模型会调用MCP工具搜索图片并展示结果\n   * 你可以进一步要求下载或生成自定义图标\n\n5. 查看图标保存位置:\n   * 默认情况下，图标会保存在项目根目录下的`icons`文件夹中\n   * 可以通过以下命令查看已保存的图标:\n     ```bash\n     ls -la icons\n     ```\n\n### 功能使用示例\n\n#### 搜索图片\n\n可以直接向大模型描述需求:\n```\n搜索关键词为\"technology\"的图片\n```\n或更具体的描述:\n```\n请在Unsplash上搜索5张关于\"artificial intelligence\"的图片\n```\n\n#### 下载图片\n\n当大模型显示搜索结果后，你可以要求下载特定图片:\n```\n下载第2张图片并保存为tech-icon.png\n```\n或者指定保存路径:\n```\n将第3张图片下载到/Users/username/Desktop/，文件名为ai-image.jpg\n```\n\n#### 生成图标\n\n可以提供详细的描述来生成符合需求的图标:\n```\n生成一个蓝色科技风格的图标，保存为blue-tech.png\n```\n或者更详细的描述:\n```\n请创建一个扁平化设计的邮件图标，红色轮廓，白色背景，图标尺寸为256x256，保存为email-icon.png\n```\n\n### 实际对话示例\n\n查看[示例对话](examples/dialog_example.md)了解如何在实际使用中与Claude/大模型交互来搜索和生成图标。\n\n### 集成到项目工作流\n\n1. 在项目初始阶段批量生成图标:\n   * 创建设计系统时，可以一次性生成多个相关图标\n   * 例如:\"帮我生成一套包含主页、设置、用户、消息通知的应用图标\"\n\n2. 开发过程中按需搜索:\n   * 在编写代码时随时查找所需图片资源\n   * 例如:\"我正在开发一个天气应用，需要几个天气相关的图标\"\n\n3. 项目完善阶段定制图标:\n   * 根据应用风格统一优化图标\n   * 例如:\"生成一组与我当前应用风格一致的社交媒体分享图标\"\n\n### 最佳实践\n\n1. **使用明确的关键词**: 搜索时使用具体、明确的关键词获得更精确的结果\n2. **指定图片源**: 根据需求选择合适的图片源（Unsplash适合自然风光，Pixabay适合商业图片等）\n3. **保存结构化命名**: 为图标使用结构化命名，如`category-name-size.png`\n4. **批量操作**: 一次性请求多个相关图标而不是逐个请求\n5. **与代码结合**: 在实际开发中提及代码上下文，大模型可以更准确地理解你的需求\n\n## 错误排查\n\n### Cursor MCP连接错误\n\n如果在Cursor中添加MCP服务时遇到\"Fail to create client\"错误，请尝试以下解决方法：\n\n1. **检查服务状态**：\n   ```bash\n   # 检查服务是否正在运行\n   lsof -i :5173\n   # 如果没有输出，表示服务未运行，请启动服务\n   python3.11 main.py\n   ```\n\n2. **测试连接**：\n   ```bash\n   # 使用curl测试API连接\n   curl -v http://localhost:5173\n   ```\n\n3. **修改连接设置**：\n   * 确保选择了正确的连接类型：SSE\n   * 尝试使用IP地址代替localhost：`http://127.0.0.1:5173`\n   * 确保URL不含额外斜杠：使用`http://localhost:5173`而非`http://localhost:5173/`\n   * 尝试使用ServerLink方式配置：\n     - 类型: sse\n     - ServerLink: http://localhost:5173/sse\n   * 有些版本的Cursor可能对URL格式有特定要求，两种方式都值得尝试\n\n4. **重启组件**：\n   * 停止并重启MCP服务\n   * 重启Cursor IDE\n   * 如果使用macOS，检查防火墙设置是否阻止了连接\n\n5. **检查日志**：\n   * 观察服务启动时的日志输出\n   * 当尝试从Cursor连接时，查看服务端有无新的日志输出\n\n6. **尝试其他端口**：\n   * 修改代码中的端口（如改为5174）并重启服务：\n   ```python\n   uvicorn.run(sse_app, host=\"0.0.0.0\", port=5174)\n   ```\n\n### 其他常见问题\n\n如果遇到问题，请检查：\n\n1. 服务是否正常运行\n2. 保存路径是否正确\n3. 目录权限是否正确\n4. 网络连接是否正常\n5. API 密钥是否有效\n6. Python 环境是否正确配置\n7. uv 是否正确安装\n8. 依赖包是否完整安装\n\n## 贡献\n\n欢迎提交问题和拉取请求来改进项目。\n\n## 许可\n\n[MIT License](LICENSE)",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcp_search_images",
        "images",
        "icons",
        "yanjunz mcp_search_images",
        "mcp_search_images search",
        "quality images"
      ],
      "category": "image-and-video-generation"
    },
    "yunwoong7--aws-nova-canvas-mcp": {
      "owner": "yunwoong7",
      "name": "aws-nova-canvas-mcp",
      "url": "https://github.com/yunwoong7/aws-nova-canvas-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/yunwoong7.webp",
      "description": "Generate and edit images with advanced features such as text-to-image generation, image inpainting, and background removal, using the Nova Canvas model from Amazon Bedrock.",
      "stars": 4,
      "forks": 3,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-06-22T12:28:20Z",
      "readme_content": "<h2 align=\"center\">\nAWS Nova Canvas MCP Server\n</h2>\n\n<div align=\"center\">\n  <img src=\"https://img.shields.io/badge/Python-3.12-3776AB?logo=python\"/>\n  <img src=\"https://img.shields.io/badge/Amazon-Bedrock-FF9900?logo=amazon&logoColor=white\"/>\n</div>\n\nAn MCP server that allows you to generate and edit images using the Nova Canvas model of Amazon Bedrock.\n\n## Features\n\n- Text to Image\n- Image Inpainting\n- Image Outpainting\n- Image Variation\n- Image Conditioning\n- Color Guided Generation\n- Background Removal\n- Show Image Thumbnails\n\n## Installation\n\n### Claude Desktop Setup\n\n1. Configure Claude Desktop\n   * Click on **Claude > Settings** from the Claude Desktop menu.\n   * When the popup appears, select **Developer** from the left menu, and click the **Edit Settings** button.\n   * This will open a folder containing the settings file. The name of this settings file is:\n   * `claude_desktop_config.json`\n\n<div align=\"center\">\n<img src=\"https://blog.kakaocdn.net/dn/bIl5q9/btsM3U5Vjw5/aGruWqP3wNmWZ1sKrnhbPk/img.png\" width=\"70%\">\n</div>\n\n3. Add the following content to the settings file (Python version):\n\n   - python version\n\n     ```json\n     \"nova-canvas\": {\n       \"command\": \"uvx\",\n       \"args\": [\n         \"aws-nova-canvas-mcp\"\n       ],\n       \"env\": {\n         \"AWS_PROFILE\": \"YOUR_AWS_PROFILE\"\n       }\n     }\n     ```\n\n     > ✅ Only AWS_PROFILE is required. Other variables like AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_REGION, and PORT are optional and not necessary if your AWS profile is set correctly.\n     >\n     > ​\t⚙️ If the setup is completed successfully, you can see that the \"nova-canvas\" item has been added in **Claude > Settings > Developer tab**.\n     > ⚠️ **Important:** MCP settings only work on the **Claude desktop app, not the Claude web browser version**\n\n## Image Save Location\n\nBy default, all generated or edited images will be saved in the following directory:\n\n* **macOS / Linux**:  `~/Desktop/aws-nova-canvas`\n* **Windows**:  `C:\\Users\\YourUsername\\Desktop\\aws-nova-canvas`\n\n> 📁 If no image save path is specified, the application will automatically create and use the folder above.\n\n<div align=\"center\">\n<img src=\"https://blog.kakaocdn.net/dn/bpUWLj/btsM4kJZC6v/HHQfQctKsevWnK6LCKEkv0/img.png\" width=\"70%\">\n</div>\n\n## Usage Example\n\n<div align=\"center\">\n<img src=\"https://blog.kakaocdn.net/dn/uNi8L/btsM4pEjswV/hSfxo1gHzPvpXPsEEyuijk/img.gif\" width=\"70%\">\n</div>\n\n## Limitations\n\n- Prompt text supports up to 1024 characters\n- Image generation allows up to 3 images at a time\n- Image variation requires 1-5 reference images\n- Color guide supports 1-10 color codes\n\n## License\n\nMIT License\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "canvas",
        "bedrock",
        "images",
        "nova canvas",
        "canvas mcp",
        "generation image"
      ],
      "category": "image-and-video-generation"
    },
    "zjf2671--hh-mcp-comfyui": {
      "owner": "zjf2671",
      "name": "hh-mcp-comfyui",
      "url": "https://github.com/zjf2671/hh-mcp-comfyui",
      "imageUrl": "/freedevtools/mcp/pfp/zjf2671.webp",
      "description": "Integrates with local ComfyUI instances via API calls to enable natural language-driven image generation. Supports dynamic parameter replacement in workflows and automatic loading of workflow files as resources.",
      "stars": 16,
      "forks": 3,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-18T16:25:43Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/zjf2671-hh-mcp-comfyui-badge.png)](https://mseep.ai/app/zjf2671-hh-mcp-comfyui)\n\n# ComfyUI MCP 服务\n\n[![English](https://img.shields.io/badge/English-Click-yellow)](docs/README.EN.md)\n[![简体中文](https://img.shields.io/badge/简体中文-点击查看-orange)](README.md)\n![Python 3.12+](https://img.shields.io/badge/python-3.12+-blue.svg)\n[![License](https://img.shields.io/badge/license-MIT-green.svg)](LiCENSE)\n[![smithery badge](https://smithery.ai/badge/@zjf2671/hh-mcp-comfyui)](https://smithery.ai/server/@zjf2671/hh-mcp-comfyui)\n\n这是一个基于Model Context Protocol (MCP)的ComfyUI图像生成服务，通过API调用本地ComfyUI实例生成图片。\n\n## 功能特性\n\n- 通过MCP协议提供图像生成服务，实现自然语言生图自由\n- 支持动态替换工作流中的提示词和尺寸等参数\n- 自动加载workflows目录下的工作流文件作为资源\n\n## 新增功能记录\n- [2025-06-29] 支持kontext图片编辑工作流\n![edit-image-85457440acc11a9f386f8ef284fd62f2.jpg](https://image.harryzhang.site/2025/07/edit-image-85457440acc11a9f386f8ef284fd62f2.jpg)\n- [2025-05-11] 支持工作流文件目录动态配置\n- [2025-05-09] 增加docker构建方式,支持Python 3.12+\n- [2025-05-07] 增加pip构建方式\n- [2025-05-06] 把项目目录src/hh修改成src/hh_mcp_comfyui,增加uvx构建方式\n- [2025-04-26] 增加图生图和移除背景样例工作流及支持图生图工具\n- [2025-04-20] 加入文生图生成工具\n \n## 效果\n\n- **Cherry Studio中使用效果**\n![image-b8f946109d63fe1ccb5e2d63933e3f9e.png](https://image.harryzhang.site/2025/07/image-b8f946109d63fe1ccb5e2d63933e3f9e.png)\n\n- **Cline中使用效果**\n![cline_gen_image-48d8515e0b59cd313879c62a1546162d.png](https://image.harryzhang.site/2025/07/cline_gen_image-48d8515e0b59cd313879c62a1546162d.png)\n![ComfyUI_00020_-d9171f87fc9e67fcc1966cdbfb952a0c.png](https://image.harryzhang.site/2025/07/ComfyUI_00020_-d9171f87fc9e67fcc1966cdbfb952a0c.png)\n\n## 安装依赖\n\n**1. 确保已安装Python 3.12+**\n\n**2. 使用uv管理Python环境：**\n- 安装uv:\n  ```bash\n  # On macOS and Linux.\n  $ curl -LsSf https://astral.sh/uv/install.sh | sh\n\n  # On Windows.\n  $ powershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n\n  # 更新uv(非必要操作):\n  $ uv self update\n  ```\n\n## 测试运行服务\n\n- **uvx方式**\n  ```bash\n  $ uvx hh-mcp-comfyui\n\n  INFO:hh_mcp_comfyui.server:Scanning for workflows in: C:\\Users\\tianw\\AppData\\Local\\uv\\cache\\archive-v0\\dp4MTo0f1qL0DdYF_BYCL\\Lib\\site-packages\\hh_mcp_comfyui\\workflows\n  INFO:hh_mcp_comfyui.server:Starting ComfyUI MCP Server...\n  ```\n- **pip方式**\n  ```bash\n  $ pip install hh_mcp_comfyui\n  \n  $ python -m hh_mcp_comfyui\n\n  INFO:hh_mcp_comfyui.server:Scanning for workflows in: F:\\Python\\Python313\\Lib\\site-packages\\hh_mcp_comfyui\\workflows\n  INFO:hh_mcp_comfyui.server:Starting ComfyUI MCP Server...\n  ```\n**出现上面的信息表示服务启动成功**\n\n## 使用方法\n> **必须确保本地ComfyUI实例正在运行(默认地址: http://127.0.0.1:8188) [ComfyUI安装地址](https://github.com/comfyanonymous/ComfyUI.git)**\n\n### Cherry Studio、Cline、Cursor等客户端的使用方式\n\n<details>\n  <summary>uvx MCP服务配置</summary>\n\n  ```bash\n  {\n    \"mcpServers\": {\n      \"hh-mcp-comfyui\": {\n        \"command\": \"uvx\",\n        \"args\": [\n          \"hh-mcp-comfyui@latest\"\n        ],\n        \"env\": {\n          \"COMFYUI_API_BASE\": \"http://127.0.0.1:8188\",\n          \"COMFYUI_WORKFLOWS_DIR\": \"/path/hh-mcp-comfyui/workflows\"\n        }\n      }\n    }\n  }\n  ```\n  </details>\n\n<details>\n  <summary>pip MCP服务配置</summary>\n\n  **需要先执行命令窗口先执行：pip install hh_mcp_comfyui**\n\n  ```bash\n  {\n    \"mcpServers\": {\n      \"hh-mcp-comfyui\": {\n        \"command\": \"python\",\n        \"args\": [\n          \"-m\",\n          \"hh_mcp_comfyui\"\n        ],\n        \"env\": {\n          \"COMFYUI_API_BASE\": \"http://127.0.0.1:8188\",\n          \"COMFYUI_WORKFLOWS_DIR\": \"/path/hh-mcp-comfyui/workflows\"\n        }\n      }\n    }\n  }\n  ```\n</details>\n\n<details>\n  <summary>docker MCP服务配置</summary>\n\n  **前提是已安装docker**\n\n  ```bash\n  {\n    \"mcpServers\": {\n      \"hh-mcp-comfyui\": {\n        \"command\": \"docker\",\n        \"args\": [\n            \"run\",\n            \"--net=host\",\n            \"-v\",\n            \"/path/hh-mcp-comfyui/workflows:/app/workflows\",\n            \"-i\",\n            \"--rm\",\n            \"zjf2671/hh-mcp-comfyui:latest\"\n        ],\n        \"env\": {\n          \"COMFYUI_API_BASE\": \"http://127.0.0.1:8188\"\n        }\n      }\n    }\n  }\n  ```\n</details>\n\n## 样例工作流copy到指定工作流目录：\n\n  （**注意**：使用下面uvx或pip方式找到你的安装工作流目录的位置把样例工作流添加进去，然后重启你的MCP服务）\n- **uvx**\n  ```bash\n  $ uvx hh-mcp-comfyui\n  ```\n  ![image-2-f89caf964efbccdad7b6fa2672d1cac0.png](https://image.harryzhang.site/2025/07/image-2-f89caf964efbccdad7b6fa2672d1cac0.png)\n- **pip**\n  \n   ```bash\n  #首先安装依赖\n  $ pip install hh_mcp_comfyui\n  $ python -m hh_mcp_comfyui\n  ```\n  ![image-3-03a069f40492fea9947a351b8707aa3f.png](https://image.harryzhang.site/2025/07/image-3-03a069f40492fea9947a351b8707aa3f.png)\n\n## 测试\n\n> **使用MCP Inspector测试服务端工具**\n\n- **uvx方式**\n  ```bash\n  $ npx @modelcontextprotocol/inspector uvx hh-mcp-comfyui\n  ``` \n- **pip方式**\n  ```bash\n  $ pip install hh_mcp_comfyui\n  $ npx @modelcontextprotocol/inspector python -m hh_mcp_comfyui\n  ``` \n - **docker方式**\n    ```bash\n    $ npx @modelcontextprotocol/inspector docker run --net=host -i --rm zjf2671/hh-mcp-comfyui\n    ``` \n然后点击连接如图即可调试：\n![image-1-44c6a003ee317093afe5a61cfe028720.png](https://image.harryzhang.site/2025/07/image-1-44c6a003ee317093afe5a61cfe028720.png)\n\n## 使用注意事项（针对没有用过comfyui的特别注意）\n\n- 默认工作流为`t2image_bizyair_flux`\n- 图片尺寸默认为1024x1024\n- 服务启动时会自动加载workflows目录下的所有JSON工作流文件\n- 如果你使用的是本项目中的**样例工作流**需要在comfyui中下载个插件，详细操作请查看：[样例工作流插件安装教程](https://ziitefe2yxn.feishu.cn/wiki/PlSmwBbBWiA0iDkc07scb4EEnHc)\n- 如果使用你本地的comfyui工作流的话，先要保证你的工作流能在comfyui正常运行，然后需要导出(API)的JSON格式，并放入到你本地的`/path/hh_mcp_comfyui/workflows`目录中\n\n## 添加新工作流\n\n1. 将工作流JSON文件放入`/path/hh_mcp_comfyui/workflows`目录中\n  \n    如果是uvx和pip启动方式请看上面 《**样例工作流copy到指定工作流目录**》 的使用方式\n\n2. 重启服务自动加载新工作流\n\n## 开发\n\n\n### 项目结构\n\n```\n.\n├── .gitignore\n├── .python-version\n├── pyproject.toml\n├── README.md\n├── uv.lock\n├── example/              # 示例工作流目录\n│   └── workflows/\n│       ├── i2image_bizyair_sdxl.json\n│       ├── t2image_bizyair_flux.json\n│       ├── i2image_cogview4.json\n│       └── t2image_sd1.5.json\n├── src/                  # 源代码目录\n│   └── hh_mcp_comfyui/\n│       ├── comfyui_client.py    # ComfyUI客户端实现\n│       ├── server.py            # MCP服务主文件\n│       └── workflows/           # 工作流文件目录\n```\n\n\n ### 初始化项目开发环境：  \n\n  ```bash\n  # Clone the repository.\n  $ git clone https://github.com/zjf2671/hh-mcp-comfyui.git\n\n  $ cd hh-mcp-comfyui\n\n  # Initialized venv\n  $ uv venv\n\n  # Activate the virtual environment.\n  $ .venv\\Scripts\\activate\n\n  # Install dependencies.\n  $ uv lock\n  Resolved 30 packages in 1ms\n\n  # sync dependencies.\n  $ uv sync\n  Resolved 30 packages in 2.54s\n  Audited 29 package in 0.02ms\n  ```\n\n### 检查服务是否正常\n\n  ```bash\n  $ uv --directory 你本地安装目录/hh-mcp-comfyui run hh-mcp-comfyui\n\n  INFO:__main__:Scanning for workflows in: D:\\cygitproject\\hh-mcp-comfyui\\src\\hh_mcp_comfyui\\workflows\n  INFO:__main__:Registered resource: workflow://t2image_bizyair_flux -> t2image_bizyair_flux.json\n  INFO:__main__:Starting ComfyUI MCP Server...\n  ```\n### 使用MCP Inspector测试服务端工具\n  \n  ```bash\n  $ npx @modelcontextprotocol/inspector uv --directory 你本地安装目录/hh-mcp-comfyui run hh-mcp-comfyui\n  ```\n\n### MCP配置\n\n  ```bash\n  {\n    \"mcpServers\": {\n      \"hh-mcp-comfyui\": {\n        \"command\": \"uv\",\n        \"args\": [\n          \"--directory\",\n          \"项目绝对路径（例如：D:/hh-mcp-comfyui）\",\n          \"run\",\n          \"hh-mcp-comfyui\"\n        ],\n        \"env\": {\n          \"COMFYUI_API_BASE\": \"http://127.0.0.1:8188\",\n          \"COMFYUI_WORKFLOWS_DIR\": \"/path/hh-mcp-comfyui/workflows\"\n        }\n      }\n    }\n  }\n  ```\n\n## 贡献\n\n1. Fork项目\n2. 创建特性分支 (`git checkout -b feature/AmazingFeature`)\n3. 提交更改 (`git commit -m 'Add some AmazingFeature'`)\n4. 推送到分支 (`git push origin feature/AmazingFeature`)\n5. 打开Pull Request\n\n---\n## 如有问题可以到公众号中联系我：\n\n*<center>![公众号二维码](https://image.harryzhang.site/2025/04/image-1-5ac2e62b072e6f1d6eb4e3638634094c.png)</center>*\n\n<center><u>👆 扫码关注，发现更多好玩的！</u></center>\n\n---\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "comfyui",
        "image",
        "dynamic",
        "comfyui instances",
        "comfyui integrates",
        "mcp comfyui"
      ],
      "category": "image-and-video-generation"
    },
    "zxkane--mcp-server-amazon-bedrock": {
      "owner": "zxkane",
      "name": "mcp-server-amazon-bedrock",
      "url": "https://github.com/zxkane/mcp-server-amazon-bedrock",
      "imageUrl": "/freedevtools/mcp/pfp/zxkane.webp",
      "description": "Integrates with Amazon Bedrock's Nova Canvas model to generate high-quality images based on text descriptions. Provides advanced features for refining image composition through negative prompts and allows control over image dimensions and quality.",
      "stars": 21,
      "forks": 11,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-25T09:31:13Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/zxkane-mcp-server-amazon-bedrock-badge.png)](https://mseep.ai/app/zxkane-mcp-server-amazon-bedrock)\n\n# Amazon Bedrock MCP Server\n\nA Model Control Protocol (MCP) server that integrates with Amazon Bedrock's Nova Canvas model for AI image generation.\n\n<a href=\"https://glama.ai/mcp/servers/9qw7dwpvj9\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/9qw7dwpvj9/badge\" alt=\"Amazon Bedrock Server MCP server\" /></a>\n\n## Features\n\n- High-quality image generation from text descriptions using Amazon's Nova Canvas model\n- Advanced control through negative prompts to refine image composition\n- Flexible configuration options for image dimensions and quality\n- Deterministic image generation with seed control\n- Robust input validation and error handling\n\n## Prerequisites\n\n1. Active AWS account with Amazon Bedrock and Nova Canvas model access\n2. Properly configured AWS credentials with required permissions\n3. Node.js version 18 or later\n\n## Installation\n\n### AWS Credentials Configuration\n\nThe server requires AWS credentials with appropriate Amazon Bedrock permissions. Configure these using one of the following methods:\n\n1. Environment variables:\n   ```bash\n   export AWS_ACCESS_KEY_ID=your_access_key\n   export AWS_SECRET_ACCESS_KEY=your_secret_key\n   export AWS_REGION=us-east-1  # or your preferred region\n   ```\n\n2. AWS credentials file (`~/.aws/credentials`):\n   ```ini\n   [the_profile_name]\n   aws_access_key_id = your_access_key\n   aws_secret_access_key = your_secret_key\n   ```\n   Environment variable for active profile:\n   ```bash\n   export AWS_PROFILE=the_profile_name\n   ```\n\n3. IAM role (when deployed on AWS infrastructure)\n\n### Claude Desktop Integration\n\nTo integrate with Claude Desktop, add the following configuration to your settings file:\n\nMacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nWindows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"amazon-bedrock\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@zxkane/mcp-server-amazon-bedrock\"\n      ],\n      \"env\": {\n        \"AWS_PROFILE\": \"your_profile_name\",         // Optional, only if you want to use a specific profile\n        \"AWS_ACCESS_KEY_ID\": \"your_access_key\",     // Optional if using AWS credentials file or IAM role\n        \"AWS_SECRET_ACCESS_KEY\": \"your_secret_key\", // Optional if using AWS credentials file or IAM role\n        \"AWS_REGION\": \"us-east-1\"                   // Optional, defaults to 'us-east-1'\n      }\n    }\n  }\n}\n```\n\n## Available Tools\n\n### generate_image\n\nCreates images from text descriptions using Amazon Bedrock's Nova Canvas model.\n\n#### Parameters\n\n- `prompt` (required): Descriptive text for the desired image (1-1024 characters)\n- `negativePrompt` (optional): Elements to exclude from the image (1-1024 characters)\n- `width` (optional): Image width in pixels (default: 1024)\n- `height` (optional): Image height in pixels (default: 1024)\n- `quality` (optional): Image quality level - \"standard\" or \"premium\" (default: \"standard\")\n- `cfg_scale` (optional): Prompt adherence strength (1.1-10, default: 6.5)\n- `seed` (optional): Generation seed for reproducibility (0-858993459, default: 12)\n- `numberOfImages` (optional): Batch size for generation (1-5, default: 1)\n\n#### Example Implementation\n\n```typescript\nconst result = await callTool('generate_image', {\n  prompt: \"A serene mountain landscape at sunset\",\n  negativePrompt: \"people, buildings, vehicles\",\n  quality: \"premium\",\n  cfg_scale: 8,\n  numberOfImages: 2\n});\n```\n\n#### Prompt Guidelines\n\nFor optimal results, avoid negative phrasing (\"no\", \"not\", \"without\") in the main prompt. Instead, move these elements to the `negativePrompt` parameter. For example, rather than using \"a landscape without buildings\" in the prompt, use \"buildings\" in the `negativePrompt`.\n\nFor detailed usage guidelines, refer to the [Nova Canvas documentation][nova-canvas-doc].\n\n## Development\n\nTo set up and run the server in a local environment:\n\n```bash\ngit clone https://github.com/zxkane/mcp-server-amazon-bedrock.git\ncd mcp-server-amazon-bedrock\nnpm install\nnpm run build\n```\n\n### Performance Considerations\n\nGeneration time is influenced by resolution (`width` and `height`), `numberOfImages`, and `quality` settings. When using higher values, be mindful of potential timeout implications in your implementation.\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n[nova-canvas-doc]: https://docs.aws.amazon.com/nova/latest/userguide/image-gen-access.html\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "bedrock",
        "canvas",
        "images",
        "amazon bedrock",
        "bedrock nova",
        "image composition"
      ],
      "category": "image-and-video-generation"
    },
    "zym9863--pixabay-mcp": {
      "owner": "zym9863",
      "name": "pixabay-mcp",
      "url": "https://github.com/zym9863/pixabay-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/zym9863.webp",
      "description": "Connect to the Pixabay API to search for images and retrieve formatted results that include image URLs and metadata. Handle errors seamlessly during API interactions for reliable performance.",
      "stars": 4,
      "forks": 1,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-29T07:41:49Z",
      "readme_content": "# pixabay-mcp MCP Server\n\n[中文版](README_zh.md)\n\nA Model Context Protocol (MCP) server for Pixabay image and video search with structured results & runtime validation.\n\n<a href=\"https://glama.ai/mcp/servers/@zym9863/pixabay-mcp\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@zym9863/pixabay-mcp/badge\" alt=\"Pixabay Server MCP server\" />\n</a>\n\nThis TypeScript MCP server exposes Pixabay search tools over stdio so AI assistants / agents can retrieve media safely and reliably.\n\nHighlights:\n- Image & video search tools (Pixabay official API)\n- Runtime argument validation (enums, ranges, semantic checks)\n- Consistent error logging without leaking sensitive keys\n- Planned structured JSON payloads for easier downstream automation (see Roadmap)\n\n## Features\n\n### Tools\n`search_pixabay_images`\n  - Required: `query` (string)\n  - Optional: `image_type` (all|photo|illustration|vector), `orientation` (all|horizontal|vertical), `per_page` (3-200)\n  - Returns: human-readable text block (current) + (planned) structured JSON array of hits\n\n`search_pixabay_videos`\n  - Required: `query`\n  - Optional: `video_type` (all|film|animation), `orientation`, `per_page` (3-200), `min_duration`, `max_duration`\n  - Returns: human-readable text block + (planned) structured JSON with duration & URLs\n\n### Configuration\nEnvironment variables:\n| Name | Required | Default | Description |\n| ---- | -------- | ------- | ----------- |\n| `PIXABAY_API_KEY` | Yes | - | Your Pixabay API key (images & videos) |\n| `PIXABAY_TIMEOUT_MS` | No | 10000 (planned) | Request timeout once feature lands |\n| `PIXABAY_RETRY` | No | 0 (planned) | Number of retry attempts for transient network errors |\n\nNotes:\n- Safe search is enabled by default.\n- Keys are never echoed back in structured errors or logs.\n\n## Usage Examples\n\nCurrent (text only response excerpt):\n```\nFound 120 images for \"cat\":\n- cat, pet, animal (User: Alice): https://.../medium1.jpg\n- kitten, cute (User: Bob): https://.../medium2.jpg\n```\n\nPlanned structured result (Roadmap v0.4+):\n```jsonc\n{\n  \"content\": [\n    { \"type\": \"text\", \"text\": \"Found 120 images for \\\"cat\\\":\\n- ...\" },\n    {\n      \"type\": \"json\",\n      \"data\": {\n        \"query\": \"cat\",\n        \"totalHits\": 120,\n        \"page\": 1,\n        \"perPage\": 20,\n        \"hits\": [\n          { \"id\": 123, \"tags\": [\"cat\",\"animal\"], \"user\": \"Alice\", \"previewURL\": \"...\", \"webformatURL\": \"...\", \"largeImageURL\": \"...\" }\n        ]\n      }\n    }\n  ]\n}\n```\n\nError response (planned shape):\n```json\n{\n  \"content\": [{ \"type\": \"text\", \"text\": \"Pixabay API error: 400 ...\" }],\n  \"isError\": true,\n  \"metadata\": { \"status\": 400, \"code\": \"UPSTREAM_BAD_REQUEST\", \"hint\": \"Check API key or parameters\" }\n}\n```\n\n## Development\n\nInstall dependencies:\n```bash\nnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n```\n\nWatch mode:\n```bash\nnpm run watch\n```\n\n## Installation\n\n### Option 1: Using npx (Recommended)\n\nAdd this to your Claude Desktop configuration:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"pixabay-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\"pixabay-mcp@latest\"],\n      \"env\": {\n        \"PIXABAY_API_KEY\": \"your_api_key_here\"\n      }\n    }\n  }\n}\n```\n\n### Option 2: Local Installation\n\n1. Clone and build the project:\n\n```bash\ngit clone https://github.com/zym9863/pixabay-mcp.git\ncd pixabay-mcp\nnpm install\nnpm run build\n```\n\n2. Add the server config:\n\n```json\n{\n  \"mcpServers\": {\n    \"pixabay-mcp\": {\n      \"command\": \"/path/to/pixabay-mcp/build/index.js\",\n      \"env\": {\n        \"PIXABAY_API_KEY\": \"your_api_key_here\"\n      }\n    }\n  }\n}\n```\n\n### API Key Setup\n\nGet your Pixabay API key from [https://pixabay.com/api/docs/](https://pixabay.com/api/docs/) and set it in the configuration above. The same key grants access to both image and video endpoints.\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n\n## Roadmap (Condensed)\n| Version | Focus | Key Items |\n| ------- | ----- | --------- |\n| v0.4 | Structured & Reliability | JSON payload, timeout, structured errors |\n| v0.5 | UX & Pagination | page/order params, limited retry, modular refactor, tests |\n| v0.6 | Multi-source Exploration | Evaluate integrating Unsplash/Pexels abstraction |\n\nSee `product.md` for full backlog & prioritization.\n\n## Contributing\nPlanned contributions welcome once tests & module split land (v0.5 target). Feel free to open issues for API shape / schema suggestions.\n\n## License\nMIT\n\n## Disclaimer\nThis project is not affiliated with Pixabay. Respect Pixabay's Terms of Service and rate limits.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "pixabay",
        "images",
        "mcp",
        "pixabay api",
        "pixabay mcp",
        "connect pixabay"
      ],
      "category": "image-and-video-generation"
    },
    "zym9863--together-ai-image-server": {
      "owner": "zym9863",
      "name": "together-ai-image-server",
      "url": "https://github.com/zym9863/together-ai-image-server",
      "imageUrl": "/freedevtools/mcp/pfp/zym9863.webp",
      "description": "Generates images from text prompts using Together AI's image generation models via the MCP protocol. It supports optional parameters for fine-tuning the image generation process.",
      "stars": 4,
      "forks": 4,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-04-21T08:41:48Z",
      "readme_content": "# Together AI Image Server\n\nEnglish | [简体中文](README_zh.md)\n\nA TypeScript-based MCP (Model Context Protocol) server for generating images using Together AI API.\n\n<a href=\"https://glama.ai/mcp/servers/p1ctvg1l87\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/p1ctvg1l87/badge\" alt=\"Together AI Image Server MCP server\" />\n</a>\n\n## Overview\n\nThis server provides a simple interface to generate images using Together AI's image generation models through the MCP protocol. It allows Claude and other MCP-compatible assistants to generate images based on text prompts.\n\n## Features\n\n### Tools\n\n- `generate_image` - Generate images from text prompts\n  - Takes a text prompt as required parameter\n  - Optional parameters for controlling generation steps and number of images\n  - Returns URLs and local paths to generated images\n\n## Prerequisites\n\n- Node.js (v14 or later recommended)\n- Together AI API key\n\n## Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/zym9863/together-ai-image-server.git\ncd together-ai-image-server\n\n# Install dependencies\nnpm install\n```\n\n## Configuration\n\nSet your Together AI API key as an environment variable:\n\n```bash\n# On Linux/macOS\nexport TOGETHER_API_KEY=\"your-api-key-here\"\n\n# On Windows (Command Prompt)\nset TOGETHER_API_KEY=your-api-key-here\n\n# On Windows (PowerShell)\n$env:TOGETHER_API_KEY=\"your-api-key-here\"\n```\n\nAlternatively, you can create a `.env` file in the project root:\n\n```\nTOGETHER_API_KEY=your-api-key-here\n```\n\n## Development\n\nBuild the server:\n\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n\n```bash\nnpm run watch\n```\n\n## Usage with Claude Desktop\n\nTo use with Claude Desktop, add the server config:\n\nOn macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`  \nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"Together AI Image Server\": {\n      \"command\": \"/path/to/together-ai-image-server/build/index.js\"\n    }\n  }\n}\n```\n\nReplace `/path/to/together-ai-image-server` with the actual path to your installation.\n\n## Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n\n## API Reference\n\n### generate_image\n\nGenerates images based on a text prompt using Together AI's image generation API.\n\n**Parameters:**\n\n- `prompt` (string, required): Text prompt for image generation\n- `steps` (number, optional, default: 4): Number of diffusion steps (1-4)\n- `n` (number, optional, default: 1): Number of images to generate (1-4)\n\n**Returns:**\n\nJSON object containing:\n- `image_urls`: Array of URLs to the generated images\n- `local_paths`: Array of paths to locally cached images\n\n## License\n\nMIT\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "images",
        "ai",
        "image",
        "ai image",
        "generates images",
        "image generation"
      ],
      "category": "image-and-video-generation"
    }
  }
}