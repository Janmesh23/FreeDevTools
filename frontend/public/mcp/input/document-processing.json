{
  "category": "document-processing",
  "categoryDisplay": "Document Processing",
  "description": "",
  "totalRepositories": 326,
  "repositories": {
    "0xshellming--mcp-summarizer": {
      "owner": "0xshellming",
      "name": "mcp-summarizer",
      "url": "https://github.com/0xshellming/mcp-summarizer",
      "imageUrl": "/freedevtools/mcp/pfp/0xshellming.webp",
      "description": "The Content Summarizer Server helps users create brief summaries of various types of written content using advanced AI technology. It simplifies complex materials into easy-to-understand summaries, making it easier to grasp key ideas quickly.",
      "stars": 131,
      "forks": 20,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-10-03T16:15:57Z",
      "readme_content": "# MCP Content Summarizer Server\n\nA Model Context Protocol (MCP) server that provides intelligent summarization capabilities for various types of content using Google's Gemini 1.5 Pro model. This server can help you generate concise summaries while maintaining key information from different content formats.\n\n<a href=\"https://3min.top\"></a>\n\n## Powered by 3MinTop\n\nThe summarization service is powered by [3MinTop](https://3min.top), an AI-powered reading tool that helps you understand a chapter's content in just three minutes. 3MinTop transforms complex content into clear summaries, making learning efficient and helping build lasting reading habits.\n\n## Features\n\n- Universal content summarization using Google's Gemini 1.5 Pro model\n- Support for multiple content types:\n  - Plain text\n  - Web pages\n  - PDF documents\n  - EPUB books\n  - HTML content\n- Customizable summary length\n- Multi-language support\n- Smart context preservation\n- Dynamic greeting resource for testing\n\n## Getting Started\n\n1. Clone this repository\n2. Install dependencies:\n   ```\n   pnpm install\n   ```\n\n3. Build the project:\n   ```\n   pnpm run build\n   ```\n\n4. Start the server:\n   ```\n   pnpm start\n   ```\n\n## Development\n\n- Use `pnpm run dev` to start the TypeScript compiler in watch mode\n- Modify `src/index.ts` to customize server behavior or add new tools\n\n## Usage with Desktop App\n\nTo integrate this server with a desktop app, add the following to your app's server configuration:\n\n```js\n{\n  \"mcpServers\": {\n    \"content-summarizer\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"{ABSOLUTE PATH TO FILE HERE}/dist/index.js\"\n      ]\n    }\n  }\n}\n```\n\n## Available Tools\n\n### summarize\n\nSummarizes content from various sources using the following parameters:\n- `content` (string | object): The input content to summarize. Can be:\n  - Text string\n  - URL for web pages\n  - Base64 encoded PDF\n  - EPUB file content\n- `type` (string): Content type (\"text\", \"url\", \"pdf\", \"epub\")\n- `maxLength` (number, optional): Maximum length of the summary in characters (default: 200)\n- `language` (string, optional): Target language for the summary (default: \"en\")\n- `focus` (string, optional): Specific aspect to focus on in the summary\n- `style` (string, optional): Summary style (\"concise\", \"detailed\", \"bullet-points\")\n\nExample usage:\n\n```typescript\n// Summarize a webpage\nconst result = await server.invoke(\"summarize\", {\n  content: \"https://example.com/article\",\n  type: \"url\",\n  maxLength: 300,\n  style: \"bullet-points\"\n});\n\n// Summarize a PDF document\nconst result = await server.invoke(\"summarize\", {\n  content: pdfBase64Content,\n  type: \"pdf\",\n  language: \"zh\",\n  style: \"detailed\"\n});\n```\n\n### greeting\n\nA dynamic resource that demonstrates basic MCP resource functionality:\n- URI format: `greeting://{name}`\n- Returns a greeting message with the provided name\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "summarizer",
        "summaries",
        "processing",
        "mcp summarizer",
        "summarizer server",
        "content summarizer"
      ],
      "category": "document-processing"
    },
    "1282saa--ppt": {
      "owner": "1282saa",
      "name": "ppt",
      "url": "https://github.com/1282saa/ppt",
      "imageUrl": "/freedevtools/mcp/pfp/1282saa.webp",
      "description": "The PowerPoint Presentation Automation Server allows users to create and edit PowerPoint presentations automatically. It provides an easy way to generate slides, add content, and customize designs through simple API calls or natural language commands.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-04-27T14:27:18Z",
      "readme_content": "# PowerPoint MCP 서버\n\n이 프로젝트는 Model Context Protocol(MCP)을 통해 PowerPoint 프레젠테이션을 자동으로 생성하고 조작할 수 있는 서버를 제공합니다. AI 모델이나 다른 클라이언트가 쉽게 파워포인트 문서를 만들고 편집할 수 있게 합니다.\n\n## 주요 기능\n\n- 새 PowerPoint 프레젠테이션 생성\n- 기존 PowerPoint 파일 열기\n- 슬라이드 추가 및 편집\n- 텍스트, 이미지, 표, 차트 등 요소 추가\n- 다양한 디자인 스타일 선택 및 적용 (default, minimal, modern_blue, corporate, dark_mode)\n- 다크 모드 프레젠테이션 지원\n- 원형 번호 스타일 및 다양한 글머리 기호 지원\n- Claude AI와의 연동을 통한 자연어 -> PPT 생성\n- MCP 프로토콜을 통한 API 제공\n- HTTP API 및 표준 입출력(stdio) 인터페이스 제공\n\n## 프로젝트 구조\n\nmcp개발/\n├── ppt_mcp_server.py # MCP 서버 (HTTP API 및 stdio 모드 지원)\n├── main.py # 메인 진입점\n├── config_loader.py # 설정 로더\n├── ppt_generator.py # PPT 생성 모듈\n├── ppt_utils.py # PPT 유틸리티 함수\n├── smithery.yaml # SmitheryAI 구성 파일\n├── README.md # 문서\n├── requirements.txt # 필요 패키지 목록\n├── data/ # 데이터 폴더\n│ ├── slide_content.json # 슬라이드 내용\n│ └── design_system.json # 디자인 설정 (다양한 스타일 포함)\n└── output/ # 생성된 파일 저장 폴더\n\n````\n\n## 실행 흐름\n\n1. `ppt_mcp_server.py` - MCP 서버로 시작 (HTTP API 또는 stdio 모드)\n2. `config_loader.py`로 디자인 설정 로드\n3. `ppt_generator.py`로 슬라이드 내용 처리 및 PPT 생성\n4. `ppt_utils.py`의 함수들을 통해 PowerPoint 조작\n5. 최종 파일은 지정된 경로에 저장\n\n## 설치 방법\n\n### 요구사항\n\n- Python 3.6 이상\n- 필수 패키지: python-pptx, flask, aiohttp\n\n### 설치 단계\n\n```bash\n# 필요한 패키지 설치\npip install -r requirements.txt\n````\n\n## 실행 방법\n\n### MCP 서버 시작 (HTTP 모드)\n\n```bash\npython ppt_mcp_server.py --host 0.0.0.0 --port 5011\n```\n\n### MCP 서버 시작 (stdio 모드, SmitheryAI 용)\n\n```bash\npython ppt_mcp_server.py --stdio\n```\n\n## 사용 가능한 스타일\n\n서버는 다음과 같은 다양한 PPT 디자인 스타일을 지원합니다:\n\n1. **default**: 기본 스타일\n\n   - Pretendard 폰트, 중앙 정렬\n   - 흰색 배경, 파란색 원형 번호 스타일\n   - 깔끔하고 현대적인 디자인\n\n2. **minimal**: 미니멀 스타일\n\n   - 나눔고딕 폰트, 왼쪽 정렬\n   - 흰색 배경, 심플한 글머리 기호\n   - 간결하고 깔끔한 디자인\n\n3. **modern_blue**: 모던 블루 스타일\n\n   - 본고딕 폰트, 왼쪽 정렬\n   - 흰색 배경, 파란색 원형 번호 스타일\n   - 푸른색 계열의 현대적인 디자인\n\n4. **corporate**: 코퍼레이트 스타일\n\n   - 나눔스퀘어 폰트, 왼쪽 정렬\n   - 흰색 배경, 화살표 형태의 글머리 기호\n   - 기업 프레젠테이션에 적합한 디자인\n\n5. **dark_mode**: 다크 모드 스타일\n   - 프리텐다드 폰트, 중앙 정렬\n   - 검은색 배경, 연두색 원형 번호 스타일\n   - 어두운 배경에 밝은 텍스트의 현대적인 디자인\n\n스타일을 선택하거나 변경하려면 다음 도구를 사용할 수 있습니다:\n\n- `get_styles`: 사용 가능한 스타일 목록 확인\n- `set_style`: 기본 스타일 설정\n\n## 사용 가능한 도구\n\n### 프레젠테이션 도구\n\n- `create_presentation`: 새 프레젠테이션 생성\n- `open_presentation`: 기존 프레젠테이션 열기\n- `save_presentation`: 프레젠테이션 저장\n\n### 슬라이드 도구\n\n- `add_slide`: 슬라이드 추가\n- `set_title`: 슬라이드 제목 설정\n- `add_bullet_points`: 슬라이드에 글머리 기호 추가\n\n### 콘텐츠 생성 도구\n\n- `generate_from_template`: 템플릿과 데이터로 프레젠테이션 생성\n- `claude_to_ppt`: Claude AI를 사용하여 자연어로 PPT 생성\n\n### 스타일 관리 도구\n\n- `get_styles`: 사용 가능한 스타일 목록 확인\n- `set_style`: 기본 스타일 설정\n\n## Claude 데스크톱 연동\n\n본 서버는 Claude 데스크톱 애플리케이션과 연동하여 자연어 프롬프트를 PPT로 변환할 수 있습니다.\n\n### 사용 방법\n\n1. Claude 데스크톱 앱 실행\n2. PPT MCP 서버 실행\n3. MCP 서버에 자연어 프롬프트 전송:\n\n```\nclaude_to_ppt \"인공지능에 관한 발표 자료를 만들어줘\" --output_path \"ai_presentation.pptx\" --style_name \"modern_blue\"\n```\n\n## SmitheryAI 연동\n\n본 서버는 SmitheryAI와 연동될 수 있으며, `smithery.yaml` 파일은, SmitheryAI가 이 서버를 MCP(Model Context Protocol)로 사용할 수 있도록 설정되어 있습니다.\n\n### SmitheryAI에서 사용하는 방법\n\n1. SmitheryAI 실행\n2. 다음 도구들을 사용할 수 있습니다:\n   - `claude_to_ppt`: Claude를 통해 자연어로 PPT 생성\n   - `get_styles`: 사용 가능한 PPT 스타일 목록 확인\n   - `set_style`: 기본 PPT 스타일 설정\n   - 기타 PPT 조작 도구들\n\n## PPT 스타일 커스터마이징\n\n`data/design_system.json` 파일을 수정하여 디자인 스타일을 변경하거나 새로운 스타일을 추가할 수 있습니다.\n\n### 스타일 구조\n\n```json\n{\n  \"styles\": {\n    \"스타일_이름\": {\n      \"slide_layouts\": { ... },\n      \"slide_text_settings\": {\n        \"title_font\": \"폰트명\",\n        \"alignment\": \"정렬(center/left/right)\",\n        ...\n      },\n      \"color_scheme\": {\n        \"background\": [R, G, B],\n        \"primary\": [R, G, B],\n        ...\n      },\n      \"bullet_settings\": {\n        \"type\": \"bullet 타입(circle_number/standard)\",\n        ...\n      },\n      ...\n    },\n    ...\n  },\n  \"current_style\": \"기본_스타일_이름\"\n}\n```\n\n## 문제 해결\n\n- **오류: 패키지를 찾을 수 없음**: `pip install -r requirements.txt` 명령으로 필요한 패키지를 설치합니다.\n- **오류: Claude 데스크톱 연결 실패**: Claude 데스크톱 앱이 실행 중인지, 지정된 포트(기본값: 5000)에서 실행 중인지 확인합니다.\n- **오류: 프레젠테이션을 저장할 수 없음**: 출력 경로가 유효한지, 쓰기 권한이 있는지 확인하세요.\n\n## API 예시\n\n### Claude로 PPT 생성 (HTTP API)\n\n```bash\ncurl -X POST http://localhost:5011/tools/claude-to-ppt \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"message\": \"인공지능의 윤리적 이슈에 대한 발표자료\",\n    \"output_path\": \"ai_ethics.pptx\",\n    \"style_name\": \"modern_blue\"\n  }'\n```\n\n### 사용 가능한 스타일 확인 (HTTP API)\n\n```bash\ncurl -X GET http://localhost:5011/tools/get_styles\n```\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "powerpoint",
        "slides",
        "presentations",
        "ppt powerpoint",
        "powerpoint presentation",
        "powerpoint presentations"
      ],
      "category": "document-processing"
    },
    "1282saa--ppt_se": {
      "owner": "1282saa",
      "name": "ppt_se",
      "url": "https://github.com/1282saa/ppt_se",
      "imageUrl": "/freedevtools/mcp/pfp/1282saa.webp",
      "description": "The PowerPoint Presentation Automation Server allows users to easily create and edit PowerPoint presentations using Python. It streamlines the process of generating slides and incorporating various elements like text, images, and charts, making it accessible for AI models and other applications.",
      "stars": 2,
      "forks": 0,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-08-16T12:14:50Z",
      "readme_content": "# PowerPoint MCP 서버\n\n이 프로젝트는 Model Context Protocol(MCP)을 통해 PowerPoint 프레젠테이션을 자동으로 생성하고 조작할 수 있는 서버를 제공합니다. AI 모델이나 다른 클라이언트가 쉽게 파워포인트 문서를 만들고 편집할 수 있게 합니다.\n\n## 주요 기능\n\n- 새 PowerPoint 프레젠테이션 생성\n- 기존 PowerPoint 파일 열기\n- 슬라이드 추가 및 편집\n- 텍스트, 이미지, 표, 차트 등 요소 추가\n- 디자인 시스템 설정을 통한 일관된 스타일 적용\n- MCP 프로토콜을 통한 API 제공\n\n## 프로젝트 구조\n\nmcp개발/\n├── main.py # 메인 진입점 (새로 생성)\n├── config_loader.py # 설정 로더 (새로 생성)\n├── ppt_generator.py # PPT 생성 모듈 (슬라이드생성.py 이름 변경)\n├── README.md # 문서 (자동화\\_PPT_README.md 이름 변경)\n├── requirements.txt # 필요 패키지 목록\n├── data/ # 데이터 폴더\n│ ├── slide_content.json # 슬라이드 내용 (슬라이드.json 이동)\n│ └── design_system.json # 디자인 설정 (ppt_design_system_config_v2.json 이동)\n├── output/ # 생성된 파일 저장 폴더\n└── utils/ # 유틸리티 모듈 폴더 (기존 그대로 유지)\n\n## 실행 흐름\n\n1. `main.py` - 메인 진입점에서 시작\n2. `config_loader.py`로 디자인 설정 로드\n3. `ppt_generator.py`로 슬라이드 내용 처리 및 PPT 생성\n4. `utils` 모듈들을 통해 PowerPoint 조작\n5. 최종 파일은 `output` 폴더에 저장\n\n## 설치 방법\n\n### 요구사항\n\n- Python 3.6 이상\n- python-pptx 라이브러리\n- mcp 라이브러리\n\n### 설치 단계\n\n```bash\n# 필요한 패키지 설치\npip install python-pptx mcp[cli]\n```\n\n## 실행 방법\n\n### MCP 서버 시작\n\n```bash\npython main.py\n```\n\n기본적으로 서버는 localhost:8000에서 실행됩니다. 다른 호스트/포트를 사용하려면:\n\n```bash\npython main.py --host 0.0.0.0 --port 8080\n```\n\n### 테스트 클라이언트 실행\n\n```bash\npython test_client.py\n```\n\n## 사용 가능한 도구\n\n### 프레젠테이션 도구\n\n- `create_presentation`: 새 프레젠테이션 생성\n- `open_presentation`: 기존 프레젠테이션 열기\n- `save_presentation`: 프레젠테이션 저장\n\n### 슬라이드 도구\n\n- `add_slide_to_presentation`: 슬라이드 추가\n- `add_content_to_slide`: 슬라이드에 내용 추가\n- `add_bullet_points_to_slide`: 슬라이드에 글머리 기호 추가\n\n### 템플릿 도구\n\n- `generate_from_template`: 템플릿과 데이터로 프레젠테이션 생성\n\n## 문제 해결\n\n- **오류: 패키지를 찾을 수 없음**: `pip install python-pptx mcp[cli]` 명령으로 필요한 패키지를 설치합니다.\n- **오류: 서버를 시작할 수 없음**: 포트가 이미 사용 중인지 확인하고, 다른 포트를 지정해 보세요.\n- **오류: 프레젠테이션을 저장할 수 없음**: 출력 경로가 유효한지, 쓰기 권한이 있는지 확인하세요.\n\n## 파일 형식\n\n### 슬라이드 내용 파일 (JSON)\n\n`data/slide_content.json`의 기본 구조는 다음과 같습니다:\n\n```json\n{\n  \"title\": \"프레젠테이션 제목\",\n  \"mainTopics\": {\n    \"주제1\": {\n      \"하위주제1\": { ... },\n      \"하위주제2\": { ... }\n    },\n    \"주제2\": [ ... ]\n  }\n}\n```\n\n### 디자인 시스템 설정 (JSON)\n\n`data/design_system.json`의 기본 구조는 다음과 같습니다:\n\n```json\n{\n  \"slide_text_settings\": {\n    \"title_font\": \"Arial\",\n    \"title_font_size\": 32,\n    ...\n  },\n  \"table_styles\": {\n    \"default\": {\n      \"header_bg_color\": [200, 200, 200],\n      ...\n    }\n  },\n  ...\n}\n```\n\n## 커스터마이징\n\n### 내용 커스터마이징\n\n`data/slide_content.json` 파일을 수정하여 프레젠테이션 내용을 변경할 수 있습니다.\n\n### 디자인 커스터마이징\n\n`data/design_system.json` 파일을 수정하여 디자인 스타일을 변경할 수 있습니다.\n\n### 코드 커스터마이징\n\n`ppt_generator.py` 파일의 다음 메서드를 수정하여 슬라이드 생성 방식을 변경할 수 있습니다:\n\n- `_create_title_slide`: 표지 슬라이드 생성\n- `_create_topic_slides`: 주제별 슬라이드 생성\n- `_create_subtopic_slide`: 하위 주제 슬라이드 생성\n- `_create_term_table`: 용어 정의 테이블 생성\n- `_create_item_list`: 항목 목록 생성\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "powerpoint",
        "slides",
        "presentations",
        "ppt_se powerpoint",
        "powerpoint presentation",
        "powerpoint presentations"
      ],
      "category": "document-processing"
    },
    "2b3pro--markdown2pdf-mcp": {
      "owner": "2b3pro",
      "name": "markdown2pdf-mcp",
      "url": "https://github.com/2b3pro/markdown2pdf-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/2b3pro.webp",
      "description": "This server converts Markdown documents into PDF files, allowing for customizable styles and syntax highlighting for code blocks. It provides an easy way to generate well-formatted PDFs from text-based Markdown content.",
      "stars": 14,
      "forks": 12,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-10-03T22:32:04Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/2b3pro-markdown2pdf-mcp-badge.png)](https://mseep.ai/app/2b3pro-markdown2pdf-mcp)\n\n# Markdown2PDF MCP Server (markdown2pdf-mcp)\n\nAn MCP server for converting Markdown documents to PDF files. This server provides a simple and efficient way to generate PDFs from Markdown content with support for syntax highlighting and custom styling. Also allows for watermarking on page 1.\n\nInspired by Alan Shaw's [markdown-pdf](https://github.com/alanshaw/markdown-pdf).\n\n## Features\n\n- Convert Markdown to PDF with a single command\n- Syntax highlighting for code blocks\n- Custom CSS styling for PDF output\n- Support for standard Markdown formatting\n- Mermaid diagram rendering\n- Modern PDF generation using Chrome's rendering engine\n- Excellent support for modern web features and fonts\n- Reliable resource loading and rendering\n\n## Limitations\n\nThe following markdown elements are not supported:\n\n- LaTeX math equations (e.g., `$x^2$` or `$$\\sum_{i=1}^n x_i$$`)\n- Complex mathematical formulas or scientific notation\n\nStick to these supported markdown elements:\n\n- Headers (all levels)\n- Text formatting (bold, italic, strikethrough)\n- Lists (ordered and unordered)\n- Code blocks with syntax highlighting\n- Tables\n- Blockquotes\n- Links\n- Images (both local files and external URLs)\n- Task lists\n- Mermaid diagrams\n\n### Mermaid Diagrams\n\nTo render a Mermaid diagram, use a `mermaid` code block:\n\n´´´markdown\n\n```mermaid\ngraph TD;\n    A-->B;\n    A-->C;\n    B-->D;\n    C-->D;\n```\n\n´´´\n\nIf there is a syntax error in your diagram, the error message will be rendered in the PDF, helping you to debug it.\n\n## Installation (from source)\n\n```bash\n# Clone the repository\ngit clone https://github.com/2b3pro/markdown2pdf-mcp.git\n\n# Navigate to the project directory\ncd markdown2pdf-mcp\n\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n```\n\n## Installation (via npm)\n\n```bash\nnpm install markdown2pdf-mcp\n```\n\n## Usage\n\n### Starting the Server\n\n```bash\nnpm start\n```\n\n### Using the MCP Tool\n\nThe server provides a single tool `create_pdf_from_markdown` with the following parameters:\n\n```typescript\n{\n  // Required parameters\n  markdown: string;    // Markdown content to convert\n\n  // Optional parameters with defaults\n  outputFilename?: string;  // Filename for the PDF (e.g., \"output.pdf\")\n  paperFormat?: string;     // 'letter' (default), 'a4', 'a3', 'a5', 'legal', 'tabloid'\n  paperOrientation?: string; // 'portrait' (default), 'landscape'\n  paperBorder?: string;     // '2cm' (default), accepts decimal values with CSS units (e.g., '1.5cm', '2.5mm', '0.5in', '10.5px')\n  watermark?: string;       // Optional watermark text (max 15 characters, uppercase)\n}\n```\n\nExample with options:\n\n```typescript\nawait use_mcp_tool({\n  server_name: \"markdown2pdf\",\n  tool_name: \"create_pdf_from_markdown\",\n  arguments: {\n    markdown: \"# Hello World\\n\\nThis is a test document.\",\n    outputFilename: \"output.pdf\",\n    paperFormat: \"a4\",\n    paperOrientation: \"landscape\",\n    paperBorder: \"1.5cm\",\n    watermark: \"DRAFT\",\n  },\n});\n```\n\nExample minimal usage:\n\n```typescript\nawait use_mcp_tool({\n  server_name: \"markdown2pdf\",\n  tool_name: \"create_pdf_from_markdown\",\n  arguments: {\n    markdown: \"# Hello World\\n\\nThis is a test document.\",\n    outputFilename: \"output.pdf\",\n  },\n});\n```\n\n## Configuration\n\n### Output Directory\n\nYou can configure the output directory in your MCP settings file for apps that use MCP such as Cline or Claude. If not configured, it will save files to $HOME:\n\n```json\n{\n  \"mcpServers\": {\n    \"markdown2pdf\": {\n      \"command\": \"node\",\n      \"args\": [\"path/to/markdown2pdf-mcp/build/index.js\"],\n      \"env\": {\n        \"M2P_OUTPUT_DIR\": \"/path/to/output/directory\"\n      }\n    }\n  }\n}\n```\n\nThe tool automatically handles file name conflicts by appending incremental numbers (e.g., output.pdf, output-1.pdf, output-2.pdf).\n\n## Dependencies\n\n- [@modelcontextprotocol/sdk](https://github.com/modelcontextprotocol/sdk) - MCP SDK for server implementation\n- [remarkable](https://github.com/jonschlinkert/remarkable) - Markdown parser\n- [highlight.js](https://github.com/highlightjs/highlight.js) - Syntax highlighting\n- [puppeteer](https://github.com/puppeteer/puppeteer) - Modern PDF generation using [Chrome for Testing](https://developer.chrome.com/blog/chrome-for-testing/) (v131.0.6778.204)\n\n## Chrome Version\n\nThis package uses Chrome v131.0.6778.204 for consistent PDF generation across all installations. This version is automatically installed when you run `npm install`.\n\n- [tmp](https://github.com/raszi/node-tmp) - Temporary file handling\n\n## Development\n\n```bash\n# Build the project\nnpm run build\n\n# Start the server\nnpm start\n```\n\n## License\n\nMIT\n\n## Contributing\n\n1. Fork the repository\n2. Create your feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add some amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "markdown2pdf",
        "markdown",
        "pdf",
        "markdown2pdf mcp",
        "2b3pro markdown2pdf",
        "markdown documents"
      ],
      "category": "document-processing"
    },
    "302ai--302_file_parser_mcp": {
      "owner": "302ai",
      "name": "302_file_parser_mcp",
      "url": "https://github.com/302ai/302_file_parser_mcp",
      "imageUrl": "/freedevtools/mcp/pfp/302ai.webp",
      "description": "The File Parser MCP Server helps you read, modify, and manage files easily. It simplifies the process of file handling, allowing developers to focus on building their applications without getting bogged down in the complexities of dealing with different file types.",
      "stars": 1,
      "forks": 1,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-07-15T13:44:27Z",
      "readme_content": "# 302AI File Parser MCP Server\n\n## Development\n\nInstall dependencies:\n\n```bash\nnpm install\n```\n\nBuild the server:\n\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n\n```bash\nnpm run watch\n```\n\n## Installation\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"302ai-file-parser-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@302ai/file-parser-mcp\"],\n      \"env\": {\n        \"302AI_API_KEY\": \"YOUR_API_KEY_HERE\"\n      }\n    }\n  }\n}\n```\n\nFind Your 302AI_API_KEY [here](https://dash.302.ai/apis/list)\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "302_file_parser_mcp",
        "files",
        "file",
        "302ai 302_file_parser_mcp",
        "302_file_parser_mcp file",
        "file parser"
      ],
      "category": "document-processing"
    },
    "54yyyu--zotero-mcp": {
      "owner": "54yyyu",
      "name": "zotero-mcp",
      "url": "https://github.com/54yyyu/zotero-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/54yyyu.webp",
      "description": "Zotero MCP allows you to link your Zotero research library with AI assistants, enabling you to discuss academic papers, receive summaries, and analyze citations for better research productivity.",
      "stars": 564,
      "forks": 42,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-04T09:19:49Z",
      "readme_content": "# Zotero MCP: Chat with your Research Library—Local or Web—in Claude, ChatGPT, and more.\n\n<p align=\"center\">\n  <a href=\"https://www.zotero.org/\">\n    <img src=\"https://img.shields.io/badge/Zotero-CC2936?style=for-the-badge&logo=zotero&logoColor=white\" alt=\"Zotero\">\n  </a>\n  <a href=\"https://www.anthropic.com/claude\">\n    <img src=\"https://img.shields.io/badge/Claude-6849C3?style=for-the-badge&logo=anthropic&logoColor=white\" alt=\"Claude\">\n  </a>\n  <a href=\"https://chatgpt.com/\">\n    <img src=\"https://img.shields.io/badge/ChatGPT-74AA9C?style=for-the-badge&logo=openai&logoColor=white\" alt=\"ChatGPT\">\n  </a>\n  <a href=\"https://modelcontextprotocol.io/introduction\">\n    <img src=\"https://img.shields.io/badge/MCP-0175C2?style=for-the-badge&logoColor=white\" alt=\"MCP\">\n  </a>\n</p>\n\n**Zotero MCP** seamlessly connects your [Zotero](https://www.zotero.org/) research library with [ChatGPT](https://openai.com), [Claude](https://www.anthropic.com/claude), and other AI assistants (e.g., [Cherry Studio](https://cherry-ai.com/), [Chorus](https://chorus.sh), [Cursor](https://www.cursor.com/)) via the [Model Context Protocol](https://modelcontextprotocol.io/introduction). Review papers, get summaries, analyze citations, extract PDF annotations, and more!\n\n## ✨ Features\n\n### 🧠 AI-Powered Semantic Search\n- **Vector-based similarity search** over your entire research library\n- **Multiple embedding models**: Default (free), OpenAI, and Gemini options\n- **Intelligent results** with similarity scores and contextual matching\n- **Auto-updating database** with configurable sync schedules\n\n### 🔍 Search Your Library\n- Find papers, articles, and books by title, author, or content\n- Perform complex searches with multiple criteria\n- Browse collections, tags, and recent additions\n- **NEW**: Semantic search for conceptual and topic-based discovery\n\n### 📚 Access Your Content\n- Retrieve detailed metadata for any item\n- Get full text content (when available)\n- Access attachments, notes, and child items\n\n### 📝 Work with Annotations\n- Extract and search PDF annotations directly\n- Access Zotero's native annotations\n- Create and update notes and annotations\n\n### 🔄 Easy Updates\n- **Smart update system** that detects your installation method (uv, pip, conda, pipx)\n- **Configuration preservation** - all settings maintained during updates\n- **Version checking** and automatic update notifications\n\n### 🌐 Flexible Access Methods\n- Local method for offline access (no API key needed)\n- Web API for cloud library access\n- Perfect for both local research and remote collaboration\n\n## 🚀 Quick Install\n\n### Default Installation\n\n#### Installing via uv\n\n```bash\nuv tool install \"git+https://github.com/54yyyu/zotero-mcp.git\"\nzotero-mcp setup  # Auto-configure (Claude Desktop supported)\n```\n\n#### Installing via pip\n\n```bash\npip install git+https://github.com/54yyyu/zotero-mcp.git\nzotero-mcp setup  # Auto-configure (Claude Desktop supported)\n```\n\n### Installing via Smithery\n\nTo install Zotero MCP via [Smithery](https://smithery.ai/server/@54yyyu/zotero-mcp) for Claude Desktop:\n\n```bash\nnpx -y @smithery/cli install @54yyyu/zotero-mcp --client claude\n```\n\n#### Updating Your Installation\n\nKeep zotero-mcp up to date with the smart update command:\n\n```bash\n# Check for updates\nzotero-mcp update --check-only\n\n# Update to latest version (preserves all configurations)\nzotero-mcp update\n```\n\n## 🧠 Semantic Search\n\nZotero MCP now includes powerful AI-powered semantic search capabilities that let you find research based on concepts and meaning, not just keywords.\n\n### Setup Semantic Search\n\nDuring setup or separately, configure semantic search:\n\n```bash\n# Configure during initial setup (recommended)\nzotero-mcp setup\n\n# Or configure semantic search separately\nzotero-mcp setup --semantic-config-only\n```\n\n**Available Embedding Models:**\n- **Default (all-MiniLM-L6-v2)**: Free, runs locally, good for most use cases\n- **OpenAI**: Better quality, requires API key (`text-embedding-3-small` or `text-embedding-3-large`)\n- **Gemini**: Better quality, requires API key (`models/text-embedding-004` or experimental models)\n\n**Update Frequency Options:**\n- **Manual**: Update only when you run `zotero-mcp update-db`\n- **Auto on startup**: Update database every time the server starts\n- **Daily**: Update once per day automatically\n- **Every N days**: Set custom interval\n\n### Using Semantic Search\n\nAfter setup, initialize your search database:\n\n```bash\n# Build the semantic search database (fast, metadata-only)\nzotero-mcp update-db\n\n# Build with full-text extraction (slower, more comprehensive)\nzotero-mcp update-db --fulltext\n\n# Check database status\nzotero-mcp db-status\n```\n\n**Example Semantic Queries in your AI assistant:**\n- *\"Find research similar to machine learning concepts in neuroscience\"*\n- *\"Papers that discuss climate change impacts on agriculture\"*\n- *\"Research related to quantum computing applications\"*\n- *\"Studies about social media influence on mental health\"*\n- *\"Find papers conceptually similar to this abstract: [paste abstract]\"*\n\nThe semantic search provides similarity scores and finds papers based on conceptual understanding, not just keyword matching.\n\n## 🖥️ Setup & Usage\n\nFull documentation is available at [Zotero MCP docs](https://stevenyuyy.us/zotero-mcp/).\n\n**Requirements**\n- Python 3.10+\n- Zotero 7+ (for local API with full-text access)\n- An MCP-compatible client (e.g., Claude Desktop, ChatGPT Developer Mode, Cherry Studio, Chorus)\n\n**For ChatGPT setup: see the [Getting Started guide](./docs/getting-started.md).**\n\n### For Claude Desktop (example MCP client)\n\n#### Configuration\nAfter installation, either:\n\n1. **Auto-configure** (recommended):\n   ```bash\n   zotero-mcp setup\n   ```\n\n2. **Manual configuration**:\n   Add to your `claude_desktop_config.json`:\n   ```json\n   {\n     \"mcpServers\": {\n       \"zotero\": {\n         \"command\": \"zotero-mcp\",\n         \"env\": {\n           \"ZOTERO_LOCAL\": \"true\"\n         }\n       }\n     }\n   }\n   ```\n\n#### Usage\n\n1. Start Zotero desktop (make sure local API is enabled in preferences)\n2. Launch Claude Desktop\n3. Access the Zotero-MCP tool through Claude Desktop's tools interface\n\nExample prompts:\n- \"Search my library for papers on machine learning\"\n- \"Find recent articles I've added about climate change\"\n- \"Summarize the key findings from my paper on quantum computing\"\n- \"Extract all PDF annotations from my paper on neural networks\"\n- \"Search my notes and annotations for mentions of 'reinforcement learning'\"\n- \"Show me papers tagged '#Arm' excluding those with '#Crypt' in my library\"\n- \"Search for papers on operating system with tag '#Arm'\"\n- \"Export the BibTeX citation for papers on machine learning\"\n- **\"Find papers conceptually similar to deep learning in computer vision\"** *(semantic search)*\n- **\"Research that relates to the intersection of AI and healthcare\"** *(semantic search)*\n- **\"Papers that discuss topics similar to this abstract: [paste text]\"** *(semantic search)*\n\n### For Cherry Studio\n\n#### Configuration\nGo to Settings -> MCP Servers -> Edit MCP Configuration, and add the following:\n\n```json\n{\n  \"mcpServers\": {\n    \"zotero\": {\n      \"name\": \"zotero\",\n      \"type\": \"stdio\",\n      \"isActive\": true,\n      \"command\": \"zotero-mcp\",\n      \"args\": [],\n      \"env\": {\n        \"ZOTERO_LOCAL\": \"true\"\n      }\n    }\n  }\n}\n```\nThen click \"Save\".\n\nCherry Studio also provides a visual configuration method for general settings and tools selection.\n\n## 🔧 Advanced Configuration\n\n### Using Web API Instead of Local API\n\nFor accessing your Zotero library via the web API (useful for remote setups):\n\n```bash\nzotero-mcp setup --no-local --api-key YOUR_API_KEY --library-id YOUR_LIBRARY_ID\n```\n\n### Environment Variables\n\n**Zotero Connection:**\n- `ZOTERO_LOCAL=true`: Use the local Zotero API (default: false)\n- `ZOTERO_API_KEY`: Your Zotero API key (for web API)\n- `ZOTERO_LIBRARY_ID`: Your Zotero library ID (for web API)\n- `ZOTERO_LIBRARY_TYPE`: The type of library (user or group, default: user)\n\n**Semantic Search:**\n- `ZOTERO_EMBEDDING_MODEL`: Embedding model to use (default, openai, gemini)\n- `OPENAI_API_KEY`: Your OpenAI API key (for OpenAI embeddings)\n- `OPENAI_EMBEDDING_MODEL`: OpenAI model name (text-embedding-3-small, text-embedding-3-large)\n- `GEMINI_API_KEY`: Your Gemini API key (for Gemini embeddings)\n- `GEMINI_EMBEDDING_MODEL`: Gemini model name (models/text-embedding-004, etc.)\n\n### Command-Line Options\n\n```bash\n# Run the server directly\nzotero-mcp serve\n\n# Specify transport method\nzotero-mcp serve --transport stdio|streamable-http|sse\n\n# Setup and configuration\nzotero-mcp setup --help                    # Get help on setup options\nzotero-mcp setup --semantic-config-only    # Configure only semantic search\nzotero-mcp setup-info                      # Show installation path and config info for MCP clients\n\n# Updates and maintenance\nzotero-mcp update                          # Update to latest version\nzotero-mcp update --check-only             # Check for updates without installing\nzotero-mcp update --force                  # Force update even if up to date\n\n# Semantic search database management\nzotero-mcp update-db                       # Update semantic search database (fast, metadata-only)\nzotero-mcp update-db --fulltext             # Update with full-text extraction (comprehensive but slower)\nzotero-mcp update-db --force-rebuild       # Force complete database rebuild\nzotero-mcp update-db --fulltext --force-rebuild  # Rebuild with full-text extraction\nzotero-mcp db-status                       # Show database status and info\n\n# General\nzotero-mcp version                         # Show current version\n```\n\n## 📑 PDF Annotation Extraction\n\nZotero MCP includes advanced PDF annotation extraction capabilities:\n\n- **Direct PDF Processing**: Extract annotations directly from PDF files, even if they're not yet indexed by Zotero\n- **Enhanced Search**: Search through PDF annotations and comments \n- **Image Annotation Support**: Extract image annotations from PDFs\n- **Seamless Integration**: Works alongside Zotero's native annotation system\n\nFor optimal annotation extraction, it is **highly recommended** to install the [Better BibTeX plugin](https://retorque.re/zotero-better-bibtex/installation/) for Zotero. The annotation-related functions have been primarily tested with this plugin and provide enhanced functionality when it's available.\n\n\nThe first time you use PDF annotation features, the necessary tools will be automatically downloaded.\n\n## 📚 Available Tools\n\n### 🧠 Semantic Search Tools\n- `zotero_semantic_search`: AI-powered similarity search with embedding models\n- `zotero_update_search_database`: Manually update the semantic search database\n- `zotero_get_search_database_status`: Check database status and configuration\n\n### 🔍 Search Tools\n- `zotero_search_items`: Search your library by keywords\n- `zotero_advanced_search`: Perform complex searches with multiple criteria\n- `zotero_get_collections`: List collections\n- `zotero_get_collection_items`: Get items in a collection\n- `zotero_get_tags`: List all tags\n- `zotero_get_recent`: Get recently added items\n- `zotero_search_by_tag`: Search your library using custom tag filters\n\n### 📚 Content Tools\n- `zotero_get_item_metadata`: Get detailed metadata (supports BibTeX export via `format=\"bibtex\"`)\n- `zotero_get_item_fulltext`: Get full text content\n- `zotero_get_item_children`: Get attachments and notes\n\n### 📝 Annotation & Notes Tools\n- `zotero_get_annotations`: Get annotations (including direct PDF extraction)\n- `zotero_get_notes`: Retrieve notes from your Zotero library\n- `zotero_search_notes`: Search in notes and annotations (including PDF-extracted)\n- `zotero_create_note`: Create a new note for an item (beta feature)\n\n## 🔍 Troubleshooting\n\n### General Issues\n- **No results found**: Ensure Zotero is running and the local API is enabled. You need to toggle on `Allow other applications on this computer to communicate with Zotero` in Zotero preferences.\n- **Can't connect to library**: Check your API key and library ID if using web API\n- **Full text not available**: Make sure you're using Zotero 7+ for local full-text access\n- **Local library limitations**: Some functionality (tagging, library modifications) may not work with local JS API. Consider using web library setup for full functionality. (See the [docs](docs/getting-started.md#local-library-limitations) for more info.)\n- **Installation/search option switching issues**: Database problems from changing install methods or search options can often be resolved with `zotero-mcp update-db --force-rebuild`\n\n### Semantic Search Issues\n- **\"Missing required environment variables\" when running update-db**: Run `zotero-mcp setup` to configure your environment, or the CLI will automatically load settings from your MCP client config (e.g., Claude Desktop)\n- **ChromaDB warnings**: Update to the latest version - deprecation warnings have been fixed\n- **Database update takes long**: By default, `update-db` is fast (metadata-only). For comprehensive indexing with full-text, use `--fulltext` flag. Use `--limit` parameter for testing: `zotero-mcp update-db --limit 100`\n- **Semantic search returns no results**: Ensure the database is initialized with `zotero-mcp update-db` and check status with `zotero-mcp db-status`\n- **Limited search quality**: For better semantic search results, use `zotero-mcp update-db --fulltext` to index full-text content (requires local Zotero setup)\n- **OpenAI/Gemini API errors**: Verify your API keys are correctly set and have sufficient credits/quota\n\n### Update Issues  \n- **Update command fails**: Check your internet connection and try `zotero-mcp update --force`\n- **Configuration lost after update**: The update process preserves configs automatically, but check `~/.config/zotero-mcp/` for backup files\n\n## 📄 License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "zotero",
        "library",
        "document",
        "mcp zotero",
        "zotero mcp",
        "zotero research"
      ],
      "category": "document-processing"
    },
    "AlexiFeng--MCP_Chat_Logger": {
      "owner": "AlexiFeng",
      "name": "MCP_Chat_Logger",
      "url": "https://github.com/AlexiFeng/MCP_Chat_Logger",
      "imageUrl": "/freedevtools/mcp/pfp/AlexiFeng.webp",
      "description": "Logs chat history in a formatted Markdown file, complete with timestamps for each message. It allows customization of save directories and differentiates conversations using session IDs.",
      "stars": 4,
      "forks": 4,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-04-11T20:31:36Z",
      "readme_content": "# MCP Chat Logger\n\n[![smithery badge](https://smithery.ai/badge/@AlexiFeng/MCP_Chat_Logger)](https://smithery.ai/server/@AlexiFeng/MCP_Chat_Logger)\n\n<div align=\"center\">\n  <a href=\"README_zh.md\">中文</a> | <a href=\"README_en.md\">English</a>\n</div>\n\n---\n\nMCP Chat Logger是一个简单而强大的聊天记录保存工具，可以将聊天历史保存为Markdown格式文件，便于后续查看和分享。\n\n## 功能特点\n\n- 支持大模型调用工具将聊天历史保存为格式化的Markdown文件\n- 自动为每条消息添加时间戳\n- 自定义保存目录\n- 支持会话ID标识不同的对话\n  \n## 下一阶段\n添加Overview功能\n\n### 安装步骤\n\n#### Installing via Smithery\n\nTo install MCP Chat Logger for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@AlexiFeng/MCP_Chat_Logger):\n\n```bash\nnpx -y @smithery/cli install @AlexiFeng/MCP_Chat_Logger --client claude\n```\n\n1. 克隆这个代码库：\n\n```bash\ngit clone https://github.com/yourusername/MCP_Chat_Logger.git\ncd MCP_Chat_Logger\n```\n\n2. 安装依赖：\n提前安装uv\n\n```bash\nuv add \"mcp[cli]\"\n```\n\n## 使用方法\n\n1. 在项目目录启动mcp服务\n```bash\nuv run chat_logger.py\n```\n\n2. 在cursor/cherry studio中添加mcp服务器配置\n\"chat_logger\": {\n      \"name\": \"chat_logger\",\n      \"isActive\": false,\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"项目路径（例如~/MCP_Chat_Logger/）\",\n        \"run\",\n        \"chat_logger.py\"\n      ]\n    }\n\n## 项目结构\n\n```\nMCP_Chat_Logger/\n├── chat_logger.py      # 核心功能实现\n├── chat_logs/          # 默认保存目录\n├── README.md           # 项目说明\n├── README_zh.md        # 中文说明\n├── README_en.md        # 英文说明\n└── .gitignore          # Git忽略文件\n```\n\n## 贡献指南\n\n欢迎提交问题和拉取请求！如果您想贡献代码，请遵循以下步骤：\n\n1. Fork这个仓库\n2. 创建您的特性分支 (`git checkout -b feature/amazing-feature`)\n3. 提交您的更改 (`git commit -m 'Add some amazing feature'`)\n4. 推送到分支 (`git push origin feature/amazing-feature`)\n5. 开启一个Pull Request\n\n## 许可证\n\n该项目采用MIT许可证 - 详情请查看 LICENSE 文件。\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcp_chat_logger",
        "logs",
        "chat",
        "alexifeng mcp_chat_logger",
        "mcp_chat_logger logs",
        "logs chat"
      ],
      "category": "document-processing"
    },
    "Arborist-ai--ClaudeHopper": {
      "owner": "Arborist-ai",
      "name": "ClaudeHopper",
      "url": "https://github.com/Arborist-ai/ClaudeHopper",
      "imageUrl": "/freedevtools/mcp/pfp/Arborist-ai.webp",
      "description": "Interact with construction documents, drawings, and specifications. Analyze technical details and retrieve specific information through advanced retrieval-augmented generation and hybrid search.",
      "stars": 3,
      "forks": 2,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-07-13T23:51:09Z",
      "readme_content": "# 🏗️ ClaudeHopper - AI-Powered Construction Document Assistant\n\n[![Node.js 18+](https://img.shields.io/badge/node-18%2B-blue.svg)](https://nodejs.org/en/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\nClaudeHopper is a specialized Model Context Protocol (MCP) server that enables Claude and other LLMs to interact directly with construction documents, drawings, and specifications through advanced RAG (Retrieval-Augmented Generation) and hybrid search. Ask questions about your construction drawings, locate specific details, and analyze technical specifications with ease.\n\n## ✨ Features\n\n- 🔍 Vector-based search for construction document retrieval optimized for CAD drawings, plans, and specs\n- 🖼️ Visual search to find similar drawings based on textual descriptions\n- 🏢 Specialized metadata extraction for construction industry document formats\n- 📊 Efficient token usage through intelligent document chunking and categorization\n- 🔒 Security through local document storage and processing\n- 📈 Support for various drawing types and construction disciplines (Structural, Civil, Architectural, etc.)\n\n## 🚀 Quick Start\n\n### Prerequisites\n\n- Node.js 18+\n- [Ollama](https://ollama.com/) for local AI models\n  - Required models: `nomic-embed-text`, `phi4`, `clip`\n- Claude Desktop App\n- For image extraction: [Poppler Utils](https://poppler.freedesktop.org/) (`pdfimages` command)\n\n### One-Click Setup\n\n1. Download ClaudeHopper\n2. Run the setup script:\n\n```bash\ncd ~/Desktop/claudehopper\nchmod +x run_now_preserve.sh\n./run_now_preserve.sh\n```\n\nThis will:\n- Create the necessary directory structure\n- Install required AI models\n- Process your construction documents\n- Configure the Claude Desktop App to use ClaudeHopper\n\n### Adding Documents\n\nPlace your construction documents in these folders:\n\n- Drawings: `~/Desktop/PDFdrawings-MCP/InputDocs/Drawings/`\n- Specifications: `~/Desktop/PDFdrawings-MCP/InputDocs/TextDocs/`\n\nAfter adding documents, run:\n```bash\n./process_pdfdrawings.sh\n```\n\n## 🏗️ Using ClaudeHopper with Claude\n\nTry these example questions in the Claude Desktop App:\n\n```\n\"What architectural drawings do we have for the project?\"\n\"Show me the structural details for the foundation system\"\n\"Find drawings that show a concrete foundation with dimensions\"\n\"Search for lift station layout drawings\"\n\"What are the specifications for interior paint?\"\n\"Find all sections discussing fire protection systems\"\n```\n\n## 🛠️ Technical Architecture\n\nClaudeHopper uses a multi-stage pipeline for processing construction documents:\n\n1. **Document Analysis**: PDF documents are analyzed for structure and content type\n2. **Metadata Extraction**: AI-assisted extraction of project information, drawing types, disciplines\n3. **Content Chunking**: Intelligent splitting of documents to maintain context\n4. **Image Extraction**: Identification and extraction of drawing images from PDFs\n5. **Vector Embedding**: Creation of semantic representations for text and images\n6. **Database Storage**: Local LanceDB storage for vector search capabilities\n\n## 👀 Testing the Image Search\n\nTo test the image search functionality, you can use the provided test script:\n\n```bash\n# Make the test script executable\nchmod +x test_image_search.sh\n\n# Run the test script\n./test_image_search.sh\n```\n\nThis will:\n- Build the application\n- Check for required dependencies (like `pdfimages`)\n- Seed the database with images from your drawings directory\n- Run a series of test queries against the image search\n\nYou can also run individual test commands:\n\n```bash\n# Run the test with the default database location\nnpm run test:image:verbose\n\n# Run the test with a specific database location\nnode tools/test_image_search.js /path/to/your/database\n```\n\n## 📝 Available Search Tools\n\nClaudeHopper provides several specialized search capabilities:\n\n- `catalog_search`: Find documents by project, discipline, drawing type, etc.\n- `chunks_search`: Locate specific content within documents\n- `all_chunks_search`: Search across the entire document collection\n- `image_search`: Find drawings based on visual similarity to textual descriptions\n\nExamples of using the image search feature can be found in the [image_search_examples.md](examples/image_search_examples.md) file.\n\n## 📜 License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "retrieval",
        "search",
        "arborist",
        "arborist ai",
        "processing arborist",
        "advanced retrieval"
      ],
      "category": "document-processing"
    },
    "ArchimedesCrypto--excel-reader-mcp": {
      "owner": "ArchimedesCrypto",
      "name": "excel-reader-mcp",
      "url": "https://github.com/ArchimedesCrypto/excel-reader-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/ArchimedesCrypto.webp",
      "description": "Read Excel files with support for automatic chunking and pagination, enabling efficient data handling for large datasets. This server can process multiple sheet selections and provides proper handling of date formats.",
      "stars": 26,
      "forks": 7,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-08-25T10:11:21Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/archimedescrypto-excel-reader-mcp-badge.png)](https://mseep.ai/app/archimedescrypto-excel-reader-mcp)\n\n# MCP Excel Reader\n\n[![smithery badge](https://smithery.ai/badge/@ArchimedesCrypto/excel-reader-mcp-chunked)](https://smithery.ai/server/@ArchimedesCrypto/excel-reader-mcp-chunked)\nA Model Context Protocol (MCP) server for reading Excel files with automatic chunking and pagination support. Built with SheetJS and TypeScript, this tool helps you handle large Excel files efficiently by automatically breaking them into manageable chunks.\n\n<a href=\"https://glama.ai/mcp/servers/jr2ggpdk3a\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/jr2ggpdk3a/badge\" alt=\"Excel Reader MCP server\" /></a>\n\n## Features\n\n- 📊 Read Excel files (.xlsx, .xls) with automatic size limits\n- 🔄 Automatic chunking for large datasets\n- 📑 Sheet selection and row pagination\n- 📅 Proper date handling\n- ⚡ Optimized for large files\n- 🛡️ Error handling and validation\n\n## Installation\n\n### Installing via Smithery\n\nTo install Excel Reader for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@ArchimedesCrypto/excel-reader-mcp-chunked):\n\n```bash\nnpx -y @smithery/cli install @ArchimedesCrypto/excel-reader-mcp-chunked --client claude\n```\n\n### As an MCP Server\n\n1. Install globally:\n```bash\nnpm install -g @archimdescrypto/excel-reader\n```\n\n2. Add to your MCP settings file (usually at `~/.config/claude/settings.json` or equivalent):\n```json\n{\n  \"mcpServers\": {\n    \"excel-reader\": {\n      \"command\": \"excel-reader\",\n      \"env\": {}\n    }\n  }\n}\n```\n\n### For Development\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/ArchimdesCrypto/mcp-excel-reader.git\ncd mcp-excel-reader\n```\n\n2. Install dependencies:\n```bash\nnpm install\n```\n\n3. Build the project:\n```bash\nnpm run build\n```\n\n## Usage\n\n## Usage\n\nThe Excel Reader provides a single tool `read_excel` with the following parameters:\n\n```typescript\ninterface ReadExcelArgs {\n  filePath: string;      // Path to Excel file\n  sheetName?: string;    // Optional sheet name (defaults to first sheet)\n  startRow?: number;     // Optional starting row for pagination\n  maxRows?: number;      // Optional maximum rows to read\n}\n\n// Response format\ninterface ExcelResponse {\n  fileName: string;\n  totalSheets: number;\n  currentSheet: {\n    name: string;\n    totalRows: number;\n    totalColumns: number;\n    chunk: {\n      rowStart: number;\n      rowEnd: number;\n      columns: string[];\n      data: Record<string, any>[];\n    };\n    hasMore: boolean;\n    nextChunk?: {\n      rowStart: number;\n      columns: string[];\n    };\n  };\n}\n```\n\n### Basic Usage\n\nWhen used with Claude or another MCP-compatible AI:\n\n```\nRead the Excel file at path/to/file.xlsx\n```\n\nThe AI will use the tool to read the file, automatically handling chunking for large files.\n\n### Features\n\n1. **Automatic Chunking**\n   - Automatically splits large files into manageable chunks\n   - Default chunk size of 100KB\n   - Provides metadata for pagination\n\n2. **Sheet Selection**\n   - Read specific sheets by name\n   - Defaults to first sheet if not specified\n\n3. **Row Pagination**\n   - Control which rows to read with startRow and maxRows\n   - Get next chunk information for continuous reading\n\n4. **Error Handling**\n   - Validates file existence and format\n   - Provides clear error messages\n   - Handles malformed Excel files gracefully\n\n## Extending with SheetJS Features\n\nThe Excel Reader is built on SheetJS and can be extended with its powerful features:\n\n### Available Extensions\n\n1. **Formula Handling**\n   ```typescript\n   // Enable formula parsing\n   const wb = XLSX.read(data, {\n     cellFormula: true,\n     cellNF: true\n   });\n   ```\n\n2. **Cell Formatting**\n   ```typescript\n   // Access cell styles and formatting\n   const styles = Object.keys(worksheet)\n     .filter(key => key[0] !== '!')\n     .map(key => ({\n       cell: key,\n       style: worksheet[key].s\n     }));\n   ```\n\n3. **Data Validation**\n   ```typescript\n   // Access data validation rules\n   const validation = worksheet['!dataValidation'];\n   ```\n\n4. **Sheet Features**\n   - Merged Cells: `worksheet['!merges']`\n   - Hidden Rows/Columns: `worksheet['!rows']`, `worksheet['!cols']`\n   - Sheet Protection: `worksheet['!protect']`\n\nFor more features and detailed documentation, visit the [SheetJS Documentation](https://docs.sheetjs.com/).\n\n## Contributing\n\n1. Fork the repository\n2. Create your feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add some amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Acknowledgments\n\n- Built with [SheetJS](https://sheetjs.com/)\n- Part of the [Model Context Protocol](https://github.com/modelcontextprotocol/mcp) ecosystem\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "excel",
        "formats",
        "archimedescrypto",
        "archimedescrypto excel",
        "excel reader",
        "document processing"
      ],
      "category": "document-processing"
    },
    "AviOfLagos--MCP-coding-assistant": {
      "owner": "AviOfLagos",
      "name": "MCP-coding-assistant",
      "url": "https://github.com/AviOfLagos/MCP-coding-assistant",
      "imageUrl": "/freedevtools/mcp/pfp/AviOfLagos.webp",
      "description": "Provides coding assistance by offering context-aware code suggestions, integrating project documentation, and detecting programming languages and technologies used in codebases.",
      "stars": 12,
      "forks": 4,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-04-20T08:33:19Z",
      "readme_content": "# Coding Assistant Server\n[![smithery badge](https://smithery.ai/badge/coding-assistant-server)](https://smithery.ai/server/coding-assistant-server)\n\nThe Coding Assistant Server is an MCP (Model Context Protocol) server that enhances the capabilities of the Cline coding agent. It provides intelligent code suggestions, reduces hallucinations, and documents the knowledge base by leveraging your project's documentation and detecting the technologies used in your codebase.\n\n## Features\n\n* **Code Suggestions** : Offers context-aware code suggestions based on your code snippets and project documentation.\n* **Documentation Integration** : Loads and vectorizes documentation files from the `docs` directory or from provided URLs.\n* **Technology Detection** : Automatically detects programming languages, frameworks, and libraries used in your project.\n* **Automatic Documentation Retrieval** : Finds and adds official documentation links for detected technologies to the knowledge base.\n* **Project Path Automation** : Reads the project path from `project_path.txt` to seamlessly integrate with your current project in Cline.\n* **Multiple Documentation Sources** : Accepts multiple documents and links to enrich the knowledge base.\n\n## Installation\n\n### Installing via Smithery\n\nTo install Coding Assistant Server for Cline automatically via [Smithery](https://smithery.ai/server/coding-assistant-server):\n\n```bash\nnpx -y @smithery/cli install coding-assistant-server --client cline\n```\n\n### Prerequisites\n\n* **Node.js** v14 or higher\n* **npm** v6 or higher\n* **OpenAI API Key**\n\n### Steps\n\n1. **Clone the Repository**\n   ```bash\n   git clone [repository-url]\n   ```\n2. **Navigate to the Project Directory**\n   ```bash\n   cd coding-assistant-server\n   ```\n3. **Install Dependencies**\n   ```bash\n   npm install\n   ```\n4. **Set Up Environment Variables**\n   * Create a `.env` file in the root directory.\n   * Add your OpenAI API key:\n     ```javascript\n     OPENAI_API_KEY=your_openai_api_key_here\n     ```\n5. **Build the Project**\n   ```bash\n   npm run build\n   ```\n\n## Usage\n\n### Starting the Server\n\nStart the Coding Assistant MCP server:\n\n```bash\nnode build/index.js\n```\n\n### Integrating with Cline\n\n1. **Update MCP Settings**\n   * Edit your MCP settings configuration file (e.g., `cline_mcp_settings.json`) to include the coding assistant server:\n     ```json\n     {\n       \"mcpServers\": {\n         \"coding-assistant\": {\n           \"command\": \"node\",\n           \"args\": [\"/path/to/coding-assistant-server/build/index.js\"],\n           \"env\": {\n             \"OPENAI_API_KEY\": \"your_openai_api_key_here\"\n           }\n         }\n       }\n     }\n     ```\n2. **Set the Project Path**\n   * Create or update the `project_path.txt` file in the `coding-assistant-server` directory with the absolute path to your current project:\n     ```javascript\n     /path/to/your/project\n     ```\n3. **Restart Cline**\n   * Restart Cline or reload the MCP settings to connect the coding assistant server.\n\n### Using the Tools\n\n#### `get_suggestions` Tool\n\nProvides code suggestions based on the provided code context.\n\n **Example Usage** :\n\n<iframe></iframe>\n\nCline used a tool on the `coding-assistant` MCP server:\n\nget_suggestions\n\nGet code suggestions based on provided code context\n\nArguments\n\n```json\n{\n    \"codeContext\": {\n      \"code\": \"function helloWorld() { console.log('Hello, world!'); }\",\n      \"language\": \"JavaScript\"\n    }\n  }\n```\n\n<iframe></iframe>\n\nResponse\n\n```json\n{\n  \"suggestions\": [\n    {\n      \"source\": \"example.txt\",\n      \"content\": \"# Coding Assistant Documentation\\n\\nThis is a sample documentation file for the coding assistant server. You can add more documentation files here for the server to use.\\n\"\n    }\n  ]\n}\n```\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "coding",
        "codebases",
        "programming",
        "coding assistant",
        "coding assistance",
        "provides coding"
      ],
      "category": "document-processing"
    },
    "AvinashBole--quip-mcp-server": {
      "owner": "AvinashBole",
      "name": "quip-mcp-server",
      "url": "https://github.com/AvinashBole/quip-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/AvinashBole.webp",
      "description": "Interact directly with Quip documents to read, append, prepend, and replace content, enhancing document management capabilities for AI assistants.",
      "stars": 4,
      "forks": 4,
      "license": "ISC License",
      "language": "JavaScript",
      "updated_at": "2025-08-28T19:40:34Z",
      "readme_content": "# Quip MCP Server\n\nA Model Context Protocol (MCP) server for Quip document operations that enables direct interaction with Quip documents from AI assistants like Claude.\n\n## Features\n\n- **Read Documents**: Fetch and display Quip document content by ID\n- **Append Content**: Add content to the end of existing documents\n- **Prepend Content**: Add content to the beginning of documents\n- **Replace Content**: Update document content\n- **Create Documents**: Intended support for creating new documents (currently redirects to web interface)\n\n## How It Works\n\nThis MCP server acts as a bridge between Claude and Quip documents. It works by:\n\n1. Receiving requests from Claude through the MCP protocol\n2. Executing a Python script (`quip_edit_fixed.py`) with the appropriate parameters\n3. Returning the results back to Claude\n\n## Prerequisites\n\n- Node.js v18 or higher\n- TypeScript\n- Python with `quip` library installed\n- A valid Quip access token\n\n## Installation\n\n1. Clone this repository:\n   ```\n   git clone https://github.com/AvinashBole/quip-mcp-server.git\n   cd quip-mcp-server\n   ```\n\n2. Install dependencies:\n   ```\n   npm install\n   ```\n\n3. Build the project:\n   ```\n   npm run build\n   ```\n\n4. Configure your MCP settings:\n   ```json\n   {\n     \"mcpServers\": {\n       \"quip\": {\n         \"command\": \"node\",\n         \"args\": [\"path/to/quip-server/build/index.js\"],\n         \"env\": {\n           \"QUIP_ACCESS_TOKEN\": \"your-quip-access-token\",\n           \"QUIP_BASE_URL\": \"https://platform.quip.com\"\n         },\n         \"disabled\": false,\n         \"autoApprove\": []\n       }\n     }\n   }\n   ```\n\n## Usage\n\nOnce connected, the following MCP tools become available to Claude:\n\n- `quip_read_document`: Read a Quip document by its thread ID\n- `quip_append_content`: Append content to a document\n- `quip_prepend_content`: Add content to the beginning of a document\n- `quip_replace_content`: Replace document content\n- `quip_create_document`: Create a new document (currently unsupported)\n\nExample usage in Claude:\n\n```\n<use_mcp_tool>\n<server_name>quip</server_name>\n<tool_name>quip_read_document</tool_name>\n<arguments>\n{\n  \"threadId\": \"YOUR_DOCUMENT_ID\"\n}\n</arguments>\n</use_mcp_tool>\n```\n\n## Python Script Integration\n\nThe server expects a Python script called `quip_edit_fixed.py` in the path specified by the `PYTHON_SCRIPT_PATH` constant. This script should support the following operations:\n\n- `read`: Read document content\n- `append`: Add content to the end of a document\n- `prepend`: Add content to the beginning of a document \n- `replace`: Update document content\n\n## License\n\nISC License\n\n## Author\n\nAvinashBole\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "quip",
        "document",
        "processing",
        "quip documents",
        "document processing",
        "quip mcp"
      ],
      "category": "document-processing"
    },
    "BH-NOTHING--quill": {
      "owner": "BH-NOTHING",
      "name": "quill",
      "url": "https://github.com/BH-NOTHING/quill",
      "imageUrl": "/freedevtools/mcp/pfp/BH-NOTHING.webp",
      "description": "A rich text editor that enables the creation and manipulation of formatted text content in web applications, supporting various styles and formats. It provides an intuitive interface and robust features for enhanced user engagement.",
      "stars": 0,
      "forks": 0,
      "license": "BSD 3-Clause \"New\" or \"Revised\" License",
      "language": "JavaScript",
      "updated_at": "2024-05-28T03:01:52Z",
      "readme_content": "Note: This branch and README covers the upcoming 2.0 release. View [1.x docs here](https://github.com/quilljs/quill/tree/1.3.6).\n\n<h1 align=\"center\">\n  <a href=\"https://quilljs.com/\" title=\"Quill\">Quill Rich Text Editor</a>\n</h1>\n<p align=\"center\">\n  <a href=\"https://quilljs.com/\" title=\"Quill\"><img alt=\"Quill Logo\" src=\"https://quilljs.com/assets/images/logo.svg\" width=\"180\"></a>\n</p>\n<p align=\"center\">\n  <a title=\"Quickstart\" href=\"#quickstart\"><strong>Quickstart</strong></a>\n  &#x2022;\n  <a title=\"Documentation\" href=\"https://quilljs.com/docs/\"><strong>Documentation</strong></a>\n  &#x2022;\n  <a title=\"Development\" href=\"https://github.com/quilljs/quill/blob/master/.github/DEVELOPMENT.md\"><strong>Development</strong></a>\n  &#x2022;\n  <a title=\"Contributing\" href=\"https://github.com/quilljs/quill/blob/master/.github/CONTRIBUTING.md\"><strong>Contributing</strong></a>\n  &#x2022;\n  <a title=\"Interactive Playground\" href=\"https://quilljs.com/playground/\"><strong>Interactive Playground</strong></a>\n</p>\n<p align=\"center\">\n  <a href=\"https://travis-ci.org/quilljs/quill\" title=\"Build Status\">\n    <img src=\"https://travis-ci.org/quilljs/quill.svg?branch=master\" alt=\"Build Status\">\n  </a>\n  <a href=\"https://npmjs.com/package/quill\" title=\"Version\">\n    <img src=\"https://img.shields.io/npm/v/quill.svg\" alt=\"Version\">\n  </a>\n  <a href=\"https://npmjs.com/package/quill\" title=\"Downloads\">\n    <img src=\"https://img.shields.io/npm/dm/quill.svg\" alt=\"Downloads\">\n  </a>\n</p>\n<p align=\"center\">\n  <a href=\"https://saucelabs.com/u/quill\" title=\"Test Status\">\n    <img src=\"https://cdn.quilljs.com/badge.svg?v=2\" alt=\"Test Status\">\n  </a>\n</p>\n\n[Quill](https://quilljs.com/) is a modern rich text editor built for compatibility and extensibility. It was created by [Jason Chen](https://twitter.com/jhchen) and [Byron Milligan](https://twitter.com/byronmilligan) and actively maintained by [Slab](https://slab.com).\n\nTo get started, check out [https://quilljs.com/](https://quilljs.com/) for documentation, guides, and live demos!\n\n\n## Quickstart\n\nInstantiate a new Quill object with a css selector for the div that should become the editor.\n\n```html\n<!-- Include Quill stylesheet -->\n<link href=\"https://cdn.quilljs.com/1.0.0/quill.snow.css\" rel=\"stylesheet\">\n\n<!-- Create the toolbar container -->\n<div id=\"toolbar\">\n  <button class=\"ql-bold\">Bold</button>\n  <button class=\"ql-italic\">Italic</button>\n</div>\n\n<!-- Create the editor container -->\n<div id=\"editor\">\n  <p>Hello World!</p>\n</div>\n\n<!-- Include the Quill library -->\n<script src=\"https://cdn.quilljs.com/1.0.0/quill.js\"></script>\n\n<!-- Initialize Quill editor -->\n<script>\n  var editor = new Quill('#editor', {\n    modules: { toolbar: '#toolbar' },\n    theme: 'snow'\n  });\n</script>\n```\n\nTake a look at the [Quill](https://quilljs.com/) website for more documentation, guides and [live playground](https://quilljs.com/playground/)!\n\n\n## Download\n\n- [npm](https://www.npmjs.com/package/quill) - `npm install quill`\n- tar - https://github.com/quilljs/quill/releases\n\n\n### CDN\n\n```html\n<!-- Main Quill library -->\n<script src=\"//cdn.quilljs.com/1.0.0/quill.js\"></script>\n<script src=\"//cdn.quilljs.com/1.0.0/quill.min.js\"></script>\n\n<!-- Theme included stylesheets -->\n<link href=\"//cdn.quilljs.com/1.0.0/quill.snow.css\" rel=\"stylesheet\">\n<link href=\"//cdn.quilljs.com/1.0.0/quill.bubble.css\" rel=\"stylesheet\">\n\n<!-- Core build with no theme, formatting, non-essential modules -->\n<link href=\"//cdn.quilljs.com/1.0.0/quill.core.css\" rel=\"stylesheet\">\n<script src=\"//cdn.quilljs.com/1.0.0/quill.core.js\"></script>\n  ```\n\n\n## Community\n\nGet help or stay up to date.\n\n- [Contribute](https://github.com/quilljs/quill/blob/develop/.github/CONTRIBUTING.md) on [Issues](https://github.com/quilljs/quill/issues)\n- Follow [@jhchen](https://twitter.com/jhchen) and [@quilljs](https://twitter.com/quilljs) on Twitter\n- Ask questions on [Stack Overflow](https://stackoverflow.com/questions/tagged/quill)\n- If privacy is required, email support@quilljs.com\n\n\n## License\n\nBSD 3-clause\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "editor",
        "document",
        "text",
        "document processing",
        "text editor",
        "processing bh"
      ],
      "category": "document-processing"
    },
    "BearCNR--fivem-docs": {
      "owner": "BearCNR",
      "name": "fivem-docs",
      "url": "https://github.com/BearCNR/fivem-docs",
      "imageUrl": "/freedevtools/mcp/pfp/BearCNR.webp",
      "description": "FiveM Documentation is a resource hub that provides guides and reference materials for developers working with FiveM, a multiplayer modification framework for Grand Theft Auto V. It aims to assist users in creating and managing their FiveM servers effectively.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "",
      "updated_at": "2025-03-07T18:56:14Z",
      "readme_content": "# FiveM Documentation 📚\n\nWelcome to the FiveM Documentation! This is the official source. You can explore detailed guides, reference materials, and development resources here.\n\n🔗 **Source:** [docs.fivem.net][docs]\n\n## Development 🚀\n\nIf you encounter any dead links or issues, please report them on our [GitHub Issues Page](https://github.com/citizenfx/fivem-docs/issues). Your feedback helps us improve!\n\n### Wanna Contribute? 🤝\n\nWe love contributions! If you're interested in helping out, check out our [Contribution Guidelines](content/docs/contributing/how-you-can-help.md) to get started.\n\n[docs]: https://docs.fivem.net\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "documentation",
        "document",
        "fivem",
        "fivem documentation",
        "fivem docs",
        "docs fivem"
      ],
      "category": "document-processing"
    },
    "Braffolk--mcp-summarization-functions": {
      "owner": "Braffolk",
      "name": "mcp-summarization-functions",
      "url": "https://github.com/Braffolk/mcp-summarization-functions",
      "imageUrl": "/freedevtools/mcp/pfp/Braffolk.webp",
      "description": "Provides intelligent text summarization to condense output and reduce token usage, preventing potential crashes during extensive tasks.",
      "stars": 36,
      "forks": 11,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-30T09:20:03Z",
      "readme_content": "<div align=\"center\">\n\n# Summarization Functions\n\n### Intelligent text summarization for the Model Context Protocol\n\n[Features](#features) •\n[AI Agent Integration](#ai-agent-integration) •\n[Installation](#installation) •\n[Usage](#usage)\n\n[![smithery badge](https://smithery.ai/badge/mcp-summarization-functions)](https://smithery.ai/server/mcp-summarization-functions)\n[![npm version](https://badge.fury.io/js/mcp-summarization-functions.svg)](https://www.npmjs.com/package/mcp-summarization-functions)\n\n</div>\n\n---\n\n## Overview\n\nA powerful MCP server that provides intelligent summarization capabilities through a clean, extensible architecture. Built with modern TypeScript and designed for seamless integration with AI workflows.\n\n## Installation\n\n### Installing via Smithery\n\nTo install Summarization Functions for Claude Desktop automatically via [Smithery](https://smithery.ai/server/mcp-summarization-functions):\n\n```bash\nnpx -y @smithery/cli install mcp-summarization-functions --client claude\n```\n\n```bash\nnpm i mcp-summarization-functions\n```\n\n## AI Agent Integration\n\nThis MCP server was primarily developed to enhance the performance and reliability of AI agents like Roo Cline and Cline. It addresses a critical challenge in AI agent operations: context window management.\n\n### Context Window Optimization\n\nAI agents frequently encounter situations where their context window gets rapidly filled with large outputs from:\n- Command execution results\n- File content readings\n- Directory listings\n- API responses\n- Error messages and stack traces\n\nThis server helps maintain efficient context usage by:\n1. Providing concise, relevant summaries instead of full content\n2. Storing full content for reference when needed\n3. Offering focused analysis based on specific needs (security, API surface, etc.)\n4. Supporting multiple output formats for optimal context utilization\n\n### Benefits for AI Agents\n\n- **Reduced Failure Rates**: By preventing context window overflow\n- **Improved Response Quality**: Through focused, relevant summaries\n- **Enhanced Efficiency**: By maintaining important context while reducing noise\n- **Better Resource Management**: Through intelligent content caching and retrieval\n- **Flexible Integration**: Supporting multiple AI providers and configuration options\n\n### Recommended AI Agent Prompt\n\nWhen integrating with AI agents, include the following in your agent's instructions:\n\n```\n# CONTEXT MANAGEMENT\n\nYou have access to summarization functions through the MCP server. These functions are NOT optional - you MUST use them for ALL potentially large outputs to prevent context overflow:\n\nMANDATORY SUMMARIZATION:\n- You MUST ALWAYS use summarization functions for:\n    - ANY first time file reading operations (unless you are CERTAIN its small and you are going to edit it)\n    - ALL command execution outputs\n    - EVERY directory analysis\n    - ANY API responses or error logs\n    - ANY output that could be large\n\nNEVER attempt to process raw output directly - ALWAYS use the appropriate summarization function:\n• For commands: summarize_command\n• For files: summarize_files\n• For directories: summarize_directory\n• For other text: summarize_text\n\nALWAYS utilize available features:\n• Specify hints for focused analysis\n• Choose appropriate output formats\n• Use content IDs to access full details only when absolutely necessary\n\nThere is NO NEED to process perfect or complete output. Summarized content is ALWAYS preferred over raw data. When in doubt, use summarization.\n```\n\n<b>Summarization in action on the Ollama repository (Gemini 2.0 Flash summarization, Claude 3.5 agent)</b>\n\n\n\n\n## Features\n\n- **Command Output Summarization**  \n  Execute commands and get concise summaries of their output\n\n- **File Content Analysis**  \n  Summarize single or multiple files while maintaining technical accuracy\n\n- **Directory Structure Understanding**  \n  Get clear overviews of complex directory structures\n\n- **Flexible Model Support**\n  Use models from different providers\n\n- **AI Agent Context Optimization**\n  Prevent context window overflow and improve AI agent performance through intelligent summarization\n\n## Configuration\n\nThe server supports multiple AI providers through environment variables:\n\n### Required Environment Variables\n\n- `PROVIDER`: AI provider to use. Supported values:\n\t\t- `ANTHROPIC` - Claude models from Anthropic\n\t\t- `OPENAI` - GPT models from OpenAI\n\t\t- `OPENAI-COMPATIBLE` - OpenAI-compatible APIs (e.g. Azure)\n\t\t- `GOOGLE` - Gemini models from Google\n- `API_KEY`: API key for the selected provider\n\n### Optional Environment Variables\n\n- `MODEL_ID`: Specific model to use (defaults to provider's standard model)\n- `PROVIDER_BASE_URL`: Custom API endpoint for OpenAI-compatible providers\n- `MAX_TOKENS`: Maximum tokens for model responses (default: 1024)\n- `SUMMARIZATION_CHAR_THRESHOLD`: Character count threshold for when to summarize (default: 512)\n- `SUMMARIZATION_CACHE_MAX_AGE`: Cache duration in milliseconds (default: 3600000 - 1 hour)\n- `MCP_WORKING_DIR` - fallback directory for trying to find files with relative paths from\n\n### Example Configurations\n\n```bash\n# Anthropic Configuration\nPROVIDER=ANTHROPIC\nAPI_KEY=your-anthropic-key\nMODEL_ID=claude-3-5-sonnet-20241022\n\n# OpenAI Configuration\nPROVIDER=OPENAI\nAPI_KEY=your-openai-key\nMODEL_ID=gpt-4-turbo-preview\n\n# Azure OpenAI Configuration\nPROVIDER=OPENAI-COMPATIBLE\nAPI_KEY=your-azure-key\nPROVIDER_BASE_URL=https://your-resource.openai.azure.com\nMODEL_ID=your-deployment-name\n\n# Google Configuration\nPROVIDER=GOOGLE\nAPI_KEY=your-google-key\nMODEL_ID=gemini-2.0-flash-exp\n```\n\n## Usage\n\nAdd the server to your MCP configuration file:\n\n```json\n{\n\t\t\"mcpServers\": {\n\t\t\t\t\"MUST_USE_summarization\": {\n\t\t\t\t\t\t\"command\": \"node\",\n\t\t\t\t\t\t\"args\": [\"path/to/summarization-functions/build/index.js\"],\n\t\t\t\t\t\t\"env\": {\n\t\t\t\t\t\t\t\t\"PROVIDER\": \"ANTHROPIC\",\n\t\t\t\t\t\t\t\t\"API_KEY\": \"your-api-key\",\n\t\t\t\t\t\t\t\t\"MODEL_ID\": \"claude-3-5-sonnet-20241022\",\n                \"MCP_WORKING_DIR\": \"default_working_directory\"\n\t\t\t\t\t\t}\n\t\t\t\t}\n\t\t}\n}\n```\n\n### Available Functions\n\nThe server provides the following summarization tools:\n\n#### `summarize_command`\nExecute and summarize command output.\n```typescript\n{\n  // Required\n  command: string,    // Command to execute\n  cwd: string,       // Working directory for command execution\n  \n  // Optional\n  hint?: string,      // Focus area: \"security_analysis\" | \"api_surface\" | \"error_handling\" | \"dependencies\" | \"type_definitions\"\n  output_format?: string  // Format: \"text\" | \"json\" | \"markdown\" | \"outline\" (default: \"text\")\n}\n```\n\n#### `summarize_files`\nSummarize file contents.\n```typescript\n{\n  // Required\n  paths: string[],    // Array of file paths to summarize (relative to cwd)\n  cwd: string,       // Working directory for resolving file paths\n  \n  // Optional\n  hint?: string,      // Focus area: \"security_analysis\" | \"api_surface\" | \"error_handling\" | \"dependencies\" | \"type_definitions\"\n  output_format?: string  // Format: \"text\" | \"json\" | \"markdown\" | \"outline\" (default: \"text\")\n}\n```\n\n#### `summarize_directory`\nGet directory structure overview.\n```typescript\n{\n  // Required\n  path: string,       // Directory path to summarize (relative to cwd)\n  cwd: string,       // Working directory for resolving directory path\n  \n  // Optional\n  recursive?: boolean,  // Whether to include subdirectories. Safe for deep directories\n  hint?: string,       // Focus area: \"security_analysis\" | \"api_surface\" | \"error_handling\" | \"dependencies\" | \"type_definitions\"\n  output_format?: string   // Format: \"text\" | \"json\" | \"markdown\" | \"outline\" (default: \"text\")\n}\n```\n\n#### `summarize_text`\nSummarize arbitrary text content.\n```typescript\n{\n  // Required\n  content: string,    // Text content to summarize\n  type: string,       // Type of content (e.g., \"log output\", \"API response\")\n  \n  // Optional\n  hint?: string,      // Focus area: \"security_analysis\" | \"api_surface\" | \"error_handling\" | \"dependencies\" | \"type_definitions\"\n  output_format?: string  // Format: \"text\" | \"json\" | \"markdown\" | \"outline\" (default: \"text\")\n}\n```\n\n#### `get_full_content`\nRetrieve the full content for a given summary ID.\n```typescript\n{\n  // Required\n  id: string         // ID of the stored content\n}\n```\n\n\n\n## Running evals\n\nThe evals package loads an mcp client that then runs the index.ts file, so there is no need to rebuild between tests. You can load environment variables by prefixing the npx command. Full documentation can be found [here](https://www.mcpevals.io/docs).\n\n```bash\nOPENAI_API_KEY=your-key  npx mcp-eval src/evals/evals.ts src/server/mcp-server.ts\n```\n## License\n\nMIT",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "summarization",
        "braffolk",
        "text",
        "mcp summarization",
        "text summarization",
        "summarization functions"
      ],
      "category": "document-processing"
    },
    "Cam10001110101--mcp-server-obsidian-jsoncanvas": {
      "owner": "Cam10001110101",
      "name": "mcp-server-obsidian-jsoncanvas",
      "url": "https://github.com/Cam10001110101/mcp-server-obsidian-jsoncanvas",
      "imageUrl": "/freedevtools/mcp/pfp/Cam10001110101.webp",
      "description": "Create, modify, and validate infinite canvas data structures using a comprehensive set of tools that manage nodes and edges while ensuring compliance with the official JSON Canvas specification.",
      "stars": 8,
      "forks": 7,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-05T05:18:59Z",
      "readme_content": "# JSON Canvas MCP Server\n\nA Model Context Protocol (MCP) server implementation that provides tools for working with JSON Canvas files according to the [official specification](https://jsoncanvas.org/spec/1.0/). This server enables creating, modifying, and validating infinite canvas data structures.\n\n## Overview\n\nThe JSON Canvas MCP server provides a complete implementation of the JSON Canvas 1.0 specification, enabling:\n\n- Creation and manipulation of infinite canvas data\n- Support for all node types (text, file, link, group)\n- Edge connections with styling and labels\n- Validation against the specification\n- Configurable output paths\n\n## Components\n\n### Resources\n\nThe server exposes the following resources:\n\n- `canvas://schema`: JSON Schema for validating canvas files\n- `canvas://examples`: Example canvas files demonstrating different features\n- `canvas://templates`: Templates for creating new canvases\n\n### Tools\n\n#### Node Operations\n\n- **create_node**\n  - Create a new node of any supported type\n  - Input:\n    - `type` (string): Node type (\"text\", \"file\", \"link\", \"group\")\n    - `properties` (object): Node-specific properties\n      - Common: `id`, `x`, `y`, `width`, `height`, `color`\n      - Type-specific: `text`, `file`, `url`, etc.\n  - Returns: Created node object\n\n- **update_node**\n  - Update an existing node's properties\n  - Input:\n    - `id` (string): Node ID to update\n    - `properties` (object): Properties to update\n  - Returns: Updated node object\n\n- **delete_node**\n  - Remove a node and its connected edges\n  - Input:\n    - `id` (string): Node ID to delete\n  - Returns: Success confirmation\n\n#### Edge Operations\n\n- **create_edge**\n  - Create a new edge between nodes\n  - Input:\n    - `id` (string): Unique edge identifier\n    - `fromNode` (string): Source node ID\n    - `toNode` (string): Target node ID\n    - `fromSide` (optional string): Start side (\"top\", \"right\", \"bottom\", \"left\")\n    - `toSide` (optional string): End side\n    - `color` (optional string): Edge color\n    - `label` (optional string): Edge label\n  - Returns: Created edge object\n\n- **update_edge**\n  - Update an existing edge's properties\n  - Input:\n    - `id` (string): Edge ID to update\n    - `properties` (object): Properties to update\n  - Returns: Updated edge object\n\n- **delete_edge**\n  - Remove an edge\n  - Input:\n    - `id` (string): Edge ID to delete\n  - Returns: Success confirmation\n\n#### Canvas Operations\n\n- **validate_canvas**\n  - Validate a canvas against the specification\n  - Input:\n    - `canvas` (object): Canvas data to validate\n  - Returns: Validation results with any errors\n\n- **export_canvas**\n  - Export canvas to different formats\n  - Input:\n    - `format` (string): Target format (\"json\", \"svg\", \"png\")\n    - `canvas` (object): Canvas data to export\n  - Returns: Exported canvas in requested format\n\n## Usage with Claude Desktop\n\n### Docker\n\nAdd this to your `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"jsoncanvas\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-v\",\n        \"canvas-data:/data\",\n        \"mcp/jsoncanvas\"\n      ],\n      \"env\": {\n        \"OUTPUT_PATH\": \"/data/output\"\n      }\n    }\n  }\n}\n```\n\n### UV\n\n```json\n{\n  \"mcpServers\": {\n    \"jsoncanvas\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/path/to/jsoncanvas\",\n        \"run\",\n        \"mcp-server-jsoncanvas\"\n      ],\n      \"env\": {\n        \"OUTPUT_PATH\": \"./output\"\n      }\n    }\n  }\n}\n```\n\n## Configuration\n\nThe server can be configured using environment variables:\n\n- `OUTPUT_PATH`: Directory where canvas files will be saved (default: \"./output\")\n- `FORMAT`: Default output format for canvas files (default: \"json\")\n\n## Building\n\n### Docker Build\n\n```bash\ndocker build -t mcp/jsoncanvas .\n```\n\n### Local Build\n\n```bash\n# Install uv if not already installed\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Create virtual environment and install dependencies\nuv venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\nuv pip install -e .\n\n# Run tests\npytest\n```\n\n## Example Usage\n\n### Creating a Canvas\n\n```python\nfrom jsoncanvas import Canvas, TextNode, Edge\n\n# Create nodes\ntitle = TextNode(\n    id=\"title\",\n    x=100,\n    y=100,\n    width=400,\n    height=100,\n    text=\"# Hello Canvas\\n\\nThis is a demonstration.\",\n    color=\"#4285F4\"\n)\n\ninfo = TextNode(\n    id=\"info\",\n    x=600,\n    y=100,\n    width=300,\n    height=100,\n    text=\"More information here\",\n    color=\"2\"  # Using preset color\n)\n\n# Create canvas\ncanvas = Canvas()\ncanvas.add_node(title)\ncanvas.add_node(info)\n\n# Connect nodes\nedge = Edge(\n    id=\"edge1\",\n    from_node=\"title\",\n    to_node=\"info\",\n    from_side=\"right\",\n    to_side=\"left\",\n    label=\"Connection\"\n)\ncanvas.add_edge(edge)\n\n# Save canvas\ncanvas.save(\"example.canvas\")\n```\n\n## License\n\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "canvas",
        "jsoncanvas",
        "nodes",
        "canvas data",
        "json canvas",
        "canvas specification"
      ],
      "category": "document-processing"
    },
    "CartographAI--atlas-docs-mcp": {
      "owner": "CartographAI",
      "name": "atlas-docs-mcp",
      "url": "https://github.com/CartographAI/atlas-docs-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/CartographAI.webp",
      "description": "Provides AI assistants with access to clean markdown documentation for various libraries and frameworks, enhancing their ability to utilize less popular or newly released libraries.",
      "stars": 33,
      "forks": 5,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-26T17:17:13Z",
      "readme_content": "# Atlas Docs MCP Server\n\n[![NPM Version](https://img.shields.io/npm/v/%40cartographai%2Fatlas-docs-mcp)](https://www.npmjs.com/package/@cartographai/atlas-docs-mcp)\n[![smithery badge](https://smithery.ai/badge/@CartographAI/atlas-docs-mcp)](https://smithery.ai/server/@CartographAI/atlas-docs-mcp)\n\nA [Model Context Protocol (MCP)](https://modelcontextprotocol.io/introduction) server that provides AI assistants with documentation for libraries and frameworks.\n\n> [!WARNING]\n> Atlas Docs is currently in beta. Not everything might work perfectly, but we're actively improving the service. Your patience and [feedback](#support--feedback) are greatly appreciated!\n\n## What Does This Server Do?\n\nLLMs are great at generating general code, but suck at correctly using less popular or newly released libraries. This isn't surprising, since the models have not been trained comprehensively on code using these libraries.\n\nAtlas Docs MCP server:\n\n- Provides technical documentation for libraries and frameworks\n- Processes the official docs into a clean markdown version for LLM consumption\n- Is easy to set up with Cursor, Cline, Windsurf and any other MCP-compatible LLM clients\n\n**Claude 3.5 Sonnet on its own:**\n\n![elevenlabs-without-atlas-annotated](https://github.com/user-attachments/assets/78b8309c-0f86-4b20-93d7-2116419f75fd)\n\n**Claude 3.5 Sonnet with Atlas Docs MCP:**\n\n![elevenlabs-with-atlas-annotated](https://github.com/user-attachments/assets/258c5126-242f-43d1-8e78-ea655f44d76a)\n\n<video src=\"https://github.com/user-attachments/assets/5fb1f3f2-18db-4ba4-8f47-da3892af22ee\"></video>\n\n## 📦 Installation\n\nAtlas Docs MCP server works with any MCP client that supports the `stdio` protocol, including:\n\n- Cursor\n- Cline\n- Windsurf\n- Claude Desktop\n\nAdd the following to your MCP client configuration file:\n\n```json\n{\n  \"mcpServers\": {\n    \"atlas-docs\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@cartographai/atlas-docs-mcp\"]\n    }\n  }\n}\n```\n\nThat's it! You may need to restart the app (for Claude Desktop) for the server to be recognised.\n\n**Tip**: Prompt your model to check the docs eg. \"Use the tools to check the documentation for Astro to ensure that you use the library correctly.\"\n\n### Installing via Smithery\n\nAlternatively, you can install Atlas Docs MCP automatically via [Smithery](https://smithery.ai/server/@CartographAI/atlas-docs-mcp). Example for claude desktop:\n\n```bash\nnpx -y @smithery/cli install @CartographAI/atlas-docs-mcp --client claude\n```\n\nChange \"claude\" to \"cursor\", \"cline\" or \"windsurf\" for the respective clients.\n\n## 📒 Available Libraries\n\n- AI-SDK (source: https://sdk.vercel.ai/docs/introduction)\n- Astro (source: https://docs.astro.build/en/getting-started)\n- ast-grep (source: https://ast-grep.github.io/llms.txt)\n- Bun (source: https://bun.sh/llms.txt)\n- CrewAI (source: https://docs.crewai.com/llms.txt)\n- Drizzle (source: https://orm.drizzle.team/llms.txt)\n- ElevenLabs (source: https://elevenlabs.io/docs/llms.txt)\n- Fireworks (source: https://docs.fireworks.ai/llms.txt)\n- Hono (source: https://hono.dev/llms.txt)\n- Langgraph-js (source: https://langchain-ai.github.io/langgraphjs/llms.txt)\n- Langgraph-py (source: https://langchain-ai.github.io/langgraph/llms.txt)\n- Mastra (source: https://mastra.ai/llms.txt)\n- ModelContextProtocol (source: https://modelcontextprotocol.io/llms.txt)\n- Pglite (source: https://pglite.dev/docs/about)\n- Prisma (source: https://www.prisma.io/docs/llms.txt)\n- Resend (source: https://resend.com/docs/llms.txt)\n- shadcn/ui (source: https://ui.shadcn.com/docs)\n- Stripe (source: https://docs.stripe.com/llms.txt)\n- Svelte (source: https://svelte.dev/docs/svelte/overview)\n- SvelteKit (source: https://svelte.dev/docs/kit/introduction)\n- tailwindcss (source: https://tailwindcss.com/docs/installation)\n- TanStack-Router (source: https://tanstack.com/router/latest/docs/framework/react/overview)\n- Trigger.dev (source: https://trigger.dev/docs/llms.txt)\n- X (source: https://docs.x.com/llms.txt)\n- Zapier (source: https://docs.zapier.com/llms.txt)\n\nWant docs for another library not in this list? Please [open an issue](https://github.com/CartographAI/atlas/issues/new) in this repo, we'll try to process and add it!\n\n## 🔨 Available Tools\n\n1. `list_docs`: List all available documentation sets\n2. `get_docs_index`: Retrieves a condensed, LLM-friendly index of a documentation set\n3. `get_docs_full`: Retrieves a complete documentation set in a single consolidated file\n4. `search_docs`: Search a documentation set by keywords\n5. `get_docs_page`: Retrieves a specific page of a documentation set\n\n## 💭 How It Works\n\nAtlas Docs processes tech libraries' documentation sites into clean, markdown versions. This MCP server provides the docs as MCP tools, calling Atlas Docs APIs for the data.\n\n## Running the backend locally\n\nPlease visit [CartographAI/atlas](https://github.com/CartographAI/atlas) and follow the instructions in the README.\nUpdate ATLAS_API_URL with the url of your deployment.\n\n## Support & Feedback\n\nPlease [open an issue](https://github.com/CartographAI/atlas/issues/new) in this repo to request docs for a library, or to report a bug.\n\nIf you have any questions, feedback, or just want to say hi, we'd love to hear from you. You can find us on Cartograph's [Discord comunity](https://discord.gg/MsBA7U7hH5) for real-time support, or email us at [contact@cartograph.app](mailto:contact@cartograph.app)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "cartographai",
        "documentation",
        "markdown",
        "processing cartographai",
        "cartographai atlas",
        "atlas docs"
      ],
      "category": "document-processing"
    },
    "ChatterBoxIO--chatterboxio-mcp-server": {
      "owner": "ChatterBoxIO",
      "name": "chatterboxio-mcp-server",
      "url": "https://github.com/ChatterBoxIO/chatterboxio-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/ChatterBoxIO.webp",
      "description": "Integrates with online meeting platforms like Zoom and Google Meet to facilitate AI agents joining meetings, capturing transcripts, and generating concise summaries of discussions.",
      "stars": 7,
      "forks": 3,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-08-22T03:17:05Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/chatterboxio-chatterboxio-mcp-server-badge.png)](https://mseep.ai/app/chatterboxio-chatterboxio-mcp-server)\n\n# ChatterBox MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@OverQuotaAI/chatterboxio-mcp-server)](https://smithery.ai/server/@OverQuotaAI/chatterboxio-mcp-server)\n\nA Model Context Protocol server implementation for ChatterBox, enabling AI agents to interact with online meetings and generate meeting summaries.\n\n<a href=\"https://glama.ai/mcp/servers/@ChatterBoxIO/chatterboxio-mcp-server\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@ChatterBoxIO/chatterboxio-mcp-server/badge\" alt=\"ChatterBox MCP Server\" />\n</a>\n\n## Overview\n\nThe ChatterBox MCP Server provides tools for AI agents to:\n\n- Join online meetings (Zoom, Google Meet, or Microsoft Teams)\n- Capture transcripts and recordings\n- Generate meeting summaries\n\n## Installation\n\n### Installing via Smithery\n\nTo install chatterboxio-mcp-server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@OverQuotaAI/chatterboxio-mcp-server):\n\n```bash\nnpx -y @smithery/cli install @OverQuotaAI/chatterboxio-mcp-server --client claude\n```\n\n### Manual Installation\n\nYou can install the dependencies using either npm or pnpm:\n\n```bash\n# Using npm\nnpm install\n\n# Using pnpm\npnpm install\n```\n\n## Configuration\n\n### Getting API Keys\n\nYou can get your API keys for free by registering on our website at [ChatterBox](https://chatter-box.io). After registration, you'll receive your API endpoint and key.\n\n### Environment Setup\n\nCreate a `.env` file in the root directory with the following variables:\n\n```env\nCHATTERBOX_API_ENDPOINT=https://api.chatter-box.io\nCHATTERBOX_API_KEY=your_api_key_here\n```\n\n## Usage\n\n### Starting the Server\n\n```bash\npnpm start\n```\n\n### Available Tools\n\n#### joinMeeting\n\nJoin a Zoom or Google Meet meeting and capture transcript and audio recording.\n\n**Parameters:**\n\n- `platform` (string): The online conference platform (\"zoom\", \"googlemeet\", or \"teams\")\n- `meetingId` (string): The ID of the meeting\n- `meetingPassword` (string, optional): The password or the passcode for the meeting\n- `botName` (string): The name of the bot\n- `webhookUrl` (string, optional): URL to receive webhook events for meeting status\n\n#### getMeetingInfo\n\nGet information about a meeting, including transcript and recording.\n\n**Parameters:**\n\n- `sessionId` (string): The session ID to get information for\n\n#### summarizeMeeting\n\nGenerate a concise summary of a meeting's contents from its transcript.\n\n**Parameters:**\n\n- `transcript` (string): The meeting transcript to summarize\n\n## Development\n\n### Prerequisites\n\n- Node.js 16+\n- npm or yarn\n\n### Building\n\n```bash\npnpm run build\n```\n\n### Debugging\n\nTo debug the MCP server using the MCP Inspector:\n\n```bash\nnpx @modelcontextprotocol/inspector\n```\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Support\n\nFor support, please visit [ChatterBox Documentation](https://chatter-box.io/documentation) or contact support@chatter-box.io.\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "chatterboxio",
        "meetings",
        "meeting",
        "chatterboxio mcp",
        "online meeting",
        "google meet"
      ],
      "category": "document-processing"
    },
    "ChrisL108--outline-mcp": {
      "owner": "ChrisL108",
      "name": "outline-mcp",
      "url": "https://github.com/ChrisL108/outline-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/ChrisL108.webp",
      "description": "Search and retrieve documents from Outline knowledge bases, facilitating access to internal documentation. Supports secure access via interactive credentials and environment variables.",
      "stars": 1,
      "forks": 0,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-04-13T01:39:32Z",
      "readme_content": "# Outline MCP\n\nAn MCP (Model Control Protocol) server for integrating Outline with Claude.\n\n## Overview\n\nThis tool provides Claude with the ability to search and retrieve documents from your Outline knowledge base. Use it to help Claude answer questions using your organization's internal documentation.\n\n## Features\n\n- Search for documents in your Outline instance\n- Retrieve full document content by ID\n- Maintain persistent credentials between sessions\n\n## Installation\n\n> **Note**: Your Outline API key must have the following permissions:\n> - `documents.info` - For retrieving document content\n> - `documents.search` - For searching documents\n\n> **Note**: If `OUTLINE_URL` and `OUTLINE_API_KEY` are not provided in your config, Claude will prompt you for them. These credentials will be saved in `~/.outline_mcp_credentials.json` for future use.\n\n### Option 1: Install via Smithery CLI (requires smithery key)\n\n```bash\nnpx -y @smithery/cli@latest install @ChrisL108/outline-mcp --client claude --key your-smithery-api-key\n```\n\nYou can enter your `OUTLINE_URL` and `OUTLINE_API_KEY` when prompted by Claude or add them to your `claude_desktop_config.json` directly:\n\n```json\n\"env\": {\n    \"OUTLINE_URL\": \"https://your.outline.com\",\n    \"OUTLINE_API_KEY\": \"your-outline-api-key\"\n}\n```\n\nYour config should look like this:\n\n```json\n\"outline-mcp\": {\n    \"command\": \"npx\",\n    \"args\": [\n      \"-y\",\n      \"@smithery/cli@latest\",\n      \"run\",\n      \"@ChrisL108/outline-mcp\",\n      \"--key\",\n      \"your-smithery-api-key\"\n    ],\n    \"env\": {\n      \"OUTLINE_URL\": \"https://your.outline.com\",\n      \"OUTLINE_API_KEY\": \"your-outline-api-key\"\n    }\n}\n```\n\n### Option 2: Install via UVX\n\n```json\n\"outline-mcp\": {\n    \"command\": \"uvx\",\n    \"args\": [\n      \"--from\",\n      \"git+https://github.com/ChrisL108/outline-mcp\",\n      \"outline-mcp\"\n    ],\n    \"env\": {\n      \"OUTLINE_URL\": \"https://your.outline.com\",\n      \"OUTLINE_API_KEY\": \"your-outline-api-key\"\n    }\n}\n```\n\n## Usage\n\nOnce installed, you can use the following functions in your conversations with Claude:\n\n### Search Documents\n\n```\nsearch_documents(query, outline_url=None, api_key=None, limit=5, status_filter=\"published\", date_filter=\"year\")\n```\n\nParameters:\n- `query`: Search term (required)\n- `outline_url`: Base URL of your Outline instance (only needed first time)\n- `api_key`: Outline API key (only needed first time)\n- `limit`: Maximum number of results (default: 5)\n- `status_filter`: Filter by status (default: \"published\")\n- `date_filter`: Filter by date (default: \"year\")\n\n### Get Document by ID\n\n```\nget_document_by_id(document_id)\n```\n\nParameters:\n- `document_id`: ID of the document to retrieve (required)\n\n### Update Credentials\n\n```\nupdate_credentials(outline_url, api_key)\n```\n\nParameters:\n- `outline_url`: Base URL of your Outline instance\n- `api_key`: Outline API key\n\n### Ping\n\n```\nping()\n```\n\nSimple test function to verify the MCP server is working.\n\n## Example Prompts\n\nHere are some example prompts you can use with Claude:\n\n1. \"Search Outline for information about our product roadmap.\"\n2. \"Can you find any documents related to our hiring process?\"\n3. \"Check our internal documentation for our AWS setup.\"\n4. \"Can you get the full content of this document? [document_id]\"\n\n## Troubleshooting\n\nIf you encounter issues:\n\n1. Ensure your Outline URL and API key are correctly configured\n2. Verify that your Outline instance is accessible\n3. Check if your API key has the necessary permissions\n4. Try the `ping()` function to verify the MCP server is running correctly\n\n## Security Considerations\n\n- Keep your API key secure and don't share it\n- The MCP server only has the permissions granted to your API key\n- Consider using a read-only API key if you only need search functionality\n\n## License\n\nMIT License\n\nCopyright (c) 2025 ChrisL108\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## Credits\n\nCreated by [ChrisL108](https://github.com/ChrisL108)",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "documents",
        "documentation",
        "document",
        "documents outline",
        "document processing",
        "outline mcp"
      ],
      "category": "document-processing"
    },
    "CodeByWaqas--MRConfluenceLinker-mcp-server": {
      "owner": "CodeByWaqas",
      "name": "MRConfluenceLinker-mcp-server",
      "url": "https://github.com/CodeByWaqas/MRConfluenceLinker-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/CodeByWaqas.webp",
      "description": "Fetch and analyze GitLab merge requests, and store the analysis results in Confluence documentation to enhance documentation workflows.",
      "stars": 0,
      "forks": 2,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-03-22T15:44:53Z",
      "readme_content": "# GitLab PR Analysis MCP Server\n\nThis project provides an MCP (Model Control Protocol) server that integrates GitLab merge request analysis with Confluence documentation. It allows you to fetch merge request details, analyze code changes, and store the results in Confluence pages.\n\n## Features\n\n- Fetch merge request details from GitLab\n- Analyze code changes in merge requests\n- Generate detailed reports including:\n  - Basic merge request information\n  - Code change statistics\n  - File type analysis\n  - Detailed file changes\n- Store analysis results in Confluence\n- Comprehensive logging for debugging\n\n## Prerequisites\n\n- Python 3.8 or higher\n- GitLab account with API access\n- Confluence account (optional, for storing analysis results)\n- Access to the required GitLab project(s)\n\n## Installation\n\n1. Clone the repository:\n```bash\ngit https://github.com/CodeByWaqas/MRConfluenceLinker-mcp-server.git\ncd MRConfluenceLinker-mcp-server\n```\n\n2. Create and activate a virtual environment:\n```bash\npython -m venv .venv\nsource .venv/bin/activate  # On Windows, use: .venv\\Scripts\\activate\n```\n\n3. Install dependencies:\n```bash\npip install -r requirements.txt\n```\nor\n```bash\nuv add \"mcp[cli]\" python-gitlab python-dotenv atlassian-python-api requests\n```\n\n## Configuration\n\n1. Copy the example environment file:\n```bash\ncp .env.example .env\n```\n\n2. Edit the `.env` file with your credentials:\n```env\nGITLAB_URL=https://gitlab.com\nGITLAB_TOKEN=your_gitlab_token\nGITLAB_PROJECT_ID=your_project_id\n\n# Optional Confluence integration\nCONFLUENCE_URL=your_confluence_url\nCONFLUENCE_USERNAME=your_username\nCONFLUENCE_TOKEN=your_confluence_token\nCONFLUENCE_SPACE=your_space_key\n```\n\n### Obtaining Credentials\n\n- **GitLab Token**: Generate a personal access token in GitLab with `api` scope\n- **Confluence Token**: Generate an API token in your Atlassian account settings\n\n## Usage\n\n1. Start the MCP server:\n```bash\npython src/MRConfluenceLinker-mcp-server/server.py\n```\nor \n\n### Setup with Claude Desktop\n```json\n# claude_desktop_config.json\n# Can find location through:\n# Claude -> Settings -> Developer -> Edit Config\n{\n  \"mcpServers\": {\n      \"MRConfluenceLinker-mcp-server\": {\n          \"command\": \"uv\",\n          \"args\": [\n              \"--directory\",\n              \"/<Absolute-path-to-folder>/MRConfluenceLinker-mcp-server/src/MRConfluenceLinker-mcp-server\",\n              \"run\",\n              \"server.py\"\n          ]\n      }\n  }\n}\n\n2. The server will listen for commands through stdin/stdout. You can interact with it using prompts like:\n\n```\nCan you fetch details for merge request #1 from project \"my-project\"?\nCan you analyze code changes in merge request #1 from project \"my-project\"?\nCan you store a summary of merge request #1 from project \"my-project\" in Confluence?\n```\n\n## Available Tools\n\nThe server provides the following tools:\n\n1. `fetch_mr_details`: Fetches details of a specific merge request or all merge requests\n   - Parameters:\n     - `project_id`: The GitLab project ID\n     - `mr_id` (optional): Specific merge request ID\n\n2. `analyze_code_changes`: Analyzes code changes in a merge request\n   - Parameters:\n     - `project_id`: The GitLab project ID\n     - `mr_id`: The merge request ID to analyze\n\n3. `store_in_confluence`: Stores analysis results in Confluence\n   - Parameters:\n     - `project_id`: The GitLab project ID\n     - `mr_id` (optional): Specific merge request ID\n     - `analysis` (optional): Analysis results to store\n\n## Logging\n\nThe server generates detailed logs in `mcp_server.log` and outputs to stderr. This helps in debugging issues with:\n- GitLab API access\n- Confluence integration\n- Code analysis\n- Page creation and updates\n\n## Error Handling\n\nThe server includes comprehensive error handling for:\n- Missing environment variables\n- API authentication issues\n- Network connectivity problems\n- Invalid project or merge request IDs\n- Confluence permission issues\n\n## Contributing\n\n1. Fork the repository\n2. Create a feature branch\n3. Commit your changes\n4. Push to the branch\n5. Create a Pull Request\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## Support\n\nFor support, please [create an issue](https://github.com/CodeByWaqas/MRConfluenceLinker-mcp-server/issues) or contact the maintainers.\n\n## Project Structure\n\n```\nMRConfluenceLinker-mcp-server/\n├── src/                           # Source code directory\n│   └── MRConfluenceLinker-mcp-server/  # Main server package\n│       ├── resources/            # Resource modules\n│       │   ├── __init__.py\n│       │   ├── client.py        # Client implementation / GitLab PR integration\n│       ├── server.py            # Main server implementation\n│       └── mcp_server.log       # Server logs\n├── __pycache__/                 # Python cache files\n├── .git/                        # Git repository\n├── .gitignore                   # Git ignore rules\n├── CONTRIBUTING.md              # Contributing guidelines\n├── LICENSE                      # Project license\n├── README.md                    # Project documentation\n├── pyproject.toml              # Python project configuration\n├── requirements.txt            # Project dependencies\n└── uv.lock                     # Dependency lock file\n```\n\n### Key Components\n\n- **Source Code**: Located in the `src/MRConfluenceLinker-mcp-server/` directory\n  - `server.py`: Main MCP server implementation\n  - `resources/client.py`: Client-side implementation contains GitLab PR integration\n\n- **Configuration Files**:\n  - `requirements.txt`: Python package dependencies\n  - `pyproject.toml`: Project metadata and build configuration\n  - `uv.lock`: Locked dependency versions\n  - `.env.example`: Environment variables template\n\n- **Documentation**:\n  - `README.md`: Project overview and setup instructions\n  - `CONTRIBUTING.md`: Contribution guidelines\n  - `LICENSE`: Project license\n\n- **Development**:\n  - `__pycache__/`: Python cache files\n  - `mcp_server.log`: Server logs for debugging\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "confluence",
        "documentation",
        "gitlab",
        "confluence documentation",
        "gitlab merge",
        "results confluence"
      ],
      "category": "document-processing"
    },
    "David09090218--ai-document-writer": {
      "owner": "David09090218",
      "name": "ai-document-writer",
      "url": "https://github.com/David09090218/ai-document-writer",
      "imageUrl": "/freedevtools/mcp/pfp/David09090218.webp",
      "description": "快速生成各类专业公文，支持用户选择公文类型和输入提示，智能生成符合规范的文档内容。响应式设计和简洁界面提高了用户的写作效率。",
      "stars": 1,
      "forks": 0,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-04-23T17:40:03Z",
      "readme_content": "# AI公文写作助手\n\n这是一个基于 Next.js 和OpenAI API开发的智能公文写作助手，可以帮助用户快速生成各类专业公文。\n\n## 功能特点\n\n- 支持多种公文类型：通知、报告、请示、总结等\n- 智能生成符合规范的公文内容\n- 提供写作提示功能\n- 响应式设计，支持各种设备\n- 简洁直观的用户界面\n\n## 技术栈\n\n- Next.js 14\n- TypeScript\n- Tailwind CSS\n- OpenAI API\n- React\n\n## 开始使用\n\n1. 克隆项目\n```bash\ngit clone [项目地址]\ncd ai-document-writer\n```\n\n2. 安装依赖\n```bash\nnpm install\n```\n\n3. 配置环境变量\n复制 `.env.local.example` 文件为 `.env.local`，并填入你的 OpenAI API 密钥：\n```\nOPENAI_API_KEY=your_openai_api_key_here\n```\n\n4. 启动开发服务器\n```bash\nnpm run dev\n```\n\n5. 在浏览器中访问 `http://localhost:3000`\n\n## 使用说明\n\n1. 在首页选择\"开始写作\"或\"查看模板\"\n2. 选择需要的公文类型\n3. 可以输入写作提示来指导AI生成内容\n4. 点击\"生成文档\"按钮\n5. 等待AI生成内容\n6. 复制生成的内容进行编辑和使用\n\n## 注意事项\n\n- 请确保有有效的 OpenAI API 密钥\n- 生成的内容仅供参考，建议进行人工审核和修改\n- 请遵守相关法律法规和公文写作规范\n\n## 许可证\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "document",
        "processing",
        "支持用户选择公文类型和输入提示",
        "document processing",
        "ai document",
        "document writer"
      ],
      "category": "document-processing"
    },
    "DumplingAI--mcp-server-dumplingai": {
      "owner": "DumplingAI",
      "name": "mcp-server-dumplingai",
      "url": "https://github.com/DumplingAI/mcp-server-dumplingai",
      "imageUrl": "/freedevtools/mcp/pfp/DumplingAI.webp",
      "description": "Integrates data scraping, content processing, and AI capabilities, with features for document conversion, web scraping, and knowledge management. Supports real-time information access through various data APIs and secure code execution.",
      "stars": 27,
      "forks": 6,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-07T08:58:27Z",
      "readme_content": "# Dumpling AI MCP Server\n\nA Model Context Protocol (MCP) server implementation that integrates with Dumpling AI for data scraping, content processing, knowledge management, AI agents, and code execution capabilities.\n\n[![smithery badge](https://smithery.ai/badge/@Dumpling-AI/mcp-server-dumplingai)](https://smithery.ai/server/@Dumpling-AI/mcp-server-dumplingai)\n\n## Features\n\n- Complete integration with all Dumpling AI API endpoints\n- Data APIs for YouTube transcripts, search, autocomplete, maps, places, news, and reviews\n- Web scraping with support for scraping, crawling, screenshots, and structured data extraction\n- Document conversion tools for text extraction, PDF operations, video processing\n- Extract data from documents, images, audio, and video\n- AI capabilities including agent completions, knowledge base management, and image generation\n- Developer tools for running JavaScript and Python code in a secure environment\n- Automatic error handling and detailed response formatting\n\n## Installation\n\n### Installing via Smithery\n\nTo install mcp-server-dumplingai for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@Dumpling-AI/mcp-server-dumplingai):\n\n```bash\nnpx -y @smithery/cli install @Dumpling-AI/mcp-server-dumplingai --client claude\n```\n\n### Running with npx\n\n```bash\nenv DUMPLING_API_KEY=your_api_key npx -y mcp-server-dumplingai\n```\n\n### Manual Installation\n\n```bash\nnpm install -g mcp-server-dumplingai\n```\n\n### Running on Cursor\n\nConfiguring Cursor 🖥️ Note: Requires Cursor version 0.45.6+\n\nTo configure Dumpling AI MCP in Cursor:\n\n1. Open Cursor Settings\n2. Go to Features > MCP Servers\n3. Click \"+ Add New MCP Server\"\n4. Enter the following:\n\n```\n{\n  \"mcpServers\": {\n    \"dumplingai\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"mcp-server-dumplingai\"],\n      \"env\": {\n        \"DUMPLING_API_KEY\": \"<your-api-key>\"\n      }\n    }\n  }\n}\n```\n\n> If you are using Windows and are running into issues, try `cmd /c \"set DUMPLING_API_KEY=your-api-key && npx -y mcp-server-dumplingai\"`\n\nReplace `your-api-key` with your Dumpling AI API key.\n\n## Configuration\n\n### Environment Variables\n\n- `DUMPLING_API_KEY`: Your Dumpling AI API key (required)\n\n## Available Tools\n\n### Data APIs\n\n#### 1. Get YouTube Transcript (`get-youtube-transcript`)\n\nExtract transcripts from YouTube videos with optional timestamps.\n\n```json\n{\n  \"name\": \"get-youtube-transcript\",\n  \"arguments\": {\n    \"videoUrl\": \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\",\n    \"includeTimestamps\": true,\n    \"timestampsToCombine\": 3,\n    \"preferredLanguage\": \"en\"\n  }\n}\n```\n\n#### 2. Search (`search`)\n\nPerform Google web searches and optionally scrape content from results.\n\n```json\n{\n  \"name\": \"search\",\n  \"arguments\": {\n    \"query\": \"machine learning basics\",\n    \"country\": \"us\",\n    \"language\": \"en\",\n    \"dateRange\": \"pastMonth\",\n    \"scrapeResults\": true,\n    \"numResultsToScrape\": 3,\n    \"scrapeOptions\": {\n      \"format\": \"markdown\",\n      \"cleaned\": true\n    }\n  }\n}\n```\n\n#### 3. Get Autocomplete (`get-autocomplete`)\n\nGet Google search autocomplete suggestions for a query.\n\n```json\n{\n  \"name\": \"get-autocomplete\",\n  \"arguments\": {\n    \"query\": \"how to learn\",\n    \"country\": \"us\",\n    \"language\": \"en\",\n    \"location\": \"New York\"\n  }\n}\n```\n\n#### 4. Search Maps (`search-maps`)\n\nSearch Google Maps for locations and businesses.\n\n```json\n{\n  \"name\": \"search-maps\",\n  \"arguments\": {\n    \"query\": \"coffee shops\",\n    \"gpsPositionZoom\": \"37.7749,-122.4194,14z\",\n    \"language\": \"en\",\n    \"page\": 1\n  }\n}\n```\n\n#### 5. Search Places (`search-places`)\n\nSearch for places with more detailed information.\n\n```json\n{\n  \"name\": \"search-places\",\n  \"arguments\": {\n    \"query\": \"hotels in paris\",\n    \"country\": \"fr\",\n    \"language\": \"en\",\n    \"page\": 1\n  }\n}\n```\n\n#### 6. Search News (`search-news`)\n\nSearch for news articles with customizable parameters.\n\n```json\n{\n  \"name\": \"search-news\",\n  \"arguments\": {\n    \"query\": \"climate change\",\n    \"country\": \"us\",\n    \"language\": \"en\",\n    \"dateRange\": \"pastWeek\"\n  }\n}\n```\n\n#### 7. Get Google Reviews (`get-google-reviews`)\n\nRetrieve Google reviews for businesses or places.\n\n```json\n{\n  \"name\": \"get-google-reviews\",\n  \"arguments\": {\n    \"businessName\": \"Eiffel Tower\",\n    \"location\": \"Paris, France\",\n    \"limit\": 10,\n    \"sortBy\": \"relevance\"\n  }\n}\n```\n\n### Web Scraping\n\n#### 8. Scrape (`scrape`)\n\nExtract content from a web page with formatting options.\n\n```json\n{\n  \"name\": \"scrape\",\n  \"arguments\": {\n    \"url\": \"https://example.com\",\n    \"format\": \"markdown\",\n    \"cleaned\": true,\n    \"renderJs\": true\n  }\n}\n```\n\n#### 9. Crawl (`crawl`)\n\nRecursively crawl websites and extract content with customizable parameters.\n\n```json\n{\n  \"name\": \"crawl\",\n  \"arguments\": {\n    \"baseUrl\": \"https://example.com\",\n    \"maxPages\": 10,\n    \"crawlBeyondBaseUrl\": false,\n    \"depth\": 2,\n    \"scrapeOptions\": {\n      \"format\": \"markdown\",\n      \"cleaned\": true,\n      \"renderJs\": true\n    }\n  }\n}\n```\n\n#### 10. Screenshot (`screenshot`)\n\nCapture screenshots of web pages with customizable viewport and format options.\n\n```json\n{\n  \"name\": \"screenshot\",\n  \"arguments\": {\n    \"url\": \"https://example.com\",\n    \"width\": 1280,\n    \"height\": 800,\n    \"fullPage\": true,\n    \"format\": \"png\",\n    \"waitFor\": 1000\n  }\n}\n```\n\n#### 11. Extract (`extract`)\n\nExtract structured data from web pages using AI-powered instructions.\n\n```json\n{\n  \"name\": \"extract\",\n  \"arguments\": {\n    \"url\": \"https://example.com/products\",\n    \"instructions\": \"Extract all product names, prices, and descriptions from this page\",\n    \"schema\": {\n      \"products\": [\n        {\n          \"name\": \"string\",\n          \"price\": \"number\",\n          \"description\": \"string\"\n        }\n      ]\n    },\n    \"renderJs\": true\n  }\n}\n```\n\n### Document Conversion\n\n#### 12. Doc to Text (`doc-to-text`)\n\nConvert documents to plaintext with optional OCR.\n\n```json\n{\n  \"name\": \"doc-to-text\",\n  \"arguments\": {\n    \"url\": \"https://example.com/document.pdf\",\n    \"options\": {\n      \"ocr\": true,\n      \"language\": \"en\"\n    }\n  }\n}\n```\n\n#### 13. Convert to PDF (`convert-to-pdf`)\n\nConvert various file formats to PDF.\n\n```json\n{\n  \"name\": \"convert-to-pdf\",\n  \"arguments\": {\n    \"url\": \"https://example.com/document.docx\",\n    \"format\": \"docx\",\n    \"options\": {\n      \"quality\": 90,\n      \"pageSize\": \"A4\",\n      \"margin\": 10\n    }\n  }\n}\n```\n\n#### 14. Merge PDFs (`merge-pdfs`)\n\nCombine multiple PDFs into a single document.\n\n```json\n{\n  \"name\": \"merge-pdfs\",\n  \"arguments\": {\n    \"urls\": [\"https://example.com/doc1.pdf\", \"https://example.com/doc2.pdf\"],\n    \"options\": {\n      \"addPageNumbers\": true,\n      \"addTableOfContents\": true\n    }\n  }\n}\n```\n\n#### 15. Trim Video (`trim-video`)\n\nExtract a specific clip from a video.\n\n```json\n{\n  \"name\": \"trim-video\",\n  \"arguments\": {\n    \"url\": \"https://example.com/video.mp4\",\n    \"startTime\": 30,\n    \"endTime\": 60,\n    \"output\": \"mp4\",\n    \"options\": {\n      \"quality\": 720,\n      \"fps\": 30\n    }\n  }\n}\n```\n\n#### 16. Extract Document (`extract-document`)\n\nExtract specific content from documents in various formats.\n\n```json\n{\n  \"name\": \"extract-document\",\n  \"arguments\": {\n    \"url\": \"https://example.com/document.pdf\",\n    \"format\": \"structured\",\n    \"options\": {\n      \"ocr\": true,\n      \"language\": \"en\",\n      \"includeMetadata\": true\n    }\n  }\n}\n```\n\n#### 17. Extract Image (`extract-image`)\n\nExtract text and information from images.\n\n```json\n{\n  \"name\": \"extract-image\",\n  \"arguments\": {\n    \"url\": \"https://example.com/image.jpg\",\n    \"extractionType\": \"text\",\n    \"options\": {\n      \"language\": \"en\",\n      \"detectOrientation\": true\n    }\n  }\n}\n```\n\n#### 18. Extract Audio (`extract-audio`)\n\nTranscribe and extract information from audio files.\n\n```json\n{\n  \"name\": \"extract-audio\",\n  \"arguments\": {\n    \"url\": \"https://example.com/audio.mp3\",\n    \"language\": \"en\",\n    \"options\": {\n      \"model\": \"enhanced\",\n      \"speakerDiarization\": true,\n      \"wordTimestamps\": true\n    }\n  }\n}\n```\n\n#### 19. Extract Video (`extract-video`)\n\nExtract content from videos including transcripts, scenes, and objects.\n\n```json\n{\n  \"name\": \"extract-video\",\n  \"arguments\": {\n    \"url\": \"https://example.com/video.mp4\",\n    \"extractionType\": \"transcript\",\n    \"options\": {\n      \"language\": \"en\",\n      \"speakerDiarization\": true\n    }\n  }\n}\n```\n\n#### 20. Read PDF Metadata (`read-pdf-metadata`)\n\nExtract metadata from PDF files.\n\n```json\n{\n  \"name\": \"read-pdf-metadata\",\n  \"arguments\": {\n    \"url\": \"https://example.com/document.pdf\",\n    \"includeExtended\": true\n  }\n}\n```\n\n#### 21. Write PDF Metadata (`write-pdf-metadata`)\n\nUpdate metadata in PDF files.\n\n```json\n{\n  \"name\": \"write-pdf-metadata\",\n  \"arguments\": {\n    \"url\": \"https://example.com/document.pdf\",\n    \"metadata\": {\n      \"title\": \"New Title\",\n      \"author\": \"John Doe\",\n      \"keywords\": [\"keyword1\", \"keyword2\"]\n    }\n  }\n}\n```\n\n### AI\n\n#### 22. Generate Agent Completion (`generate-agent-completion`)\n\nGet AI agent completions with optional tool definitions.\n\n```json\n{\n  \"name\": \"generate-agent-completion\",\n  \"arguments\": {\n    \"prompt\": \"How can I improve my website's SEO?\",\n    \"model\": \"gpt-4\",\n    \"temperature\": 0.7,\n    \"maxTokens\": 500,\n    \"context\": [\"The website is an e-commerce store selling handmade crafts.\"]\n  }\n}\n```\n\n#### 23. Search Knowledge Base (`search-knowledge-base`)\n\nSearch a knowledge base for relevant information.\n\n```json\n{\n  \"name\": \"search-knowledge-base\",\n  \"arguments\": {\n    \"kbId\": \"kb_12345\",\n    \"query\": \"How to optimize database performance\",\n    \"limit\": 5,\n    \"similarityThreshold\": 0.7\n  }\n}\n```\n\n#### 24. Add to Knowledge Base (`add-to-knowledge-base`)\n\nAdd entries to a knowledge base.\n\n```json\n{\n  \"name\": \"add-to-knowledge-base\",\n  \"arguments\": {\n    \"kbId\": \"kb_12345\",\n    \"entries\": [\n      {\n        \"text\": \"MongoDB is a document-based NoSQL database.\",\n        \"metadata\": {\n          \"source\": \"MongoDB documentation\",\n          \"category\": \"databases\"\n        }\n      }\n    ],\n    \"upsert\": true\n  }\n}\n```\n\n#### 25. Generate AI Image (`generate-ai-image`)\n\nGenerate images using AI models.\n\n```json\n{\n  \"name\": \"generate-ai-image\",\n  \"arguments\": {\n    \"prompt\": \"A futuristic city with flying cars and neon lights\",\n    \"width\": 1024,\n    \"height\": 1024,\n    \"numImages\": 1,\n    \"quality\": \"hd\",\n    \"style\": \"photorealistic\"\n  }\n}\n```\n\n#### 26. Generate Image (`generate-image`)\n\nGenerate images using various AI providers.\n\n```json\n{\n  \"name\": \"generate-image\",\n  \"arguments\": {\n    \"prompt\": \"A golden retriever in a meadow of wildflowers\",\n    \"provider\": \"dalle\",\n    \"width\": 1024,\n    \"height\": 1024,\n    \"numImages\": 1\n  }\n}\n```\n\n### Developer Tools\n\n#### 27. Run JavaScript Code (`run-js-code`)\n\nExecute JavaScript code with optional dependencies.\n\n```json\n{\n  \"name\": \"run-js-code\",\n  \"arguments\": {\n    \"code\": \"const result = [1, 2, 3, 4].reduce((sum, num) => sum + num, 0); console.log(`Sum: ${result}`); return result;\",\n    \"dependencies\": {\n      \"lodash\": \"^4.17.21\"\n    },\n    \"timeout\": 5000\n  }\n}\n```\n\n#### 28. Run Python Code (`run-python-code`)\n\nExecute Python code with optional dependencies.\n\n```json\n{\n  \"name\": \"run-python-code\",\n  \"arguments\": {\n    \"code\": \"import numpy as np\\narr = np.array([1, 2, 3, 4, 5])\\nmean = np.mean(arr)\\nprint(f'Mean: {mean}')\\nreturn mean\",\n    \"dependencies\": [\"numpy\", \"pandas\"],\n    \"timeout\": 10000,\n    \"saveOutputFiles\": true\n  }\n}\n```\n\n## Error Handling\n\nThe server provides robust error handling:\n\n- Detailed error messages with HTTP status codes\n- API key validation\n- Input validation using Zod schemas\n- Network error handling with descriptive messages\n\nExample error response:\n\n```json\n{\n  \"content\": [\n    {\n      \"type\": \"text\",\n      \"text\": \"Error: Failed to fetch YouTube transcript: 404 Not Found\"\n    }\n  ],\n  \"isError\": true\n}\n```\n\n## Development\n\n```bash\n# Install dependencies\nnpm install\n\n# Build\nnpm run build\n\n```\n\n## License\n\nMIT License - see LICENSE file for details\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "dumplingai",
        "scraping",
        "processing",
        "processing dumplingai",
        "server dumplingai",
        "dumplingai mcp"
      ],
      "category": "document-processing"
    },
    "Excoriate--mcp-terragrunt-docs": {
      "owner": "Excoriate",
      "name": "mcp-terragrunt-docs",
      "url": "https://github.com/Excoriate/mcp-terragrunt-docs",
      "imageUrl": "/freedevtools/mcp/pfp/Excoriate.webp",
      "description": "Provides access to up-to-date Terragrunt documentation and GitHub issue information for enhanced infrastructure-as-code development. Enables contextual querying and assistance for AI workflows or IDE integrations.",
      "stars": 15,
      "forks": 2,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-25T15:53:29Z",
      "readme_content": "# MCP Server: Terragrunt Docs Provider\n\n[![Language](https://img.shields.io/badge/language-Deno/TypeScript-blue.svg)](https://deno.land/)\n[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE) <!-- Assuming MIT, add LICENSE file if needed -->\n\nA [Model Context Protocol (MCP)](modelcontextprotocol.io) server built with Deno and TypeScript, designed to provide contextual information related to [Terragrunt](https://terragrunt.gruntwork.io/).\n\n## Overview\n\nThis server acts as an MCP provider, exposing tools and resources that allow AI agents or other MCP clients to query information about Terragrunt documentation and development information, such as GitHub issues.\n\n- Watch a realistic demo 📺 on Claude Desktop [here](https://screen.studio/share/UKJNhBNq)\n\n---\n\n## Why?\n\nWhen writing IaC configurations, mostly in terragrunt, the IDE support isn't that good, in VSCode the terraform plugin is good, but not for terragrunt; it does not recognize the terragrunt blocks and does not provide any autocompletion. When interacting with AI autocompletion, it's common to get incorrect results, or false-positive linting errors. With this MCP server, you can provide to your LLM/AI assistant the latest documentation and issues from the Terragrunt GitHub repository, so it can use that to provide you with the most accurate information.\n\n## Tools\n\n> **Note:** All tools require a valid GitHub token set as an environment variable: `GITHUB_TOKEN`, `GH_TOKEN`, or `GITHUB_PERSONAL_ACCESS_TOKEN`.\n\n| Tool Name                   | Purpose                                                                 | Inputs                                   | Outputs                                                                 | Use Case                                                                                          |\n|-----------------------------|-------------------------------------------------------------------------|------------------------------------------|-------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------|\n| `list-doc-categories`       | Retrieve all documentation categories from Terragrunt docs.             | None                                     | Array of objects with `name` (string) and `link` (string) properties    | Use when you need to explore the available documentation structure or when building a documentation navigation system. This is typically the first tool to call when starting to work with Terragrunt docs. |\n| `list-all-docs-by-category` | List all docs in a specific category.                                   | category (string)                        | Array of objects with `name` (string), `link` (string), and `content` (string) | Use when you need to see all available documentation within a specific category, such as when building a category-specific documentation viewer or when you need to scan through all docs in a particular area. |\n| `read-document-from-category` | Read a specific doc from a category.                                    | category (string), document (string)     | Object containing `content` (string) with the full markdown content     | Use when you need to access the complete content of a specific document, such as when implementing documentation search or when you need to reference specific documentation in your application. |\n| `read-all-docs-from-category` | Retrieve and merge all docs in a category into one response.            | category (string)                        | Object containing `content` (string) with all docs merged into one      | Use when you need a comprehensive view of all documentation within a category, such as when building a documentation search feature or when you need to analyze the complete documentation set for a specific topic. |\n| `get-all-open-issues`         | Retrieve all open issues from Terragrunt GitHub repo.                   | all (boolean, optional)                  | Array of objects with `title` (string), `number` (number), `state` (string), `created_at` (string), `updated_at` (string), `body` (string), and `labels` (string[]) | Use when you need to track or analyze current issues in the Terragrunt project, such as when building an issue dashboard, performing issue triage, or when you need to stay updated with the latest project challenges and discussions. |\n\n## Setup\n\n1. **Install Deno:**\n   - [Deno Installation Guide](https://deno.land/manual/getting_started/installation)\n2. **Clone the repository:**\n\n   ```sh\n   git clone https://github.com/Excoriate/mcp-terragrunt-docs.git\n   cd mcp-terragrunt-docs\n   ```\n\n3. **Set your GitHub token as an environment variable:**\n   - On Unix/macOS:\n\n     ```sh\n     export GITHUB_TOKEN=ghp_xxx... # or GH_TOKEN or GITHUB_PERSONAL_ACCESS_TOKEN\n     ```\n   - On Windows (cmd):\n\n     ```cmd\n     set GITHUB_TOKEN=ghp_xxx...\n     ```\n>Note: You can also set the token in the `.env` file.\n\n4. **Run the MCP server:**\n\n   ```sh\n   # directly using deno\n   deno run -A main.ts\n\n   # Using the justfile\n   just run\n\n   # You can also debug it, and inspect it locally\n   just inspect\n   ```\nThe most straightforward method is to use it directly from [JSR](https://jsr.io/) (Javascript Registry ❤️)\n```sh\n# export your github token\nexport GITHUB_TOKEN=ghp_xxx...\n\n# run it\ndeno run -A jsr:@excoriate/mcp-terragrunt-docs@0.1.0\n```\n\n### Usage with Claude Desktop\nTo use this Deno-based MCP server with Claude Desktop, add the following to your `claude_desktop_config.json`:\n\n#### Using Deno\n\n```json\n{\n  \"mcpServers\": {\n    \"terragrunt_docs\": {\n      \"command\": \"deno\",\n      \"args\": [\n        \"run\",\n        \"-A\",\n        \"main.ts\"\n      ],\n      \"env\": {\n        \"GITHUB_TOKEN\": \"<YOUR_TOKEN>\"\n      },\n    }\n  }\n}\n```\n\n#### Using Docker\n\n```json\n{\n  \"mcpServers\": {\n    \"terragrunt_docs\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-e\", \"GITHUB_TOKEN=<YOUR_TOKEN>\", \"mcp-terragrunt-docs\"\n      ],\n      \"env\": {\n        \"GITHUB_TOKEN\": \"<YOUR_TOKEN>\"\n      }\n    }\n  }\n}\n```\n\n#### Using JSR\n\n```json\n{\n  \"mcpServers\": {\n    \"terragrunt_docs\": {\n      \"command\": \"deno\",\n      \"args\": [\n        \"run\",\n        \"-A\",\n        \"jsr:@excoriate/mcp-terragrunt-docs@0.1.0\"\n      ],\n      \"env\": {\n        \"GITHUB_TOKEN\": \"<YOUR_TOKEN>\"\n      }\n    }\n  }\n}\n```\n\n### Build the Docker image\n\n```sh\ndocker build -t mcp-terragrunt-docs .\n```\n\n### Run the MCP server in Docker\n\n```sh\ndocker run -it --rm \\\n  -e GITHUB_TOKEN=ghp_xxx... \\\n  mcp-terragrunt-docs\n```\n\n- Replace `ghp_xxx...` with your [GitHub Personal Access Token](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens) with appropriate permissions.\n- You can also use `GH_TOKEN` or `GITHUB_PERSONAL_ACCESS_TOKEN` as the environment variable name.\n- If you want to use a local `.env` file, you can pass it with `--env-file .env`.\n\n## Contributing\n\nSee [docs/CONTRIBUTING.md](docs/CONTRIBUTING.md) for detailed contribution guidelines, including setup, code style, PR process, and codebase structure reference.\n\n## Security\n\nSee [SECURITY.md](SECURITY.md) for the project's security policy, including how to report vulnerabilities and responsible disclosure guidelines.\n\n## License\n\nThis project is licensed under the [MIT License](LICENSE).\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "terragrunt",
        "documentation",
        "document",
        "terragrunt docs",
        "terragrunt documentation",
        "mcp terragrunt"
      ],
      "category": "document-processing"
    },
    "FradSer--mcp-server-to-markdown": {
      "owner": "FradSer",
      "name": "mcp-server-to-markdown",
      "url": "https://github.com/FradSer/mcp-server-to-markdown",
      "imageUrl": "/freedevtools/mcp/pfp/FradSer.webp",
      "description": "Converts various file formats into Markdown descriptions, helping users obtain structured information from documents. Integrates with Cloudflare AI services for efficient document processing.",
      "stars": 34,
      "forks": 4,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-09-04T14:38:58Z",
      "readme_content": "# MCP Server To Markdown ![](https://img.shields.io/badge/A%20FRAD%20PRODUCT-WIP-yellow)\n\n[![Twitter Follow](https://img.shields.io/twitter/follow/FradSer?style=social)](https://twitter.com/FradSer)\n[![smithery badge](https://smithery.ai/badge/@FradSer/mcp-server-to-markdown)](https://smithery.ai/server/@FradSer/mcp-server-to-markdown)\n\nEnglish | [简体中文](README.zh-CN.md)\n\nA powerful Model Context Protocol (MCP) server that leverages Cloudflare AI services to convert various file formats into Markdown descriptions. This server provides a standardized interface for seamless file conversion and description generation.\n\n## Key Features\n\n- Seamless integration with Cloudflare AI services\n- Efficient Markdown description generation\n- Comprehensive file format support\n- Native Cloudflare tomarkdown API integration\n- User-friendly MCP interface\n- Cross-platform compatibility\n\n## Supported File Formats\n\n| Category | File Extensions |\n|----------|----------------|\n| Documents | .pdf |\n| Images | .jpeg, .jpg, .png, .webp, .svg |\n| Web Content | .html |\n| Data | .xml, .csv |\n| Spreadsheets | .xlsx, .xlsm, .xlsb, .xls, .et, .ods, .numbers |\n\n## System Requirements\n\n- Node.js 18 or later\n- Valid Cloudflare API Token\n- Active Cloudflare Account ID\n\n## Installation\n\n### Installing via Smithery\n\nTo install Markdown转换服务器 for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@FradSer/mcp-server-to-markdown):\n\n```bash\nnpx -y @smithery/cli install @FradSer/mcp-server-to-markdown --client claude\n```\n\n### Manual Installation\nInstall globally using npm:\n\n```bash\nnpm install -g mcp-server-to-markdown\n```\n\n## MCP Client Configuration\n\n### Cursor Integration\n\n1. Navigate to Cursor settings\n2. Select \"MCP\" from the sidebar\n3. Choose \"Add new global MCP server\"\n4. Apply the following configuration:\n    ```json\n    {\n      \"mcpServers\": {\n        \"to-markdown\": {\n          \"command\": \"mcp-server-to-markdown\",\n          \"args\": [\n            \"CLOUDFLARE_API_TOKEN\": \"your_api_token\"\n            \"CLOUDFLARE_ACCOUNT_ID\": \"your_account_id\"\n          ]\n        }\n      }\n    }\n    ```\n\n### Claude Desktop Setup\n\nAdd the following to your `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"to-markdown\": {\n      \"command\": \"mcp-server-to-markdown\",\n      \"args\": [\n            \"CLOUDFLARE_API_TOKEN\": \"your_api_token\"\n            \"CLOUDFLARE_ACCOUNT_ID\": \"your_account_id\"\n          ]\n    }\n  }\n}\n```\n\n### ChatWise Configuration\n\n1. Launch ChatWise\n2. Access Settings\n3. Select Tools section\n4. Click \"+\" to add new tool\n5. Configure with these parameters:\n   - Type: `stdio`\n   - ID: `to-markdown`\n   - Command: `mcp-server-to-markdown`\n   - Args:\n      ```\n      CLOUDFLARE_API_TOKEN=your_api_token\n      CLOUDFLARE_ACCOUNT_ID=your_account_id\n      ```\n\n## API Reference\n\n### to-markdown Tool\n\nConverts various file formats to Markdown descriptions.\n\n**Input Parameters:**\n- `filePaths`: Array<string> (required) - List of file paths to process\n\n**Response Structure:**\n```json\n[\n  {\n    \"filename\": \"example.pdf\",\n    \"mimeType\": \"application/pdf\",\n    \"description\": \"Generated Markdown description\",\n    \"tokens\": 123\n  }\n]\n```\n\n## Development Guide\n\n### Getting Started\n\n1. Clone and setup environment:\n```bash\ngit clone <repository-url>\ncd mcp-server-to-markdown\ncp .env.example .env\n```\n\n2. Configure Cloudflare credentials:\n```plaintext\nCLOUDFLARE_API_TOKEN=your_api_token\nCLOUDFLARE_ACCOUNT_ID=your_account_id\n```\n\n3. Install dependencies and build:\n```bash\nnpm install\nnpm run build\n```\n\n### Project Structure\n\n```\n.\n├── src/             # Source code\n├── dist/            # Compiled output\n├── types.ts         # Type definitions\n└── .env             # Environment configuration\n```\n\n### Available Scripts\n\n- `npm run build` - Build TypeScript code\n- `npm run inspect` - Run with MCP inspector\n\n## Usage Example\n\n```typescript\nconst result = await toMarkdown({\n  filePaths: [\n    \"/path/to/document.pdf\",\n    \"/path/to/image.jpg\"\n  ]\n});\n```\n\n## License\n\nMIT License\n\nThis project is maintained by [Frad LEE](https://twitter.com/FradSer)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "markdown",
        "cloudflare",
        "formats",
        "formats markdown",
        "server markdown",
        "document processing"
      ],
      "category": "document-processing"
    },
    "FutureUnreal--mcp-pdf2md": {
      "owner": "FutureUnreal",
      "name": "mcp-pdf2md",
      "url": "https://github.com/FutureUnreal/mcp-pdf2md",
      "imageUrl": "/freedevtools/mcp/pfp/FutureUnreal.webp",
      "description": "Converts PDF files to structured Markdown format while preserving the original layout. Supports batch processing of local files and URLs for efficient handling of multiple documents.",
      "stars": 17,
      "forks": 5,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-09T05:32:40Z",
      "readme_content": "# MCP-PDF2MD\n\n[![smithery badge](https://smithery.ai/badge/@FutureUnreal/mcp-pdf2md)](https://smithery.ai/server/@FutureUnreal/mcp-pdf2md)\n[English](#pdf2md-service) | [中文](README_CN.md)\n\n# MCP-PDF2MD Service\n\nAn MCP-based high-performance PDF to Markdown conversion service powered by MinerU API, supporting batch processing for local files and URL links with structured output.\n\n## Key Features\n\n- Format Conversion: Convert PDF files to structured Markdown format.\n- Multi-source Support: Process both local PDF files and URL links.\n- Intelligent Processing: Automatically select the best processing method.\n- Batch Processing: Support multi-file batch conversion for efficient handling of large volumes of PDF files.\n- MCP Integration: Seamless integration with LLM clients like Claude Desktop.\n- Structure Preservation: Maintain the original document structure, including headings, paragraphs, lists, etc.\n- Smart Layout: Output text in human-readable order, suitable for single-column, multi-column, and complex layouts.\n- Formula Conversion: Automatically recognize and convert formulas in the document to LaTeX format.\n- Table Extraction: Automatically recognize and convert tables in the document to structured format.\n- Cleanup Optimization: Remove headers, footers, footnotes, page numbers, etc., to ensure semantic coherence.\n- High-Quality Extraction: High-quality extraction of text, images, and layout information from PDF documents.\n\n## System Requirements\n\n- Software: Python 3.10+\n\n## Quick Start\n\n1. Clone the repository and enter the directory:\n   ```bash\n   git clone https://github.com/FutureUnreal/mcp-pdf2md.git\n   cd mcp-pdf2md\n   ```\n\n2. Create a virtual environment and install dependencies:\n   \n   **Linux/macOS**:\n   ```bash\n   uv venv\n   source .venv/bin/activate\n   uv pip install -e .\n   ```\n   \n   **Windows**:\n   ```bash\n   uv venv\n   .venv\\Scripts\\activate\n   uv pip install -e .\n   ```\n\n3. Configure environment variables:\n\n   Create a `.env` file in the project root directory and set the following environment variables:\n   ```\n   MINERU_API_BASE=https://mineru.net/api/v4/extract/task\n   MINERU_BATCH_API=https://mineru.net/api/v4/extract/task/batch\n   MINERU_BATCH_RESULTS_API=https://mineru.net/api/v4/extract-results/batch\n   MINERU_API_KEY=your_api_key_here\n   ```\n\n4. Start the service:\n   ```bash\n   uv run pdf2md\n   ```\n\n## Command Line Arguments\n\nThe server supports the following command line arguments:\n\n## Claude Desktop Configuration\n\nAdd the following configuration in Claude Desktop:\n\n**Windows**:\n```json\n{\n    \"mcpServers\": {\n        \"pdf2md\": {\n            \"command\": \"uv\",\n            \"args\": [\n                \"--directory\",\n                \"C:\\\\path\\\\to\\\\mcp-pdf2md\",\n                \"run\",\n                \"pdf2md\",\n                \"--output-dir\",\n                \"C:\\\\path\\\\to\\\\output\"\n            ],\n            \"env\": {\n                \"MINERU_API_KEY\": \"your_api_key_here\"\n            }\n        }\n    }\n}\n```\n\n**Linux/macOS**:\n```json\n{\n    \"mcpServers\": {\n        \"pdf2md\": {\n            \"command\": \"uv\",\n            \"args\": [\n                \"--directory\",\n                \"/path/to/mcp-pdf2md\",\n                \"run\",\n                \"pdf2md\",\n                \"--output-dir\",\n                \"/path/to/output\"\n            ],\n            \"env\": {\n                \"MINERU_API_KEY\": \"your_api_key_here\"\n            }\n        }\n    }\n}\n```\n\n**Note about API Key Configuration:**\nYou can set the API key in two ways:\n1. In the `.env` file within the project directory (recommended for development)\n2. In the Claude Desktop configuration as shown above (recommended for regular use)\n\nIf you set the API key in both places, the one in the Claude Desktop configuration will take precedence.\n\n## MCP Tools\n\nThe server provides the following MCP tools:\n\n- **convert_pdf_url**: Convert PDF URL to Markdown\n- **convert_pdf_file**: Convert local PDF file to Markdown\n\n## Getting MinerU API Key\n\nThis project relies on the MinerU API for PDF content extraction. To obtain an API key:\n\n1. Visit [MinerU official website](https://mineru.net/) and register for an account\n2. After logging in, apply for API testing qualification at [this link](https://mineru.net/apiManage/docs?openApplyModal=true)\n3. Once your application is approved, you can access the [API Management](https://mineru.net/apiManage/token) page\n4. Generate your API key following the instructions provided\n5. Copy the generated API key\n6. Use this string as the value for `MINERU_API_KEY`\n\nNote that access to the MinerU API is currently in testing phase and requires approval from the MinerU team. The approval process may take some time, so plan accordingly.\n\n## Demo\n\n### Input PDF\n\n\n### Output Markdown\n\n\n## License\n\nMIT License - see the LICENSE file for details.\n\n## Credits\n\nThis project is based on the API from [MinerU](https://github.com/opendatalab/MinerU/tree/master).",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "pdf2md",
        "pdf",
        "markdown",
        "pdf2md converts",
        "mcp pdf2md",
        "pdf files"
      ],
      "category": "document-processing"
    },
    "GHSix--AverbePorto-MCP": {
      "owner": "GHSix",
      "name": "AverbePorto-MCP",
      "url": "https://github.com/GHSix/AverbePorto-MCP",
      "imageUrl": "/freedevtools/mcp/pfp/GHSix.webp",
      "description": "Integrates with AverbePorto to manage authentication and document submission for cargo insurance endorsements. Provides a secure API for automated document handling and protocol consultations.",
      "stars": 0,
      "forks": 1,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-04-15T17:32:34Z",
      "readme_content": "# AverbePorto-MCP\n\n[![smithery badge](https://smithery.ai/badge/@GHSix/averbeporto-mcp)](https://smithery.ai/server/@GHSix/averbeporto-mcp)\n\n## 🌟 Sobre\nO AverbePorto-MCP é um servidor MCP (Model Context Protocol) que permite a integração com a plataforma [AverbePorto](https://www.averbeporto.com.br), facilitando o acesso aos serviços de autenticação e envio de documentos através de ferramentas de IA (Inteligência Artificial).\n\n## 🌐 Acessando o Sistema Web\n\n1. Acesse [https://www.averbeporto.com.br](https://www.averbeporto.com.br)\n2. Faça login com suas credenciais de usuário\n3. Na plataforma, você poderá:\n   - Gerar Credenciais de API em Cadastro do Usuário\n   - Realizar envio de documentos XML\n   - Consultar protocolos ANTT\n   - Acompanhar e gerenciar suas averbações de seguros de carga\n\n## 🤖 Utilizando o MCP Server com Ferramentas de IA\n\n### Instalação pelo Smithery\n\nPara instalar averbeporto-mcp para Claude Desktop automaticamente via [Smithery](https://smithery.ai/server/@GHSix/averbeporto-mcp):\n\n```bash\nnpx -y @smithery/cli install @GHSix/averbeporto-mcp --client claude\n```\n\n### [Claude Desktop](https://claude.ai/download)\n1. Edite o arquivo `%APPDATA%\\Claude\\claude_desktop_config.json` (Windows) ou `~/Library/Application Support/Claude/claude_desktop_config.json` (MacOS) e adicione a seguinte configuração:\n   ```json\n    {\n      \"mcpServers\": {\n        \"AverbePorto-MCP\": {\n          \"command\": \"node\",\n          \"args\": [\"/caminho/para/AverbePorto-MCP/build/index.js\"]\n        }\n      }\n    }\n   ```\n2. Ao iniciar a conversa, o servidor MCP será automaticamente iniciado com base na configuração.\n\n### [Cursor](https://www.cursor.com/), [Roo Code](https://roocode.com/) e outros\n1. Crie um arquivo como `.cursor/mcp.json` ou `.roo/mcp.json` em seu projeto com a seguinte configuração:\n   ```json\n    {\n      \"mcpServers\": {\n        \"AverbePorto-MCP\": {\n          \"command\": \"node\",\n          \"args\": [\"/caminho/para/AverbePorto-MCP/build/index.js\"],\n          \"disabled\": false,\n          \"alwaysAllow\": [\n            \"login\",\n            \"consultProtocol\",\n            \"upload\",\n            \"retrieveDocument\",\n            \"decomposeKey\"\n          ]\n        }\n      }\n    }\n   ```\n2. Ao iniciar a conversa, o servidor MCP será automaticamente iniciado com base na configuração.\n\n### [Github Copilot](https://github.com/features/copilot)\n1. Com o Github Copilot ativo em seu editor, crie o arquivo `.vscode/mcp.json`:\n   ```json\n   {\n     \"inputs\": [\n       {\n         \"type\": \"promptString\",\n         \"id\": \"averbeporto-user\",\n         \"description\": \"AverbePorto API Username\"\n       },\n       {\n         \"type\": \"promptString\",\n         \"id\": \"averbeporto-pass\",\n         \"description\": \"AverbePorto API Password\",\n         \"password\": true\n       }\n     ],\n     \"servers\": {\n       \"AverbePorto-MCP\": {\n         \"command\": \"node\",\n         \"args\": [\"/caminho/para/AverbePorto-MCP/build/index.js\"],\n         \"env\": {\n           \"AVERBEPORTO_USER\": \"${input:averbeporto-user}\",\n           \"AVERBEPORTO_PASS\": \"${input:averbeporto-pass}\"\n         }\n       }\n     }\n   }\n   ```\n2. O VS Code solicitará suas credenciais na primeira execução e as armazenará de forma segura.\n3. O Copilot reconhecerá os comandos MCP e oferecerá sugestões contextualizadas para:\n   - Autenticação na API\n   - Upload de documentos XML\n   - Consulta de protocolos ANTT\n4. As credenciais serão automaticamente injetadas nas chamadas da API.\n\n## 📚 Ferramentas Disponíveis para a IA\n\nO AverbePorto-MCP oferece as seguintes ferramentas:\n\n- `login`: Autenticação na plataforma\n  - Parâmetros: `user`, `pass`\n  - Retorna: `sessionId`\n\n- `upload`: Envio de documentos\n  - Parâmetros: `sessionId`, `filePath`, `recipient` (opcional), `version` (opcional)\n  - Retorna: `uploadId`\n\n- `consultProtocol`: Consulta de protocolos por chave ou vice-versa\n  - Parâmetros: `sessionId`, `keys`, `protocols`, `outputFormat`, `download`, `delimiter`\n  - Formatos de saída: json, xml, csv\n\n- `retrieveDocument`: Consulta de documentos enviados\n  - Parâmetros:\n    - `sessionId`: ID da sessão obtido no login.\n    - `modDoc`: Tipo de documento (e.g., DI, MDF-e, CT-e, NF-e, Minuta CT-e).\n    - `dtStart` e `dtLimit`: Datas de início e fim no formato `YYYY-MM-DD`.\n    - `dtType`: Tipo de data (Update, Emission, Send), padrão é `Send`.\n    - Filtros opcionais: `numDoc`, `emit`, `rem`, `exped`, `receb`, `dest`, `toma`, `importador`, `representante`, `prot`, `taxId`.\n    - Paginação: `page`, `start`, `limit`.\n    - Outros: `relation`, `modal`, `valid`.\n\n- `decomposeKey`: Decomposição de chaves para análise\n  - Parâmetros:\n    - `key`: Chave de acesso de 44 dígitos para NF-e, CT-e ou MDF-e.\n\n## 🔒 Segurança\n- Utilize as credenciais de API geradas no módulo Cadastro do Usuário\n- Mantenha suas credenciais em segurança\n- Não compartilhe seu `sessionId`\n- Utilize sempre conexões seguras\n- Mantenha o servidor MCP atualizado\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "averbeporto",
        "document",
        "authentication",
        "averbeporto mcp",
        "averbeporto manage",
        "ghsix averbeporto"
      ],
      "category": "document-processing"
    },
    "Geeksfino--kb-mcp-server": {
      "owner": "Geeksfino",
      "name": "kb-mcp-server",
      "url": "https://github.com/Geeksfino/kb-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/Geeksfino.webp",
      "description": "Provides semantic search capabilities, builds and queries knowledge graphs, and facilitates AI-driven text processing through a standardized interface. Integrates vector databases with relational databases for enhanced data utilization.",
      "stars": 49,
      "forks": 11,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-08-31T17:38:32Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/geeksfino-kb-mcp-server-badge.png)](https://mseep.ai/app/geeksfino-kb-mcp-server)\n\n# Embedding MCP Server\n\nA Model Context Protocol (MCP) server implementation powered by txtai, providing semantic search, knowledge graph capabilities, and AI-driven text processing through a standardized interface.\n\n## The Power of txtai: All-in-one Embeddings Database\n\nThis project leverages [txtai](https://github.com/neuml/txtai), an all-in-one embeddings database for RAG leveraging semantic search, knowledge graph construction, and language model workflows. txtai offers several key advantages:\n\n- **Unified Vector Database**: Combines vector indexes, graph networks, and relational databases in a single platform\n- **Semantic Search**: Find information based on meaning, not just keywords\n- **Knowledge Graph Integration**: Automatically build and query knowledge graphs from your data\n- **Portable Knowledge Bases**: Save entire knowledge bases as compressed archives (.tar.gz) that can be easily shared and loaded\n- **Extensible Pipeline System**: Process text, documents, audio, images, and video through a unified API\n- **Local-first Architecture**: Run everything locally without sending data to external services\n\n## How It Works\n\nThe project contains a knowledge base builder tool and a MCP server. The knowledge base builder tool is a command-line interface for creating and managing knowledge bases. The MCP server provides a standardized interface to access the knowledge base. \n\nIt is not required to use the knowledge base builder tool to build a knowledge base. You can always build a knowledge base using txtai's programming interface by writing a Python script or even using a jupyter notebook. As long as the knowledge base is built using txtai, it can be loaded by the MCP server. Better yet, the knowledge base can be a folder on the file system or an exported .tar.gz file. Just give it to the MCP server and it will load it.\n\n### 1. Build a Knowledge Base with kb_builder\n\nThe `kb_builder` module provides a command-line interface for creating and managing knowledge bases:\n\n- Process documents from various sources (files, directories, JSON)\n- Extract text and create embeddings\n- Build knowledge graphs automatically\n- Export portable knowledge bases\n\nNote it is possibly limited in functionality and currently only provided for convenience.\n\n### 2. Start the MCP Server\n\nThe MCP server provides a standardized interface to access the knowledge base:\n\n- Semantic search capabilities\n- Knowledge graph querying and visualization\n- Text processing pipelines (summarization, extraction, etc.)\n- Full compliance with the Model Context Protocol\n\n## Installation\n\n### Recommended: Using uv with Python 3.10+\n\nWe recommend using [uv](https://github.com/astral-sh/uv) with Python 3.10 or newer for the best experience. This provides better dependency management and ensures consistent behavior.\n\n```bash\n# Install uv if you don't have it already\npip install -U uv\n\n# Create a virtual environment with Python 3.10 or newer\nuv venv --python=3.10  # or 3.11, 3.12, etc.\n\n# Activate the virtual environment (bash/zsh)\nsource .venv/bin/activate\n# For fish shell\n# source .venv/bin/activate.fish\n\n# Install from PyPI\nuv pip install kb-mcp-server\n```\n\n> **Note**: We pin transformers to version 4.49.0 to avoid deprecation warnings about `transformers.agents.tools` that appear in version 4.50.0 and newer. If you use a newer version of transformers, you may see these warnings, but they don't affect functionality.\n\n### Using conda\n\n```bash\n# Create a new conda environment (optional)\nconda create -n embedding-mcp python=3.10\nconda activate embedding-mcp\n\n# Install from PyPI\npip install kb-mcp-server\n```\n\n### From Source\n\n```bash\n# Create a new conda environment\nconda create -n embedding-mcp python=3.10\nconda activate embedding-mcp\n\n# Clone the repository\ngit clone https://github.com/Geeksfino/kb-mcp-server.git.git\ncd kb-mcp-server\n\n# Install dependencies\npip install -e .\n```\n\n### Using uv (Faster Alternative)\n\n```bash\n# Install uv if not already installed\npip install uv\n\n# Create a new virtual environment\nuv venv\nsource .venv/bin/activate\n\n# Option 1: Install from PyPI\nuv pip install kb-mcp-server\n\n# Option 2: Install from source (for development)\nuv pip install -e .\n```\n\n### Using uvx (No Installation Required)\n\n[uvx](https://github.com/astral-sh/uv) allows you to run packages directly from PyPI without installing them:\n\n```bash\n# Run the MCP server\nuvx --from kb-mcp-server@0.3.0 kb-mcp-server --embeddings /path/to/knowledge_base\n\n# Build a knowledge base\nuvx --from kb-mcp-server@0.3.0 kb-build --input /path/to/documents --config config.yml\n\n# Search a knowledge base\nuvx --from kb-mcp-server@0.3.0 kb-search /path/to/knowledge_base \"Your search query\"\n```\n\n## Command Line Usage\n\n### Building a Knowledge Base\n\nYou can use the command-line tools installed from PyPI, the Python module directly, or the convenient shell scripts:\n\n#### Using the PyPI Installed Commands\n\n```bash\n# Build a knowledge base from documents\nkb-build --input /path/to/documents --config config.yml\n\n# Update an existing knowledge base with new documents\nkb-build --input /path/to/new_documents --update\n\n# Export a knowledge base for portability\nkb-build --input /path/to/documents --export my_knowledge_base.tar.gz\n\n# Search a knowledge base\nkb-search /path/to/knowledge_base \"What is machine learning?\"\n\n# Search with graph enhancement\nkb-search /path/to/knowledge_base \"What is machine learning?\" --graph --limit 10\n```\n\n#### Using uvx (No Installation Required)\n\n```bash\n# Build a knowledge base from documents\nuvx --from kb-mcp-server@0.3.0 kb-build --input /path/to/documents --config config.yml\n\n# Update an existing knowledge base with new documents\nuvx --from kb-mcp-server@0.3.0 kb-build --input /path/to/new_documents --update\n\n# Export a knowledge base for portability\nuvx --from kb-mcp-server@0.3.0 kb-build --input /path/to/documents --export my_knowledge_base.tar.gz\n\n# Search a knowledge base\nuvx --from kb-mcp-server@0.3.0 kb-search /path/to/knowledge_base \"What is machine learning?\"\n\n# Search with graph enhancement\nuvx --from kb-mcp-server@0.3.0 kb-search /path/to/knowledge_base \"What is machine learning?\" --graph --limit 10\n```\n\n#### Using the Python Module\n\n```bash\n# Build a knowledge base from documents\npython -m kb_builder build --input /path/to/documents --config config.yml\n\n# Update an existing knowledge base with new documents\npython -m kb_builder build --input /path/to/new_documents --update\n\n# Export a knowledge base for portability\npython -m kb_builder build --input /path/to/documents --export my_knowledge_base.tar.gz\n```\n\n#### Using the Convenience Scripts\n\nThe repository includes convenient wrapper scripts that make it easier to build and search knowledge bases:\n\n```bash\n# Build a knowledge base using a template configuration\n./scripts/kb_build.sh /path/to/documents technical_docs\n\n# Build using a custom configuration file\n./scripts/kb_build.sh /path/to/documents /path/to/my_config.yml\n\n# Update an existing knowledge base\n./scripts/kb_build.sh /path/to/documents technical_docs --update\n\n# Search a knowledge base\n./scripts/kb_search.sh /path/to/knowledge_base \"What is machine learning?\"\n\n# Search with graph enhancement\n./scripts/kb_search.sh /path/to/knowledge_base \"What is machine learning?\" --graph\n```\n\nRun `./scripts/kb_build.sh --help` or `./scripts/kb_search.sh --help` for more options.\n\n### Starting the MCP Server\n\n#### Using the PyPI Installed Command\n\n```bash\n# Start with a specific knowledge base folder\nkb-mcp-server --embeddings /path/to/knowledge_base_folder\n\n# Start with a given knowledge base archive\nkb-mcp-server --embeddings /path/to/knowledge_base.tar.gz\n```\n\n#### Using uvx (No Installation Required)\n\n```bash\n# Start with a specific knowledge base folder\nuvx kb-mcp-server@0.2.6 --embeddings /path/to/knowledge_base_folder\n\n# Start with a given knowledge base archive\nuvx kb-mcp-server@0.2.6 --embeddings /path/to/knowledge_base.tar.gz\n```\n\n#### Using the Python Module\n\n```bash\n# Start with a specific knowledge base folder\npython -m txtai_mcp_server --embeddings /path/to/knowledge_base_folder\n\n# Start with a given knowledge base archive\npython -m txtai_mcp_server --embeddings /path/to/knowledge_base.tar.gz\n```\n## MCP Server Configuration\n\nThe MCP server is configured using environment variables or command-line arguments, not YAML files. YAML files are only used for configuring txtai components during knowledge base building.\n\nHere's how to configure the MCP server:\n\n```bash\n# Start the server with command-line arguments\nkb-mcp-server --embeddings /path/to/knowledge_base --host 0.0.0.0 --port 8000\n\n# Or using uvx (no installation required)\nuvx kb-mcp-server@0.2.6 --embeddings /path/to/knowledge_base --host 0.0.0.0 --port 8000\n\n# Or using the Python module\npython -m txtai_mcp_server --embeddings /path/to/knowledge_base --host 0.0.0.0 --port 8000\n\n# Or use environment variables\nexport TXTAI_EMBEDDINGS=/path/to/knowledge_base\nexport MCP_SSE_HOST=0.0.0.0\nexport MCP_SSE_PORT=8000\npython -m txtai_mcp_server\n```\n\nCommon configuration options:\n- `--embeddings`: Path to the knowledge base (required)\n- `--host`: Host address to bind to (default: localhost)\n- `--port`: Port to listen on (default: 8000)\n- `--transport`: Transport to use, either 'sse' or 'stdio' (default: stdio)\n- `--enable-causal-boost`: Enable causal boost feature for enhanced relevance scoring\n- `--causal-config`: Path to custom causal boost configuration YAML file\n\n## Configuring LLM Clients to Use the MCP Server\n\nTo configure an LLM client to use the MCP server, you need to create an MCP configuration file. Here's an example `mcp_config.json`:\n\n### Using the server directly\n\nIf you use a virtual Python environment to install the server, you can use the following configuration - note that MCP host like Claude will not be able to connect to the server if you use a virtual environment, you need to use the absolute path to the Python executable of the virtual environment where you did \"pip install\" or \"uv pip install\", for example\n\n```json\n{\n  \"mcpServers\": {\n    \"kb-server\": {\n      \"command\": \"/your/home/project/.venv/bin/kb-mcp-server\",\n      \"args\": [\n        \"--embeddings\", \n        \"/path/to/knowledge_base.tar.gz\"\n      ],\n      \"cwd\": \"/path/to/working/directory\"\n    }\n  }\n}\n```\n\n### Using system default Python\n\nIf you use your system default Python, you can use the following configuration:\n\n```json\n{\n    \"rag-server\": {\n      \"command\": \"python3\",\n      \"args\": [\n        \"-m\",\n        \"txtai_mcp_server\",\n        \"--embeddings\",\n        \"/path/to/knowledge_base.tar.gz\",\n        \"--enable-causal-boost\"\n      ],\n      \"cwd\": \"/path/to/working/directory\"\n    }\n}\n```\n\nAlternatively, if you're using uvx, assuming you have uvx installed in your system via \"brew install uvx\" etc, or you 've installed uvx and made it globally accessible via:\n```\n# Create a symlink to /usr/local/bin (which is typically in the system PATH)\nsudo ln -s /Users/cliang/.local/bin/uvx /usr/local/bin/uvx\n```\nThis creates a symbolic link from your user-specific installation to a system-wide location. For macOS applications like Claude Desktop, you can modify the system-wide PATH by creating or editing a launchd configuration file:\n```\n# Create a plist file to set environment variables for all GUI applications\nsudo nano /Library/LaunchAgents/environment.plist\n```\nAdd this content:\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\">\n<plist version=\"1.0\">\n<dict>\n  <key>Label</key>\n  <string>my.startup</string>\n  <key>ProgramArguments</key>\n  <array>\n    <string>sh</string>\n    <string>-c</string>\n    <string>launchctl setenv PATH $PATH:/Users/cliang/.local/bin</string>\n  </array>\n  <key>RunAtLoad</key>\n  <true/>\n</dict>\n</plist>\n```\n\nThen load it:\n```\nsudo launchctl load -w /Library/LaunchAgents/environment.plist\n```\nYou'll need to restart your computer for this to take effect, though.\n\n\n```json\n{\n  \"mcpServers\": {\n    \"kb-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"kb-mcp-server@0.2.6\",\n        \"--embeddings\", \"/path/to/knowledge_base\",\n        \"--host\", \"localhost\",\n        \"--port\", \"8000\"\n      ],\n      \"cwd\": \"/path/to/working/directory\"\n    }\n  }\n}\n```\n\nPlace this configuration file in a location accessible to your LLM client and configure the client to use it. The exact configuration steps will depend on your specific LLM client.\n\n## Advanced Knowledge Base Configuration\n\nBuilding a knowledge base with txtai requires a YAML configuration file that controls various aspects of the embedding process. This configuration is used by the `kb_builder` tool, not the MCP server itself.\n\nOne may need to tune segmentation/chunking strategies, embedding models, and scoring methods, as well as configure graph construction, causal boosting, weights of hybrid search, and more.\n\nFortunately, txtai provides a powerful YAML configuration system that requires no coding. Here's an example of a comprehensive configuration for knowledge base building:\n\n```yaml\n# Path to save/load embeddings index\npath: ~/.txtai/embeddings\nwritable: true\n\n# Content storage in SQLite\ncontent:\n  path: sqlite:///~/.txtai/content.db\n\n# Embeddings configuration\nembeddings:\n  # Model settings\n  path: sentence-transformers/nli-mpnet-base-v2\n  backend: faiss\n  gpu: true\n  batch: 32\n  normalize: true\n  \n  # Scoring settings\n  scoring: hybrid\n  hybridalpha: 0.75\n\n# Pipeline configuration\npipeline:\n  workers: 2\n  queue: 100\n  timeout: 300\n\n# Question-answering pipeline\nextractor:\n  path: distilbert-base-cased-distilled-squad\n  maxlength: 512\n  minscore: 0.3\n\n# Graph configuration\ngraph:\n  backend: sqlite\n  path: ~/.txtai/graph.db\n  similarity: 0.75  # Threshold for creating graph connections\n  limit: 10  # Maximum connections per node\n```\n\n### Configuration Examples\n\nThe `src/kb_builder/configs` directory contains configuration templates for different use cases and storage backends:\n\n#### Storage and Backend Configurations\n- `memory.yml`: In-memory vectors (fastest for development, no persistence)\n- `sqlite-faiss.yml`: SQLite for content + FAISS for vectors (local file-based persistence)\n- `postgres-pgvector.yml`: PostgreSQL + pgvector (production-ready with full persistence)\n\n#### Domain-Specific Configurations\n- `base.yml`: Base configuration template\n- `code_repositories.yml`: Optimized for code repositories\n- `data_science.yml`: Configured for data science documents\n- `general_knowledge.yml`: General purpose knowledge base\n- `research_papers.yml`: Optimized for academic papers\n- `technical_docs.yml`: Configured for technical documentation\n\nYou can use these as starting points for your own configurations:\n\n```bash\npython -m kb_builder build --input /path/to/documents --config src/kb_builder/configs/technical_docs.yml\n\n# Or use a storage-specific configuration\npython -m kb_builder build --input /path/to/documents --config src/kb_builder/configs/postgres-pgvector.yml\n```\n\n## Advanced Features\n\n### Knowledge Graph Capabilities\n\nThe MCP server leverages txtai's built-in graph functionality to provide powerful knowledge graph capabilities:\n\n- **Automatic Graph Construction**: Build knowledge graphs from your documents automatically\n- **Graph Traversal**: Navigate through related concepts and documents\n- **Path Finding**: Discover connections between different pieces of information\n- **Community Detection**: Identify clusters of related information\n\n### Causal Boosting Mechanism\n\nThe MCP server includes a sophisticated causal boosting mechanism that enhances search relevance by identifying and prioritizing causal relationships:\n\n- **Pattern Recognition**: Detects causal language patterns in both queries and documents\n- **Multilingual Support**: Automatically applies appropriate patterns based on detected query language\n- **Configurable Boost Multipliers**: Different types of causal matches receive customizable boost factors\n- **Enhanced Relevance**: Results that explain causal relationships are prioritized in search results\n\nThis mechanism significantly improves responses to \"why\" and \"how\" questions by surfacing content that explains relationships between concepts. The causal boosting configuration is highly customizable through YAML files, allowing adaptation to different domains and languages.\n\n\n## License\n\nMIT License - see LICENSE file for details\n\n\n\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "databases",
        "semantic",
        "queries",
        "semantic search",
        "document processing",
        "text processing"
      ],
      "category": "document-processing"
    },
    "GoatWang--YTTranscipterMultilingualMCP": {
      "owner": "GoatWang",
      "name": "YTTranscipterMultilingualMCP",
      "url": "https://github.com/GoatWang/YTTranscipterMultilingualMCP",
      "imageUrl": "/freedevtools/mcp/pfp/GoatWang.webp",
      "description": "Transcribes YouTube videos into text across multiple languages to enhance content accessibility and audience engagement. Facilitates the conversion of spoken language into written form for improved reach.",
      "stars": 0,
      "forks": 1,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-04-08T08:45:53Z",
      "readme_content": "# YTTranscipterMultilingualMCP\n[![smithery badge](https://smithery.ai/badge/@GoatWang/yttransciptermultilingualmcp)](https://smithery.ai/server/@GoatWang/yttransciptermultilingualmcp)\n\n## Description\n\nThis repository contains the code for YTTranscipterMultilingualMCP, a service for transcribing YouTube videos in multiple languages.\n\n## Usage\nNotice: command should come with `<full-path-of-uvx>` e.g. `/Library/Frameworks/Python.framework/Versions/3.10/bin/uvx`\n```\n{\n  \"mcpServers\": {\n    \"yt-transcipter-multilingual\": {\n      \"command\": \"/Library/Frameworks/Python.framework/Versions/3.10/bin/uvx\", \n      \"args\": [\n        \"--from\",\n        \"git+https://github.com/GoatWang/YTTranscipterMultilingualMCP\",\n        \"yt-transcipter-multilingual\"\n      ]\n    }    \n  }\n}\n```\n\n## Prerequisites\n\n* Python 3.10+\n* Docker\n\n## Other Info\n\n1. Clone the repository:\n\n   ```bash\n   git clone https://github.com/GoatWang/YTTranscipterMultilingualMCP\n   ```\n\n2. Build the Docker image:\n\n   ```bash\n   docker build -t yt-transcipter-multilingual .\n   ```\n\n3. Run the Docker container:\n\n   ```bash\n   docker run -d -p 5000:5000 yt-transcipter-multilingual\n   ```\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "transcribes",
        "yttransciptermultilingualmcp",
        "youtube",
        "transcribes youtube",
        "yttransciptermultilingualmcp transcribes",
        "videos text"
      ],
      "category": "document-processing"
    },
    "GongRzhe--JSON-MCP-Server": {
      "owner": "GongRzhe",
      "name": "JSON-MCP-Server",
      "url": "https://github.com/GongRzhe/JSON-MCP-Server",
      "imageUrl": "/freedevtools/mcp/pfp/GongRzhe.webp",
      "description": "Query and manipulate JSON data using standardized tools and JSONPath syntax with extended operations.",
      "stars": 78,
      "forks": 19,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-25T15:25:12Z",
      "readme_content": "# JSON MCP Server (@gongrzhe/server-json-mcp@1.0.3)\n\nA JSON Model Context Protocol (MCP) server implementation for querying and manipulating JSON data. This server enables LLMs to interact with JSON data through a set of standardized tools.\n\n<a href=\"https://glama.ai/mcp/servers/9g137c4b4k\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/9g137c4b4k/badge\" alt=\"JSON Server MCP server\" />\n</a>\n\n## Installation & Usage\n\n```bash\n# Using npx with specific version (recommended)\nnpx @gongrzhe/server-json-mcp@1.0.3\n\n# Install specific version globally\nnpm install -g @gongrzhe/server-json-mcp@1.0.3\n\n# Run after global installation\nserver-json-mcp\n```\n\n## Components\n\n### Tools\n\n- **query**\n  - Query JSON data using JSONPath syntax with extended operations\n  - Input:\n    - `url` (string): URL of the JSON data source\n    - `jsonPath` (string): JSONPath expression with optional operations\n\n- **filter**\n  - Filter JSON data using conditions\n  - Input:\n    - `url` (string): URL of the JSON data source\n    - `jsonPath` (string): Base JSONPath expression\n    - `condition` (string): Filter condition\n\n### Supported Operations\n\n#### Array Operations\n- **Slicing**: `$[0:5]`, `$[-3:]`, `$[1:4]`\n- **Sorting**: `$.sort(price)`, `$.sort(-price)`\n- **Distinct**: `$.distinct()`\n- **Transformations**: \n  - Map: `$.map(fieldName)`\n  - Flatten: `$.flatten()`\n  - Union: `$.union([1,2,3])`\n  - Intersection: `$.intersection([1,2,3])`\n\n#### String Operations\n- **Case**: `$.toLowerCase()`, `$.toUpperCase()`\n- **Tests**: `$.startsWith('test')`, `$.endsWith('test')`\n- **Search**: `$.contains('test')`, `$.matches('pattern')`\n\n#### Numeric Operations\n- **Math**: `$.math(+10)`, `$.pow2()`\n- **Rounding**: `$.round()`, `$.floor()`, `$.ceil()`\n- **Functions**: `$.abs()`, `$.sqrt()`\n\n#### Date Operations\n- **Format**: `$.format('YYYY-MM-DD')`\n- **Check**: `$.isToday()`\n- **Modify**: `$.add(1, 'days')`\n\n#### Aggregation Operations\n- **Group**: `$.groupBy(category)`\n- **Stats**: `$.sum(price)`, `$.avg(price)`, `$.min(price)`, `$.max(price)`\n\n## Configuration\n\n### Usage with Claude Desktop\n\nTo use this server with the Claude Desktop app, add the following configuration to your `claude_desktop_config.json`:\n\n```json\n{\n  \"json\": {\n    \"command\": \"npx\",\n    \"args\": [\n      \"@gongrzhe/server-json-mcp@1.0.3\"\n    ]\n  }\n}\n```\n\nAlternatively, you can use the node command directly if you have the package installed:\n\n```json\n{\n  \"json\": {\n    \"command\": \"node\",\n    \"args\": [\n      \"path/to/build/index.js\"\n    ]\n  }\n}\n```\n\n## Development\n\n### Building from Source\n\n1. Clone the repository\n2. Install dependencies:\n   ```bash\n   npm install\n   ```\n3. Build the project:\n   ```bash\n   npm run build\n   ```\n\n## Notes\n\n1. All JSONPath expressions start with `$` representing the root object\n2. Array indices are zero-based\n3. String values in operations should be wrapped in quotes\n4. Date operations support 'days', 'months', and 'years' units\n5. Numeric operations support basic arithmetic operators (+, -, *, /)\n\n## License\n\nMIT",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "jsonpath",
        "json",
        "mcp",
        "json mcp",
        "tools jsonpath",
        "jsonpath syntax"
      ],
      "category": "document-processing"
    },
    "GongRzhe--Langflow-DOC-QA-SERVER": {
      "owner": "GongRzhe",
      "name": "Langflow-DOC-QA-SERVER",
      "url": "https://github.com/GongRzhe/Langflow-DOC-QA-SERVER",
      "imageUrl": "/freedevtools/mcp/pfp/GongRzhe.webp",
      "description": "Query documents using a Q&A system to retrieve precise answers efficiently. The server leverages a Langflow backend for enhanced document management and interaction.",
      "stars": 14,
      "forks": 9,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-07-30T02:34:58Z",
      "readme_content": "# Langflow-DOC-QA-SERVER\n![](https://badge.mcpx.dev?type=server 'MCP Server')\n[![smithery badge](https://smithery.ai/badge/@GongRzhe/Langflow-DOC-QA-SERVER)](https://smithery.ai/server/@GongRzhe/Langflow-DOC-QA-SERVER)\n\n<a href=\"https://glama.ai/mcp/servers/@GongRzhe/Langflow-DOC-QA-SERVER\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@GongRzhe/Langflow-DOC-QA-SERVER/badge\" alt=\"Langflow Document Q&A Server MCP server\" />\n</a>\n\nA Model Context Protocol server for document Q&A powered by Langflow\n\nThis is a TypeScript-based MCP server that implements a document Q&A system. It demonstrates core MCP concepts by providing a simple interface to query documents through a Langflow backend.\n\n## Prerequisites\n\n### 1. Create Langflow Document Q&A Flow\n1. Open Langflow and create a new flow from the \"Document Q&A\" template\n2. Configure your flow with necessary components (ChatInput, File Upload, LLM, etc.)\n3. Save your flow\n\n![image](https://github.com/user-attachments/assets/0df89122-d7a8-4d18-9a39-57af4240b7ac)\n\n\n### 2. Get Flow API Endpoint\n1. Click the \"API\" button in the top right corner of Langflow\n2. Copy the API endpoint URL from the cURL command\n   Example: `http://127.0.0.1:7860/api/v1/run/<flow-id>?stream=false`\n3. Save this URL as it will be needed for the `API_ENDPOINT` configuration\n\n![image](https://github.com/user-attachments/assets/6c9ba5e2-4aa3-4a8c-89c2-adc3d400c828)\n\n\n## Features\n\n### Tools\n- `query_docs` - Query the document Q&A system\n  - Takes a query string as input\n  - Returns responses from the Langflow backend\n\n## Development\n\nInstall dependencies:\n```bash\nnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n```bash\nnpm run watch\n```\n\n## Installation\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"langflow-doc-qa-server\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/path/to/doc-qa-server/build/index.js\"\n      ],\n      \"env\": {\n        \"API_ENDPOINT\": \"http://127.0.0.1:7860/api/v1/run/480ec7b3-29d2-4caa-b03b-e74118f35fac\"\n      }\n    }\n  }\n}\n```\n\n![image](https://github.com/user-attachments/assets/b0821378-ed13-4225-81a9-8beab1dc4b48)\n\n### Installing via Smithery\n\nTo install Document Q&A Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@GongRzhe/Langflow-DOC-QA-SERVER):\n\n```bash\nnpx -y @smithery/cli install @GongRzhe/Langflow-DOC-QA-SERVER --client claude\n```\n\n### Environment Variables\n\nThe server supports the following environment variables for configuration:\n\n- `API_ENDPOINT`: The endpoint URL for the Langflow API service. Defaults to `http://127.0.0.1:7860/api/v1/run/480ec7b3-29d2-4caa-b03b-e74118f35fac` if not specified.\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n\n## 📜 License\n\nThis project is licensed under the MIT License.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "langflow",
        "documents",
        "document",
        "document processing",
        "query documents",
        "langflow backend"
      ],
      "category": "document-processing"
    },
    "GongRzhe--Office-PowerPoint-MCP-Server": {
      "owner": "GongRzhe",
      "name": "Office-PowerPoint-MCP-Server",
      "url": "https://github.com/GongRzhe/Office-PowerPoint-MCP-Server",
      "imageUrl": "/freedevtools/mcp/pfp/GongRzhe.webp",
      "description": "Create, edit, and manipulate PowerPoint presentations using various automation tools. Streamlines workflow by providing functionalities to enhance presentation tasks.",
      "stars": 1063,
      "forks": 133,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-03T17:00:09Z",
      "readme_content": "# Office-PowerPoint-MCP-Server\n[![smithery badge](https://smithery.ai/badge/@GongRzhe/Office-PowerPoint-MCP-Server)](https://smithery.ai/server/@GongRzhe/Office-PowerPoint-MCP-Server)\n![](https://badge.mcpx.dev?type=server 'MCP Server')\n\nA comprehensive MCP (Model Context Protocol) server for PowerPoint manipulation using python-pptx. **Version 2.0** provides 32 powerful tools organized into 11 specialized modules, offering complete PowerPoint creation, management, and professional design capabilities. The server features a modular architecture with enhanced parameter handling, intelligent operation selection, and comprehensive error handling.\n\n----\n\n# **Not so ugly anymore with new slide_layout_templates**\n\n\n\n----\n\n### Example\n\n#### Pormpt\n\n<img width=\"1280\" alt=\"650f4cc5d0f1ea4f3b1580800cb0deb\" src=\"https://github.com/user-attachments/assets/90633c97-f373-4c85-bc9c-a1d7b891c344\" />\n\n#### Output\n\n<img width=\"1640\" alt=\"084f1cf4bc7e4fcd4890c8f94f536c1\" src=\"https://github.com/user-attachments/assets/420e63a0-15a4-46d8-b149-1408d23af038\" />\n\n#### Demo's GIF -> (./public/demo.mp4)\n\n\n\n## Features\n\n### Core PowerPoint Operations\n- **Round-trip support** for any Open XML presentation (.pptx file) including all elements\n- **Template support** with automatic theme and layout preservation\n- **Multi-presentation management** with global state tracking\n- **Core document properties** management (title, subject, author, keywords, comments)\n\n### Content Creation & Management\n- **Slide management** with flexible layout selection\n- **Text manipulation** with placeholder population and bullet point creation\n- **Advanced text formatting** with font, color, alignment, and style controls\n- **Text validation** with automatic fit checking and optimization suggestions\n\n### Visual Elements\n- **Image handling** with file and base64 input support\n- **Image enhancement** using Pillow with brightness, contrast, saturation, and filter controls\n- **Professional image effects** including shadows, reflections, glows, and soft edges\n- **Shape creation** with 20+ auto shape types (rectangles, ovals, flowchart elements, etc.)\n- **Table creation** with advanced cell formatting and styling\n\n### Charts & Data Visualization\n- **Chart support** for column, bar, line, and pie charts\n- **Data series management** with categories and multiple series support\n- **Chart formatting** with legends, data labels, and titles\n\n### Professional Design Features\n- **4 professional color schemes** (Modern Blue, Corporate Gray, Elegant Green, Warm Red)\n- **Professional typography** with Segoe UI font family and size presets\n- **Theme application** with automatic styling across presentations\n- **Gradient backgrounds** with customizable directions and color schemes\n- **Slide enhancement** tools for existing content\n- **25 built-in slide templates** with dynamic sizing and visual effects\n- **Advanced template features** including auto-wrapping, dynamic font sizing, and professional animations\n\n### Advanced Features\n- **Font analysis and optimization** using FontTools\n- **Picture effects** with 9 different visual effects (shadow, reflection, glow, bevel, etc.)\n- **Comprehensive validation** with automatic error fixing\n- **Template search** with configurable directory paths\n- **Professional layout calculations** with margin and spacing management\n\n## Installation\n\n### Installing via Smithery\n\nTo install PowerPoint Manipulation Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@GongRzhe/Office-PowerPoint-MCP-Server):\n\n```bash\nnpx -y @smithery/cli install @GongRzhe/Office-PowerPoint-MCP-Server --client claude\n```\n\n### Prerequisites\n\n- Python 3.6 or higher (as specified in pyproject.toml)\n- pip package manager\n- Optional: uvx for package execution without local installation\n\n### Installation Options\n\n#### Option 1: Using the Setup Script (Recommended)\n\nThe easiest way to set up the PowerPoint MCP Server is using the provided setup script, which automates the installation process:\n\n```bash\npython setup_mcp.py\n```\n\nThis script will:\n- Check prerequisites\n- Offer installation options:\n  - Install from PyPI (recommended for most users)\n  - Set up local development environment\n- Install required dependencies\n- Generate the appropriate MCP configuration file\n- Provide instructions for integrating with Claude Desktop\n\nThe script offers different paths based on your environment:\n- If you have `uvx` installed, it will configure using UVX (recommended)\n- If the server is already installed, it provides configuration options\n- If the server is not installed, it offers installation methods\n\n#### Option 2: Manual Installation\n\n1. Clone the repository:\n   ```bash\n   git clone https://github.com/GongRzhe/Office-PowerPoint-MCP-Server.git\n   cd Office-PowerPoint-MCP-Server\n   ```\n\n2. Install dependencies:\n   ```bash\n   pip install -r requirements.txt\n   ```\n\n3. Make the server executable:\n   ```bash\n   chmod +x ppt_mcp_server.py\n   ```\n\n## Usage\n\nDisplay help text:\n```bash\npython ppt_mcp_server.py -h\n```\n\n### Starting the Stdio Server\n\nRun the stdio server:\n\n```bash\npython ppt_mcp_server.py\n```\n\n### Starting the Streamable-Http Server\n\nRun the streamable-http server on port 8000:\n\n```bash\npython ppt_mcp_server.py --transport http --port 8000\n```\n\nRun in Docker\n```bash\ndocker build -t ppt_mcp_server .\ndocker run -d --rm -p 8000:8000 ppt_mcp_server -t http\n```\n\n\n### MCP Configuration\n\n#### Option 1: Local Python Server\n\nAdd the server to your MCP settings configuration file:\n\n```json\n{\n  \"mcpServers\": {\n    \"ppt\": {\n      \"command\": \"python\",\n      \"args\": [\"/path/to/ppt_mcp_server.py\"],\n      \"env\": {}\n    }\n  }\n}\n```\n\n#### Option 2: Using UVX (No Local Installation Required)\n\nIf you have `uvx` installed, you can run the server directly from PyPI without local installation:\n\n```json\n{\n  \"mcpServers\": {\n    \"ppt\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"--from\", \"office-powerpoint-mcp-server\", \"ppt_mcp_server\"\n      ],\n      \"env\": {}\n    }\n  }\n}\n```\n\n## 🚀 What's New in v2.0\n\n### **Comprehensive Tool Suite (32 Tools)**\n- **Complete PowerPoint manipulation** with 34 specialized tools\n- **11 organized modules** covering all aspects of presentation creation\n- **Enhanced parameter handling** with comprehensive validation\n- **Intelligent defaults** and operation-based interfaces\n\n### **Built-in Slide Templates**\n- **25+ professional slide templates** with dynamic features built-in\n- **Advanced template system** with auto-generation capabilities\n- **Auto-sizing text** that adapts to content length and container size\n- **Professional visual effects** including shadows, glows, and gradients\n- **Complete presentation generation** from template sequences\n\n### **Modular Architecture**\n- **11 specialized modules**: presentation, content, structural, professional, template, hyperlink, chart, connector, master, and transition tools\n- **Better maintainability** with separated concerns\n- **Easier extensibility** for adding new features\n- **Cleaner code structure** with shared utilities\n\n## Available Tools\n\nThe server provides **34 specialized tools** organized into the following categories:\n\n### **Presentation Management (7 tools)**\n1. **create_presentation** - Create new presentations\n2. **create_presentation_from_template** - Create from templates with theme preservation\n3. **open_presentation** - Open existing presentations\n4. **save_presentation** - Save presentations to files\n5. **get_presentation_info** - Get comprehensive presentation information\n6. **get_template_file_info** - Analyze template files and layouts\n7. **set_core_properties** - Set document properties\n\n### **Content Management (8 tools)**\n8. **add_slide** - Add slides with optional background styling\n9. **get_slide_info** - Get detailed slide information\n10. **extract_slide_text** - ✨ **NEW** Extract all text content from a specific slide\n11. **extract_presentation_text** - ✨ **NEW** Extract text content from all slides in presentation\n12. **populate_placeholder** - Populate placeholders with text\n13. **add_bullet_points** - Add formatted bullet points\n14. **manage_text** - ✨ **Unified text tool** (add/format/validate/format_runs)\n15. **manage_image** - ✨ **Unified image tool** (add/enhance)\n\n### **Template Operations (7 tools)**\n16. **list_slide_templates** - Browse available slide layout templates\n17. **apply_slide_template** - Apply structured layout templates to existing slides\n18. **create_slide_from_template** - Create new slides using layout templates\n19. **create_presentation_from_templates** - Create complete presentations from template sequences\n20. **get_template_info** - Get detailed information about specific templates\n21. **auto_generate_presentation** - Automatically generate presentations based on topic\n22. **optimize_slide_text** - Optimize text elements for better readability and fit\n\n### **Structural Elements (4 tools)**\n23. **add_table** - Create tables with enhanced formatting\n24. **format_table_cell** - Format individual table cells\n25. **add_shape** - Add shapes with text and formatting options\n26. **add_chart** - Create charts with comprehensive customization\n\n### **Professional Design (3 tools)**\n27. **apply_professional_design** - ✨ **Unified design tool** (themes/slides/enhancement)\n28. **apply_picture_effects** - ✨ **Unified effects tool** (9+ effects combined)\n29. **manage_fonts** - ✨ **Unified font tool** (analyze/optimize/recommend)\n\n### **Specialized Features (5 tools)**\n30. **manage_hyperlinks** - Complete hyperlink management (add/remove/list/update)\n31. **manage_slide_masters** - Access and manage slide master properties and layouts\n32. **add_connector** - Add connector lines/arrows between points on slides\n33. **update_chart_data** - Replace existing chart data with new categories and series\n34. **manage_slide_transitions** - Basic slide transition management\n\n## 🌟 Key Unified Tools\n\n### **`manage_text`** - All-in-One Text Management\n```python\n# Add text box\nmanage_text(slide_index=0, operation=\"add\", text=\"Hello World\", font_size=24)\n\n# Format existing text\nmanage_text(slide_index=0, operation=\"format\", shape_index=0, bold=True, color=[255,0,0])\n\n# Validate text fit with auto-fix\nmanage_text(slide_index=0, operation=\"validate\", shape_index=0, validation_only=False)\n```\n\n### **`manage_image`** - Complete Image Handling\n```python\n# Add image with enhancement\nmanage_image(slide_index=0, operation=\"add\", image_source=\"logo.png\", \n            enhancement_style=\"presentation\")\n\n# Enhance existing image\nmanage_image(slide_index=0, operation=\"enhance\", image_source=\"photo.jpg\",\n            brightness=1.2, contrast=1.1, saturation=1.3)\n```\n\n### **`apply_picture_effects`** - Multiple Effects in One Call\n```python\n# Apply combined effects\napply_picture_effects(slide_index=0, shape_index=0, effects={\n    \"shadow\": {\"blur_radius\": 4.0, \"color\": [128,128,128]},\n    \"glow\": {\"size\": 5.0, \"color\": [0,176,240]},\n    \"rotation\": {\"rotation\": 15.0}\n})\n```\n\n### **`apply_professional_design`** - Theme & Design Management\n```python\n# Add professional slide\napply_professional_design(operation=\"slide\", slide_type=\"title_content\", \n                         color_scheme=\"modern_blue\", title=\"My Presentation\")\n\n# Apply theme to entire presentation  \napply_professional_design(operation=\"theme\", color_scheme=\"corporate_gray\")\n\n# Enhance existing slide\napply_professional_design(operation=\"enhance\", slide_index=0, color_scheme=\"elegant_green\")\n```\n\n## Examples\n\n### Creating a New Presentation\n\n```python\n# Create a new presentation\nresult = use_mcp_tool(\n    server_name=\"ppt\",\n    tool_name=\"create_presentation\",\n    arguments={}\n)\npresentation_id = result[\"presentation_id\"]\n\n# Add a title slide\nresult = use_mcp_tool(\n    server_name=\"ppt\",\n    tool_name=\"add_slide\",\n    arguments={\n        \"layout_index\": 0,  # Title slide layout\n        \"title\": \"My Presentation\",\n        \"presentation_id\": presentation_id\n    }\n)\nslide_index = result[\"slide_index\"]\n\n# Populate subtitle placeholder\nresult = use_mcp_tool(\n    server_name=\"ppt\",\n    tool_name=\"populate_placeholder\",\n    arguments={\n        \"slide_index\": slide_index,\n        \"placeholder_idx\": 1,  # Subtitle placeholder\n        \"text\": \"Created with PowerPoint MCP Server\",\n        \"presentation_id\": presentation_id\n    }\n)\n\n# Save the presentation\nresult = use_mcp_tool(\n    server_name=\"ppt\",\n    tool_name=\"save_presentation\",\n    arguments={\n        \"file_path\": \"my_presentation.pptx\",\n        \"presentation_id\": presentation_id\n    }\n)\n```\n\n### Creating a Professional Presentation with v2.0\n\n```python\n# Create a professional slide with modern styling - CONSOLIDATED TOOL\nresult = use_mcp_tool(\n    server_name=\"ppt\",\n    tool_name=\"apply_professional_design\",\n    arguments={\n        \"operation\": \"slide\",\n        \"slide_type\": \"title_content\",\n        \"color_scheme\": \"modern_blue\",\n        \"title\": \"Quarterly Business Review\",\n        \"content\": [\n            \"Revenue increased by 15% compared to last quarter\",\n            \"Customer satisfaction scores reached all-time high of 94%\",\n            \"Successfully launched 3 new product features\",\n            \"Expanded team by 12 new talented professionals\"\n        ]\n    }\n)\n\n# Apply professional theme to entire presentation - SAME TOOL, DIFFERENT OPERATION\nresult = use_mcp_tool(\n    server_name=\"ppt\",\n    tool_name=\"apply_professional_design\",\n    arguments={\n        \"operation\": \"theme\",\n        \"color_scheme\": \"modern_blue\",\n        \"apply_to_existing\": True\n    }\n)\n\n# Add slide with gradient background - ENHANCED ADD_SLIDE\nresult = use_mcp_tool(\n    server_name=\"ppt\",\n    tool_name=\"add_slide\",\n    arguments={\n        \"layout_index\": 0,\n        \"background_type\": \"professional_gradient\",\n        \"color_scheme\": \"modern_blue\",\n        \"gradient_direction\": \"diagonal\"\n    }\n)\n```\n\n### Working with Built-in Slide Templates (New in v2.0)\n\n```python\n# List all available slide templates with their features\nresult = use_mcp_tool(\n    server_name=\"ppt\",\n    tool_name=\"list_slide_templates\",\n    arguments={}\n)\n\n# Apply a professional template to an existing slide\nresult = use_mcp_tool(\n    server_name=\"ppt\",\n    tool_name=\"apply_slide_template\",\n    arguments={\n        \"slide_index\": 0,\n        \"template_id\": \"title_slide\",\n        \"color_scheme\": \"modern_blue\",\n        \"content_mapping\": {\n            \"title\": \"Quarterly Business Review\",\n            \"subtitle\": \"Q4 2024 Results\",\n            \"author\": \"Leadership Team\"\n        }\n    }\n)\n\n# Create a new slide using a template\nresult = use_mcp_tool(\n    server_name=\"ppt\",\n    tool_name=\"create_slide_from_template\",\n    arguments={\n        \"template_id\": \"text_with_image\",\n        \"color_scheme\": \"elegant_green\",\n        \"content_mapping\": {\n            \"title\": \"Our Revolutionary Solution\",\n            \"content\": \"• 250% increase in efficiency\\n• 98% customer satisfaction\\n• Industry-leading performance\"\n        },\n        \"image_paths\": {\n            \"supporting\": \"path/to/product_image.jpg\"\n        }\n    }\n)\n\n# Generate a complete presentation from multiple templates\nresult = use_mcp_tool(\n    server_name=\"ppt\",\n    tool_name=\"create_presentation_from_templates\",\n    arguments={\n        \"template_sequence\": [\n            {\n                \"template_id\": \"title_slide\",\n                \"content\": {\n                    \"title\": \"2024 Annual Report\",\n                    \"subtitle\": \"Growth and Innovation\",\n                    \"author\": \"Executive Team\"\n                }\n            },\n            {\n                \"template_id\": \"key_metrics_dashboard\",\n                \"content\": {\n                    \"metric_1_value\": \"94%\",\n                    \"metric_2_value\": \"$2.4M\",\n                    \"metric_3_value\": \"247\"\n                }\n            },\n            {\n                \"template_id\": \"before_after_comparison\",\n                \"content\": {\n                    \"content_left\": \"Manual processes taking hours\",\n                    \"content_right\": \"Automated workflows in minutes\"\n                }\n            }\n        ],\n        \"color_scheme\": \"modern_blue\"\n    }\n)\n```\n\n### Enhanced Image Management with v2.0\n\n```python\n# Add image with automatic enhancement - CONSOLIDATED TOOL\nresult = use_mcp_tool(\n    server_name=\"ppt\",\n    tool_name=\"manage_image\",\n    arguments={\n        \"slide_index\": 1,\n        \"operation\": \"add\",\n        \"image_source\": \"company_logo.png\",\n        \"left\": 1.0,\n        \"top\": 1.0,\n        \"width\": 3.0,\n        \"height\": 2.0,\n        \"enhancement_style\": \"presentation\"\n    }\n)\n\n# Apply multiple picture effects at once - CONSOLIDATED TOOL\nresult = use_mcp_tool(\n    server_name=\"ppt\",\n    tool_name=\"apply_picture_effects\",\n    arguments={\n        \"slide_index\": 1,\n        \"shape_index\": 0,\n        \"effects\": {\n            \"shadow\": {\n                \"shadow_type\": \"outer\",\n                \"blur_radius\": 4.0,\n                \"distance\": 3.0,\n                \"direction\": 315.0,\n                \"color\": [128, 128, 128],\n                \"transparency\": 0.6\n            },\n            \"glow\": {\n                \"size\": 5.0,\n                \"color\": [0, 176, 240],\n                \"transparency\": 0.4\n            }\n        }\n    }\n)\n```\n\n### Advanced Text Management with v2.0\n\n```python\n# Add and format text in one operation - CONSOLIDATED TOOL\nresult = use_mcp_tool(\n    server_name=\"ppt\",\n    tool_name=\"manage_text\",\n    arguments={\n        \"slide_index\": 0,\n        \"operation\": \"add\",\n        \"left\": 1.0,\n        \"top\": 2.0,\n        \"width\": 8.0,\n        \"height\": 1.5,\n        \"text\": \"Welcome to Our Quarterly Review\",\n        \"font_size\": 32,\n        \"font_name\": \"Segoe UI\",\n        \"bold\": True,\n        \"color\": [0, 120, 215],\n        \"alignment\": \"center\",\n        \"auto_fit\": True\n    }\n)\n\n# Validate and fix text fit issues - SAME TOOL, DIFFERENT OPERATION\nresult = use_mcp_tool(\n    server_name=\"ppt\",\n    tool_name=\"manage_text\",\n    arguments={\n        \"slide_index\": 0,\n        \"operation\": \"validate\",\n        \"shape_index\": 0,\n        \"validation_only\": False,  # Auto-fix enabled\n        \"min_font_size\": 10,\n        \"max_font_size\": 48\n    }\n)\n```\n\n### Creating a Presentation from Template\n\n```python\n# First, inspect a template to see its layouts and properties\nresult = use_mcp_tool(\n    server_name=\"ppt\",\n    tool_name=\"get_template_info\",\n    arguments={\n        \"template_path\": \"company_template.pptx\"\n    }\n)\ntemplate_info = result\n\n# Create a new presentation from the template\nresult = use_mcp_tool(\n    server_name=\"ppt\",\n    tool_name=\"create_presentation_from_template\",\n    arguments={\n        \"template_path\": \"company_template.pptx\"\n    }\n)\npresentation_id = result[\"presentation_id\"]\n\n# Add a slide using one of the template's layouts\nresult = use_mcp_tool(\n    server_name=\"ppt\",\n    tool_name=\"add_slide\",\n    arguments={\n        \"layout_index\": 1,  # Use layout from template\n        \"title\": \"Quarterly Report\",\n        \"presentation_id\": presentation_id\n    }\n)\n\n# Save the presentation\nresult = use_mcp_tool(\n    server_name=\"ppt\",\n    tool_name=\"save_presentation\",\n    arguments={\n        \"file_path\": \"quarterly_report.pptx\",\n        \"presentation_id\": presentation_id\n    }\n)\n```\n\n### Adding Advanced Charts and Data Visualization\n\n```python\n# Add a chart slide\nresult = use_mcp_tool(\n    server_name=\"ppt\",\n    tool_name=\"add_slide\",\n    arguments={\n        \"layout_index\": 1,  # Content slide layout\n        \"title\": \"Sales Data\",\n        \"presentation_id\": presentation_id\n    }\n)\nslide_index = result[\"slide_index\"]\n\n# Add a column chart with comprehensive customization\nresult = use_mcp_tool(\n    server_name=\"ppt\",\n    tool_name=\"add_chart\",\n    arguments={\n        \"slide_index\": slide_index,\n        \"chart_type\": \"column\",\n        \"left\": 1.0,\n        \"top\": 2.0,\n        \"width\": 8.0,\n        \"height\": 4.5,\n        \"categories\": [\"Q1\", \"Q2\", \"Q3\", \"Q4\"],\n        \"series_names\": [\"2023\", \"2024\"],\n        \"series_values\": [\n            [100, 120, 140, 160],\n            [110, 130, 150, 170]\n        ],\n        \"has_legend\": True,\n        \"legend_position\": \"bottom\",\n        \"has_data_labels\": True,\n        \"title\": \"Quarterly Sales Performance\",\n        \"presentation_id\": presentation_id\n    }\n)\n```\n\n### Text Validation and Optimization with v2.0\n\n```python\n# Validate text fit and get optimization suggestions - USING CONSOLIDATED TOOL\nresult = use_mcp_tool(\n    server_name=\"ppt\",\n    tool_name=\"manage_text\",\n    arguments={\n        \"slide_index\": 0,\n        \"operation\": \"validate\",\n        \"shape_index\": 0,\n        \"text\": \"This is a very long title that might not fit properly in the designated text box area\",\n        \"font_size\": 24,\n        \"validation_only\": True\n    }\n)\n\n# Comprehensive slide validation with automatic fixes - SAME TOOL, AUTO-FIX ENABLED\nresult = use_mcp_tool(\n    server_name=\"ppt\",\n    tool_name=\"manage_text\",\n    arguments={\n        \"slide_index\": 0,\n        \"operation\": \"validate\",\n        \"shape_index\": 0,\n        \"validation_only\": False,  # Auto-fix enabled\n        \"min_font_size\": 10,\n        \"max_font_size\": 48\n    }\n)\n```\n\n### Reading Slide Content with New Text Extraction Tools (v2.1)\n\n```python\n# Extract text content from a specific slide - NEW TOOL\nresult = use_mcp_tool(\n    server_name=\"ppt\",\n    tool_name=\"extract_slide_text\",\n    arguments={\n        \"slide_index\": 0,\n        \"presentation_id\": presentation_id\n    }\n)\n\n# The result includes:\n{\n    \"success\": True,\n    \"slide_index\": 0,\n    \"text_content\": {\n        \"slide_title\": \"Quarterly Business Review\",\n        \"placeholders\": [\n            {\n                \"shape_index\": 1,\n                \"shape_name\": \"Subtitle Placeholder 2\",\n                \"text\": \"Q4 2024 Results\",\n                \"placeholder_type\": \"SUBTITLE\",\n                \"placeholder_idx\": 1\n            }\n        ],\n        \"text_shapes\": [\n            {\n                \"shape_index\": 3,\n                \"shape_name\": \"TextBox 4\",\n                \"text\": \"Revenue increased by 15%\"\n            }\n        ],\n        \"table_text\": [],\n        \"all_text_combined\": \"Quarterly Business Review\\nQ4 2024 Results\\nRevenue increased by 15%\"\n    },\n    \"total_text_shapes\": 2,\n    \"has_title\": True,\n    \"has_tables\": False\n}\n\n# Extract text from all slides in the presentation - NEW TOOL\nresult = use_mcp_tool(\n    server_name=\"ppt\",\n    tool_name=\"extract_presentation_text\",\n    arguments={\n        \"presentation_id\": presentation_id,\n        \"include_slide_info\": True\n    }\n)\n\n# The result includes comprehensive text extraction:\n{\n    \"success\": True,\n    \"presentation_id\": \"pres_123\",\n    \"total_slides\": 5,\n    \"slides_with_text\": 4,\n    \"total_text_shapes\": 12,\n    \"slides_with_titles\": 3,\n    \"slides_with_tables\": 1,\n    \"slides_text\": [...],  # Detailed per-slide text content\n    \"all_presentation_text_combined\": \"=== SLIDE 1 ===\\nTitle Here\\nContent here...\"\n}\n\n# Extract text without additional slide metadata for cleaner output\nresult = use_mcp_tool(\n    server_name=\"ppt\",\n    tool_name=\"extract_presentation_text\",\n    arguments={\n        \"presentation_id\": presentation_id,\n        \"include_slide_info\": False\n    }\n)\n```\n\n## Template Support\n\n### Working with Templates\n\nThe PowerPoint MCP Server provides comprehensive template support for creating presentations from existing template files. This feature enables:\n\n- **Corporate branding** with predefined themes, layouts, and styles\n- **Consistent presentations** across teams and projects  \n- **Custom slide masters** and specialized layouts\n- **Pre-configured properties** and document settings\n- **Flexible template discovery** with configurable search paths\n\n### Template File Requirements\n\n- **Supported formats**: `.pptx` and `.potx` files\n- **Existing content**: Templates can contain existing slides (preserved during creation)\n- **Layout availability**: All custom layouts and slide masters are accessible\n- **Search locations**: Configurable via `PPT_TEMPLATE_PATH` environment variable\n- **Default search paths**: Current directory, `./templates`, `./assets`, `./resources`\n\n### Template Configuration\n\nSet the `PPT_TEMPLATE_PATH` environment variable to specify custom template directories:\n\n```bash\n# Unix/Linux/macOS\nexport PPT_TEMPLATE_PATH=\"/path/to/templates:/another/path\"\n\n# Windows  \nset PPT_TEMPLATE_PATH=\"C:\\templates;C:\\company_templates\"\n```\n\n### Template Workflow\n\n1. **Inspect Template**: Use `get_template_info` to analyze available layouts and properties\n2. **Create from Template**: Use `create_presentation_from_template` with automatic theme preservation\n3. **Use Template Layouts**: Reference layout indices from template analysis when adding slides  \n4. **Maintain Branding**: Template themes, fonts, and colors are automatically applied to new content\n\n### Professional Color Schemes\n\nThe server includes 4 built-in professional color schemes:\n- **Modern Blue**: Microsoft-inspired blue theme with complementary colors\n- **Corporate Gray**: Professional grayscale theme with blue accents\n- **Elegant Green**: Forest green theme with cream and light green accents  \n- **Warm Red**: Deep red theme with orange and yellow accents\n\nEach scheme includes primary, secondary, accent, light, and text colors optimized for business presentations.\n\n## 🎨 Built-in Slide Templates (New in v2.0)\n\nThe PowerPoint MCP Server now includes **25 professional slide templates** with advanced dynamic features. All templates support:\n\n### **Dynamic Features**\n- **Automatic text sizing** based on content length and container dimensions\n- **Intelligent text wrapping** to fit within specified areas\n- **Visual effects** including shadows, glows, and outlines\n- **Gradient backgrounds** with multi-layer compositions\n- **Professional animations** ready for presentation delivery\n- **Interactive hover effects** for enhanced user experience\n- **Smart content overflow handling** with automatic adjustments\n\n### **Available Template Categories**\n\n#### **Title & Introduction Slides**\n- `title_slide` - Dynamic title slide with gradient background and text effects\n- `chapter_intro` - Section divider with chapter numbering and styling\n- `thank_you_slide` - Closing slide with contact information and effects\n\n#### **Content Layout Slides**\n- `text_with_image` - Text content with stylized image and interactive elements\n- `two_column_text` - Two equal columns of text with dynamic sizing\n- `two_column_text_images` - Two columns with text and corresponding images\n- `three_column_layout` - Three equal columns with text and images\n- `full_image_slide` - Large background image with text overlay\n\n#### **Business & Analytics Slides**\n- `key_metrics_dashboard` - Interactive metrics dashboard with animated counters\n- `before_after_comparison` - Dynamic comparison layout with visual dividers\n- `chart_comparison` - Two charts side by side for performance comparison\n- `data_table_slide` - Slide focused on tabular data with professional styling\n- `timeline_slide` - Horizontal timeline with milestones and effects\n\n#### **Process & Flow Slides**\n- `process_flow` - Step-by-step process visualization with enhanced effects\n- `agenda_slide` - Table of contents or agenda overview with styling\n- `quote_testimonial` - Featured quote or customer testimonial with effects\n\n#### **Team & Organization Slides**\n- `team_introduction` - Team member showcase with photos and roles\n\n### **Template Usage Examples**\n\n```python\n# Browse all available templates\ntemplates = use_mcp_tool(\"ppt\", \"list_slide_templates\", {})\n\n# Key templates with their features:\n{\n  \"title_slide\": {\n    \"features\": [\"Dynamic text sizing\", \"Gradient backgrounds\", \"Text effects\"],\n    \"elements\": [\"title\", \"subtitle\", \"author\", \"decorative_accent\"]\n  },\n  \"key_metrics_dashboard\": {\n    \"features\": [\"Animated counters\", \"Gradient containers\", \"Trend visualization\"],\n    \"elements\": [\"3 metric containers\", \"trend chart\", \"insights callout\"]\n  },\n  \"before_after_comparison\": {\n    \"features\": [\"Split gradient background\", \"VS divider\", \"Improvement arrow\"],\n    \"elements\": [\"before/after headers\", \"comparison content\", \"improvement metrics\"]\n  }\n}\n```\n\n### **Color Scheme Integration**\nAll templates work seamlessly with the 4 professional color schemes:\n- **modern_blue**: Microsoft-inspired theme with dynamic gradients\n- **corporate_gray**: Professional grayscale with blue accents\n- **elegant_green**: Forest green with cream and light accents\n- **warm_red**: Deep red with orange and yellow highlights\n\n### **Dynamic Content Adaptation**\nTemplates automatically adjust to content:\n- **Font sizes** scale based on text length (8pt - 44pt range)\n- **Line spacing** adjusts for readability (1.0x - 1.4x)\n- **Text wrapping** intelligently breaks lines at optimal points\n- **Container sizing** adapts to content overflow\n- **Visual effects** scale appropriately with element sizes\n\n## 📁 File Structure\n\n```\nOffice-PowerPoint-MCP-Server/\n├── ppt_mcp_server.py          # Main consolidated server (v2.0)\n├── slide_layout_templates.json # 25+ professional slide templates with dynamic features\n├── tools/                     # 11 specialized tool modules (32 tools total)\n│   ├── __init__.py\n│   ├── presentation_tools.py  # Presentation management (7 tools)\n│   ├── content_tools.py       # Content & slides (6 tools)\n│   ├── template_tools.py      # Template operations (7 tools)\n│   ├── structural_tools.py    # Tables, shapes, charts (4 tools)\n│   ├── professional_tools.py  # Themes, effects, fonts (3 tools)\n│   ├── hyperlink_tools.py     # Hyperlink management (1 tool)\n│   ├── chart_tools.py         # Advanced chart operations (1 tool)\n│   ├── connector_tools.py     # Connector lines/arrows (1 tool)\n│   ├── master_tools.py        # Slide master management (1 tool)\n│   └── transition_tools.py    # Slide transitions (1 tool)\n├── utils/                     # 7 organized utility modules (68+ functions)\n│   ├── __init__.py\n│   ├── core_utils.py          # Error handling & safe operations\n│   ├── presentation_utils.py  # Presentation management utilities\n│   ├── content_utils.py       # Content & slide operations\n│   ├── design_utils.py        # Themes, colors, effects & fonts\n│   ├── template_utils.py      # Template management & dynamic features\n│   └── validation_utils.py    # Text & layout validation\n├── setup_mcp.py              # Interactive setup script\n├── pyproject.toml            # Updated for v2.0\n└── README.md                 # This documentation\n```\n\n## 🏗️ Architecture Benefits\n\n### **Modular Design**\n- **7 focused utility modules** with clear responsibilities\n- **11 organized tool modules** for comprehensive coverage\n- **68+ utility functions** organized by functionality\n- **32 MCP tools** covering all PowerPoint manipulation needs\n- **Clear separation of concerns** for easier development\n\n### **Code Organization**\n- **Logical grouping** of related functionality across modules\n- **Better discoverability** with organized tool categories\n- **Improved testability** with isolated modules\n- **Future extensibility** through modular structure\n\n### **Comprehensive Coverage**\n- **Complete PowerPoint lifecycle** from creation to presentation\n- **Advanced template system** with auto-generation capabilities\n- **Professional design tools** with multiple effects and styling options\n- **Specialized features** including hyperlinks, connectors, and slide masters\n\n### **Developer Experience**\n- **Clear responsibility boundaries** between modules\n- **Easier debugging** with smaller, focused files\n- **Simpler testing** with isolated functionality\n- **Enhanced maintainability** through separation of concerns\n\n## 🔄 What's New in Version 2.0\n\n**Enhanced functionality with comprehensive tool coverage!** The updated server provides:\n\n### **New Specialized Tools Added:**\n- **`manage_hyperlinks`** - Complete hyperlink management for text elements\n- **`update_chart_data`** - Advanced chart data replacement and updating\n- **`add_connector`** - Connector lines and arrows between slide elements\n- **`manage_slide_masters`** - Access to slide master properties and layouts\n- **`manage_slide_transitions`** - Basic slide transition management\n- **`auto_generate_presentation`** - AI-powered presentation generation\n- **`optimize_slide_text`** - Text optimization for better readability\n\n### **Enhanced Existing Tools:**\n- **`manage_text`** - Now supports text run formatting with `format_runs` operation\n- **`create_presentation_from_templates`** - Enhanced template sequence processing\n- **`apply_picture_effects`** - Expanded effect combinations and options\n\n## 🔄 What's New in Version 2.1\n\n**Text extraction capabilities added!** Now you can read content from existing presentations:\n\n### **New Text Extraction Tools Added:**\n- **`extract_slide_text`** - Extract all text content from a specific slide including titles, placeholders, text shapes, and tables\n- **`extract_presentation_text`** - Extract text content from all slides in a presentation with comprehensive statistics and combined output\n\n### **Key Features of Text Extraction:**\n- **Complete text coverage** - Extracts from titles, placeholders, text boxes, and table cells\n- **Structured output** - Organized by content type (titles, placeholders, shapes, tables)\n- **Presentation-wide analysis** - Statistics on text distribution across slides\n- **Flexible output options** - Individual slide content or combined presentation text\n- **Error handling** - Graceful handling of slides that cannot be processed\n\n## License\n\nMIT",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "powerpoint",
        "presentations",
        "presentation",
        "powerpoint mcp",
        "powerpoint presentations",
        "office powerpoint"
      ],
      "category": "document-processing"
    },
    "Hajime-Y--deep-research-mcp": {
      "owner": "Hajime-Y",
      "name": "deep-research-mcp",
      "url": "https://github.com/Hajime-Y/deep-research-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/Hajime-Y.webp",
      "description": "Provides advanced web search capabilities, document analysis, and image processing. Extracts information from various sources including PDFs and YouTube transcripts efficiently.",
      "stars": 12,
      "forks": 1,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-09-06T18:57:01Z",
      "readme_content": "# Deep Research MCP Server\n\nDeep Research is an agent-based tool that provides web search and advanced research capabilities. It leverages HuggingFace's `smolagents` and is implemented as an MCP server.\n\nThis project is based on [HuggingFace's open_deep_research example](https://github.com/huggingface/smolagents/tree/main/examples/open_deep_research).\n\n## Features\n\n- Web search and information gathering\n- PDF and document analysis\n- Image analysis and description\n- YouTube transcript retrieval\n- Archive site search\n\n## Requirements\n\n- Python 3.11 or higher\n- `uv` package manager\n- The following API keys:\n  - OpenAI API key\n  - HuggingFace token\n  - SerpAPI key\n\n## Installation\n\n1. Clone the repository:\n\n```bash\ngit clone https://github.com/Hajime-Y/deep-research-mcp.git\ncd deep-research-mcp\n```\n\n2. Create a virtual environment and install dependencies:\n\n```bash\nuv venv\nsource .venv/bin/activate # For Linux or Mac\n# .venv\\Scripts\\activate # For Windows\nuv sync\n```\n\n## Environment Variables\n\nCreate a `.env` file in the root directory of the project and set the following environment variables:\n\n```\nOPENAI_API_KEY=your_openai_api_key\nHF_TOKEN=your_huggingface_token\nSERPER_API_KEY=your_serper_api_key\n```\n\nYou can obtain a SERPER_API_KEY by signing up at [Serper.dev](https://serper.dev/signup).\n\n## Usage\n\nStart the MCP server:\n\n```bash\nuv run deep_research.py\n```\n\nThis will launch the `deep_research` agent as an MCP server.\n\n## Docker Usage\n\nYou can also run this MCP server in a Docker container:\n\n```bash\n# Build the Docker image\ndocker build -t deep-research-mcp .\n\n# Run with required API keys\ndocker run -p 8080:8080 \\\n  -e OPENAI_API_KEY=your_openai_api_key \\\n  -e HF_TOKEN=your_huggingface_token \\\n  -e SERPER_API_KEY=your_serper_api_key \\\n  deep-research-mcp\n```\n\n### Registering with MCP Clients\n\nTo register this Docker container as an MCP server in different clients:\n\n#### Claude Desktop\n\nAdd the following to your Claude Desktop configuration file (typically located at `~/.config/Claude/claude_desktop_config.json` on Linux, `~/Library/Application Support/Claude/claude_desktop_config.json` on macOS, or `%APPDATA%\\Claude\\claude_desktop_config.json` on Windows):\n\n```json\n{\n  \"mcpServers\": {\n    \"deep-research-mcp\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\", \n        \"-i\", \n        \"--rm\", \n        \"-e\", \"OPENAI_API_KEY=your_openai_api_key\",\n        \"-e\", \"HF_TOKEN=your_huggingface_token\", \n        \"-e\", \"SERPER_API_KEY=your_serper_api_key\",\n        \"deep-research-mcp\"\n      ]\n    }\n  }\n}\n```\n\n#### Cursor IDE\n\nFor Cursor IDE, add the following configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"deep-research-mcp\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\", \n        \"-i\", \n        \"--rm\", \n        \"-e\", \"OPENAI_API_KEY=your_openai_api_key\",\n        \"-e\", \"HF_TOKEN=your_huggingface_token\", \n        \"-e\", \"SERPER_API_KEY=your_serper_api_key\",\n        \"deep-research-mcp\"\n      ]\n    }\n  }\n}\n```\n\n#### Using with Remote MCP Server\n\nIf you're running the MCP server on a remote machine or exposing it as a service, you can use the URL-based configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"deep-research-mcp\": {\n      \"url\": \"http://your-server-address:8080/mcp\",\n      \"type\": \"sse\"\n    }\n  }\n}\n```\n\n## Key Components\n\n- `deep_research.py`: Entry point for the MCP server\n- `create_agent.py`: Agent creation and configuration\n- `scripts/`: Various tools and utilities\n  - `text_web_browser.py`: Text-based web browser\n  - `text_inspector_tool.py`: File inspection tool\n  - `visual_qa.py`: Image analysis tool\n  - `mdconvert.py`: Converts various file formats to Markdown\n\n## License\n\nThis project is provided under the Apache License 2.0.\n\n## Acknowledgements\n\nThis project uses code from HuggingFace's `smolagents` and Microsoft's `autogen` projects.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcp",
        "document",
        "hajime",
        "processing hajime",
        "document processing",
        "research mcp"
      ],
      "category": "document-processing"
    },
    "Handwriting-OCR--handwriting-ocr-mcp-server": {
      "owner": "Handwriting-OCR",
      "name": "handwriting-ocr-mcp-server",
      "url": "https://github.com/Handwriting-OCR/handwriting-ocr-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/Handwriting-OCR.webp",
      "description": "Integrate applications with the Handwriting OCR service to process images and PDF documents for text extraction. Upload documents, check processing status, and retrieve OCR results in Markdown format.",
      "stars": 11,
      "forks": 4,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-10-01T06:46:15Z",
      "readme_content": "# Handwriting OCR MCP Server\n[![smithery badge](https://smithery.ai/badge/@Handwriting-OCR/handwriting-ocr-mcp-server)](https://smithery.ai/server/@Handwriting-OCR/handwriting-ocr-mcp-server)\n\nA Model Context Protocol (MCP) Server for [Handwriting OCR](https://www.handwritingocr.com) API.\n\n## Overview\n\nThe Handwriting OCR MCP Server enables integration between MCP clients and the Handwriting OCR service. This document outlines the setup process and provides a basic example of using the client.\n\nThis server allows you to upload images and PDF documents, check their status, and retrieve the OCR result as Markdown.\n\n## Tools\n\n### Transcription\n\n*   Upload Document\n*   Check Status\n*   Get Text\n\n## Prerequisites\n\nBefore you begin, ensure you have the following:\n\n*   Node.js installed on your system (recommended version 18.x or higher).\n*   An active account on the [Handwriting OCR Platform](https://www.handwritingocr.com) and an active [API token](https://www.handwritingocr.com/settings/api).\n\n## Installation\n\n### Installing via Smithery\n\nTo install handwriting-ocr-mcp-server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@Handwriting-OCR/handwriting-ocr-mcp-server):\n\n```bash\nnpx -y @smithery/cli install @Handwriting-OCR/handwriting-ocr-mcp-server --client claude\n```\n\n### Installing manually for Claude Desktop\n\nTo use the Handwriting OCR MCP Server in Claude Desktop application, use:\n\n```json\n{\n    \"mcpServers\": {\n        \"handwriting-ocr\": {\n            \"command\": \"node\",\n            \"args\": [\n                \"/Users/mateo/Local/Code/MCP/handwriting-ocr/build/index.js\"\n            ],\n            \"env\": {\n                \"API_TOKEN\": \"your-api-token\",\n            },\n            \"disabled\": false,\n            \"autoApprove\": []\n        }\n    }\n}\n```\n\n## Configuration\n\nThe Handwriting OCR MCP Server supports environment variables to be set for authentication and configuration:\n\n*   `API_TOKEN`: Your API token.\n\nYou can find these values in the API settings dashboard on the [Handwriting OCR Platform](https://www.handwritingocr.com).\n\n## Support\n\nPlease refer to the [Handwriting OCR API Documentation](https://www.handwritingocr.com/api/docs).\n\nFor support with the Handwriting OCR MCP Server, please submit a [GitHub Issue](https://github.com/modelcontextprotocol/servers/issues).\n\n## About\n\nModel Context Protocol (MCP) Server for Handwriting OCR Platform\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ocr",
        "handwriting",
        "processing",
        "ocr mcp",
        "handwriting ocr",
        "ocr service"
      ],
      "category": "document-processing"
    },
    "HenryHaoson--Yuque-MCP-Server": {
      "owner": "HenryHaoson",
      "name": "Yuque-MCP-Server",
      "url": "https://github.com/HenryHaoson/Yuque-MCP-Server",
      "imageUrl": "/freedevtools/mcp/pfp/HenryHaoson.webp",
      "description": "Integrate with the Yuque API for managing documents and user information. Supports creating, reading, updating, and deleting documents while providing access to analytics and statistics for knowledge bases.",
      "stars": 25,
      "forks": 12,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-09-23T06:26:56Z",
      "readme_content": "# GitHub Actions 工作流使用说明\n\n## 工作流概述\n\n本仓库配置了以下 GitHub Actions 工作流：\n\n1. **版本更新 (version-bump)**: 用于自动更新 npm 包版本号\n2. **NPM 包发布 (npm-publish)**: 用于自动构建并发布 npm 包到 npmjs.com\n\n## 使用方法\n\n### 版本更新工作流\n\n此工作流允许你通过 GitHub 界面手动触发版本更新：\n\n1. 进入仓库的 \"Actions\" 选项卡\n2. 选择 \"版本更新\" 工作流\n3. 点击 \"Run workflow\" 按钮\n4. 选择版本更新类型（patch、minor 或 major）\n5. 点击 \"Run workflow\" 确认\n\n工作流将自动：\n- 更新 package.json 中的版本号\n- 创建对应的 Git 标签\n- 提交并推送所有更改\n\n### NPM 包发布工作流\n\n此工作流在以下情况下自动触发：\n\n1. 当创建新的 GitHub Release 时\n2. 手动触发时\n\n要手动触发发布流程：\n1. 进入仓库的 \"Actions\" 选项卡\n2. 选择 \"发布 NPM 包\" 工作流\n3. 点击 \"Run workflow\" 按钮\n4. 点击 \"Run workflow\" 确认\n\n## 配置 npm 发布令牌\n\n要使 NPM 发布工作流正常工作，需要在 GitHub 仓库中配置 NPM 令牌：\n\n1. 在 npm 网站上生成访问令牌 (https://www.npmjs.com/settings/[用户名]/tokens)\n2. 在 GitHub 仓库中，进入 \"Settings\" > \"Secrets and variables\" > \"Actions\"\n3. 点击 \"New repository secret\"\n4. 名称填写 `NPM_TOKEN`，值填写你的 npm 访问令牌\n5. 点击 \"Add secret\" 保存 ",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "yuque",
        "documents",
        "document",
        "yuque api",
        "integrate yuque",
        "document processing"
      ],
      "category": "document-processing"
    },
    "HireTechUpUp--mcp-server-novacv": {
      "owner": "HireTechUpUp",
      "name": "mcp-server-novacv",
      "url": "https://github.com/HireTechUpUp/mcp-server-novacv",
      "imageUrl": "/freedevtools/mcp/pfp/HireTechUpUp.webp",
      "description": "Connect to the NovaCV API for generating professional resumes, analyzing resume content, and converting resume text into structured formats like JSON. It provides features for creating tailored resumes in PDF format and accessing available template options.",
      "stars": 3,
      "forks": 2,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-06-11T08:22:18Z",
      "readme_content": "# MCP Server for NovaCV\n\n模型上下文协议(MCP)服务器，用于接入 NovaCV 简历服务 API。\n\n## 功能特点\n\n- 生成简历 PDF\n- 获取可用简历模板列表\n- 将简历文本转换为 JSON Resume 格式\n- 分析简历文本内容\n\n## 获取 API 密钥\n\n在使用此服务前，您需要获取 NovaCV API 密钥：\n\n1. 访问 [NovaCV API 官网](https://api.nova-cv.com)\n2. 注册或登录您的账户\n3. 在控制面板中找到 \"API Keys\" 或 \"开发者\" 部分\n4. 创建新的 API 密钥并复制它\n5. 在使用 MCP 服务时配置此密钥\n\n请妥善保管您的 API 密钥，不要在公共场合分享。\n\n## 安装\n\n```bash\n# 全局安装\nnpm install -g mcp-server-novacv\n\n# 或使用 npx 运行\nnpx mcp-server-novacv --api_key=your_api_key\n```\n\n## 快速开始\n\n### 方法一：直接运行（推荐）\n\n最简单的方式是使用我们提供的快速启动命令：\n\n```bash\n# 一键构建并启动服务\nnpm run run\n```\n\n### 方法二：使用 MCP Inspector 进行开发和测试\n\n我们提供了一个组合命令，可以一键构建和启动 Inspector：\n\n```bash\n# 一键构建并启动 Inspector\nnpm run debug\n```\n\n## 使用方法\n\n### 命令行选项\n\n```bash\nnpx mcp-server-novacv [选项]\n\n选项:\n  --api_key=KEY        设置 NovaCV API 密钥\n  --api_base_url=URL   设置 API 基础 URL\n  --timeout=MS         设置 API 超时时间 (毫秒)\n  --help, -h           显示帮助信息\n  --version, -v        显示版本信息\n```\n\n### 环境变量配置\n\n可以通过环境变量配置 API 密钥：\n\n```bash\nNOVACV_API_KEY=your_api_key mcp-server-novacv\n```\n\n或者创建 `.env` 文件：\n\n```\nNOVACV_API_KEY=your_api_key\nNOVACV_API_BASE_URL=https://api.nova-cv.com\n```\n\n> **提示**：API 密钥可以从 [NovaCV API 官网](https://api.nova-cv.com) 获取，请参考上方的 \"获取 API 密钥\" 部分。\n\n### 在 MCP 客户端配置\n\n#### Cursor 配置\n\n在 Cursor 配置文件中添加:\n\n```json\n{\n  \"mcpServers\": {\n    \"novacv\": {\n      \"command\": \"npx\",\n      \"args\": [\"mcp-server-novacv\"],\n      \"env\": {\n        \"NOVACV_API_KEY\": \"your_api_key\"\n      }\n    }\n  }\n}\n```\n\n#### Cherry Studio 配置\n\n在 Cherry Studio 中设置 MCP 服务:\n\n1. 打开设置（点击左下角设置图标或使用 `Ctrl+,`/`Cmd+,`）\n2. 找到 MCP 或 Model Context Protocol 设置区域\n3. 添加新服务，配置如下:\n   - 名称: `novacv`\n   - 命令: `npx`\n   - 参数: `mcp-server-novacv`\n   - 环境变量: 添加 `NOVACV_API_KEY` 并设置您的 API 密钥\n\n如果支持 JSON 配置，添加以下内容:\n\n```json\n{\n  \"novacv\": {\n    \"command\": \"npx\",\n    \"args\": [\"mcp-server-novacv\"],\n    \"env\": {\n      \"NOVACV_API_KEY\": \"your_api_key\"\n    }\n  }\n}\n```\n\n## 可用工具\n\nMCP 服务器提供以下工具：\n\n- `generate_resume_from_text`: 一键将简历文本转换为精美PDF简历，支持多种模板。只需提供简历文本内容，系统会自动进行格式转换并生成专业PDF文件，无需手动处理JSON数据\n- `get_templates`: 获取所有可用的简历模板，返回模板列表及其详细信息，包括模板ID、名称、缩略图等\n- `convert_resume_text`: 将纯文本格式的简历内容转换为标准JSON Resume格式。系统会智能识别简历中的各个部分，并按照国际通用的JSON Resume标准进行结构化处理\n- `analyze_resume_text`: 对简历文本进行深度分析，提供专业评估和改进建议。系统会分析简历的完整性、关键词使用、技能匹配度等方面，并给出针对性的优化建议\n\n## 使用示例\n\n### 获取模板列表\n\n在支持 MCP 的客户端中使用 `mcp_novacv_get_templates` 命令获取所有可用的简历模板。\n\n### 生成简历\n\n使用 `mcp_novacv_generate_resume_from_text` 命令并提供简历文本内容和模板名称生成 PDF 简历。\n\n### 分析简历文本\n\n使用 `mcp_novacv_analyze_resume_text` 命令分析纯文本简历内容。\n\n### 转换简历文本为 JSON Resume\n\n使用 `mcp_novacv_convert_resume_text` 命令将简历文本转换为结构化的 JSON Resume 格式。\n\n## 开发\n\n```bash\n# 安装依赖\nnpm install\n\n# 开发模式（监视文件变化）\nnpm run dev\n\n# 构建项目\nnpm run build\n\n# 运行服务（构建并启动）\nnpm run run\n\n# 使用 MCP Inspector 调试（构建并启动Inspector）\nnpm run debug\n```\n\n## 故障排除\n\n如果您在设置过程中遇到问题:\n\n1. 确认包安装成功: `npx mcp-server-novacv --version`\n2. 检查 API 密钥是否正确设置\n3. 查看客户端日志中是否有相关错误信息\n\n### API 密钥问题\n\n如果遇到 API 密钥相关错误：\n\n- 确保您已从 [https://api.nova-cv.com](https://api.nova-cv.com) 获取了有效的 API 密钥\n- 检查密钥是否已过期或超出使用限制\n- 尝试重新生成新的 API 密钥\n- 确保环境变量或配置文件中的密钥没有多余的空格或引号\n\n## 许可证\n\nMIT \n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "resumes",
        "novacv",
        "resume",
        "novacv api",
        "server novacv",
        "resumes pdf"
      ],
      "category": "document-processing"
    },
    "JDJR2024--markdownify-mcp-utf8": {
      "owner": "JDJR2024",
      "name": "markdownify-mcp-utf8",
      "url": "https://github.com/JDJR2024/markdownify-mcp-utf8",
      "imageUrl": "/freedevtools/mcp/pfp/JDJR2024.webp",
      "description": "Converts various file types to Markdown format, with robust support for UTF-8 encoding and optimized for multilingual content handling. Ensures accurate transformation of documents and web pages while addressing encoding issues, especially on Windows systems.",
      "stars": 10,
      "forks": 5,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-08T17:20:52Z",
      "readme_content": "# Markdownify MCP Server - UTF-8 Enhanced\n\nThis is an enhanced version of the [original Markdownify MCP project](https://github.com/cursor-ai/markdownify-mcp), with improved UTF-8 encoding support and optimized handling of multilingual content.\n\n[中文文档](README-CN.md)\n\n## Enhancements\n\n- Added comprehensive UTF-8 encoding support\n- Optimized handling of multilingual content\n- Fixed encoding issues on Windows systems\n- Improved error handling mechanisms\n\n## Key Differences from Original Project\n\n1. Enhanced Encoding Support:\n   - Full UTF-8 support across all operations\n   - Proper handling of Chinese, Japanese, Korean and other non-ASCII characters\n   - Fixed Windows-specific encoding issues (cmd.exe and PowerShell compatibility)\n\n2. Improved Error Handling:\n   - Detailed error messages in both English and Chinese\n   - Better exception handling for network issues\n   - Graceful fallback mechanisms for conversion failures\n\n3. Extended Functionality:\n   - Added support for batch processing multiple files\n   - Enhanced YouTube video transcript handling\n   - Improved metadata extraction from various file formats\n   - Better preservation of document formatting\n\n4. Performance Optimizations:\n   - Optimized memory usage for large file conversions\n   - Faster processing of multilingual content\n   - Reduced dependency conflicts\n\n5. Better Development Experience:\n   - Comprehensive debugging options\n   - Detailed logging system\n   - Environment-specific configuration support\n   - Clear documentation in both English and Chinese\n\n## Features\n\nSupports converting various file types to Markdown:\n- PDF files\n- Images (with metadata)\n- Audio (with transcription)\n- Word documents (DOCX)\n- Excel spreadsheets (XLSX)\n- PowerPoint presentations (PPTX)\n- Web content:\n  - YouTube video transcripts\n  - Search results\n  - General web pages\n- Existing Markdown files\n\n## Quick Start\n\n1. Clone this repository:\n   ```bash\n   git clone https://github.com/JDJR2024/markdownify-mcp-utf8.git\n   cd markdownify-mcp-utf8\n   ```\n\n2. Install dependencies:\n   ```bash\n   pnpm install\n   ```\n   Note: This will also install `uv` and related Python dependencies.\n\n3. Build the project:\n   ```bash\n   pnpm run build\n   ```\n\n4. Start the server:\n   ```bash\n   pnpm start\n   ```\n\n## Requirements\n\n- Node.js 16.0 or higher\n- Python 3.8 or higher\n- pnpm package manager\n- Git\n\n## Detailed Installation Guide\n\n### 1. Environment Setup\n\n1. Install Node.js:\n   - Download from [Node.js official website](https://nodejs.org/)\n   - Verify installation: `node --version`\n\n2. Install pnpm:\n   ```bash\n   npm install -g pnpm\n   pnpm --version\n   ```\n\n3. Install Python:\n   - Download from [Python official website](https://www.python.org/downloads/)\n   - Ensure Python is added to PATH during installation\n   - Verify installation: `python --version`\n\n4. (Windows Only) Configure UTF-8 Support:\n   ```bash\n   # Set system-wide UTF-8\n   setx PYTHONIOENCODING UTF-8\n   # Set current session UTF-8\n   set PYTHONIOENCODING=UTF-8\n   # Enable UTF-8 in command prompt\n   chcp 65001\n   ```\n\n### 2. Project Setup\n\n1. Clone the repository:\n   ```bash\n   git clone https://github.com/JDJR2024/markdownify-mcp-utf8.git\n   cd markdownify-mcp-utf8\n   ```\n\n2. Create and activate Python virtual environment:\n   ```bash\n   # Windows\n   python -m venv .venv\n   .venv\\Scripts\\activate\n\n   # Linux/macOS\n   python3 -m venv .venv\n   source .venv/bin/activate\n   ```\n\n3. Install project dependencies:\n   ```bash\n   # Install Node.js dependencies\n   pnpm install\n\n   # Install Python dependencies (will be handled by setup.sh)\n   ./setup.sh\n   ```\n\n4. Build the project:\n   ```bash\n   pnpm run build\n   ```\n\n### 3. Verification\n\n1. Start the server:\n   ```bash\n   pnpm start\n   ```\n\n2. Test the installation:\n   ```bash\n   # Convert a web page\n   python convert_utf8.py \"https://example.com\"\n\n   # Convert a local file\n   python convert_utf8.py \"path/to/your/file.docx\"\n   ```\n\n## Usage Guide\n\n### Basic Usage\n\n1. Converting Web Pages:\n   ```bash\n   python convert_utf8.py \"https://example.com\"\n   ```\n   The converted markdown will be saved as `converted_result.md`\n\n2. Converting Local Files:\n   ```bash\n   # Convert DOCX\n   python convert_utf8.py \"document.docx\"\n\n   # Convert PDF\n   python convert_utf8.py \"document.pdf\"\n\n   # Convert PowerPoint\n   python convert_utf8.py \"presentation.pptx\"\n\n   # Convert Excel\n   python convert_utf8.py \"spreadsheet.xlsx\"\n   ```\n\n3. Converting YouTube Videos:\n   ```bash\n   python convert_utf8.py \"https://www.youtube.com/watch?v=VIDEO_ID\"\n   ```\n\n### Advanced Usage\n\n1. Environment Variables:\n   ```bash\n   # Set custom UV path\n   export UV_PATH=\"/custom/path/to/uv\"\n\n   # Set custom output directory\n   export MARKDOWN_OUTPUT_DIR=\"/custom/output/path\"\n   ```\n\n2. Batch Processing:\n   Create a batch file (e.g., `convert_batch.txt`) with URLs or file paths:\n   ```text\n   https://example1.com\n   https://example2.com\n   file1.docx\n   file2.pdf\n   ```\n   Then run:\n   ```bash\n   while read -r line; do python convert_utf8.py \"$line\"; done < convert_batch.txt\n   ```\n\n### Troubleshooting\n\n1. Common Issues:\n   - If you see encoding errors, ensure UTF-8 is properly set\n   - For permission issues on Windows, run as Administrator\n   - For Python path issues, ensure virtual environment is activated\n\n2. Debugging:\n   ```bash\n   # Enable debug output\n   export DEBUG=true\n   python convert_utf8.py \"your_file.docx\"\n   ```\n\n## Usage\n\n### Command Line\n\nConvert web page to Markdown:\n```bash\npython convert_utf8.py \"https://example.com\"\n```\n\nConvert local file:\n```bash\npython convert_utf8.py \"path/to/your/file.docx\"\n```\n\n### Desktop App Integration\n\nTo integrate this server with a desktop app, add the following to your app's server configuration:\n\n```js\n{\n  \"mcpServers\": {\n    \"markdownify\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"{ABSOLUTE_PATH}/dist/index.js\"\n      ],\n      \"env\": {\n        \"UV_PATH\": \"/path/to/uv\"\n      }\n    }\n  }\n}\n```\n\n## Troubleshooting\n\n1. Encoding Issues\n   - If you encounter character encoding issues, ensure the `PYTHONIOENCODING` environment variable is set to `utf-8`\n   - Windows users may need to run `chcp 65001` to enable UTF-8 support\n\n2. Permission Issues\n   - Ensure you have sufficient file read/write permissions\n   - On Windows, you may need to run as administrator\n\n## Acknowledgments\n\nThis project is based on the original work by Zach Caceres. Thanks to the original author for their outstanding contribution.\n\n## License\n\nThis project continues to be licensed under the MIT License. See the [LICENSE](LICENSE) file for details.\n\n## Contributing\n\nContributions are welcome! Before submitting a Pull Request, please:\n1. Ensure your code follows the project's coding standards\n2. Add necessary tests and documentation\n3. Update relevant sections in the README\n\n## Contact\n\nFor issues or suggestions:\n1. Submit an Issue: https://github.com/JDJR2024/markdownify-mcp-utf8/issues\n2. Create a Pull Request: https://github.com/JDJR2024/markdownify-mcp-utf8/pulls\n3. Email: jdidndosmmxmx@gmail.com ",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "markdownify",
        "markdown",
        "jdjr2024",
        "jdjr2024 markdownify",
        "markdown format",
        "markdownify mcp"
      ],
      "category": "document-processing"
    },
    "JackKuo666--semanticscholar-MCP-Server": {
      "owner": "JackKuo666",
      "name": "semanticscholar-MCP-Server",
      "url": "https://github.com/JackKuo666/semanticscholar-MCP-Server",
      "imageUrl": "/freedevtools/mcp/pfp/JackKuo666.webp",
      "description": "Search for academic papers, retrieve detailed information about specific papers and authors, and access citations and references through the Semantic Scholar API.",
      "stars": 29,
      "forks": 6,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-09-26T19:47:33Z",
      "readme_content": "# 🎓 Semantic Scholar MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@JackKuo666/semanticscholar-mcp-server)](https://smithery.ai/server/@JackKuo666/semanticscholar-mcp-server)\n\nThis project implements a Model Context Protocol (MCP) server for interacting with the Semantic Scholar API. It provides tools for searching papers, retrieving paper and author details, and fetching citations and references.\n\n## ✨ Features\n\n- 🔍 Search for papers on Semantic Scholar\n- 📄 Retrieve detailed information about specific papers\n- 👤 Get author details\n- 🔗 Fetch citations and references for a paper\n\n## 📋 Prerequisites\n\n- 🐍 Python 3.10+\n- 📚 `semanticscholar` Python package\n- 🔧 `mcp` Python package (Model Context Protocol)\n\n## 🚀 Installation\n### Installing via Smithery\n\nTo install semanticscholar Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@JackKuo666/semanticscholar-mcp-server):\n\n#### claude\n\n```sh\nnpx -y @smithery/cli@latest install @JackKuo666/semanticscholar-mcp-server --client claude --config \"{}\"\n```\n\n#### Cursor\n\nPaste the following into Settings → Cursor Settings → MCP → Add new server: \n- Mac/Linux  \n```s\nnpx -y @smithery/cli@latest run @JackKuo666/semanticscholar-mcp-server --client cursor --config \"{}\" \n```\n#### Windsurf\n```sh\nnpx -y @smithery/cli@latest install @JackKuo666/semanticscholar-mcp-server --client windsurf --config \"{}\"\n```\n### CLine\n```sh\nnpx -y @smithery/cli@latest install @JackKuo666/semanticscholar-mcp-server --client cline --config \"{}\"\n```\n\n\n1. Clone this repository:\n   ```\n   git clone https://github.com/JackKuo666/semanticscholar-MCP-Server.git\n   cd semanticscholar-mcp-server\n   ```\n\n2. Install the required packages:\n   ```\n   pip install semanticscholar mcp\n   ```\n\n## 🖥️ Usage\n\n1. Start the Semantic Scholar MCP server:\n   ```\n   python semantic_scholar_server.py\n   ```\n\n2. The server will start and listen for MCP requests.\n\n3. Use an MCP client to interact with the server and access the following tools:\n\n   - 🔍 `search_semantic_scholar`: Search for papers using a query string\n   - 📄 `get_semantic_scholar_paper_details`: Get details of a specific paper\n   - 👤 `get_semantic_scholar_author_details`: Get details of a specific author\n   - 🔗 `get_semantic_scholar_citations_and_references`: Get citations and references for a paper\n\n## Usage with Claude Desktop\n\nAdd this configuration to your `claude_desktop_config.json`:\n\n(Mac OS)\n\n```json\n{\n  \"mcpServers\": {\n    \"semanticscholar\": {\n      \"command\": \"python\",\n      \"args\": [\"-m\", \"semanticscholar_mcp_server\"]\n      }\n  }\n}\n```\n\n(Windows version):\n\n```json\n{\n  \"mcpServers\": {\n    \"semanticscholar\": {\n      \"command\": \"C:\\\\Users\\\\YOUR\\\\PATH\\\\miniconda3\\\\envs\\\\mcp_server\\\\python.exe\",\n      \"args\": [\n        \"D:\\\\code\\\\YOUR\\\\PATH\\\\semanticscholar-MCP-Server\\\\semanticscholar_server.py\"\n      ],\n      \"env\": {},\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\nUsing with Cline\n```json\n{\n  \"mcpServers\": {\n    \"semanticscholar\": {\n      \"command\": \"bash\",\n      \"args\": [\n        \"-c\",\n        \"source /home/YOUR/PATH/.venv/bin/activate && python /home/YOUR/PATH/semanticscholar_mcp_server.py\"\n      ],\n      \"env\": {},\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\n## 📁 File Structure\n\n- 📜 `semantic_scholar_search.py`: Contains functions for interacting with the Semantic Scholar API\n- 🖥️ `semantic_scholar_server.py`: Implements the MCP server and defines the available tools\n\n## 🤝 Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## 📄 License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "scholar",
        "citations",
        "semantic",
        "semantic scholar",
        "scholar api",
        "search academic"
      ],
      "category": "document-processing"
    },
    "JayZeeDesign--figma-mcp": {
      "owner": "JayZeeDesign",
      "name": "figma-mcp",
      "url": "https://github.com/JayZeeDesign/figma-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/JayZeeDesign.webp",
      "description": "Facilitates access to Figma files and prototypes, enabling integration of design assets directly into AI coding environments. Streamlines design workflows by connecting AI agents with Figma's design resources.",
      "stars": 61,
      "forks": 17,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-08-18T11:25:43Z",
      "readme_content": "# Figma MCP Python\n\n[![PyPI version](https://badge.fury.io/py/figma-mcp.svg)](https://badge.fury.io/py/figma-mcp)\n\nAllow your AI coding agents to access Figma files & prototypes directly.\nYou can DM me for any issues / improvements: https://x.com/jasonzhou1993\n\n<a href=\"https://glama.ai/mcp/servers/pqweyr4aq9\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/pqweyr4aq9/badge\" alt=\"figma-mcp MCP server\" />\n</a>\n\n## Quick Installation with pipx\n\n```bash\npipx install figma-mcp\n```\n\n### For Cursor:\n\n1. In settings, add an MCP server using the command:\n```shell\nfigma-mcp --figma-api-key=your_figma_key\n```\n\n2. OR Add a `.cursor/mcp.json` file in your project:\n\n```json\n{\n  \"mcpServers\": {\n    \"figma-python\": {\n      \"command\": \"figma-mcp\",\n      \"args\": [\n        \"--figma-api-key=your_figma_key\"\n      ]\n    } \n  }\n}\n```\n\n\n### For other IDEs like Windsurf, use an MCP configuration file (e.g., `mcp_config.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"figma-python\": {\n      \"command\": \"figma-mcp\",\n      \"args\": [\n        \"--figma-api-key=your_figma_key\"\n      ]\n    } \n  }\n}\n```\n\n\n## Install uv and set up the environment\n```bash\ncurl -LsSf https://astral.sh/uv/install.sh | sh\nuv venv\nsource .venv/bin/activate\nuv sync\n```\n\n## Test locally\n```bash\npython -m figma_mcp.main\n```",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "prototypes",
        "ai",
        "figma",
        "figma design",
        "files prototypes",
        "figma files"
      ],
      "category": "document-processing"
    },
    "JoeBuildsStuff--mcp-jina-ai": {
      "owner": "JoeBuildsStuff",
      "name": "mcp-jina-ai",
      "url": "https://github.com/JoeBuildsStuff/mcp-jina-ai",
      "imageUrl": "/freedevtools/mcp/pfp/JoeBuildsStuff.webp",
      "description": "Access Jina AI's web services for web page reading, web search, and fact checking. Extract and format content from web pages for use with LLMs.",
      "stars": 30,
      "forks": 8,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-10-03T04:12:28Z",
      "readme_content": "# Jina AI MCP Server\n[![smithery badge](https://smithery.ai/badge/jina-ai-mcp-server)](https://smithery.ai/server/jina-ai-mcp)\n[![smithery badge](https://smithery.ai/badge/jina-ai-mcp-server)](https://smithery.ai/server/jina-ai-mcp-server)\n\nAn MCP server that provides access to Jina AI's powerful web services through Claude. This server implements three main tools:\n\n- Web page reading and content extraction\n- Web search\n- Fact checking/grounding\n\n<a href=\"https://glama.ai/mcp/servers/c1l6ib2j49\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/c1l6ib2j49/badge\" alt=\"mcp-jina-ai MCP server\" /></a>\n\n## Features\n\n### Tools\n\n#### `read_webpage`\n- Extract content from web pages in a format optimized for LLMs\n- Supports multiple output formats (Default, Markdown, HTML, Text, Screenshot, Pageshot)\n- Options for including links and images\n- Ability to generate alt text for images\n- Cache control options\n\n#### `search_web`\n- Search the web using Jina AI's search API\n- Configurable number of results (default: 5)\n- Support for image retention and alt text generation\n- Multiple return formats (markdown, text, html)\n- Returns structured results with titles, descriptions, and content\n\n#### `fact_check`\n- Fact-check statements using Jina AI's grounding engine\n- Provides factuality scores and supporting evidence \n- Optional deep-dive mode for more thorough analysis\n- Returns references with key quotes and supportive/contradictory classification\n\n## Setup\n\n### Prerequisites\n\nYou'll need a Jina AI API key to use this server. Get one for free at https://jina.ai/\n\n### Installation\n\nThere are two ways to use this server:\n\n#### Installing via Smithery\n\nTo install Jina AI for Claude Desktop automatically via [Smithery](https://smithery.ai/server/jina-ai-mcp-server):\n\n```bash\nnpx -y @smithery/cli install jina-ai-mcp-server --client claude\n```\n\n#### Option 1: NPX (Recommended)\nAdd this configuration to your Claude Desktop config file:\n\n```json\n{\n  \"mcpServers\": {\n    \"jina-ai-mcp-server\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"jina-ai-mcp-server\"\n      ],\n      \"env\": {\n        \"JINA_API_KEY\": \"<YOUR_KEY>\"\n      }\n    }\n  }\n}\n```\n\n#### Option 2: Local Installation\n1. Clone the repository\n2. Install dependencies:\n```bash\nnpm install\n```\n\n3. Build the server:\n```bash\nnpm run build\n```\n\n4. Add this configuration to your Claude Desktop config:\n```json\n{\n  \"mcpServers\": {\n    \"jina-ai-mcp-server\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/path/to/jina-ai-mcp-server/dist/index.js\"\n      ],\n      \"env\": {\n        \"JINA_API_KEY\": \"<YOUR_KEY>\"\n      }\n    }\n  }\n}\n```\n\n### Config File Location\n\nOn MacOS:\n```bash\n~/Library/Application Support/Claude/claude_desktop_config.json\n```\n\nOn Windows:\n```bash\n%APPDATA%/Claude/claude_desktop_config.json\n```\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector):\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n\n## API Response Types\n\nAll tools return structured JSON responses that include:\n\n- Status codes and metadata\n- Formatted content based on the requested output type\n- Usage information (token counts)\n- When applicable: images, links, and additional metadata\n\nFor detailed schema information, see `schemas.ts`.\n\n\n## Running evals\n\nThe evals package loads an mcp client that then runs the index.ts file, so there is no need to rebuild between tests. You can load environment variables by prefixing the npx command. Full documentation can be found [here](https://www.mcpevals.io/docs).\n\n```bash\nOPENAI_API_KEY=your-key  npx mcp-eval evals.ts index.ts\n```",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "web",
        "jina",
        "pages",
        "mcp jina",
        "ai web",
        "access jina"
      ],
      "category": "document-processing"
    },
    "JustasMonkev--mcp-accessibility-scanner": {
      "owner": "JustasMonkev",
      "name": "mcp-accessibility-scanner",
      "url": "https://github.com/JustasMonkev/mcp-accessibility-scanner",
      "imageUrl": "/freedevtools/mcp/pfp/JustasMonkev.webp",
      "description": "Automated web accessibility scanning using Playwright and Axe-core, enabling WCAG compliance checks and annotated screenshot capture. Generates detailed accessibility reports and interacts with web pages through browser automation.",
      "stars": 18,
      "forks": 5,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T11:01:21Z",
      "readme_content": "\n# MCP Accessibility Scanner 🔍\n\n[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/justasmonkev-mcp-accessibility-scanner-badge.png)](https://mseep.ai/app/justasmonkev-mcp-accessibility-scanner)\n\nA Model Context Protocol (MCP) server that provides automated web accessibility scanning using Playwright and Axe-core. This server enables LLMs to perform WCAG compliance checks, capture annotated screenshots, and generate detailed accessibility reports.\nA powerful Model Context Protocol (MCP) server that provides automated web accessibility scanning and browser automation using Playwright and Axe-core. This server enables LLMs to perform WCAG compliance checks, interact with web pages, manage persistent browser sessions, and generate detailed accessibility reports with visual annotations.\n\n## Features\n\n### Accessibility Scanning\n✅ Full WCAG 2.0/2.1/2.2 compliance checking (A, AA, AAA levels)  \n🖼️ Automatic screenshot capture with violation highlighting  \n📄 Detailed JSON reports with remediation guidance  \n🎯 Support for specific violation categories (color contrast, ARIA, forms, keyboard navigation, etc.)  \n\n### Browser Automation\n🖱️ Click, hover, and drag elements using accessibility snapshots  \n⌨️ Type text and handle keyboard inputs  \n🔍 Capture page snapshots to discover all interactive elements  \n📸 Take screenshots and save PDFs  \n🎯 Support for both element-based and coordinate-based interactions  \n\n### Advanced Features\n📑 Tab management for multi-page workflows  \n🌐 Monitor console messages and network requests  \n⏱️ Wait for dynamic content to load  \n📁 Handle file uploads and browser dialogs  \n🔄 Navigate through browser history\n\n## Installation\n\nYou can install the package using any of these methods:\n\nUsing npm:\n```bash\nnpm install -g mcp-accessibility-scanner\n```\n\n### Installation in VS Code\n\nInstall the Accessibility Scanner in VS Code using the VS Code CLI:\n\nFor VS Code:\n```bash\ncode --add-mcp '{\"name\":\"accessibility-scanner\",\"command\":\"npx\",\"args\":[\"mcp-accessibility-scanner\"]}'\n```\n\nFor VS Code Insiders:\n```bash\ncode-insiders --add-mcp '{\"name\":\"accessibility-scanner\",\"command\":\"npx\",\"args\":[\"mcp-accessibility-scanner\"]}'\n```\n\n## Configuration\n\nHere's the Claude Desktop configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"accessibility-scanner\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"mcp-accessibility-scanner\"]\n    }\n  }\n}\n```\n\n### Advanced Configuration\n\nYou can pass a configuration file to customize Playwright behavior:\n\n```json\n{\n  \"mcpServers\": {\n    \"accessibility-scanner\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"mcp-accessibility-scanner\", \"--config\", \"/path/to/config.json\"]\n    }\n  }\n}\n```\n\n#### Configuration Options\n\nCreate a `config.json` file with the following options:\n\n```json\n{\n  \"browser\": {\n    \"browserName\": \"chromium\",\n    \"launchOptions\": {\n      \"headless\": true,\n      \"channel\": \"chrome\"\n    }\n  },\n  \"timeouts\": {\n    \"navigationTimeout\": 60000,\n    \"defaultTimeout\": 5000\n  },\n  \"network\": {\n    \"allowedOrigins\": [\"example.com\", \"trusted-site.com\"],\n    \"blockedOrigins\": [\"ads.example.com\"]\n  }\n}\n```\n\n**Available Options:**\n\n- `browser.browserName`: Browser to use (`chromium`, `firefox`, `webkit`)\n- `browser.launchOptions.headless`: Run browser in headless mode (default: `true` on Linux without display, `false` otherwise)\n- `browser.launchOptions.channel`: Browser channel (`chrome`, `chrome-beta`, `msedge`, etc.)\n- `timeouts.navigationTimeout`: Maximum time for page navigation in milliseconds (default: `60000`)\n- `timeouts.defaultTimeout`: Default timeout for Playwright operations in milliseconds (default: `5000`)\n- `network.allowedOrigins`: List of origins to allow (blocks all others if specified)\n- `network.blockedOrigins`: List of origins to block\n\n## Available Tools\n\nThe MCP server provides comprehensive browser automation and accessibility scanning tools:\n\n### Core Accessibility Tool\n\n#### `scan_page`\nPerforms a comprehensive accessibility scan on the current page using Axe-core.\n\n**Parameters:**\n- `violationsTag`: Array of WCAG/violation tags to check\n\n**Supported Violation Tags:**\n- WCAG standards: `wcag2a`, `wcag2aa`, `wcag2aaa`, `wcag21a`, `wcag21aa`, `wcag21aaa`, `wcag22a`, `wcag22aa`, `wcag22aaa`\n- Section 508: `section508`\n- Categories: `cat.aria`, `cat.color`, `cat.forms`, `cat.keyboard`, `cat.language`, `cat.name-role-value`, `cat.parsing`, `cat.semantics`, `cat.sensory-and-visual-cues`, `cat.structure`, `cat.tables`, `cat.text-alternatives`, `cat.time-and-media`\n\n### Navigation Tools\n\n#### `browser_navigate`\nNavigate to a URL.\n- Parameters: `url` (string)\n\n#### `browser_navigate_back`\nGo back to the previous page.\n\n#### `browser_navigate_forward`\nGo forward to the next page.\n\n### Page Interaction Tools\n\n#### `browser_snapshot`\nCapture accessibility snapshot of the current page (better than screenshot for analysis).\n\n#### `browser_click`\nPerform click on a web page element.\n- Parameters: `element` (description), `ref` (element reference), `doubleClick` (optional)\n\n#### `browser_type`\nType text into editable element.\n- Parameters: `element`, `ref`, `text`, `submit` (optional), `slowly` (optional)\n\n#### `browser_hover`\nHover over element on page.\n- Parameters: `element`, `ref`\n\n#### `browser_drag`\nPerform drag and drop between two elements.\n- Parameters: `startElement`, `startRef`, `endElement`, `endRef`\n\n#### `browser_select_option`\nSelect an option in a dropdown.\n- Parameters: `element`, `ref`, `values` (array)\n\n#### `browser_press_key`\nPress a key on the keyboard.\n- Parameters: `key` (e.g., 'ArrowLeft' or 'a')\n\n### Screenshot & Visual Tools\n\n#### `browser_take_screenshot`\nTake a screenshot of the current page.\n- Parameters: `raw` (optional), `filename` (optional), `element` (optional), `ref` (optional)\n\n#### `browser_pdf_save`\nSave page as PDF.\n- Parameters: `filename` (optional, defaults to `page-{timestamp}.pdf`)\n\n### Browser Management\n\n#### `browser_close`\nClose the page.\n\n#### `browser_resize`\nResize the browser window.\n- Parameters: `width`, `height`\n\n### Tab Management\n\n#### `browser_tab_list`\nList all open browser tabs.\n\n#### `browser_tab_new`\nOpen a new tab.\n- Parameters: `url` (optional)\n\n#### `browser_tab_select`\nSelect a tab by index.\n- Parameters: `index`\n\n#### `browser_tab_close`\nClose a tab.\n- Parameters: `index` (optional, closes current tab if not provided)\n\n### Information & Monitoring Tools\n\n#### `browser_console_messages`\nReturns all console messages from the page.\n\n#### `browser_network_requests`\nReturns all network requests since loading the page.\n\n### Utility Tools\n\n#### `browser_wait_for`\nWait for text to appear/disappear or time to pass.\n- Parameters: `time` (optional), `text` (optional), `textGone` (optional)\n\n#### `browser_handle_dialog`\nHandle browser dialogs (alerts, confirms, prompts).\n- Parameters: `accept` (boolean), `promptText` (optional)\n\n#### `browser_file_upload`\nUpload files to the page.\n- Parameters: `paths` (array of absolute file paths)\n\n### Vision Mode Tools (Coordinate-based Interaction)\n\n#### `browser_screen_capture`\nTake a screenshot for coordinate-based interaction.\n\n#### `browser_screen_move_mouse`\nMove mouse to specific coordinates.\n- Parameters: `element`, `x`, `y`\n\n#### `browser_screen_click`\nClick at specific coordinates.\n- Parameters: `element`, `x`, `y`\n\n#### `browser_screen_drag`\nDrag from one coordinate to another.\n- Parameters: `element`, `startX`, `startY`, `endX`, `endY`\n\n#### `browser_screen_type`\nType text (coordinate-independent).\n- Parameters: `text`, `submit` (optional)\n\n## Usage Examples\n\n### Basic Accessibility Scan\n```\n1. Navigate to example.com using browser_navigate\n2. Run scan_page with violationsTag: [\"wcag21aa\"]\n```\n\n### Color Contrast Check\n```\n1. Use browser_navigate to go to example.com\n2. Run scan_page with violationsTag: [\"cat.color\"]\n```\n\n### Multi-step Workflow\n```\n1. Navigate to example.com with browser_navigate\n2. Take a browser_snapshot to see available elements\n3. Click the \"Sign In\" button using browser_click\n4. Type \"user@example.com\" using browser_type\n5. Run scan_page on the login page\n6. Take a browser_take_screenshot to capture the final state\n```\n\n### Page Analysis\n```\n1. Navigate to example.com\n2. Use browser_snapshot to capture all interactive elements\n3. Review console messages with browser_console_messages\n4. Check network activity with browser_network_requests\n```\n\n### Tab Management\n```\n1. Open a new tab with browser_tab_new\n2. Navigate to different pages in each tab\n3. Switch between tabs using browser_tab_select\n4. List all tabs with browser_tab_list\n```\n\n### Waiting for Dynamic Content\n```\n1. Navigate to a page\n2. Use browser_wait_for to wait for specific text to appear\n3. Interact with the dynamically loaded content\n```\n\n**Note:** Most interaction tools require element references from browser_snapshot. Always capture a snapshot before attempting to interact with page elements.\n\n## Development\n\nClone and set up the project:\n```bash\ngit clone https://github.com/JustasMonkev/mcp-accessibility-scanner.git\ncd mcp-accessibility-scanner\nnpm install\n```\n\n## License\n\nMIT\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "accessibility",
        "scanning",
        "scanner",
        "accessibility scanning",
        "accessibility scanner",
        "web accessibility"
      ],
      "category": "document-processing"
    },
    "Klavis-AI--klavis": {
      "owner": "Klavis-AI",
      "name": "klavis",
      "url": "https://github.com/Klavis-AI/klavis",
      "imageUrl": "/freedevtools/mcp/pfp/Klavis-AI.webp",
      "description": "Generates visually appealing web reports based on simple search queries, integrating live web search results and storing reports in a database for easy access. Utilizes AI to synthesize information into interactive HTML formats.",
      "stars": 4547,
      "forks": 432,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-10-04T10:01:35Z",
      "readme_content": "<div align=\"center\">\n  <picture>\n    <img src=\"https://raw.githubusercontent.com/klavis-ai/klavis/main/static/klavis-ai.png\" width=\"100\">\n  </picture>\n</div>\n\n<h1 align=\"center\">Klavis AI</h1>\n<p align=\"center\"><strong>📦 MCP integration layers that let AI agents use tools reliably at any scale</strong></p>\n\n<div align=\"center\">\n\n[![Documentation](https://img.shields.io/badge/Documentation-📖-green)](https://docs.klavis.ai)\n[![Website](https://img.shields.io/badge/Website-🌐-purple)](https://www.klavis.ai)\n[![Discord](https://img.shields.io/badge/Discord-Join-7289DA?logo=discord&logoColor=white)](https://discord.gg/p7TuTEcssn)\n[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)\n\n<a href=\"https://www.producthunt.com/products/strata-2?embed=true&utm_source=badge-top-post-badge&utm_medium=badge&utm_source=badge-strata&#0045;2\" target=\"_blank\"><img src=\"https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=1016948&theme=light&period=daily&t=1758639605639\" alt=\"Strata - One&#0032;MCP&#0032;server&#0032;for&#0032;AI&#0032;agents&#0032;to&#0032;handle&#0032;thousands&#0032;of&#0032;tools | Product Hunt\" style=\"width: 250px; height: 54px;\" width=\"250\" height=\"54\" /></a>\n\n</div>\n\n## 🎯 Choose Your Solution\n\n<div align=\"center\">\n  <table>\n    <tr>\n      <td align=\"center\" width=\"50%\" valign=\"top\" style=\"vertical-align: top; height: 250px;\">\n        <div style=\"height: 100%; display: flex; flex-direction: column; justify-content: space-between;\">\n          <div>\n            <h2>📦 Strata</h2>\n            <p><strong>Unified MCP Router</strong></p>\n            <p>One MCP server for AI agents to use tools reliably at any scale</p>\n          </div>\n          <div>\n            <a href=\"open-strata/README.md\">\n              <img src=\"https://img.shields.io/badge/Explore-Strata-blue?style=for-the-badge&logo=data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjIwIiBoZWlnaHQ9IjIwIiByeD0iNCIgcnk9IjQiIHN0cm9rZT0id2hpdGUiIHN0cm9rZS13aWR0aD0iMiIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIiBzdHJva2UtbGluZWpvaW49InJvdW5kIi8+CjxyZWN0IHg9IjYiIHk9IjYiIHdpZHRoPSI0IiBoZWlnaHQ9IjQiIHJ4PSIxIiByeT0iMSIgZmlsbD0id2hpdGUiLz4KPHJlY3QgeD0iMTQiIHk9IjYiIHdpZHRoPSI0IiBoZWlnaHQ9IjQiIHJ4PSIxIiByeT0iMSIgZmlsbD0id2hpdGUiLz4KPHJlY3QgeD0iNiIgeT0iMTQiIHdpZHRoPSI0IiBoZWlnaHQ9IjQiIHJ4PSIxIiByeT0iMSIgZmlsbD0id2hpdGUiLz4KPHJlY3QgeD0iMTQiIHk9IjE0IiB3aWR0aD0iNCIgaGVpZ2h0PSI0IiByeD0iMSIgcnk9IjEiIGZpbGw9IndoaXRlIi8+Cjwvc3ZnPg==\" height=\"40\">\n            </a>\n          </div>\n        </div>\n      </td>\n      <td align=\"center\" width=\"50%\" valign=\"top\" style=\"vertical-align: top; height: 250px;\">\n        <div style=\"height: 100%; display: flex; flex-direction: column; justify-content: space-between;\">\n          <div>\n            <h2>🛠️ MCP Integrations</h2>\n            <p><strong>50+ Production MCP Servers</strong></p>\n            <p>Self-hosted or managed MCP servers with enterprise OAuth support for all major services</p>\n          </div>\n          <div>\n            <a href=\"mcp_servers/README.md\">\n              <img src=\"https://img.shields.io/badge/Explore-MCP%20Servers-purple?style=for-the-badge&logo=data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZD0iTTIwLjUgN0gzLjVDMi42NzE1NyA3IDIgNy42NzE1NyAyIDguNVYxNS41QzIgMTYuMzI4NCAyLjY3MTU3IDE3IDMuNSAxN0gyMC41QzIxLjMyODQgMTcgMjIgMTYuMzI4NCAyMiAxNS41VjguNUMyMiA3LjY3MTU3IDIxLjMyODQgNyAyMC41IDdaIiBzdHJva2U9IndoaXRlIiBzdHJva2Utd2lkdGg9IjIiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCIgc3Ryb2tlLWxpbmVqb2luPSJyb3VuZCIvPgo8cGF0aCBkPSJNNiAxMkgxOCIgc3Ryb2tlPSJ3aGl0ZSIgc3Ryb2tlLXdpZHRoPSIyIiBzdHJva2UtbGluZWNhcD0icm91bmQiLz4KPGNpcmNsZSBjeD0iNSIgY3k9IjEyIiByPSIxIiBmaWxsPSJ3aGl0ZSIvPgo8Y2lyY2xlIGN4PSIxOSIgY3k9IjEyIiByPSIxIiBmaWxsPSJ3aGl0ZSIvPgo8L3N2Zz4=\" height=\"40\">\n            </a>\n          </div>\n        </div>\n      </td>\n    </tr>\n  </table>\n</div>\n\n## Strata\n\nStrata is one MCP server that guides your AI agents use tools reliably progressively at any scale.\n\n### Why Strata?\n\n🎯 **Scalable Tool Integration** → Beyond 40-50 tool limits  \n🚀 **Progressive Discovery** → Guides agents from intent to action, step-by-step.\n\n[📖 **Learn More** →](https://docs.klavis.ai/documentation/concepts/strata)\n\n## MCP Integrations\n\n**50+ production MCP servers. OAuth included. Deploy anywhere.**\n\nConnect your AI to GitHub, Gmail, Slack, Salesforce, and more - all with enterprise OAuth and Docker support.\n\n🔐 **Real OAuth** → Not just API keys  \n🐳 **Docker ready** → One-line deploy  \n\n[🌐 **Browse All Servers** →](https://docs.klavis.ai/documentation/mcp-server/overview)\n\n## 🚀 Quick Start\n\n### Option 1: Open Source\n\nSelf-host everything on your own infrastructure:\n\n```bash\n# Run any MCP Integration\ndocker pull ghcr.io/klavis-ai/github-mcp-server:latest\ndocker run -p 5000:5000 ghcr.io/klavis-ai/github-mcp-server:latest\n\n# Install Open Source Strata locally\npipx install strata-mcp\nstrata add --type stdio playwright npx @playwright/mcp@latest\n```\n\n### Option 2: Use Hosted Service by WebUI\n\nGet instant access without any setup:\n\n1. **Sign Up**: [Create account →](https://www.klavis.ai/auth/sign-up)\n2. **Get Started**: [Follow quickstart guide →](https://docs.klavis.ai/documentation/quickstart)\n3. **Use Strata or individual MCP servers** in Claude Code, Cursor, VSCode, etc.\n\nReady in under 2 minutes! 🚀\n\n### Option 3: SDK\n\nBuild custom applications with our SDKs:\n\n```python\n# Python SDK\nfrom klavis import Klavis\nfrom klavis.types import McpServerName\n\nklavis = Klavis(api_key=\"your-key\")\n\n# Create Strata instance\nstrata = klavis.mcp_server.create_strata_server(\n    user_id=\"user123\",\n    servers=[McpServerName.GMAIL, McpServerName.YOUTUBE],\n)\n\n# Or use individual MCP servers\ngmail = klavis.mcp_server.create_server_instance(\n    server_name=McpServerName.GMAIL,\n    user_id=\"user123\",\n)\n```\n\n```typescript\n// TypeScript SDK\nimport { KlavisClient, McpServerName } from 'klavis';\n\nconst klavis = new KlavisClient({ apiKey: 'your-api-key' });\n\n// Create Strata instance\nconst strata = await klavis.mcpServer.createStrataServer({\n    userId: \"user123\",\n    servers: [McpServerName.GMAIL, McpServerName.YOUTUBE]\n});\n\n// Or use individual MCP servers\nconst gmail = await klavis.mcpServer.createServerInstance({\n    serverName: McpServerName.GMAIL,\n    userId: \"user123\"\n});\n```\n\n### Option 4: Direct API\n\nUse REST API for any programming language:\n\n```bash\n# Create Strata server\ncurl -X POST \"https://api.klavis.ai/v1/mcp-server/strata\" \\\n  -H \"Authorization: Bearer your-api-key\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"user_id\": \"user123\",\n    \"servers\": [\"GMAIL\", \"YOUTUBE\"]\n  }'\n\n# Create individual MCP server\ncurl -X POST \"https://api.klavis.ai/v1/mcp-server/instance\" \\\n  -H \"Authorization: Bearer your-api-key\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"server_name\": \"GMAIL\",\n    \"user_id\": \"user123\"\n  }'\n```\n\n[📖 **Complete Documentation** →](https://docs.klavis.ai/documentation/quickstart)\n\n\n## 📚 Resources\n\n- 📖 [Documentation](https://docs.klavis.ai)\n- 💬 [Discord Community](https://discord.gg/p7TuTEcssn)\n- 🐛 [Report Issues](https://github.com/klavis-ai/klavis/issues)\n- 🌐 [Klavis AI Website](https://www.klavis.ai)\n\n## 📜 License\n\n- **Root Repository**: Apache 2.0 license - see [LICENSE](LICENSE)\n\n---\n\n<div align=\"center\">\n  <p><strong>Klavis AI (YC X25) 🚀 Empowering AI with Seamless Integration</strong></p>\n</div>",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "klavis",
        "html",
        "interactive",
        "processing klavis",
        "klavis ai",
        "ai klavis"
      ],
      "category": "document-processing"
    },
    "KorigamiK--markitdown_mcp_server": {
      "owner": "KorigamiK",
      "name": "markitdown_mcp_server",
      "url": "https://github.com/KorigamiK/markitdown_mcp_server",
      "imageUrl": "/freedevtools/mcp/pfp/KorigamiK.webp",
      "description": "Converts various file formats to Markdown, utilizing the MarkItDown utility to handle documents, images, and audio files.",
      "stars": 56,
      "forks": 12,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-30T06:48:21Z",
      "readme_content": "# MarkItDown MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@KorigamiK/markitdown_mcp_server)](https://smithery.ai/server/@KorigamiK/markitdown_mcp_server)\n\nA Model Context Protocol (MCP) server that converts various file formats to Markdown using the MarkItDown utility.\n\n<a href=\"https://glama.ai/mcp/servers/sbc6bljjg5\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/sbc6bljjg5/badge\" alt=\"MarkItDown Server MCP server\" /></a>\n\n## Supported Formats\n\n- PDF\n- PowerPoint\n- Word\n- Excel\n- Images (EXIF metadata and OCR)\n- Audio (EXIF metadata and speech transcription)\n- HTML\n- Text-based formats (CSV, JSON, XML)\n- ZIP files (iterates over contents)\n\n## Installation\n\n### Installing via Smithery\n\nTo install MarkItDown MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@KorigamiK/markitdown_mcp_server):\n\n```bash\nnpx -y @smithery/cli install @KorigamiK/markitdown_mcp_server --client claude\n```\n\n### Manual Installation\n\n1. Clone this repository\n2. Install dependencies:\n```bash\nuv install\n```\n\n## Usage\n\n### As MCP Server\n\nThe server can be integrated with any MCP client. Here are some examples:\n\n#### Zed Editor\n\nAdd the following to your `settings.json`:\n\n```json\n\"context_servers\": {\n  \"markitdown_mcp\": {\n    \"settings\": {},\n    \"command\": {\n      \"path\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/path/to/markitdown_mcp_server\",\n        \"run\",\n        \"markitdown\"\n      ]\n    }\n  }\n}\n```\n\n### Commands\n\nThe server responds to the following MCP commands:\n\n- `/md <file>` - Convert the specified file to Markdown\n\nExample:\n```bash\n/md document.pdf\n```\n\n## Supported MCP Clients\n\nWorks with any MCP-compliant client listed at [modelcontextprotocol.io/clients](https://modelcontextprotocol.io/clients), including:\n\n- Zed Editor\n- Any other MCP-compatible editors and tools\n\n## License\n\nMIT License. See [LICENSE](LICENSE) for details.\n\n## Acknowledgements\n\nhttps://github.com/microsoft/markitdown#readme\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "markitdown",
        "markitdown_mcp_server",
        "markdown",
        "korigamik markitdown_mcp_server",
        "markitdown utility",
        "formats markdown"
      ],
      "category": "document-processing"
    },
    "Kryzo--mcp-bibliotheque_nationale_de_France": {
      "owner": "Kryzo",
      "name": "mcp-bibliotheque_nationale_de_France",
      "url": "https://github.com/Kryzo/mcp-bibliotheque_nationale_de_France",
      "imageUrl": "/freedevtools/mcp/pfp/Kryzo.webp",
      "description": "Access the Gallica digital library to search for documents, images, maps, and other resources, and generate structured research reports that include organized bibliographies and relevant visual content.",
      "stars": 5,
      "forks": 3,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-10-01T16:19:01Z",
      "readme_content": "# BnF API Server\n\nUn serveur MCP (Model-Client-Protocol) pour accéder à l'API Gallica de la Bibliothèque nationale de France (BnF) et générer des rapports de recherche séquentiels.\n\n## Fonctionnalités\n\n- **Recherche dans Gallica** : Recherche de documents, images, cartes et autres ressources dans la bibliothèque numérique Gallica\n- **Génération de rapports séquentiels** : Création automatique de rapports de recherche structurés sur n'importe quel sujet\n- **Intégration de graphiques** : Inclusion d'images et de cartes pertinentes dans les rapports générés\n- **Citations formatées** : Génération automatique de bibliographies avec citations correctement formatées\n\n## Installation\n\n### Prérequis\n\n- Python 3.8 ou supérieur\n- Pip (gestionnaire de paquets Python)\n\n### Étapes d'installation\n\n1. **Cloner le dépôt**:\n   ```bash\n   git clone https://github.com/votre-nom/mcp-bnf.git\n   cd mcp-bnf\n   ```\n\n2. **Installer les dépendances**:\n   ```bash\n   pip install -r requirements.txt\n   ```\n\n## Configuration avec Claude Desktop\n\n1. **Installer Claude Desktop** si ce n'est pas déjà fait.\n\n2. **Ouvrir la configuration de Claude Desktop**:\n   - Accéder aux paramètres de Claude Desktop\n   - Ouvrir le fichier de configuration (généralement situé à `%APPDATA%\\Claude\\claude_desktop_config.json`)\n\n```json\n{\n \"bnf\": {\n  \"command\": \"py\",\n  \"args\": [\n    \"c:\\\\chemin\\\\vers\\\\mcp-bnf\\\\bnf_server.py\"\n  ],\n  \"cwd\": \"c:\\\\chemin\\\\vers\\\\mcp-bnf\"\n},\n```\n\nRemplacez `chemin\\\\vers\\\\mcp-bnf` par le chemin réel vers votre répertoire d'installation.\n\n3. **Enregistrer le fichier de configuration** et redémarrer Claude Desktop\n\n## Outils MCP disponibles\n\nUne fois configuré, les outils suivants seront disponibles dans Claude Desktop:\n\n### Recherche dans Gallica\n\nPermet de rechercher des documents dans la bibliothèque numérique Gallica de la BnF en utilisant différents critères (titre, auteur, sujet, date, type de document).\n\n### Génération de rapports séquentiels\n\nCrée des rapports de recherche complets sur n'importe quel sujet en utilisant les sources de Gallica. Les rapports incluent:\n- Une bibliographie formatée\n- Une introduction\n- Un contexte historique\n- Une analyse\n- Une conclusion\n- Des images et cartes pertinentes (optionnel)\n\n## Structure du projet\n\n```\nmcp-bnf/\n│\n├── bnf_server.py              # Serveur MCP principal\n├── requirements.txt           # Dépendances du projet\n│\n└── bnf_api/                   # Package API BnF\n    ├── __init__.py            # Exports du package\n    ├── api.py                 # Client API Gallica BnF\n    ├── search.py              # Fonctions de recherche\n    ├── config.py              # Constantes et configuration\n    └── sequential_reporting.py # Outil de génération de rapports séquentiels\n```\n\n## Utilisation\n\nUne fois configuré avec Claude Desktop, vous pouvez demander à Claude d'utiliser les outils BnF pour:\n\n1. **Rechercher des documents**:\n   - \"Recherche des livres sur Victor Hugo dans Gallica\"\n   - \"Trouve des cartes de Paris du 19ème siècle\"\n\n2. **Générer des rapports**:\n   - \"Crée un rapport sur l'impressionnisme en France\"\n   - \"Génère un rapport sur l'histoire du Liban sous mandat français avec des images\"\n\n## Développement\n\nPour contribuer au projet:\n\n1. Forker le dépôt\n2. Créer une branche pour votre fonctionnalité (`git checkout -b feature/nouvelle-fonctionnalite`)\n3. Committer vos changements (`git commit -am 'Ajouter une nouvelle fonctionnalité'`)\n4. Pousser vers la branche (`git push origin feature/nouvelle-fonctionnalite`)\n5. Créer une Pull Request\n\n## Licence\n\nCe projet est open source.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "bibliotheque_nationale_de_france",
        "bibliographies",
        "library",
        "mcp bibliotheque_nationale_de_france",
        "bibliotheque_nationale_de_france access",
        "organized bibliographies"
      ],
      "category": "document-processing"
    },
    "KunihiroS--kv-extractor-mcp-server": {
      "owner": "KunihiroS",
      "name": "kv-extractor-mcp-server",
      "url": "https://github.com/KunihiroS/kv-extractor-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/KunihiroS.webp",
      "description": "Extracts key-value pairs from noisy or unstructured text in multiple languages, ensuring type-safe outputs in JSON, YAML, or TOML formats. Utilizes advanced LLMs and pydantic for data structuring and validation, supporting languages like Japanese, English, and Chinese.",
      "stars": 1,
      "forks": 2,
      "license": "GNU General Public License v3.0",
      "language": "Python",
      "updated_at": "2025-07-16T11:24:07Z",
      "readme_content": "# Flexible Key-Value Extracting MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@KunihiroS/kv-extractor-mcp-server)](https://smithery.ai/server/@KunihiroS/kv-extractor-mcp-server)\n\nVersion: 0.3.2\n\nThis MCP server extracts key-value pairs from arbitrary, noisy, or unstructured text using LLMs (GPT-4.1-mini) and pydantic-ai. \nIt ensures type safety and supports multiple output formats (JSON, YAML, TOML). The server is robust to any input and always attempts to structure data as much as possible, however, perfect extraction is **not guaranteed**.\n\n---\n## 🤔💡 Why Use This MCP Server?\n\nWhile many Large Language Model (LLMs) services offer structured output capabilities, this MCP server provides distinct advantages for key-value extraction, especially from challenging real-world text:\n\n*   🔑🔍 **Automatic Key Discovery**: A core strength is its ability to *autonomously identify and extract relevant key-value pairs* from unstructured text *without requiring pre-defined keys*. While typical LLM structured outputs need you to specify the keys you're looking for, this server discovers them, making it highly effective for diverse and unpredictable data where the structure is not known beforehand.\n*   💪🧱 **Superior Robustness for Complex Inputs**: It excels with arbitrary, noisy, or unstructured text where standard LLM structured outputs might falter. The multi-step pipeline is specifically designed to sift through and make sense of imperfect data.\n*   🌐🗣️ **Advanced Multi-Lingual Preprocessing**: Before LLM processing, it leverages spaCy for Named Entity Recognition (NER) in Japanese, English, and Chinese (Simplified/Traditional), significantly enhancing extraction accuracy for these languages by providing context-rich candidate phrases.\n*   🔄✍️ **Iterative Refinement and Typing**: Unlike a single-pass extraction, this server employs a sophisticated pipeline including LLM-based type annotation, LLM-based type evaluation, and rule-based/LLM-fallback normalization. This ensures more accurate and contextually appropriate data types.\n*   ✅🛡️ **Guaranteed Type Safety and Schema Adherence**: Final structuring with Pydantic ensures that the output is not only structured but also type-safe and validated against a defined schema, providing reliable data for downstream applications.\n*   📊⚙️ **Consistent and Predictable Output**: The server is designed to always return a well-formed response, even if extraction is partial or encounters issues, which is critical for building robust automated systems.\n\n---\n\n## Release Notes\n\n### v0.3.2\n- Fix: FastMCP caused error.\n\n### v0.3.1\n- Update: Improve type evaluation prompt for robust correction.\n- Update: Added the strong point of this MCP server on README.md\n\n### v0.2.0\n- Fix: Lang code for zh-cn / zh-tw.\n\n### v0.1.0\n- Initial release\n\n## Tools\n\n- `/extract_json` : Extracts type-safe key-value pairs in JSON format from input text.\n- `/extract_yaml` : Extracts type-safe key-value pairs in YAML format from input text.\n- `/extract_toml` : Extracts type-safe key-value pairs in TOML format from input text.\n    - *Note: Due to TOML specifications, arrays of objects (dicts) or deeply nested structures cannot be directly represented. See \"Note on TOML Output Limitations\" below for details.*\n\n**Note:**\n- Supported languages: Japanese, English, and Chinese (Simplified: zh-cn / Traditional: zh-tw).\n- Extraction relies on pydantic-ai and LLMs. Perfect extraction is not guaranteed.\n- Longer input sentences will take more time to process. Please be patient.\n- On first launch, the server will download spaCy models, so the process will take longer initially.\n\n### Estimated Processing Time Sample\n\n| Input Tokens | Input Characters (approx.) | Measured Processing Time (sec) | Model Configuration |\n|:-----------:|:--------------------------:|:------------------------------:|:-------------------|\n| 200         | ~400                       | ~15                            | gpt-4.1-mini       |\n\n*Actual processing time may vary significantly depending on API response, network conditions, and model load. Even short texts may take 15 seconds or more.*\n\n## Features\n- **Flexible extraction**: Handles any input, including noisy or broken data.\n- **JP / EN / ZH-CN / ZH-TW full support**: Preprocessing with spaCy NER by automatic language detection (Japanese, English, Chinese [Simplified: zh-cn / Traditional: zh-tw] supported; others are rejected with error).\n- **Type-safe output**: Uses Pydantic for output validation.\n- **Multiple formats**: Returns results as JSON, YAML, or TOML.\n- **Robust error handling**: Always returns a well-formed response, even on failure.\n- **High accuracy**: Uses GPT-4.1-mini for both extraction/annotation and type evaluation, with Pydantic for final structuring.\n\n## Tested Scenarios\nThe server has been tested with various inputs, including:\n- Simple key-value pairs\n- Noisy or unstructured text with important information buried within\n- Different data formats (JSON, YAML, TOML) for output\n\n## Processing Flow\nBelow is a flowchart representing the processing flow of the key-value extraction pipeline as implemented in `server.py`:\n\n```mermaid\nflowchart TD\n    A[Input Text] --> B[Step 0: Preprocessing with spaCy Lang Detect then NER]\n    B --> C[Step 1: Key-Value Extraction - LLM]\n    C --> D[Step 2: Type Annotation - LLM]\n    D --> E[Step 3: Type Evaluation - LLM]\n    E --> F[Step 4: Type Normalization - Static Rules + LLM]\n    F --> G[Step 5: Final Structuring with Pydantic]\n    G --> H[Output in JSON/YAML/TOML]\n```\n\n## Preprocessing with spaCy (Multilingual NER)\n\nThis server uses [spaCy](https://spacy.io/) with automatic language detection to extract named entities from the input text **before** passing it to the LLM. Supported languages are Japanese (`ja_core_news_md`), English (`en_core_web_sm`), and Chinese (Simplified/Traditional, `zh_core_web_sm`).\n\n- The language of the input text is automatically detected using `langdetect`.\n- If the detected language is not Japanese, English, or Chinese, the server returns an error: `Unsupported lang detected`.\n- The appropriate spaCy model is automatically downloaded and loaded as needed. No manual installation is required.\n- The extracted phrase list is included in the LLM prompt as follows:\n\n  > [Preprocessing Candidate Phrases (spaCy NER)]\n  > The following is a list of phrases automatically extracted from the input text using spaCy's detected language model.\n  > These phrases represent detected entities such as names, dates, organizations, locations, numbers, etc.\n  > This list is for reference only and may contain irrelevant or incorrect items. The LLM uses its own judgment and considers the entire input text to flexibly infer the most appropriate key-value pairs.\n\n## Step Details\n\nThis project's key-value extraction pipeline consists of multiple steps. Each step's details are as follows:\n\n### Step 0: Preprocessing with spaCy (Language Detection → Named Entity Recognition)\n- **Purpose**: Automatically detect the language of the input text and use the appropriate spaCy model (e.g., `ja_core_news_md`, `en_core_web_sm`, `zh_core_web_sm`) to extract named entities.\n- **Output**: The extracted phrase list, which is included in the LLM prompt as a hint to improve key-value pair extraction accuracy.\n\n### Step 1: Key-Value Extraction (LLM)\n- **Purpose**: Use GPT-4.1-mini to extract key-value pairs from the input text and the extracted phrase list.\n- **Details**:\n  - The prompt includes instructions to return list-formatted values when the same key appears multiple times.\n  - Few-shot examples are designed to include list-formatted outputs.\n- **Output**: Example: `key: person, value: [\"Tanaka\", \"Sato\"]`\n\n### Step 2: Type Annotation (LLM)\n- **Purpose**: Use GPT-4.1-mini to infer the data type (int, str, bool, list, etc.) of each key-value pair extracted in Step 1.\n- **Details**:\n  - The type annotation prompt includes instructions for list and multiple value support.\n- **Output**: Example: `key: person, value: [\"Tanaka\", \"Sato\"] -> list[str]`\n\n### Step 3: Type Evaluation (LLM)\n- **Purpose**: Use GPT-4.1-mini to evaluate and correct the type annotations from Step 2.\n- **Details**:\n  - For each key-value pair, GPT-4.1-mini re-evaluates the type annotation's validity and context.\n  - If type errors or ambiguities are detected, GPT-4.1-mini automatically corrects or supplements the type.\n  - Example: Correcting a value extracted as a number but should be a string, or determining whether a value is a list or a single value.\n- **Output**: The type-evaluated key-value pair list.\n\n### Step 4: Type Normalization (Static Rules + LLM Fallback)\n- **Purpose**: Convert the type-evaluated data into Python's standard types (int, float, bool, str, list, None, etc.).\n- **Details**:\n  - Apply static normalization rules (regular expressions or type conversion functions) to convert values into Python's standard types.\n  - Example: Converting comma-separated values to lists, \"true\"/\"false\" to bool, or date expressions to standard formats.\n  - If static rules cannot convert a value, use LLM-based type conversion fallback.\n  - Unconvertible values are safely handled as None or str.\n- **Output**: The Python-type-normalized key-value pair list.\n\n### Step 5: Final Structuring with Pydantic\n- **Purpose**: Validate and structure the type-normalized data using Pydantic models (KVOut/KVPayload).\n- **Details**:\n  - Map each key-value pair to Pydantic models, ensuring type safety and data integrity.\n  - Validate single values, lists, null, and composite types according to the schema.\n  - If validation fails, attach error information while preserving as much data as possible.\n  - The final output is returned in the specified format (JSON, YAML, or TOML).\n- **Output**: The type-safe and validated dict or specified format (JSON/YAML/TOML) output.\n\n---\n\nThis pipeline is designed to accommodate future list format support and Pydantic schema extensions.\n\n## Note on TOML Output Limitations\n\n- In TOML, simple arrays (e.g., `items = [\"A\", \"B\"]`) can be represented natively, but\n  **arrays of objects (dicts) or deeply nested structures cannot be directly represented due to TOML specifications.**\n- Therefore, complex lists or nested structures (e.g., `[{\"name\": \"A\"}, {\"name\": \"B\"}]`) are\n  **stored as \"JSON strings\" in TOML values.**\n- This is a design choice to prevent information loss due to TOML's specification limitations.\n- YAML and JSON formats can represent nested structures as-is.\n\n## Example Input/Output\nInput:\n```\nThank you for your order (Order Number: ORD-98765). Product: High-Performance Laptop, Price: 89,800 JPY (tax excluded), Delivery: May 15-17. Shipping address: 1-2-3 Shinjuku, Shinjuku-ku, Tokyo, Apartment 101. Phone: 090-1234-5678. Payment: Credit Card (VISA, last 4 digits: 1234). For changes, contact support@example.com.\n```\n\nOutput (JSON):\n```json\n{\n  \"order_number\": \"ORD-98765\",\n  \"product_name\": \"High-Performance Laptop\",\n  \"price\": 89800,\n  \"price_currency\": \"JPY\",\n  \"tax_excluded\": true,\n  \"delivery_start_date\": \"20240515\",\n  \"delivery_end_date\": \"20240517\",\n  \"shipping_address\": \"1-2-3 Shinjuku, Shinjuku-ku, Tokyo, Apartment 101\",\n  \"phone_number\": \"090-1234-5678\",\n  \"payment_method\": \"Credit Card\",\n  \"card_type\": \"VISA\",\n  \"card_last4\": \"1234\",\n  \"customer_support_email\": \"support@example.com\"\n}\n```\n\nOutput (YAML):\n```yaml\norder_number: ORD-98765\nproduct_name: High-Performance Laptop\nprice: 89800\nprice_currency: JPY\ntax_excluded: true\ndelivery_start_date: '20240515'\ndelivery_end_date: '20240517'\nshipping_address: 1-2-3 Shinjuku, Shinjuku-ku, Tokyo, Apartment 101\nphone_number: 090-1234-5678\npayment_method: Credit Card\ncard_type: VISA\ncard_last4: '1234'\ncustomer_support_email: support@example.com\n```\n\nOutput (TOML, simple case):\n```toml\norder_number = \"ORD-98765\"\nproduct_name = \"High-Performance Laptop\"\nprice = 89800\nprice_currency = \"JPY\"\ntax_excluded = true\ndelivery_start_date = \"20240515\"\ndelivery_end_date = \"20240517\"\nshipping_address = \"1-2-3 Shinjuku, Shinjuku-ku, Tokyo, Apartment 101\"\nphone_number = \"090-1234-5678\"\npayment_method = \"Credit Card\"\ncard_type = \"VISA\"\ncard_last4 = \"1234\"\n```\n\nOutput (TOML, complex case):\n```toml\nitems = '[{\"name\": \"A\", \"qty\": 2}, {\"name\": \"B\", \"qty\": 5}]'\naddresses = '[{\"city\": \"Tokyo\", \"zip\": \"160-0022\"}, {\"city\": \"Osaka\", \"zip\": \"530-0001\"}]'\n```\n*Note: Arrays of objects or nested structures are stored as JSON strings in TOML.*\n\n## Tools\n\n### 1. `extract_json`\n- **Description**: Extracts key-value pairs from arbitrary noisy text and returns them as type-safe JSON (Python dict).\n- **Arguments**:\n  - `input_text` (string): Input string containing noisy or unstructured data.\n- **Returns**: `{ \"success\": True, \"result\": ... }` or `{ \"success\": False, \"error\": ... }`\n- **Example**:\n  ```json\n  {\n    \"success\": true,\n    \"result\": { \"foo\": 1, \"bar\": \"baz\" }\n  }\n  ```\n\n### 2. `extract_yaml`\n- **Description**: Extracts key-value pairs from arbitrary noisy text and returns them as type-safe YAML (string).\n- **Arguments**:\n  - `input_text` (string): Input string containing noisy or unstructured data.\n- **Returns**: `{ \"success\": True, \"result\": ... }` or `{ \"success\": False, \"error\": ... }`\n- **Example**:\n  ```json\n  {\n    \"success\": true,\n    \"result\": \"foo: 1\\nbar: baz\"\n  }\n  ```\n\n### 3. `extract_toml`\n- **Description**: Extracts key-value pairs from arbitrary noisy text and returns them as type-safe TOML (string).\n- **Arguments**:\n  - `input_text` (string): Input string containing noisy or unstructured data.\n- **Returns**: `{ \"success\": True, \"result\": ... }` or `{ \"success\": False, \"error\": ... }`\n- **Example**:\n  ```json\n  {\n    \"success\": true,\n    \"result\": \"foo = 1\\nbar = \\\"baz\\\"\"\n  }\n  ```\n\n## Usage\n\n### Installing via Smithery\n\nTo install kv-extractor-mcp-server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@KunihiroS/kv-extractor-mcp-server):\n\n```bash\nnpx -y @smithery/cli install @KunihiroS/kv-extractor-mcp-server --client claude\n```\n\n### Requirements\n- Python 3.9+\n- API key for OpenAI models (set in `settings.json` under `env`)\n\n### Running the Server\n\n```bash\npython server.py\n```\n*In case you want to run the server manually.*\n\n## MCP Host Configuration\n\nWhen running this MCP Server, you **must explicitly specify the log output mode and (if enabled) the absolute log file path via command-line arguments**.\n\n- `--log=off` : Disable all logging (no logs are written)\n- `--log=on --logfile=/absolute/path/to/logfile.log` : Enable logging and write logs to the specified absolute file path\n- Both arguments are **required** when logging is enabled. The server will exit with an error if either is missing, the path is not absolute, or if invalid values are given.\n\n### Example: Logging Disabled\n```json\n\"kv-extractor-mcp-server\": {\n  \"command\": \"pipx\",\n  \"args\": [\"run\", \"kv-extractor-mcp-server\", \"--log=off\"],\n  \"env\": {\n    \"OPENAI_API_KEY\": \"{apikey}\"\n  }\n}\n```\n\n### Example: Logging Enabled (absolute log file path required)\n```json\n\"kv-extractor-mcp-server\": {\n  \"command\": \"pipx\",\n  \"args\": [\"run\", \"kv-extractor-mcp-server\", \"--log=on\", \"--logfile=/workspace/logs/kv-extractor-mcp-server.log\"],\n  \"env\": {\n    \"OPENAI_API_KEY\": \"{apikey}\"\n  }\n}\n```\n\n> **Note:**\n> - When logging is enabled, logs are written **only** to the specified absolute file path. Relative paths or omission of `--logfile` will cause an error.\n> - When logging is disabled, no logs are output.\n> - If the required arguments are missing or invalid, the server will not start and will print an error message.\n> - The log file must be accessible and writable by the MCP Server process.\n> - If you have trouble to run this server, it may be due to caching older version of kv-extractor-mcp-server. Please try to run it with the latest version (set `x.y.z` to the latest version) of kv-extractor-mcp-server by the below setting.\n\n```json\n\"kv-extractor-mcp-server\": {\n  \"command\": \"pipx\",\n  \"args\": [\"run\", \"kv-extractor-mcp-server==x.y.z\", \"--log=off\"],\n  \"env\": {\n    \"OPENAI_API_KEY\": \"{apikey}\"\n  }\n}\n```\n\n## License\nGPL-3.0-or-later\n\n## Author\nKunihiroS (and contributors)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "formats",
        "kunihiros",
        "extractor",
        "processing kunihiros",
        "kv extractor",
        "kunihiros kv"
      ],
      "category": "document-processing"
    },
    "LaubPlusCo--mcp-webdav-server": {
      "owner": "LaubPlusCo",
      "name": "mcp-webdav-server",
      "url": "https://github.com/LaubPlusCo/mcp-webdav-server",
      "imageUrl": "/freedevtools/mcp/pfp/LaubPlusCo.webp",
      "description": "Enable natural language interaction with WebDAV file systems to perform CRUD operations on files and directories through a secure and configurable MCP server. Supports connections with optional authentication and efficient management of file operations via multiple transport methods.",
      "stars": 9,
      "forks": 7,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-22T11:13:16Z",
      "readme_content": "# WebDAV MCP Server\n\nA Model Context Protocol (MCP) server that enables CRUD operations on a WebDAV endpoint with basic authentication. This server enables Claude Desktop and other MCP clients to interact with WebDAV file systems through natural language commands.\n\n## Features\n\n- Connect to any WebDAV server with optional authentication\n- Perform CRUD operations on files and directories\n- Expose file operations as MCP resources and tools\n- Run via stdio transport (for Claude Desktop integration) or HTTP/SSE transport\n- Secure access with optional basic authentication\n- Support for bcrypt-encrypted passwords for MCP server authentication (WebDAV passwords must be plain text due to protocol limitations)\n- Connection pooling for better performance with WebDAV servers\n- Configuration validation using Zod\n- Structured logging for better troubleshooting\n\n## Prerequisites\n\n- Node.js 18 or later\n- npm or yarn\n- WebDAV server (for actual file operations)\n\n## Installation\n\n### Option 1: Install from npm package\n\n```bash\n# Global installation\nnpm install -g webdav-mcp-server\n\n# Or with npx\nnpx webdav-mcp-server\n```\n\n### Option 2: Clone and build from source\n\n```bash\n# Clone repository\ngit clone https://github.com/yourusername/webdav-mcp-server.git\ncd webdav-mcp-server\n\n# Install dependencies\nnpm install\n\n# Build the application\nnpm run build\n```\n\n### Option 3: Docker\n\n```bash\n# Build the Docker image\ndocker build -t webdav-mcp-server .\n\n# Run the container without authentication\ndocker run -p 3000:3000 \\\n  -e WEBDAV_ROOT_URL=http://your-webdav-server \\\n  -e WEBDAV_ROOT_PATH=/webdav \\\n  webdav-mcp-server\n  \n# Run the container with authentication for both WebDAV and MCP server\ndocker run -p 3000:3000 \\\n  -e WEBDAV_ROOT_URL=http://your-webdav-server \\\n  -e WEBDAV_ROOT_PATH=/webdav \\\n  -e WEBDAV_AUTH_ENABLED=true \\\n  -e WEBDAV_USERNAME=admin \\\n  -e WEBDAV_PASSWORD=password \\\n  -e AUTH_ENABLED=true \\\n  -e AUTH_USERNAME=user \\\n  -e AUTH_PASSWORD=pass \\\n  webdav-mcp-server\n```\n\n## Configuration\n\nCreate a `.env` file in the root directory with the following variables:\n\n```env\n# WebDAV configuration\nWEBDAV_ROOT_URL=http://localhost:4080\nWEBDAV_ROOT_PATH=/webdav\n\n# WebDAV authentication (optional)\nWEBDAV_AUTH_ENABLED=true\nWEBDAV_USERNAME=admin\n\n# WebDAV password must be plain text (required when auth enabled)\n# The WebDAV protocol requires sending the actual password to the server\nWEBDAV_PASSWORD=password\n\n# Server configuration (for HTTP mode)\nSERVER_PORT=3000\n\n# Authentication configuration for MCP server (optional)\nAUTH_ENABLED=true\nAUTH_USERNAME=user\nAUTH_PASSWORD=pass\nAUTH_REALM=MCP WebDAV Server\n\n# Auth password for MCP server can be a bcrypt hash (unlike WebDAV passwords)\n# AUTH_PASSWORD={bcrypt}$2y$10$CyLKnUwn9fqqKQFEbxpZFuE9mzWR/x8t6TE7.CgAN0oT8I/5jKJBy\n```\n\n### Encrypted Passwords for MCP Server Authentication\n\nFor enhanced security of the MCP server (not WebDAV connections), you can use bcrypt-encrypted passwords instead of storing them in plain text:\n\n1. Generate a bcrypt hash:\n   ```bash\n   # Using the built-in utility\n   npm run generate-hash -- yourpassword\n   \n   # Or with npx\n   npx webdav-mcp-generate-hash yourpassword\n   ```\n\n2. Add the hash to your .env file with the {bcrypt} prefix:\n   ```\n   AUTH_PASSWORD={bcrypt}$2y$10$CyLKnUwn9fqqKQFEbxpZFuE9mzWR/x8t6TE7.CgAN0oT8I/5jKJBy\n   ```\n\nThis way, your MCP server password is stored securely. Note that WebDAV passwords must always be in plain text due to protocol requirements.\n\n## Usage\n\n### Running with stdio transport\n\nThis mode is ideal for direct integration with Claude Desktop.\n\n```bash\n# If installed globally\nwebdav-mcp-server\n\n# If using npx\nnpx webdav-mcp-server\n\n# If built from source\nnode dist/index.js\n```\n\n### Running with HTTP/SSE transport\n\nThis mode enables the server to be accessed over HTTP with Server-Sent Events for real-time communication.\n\n```bash\n# If installed globally\nwebdav-mcp-server --http\n\n# If using npx\nnpx webdav-mcp-server --http\n\n# If built from source\nnode dist/index.js --http\n```\n\n## Quick Start with Docker Compose\n\nThe easiest way to get started with both the WebDAV server and the MCP server is to use Docker Compose:\n\n```bash\n# Start both WebDAV and MCP servers\ncd docker\ndocker-compose up -d\n\n# This will start:\n# - hacdias/webdav server on port 4080 (username: admin, password: admin)\n# - MCP server on port 3000 (username: user, password: pass)\n```\n\nThis setup uses [hacdias/webdav](https://github.com/hacdias/webdav), a simple and standalone WebDAV server written in Go. The configuration for the WebDAV server is stored in `webdav_config.yml`, which you can modify to adjust permissions, add users, or change other settings.\n\nThe WebDAV server stores all files in a Docker volume called `webdav_data`, which persists across container restarts.\n\n## WebDAV Server Configuration\n\nThe `webdav_config.yml` file configures the hacdias/webdav server used in the Docker Compose setup. Here's what you can customize:\n\n```yaml\n# Server address and port\naddress: 0.0.0.0\nport: 6060\n\n# Root data directory\ndirectory: /data\n\n# Enable/disable CORS\ncors:\n  enabled: true\n  # Additional CORS settings...\n\n# Default permissions (C=Create, R=Read, U=Update, D=Delete)\npermissions: CRUD\n\n# User definitions\nusers:\n  - username: admin\n    password: admin      # Plain text password\n    permissions: CRUD    # Full permissions\n  \n  - username: reader\n    password: reader\n    permissions: R       # Read-only permissions\n    \n  # You can also use bcrypt-encrypted passwords\n  - username: secure\n    password: \"{bcrypt}$2y$10$zEP6oofmXFeHaeMfBNLnP.DO8m.H.Mwhd24/TOX2MWLxAExXi4qgi\"\n```\n\nFor more advanced configuration options, refer to the [hacdias/webdav documentation](https://github.com/hacdias/webdav).\n\n## Testing\n\nTo run the tests:\n\n```bash\nnpm test\n```\n\n## Integrating with Claude Desktop\n\n1. Ensure the MCP feature is enabled in Claude Desktop\n\n<details>\n<summary>Using npx</summary>\n2. Open Claude Desktop settings and click edit config (`claude_desktop_config.json`)\n3. Add\n```json\n{\n    \"mcpServers\": {\n        \"webdav\": {\n            \"command\": \"npx\",\n            \"args\": [\n                \"-y\",\n                \"webdav-mcp-server\"\n            ],\n            \"env\": {\n                \"WEBDAV_ROOT_URL\": \"<WEBDAV_ROOT_URL>\",\n                \"WEBDAV_ROOT_PATH\": \"<WEBDAV_ROOT_PATH>\",\n                \"WEBDAV_USERNAME\": \"<WEBDAV_USERNAME>\",\n                \"WEBDAV_PASSWORD\": \"<WEBDAV_PASSWORD>\",\n                \"WEBDAV_AUTH_ENABLED\": \"true|false\"\n            }\n        }\n    }\n}\n```\n</details>\n<details>\n<summary>Using node and local build</summary>\n2. Clone this repository and run `setup.sh` on mac/linux or `setup.bat` on windows\n3. Open Claude Desktop settings and click edit config (`claude_desktop_config.json`)\n4. Add\n```json\n{\n    \"mcpServers\": {\n        \"webdav\": {\n            \"command\": \"node\",\n            \"args\": [\n                \"<path to repository>/dist/index.js\"\n            ],\n            \"env\": {\n                \"WEBDAV_ROOT_URL\": \"<WEBDAV_ROOT_URL>\",\n                \"WEBDAV_ROOT_PATH\": \"<WEBDAV_ROOT_PATH>\",\n                \"WEBDAV_USERNAME\": \"<WEBDAV_USERNAME>\",\n                \"WEBDAV_PASSWORD\": \"<WEBDAV_PASSWORD>\",\n                \"WEBDAV_AUTH_ENABLED\": \"true|false\"\n            }\n        }\n    }\n}\n```\n</details>\n\n## Available MCP Resources\n\n- `webdav://{path}/list` - List files in a directory\n- `webdav://{path}/content` - Get file content\n- `webdav://{path}/info` - Get file or directory information\n\n## Available MCP Tools\n\n- `webdav_create_remote_file` - Create a new file on a remote WebDAV server\n- `webdav_get_remote_file` - Retrieve content from a file stored on a remote WebDAV server\n- `webdav_update_remote_file` - Update an existing file on a remote WebDAV server\n- `webdav_delete_remote_item` - Delete a file or directory from a remote WebDAV server\n- `webdav_create_remote_directory` - Create a new directory on a remote WebDAV server\n- `webdav_move_remote_item` - Move or rename a file/directory on a remote WebDAV server\n- `webdav_copy_remote_item` - Copy a file/directory to a new location on a remote WebDAV server\n- `webdav_list_remote_directory` - List files and directories on a remote WebDAV server\n\n## Available MCP Prompts\n\n- `webdav_create_remote_file` - Prompt to create a new file on a remote WebDAV server\n- `webdav_get_remote_file` - Prompt to retrieve content from a remote WebDAV file\n- `webdav_update_remote_file` - Prompt to update a file on a remote WebDAV server\n- `webdav_delete_remote_item` - Prompt to delete a file/directory from a remote WebDAV server\n- `webdav_list_remote_directory` - Prompt to list directory contents on a remote WebDAV server\n- `webdav_create_remote_directory` - Prompt to create a directory on a remote WebDAV server\n- `webdav_move_remote_item` - Prompt to move/rename a file/directory on a remote WebDAV server\n- `webdav_copy_remote_item` - Prompt to copy a file/directory on a remote WebDAV server\n\n## Example Queries in Claude\n\nHere are some example queries you can use in Claude Desktop once the WebDAV MCP server is connected:\n\n- \"List files on my remote WebDAV server\"\n- \"Create a new text file called notes.txt on my remote WebDAV server with the following content: Hello World\"\n- \"Get the content of document.txt from my remote WebDAV server\"\n- \"Update config.json on my remote WebDAV server with this new configuration\"\n- \"Create a directory called projects on my remote WebDAV server\"\n- \"Copy report.docx to a backup location on my remote WebDAV server\"\n- \"Move the file old_name.txt to new_name.txt on my remote WebDAV server\"\n- \"Delete temp.txt from my remote WebDAV server\"\n\n## Programmatic Usage\n\nYou can also use this package programmatically in your own projects:\n\n```javascript\nimport { startWebDAVServer } from 'webdav-mcp-server';\n\n// For stdio transport without authentication\nawait startWebDAVServer({\n  webdavConfig: {\n    rootUrl: 'http://your-webdav-server',\n    rootPath: '/webdav',\n    authEnabled: false\n  },\n  useHttp: false\n});\n\n// For stdio transport with WebDAV authentication (password must be plain text)\nawait startWebDAVServer({\n  webdavConfig: {\n    rootUrl: 'http://your-webdav-server',\n    rootPath: '/webdav',\n    authEnabled: true,\n    username: 'admin',\n    password: 'password'\n  },\n  useHttp: false\n});\n\n// With bcrypt hash for MCP server password (HTTP auth only)\nawait startWebDAVServer({\n  webdavConfig: {\n    rootUrl: 'http://your-webdav-server',\n    rootPath: '/webdav',\n    authEnabled: true,\n    username: 'admin',\n    password: 'password' // WebDAV password must be plain text\n  },\n  useHttp: true,\n  httpConfig: {\n    port: 3000,\n    auth: {\n      enabled: true,\n      username: 'user',\n      password: '{bcrypt}$2y$10$CyLKnUwn9fqqKQFEbxpZFuE9mzWR/x8t6TE7.CgAN0oT8I/5jKJBy'\n    }\n  }\n});\n\n// For HTTP transport with MCP authentication\nawait startWebDAVServer({\n  webdavConfig: {\n    rootUrl: 'http://your-webdav-server',\n    rootPath: '/webdav',\n    authEnabled: true,\n    username: 'admin',\n    password: 'password'\n  },\n  useHttp: true,\n  httpConfig: {\n    port: 3000,\n    auth: {\n      enabled: true,\n      username: 'user',\n      password: 'pass',\n      realm: 'MCP WebDAV Server'\n    }\n  }\n});\n\n// For HTTP transport without authentication\nawait startWebDAVServer({\n  webdavConfig: {\n    rootUrl: 'http://your-webdav-server',\n    rootPath: '/webdav',\n    authEnabled: false\n  },\n  useHttp: true,\n  httpConfig: {\n    port: 3000,\n    auth: {\n      enabled: false\n    }\n  }\n});\n```\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "webdav",
        "files",
        "document",
        "mcp webdav",
        "webdav server",
        "webdav file"
      ],
      "category": "document-processing"
    },
    "Layr-Labs--eigenlayer-mcp-server": {
      "owner": "Layr-Labs",
      "name": "eigenlayer-mcp-server",
      "url": "https://github.com/Layr-Labs/eigenlayer-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/Layr-Labs.webp",
      "description": "Provides detailed EigenLayer documentation to AI assistants through a dedicated server interface, enabling seamless integration and querying of EigenLayer concepts and mechanisms.",
      "stars": 1,
      "forks": 1,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-07-22T17:33:19Z",
      "readme_content": "# EigenLayer MCP Server built on Next.js\n\n\n## Features\n\n- Provides EigenLayer documentation to Claude or other AI assistants via MCP\n- Runs as a standalone server locally or as a serverless function on Vercel\n\nInspired by initial testing [here](https://x.com/dabit3/status/1902502245855383724).\nCloned from [Vercel Next.js MCP template](https://vercel.com/templates/next.js/model-context-protocol-mcp-with-next-js)\n\n\n# Test the public endpoint with Claude:\n\n1) Add the live URL to Claude via the following command (in any folder):  \n   ```claude mcp add --transport sse eigenlayer-mcp-server https://eigenlayer-mcp-server-sand.vercel.app/sse```\n2) Install [Claude Code](https://docs.anthropic.com/en/docs/agents-and-tools/claude-code/overview). Run command `claude` to enter Claude Code and confirm the  mcp server is added\n3) Test with a query like \"Can you explain how EigenLayer's restaking mechanism works?\"\n\n\n# Build, Run, Testing Locally\n\nIn terminal window 1\n```\nrm -rf .next node_modules .vercel\npnpm store prune\npnpm install\npnpm build\npnpm dev\n\nnode scripts/test-client.mjs https://localhost:3000\n```\n\nIn terminal window 2\nTest with MCP Inspector\n```\nnpx @modelcontextprotocol/inspector node public/index.js\n```\nAdditional notes [here](https://github.com/modelcontextprotocol/inspector).\n\n\n## Add to Claude Code\n\n```\nclaude mcp add\n```\n(then follow on screen instructions)\n\n## Sample Client\n\n`script/test-client.mjs` contains a sample client to try invocations.\n\n```sh\nnode scripts/test-client.mjs http://localhost:3000\n```\n\n\n## Security Bugs\nPlease report security vulnerabilities to security@eigenlabs.org. Do NOT report security bugs via Github Issues.\n\n## Disclaimer\n🚧 EigenLayer MCP Server is under active development and has not been audited. EigenLayer MCP Server is rapidly being upgraded, features may be added, removed or otherwise improved or modified and interfaces will have breaking changes. EigenLayer MCP Server should be used only for testing purposes and not in production. EigenLayer MCP Server is provided \"as is\" and Eigen Labs, Inc. does not guarantee its functionality or provide support for its use in production. 🚧\n\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "eigenlayer",
        "documentation",
        "processing",
        "eigenlayer documentation",
        "labs eigenlayer",
        "eigenlayer mcp"
      ],
      "category": "document-processing"
    },
    "Levis0045--ntealan-apis-mcp-server": {
      "owner": "Levis0045",
      "name": "ntealan-apis-mcp-server",
      "url": "https://github.com/Levis0045/ntealan-apis-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/Levis0045.webp",
      "description": "Manage dictionary data, articles, and user contributions through a modular and extensible interface. Supports asynchronous operations for efficient integration with NTeALan REST APIs.",
      "stars": 0,
      "forks": 1,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-05-01T17:38:00Z",
      "readme_content": "<div align=\"center\">\n\n\n \n<span style=\"font-weight: bold\"> <strong>NTeALan dictionaries MCP Server</strong></span> is a modular, extensible <a href=\"https://modelcontextprotocol.io/\"> Model Context Protocol (MCP) </a> server for [NTeALan REST APIs dictionaries](https://apis.ntealan.net/ntealan) and contributions. This project provides a unified interface for managing dictionary data, articles, and user contributions, and is designed for easy integration and extension.\n\nThe project is deployed at [https://apis.ntealan.net/ntealan/mcpserver](https://apis.ntealan.net/ntealan/mcpserver). Add `/sse` path to connect to a MCP client. Only resource actions can be used now.\n\n⚠️ This dev endpoint could be unavailable sometimes. Just create an issue and we will work on it.\n\n[![smithery badge](https://smithery.ai/badge/@Levis0045/ntealan-apis-mcp-server)](https://smithery.ai/server/@Levis0045/ntealan-apis-mcp-server)\n\n[![PyPI][pypi-badge]][pypi-url]\n[![MIT licensed][mit-badge]][mit-url]\n[![Documentation][docs-badge]][docs-url]\n\n</div>\n\n---\n\n## 🦜 Table of Contents\n\n- [Features](#features)\n- [Getting Started](#getting-started)\n  - [Prerequisites](#prerequisites)\n  - [Installation](#installation)\n  - [Running the Server](#running-the-server)\n- [Project Structure](#project-structure)\n- [Usage](#usage)\n  - [Resources](#primitive-resources)\n  - [Tools](#primitive-tools)\n- [Contributing](#contributing)\n- [Contact](#contact)\n\n---\n\n## 🦜 Features\n\n- **Dictionary Management**: Create, update, delete, and retrieve dictionaries and their metadata.\n- **Article Management**: Manage articles within dictionaries, including statistics and filtering.\n- **Contribution Management**: Track and manage user contributions to articles and dictionaries.\n- **Extensible MCP Server**: Easily add new resources and tools.\n- **Async Support**: Built on top of `fastmcp` and `aiohttp` for high performance.\n- **OpenAPI-like Resource Registration**: Register resources and tools with URIs and tags.\n\n---\n\n## 🦜 Getting Started\n\n### Prerequisites\n\n- Python 3.11+\n- [uv](https://github.com/astral-sh/uv)\n- [aiohttp](https://docs.aiohttp.org/)\n- [pydantic](https://docs.pydantic.dev/)\n- [fastmcp](https://gofastmcp.com/getting-started/welcome) (or your fork)\n- [aiodns](https://github.com/saghul/aiodns)\n- [python-dotenv](https://github.com/theskumar/python-dotenv)\n\n### Installation\n\n\n#### Installing via pip\n\nClone the repository and install dependencies:\n\n```bash\ngit clone https://github.com/Levis0045/ntealan-apis-mcp-server.git\ncd ntealan-apis-mcp-server\npip install .\n```\n\n#### (Optional) Install and use [uv](https://github.com/astral-sh/uv) for faster dependency management\n\nIf you want faster installs and modern Python packaging, you can use [uv](https://github.com/astral-sh/uv) in the `ntealan-apis-mcp-server` directory:\n\n```bash\nuv sync\n```\n\n### Running the Server\n\nTo start the MCP server:\n\n```bash\npython -m ntealanmcp -t stdio\n```\n\nOr, if you have [uv](https://github.com/astral-sh/uv) installed, you can run server command:\n\n```bash\nntealanmcp -t stdio\n```\n\nThe server will run using the `Server-Sent Events (sse)` transport by default at this endpoint `http://127.0.0.1:8000/sse`. You can modify the transport in `main.py` if needed.\n\n---\n\n## 🦜 Project Structure\n\n```\nntealan-api/\n├── src/\n│   └── ntealan_apis_mcp/\n│       ├── main.py\n│       ├── models/\n│       │   ├── article.py\n│       │   ├── contribution.py\n│       │   ├── dictionary.py\n│       │   └── common.py\n│       ├── primitives/\n│       |    ├── resources/\n│       │    │   ├── article.py\n│       │    │   ├── contribution.py\n│       │    │   └── dictionary.py\n│       |    └── tools/\n│       |        ├── article.py\n│       |        ├── contribution.py\n│       |        └── dictionary.py\n│       └── common/\n│           ├── utils.py\n│           ├── cache.py\n│           └── http_session.py\n├── examples/\n├── tests/\n├── pyproject.toml\n└── requirements.txt\n```\n\n---\n\n## 🦜 Usage\n\n### Primitive resources\n\nResources are asynchronous functions that expose public Data from NTeALan API endpoints for  dictionaries, articles, and contributions. They are registered with the MCP server and can be called via their custom URIs.\n\nExample resource registration:\n\n```python\nntl_mcp_server.add_resource_fn(\n    lambda dictionary_id, article_id, params: get_article_by_id(\n        dictionary_id, article_id, params, ntl_mcp_server.get_context()\n    ),\n    name=\"get_article_by_id\",\n    uri=\"ntealan-apis://articles/dictionary/{dictionary_id}/{article_id}?{params}\",\n    tags=[\"article-endpoint\", \"mcp-resource\"],\n    mime_type=\"application/json\",\n    description=\"Get an article by ID\"\n)\n\n# or just use the classic integration\n@ntl_mcp_server.resource(\n    uri=\"ntealan-apis://articles/dictionary/{dictionary_id}/{article_id}?{params}\",\n    tags=[\"article-endpoint\", \"mcp-resource\"],\n    mime_type=\"application/json\"\n)\nasync def get_article_by_id(\n    dictionary_id: str, article_id: UUID,\n    params: str, ctx: Context\n) -> McpResourceResponse:\n    \"\"\"\n    Retrieve a article by its unique identifier.\n    \"\"\"\n    # Placeholder logic\n    return {\"status\": \"OK\", \"data\": f\"Hello, {article_id}!\"}\n\n```\n\nList of existings resources and status:\n\n| Name / URI Pattern                                                        | Description                                      | Parameters                                      | Development Status   |\n|---------------------------------------------------------------------------|--------------------------------------------------|-------------------------------------------------|---------------------|\n| `ntealan-apis://dictionaries/dictionary/{dictionary_id}`                  | Get dictionary metadata by ID                     | `dictionary_id`                                 | Stable              |\n| `ntealan-apis://dictionaries?limit=2`                                     | Get all dictionaries metadata                     | `limit`                                         | Stable              |\n| `ntealan-apis://dictionaries/statistics/{dictionary_id}`                  | Get statistics for a specific dictionary          | `dictionary_id`                                 | Stable              |\n| `ntealan-apis://dictionaries/statistics`                                  | Get statistics for all dictionaries               | None                                            | Stable              |\n| `ntealan-apis://articles/dictionary/{dictionary_id}/{article_id}?none`    | Get article by ID                                 | `dictionary_id`, `article_id`                   | Stable              |\n| `ntealan-apis://articles?limit=2`                                         | Get all articles                                  | `limit`                                         | Stable              |\n| `ntealan-apis://articles/dictionary/{dictionary_id}?limit=2`              | Get all articles for a dictionary                 | `dictionary_id`, `limit`                        | Stable              |\n| `ntealan-apis://articles/statistics/{dictionary_id}`                      | Get article statistics for a dictionary           | `dictionary_id`                                 | Stable              |\n| `ntealan-apis://articles/statistics`                                      | Get statistics for all articles                   | None                                            | Not stable          |\n| `ntealan-apis://contributions/{dictionary_id}/{contribution_id}`          | Get contribution by ID                            | `dictionary_id`, `contribution_id`              | Stable              |\n| `ntealan-apis://greeting/Elvis`                                           | Greeting resource                                 | `name`                                          | Stable              |\n| `ntealan-apis://articles/dictionaries/search/{dictionary_id}?q=mba&page=1&limit=1` | Search articles in a dictionary                   | `dictionary_id`, `q`, `page`, `limit`           | Stable              |\n| `ntealan-apis://articles/search?q=mba&page=1`                             | Search articles                                  | `q`, `page`                                     | Stable              |\n| `ntealan-apis://dictionaries/search?q=yemb&page=1&limit=1`                | Search dictionaries                              | `q`, `page`, `limit`                            |  Stable              |\n\n### Primitive tools\n\nTools are utility functions for creating, updating, and deleting dictionaries, articles, and contributions.\n\nExample tool registration:\n\n```python\nntl_mcp_server.add_tool(\n    create_dictionary,\n    description=\"Create a new dictionary\",\n    tags=[\"mcp-tool\", \"dictionary-endpoint\"]\n)\n```\n\nList of existings tools and status (NOT YET IMPLEMENTED):\n\n\n| Tool Name              | Description                        | Required Payload Fields                                      | Development Status   |\n|------------------------|------------------------------------|-------------------------------------------------------------|---------------------|\n| `create_dictionary`    | Create a new dictionary            | `data` (dictionary fields)                                  | Not started              |\n| `update_dictionary`    | Update an existing dictionary      | `dictionary_id`, `data` (fields to update)                  | Not started              |\n| `delete_dictionary`    | Delete a dictionary                | `dictionary_id`                                             | Not started              |\n| `create_article`       | Create a new article               | `dictionary_id`, `data` (article fields)                    | Not started              |\n| `update_article`       | Update an article                  | `dictionary_id`, `article_id`, `data` (fields to update)    | Not started              |\n| `delete_article`       | Delete an article                  | `dictionary_id`, `article_id`                               | Not started              |\n| `create_contribution`  | Create a new contribution          | `dictionary_id`, `article_id`, `data` (contribution fields) | Not started              |\n| `update_contribution`  | Update a contribution              | `dictionary_id`, `article_id`, `contribution_id`, `data`    | Not started              |\n| `delete_contribution`  | Delete a contribution              | `dictionary_id`, `article_id`, `contribution_id`            | Not started              |\n\n\n### Run examples\n\nCheck `examples/` folder to run and test some samples.\n\n```bash\n# for all resources\nuv run examples/run_client_resources.py -t sse -e prod -s 8\n# for all tools\nuv run examples/run_client_tools.py -t stdio -e local -s 0\n```\n\nYou can get docs on :\n\n```bash\n# for all resources\nuv run examples/run_client_resources.py -h\n# for all tools\nuv run examples/run_client_tools.py -h\n```\n\n### Deploying with Docker\n\nYou can deploy the MCP server using Docker and serve it behind an Nginx reverse proxy for production environments.\n\n#### 1. Build the Docker image\n\nBuild the Docker image manually:\n\n```bash\ndocker build -t ntealan-mcp-server .\n```\n\n#### 2. Or automatically build and start the service\n\n- Get and check the latest version of compose and Docker. You will get in response `Docker Compose version v2.35.1`.\n\n```bash\ndocker compose version\n```\n- Build and start the service\n\n```bash\ndocker compose up --build -d\n```\n\n- Your MCP server will now be accessible at this address `http://0.0.0.0:8000` or your configured domain.\n\n- Connect with MCP Client at `http://127.0.0.1:8000/sse` or your configured domain.\n\n\n### Connect with Smithery\n\n- Install mcp cli \n\n```bash\nuv add \"mcp[cli]\"\n```\n\n- Connect with MCP client \n\n```python\nimport mcp\nfrom mcp.client.websocket import websocket_client\nimport json\nimport base64\n\nsmithery_api_key = \"your-api-key\"\nurl = f\"wss://server.smithery.ai/@Levis0045/ntealan-apis-mcp-server/ws?api_key={smithery_api_key}\"\n\nasync def main():\n    # Connect to the server using websocket client\n    async with websocket_client(url) as streams:\n        async with mcp.ClientSession(*streams) as session:\n            # Initialize the connection\n            await session.initialize()\n            # List available tools\n            tools_result = await session.list_tools()\n            print(f\"Available tools: {', '.join([t.name for t in tools_result.tools])}\")\n\n            # Example of calling a tool:\n            # result = await session.call_tool(\"tool-name\", arguments={\"arg1\": \"value\"})\n\nif __name__ == \"__main__\":\n    import asyncio\n    asyncio.run(main())\n```\n\n---\n\n## 🦜 Contributing\n\nGet more informations in this file: [CONTRIBUTION.md](CONTRIBUTION.md)\n\n\n## 🦜 Contact\n\n- **Project Lead**: Elvis Mboning@[NTeALan](https://ntealan.org/)\n- **NTeALan APIs documentation**: [https://apis.ntealan.net/ntealan](https://apis.ntealan.net/ntealan)\n- **GitHub Issues**: [https://github.com/Levis0045/ntealan-apis-mcp-server/issues](https://github.com/Levis0045/ntealan-apis-mcp-server/issues)\n- **Email**: contact@ntealan.org\n\n\n[pypi-badge]: https://img.shields.io/pypi/v/mcp.svg\n[pypi-url]: https://pypi.org/project/ntealan_apis_mcp/\n[mit-badge]: https://img.shields.io/pypi/l/mcp.svg\n[mit-url]: https://github.com/Levis0045/ntealan-apis-mcp-server/blob/v1/LICENSE\n[docs-badge]: https://img.shields.io/badge/docs-modelcontextprotocol.io-blue.svg\n[docs-url]: https://raw.githubusercontent.com/Levis0045/ntealan-apis-mcp-server/refs/heads/v1/README.md\n[spec-url]: https://github.com/Levis0045/ntealan-apis-mcp-server/blob/v1/README.md\n[python-url]: https://www.python.org/downloads/",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "apis",
        "ntealan",
        "document",
        "ntealan apis",
        "ntealan rest",
        "apis mcp"
      ],
      "category": "document-processing"
    },
    "M-Gonzalo--cosa-sai": {
      "owner": "M-Gonzalo",
      "name": "cosa-sai",
      "url": "https://github.com/M-Gonzalo/cosa-sai",
      "imageUrl": "/freedevtools/mcp/pfp/M-Gonzalo.webp",
      "description": "Access documentation for a variety of technologies through the Gemini API, leveraging a curated knowledge base to provide accurate responses to complex queries. This server is designed to handle large context windows for improved comprehension of technical materials.",
      "stars": 13,
      "forks": 2,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-05-23T00:21:06Z",
      "readme_content": "# Gemini Docs MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@M-Gonzalo/cosa-sai)](https://smithery.ai/server/@M-Gonzalo/cosa-sai)\n\n## Description\n\nThis project implements an MCP server that enables access to documentation for various technologies using the Gemini API with its gigantic context window of 2M tokens. It should work for any client, but is targeted especially to the Roo/Cline environment.\n\nThis approach offers several advantages over simply browsing the web or using a search engine:\n\n*   **Access to a curated knowledge base:** The LLM uses a specific set of documentation, avoiding junk results and false positives that can confuse the model.\n*   **Overcomes context window limitations:** By providing the documentation directly, the LLM can access more information than would be possible with web search alone.\n*   **Tailored and well-thought-out responses:** The LLM doesn't just provide snippets from the documentation, but crafts well-reasoned answers that take into consideration the entire specification for the technology in question. This allows for more complex questions like \"what alternative ways of doing X are there?\" or \"is this snippet idiomatic?\".\n\nIt also overcomes some problemmatic hurdles of traditional RAG systems:\n\n*   **No need for chunking:** The LLM can access the entire documentation in one go, without needing to chunk it into smaller pieces, and having to painfully test and choose between all the possible ways of doing so.\n*   **No need for a retriever:** The Gemini API itself serves as a powerful retriever that can access the entire documentation, so there's no need to implement a custom one.\n*   **No vectorization, vector DBs, or other complex systems:** We work directly with plain text, and since we can see everything at once, we don't need vectors for similarity search. If it's relevant, we know about it.\n\nThere are some limitations, though:\n\n*   **No real-time updates:** The documentation is static and won't be updated in real time. This means that the LLM might not know about the latest features or changes in the technology unless we manually update the documentation or provide an automated way of doing so.\n*   **A lot of tokens is not the same as an infinite context window:** The LLM can only see about 2 million tokens at a time, so it might not be able to see the entire documentation for some technologies. This is especially true for large and complex stacks with copious amounts of documentation.\n*   **It's not that fast:** We're using Gemini 1.5 Pro (not Flash), and we're loading it with a whole bunch of documentation, so it might take a while to get a response. This is especially true for the first query, as the server needs to upload the documentation to the API.\n\n## Features\n\n*   Enables clients to take an \"ask your docs\" approach to learning and debugging for an arbitrary number of technologies, including some obscure or lesser-known ones.\n*   Uses the Gemini API to answer questions about the documentation.\n*   Supports multiple tools for querying the documentation:\n    *   `can_x_be_done`: Check if a specific task can be done in a given technology.\n    *   `hints_for_problem`: Get hints for solving a specific problem.\n    *   `is_this_good_practice`: Check if a code snippet follows good practices.\n    *   `how_to_do_x`: Get examples and alternative approaches for a specific task.\n*   Provides a logging system for debugging (enabled with the `--verbose` flag).\n\n## Getting Started\n\n### Installing via Smithery\n\nTo install Gemini Docs Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@M-Gonzalo/cosa-sai):\n\n```bash\nnpx -y @smithery/cli install @M-Gonzalo/cosa-sai --client claude\n```\n\nThis MCP server is automatically started and managed by the client. To enable it, you need to configure it in your settings file (for example, `~/.config/Code/User/globalStorage/rooveterinaryinc.roo-cline/settings/cline_mcp_settings.json`). There's usually a button for opening up the settings file in the client.\n\nHere's the configuration for this server:\n\n```json\n{\n  \"command\": \"bun\",\n  \"args\": [\n    \"--watch\",\n    \"path/to/repo/cosa-sai-mcp/src/index.ts\",\n    \"--verbose\"\n  ],\n  \"env\": {\n    \"GEMINI_API_KEY\": \"<your_gemini_api_key>\"\n  },\n  \"disabled\": false,\n  \"alwaysAllow\": [\n    \"can_x_be_done\",\n    \"hints_for_problem\",\n    \"is_this_good_practice\",\n    \"how_to_do_x\"\n  ],\n  \"timeout\": 60 // in seconds\n}\n```\n\n## Procuring and Sanitizing the Knowledge Base\n\nThis MCP server requires a knowledge base of documentation to answer questions. You must manually procure this knowledge base, either by downloading a public repository, scraping a website, or using other methods.\n\nAn optional sanitation process can be performed to clean up the original documentation from styling and other unnecessary content.\n\nHere are some basic tools for doing so. Better solutions are encouraged:\n\n**Naive Scrapper:**\n\n```bash\nwget --mirror --convert-links --adjust-extension --page-requisites --no-parent --directory-prefix=./local_copy --no-verbose --show-progress $1\n```\n\n**Quick and Dirty Conversor to Markdown-ish:**\n\n```bash\n#!/bin/bash\n\ndirectory=\"${1:-.}\"  # Default to current directory if no argument is provided\noutput_file=\"${2:-concatenated.md}\"  # Default output file name\n\necho \"Concatenating files in '$directory' into '$output_file'...\"\n\n# Clear output file if it exists\ntruncate -s 0 \"$output_file\"\n\n# Find all files (excluding directories) and process them\nfind \"$directory\" -type f -name '*.html' | while IFS= read -r file; do\n    echo \"=== ${file#./} ===\" >> \"$output_file\"\n    cat \"$file\" \\\n    | grep -v 'base64' \\\n    | html2markdown >> \"$output_file\"\n    echo -e \"\\n\" >> \"$output_file\"\ndone\n\necho \"Done! Output saved to '$output_file'\"\n```\n\n## Usage\n\nThis server provides the following tools:\n\n*   **can\\_x\\_be\\_done:** Checks if a specific task can be done in a given technology.\n    *   **Input:** `docs`, `prompt`, `x`, `technology`\n    *   **Output:** `success`, `data`\n*   **hints\\_for\\_problem:** Gets hints for solving a specific problem.\n    *   **Input:** `docs`, `prompt`, `problem`, `context`, `environment`\n    *   **Output:** `success`, `data`\n*   **is\\_this\\_good\\_practice:** Checks if a code snippet follows good practices.\n    *   **Input:** `docs`, `prompt`, `snippet`, `context`\n    *   **Output:** `success`, `data`\n*   **how\\_to\\_do\\_x:** Gets examples and alternative approaches for a specific task.\n    *   **Input:** `docs`, `prompt`, `x`, `technology`\n    *   **Output:** `success`, `data`\n\n## Contributing\n\nContributions are welcome! Please follow these guidelines:\n\n1.  Fork the repository.\n2.  Create a new branch for your feature or bug fix.\n3.  Make your changes and commit them with descriptive commit messages.\n4.  Submit a pull request.\n\n## License\n\nThis project is licensed under the MIT License.\n\n## Disclaimer\n\nThis is a very early version of the project, and it's likely to have bugs and limitations. Please report any issues you find, and feel free to suggest improvements or new features.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "documentation",
        "document",
        "api",
        "documentation variety",
        "access documentation",
        "document processing"
      ],
      "category": "document-processing"
    },
    "MKhalusova--unstructured-mcp": {
      "owner": "MKhalusova",
      "name": "unstructured-mcp",
      "url": "https://github.com/MKhalusova/unstructured-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/MKhalusova.webp",
      "description": "Enable extraction and utilization of content from various unstructured document formats, supporting seamless storage and retrieval via AWS S3. Process documents directly in applications to enhance data extraction capabilities for LLMs.",
      "stars": 6,
      "forks": 5,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-05-21T18:55:48Z",
      "readme_content": "A Model Context Protocol server that provides unstructured document processing capabilities. \nThis server enables LLMs to extract and use content from an unstructured document.\n\n**This repo is work in progress, proceed with caution :)**\n\nSupported file types:\n\n```\n{\".abw\", \".bmp\", \".csv\", \".cwk\", \".dbf\", \".dif\", \".doc\", \".docm\", \".docx\", \".dot\",\n \".dotm\", \".eml\", \".epub\", \".et\", \".eth\", \".fods\", \".gif\", \".heic\", \".htm\", \".html\",\n \".hwp\", \".jpeg\", \".jpg\", \".md\", \".mcw\", \".mw\", \".odt\", \".org\", \".p7s\", \".pages\",\n \".pbd\", \".pdf\", \".png\", \".pot\", \".potm\", \".ppt\", \".pptm\", \".pptx\", \".prn\", \".rst\",\n \".rtf\", \".sdp\", \".sgl\", \".svg\", \".sxg\", \".tiff\", \".txt\", \".tsv\", \".uof\", \".uos1\",\n \".uos2\", \".web\", \".webp\", \".wk2\", \".xls\", \".xlsb\", \".xlsm\", \".xlsx\", \".xlw\", \".xml\",\n \".zabw\"}\n```\n\nPrerequisites: \nYou'll need:\n* Unstructured API key. [Learn how to obtain one here](https://docs.unstructured.io/api-reference/partition/overview#get-started)\n* Claude Desktop installed locally\n\nQuick TLDR on how to add this MCP to your Claude Desktop:\n1. Clone the repo and set up the UV environment.\n2. Create a `.env` file in the root directory and add the following env variable: `UNSTRUCTURED_API_KEY`.\n3. Run the MCP server: `uv run doc_processor.py`\n4. Go to `~/Library/Application Support/Claude/` and create a `claude_desktop_config.json`. In that file add:\n```\n{\n    \"mcpServers\": {\n        \"unstructured_doc_processor\": {\n            \"command\": \"PATH/TO/YOUR/UV\",\n            \"args\": [\n                \"--directory\",\n                \"ABSOLUTE/PATH/TO/YOUR/unstructured-mcp/\",\n                \"run\",\n                \"doc_processor.py\"\n            ],\n            \"disabled\": false\n        }\n    }\n}\n```\n5. Restart Claude Desktop. You should now be able to use the MCP.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "unstructured",
        "documents",
        "s3",
        "unstructured document",
        "unstructured mcp",
        "document processing"
      ],
      "category": "document-processing"
    },
    "MaitreyaM--FILE-CONVERTER-MCP": {
      "owner": "MaitreyaM",
      "name": "FILE-CONVERTER-MCP",
      "url": "https://github.com/MaitreyaM/FILE-CONVERTER-MCP",
      "imageUrl": "/freedevtools/mcp/pfp/MaitreyaM.webp",
      "description": "Convert documents between various formats using Pandoc, enabling seamless integration and automation in workflows. Supports a wide range of formats including Markdown, DOCX, HTML, PDF, and EPUB.",
      "stars": 5,
      "forks": 5,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-08-09T18:03:55Z",
      "readme_content": "# Pandoc MCP Server\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT) <!-- Optional: Add a license badge -->\n[![smithery badge](https://smithery.ai/badge/@MaitreyaM/file-converter-mcp)](https://smithery.ai/server/@MaitreyaM/file-converter-mcp)\n\nA Python-based MCP (Model Context Protocol) server that provides powerful document conversion capabilities via Pandoc. This server allows AI agents (like Claude via LangChain/LangGraph) to request file conversions between various formats such as Markdown, DOCX, HTML, PDF, EPUB, and many more.\n\nThis project uses:\n\n*   **[FastMCP](https://github.com/model-context-protocol/mcp-py/blob/main/docs/fastmcp.md):** A Python library for easily creating MCP servers.\n*   **[pypandoc](https://github.com/NicklasTegner/pypandoc):** A Python wrapper around the Pandoc command-line tool.\n*   **[Pandoc](https://pandoc.org/):** The universal document converter.\n*   **(Optional) Docker:** For containerized deployment, bundling all dependencies (Python, Pandoc, LaTeX).\n\n## Features\n\n*   Exposes a single MCP tool: `convert_document`.\n*   Supports a wide range of input and output formats handled by Pandoc.\n*   Allows specifying input format (if auto-detection fails) and output format.\n*   Supports passing extra command-line arguments to Pandoc for advanced control (e.g., Table of Contents, PDF margins, standalone files).\n*   Includes Docker configuration (`Dockerfile`) for creating a self-contained server environment including Pandoc and necessary LaTeX components for PDF generation.\n*   Designed for integration with MCP clients, particularly LangChain/LangGraph agents.\n\n## Exposed MCP Tool\n\n### `convert_document`\n\nConverts a document from one format to another using Pandoc.\n\n**Arguments:**\n\n*   `input_file_path` (str, **required**): The path *accessible by the server* to the input document file. If running in Docker with a volume mount, this should be the path *inside the container* (e.g., `/data/my_doc.docx`).\n*   `output_file_path` (str, **required**): The path *accessible by the server* where the converted output file should be saved. If running in Docker, this should be the path *inside the container* (e.g., `/data/my_output.pdf`). The directory will be created if it doesn't exist within the server's accessible filesystem.\n*   `to_format` (str, **required**): The target format for the conversion (e.g., 'markdown', 'docx', 'pdf', 'html', 'rst', 'epub'). See [Pandoc documentation](https://pandoc.org/MANUAL.html#general-options) for a full list (`--list-output-formats`).\n*   `from_format` (str, *optional*): The format of the input file. If `None`, pandoc will try to guess from the file extension. Specify if the extension is ambiguous or missing (e.g., 'md', 'docx', 'html'). Defaults to `None`.\n*   `extra_args` (List[str], *optional*): A list of additional command-line arguments to pass directly to pandoc (e.g., `['--toc']`, `['-V', 'geometry:margin=1.5cm']`, `['--standalone']`). Defaults to `None`.\n\n**Returns:**\n\n*   (str): A message indicating success (e.g., \"Successfully converted document to '/data/my_output.pdf'\") or an error message (e.g., \"Error: Input file not found...\", \"Error during conversion: Pandoc died...\").\n\n## Setup and Running\n\nYou can run this server either locally (requires manual installation of dependencies) or using the provided Docker configuration (recommended for ease of use and deployment).\n\n### Installing via Smithery\n\nTo install Pandoc Document Converter for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@MaitreyaM/file-converter-mcp):\n\n```bash\nnpx -y @smithery/cli install @MaitreyaM/file-converter-mcp --client claude\n```\n\n### Option 1: Running with Docker (Recommended)\n\nThis method bundles Python, Pandoc, LaTeX, and required libraries into a container. **You only need Docker Desktop installed locally.**\n\n1.  **Install Docker:** Download and install [Docker Desktop](https://www.docker.com/products/docker-desktop/) for your operating system. Start Docker Desktop.\n2.  **Clone Repository:** Get the project files:\n    ```bash\n    git clone https://github.com/your-username/pandoc-mcp-server.git # Replace with your repo URL\n    cd pandoc-mcp-server\n    ```\n3.  **Build the Docker Image:** This command builds the image using the `Dockerfile`. It installs Pandoc, a capable TeX Live distribution (for PDF support), and Python dependencies inside the image. This step might take several minutes the first time.\n    ```bash\n    docker build -t pandoc-converter-server .\n    ```\n4.  **Run the Container:** This starts the server inside the container.\n    *   **Choose a directory on your host machine** to share with the container for input/output files (e.g., the current project directory).\n    *   Run the container, mapping the host directory to `/data` inside the container and mapping port 8000. **Replace `/path/to/your/local/project` with the actual absolute path to the project directory on your machine.**\n    ```bash\n    # Example using the current directory (.) as the host path:\n    docker run -it --rm -p 8000:8000 -v \"$(pwd)\":/data pandoc-converter-server\n\n    # Or using an absolute path (replace):\n    # docker run -it --rm -p 8000:8000 -v \"/path/to/your/local/project\":/data pandoc-converter-server\n    ```\n    *   `-it`: Runs interactively (shows logs, allows Ctrl+C).\n    *   `--rm`: Removes the container when stopped.\n    *   `-p 8000:8000`: Maps port 8000 on your host to port 8000 in the container.\n    *   `-v \"$(pwd)\":/data`: Mounts the current working directory on your host to `/data` inside the container. Files placed in your local project directory will appear in `/data` inside the container, and files saved to `/data` by the server will appear in your local project directory.\n    *   `pandoc-converter-server`: The name of the image you built.\n5.  **Server is Running:** You should see logs indicating the server started and is listening on SSE (`http://0.0.0.0:8000`). It's ready to accept connections from your MCP client (like the LangChain agent).\n6.  **Connecting from Client:** Configure your MCP client (e.g., `MultiServerMCPClient`) to connect to `http://127.0.0.1:8000/sse` with `transport: \"sse\"`.\n7.  **Using the Tool:** When interacting with your agent/client, refer to files using their path *inside the container*, prefixed with `/data/`. For example: `convert /data/my_input.docx to pdf at /data/my_output.pdf`. The output file will appear in your local project directory due to the volume mapping.\n\n### Option 2: Running Locally (Manual Dependency Installation)\n\nThis requires you to install Python, Pandoc, and a LaTeX distribution directly onto your host machine.\n\n1.  **Install Python:** Ensure you have Python >= 3.10 installed.\n2.  **Install Pandoc:** Install the Pandoc command-line tool for your OS. Follow instructions at [pandoc.org/installing.html](https://pandoc.org/installing.html). Verify by running `pandoc --version` in a new terminal.\n3.  **Install LaTeX:** For PDF generation, install a TeX distribution.\n    *   **macOS:** `brew install --cask mactex-no-gui` (Recommended via Homebrew)\n    *   **Debian/Ubuntu:** `sudo apt-get update && sudo apt-get install texlive-latex-base texlive-fonts-recommended texlive-latex-extra texlive-fonts-extra` (or `texlive-full` for everything, but large).\n    *   **Windows:** Install [MiKTeX](https://miktex.org/) or [TeX Live](https://www.tug.org/texlive/). Ensure the `bin` directory containing `pdflatex.exe` is added to your system's PATH.\n    *   Verify by running `pdflatex --version` in a new terminal.\n4.  **Clone Repository:**\n    ```bash\n    git clone https://github.com/your-username/pandoc-mcp-server.git # Replace with your repo URL\n    cd pandoc-mcp-server\n    ```\n5.  **Create Virtual Environment (Recommended):**\n    ```bash\n    python -m venv venv\n    source venv/bin/activate # Linux/macOS\n    # venv\\Scripts\\activate # Windows\n    ```\n    *(Or use Conda: `conda create --name pandoc-env python=3.11 && conda activate pandoc-env`)*\n6.  **Install Python Dependencies:**\n    ```bash\n    pip install -r requirements.txt\n    ```\n7.  **Run the Server:**\n    ```bash\n    python pandoc_mcp_server.py\n    ```\n8.  **Server is Running:** It will listen on `http://127.0.0.1:8000/sse`.\n9.  **Connecting from Client:** Configure your MCP client to connect to `http://127.0.0.1:8000/sse`.\n10. **Using the Tool:** Refer to files using their regular paths on your local machine (e.g., `convert my_input.docx to pdf at my_output.pdf`, assuming files are in the same directory, or use absolute paths).\n\n## Example Agent Interaction (Running Server in Docker)\n\nAssuming the server container is running with the volume mount:\n\n```\nYou: convert /data/report.md to pdf\n\nAgent: Thinking...\n[Agent calls convert_document tool with input='/data/report.md', output='/data/report.pdf', to='pdf']\nAgent: Successfully converted document to '/data/report.pdf'\n[The bot may then attempt to upload report.pdf from the local project directory]\n```\n\n## Files\n\n*   `pandoc_mcp_server.py`: The main Python script for the MCP server.\n*   `Dockerfile`: Instructions for building the Docker container image.\n*   `requirements.txt`: Python dependencies needed inside the Docker container (or local venv).\n*   `.gitignore`: Specifies intentionally untracked files for Git.\n*   `README.md`: This file.\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request or open an Issue.\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "pandoc",
        "formats",
        "docx",
        "using pandoc",
        "convert documents",
        "pandoc enabling"
      ],
      "category": "document-processing"
    },
    "Meeting-BaaS--meeting-mcp": {
      "owner": "Meeting-BaaS",
      "name": "meeting-mcp",
      "url": "https://github.com/Meeting-BaaS/meeting-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/Meeting-BaaS.webp",
      "description": "Manage meeting data including transcripts, recordings, and calendar events while providing search functionality for easy organization and retrieval.",
      "stars": 20,
      "forks": 7,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-12T20:09:05Z",
      "readme_content": "# Meeting BaaS MCP Server\n[](https://meetingBaaS.com)\n\n<p align=\"center\"><a href=\"https://discord.com/invite/dsvFgDTr6c\"><img height=\"60px\" src=\"https://user-images.githubusercontent.com/31022056/158916278-4504b838-7ecb-4ab9-a900-7dc002aade78.png\" alt=\"Join our Discord!\"></a></p>\n\nA Model Context Protocol (MCP) server that provides tools for managing meeting data, including transcripts, recordings, calendar events, and search functionality.\n\n## QUICK START: Claude Desktop Integration\n\nTo use Meeting BaaS with Claude Desktop:\n\n1. Edit the Claude Desktop configuration file:\n   ```bash\n   vim ~/Library/Application\\ Support/Claude/claude_desktop_config.json\n   ```\n\n2. Add the Meeting BaaS configuration:\n   ```json\n   \"meetingbaas\": {\n     \"command\": \"/bin/bash\",\n     \"args\": [\n       \"-c\",\n       \"cd /path/to/meeting-mcp && (npm run build 1>&2) && export MCP_FROM_CLAUDE=true && node dist/index.js\"\n     ],\n     \"headers\": {\n       \"x-api-key\": \"YOUR_API_KEY\"\n     }\n   }\n   ```\n\n3. For calendar integration, you can add the `calendarOAuth` section to your `botConfig`:\n   ```json\n   \"botConfig\": {\n     \"calendarOAuth\": {\n       \"platform\": \"Google\",  // or \"Microsoft\"\n       \"clientId\": \"YOUR_OAUTH_CLIENT_ID\",\n       \"clientSecret\": \"YOUR_OAUTH_CLIENT_SECRET\", \n       \"refreshToken\": \"YOUR_REFRESH_TOKEN\",\n       \"rawCalendarId\": \"primary@gmail.com\"  // Optional\n     }\n   }\n   ```\n\n4. Save the file and restart Claude Desktop.\n\n> **Note:** Calendar integration is optional. Meeting BaaS can be used without connecting a calendar by simply omitting the `calendarOAuth` section.\n\n## Overview\n\nThis project implements a Model Context Protocol (MCP) server that allows AI assistants like Claude and Cursor to access and manipulate meeting data. It exposes a set of tools and resources that can be used to:\n\n- **Invite Meeting Bots**: Create and invite bots to your video conferences that automatically record and transcribe meetings\n\n  ```\n  \"Create a new meeting bot for my Zoom call tomorrow\"\n  ```\n\n- **Query Meeting Data**: Search through meeting transcripts and find specific information without watching entire recordings\n\n  ```\n  \"Search my recent meetings for discussions about the quarterly budget\"\n  \"Find all mentions of Project Apollo in yesterday's team meeting\"\n  \"Show me parts of the meeting where Jane was speaking\"\n  ```\n\n- **Manage Calendar Events**: View and organize calendar entries and upcoming meetings\n\n- **Access Recording Information**: Get metadata about meeting recordings and their status\n\n## Prerequisites\n\n- Node.js (v16 or later)\n- npm\n- **MeetingBaaS Account**: You need access to a MeetingBaaS account using your corporate email address\n  - All logs, bots, and shared links are available to colleagues with the same corporate domain (not personal emails like gmail.com)\n  - This enables seamless collaboration where all team members can access meeting recordings and transcripts created by anyone in your organization\n\n## Installation\n\n1. Clone the repository:\n\n   ```bash\n   git clone <repository-url>\n   cd mcp-baas\n   ```\n\n2. Install dependencies:\n\n   ```bash\n   npm install\n   ```\n\n3. Build the project:\n   ```bash\n   npm run build\n   ```\n\n## Usage\n\nStart the server:\n\n```bash\nnpm run start\n```\n\nBy default, the server runs on port 7017 and exposes the MCP endpoint at `http://localhost:7017/mcp`.\n\n## Available Tools\n\nThe server exposes several tools through the MCP protocol:\n\n### Calendar Tools\n\n- `oauthGuidance`: Get detailed step-by-step instructions on setting up OAuth for Google or Microsoft calendars\n  - No parameters required\n  - Returns comprehensive instructions for obtaining OAuth credentials and setting up calendar integration\n\n- `listRawCalendars`: Lists available calendars from Google or Microsoft before integration\n  - Parameters: `platform` (\"Google\" or \"Microsoft\"), `clientId`, `clientSecret`, `refreshToken`\n  - Returns a list of available calendars with their IDs and primary status\n\n- `setupCalendarOAuth`: Integrates a calendar using OAuth credentials\n  - Parameters: `platform` (\"Google\" or \"Microsoft\"), `clientId`, `clientSecret`, `refreshToken`, `rawCalendarId` (optional)\n  - Returns confirmation of successful integration with calendar details\n\n- `listCalendars`: Lists all integrated calendars\n  - No parameters required\n  - Returns a list of all calendars with their names, email addresses, and UUIDs\n\n- `getCalendar`: Gets detailed information about a specific calendar integration\n  - Parameters: `calendarId` (UUID of the calendar)\n  - Returns comprehensive calendar details\n\n- `deleteCalendar`: Permanently removes a calendar integration\n  - Parameters: `calendarId` (UUID of the calendar)\n  - Returns confirmation of successful deletion\n\n- `resyncAllCalendars`: Forces a refresh of all connected calendars\n  - No parameters required\n  - Returns the status of the sync operation\n\n- `listUpcomingMeetings`: Lists upcoming meetings from a calendar\n  - Parameters: `calendarId`, `status` (optional: \"upcoming\", \"past\", \"all\"), `limit` (optional)\n  - Returns a list of meetings with their names, times, and recording status\n\n- `listEvents`: Lists calendar events with comprehensive filtering options\n  - Parameters: `calendarId`, plus optional filters like `startDateGte`, `startDateLte`, `attendeeEmail`, etc.\n  - Returns detailed event listings with rich information\n\n- `listEventsWithCredentials`: Lists calendar events with credentials provided directly in the query\n  - Parameters: `calendarId`, `apiKey`, plus same optional filters as `listEvents`\n  - Returns the same detailed information as `listEvents` but with direct authentication\n\n- `getEvent`: Gets detailed information about a specific calendar event\n  - Parameters: `eventId` (UUID of the event)\n  - Returns comprehensive event details including attendees and recording status\n\n- `scheduleRecording`: Schedules a bot to record an upcoming meeting\n  - Parameters: `eventId`, `botName`, plus optional settings like `botImage`, `recordingMode`, etc.\n  - Returns confirmation of successful scheduling\n\n- `scheduleRecordingWithCredentials`: Schedules recording with credentials provided directly in the query\n  - Parameters: `eventId`, `apiKey`, `botName`, plus same optional settings as `scheduleRecording`\n  - Returns confirmation of successful scheduling\n\n- `cancelRecording`: Cancels a previously scheduled recording\n  - Parameters: `eventId`, `allOccurrences` (optional, for recurring events)\n  - Returns confirmation of successful cancellation\n\n- `cancelRecordingWithCredentials`: Cancels recording with credentials provided directly in the query\n  - Parameters: `eventId`, `apiKey`, `allOccurrences` (optional)\n  - Returns confirmation of successful cancellation\n\n- `checkCalendarIntegration`: Checks and diagnoses calendar integration status\n  - No parameters required\n  - Returns a comprehensive status report and troubleshooting tips\n\n### Meeting Tools\n\n- `createBot`: Creates a meeting bot that can join video conferences to record and transcribe meetings\n  - Parameters: \n    - `meeting_url` (URL of the meeting to join)\n    - `name` (optional bot name)\n    - `botImage` (optional URL to an image for the bot's avatar) \n    - `entryMessage` (optional message the bot will send when joining)\n    - `deduplicationKey` (optional key to override the 5-minute restriction on joining the same meeting)\n    - `nooneJoinedTimeout` (optional timeout in seconds for bot to leave if no one joins)\n    - `waitingRoomTimeout` (optional timeout in seconds for bot to leave if stuck in waiting room)\n    - `speechToTextProvider` (optional provider for transcription: \"Gladia\", \"Runpod\", or \"Default\")\n    - `speechToTextApiKey` (optional API key for the speech-to-text provider)\n    - `streamingInputUrl` (optional WebSocket URL to stream audio input)\n    - `streamingOutputUrl` (optional WebSocket URL to stream audio output)\n    - `streamingAudioFrequency` (optional frequency for streaming: \"16khz\" or \"24khz\")\n    - `extra` (optional object with additional metadata about the meeting, such as meeting type, custom summary prompt, search keywords)\n  - Returns: Bot details including ID and join status\n- `getBots`: Lists all bots and their associated meetings\n- `getBotsByMeeting`: Gets bots for a specific meeting URL\n- `getRecording`: Retrieves recording information for a specific bot/meeting\n- `getRecordingStatus`: Checks the status of a recording in progress\n- `getMeetingData`: Gets transcript and recording data for a specific meeting\n  - Parameters: `meetingId` (ID of the meeting to get data for)\n  - Returns: Information about the meeting recording including duration and transcript segment count\n- `getMeetingDataWithCredentials`: Gets transcript and recording data using direct API credentials\n  - Parameters: `meetingId` (ID of the meeting), `apiKey` (API key for authentication)\n  - Returns: Same information as `getMeetingData` but with direct authentication\n\n### Transcript Tools\n\n- `getMeetingTranscript`: Gets a meeting transcript with speaker names and content grouped by speaker\n  - Parameters: `botId` (the bot that recorded the meeting)\n  - Returns: Complete transcript with speaker information, formatted as paragraphs grouped by speaker\n  - Example output:\n    ```\n    Meeting: \"Weekly Team Meeting\"\n    Duration: 45m 30s\n    Transcript:\n\n    John Smith: Hello everyone, thanks for joining today's call. We have a lot to cover regarding the Q3 roadmap and our current progress on the platform redesign.\n\n    Sarah Johnson: Thanks John. I've prepared some slides about the user testing results we got back yesterday. The feedback was generally positive but there are a few areas we need to address.\n    ```\n\n- `findKeyMoments`: Automatically identifies and shares links to important moments in a meeting\n  - Parameters: `botId`, optional `meetingTitle`, optional list of `topics` to look for, and optional `maxMoments`\n  - Returns: Markdown-formatted list of key moments with links, automatically detected based on transcript\n  - Uses AI-powered analysis to find significant moments without requiring manual timestamp selection\n\n### QR Code Tools\n\n- `generateQRCode`: Creates an AI-generated QR code image that can be used as a bot avatar\n  - Parameters:\n    - `type`: Type of QR code (url, email, phone, sms, text)\n    - `to`: Destination for the QR code (URL, email, phone number, or text)\n    - `prompt`: AI prompt to customize the QR code (max 1000 characters). You can include your API key directly in the prompt text by typing \"API key: qrc_your_key\" or similar phrases.\n    - `style`: Style of the QR code (style_default, style_dots, style_rounded, style_crystal)\n    - `useAsBotImage`: Whether to use the generated QR code as the bot avatar (default: true)\n    - `template`: Template ID for the QR code (optional)\n    - `apiKey`: Your QR Code AI API key (optional, will use default if not provided)\n  - Returns: URL to the generated QR code image that can be used directly with the joinMeeting tool\n  - Example usage:\n    ```\n    \"Generate a QR code with my email lazare@spoke.app that looks like a Tiger in crystal style\"\n    ```\n  - Example with API key in the prompt:\n    ```\n    \"Generate a QR code for my website https://example.com that looks like a mountain landscape. Use API key: qrc_my-personal-api-key-123456\"\n    ```\n  - Example with formal parameter:\n    ```\n    \"Generate a QR code with the following parameters:\n    - Type: email\n    - To: john.doe@example.com\n    - Prompt: Create a QR code that looks like a mountain landscape\n    - Style: style_rounded\n    - API Key: qrc_my-personal-api-key-123456\"\n    ```\n\n### Link Sharing Tools\n\n- `shareableMeetingLink`: Generates a nicely formatted, shareable link to a meeting recording\n  - Parameters: `botId`, plus optional `timestamp`, `title`, `speakerName`, and `description`\n  - Returns: Markdown-formatted link with metadata that can be shared directly in chat\n  - Example: \n    ```\n    📽️ **Meeting Recording: Weekly Team Sync**\n    ⏱️ Timestamp: 00:12:35\n    🎤 Speaker: Sarah Johnson\n    📝 Discussing the new product roadmap\n\n    🔗 [View Recording](https://meetingbaas.com/viewer/abc123?t=755)\n    ```\n\n- `shareMeetingSegments`: Creates a list of links to multiple important moments in a meeting\n  - Parameters: `botId` and an array of `segments` with timestamps, speakers, and descriptions\n  - Returns: Markdown-formatted list of segments with direct links to each moment\n  - Useful for creating a table of contents for a long meeting\n\n## Example Workflows\n\n### Recording a Meeting\n\n1. Create a bot for your upcoming meeting:\n\n   ```\n   \"Create a bot for my Zoom meeting at https://zoom.us/j/123456789\"\n   ```\n\n2. The bot joins the meeting automatically and begins recording.\n\n3. Check recording status:\n   ```\n   \"What's the status of my meeting recording for the Zoom call I started earlier?\"\n   ```\n\n### Calendar Integration and Automatic Recording\n\n1. Get guidance on obtaining OAuth credentials:\n\n   ```\n   \"I want to integrate my Google Calendar. How do I get OAuth credentials?\"\n   ```\n\n2. List your available calendars before integration:\n\n   ```\n   \"List my available Google calendars. Here are my OAuth credentials:\n   - Client ID: my-client-id-123456789.apps.googleusercontent.com\n   - Client Secret: my-client-secret-ABCDEF123456\n   - Refresh Token: my-refresh-token-ABCDEF123456789\"\n   ```\n\n3. Set up calendar integration with a specific calendar:\n\n   ```\n   \"Integrate my Google Calendar using these credentials:\n   - Platform: Google\n   - Client ID: my-client-id-123456789.apps.googleusercontent.com\n   - Client Secret: my-client-secret-ABCDEF123456\n   - Refresh Token: my-refresh-token-ABCDEF123456789\n   - Raw Calendar ID: primary@gmail.com\"\n   ```\n\n4. View your upcoming meetings:\n\n   ```\n   \"Show me my upcoming meetings from calendar 1a2b3c4d-5e6f-7a8b-9c0d-1e2f3a4b5c6d\"\n   ```\n\n5. Schedule recording for an upcoming meeting:\n\n   ```\n   \"Schedule a recording for my team meeting with event ID 7a8b9c0d-1e2f-3a4b-5c6d-7e8f9a0b1c2d.\n   Configure the bot with:\n   - Name: Team Meeting Bot\n   - Recording Mode: gallery_view\n   - Entry Message: Hello everyone, I'm here to record the meeting\"\n   ```\n\n6. Check all recordings scheduled in your calendar:\n\n   ```\n   \"Show me all meetings in my calendar that have recordings scheduled\"\n   ```\n\n7. Cancel a previously scheduled recording:\n\n   ```\n   \"Cancel the recording for event 7a8b9c0d-1e2f-3a4b-5c6d-7e8f9a0b1c2d\"\n   ```\n\n8. Refresh calendar data if meetings are missing:\n\n   ```\n   \"Force a resync of all my connected calendars\"\n   ```\n\n### Analyzing Meeting Content\n\n1. Get the full transcript of a meeting:\n\n   ```\n   \"Get the transcript from my team meeting with bot ID abc-123\"\n   ```\n\n2. Find key moments in a meeting:\n\n   ```\n   \"Identify key moments from yesterday's product planning meeting with bot ID xyz-456\"\n   ```\n\n3. Share a specific moment from a meeting:\n\n   ```\n   \"Create a shareable link to the part of meeting abc-123 at timestamp 12:45 where John was talking about the budget\"\n   ```\n\n### Using Direct Credential Tools\n\nYou can provide API credentials directly in your queries:\n\n1. List events with direct credentials:\n\n   ```\n   \"List events from calendar 5c99f8a4-f498-40d0-88f0-29f698c53c51 using API key tesban where attendee is philipe@spoke.app\"\n   ```\n\n2. Schedule a recording with direct credentials:\n\n   ```\n   \"Schedule a recording for event 78d06b42-794f-4efe-8195-62db1f0052d5 using API key tesban with bot name 'Weekly Meeting Bot'\"\n   ```\n\n3. Cancel a recording with direct credentials:\n\n   ```\n   \"Cancel the recording for event 97cd62f0-ea9b-42b3-add5-7a607ce6d80f using API key tesban\"\n   ```\n\n4. Get meeting data with direct credentials:\n\n   ```\n   \"Get meeting data for meeting 47de9462-bea7-406c-b79a-fd6b82c3de76 using API key tesban\"\n   ```\n\n### Using AI-Generated QR Codes as Bot Avatars\n\n1. Generate a QR code with your contact information and a custom design:\n\n   ```\n   \"Generate a QR code with the following parameters:\n   - Type: email\n   - To: john.doe@company.com\n   - Prompt: Create a professional-looking QR code with abstract blue patterns that resemble a corporate logo\n   - Style: style_crystal\"\n   ```\n\n2. Use the generated QR code as a bot avatar in a meeting:\n\n   ```\n   \"Join my Zoom meeting at https://zoom.us/j/123456789 with the following parameters:\n   - Bot name: QR Code Assistant\n   - Bot image: [URL from the generated QR code]\n   - Entry message: Hello everyone, I'm here to record the meeting. You can scan my avatar to get my contact information.\"\n   ```\n\n3. Generate a QR code with a meeting link for easy sharing:\n\n   ```\n   \"Generate a QR code with the following parameters:\n   - Type: url\n   - To: https://zoom.us/j/123456789\n   - Prompt: Create a colorful QR code with a calendar icon in the center\n   - Style: style_rounded\"\n   ```\n\n### Accessing Meeting Recordings\n\nMeeting recordings can be accessed directly through the Meeting BaaS viewer using the bot ID:\n\n```\nhttps://meetingbaas.com/viewer/{BOT_ID}\n```\n\nFor example:\n```\nhttps://meetingbaas.com/viewer/67738f48-2360-4f9e-a999-275a74208ff5\n```\n\nThis viewer provides:\n- The meeting video recording\n- Synchronized transcript with speaker identification\n- Navigation by speaker or topic\n- Direct link sharing with teammates\n\nWhen using the `createBot`, `getBots`, or search tools, you'll receive bot IDs that can be used to construct these viewer URLs for easy access to recordings.\n\n> **Important**: All meeting recordings and links are automatically shared with colleagues who have the same corporate email domain (e.g., @yourcompany.com). This allows your entire team to access recordings without requiring individual permissions, creating a collaborative environment where meeting knowledge is accessible to everyone in your organization.\n\n## Configuration\n\nThe server can be configured through environment variables or by editing the `src/config.ts` file.\n\nKey configuration options:\n\n- `PORT`: The port the server listens on (default: 7017)\n- `API_BASE_URL`: The base URL for the Meeting BaaS API\n- `DEFAULT_API_KEY`: Default API key for testing\n\n## Integration with Cursor\n\nTo integrate with Cursor:\n\n1. Open Cursor\n2. Go to Settings\n3. Navigate to \"Model Context Protocol\"\n4. Add a new server with:\n   - Name: \"Meeting BaaS MCP\"\n   - Type: \"sse\"\n   - Server URL: \"http://localhost:7017/mcp\"\n   - Optionally add headers if authentication is required\n\n## Development\n\n### Build\n\n```bash\nnpm run build\n```\n\n### Test with MCP Inspector\n\n```bash\nnpm run inspect\n```\n\n### Development mode (with auto-reload)\n\n```bash\nnpm run dev\n```\n\n### Log Management\n\nThe server includes optimized logging with:\n\n```bash\nnpm run cleanup\n```\n\nThis command:\n- Cleans up unnecessary log files and cached data\n- Filters out repetitive ping messages from logs\n- Reduces disk usage while preserving important log information\n- Maintains a smaller log footprint for long-running servers\n\n## Project Structure\n\n- `src/index.ts`: Main entry point\n- `src/tools/`: Tool implementations\n- `src/resources/`: Resource definitions\n- `src/api/`: API client for the Meeting BaaS backend\n- `src/types/`: TypeScript type definitions\n- `src/config.ts`: Server configuration\n- `src/utils/`: Utility functions\n  - `logging.ts`: Log filtering and management\n  - `tinyDb.ts`: Persistent bot tracking database\n\n## Authentication\n\nThe server expects an API key in the `x-api-key` header for authentication. You can configure the default API key in the configuration.\n\nDirect authentication is also supported in many tools (named with \"WithCredentials\") where you can provide the API key directly as a parameter rather than in headers.\n\n## License\n\n[MIT](LICENSE)\n\n## QR Code API Key Configuration\n\nThe QR code generator tool requires an API key from QR Code AI API. There are several ways to provide this:\n\n1. **Directly in the prompt**: Include your API key directly in the prompt text when using the `generateQRCode` tool, e.g., \"Generate a QR code for my website https://example.com with API key: qrc_your_key\"\n\n2. **As a parameter**: Provide your API key as the `apiKey` parameter when using the `generateQRCode` tool\n\n3. **Environment variable**: Set the `QRCODE_API_KEY` environment variable\n\n4. **Claude Desktop config**: Add the API key to your Claude Desktop configuration file located at:\n   - Mac/Linux: `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n\n   Example configuration:\n   ```json\n   {\n     \"headers\": {\n       \"x-api-key\": \"qrc_your_key_here\" \n     }\n   }\n   ```\n\nThe tool will check for the API key in the order listed above. If no API key is provided, the default API key will be used if available.\n\nYou can obtain an API key by signing up at [QR Code AI API](https://qrcode-ai.com).",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "meeting",
        "mcp",
        "organization",
        "processing meeting",
        "manage meeting",
        "baas meeting"
      ],
      "category": "document-processing"
    },
    "Melbourneandrew--docs2prompt-mcp": {
      "owner": "Melbourneandrew",
      "name": "docs2prompt-mcp",
      "url": "https://github.com/Melbourneandrew/docs2prompt-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/Melbourneandrew.webp",
      "description": "Transforms documentation from GitHub repositories or dedicated websites into LLM-friendly prompts for enhanced context and understanding in AI applications.",
      "stars": 0,
      "forks": 1,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-03-21T02:59:39Z",
      "readme_content": "# MCP Server for docs2prompt\n\n[![](https://badge.mcpx.dev?type=server 'MCP Server')](https://modelcontextprotocol.io/introduction)\n[![License](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](https://github.com/rezabrizi/docs2prompt/blob/main/LICENSE)\n\n[docs2prompt](https://github.com/rezabrizi/docs2prompt) is a python library and line tool developed by [Reza Tabrizi](https://github.com/rezabrizi) that turns documentation in github repositories or hosted on dedicated websites into LLM-friendly prompts.\n\nThis repository contains an MCP server that wraps docs2prompt for use by any MCP client (Cursor, Claude, Windsurf, etc).\n\n## Run Server (Development)\n1. [Install UV](https://docs.astral.sh/uv/getting-started/installation/)\n```\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n```\n2. Clone the repository:\n```\ngit clone https://github.com/Melbourneandrew/docs2prompt-mcp\n```\n\n3. Put this in your MCP client config (Add your path and [github access token](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens)):\n```\n{\n    \"mcpServers\": {\n        \"docs2prompt\": {\n            \"command\": \"uv\",\n            \"args\": [\n                \"--directory\",\n                \"/YOUR/LOCAL/PATH/docs2prompt-mcp/src\",\n                \"run\",\n                \"main.py\"\n            ],\n            \"env\": {\n                \"GITHUB_TOKEN\": \"\"\n            }\n        }\n    }\n}\n```\n\nIf you need, here are guides to set up MCP for common clients:\n* [Cursor](https://docs.cursor.com/context/model-context-protocol)\n* [Claude Desktop](https://modelcontextprotocol.io/quickstart/server#test-with-commands)",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "documentation",
        "docs2prompt",
        "document",
        "docs2prompt mcp",
        "documentation github",
        "melbourneandrew docs2prompt"
      ],
      "category": "document-processing"
    },
    "MeterLong--MCP-Doc": {
      "owner": "MeterLong",
      "name": "MCP-Doc",
      "url": "https://github.com/MeterLong/MCP-Doc",
      "imageUrl": "/freedevtools/mcp/pfp/MeterLong.webp",
      "description": "Create, edit, and manage Word documents using natural language commands, facilitating document operations and formatting. Support for table processing, image insertion, and layout control is also included.",
      "stars": 132,
      "forks": 15,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-10-04T00:28:46Z",
      "readme_content": "# Docx MCP Service\n\n[English](README.md) | [中文](README_ZH.md)\n\n[![smithery badge](https://smithery.ai/badge/@MeterLong/mcp-doc)](https://smithery.ai/server/@MeterLong/mcp-doc)\n\nA Docx document processing service based on the FastMCP library, supporting the creation, editing, and management of Word documents using AI assistants in Cursor.\n\n## Features\n\n- **Complete Document Operations**: Support for creating, opening, saving documents, as well as adding, editing, and deleting content\n- **Formatting**: Support for setting fonts, colors, sizes, alignment, and other formatting options\n- **Table Processing**: Support for creating, editing, merging, and splitting table cells\n- **Image Insertion**: Support for inserting images and setting their sizes\n- **Layout Control**: Support for setting page margins, adding page breaks, and other layout elements\n- **Query Functions**: Support for retrieving document information, paragraph content, and table data\n- **Convenient Editing**: Support for find and replace functionality\n- **Section Editing**: Support for replacing content in specific sections while preserving original formatting and styles\n\n## Installation Dependencies\n\nEnsure Python 3.10+ is installed, then install the following dependencies:\n\n```bash\npip3 install python-docx mcp\n```\n\n## Usage\n\n### Using as an MCP Service in Cursor\n\n1. Open Cursor and go to Settings\n2. Find the `Features > MCP Servers` section\n3. Click `Add new MCP server`\n4. Fill in the following information:\n   - Name: MCP_DOCX\n   - Type: Command\n   - Command: `python3 /path/to/MCP_dox/server.py` (replace with the actual path to your `server.py`)\n5. Click `Add` to add the service\n\nAfter adding, you can use natural language to operate Word documents in Cursor's AI assistant, for example:\n\n- \"Create a new Word document and save it to the desktop\"\n- \"Add a level 3 heading\"\n- \"Insert a 3x4 table and fill it with data\"\n- \"Set the second paragraph to bold and center-aligned\"\n\n## Supported Operations\n\nThe service supports the following operations:\n\n- **Document Management**: `create_document`, `open_document`, `save_document`\n- **Content Addition**: `add_paragraph`, `add_heading`, `add_table`, `add_picture`\n- **Content Editing**: `edit_paragraph`, `delete_paragraph`, `delete_text`\n- **Table Operations**: `add_table_row`, `delete_table_row`, `edit_table_cell`, `merge_table_cells`, `split_table`\n- **Layout Control**: `add_page_break`, `set_page_margins`\n- **Query Functions**: `get_document_info`, `get_paragraphs`, `get_tables`, `search_text`\n- **File Operations**: `create_document`, `open_document`, `save_document`, `save_as_document`, `create_document_copy`\n- **Section Editing**: `replace_section`, `edit_section_by_keyword`\n- **Other Functions**: `find_and_replace`, `search_and_replace` (with preview functionality)\n\n## How It Works\n\n1. The service uses the Python-docx library to process Word documents\n2. It implements the MCP protocol through the FastMCP library to communicate with AI assistants\n3. It processes requests and returns formatted responses\n4. It supports complete error handling and status reporting\n\n## Typography Capabilities\n\nThe service has good typography understanding capabilities:\n\n- **Text Hierarchy**: Support for heading levels (1-9) and paragraph organization\n- **Page Layout**: Support for page margin settings\n- **Visual Elements**: Support for font styles (bold, italic, underline, color) and alignment\n- **Table Layout**: Support for creating tables, merging cells, splitting tables, and setting table formats\n- **Pagination Control**: Support for adding page breaks\n\n## Development Notes\n\n- `server.py` - Core implementation of the MCP service using the FastMCP library\n\n## Troubleshooting\n\nIf you encounter problems in Cursor, try the following steps:\n\n1. Ensure Python 3.10+ is correctly installed\n2. Ensure the python-docx and mcp libraries are correctly installed\n3. Check if the server path is correct\n4. Restart the Cursor application\n\n## Notes\n\n- Ensure the python-docx and mcp libraries are correctly installed\n- Ensure Chinese characters in paths can be correctly processed\n- Using absolute paths can avoid path parsing issues\n\n## License\n\nMIT License\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "document",
        "documents",
        "mcp",
        "mcp doc",
        "document processing",
        "word documents"
      ],
      "category": "document-processing"
    },
    "Mistizz--mcp-JapaneseTextAnalyzer": {
      "owner": "Mistizz",
      "name": "mcp-JapaneseTextAnalyzer",
      "url": "https://github.com/Mistizz/mcp-JapaneseTextAnalyzer",
      "imageUrl": "/freedevtools/mcp/pfp/Mistizz.webp",
      "description": "Analyzes Japanese and English texts by counting characters and words and evaluating linguistic features such as average sentence length and lexical diversity. Supports input via file paths or direct text input, accommodating both absolute and relative paths.",
      "stars": 2,
      "forks": 3,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-08-25T18:29:31Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/mistizz-mcp-japanesetextanalyzer-badge.png)](https://mseep.ai/app/mistizz-mcp-japanesetextanalyzer)\n\n# Japanese Text Analyzer MCP Server\n日本語テキストの形態素解析を行えるMCPサーバーです。文章の特徴を言語学的な観点から測定・評価し、文章生成のフィードバックに役立ちます。\n\n[![smithery badge](https://smithery.ai/badge/@Mistizz/mcp-JapaneseTextAnalyzer)](https://smithery.ai/server/@Mistizz/mcp-JapaneseTextAnalyzer)\n<a href=\"https://glama.ai/mcp/servers/@Mistizz/mcp-JapaneseTextAnalyzer\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@Mistizz/mcp-JapaneseTextAnalyzer/badge\" alt=\"Japanese Text Analyzer MCP server\" />\n</a>\n\n## 機能\n\n- 日本語テキストの文字数（スペースや改行を除いた実質的な文字数）をカウント\n- 日本語テキストの単語数をカウント\n- 日本語テキストの詳細な言語的特徴の分析（平均文長、品詞の割合、語彙の多様性など）\n- ファイルパスまたは直接テキスト入力の両方に対応\n- 柔軟なファイルパス解決（絶対パス・相対パス・ファイル名のみでも検索可能）\n\n## Tools\n\n現在、以下のツールが実装されています：\n\n### count_chars\n\nファイルの文字数を計測します。絶対パスを指定してください（Windows形式 C:\\Users\\...、またはWSL/Linux形式 /c/Users/... のどちらも可）。スペースや改行を除いた実質的な文字数をカウントします。\n\n**入力:**\n- `filePath` (string): 文字数をカウントするファイルのパス（Windows形式かWSL/Linux形式の絶対パスを推奨）\n\n**出力:**\n- ファイルの文字数（スペースや改行を除外した実質的な文字数）\n\n### count_words\n\nファイルの単語数を計測します。絶対パスを指定してください（Windows形式 C:\\Users\\...、またはWSL/Linux形式 /c/Users/... のどちらも可）。英語ではスペースで区切られた単語をカウントし、日本語では形態素解析を使用します。\n\n**入力:**\n- `filePath` (string): 単語数をカウントするファイルのパス（Windows形式かWSL/Linux形式の絶対パスを推奨）\n- `language` (string, オプション, デフォルト: \"en\"): ファイルの言語 (en: 英語, ja: 日本語)\n\n**出力:**\n- ファイルの単語数\n- 日本語モードの場合は、形態素解析の詳細結果も表示\n\n### count_clipboard_chars\n\nテキストの文字数を計測します。スペースや改行を除いた実質的な文字数をカウントします。\n\n**入力:**\n- `text` (string): 文字数をカウントするテキスト\n\n**出力:**\n- テキストの文字数（スペースや改行を除外した実質的な文字数）\n\n### count_clipboard_words\n\nテキストの単語数を計測します。英語ではスペースで区切られた単語をカウントし、日本語では形態素解析を使用します。\n\n**入力:**\n- `text` (string): 単語数をカウントするテキスト\n- `language` (string, オプション, デフォルト: \"en\"): テキストの言語 (en: 英語, ja: 日本語)\n\n**出力:**\n- テキストの単語数\n- 日本語モードの場合は、形態素解析の詳細結果も表示\n\n### analyze_text\n\nテキストの詳細な形態素解析と言語的特徴の分析を行います。文の複雑さ、品詞の割合、語彙の多様性などを解析します。\n\n**入力:**\n- `text` (string): 分析するテキスト\n\n**出力:**\n- テキストの基本情報（総文字数、文の数、総形態素数）\n- 詳細分析結果（平均文長、品詞の割合、文字種の割合、語彙の多様性など）\n\n### analyze_file\n\nファイルの詳細な形態素解析と言語的特徴の分析を行います。文の複雑さ、品詞の割合、語彙の多様性などを解析します。\n\n**入力:**\n- `filePath` (string): 分析するファイルのパス（Windows形式かWSL/Linux形式の絶対パスを推奨）\n\n**出力:**\n- ファイルの基本情報（総文字数、文の数、総形態素数）\n- 詳細分析結果（平均文長、品詞の割合、文字種の割合、語彙の多様性など）\n\n## 使用方法\n\n### Installing via Smithery\n\nTo install Japanese Text Analyzer for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@Mistizz/mcp-JapaneseTextAnalyzer):\n\n```bash\nnpx -y @smithery/cli install @Mistizz/mcp-JapaneseTextAnalyzer --client claude\n```\n\n### npxでの実行\n\nこのパッケージはnpxでGitHubリポジトリから直接実行できます：\n\n```bash\nnpx -y github:Mistizz/mcp-JapaneseTextAnalyzer\n```\n\n### Claude for Desktopでの使用\n\nClaude for Desktopの設定ファイルに以下を追加してください:\n\n**Windows:**\n`%AppData%\\Claude\\claude_desktop_config.json`\n\n**macOS:**\n`~/Library/Application Support/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"JapaneseTextAnalyzer\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"github:Mistizz/mcp-JapaneseTextAnalyzer\"\n      ]\n    }\n  }\n}\n```\n\n### Cursorでの使用\n\nCursorでも同様の設定を`.cursor`フォルダ内の`mcp.json`ファイルに追加します。\n\n**Windows:**\n`%USERPROFILE%\\.cursor\\mcp.json`\n\n**macOS/Linux:**\n`~/.cursor/mcp.json`\n\n一般的な設定(殆どの環境で動作):\n```json\n{\n  \"mcpServers\": {\n    \"JapaneseTextAnalyzer\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"github:Mistizz/mcp-JapaneseTextAnalyzer\"\n      ]\n    }\n  }\n}\n```\n\nWindows環境において、上記で動作しなかった場合、下記を試してみてください：\n```json\n{\n  \"mcpServers\": {\n    \"JapaneseTextAnalyzer\": {\n      \"command\": \"cmd\",\n      \"args\": [\n        \"/c\",\n        \"npx\",\n        \"-y\",\n        \"github:Mistizz/mcp-JapaneseTextAnalyzer\"\n      ]\n    }\n  }\n}\n```\n\n## 使用例\n\n### 直接テキストの文字数を数える\n```\nこのテキストの文字数を数えてください。\n```\n\n### ファイルの単語数を日本語モードで数える\n```\nC:\\path\\to\\your\\file.txt の単語数を日本語モードで数えてください。\n```\n\n### WSL/Linux形式のパスで単語数を数える\n```\n/c/Users/username/Documents/file.txt の単語数を日本語モードで数えてください。\n```\n\n### ファイル名だけで単語数を数える\n```\nREADME.md の単語数を英語モードで数えてください。\n```\n\n### テキストを貼り付けて日本語の単語数を数える\n```\n次のテキストの日本語の単語数を数えてください：\n\n吾輩は猫である。名前はまだ無い。どこで生れたかとんと見当がつかぬ。何でも薄暗いじめじめした所でニャーニャー泣いていた事だけは記憶している。\n```\n\n### テキストの詳細な言語的特徴を分析する\n```\n次のテキストを詳細に分析してください：\n\n私は昨日、新しい本を買いました。とても面白そうな小説で、友人からの評判も良かったです。今週末にゆっくり読む予定です。\n```\n\n### ファイルの詳細な言語的特徴を分析する\n```\nC:\\path\\to\\your\\file.txt を詳細に分析してください。\n```\n\n## ファイルパス解決機能\n\nこのツールは、ファイルパスが指定された場合に柔軟にファイルを探索します：\n\n1. 絶対パスが指定された場合はそのまま使用\n   - Windows形式の絶対パス（例: `C:\\Users\\username\\Documents\\file.txt`）\n   - WSL/Linux形式の絶対パス（例: `/c/Users/username/Documents/file.txt`）のどちらも自動的に検出・変換\n2. カレントディレクトリ（作業ディレクトリ）を基準に相対パスを解決\n3. ホームディレクトリ（`%USERPROFILE%`や`$HOME`）を基準に検索\n4. デスクトップディレクトリを基準に検索\n5. ドキュメントディレクトリを基準に検索\n\nこれにより、単に「README.md」のようなファイル名だけを指定しても、いくつかの一般的なディレクトリで自動的に検索し、ファイルが見つかった場合はそれを使用します。また、WSL環境やGit Bashなどから取得したパス（`/c/Users/...`形式）も、Windows環境でそのまま使用できます。\n\n## 内部動作について\n\nこのツールは、日本語の単語数カウントに「kuromoji.js」という形態素解析ライブラリを使用しています。形態素解析は自然言語処理の基本的な処理で、文章を意味を持つ最小単位（形態素）に分割します。\n\n形態素解析の処理は初期化に時間がかかることがあります。特に、辞書データを読み込む必要があるため、初回実行時に少々時間がかかる場合があります。サーバー起動時に形態素解析器の初期化を行うことで、ツール実行時の遅延を最小限に抑えています。\n\n### 言語的特徴の分析について\n\n「analyze_text」と「analyze_file」ツールは、形態素解析の結果に基づいて、テキストの様々な言語的特徴を計算します。これらには以下のような指標が含まれます：\n\n- **平均文長**: 一文あたりの平均文字数。この値が大きいほど、読みにくい文章である可能性があります。\n- **文あたりの形態素数**: 一文あたりの平均形態素数。文の密度や構文の複雑さを表します。\n- **品詞の割合**: 名詞・動詞・形容詞などの品詞がテキスト中でどのような割合で使われているかを示します。\n- **助詞の割合**: 特定の助詞がどのような頻度で使われているかを示し、文の構造や流れを分析します。\n- **文字種の割合**: ひらがな・カタカナ・漢字・英数字の構成比率を示します。\n- **語彙の多様性**: 異なった単語数と総単語数の比率（タイプ/トークン比）を示し、語彙の豊かさを計測します。\n- **カタカナ語の割合**: カタカナ語の使用頻度を示し、外来語や専門用語の多さ、文体のカジュアルさを反映します。\n- **敬語の頻度**: 敬語表現の使用頻度を示し、文章の丁寧さやフォーマル度を測定します。\n- **句読点の平均数**: 文あたりの句読点の平均数を示し、文の区切りや読みやすさに関する指標を提供します。\n\nこれらの指標を組み合わせることで、テキストの特性を多角的に分析し、文体や読みやすさ、専門性などを評価することができます。\n\n## ライセンス\n\nこのMCPサーバーはMITライセンスの下で提供されています。これは、MITライセンスの条件に従って、ソフトウェアを自由に使用、変更、配布できることを意味します。詳細については、プロジェクトリポジトリのLICENSEファイルをご覧ください。\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "japanesetextanalyzer",
        "texts",
        "analyzes",
        "mcp japanesetextanalyzer",
        "japanesetextanalyzer analyzes",
        "analyzes japanese"
      ],
      "category": "document-processing"
    },
    "Msparihar--mcp-server-firecrawl": {
      "owner": "Msparihar",
      "name": "mcp-server-firecrawl",
      "url": "https://github.com/Msparihar/mcp-server-firecrawl",
      "imageUrl": "/freedevtools/mcp/pfp/Msparihar.webp",
      "description": "Provides capabilities for web scraping, intelligent content searching, and site crawling using the Firecrawl API, facilitating customizable data extraction and structured output.",
      "stars": 2,
      "forks": 3,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-02-20T06:10:43Z",
      "readme_content": "# Firecrawl MCP Server\n\nA Model Context Protocol (MCP) server for web scraping, content searching, site crawling, and data extraction using the Firecrawl API.\n\n## Features\n\n- **Web Scraping**: Extract content from any webpage with customizable options\n  - Mobile device emulation\n  - Ad and popup blocking\n  - Content filtering\n  - Structured data extraction\n  - Multiple output formats\n\n- **Content Search**: Intelligent search capabilities\n  - Multi-language support\n  - Location-based results\n  - Customizable result limits\n  - Structured output formats\n\n- **Site Crawling**: Advanced web crawling functionality\n  - Depth control\n  - Path filtering\n  - Rate limiting\n  - Progress tracking\n  - Sitemap integration\n\n- **Site Mapping**: Generate site structure maps\n  - Subdomain support\n  - Search filtering\n  - Link analysis\n  - Visual hierarchy\n\n- **Data Extraction**: Extract structured data from multiple URLs\n  - Schema validation\n  - Batch processing\n  - Web search enrichment\n  - Custom extraction prompts\n\n## Installation\n\n```bash\n# Global installation\nnpm install -g @modelcontextprotocol/mcp-server-firecrawl\n\n# Local project installation\nnpm install @modelcontextprotocol/mcp-server-firecrawl\n```\n\n## Quick Start\n\n1. Get your Firecrawl API key from the [developer portal](https://firecrawl.dev/dashboard)\n\n2. Set your API key:\n\n   **Unix/Linux/macOS (bash/zsh):**\n\n   ```bash\n   export FIRECRAWL_API_KEY=your-api-key\n   ```\n\n   **Windows (Command Prompt):**\n\n   ```cmd\n   set FIRECRAWL_API_KEY=your-api-key\n   ```\n\n   **Windows (PowerShell):**\n\n   ```powershell\n   $env:FIRECRAWL_API_KEY = \"your-api-key\"\n   ```\n\n   **Alternative: Using .env file (recommended for development):**\n\n   ```bash\n   # Install dotenv\n   npm install dotenv\n\n   # Create .env file\n   echo \"FIRECRAWL_API_KEY=your-api-key\" > .env\n   ```\n\n   Then in your code:\n\n   ```javascript\n   import dotenv from 'dotenv';\n   dotenv.config();\n   ```\n\n3. Run the server:\n\n   ```bash\n   mcp-server-firecrawl\n   ```\n\n## Integration\n\n### Claude Desktop App\n\nAdd to your MCP settings:\n\n```json\n{\n  \"firecrawl\": {\n    \"command\": \"mcp-server-firecrawl\",\n    \"env\": {\n      \"FIRECRAWL_API_KEY\": \"your-api-key\"\n    }\n  }\n}\n```\n\n### Claude VSCode Extension\n\nAdd to your MCP configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"firecrawl\": {\n      \"command\": \"mcp-server-firecrawl\",\n      \"env\": {\n        \"FIRECRAWL_API_KEY\": \"your-api-key\"\n      }\n    }\n  }\n}\n```\n\n## Usage Examples\n\n### Web Scraping\n\n```typescript\n// Basic scraping\n{\n  name: \"scrape_url\",\n  arguments: {\n    url: \"https://example.com\",\n    formats: [\"markdown\"],\n    onlyMainContent: true\n  }\n}\n\n// Advanced extraction\n{\n  name: \"scrape_url\",\n  arguments: {\n    url: \"https://example.com/blog\",\n    jsonOptions: {\n      prompt: \"Extract article content\",\n      schema: {\n        title: \"string\",\n        content: \"string\"\n      }\n    },\n    mobile: true,\n    blockAds: true\n  }\n}\n```\n\n### Site Crawling\n\n```typescript\n// Basic crawling\n{\n  name: \"crawl\",\n  arguments: {\n    url: \"https://example.com\",\n    maxDepth: 2,\n    limit: 100\n  }\n}\n\n// Advanced crawling\n{\n  name: \"crawl\",\n  arguments: {\n    url: \"https://example.com\",\n    maxDepth: 3,\n    includePaths: [\"/blog\", \"/products\"],\n    excludePaths: [\"/admin\"],\n    ignoreQueryParameters: true\n  }\n}\n```\n\n### Site Mapping\n\n```typescript\n// Generate site map\n{\n  name: \"map\",\n  arguments: {\n    url: \"https://example.com\",\n    includeSubdomains: true,\n    limit: 1000\n  }\n}\n```\n\n### Data Extraction\n\n```typescript\n// Extract structured data\n{\n  name: \"extract\",\n  arguments: {\n    urls: [\"https://example.com/product1\", \"https://example.com/product2\"],\n    prompt: \"Extract product details\",\n    schema: {\n      name: \"string\",\n      price: \"number\",\n      description: \"string\"\n    }\n  }\n}\n```\n\n## Configuration\n\nSee [configuration guide](https://github.com/Msparihar/mcp-server-firecrawl/blob/main/docs/configuration.md) for detailed setup options.\n\n## API Documentation\n\nSee [API documentation](https://github.com/Msparihar/mcp-server-firecrawl/blob/main/docs/api.md) for detailed endpoint specifications.\n\n## Development\n\n```bash\n# Install dependencies\nnpm install\n\n# Build\nnpm run build\n\n# Run tests\nnpm test\n\n# Start in development mode\nnpm run dev\n```\n\n## Examples\n\nCheck the [examples](https://github.com/Msparihar/mcp-server-firecrawl/tree/main/examples) directory for more usage examples:\n\n- Basic scraping: [scrape.ts](https://github.com/Msparihar/mcp-server-firecrawl/blob/main/examples/scrape.ts)\n- Crawling and mapping: [crawl-and-map.ts](https://github.com/Msparihar/mcp-server-firecrawl/blob/main/examples/crawl-and-map.ts)\n\n## Error Handling\n\nThe server implements robust error handling:\n\n- Rate limiting with exponential backoff\n- Automatic retries\n- Detailed error messages\n- Debug logging\n\n## Security\n\n- API key protection\n- Request validation\n- Domain allowlisting\n- Rate limiting\n- Safe error messages\n\n## Contributing\n\nSee [CONTRIBUTING.md](https://github.com/Msparihar/mcp-server-firecrawl/blob/main/CONTRIBUTING.md) for contribution guidelines.\n\n## License\n\nMIT License - see [LICENSE](https://github.com/Msparihar/mcp-server-firecrawl/blob/main/LICENSE) for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "firecrawl",
        "scraping",
        "msparihar",
        "firecrawl provides",
        "server firecrawl",
        "using firecrawl"
      ],
      "category": "document-processing"
    },
    "MushroomFleet--TranscriptionTools-MCP": {
      "owner": "MushroomFleet",
      "name": "TranscriptionTools-MCP",
      "url": "https://github.com/MushroomFleet/TranscriptionTools-MCP",
      "imageUrl": "/freedevtools/mcp/pfp/MushroomFleet.webp",
      "description": "Enhances transcription workflows by automatically repairing errors, formatting transcripts naturally, and generating concise summaries. Utilizes advanced language models for intelligent processing of audio transcripts.",
      "stars": 17,
      "forks": 6,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-29T09:06:20Z",
      "readme_content": "# TranscriptionTools MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@MushroomFleet/transcriptiontools-mcp)](https://smithery.ai/server/@MushroomFleet/transcriptiontools-mcp)\n\nAn MCP server providing intelligent transcript processing capabilities, featuring natural formatting, contextual repair, and smart summarization powered by Deep Thinking LLMs.\n\n<a href=\"https://glama.ai/mcp/servers/in1wo7l928\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/in1wo7l928/badge\" alt=\"TranscriptionTools Server MCP server\" />\n</a>\n\n## Available MCP Tools\n\nThis MCP server exposes four powerful tools for transcript processing:\n\n1. **repair_text** - Analyzes and repairs transcription errors with greater than 90% confidence\n2. **get_repair_log** - Retrieves detailed analysis logs from previous repairs\n3. **format_transcript** - Transforms timestamped transcripts into naturally formatted text\n4. **summary_text** - Generates intelligent summaries using ACE cognitive methodology\n\n## Installation\n\n### Installing via Smithery\n\nTo install Transcription Tools for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@MushroomFleet/transcriptiontools-mcp):\n\n```bash\nnpx -y @smithery/cli install @MushroomFleet/transcriptiontools-mcp --client claude\n```\n\n1. Clone this repository:\n```bash\ngit clone https://github.com/mushroomfleet/TranscriptionTools-MCP\ncd TranscriptionTools-MCP\n```\n\n2. Install dependencies:\n```bash\nnpm install\n```\n\n3. Build the server:\n```bash\nnpm run build\n```\n\n4. Configure the MCP server in your MCP settings file:\n```json\n{\n  \"mcpServers\": {\n    \"transcription-tools\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/TranscriptionTools-MCP/build/index.js\"],\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\n## Using the MCP Tools\n\n### Repairing Transcription Errors\n\n```\n<use_mcp_tool>\n<server_name>transcription-tools</server_name>\n<tool_name>repair_text</tool_name>\n<arguments>\n{\n  \"input_text\": \"We recieve about ten thousand dollars which is defiantly not enough.\",\n  \"is_file_path\": false\n}\n</arguments>\n</use_mcp_tool>\n```\n\n### Formatting Timestamped Transcripts\n\n```\n<use_mcp_tool>\n<server_name>transcription-tools</server_name>\n<tool_name>format_transcript</tool_name>\n<arguments>\n{\n  \"input_text\": \"/path/to/timestamped-transcript.txt\",\n  \"is_file_path\": true,\n  \"paragraph_gap\": 8,\n  \"line_gap\": 4\n}\n</arguments>\n</use_mcp_tool>\n```\n\n### Generating Summaries\n\n```\n<use_mcp_tool>\n<server_name>transcription-tools</server_name>\n<tool_name>summary_text</tool_name>\n<arguments>\n{\n  \"input_text\": \"Long text to summarize...\",\n  \"is_file_path\": false,\n  \"constraint_type\": \"words\",\n  \"constraint_value\": 100\n}\n</arguments>\n</use_mcp_tool>\n```\n\n### Retrieving Repair Logs\n\n```\n<use_mcp_tool>\n<server_name>transcription-tools</server_name>\n<tool_name>get_repair_log</tool_name>\n<arguments>\n{\n  \"session_id\": \"20241206143022\"\n}\n</arguments>\n</use_mcp_tool>\n```\n\n## Core Technologies\n\n### Natural Formatting\n- Removes timestamps while preserving speech patterns\n- Applies intelligent spacing based on pause duration\n- Respects natural grammar and language flow\n- Maintains exact transcribed content\n\n### Contextual Repair\n- Identifies and corrects likely transcription errors\n- Uses semantic context for high-confidence corrections\n- Maintains detailed logs of all changes\n- 90% confidence threshold for corrections\n- No original audio required\n\n### Smart Summarization\n- Creates concise summaries of processed transcripts\n- Supports multiple constraint types:\n  - Time-based (speaking duration)\n  - Character count\n  - Word count\n- Preserves key information and context\n- Maintains natural speaking rhythm\n\n## Project Structure\n```\n/\n├── .gitignore         # Git ignore file\n├── LICENSE            # MIT license file\n├── README.md          # This documentation\n├── package.json       # Package dependencies and scripts\n├── tsconfig.json      # TypeScript configuration\n├── build/             # Compiled JavaScript files (generated after build)\n│   ├── tools/         # Compiled tool implementations\n│   └── utils/         # Compiled utility functions\n└── src/               # Source TypeScript files\n    ├── index.ts       # MCP server entry point\n    ├── tools/         # Tool implementations\n    │   ├── formatting.ts\n    │   ├── repair.ts\n    │   └── summary.ts\n    └── utils/         # Utility functions\n        ├── file-handler.ts\n        └── logger.ts\n```\n\n## Configuration\n\nYou can customize the server behavior by modifying the source code directly. The key configuration parameters are found in the respective tool implementation files:\n\n```typescript\n// In src/tools/formatting.ts\nconst paragraph_gap = 8; // seconds\nconst line_gap = 4;      // seconds\n\n// In src/tools/repair.ts\nconst confidence_threshold = 90; // percentage\n\n// In src/tools/summary.ts\nconst default_speaking_pace = 150; // words per minute\n```\n\n## License\nMIT",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "transcriptiontools",
        "transcription",
        "transcripts",
        "mushroomfleet transcriptiontools",
        "transcriptiontools mcp",
        "transcription workflows"
      ],
      "category": "document-processing"
    },
    "MymInsomnia--textClassifier": {
      "owner": "MymInsomnia",
      "name": "textClassifier",
      "url": "https://github.com/MymInsomnia/textClassifier",
      "imageUrl": "/freedevtools/mcp/pfp/MymInsomnia.webp",
      "description": "Multiple common text classification models based on CNN, RNN, and pre-trained NLP architectures for sentiment analysis and text classification. Supports data preprocessing, training word embeddings, and implementing advanced models like Bi-LSTM, Transformer, ELMo, and BERT for improved classification accuracy.",
      "stars": 1,
      "forks": 0,
      "license": "No License",
      "language": "Jupyter Notebook",
      "updated_at": "2019-06-14T07:35:55Z",
      "readme_content": "### 文本分类项目\n***\n**本项目为基于CNN，RNN 和NLP中预训练模型构建的多个常见的文本分类模型。**\n\n#### requirements\n* python==3.5.6\n* tensorflow-gpu==1.10.0\n\n#### 1. 数据集\n&ensp;&ensp;数据集为IMDB电影评论的情感分析数据集，总共有三个部分：\n* 带标签的训练集：labeledTrainData.tsv\n* 不带标签的训练集：unlabeledTrainData.tsv\n* 测试集：testData.tsv\n\n&ensp;&ensp;字段的含义：\n* id  电影评论的id\n* review  电影评论的内容\n* sentiment  情感分类的标签（只有labeledTrainData.tsv数据集中有）\n\n#### 2. 数据预处理 \n&ensp;&ensp;数据预处理方法/dataHelper/processData.ipynb\n\n&ensp;&ensp;将原始数据处理成干净的数据，处理后的数据存储在/data/preProcess下，数据预处理包括：\n* 去除各种标点符号\n* 生成训练word2vec模型的输入数据 /data/preProcess/wordEmbedding.txt\n\n#### 3. 训练word2vec词向量\n&ensp;&ensp;预训练word2vec词向量/word2vec/genWord2Vec.ipynb\n* 预训练的词向量保存为bin格式 /word2vec/word2Vec.bin\n\n#### 4. textCNN 文本分类\n&ensp;&ensp;textCNN模型来源于论文[Convolutional Neural Networks for Sentence Classification](https://arxiv.org/abs/1408.5882)\n\n&ensp;&ensp;textCNN可以看作是一个由三个单层的卷积网络的输出结果进行拼接的融合模型，作者提出了三种大小的卷积核[3, 4, 5]，卷积核的滑动使得其\n类似于NLP中的n-grams，因此当你需要更多尺度的n-grams时，你可以选择增加不同大小的卷积核，比如大小为2的卷积核可以代表\n2-grams.\n\n&ensp;&ensp;textCNN代码在/textCNN/textCNN.ipynb。实现包括四个部分：\n* 参数配置类 Config （包括训练参数，模型参数和其他参数）\n* 数据预处理类 Dataset （包括生成词汇空间，获得预训练词向量，分割训练集和验证集）\n* textCNN模型类 TextCNN\n* 模型训练\n\n#### 5. charCNN 文本分类\n&ensp;&ensp;textCNN模型来源于论文[Character-level Convolutional Networks for Text\nClassification](https://arxiv.org/abs/1509.01626)\n\n&ensp;&ensp;char-CNN是一种基于字符级的文本分类器，将所有的文本都用字符表示，\n*注意这里的数据预处理时不可以去掉标点符号或者其他的各种符号，最好是保存论文中提出的69种字符，我一开始使用去掉特殊符号的字符后的文本输入到模型中会无法收敛*。\n此外由于训练数据集比较少，即使论文中最小的网络也无法收敛，此时可以减小模型的复杂度，包括去掉一些卷积层等。\n\n&ensp;&ensp;charCNN代码在/charCNN/charCNN.ipynb。实现也包括四个部分，也textCNN一致，但是在这里的数据预处理有很大不一样，剩下\n的就是模型结构不同，此外模型中可以引入BN层来对每一层的输出做归一化处理。\n\n#### 6. Bi-LSTM 文本分类\n&ensp;&ensp;Bi-LSTM可以参考我的博客[深度学习之从RNN到LSTM](https://www.cnblogs.com/jiangxinyang/p/9362922.html)\n\n&ensp;&ensp;Bi-LSTM是双向LSTM，LSTM是RNN的一种，是一种时序模型，Bi-LSTM是双向LSTM，旨在同时捕获文本中上下文的信息，\n在情感分析类的问题中有良好的表现。\n\n&ensp;&ensp;Bi-LSTM的代码在/Bi-LSTM/Bi-LSTM.ipynb中。除了模型类的代码有改动，其余代码几乎和textCNN一样。\n\n#### 7. Bi-LSTM + Attention 文本分类\n&ensp;&ensp;Bi-LSTM + Attention模型来源于论文[Attention-Based Bidirectional Long Short-Term Memory Networks for\nRelation Classification](http://aclweb.org/anthology/Y/Y15/Y15-1009.pdf)\n\n&ensp;&ensp;Bi-LSTM + Attention 就是在Bi-LSTM的模型上加入Attention层，在Bi-LSTM中我们会用最后一个时序的输出向量\n作为特征向量，然后进行softmax分类。Attention是先计算每个时序的权重，然后将所有时序\n的向量进行加权和作为特征向量，然后进行softmax分类。在实验中，加上Attention确实对结果有所提升。\n\n&ensp;&ensp;Bi-LSTM + Attention的代码在/Bi-LSTM+Attention/Bi-LSTMAttention.ipynb中，除了模型类中\n加入Attention层，其余代码和Bi-LSTM一致。\n\n#### 8. RCNN 文本分类\n&ensp;&ensp;RCNN模型来源于论文[Recurrent Convolutional Neural Networks for Text Classification](https://arxiv.org/abs/1609.04243)\n\n&ensp;&ensp;RCNN 整体的模型构建流程如下：\n* 利用Bi-LSTM获得上下文的信息，类似于语言模型\n* 将Bi-LSTM获得的隐层输出和词向量拼接[fwOutput, wordEmbedding, bwOutput]\n* 将拼接后的向量非线性映射到低维\n* 向量中的每一个位置的值都取所有时序上的最大值，得到最终的特征向量，该过程类似于max-pool\n* softmax分类\n\n&ensp;&ensp;RCNN的代码在/RCNN/RCNN.ipynb中。\n\n#### 9. adversarialLSTM 文本分类\n&ensp;&ensp;Adversarial LSTM模型来源于论文[Adversarial Training Methods\nFor Semi-Supervised Text Classification](https://arxiv.org/abs/1605.07725)\n\n&ensp;&ensp;adversarialLSTM的核心思想是通过对word Embedding上添加噪音生成对抗样本，将对抗样本以和原始样本\n同样的形式喂给模型，得到一个Adversarial Loss，通过和原始样本的loss相加得到新的损失，通过优化该新\n的损失来训练模型，作者认为这种方法能对word embedding加上正则化，避免过拟合。\n\n&ensp;&ensp;adversarialLSTM的代码在/adversarialLSTM/adversarialLSTM.ipynb中。\n\n#### 10. Transformer 文本分类\n&ensp;&ensp;Transformer模型来源于论文[Attention Is All You Need](https://arxiv.org/abs/1706.03762)\n\n&ensp;&ensp;Transformer模型有两个结构：Encoder和Decoder，在进行文本分类时只需要用到\nEncoder结构，Decoder结构是生成式模型，用于自然语言生成的。Transformer的核心结构是\nself-Attention机制，具体的介绍见[Transformer模型（Atention is all you need）](https://www.cnblogs.com/jiangxinyang/p/10069330.html)。\n\n&ensp;&ensp;Transformer模型的代码在/Transformer/transformer.ipynb中。\n\n#### 11. ELMo预训练模型 文本分类\n&ensp;&ensp;ELMo模型来源于论文[Deep contextualized word representations](https://arxiv.org/abs/1802.05365?context=cs)\n\n&ensp;&ensp;ELMo的结构是BiLM（双向语言模型），基于ELMo的预训练模型能动态地生成\n词的向量表示，具体的介绍见[ELMO模型（Deep contextualized word representation）](https://www.cnblogs.com/jiangxinyang/p/10060887.html)\n\n&ensp;&ensp;ELMo预训练模型用于文本分类的代码位于/ELMo/elmo.ipynb中。\n/ELMo/bilm/下是ELMo项目中的源码，/ELMo/modelParams/下是各种文件。\n\n#### 12. Bert预训练模型 文本分类\n&ensp;&ensp;BERT模型来源于论文[BERT: Pre-training of Deep Bidirectional Transformers for\nLanguage Understanding](https://arxiv.org/abs/1810.04805)\n\n&ensp;&ensp;BERT模型是基于双向Transformer实现的语言模型，集预训练和下游任务于一个模型中，\n因此在使用的时候我们不需要搭建自己的下游任务模型，直接用BERT模型即可，我们将谷歌开源的源码下载\n下来放在bert文件夹中，在进行文本分类只需要修改run_classifier.py文件即可，另外我们需要将训练集\n和验证集分割后保存在两个不同的文件中，放置在/BERT/data下。然后还需要下载谷歌预训练好的模型放置在\n/BERT/modelParams文件夹下，还需要建一个/BERT/output文件夹用来放置训练后的模型文件\n\n&ensp;&ensp;做完上面的步骤之后只要执行下面的脚本即可\n\n&ensp;&ensp;export BERT_BASE_DIR=../modelParams/uncased_L-12_H-768_A-12\n\n&ensp;&ensp;export DATASET=../data/\n\n&ensp;&ensp;python run_classifier.py \\\n  &ensp;&ensp;&ensp;&ensp;--data_dir=$MY_DATASET \\\n  &ensp;&ensp;&ensp;&ensp;--task_name=imdb \\\n  &ensp;&ensp;&ensp;&ensp;--vocab_file=$BERT_BASE_DIR/vocab.txt \\\n  &ensp;&ensp;&ensp;&ensp;--bert_config_file=$BERT_BASE_DIR/bert_config.json \\\n  &ensp;&ensp;&ensp;&ensp;--output_dir=../output/ \\\n  &ensp;&ensp;&ensp;&ensp;--do_train=true \\\n  &ensp;&ensp;&ensp;&ensp;--do_eval=true \\\n  &ensp;&ensp;&ensp;&ensp;--init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \\\n  &ensp;&ensp;&ensp;&ensp;--max_seq_length=200 \\\n  &ensp;&ensp;&ensp;&ensp;--train_batch_size=16 \\\n  &ensp;&ensp;&ensp;&ensp;--learning_rate=5e-5\\\n  &ensp;&ensp;&ensp;&ensp;--num_train_epochs=3.0\n\n&ensp;&ensp;BERT模型用于文本分类的详细使用可以看我的博客\n[文本分类实战（十）—— BERT 预训练模型](https://www.cnblogs.com/jiangxinyang/p/10241243.html)\n\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "textclassifier",
        "lstm",
        "nlp",
        "trained nlp",
        "text classification",
        "myminsomnia textclassifier"
      ],
      "category": "document-processing"
    },
    "OpenTorah-ai--mcp-sefaria-server": {
      "owner": "OpenTorah-ai",
      "name": "mcp-sefaria-server",
      "url": "https://github.com/OpenTorah-ai/mcp-sefaria-server",
      "imageUrl": "/freedevtools/mcp/pfp/OpenTorah-ai.webp",
      "description": "Access and reference Jewish texts and commentaries through a standardized interface.",
      "stars": 0,
      "forks": 1,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-02-25T08:57:14Z",
      "readme_content": "# Sefaria Jewish Library MCP Server\n\n[![smithery badge](https://smithery.ai/badge/mcp-sefaria-server)](https://smithery.ai/server/mcp-sefaria-server)\nAn MCP (Model Context Protocol) server that provides access to Jewish texts from the Sefaria library. This server enables Large Language Models to retrieve and reference Jewish texts through a standardized interface.\n\n<a href=\"https://glama.ai/mcp/servers/j3v6vnp4xk\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/j3v6vnp4xk/badge\" alt=\"Sefaria Jewish Library Server MCP server\" /></a>\n\n## Features\n\n- Retrieve Jewish texts by reference\n- Retrieve commentaries on a given text\n\n## Installation\n\nRequires Python 3.10 or higher.\n\n### Installing via Smithery\n\nTo install Sefaria Jewish Library for Claude Desktop automatically via [Smithery](https://smithery.ai/server/mcp-sefaria-server):\n\n```bash\nnpx -y @smithery/cli install mcp-sefaria-server --client claude\n```\n\n### Clone the repository\n```bash\ngit clone https://github.com/sivan22/mcp-sefaria-server.git\ncd mcp-sefaria-server\n```\n\n\n## Running the Server\n\nThe server can be run directly:\n\n```bash\nuv --directory path/to/directory run sefaria_jewish_library\n```\n\nOr through an MCP client that supports the Model Context Protocol.\nfor claude desktop app and cline you should use the following config:\n```\n{\n  \"mcpServers\": {        \n      \"sefaria_jewish_library\": {\n          \"command\": \"uv\",\n          \"args\": [\n              \"--directory\",\n              \"C:/dev/mcp-sefaria-server\",\n              \"run\",\n              \"sefaria_jewish_library\"\n          ],\n          \"env\": {\n            \"PYTHONIOENCODING\": \"utf-8\" \n          }\n      }\n  }\n}\n```\n\n## Available tools\n\nThe server provides the following tools through the MCP interface:\n\n### get_text\n\nRetrieves a specific Jewish text by its reference.\n\nExample:\n```\nreference: \"Genesis 1:1\"\nreference: \"שמות פרק ב פסוק ג\"\nreference: \"משנה ברכות פרק א משנה א\"\n```\n\n### get_commentaries\n\nRetrieves a list of commentaries for a given text.\n\nExample:\n```\nreference: \"Genesis 1:1\"\nreference: \"שמות פרק ב פסוק ג\"\nreference: \"משנה ברכות פרק א משנה א\"\n```\n\n## Development\n\nThis project uses:\n- [MCP SDK](https://github.com/modelcontextprotocol/sdk) for server implementation\n- [Sefaria API](https://github.com/Sefaria/Sefaria-API) for accessing Jewish texts\n\n## Requirements\n\n- Python >= 3.10\n- MCP SDK >= 1.1.1\n- Sefaria API\n\n## License\n\nMIT License\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "commentaries",
        "texts",
        "jewish",
        "jewish texts",
        "texts commentaries",
        "commentaries standardized"
      ],
      "category": "document-processing"
    },
    "PARS-DOE--autodocument": {
      "owner": "PARS-DOE",
      "name": "autodocument",
      "url": "https://github.com/PARS-DOE/autodocument",
      "imageUrl": "/freedevtools/mcp/pfp/PARS-DOE.webp",
      "description": "Generates comprehensive documentation, test plans, and code reviews by analyzing code repositories and directory structures. Utilizes AI to enhance development workflows with detailed insights into security and best practices.",
      "stars": 5,
      "forks": 4,
      "license": "Creative Commons Zero v1.0 Universal",
      "language": "TypeScript",
      "updated_at": "2025-05-26T15:04:36Z",
      "readme_content": "# Autodocument MCP Server\n\nAn MCP (Model Context Protocol) server that automatically generates documentation for code repositories by analyzing directory structures and code files using OpenRouter API.\n\n\n## Features\n\n- **Smart Directory Analysis**: Recursively analyzes directories and files in a code repository\n- **Git Integration**: Respects `.gitignore` patterns to skip ignored files\n- **AI-Powered Documentation**: Uses OpenRouter API (with Claude 3.7 by default) to generate comprehensive documentation\n- **Test Plan Generation**: Automatically creates test plans with suitable test types, edge cases, and mock requirements\n- **Code Review**: Performs senior developer-level code reviews focused on security, best practices, and improvements\n- **Bottom-Up Approach**: Starts with leaf directories and works upward, creating a coherent documentation hierarchy\n- **Intelligent File Handling**:\n  - Creates `documentation.md`, `testplan.md`, and `review.md` files at each directory level\n  - Skips single-file directories but includes their content in parent outputs\n  - Supports updating existing files\n  - Creates fallback files for directories that exceed limits\n- **Progress Reporting**: Provides detailed progress updates to prevent timeouts in long-running operations\n- **Highly Configurable**: Customize file extensions, size limits, models, prompts, and more\n- **Extensible Architecture**: Modular design makes it easy to add more auto-* tools in the future\n\n## Installation\n\n### Prerequisites\n\n- Node.js (v16 or newer)\n- An [OpenRouter API key](https://openrouter.ai/)\n\n### Installation Steps\n\n```bash\n# Clone the repository\ngit clone https://github.com/PARS-DOE/autodocument.git\ncd autodocument\n\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n```\n\n## Configuration\n\nConfigure autodocument using environment variables, command-line arguments, or an MCP configuration file:\n\n### Environment Variables\n\n- `OPENROUTER_API_KEY`: Your OpenRouter API key\n- `OPENROUTER_MODEL`: Model to use (default: `anthropic/claude-3-7-sonnet`)\n- `MAX_FILE_SIZE_KB`: Maximum file size in KB (default: 100)\n- `MAX_FILES_PER_DIR`: Maximum number of files per directory (default: 20)\n\n## Using with Roo or Cline\n\nRoo Code and Cline are AI assistants that support the Model Context Protocol (MCP), which allows them to use external tools like autodocument.\n\n### Setup for Roo/Cline\n\n1. **Clone and build the repository** (follow the Installation Steps above)\n\n2. **Configure the MCP server**:\n\n   #### For Roo:\n\n   In the MCP Servers menu, Edit the MCP Settings and add the autodocument configuration using the full path to where you cloned the repository:\n\n   Add the autodocument configuration using the full path to where you cloned the repository:\n   ```json\n   {\n     \"mcpServers\": {\n       \"autodocument\": {\n         \"command\": \"node\",\n         \"args\": [\"/path/to/autodocument/build/index.js\"],\n         \"env\": {\n           \"OPENROUTER_API_KEY\": \"your-api-key-here\"\n         },\n         \"disabled\": false,\n         \"alwaysAllow\": []\n       }\n     }\n   }\n   ```\n\n   #### For Claude Desktop App:\n   Edit the Claude desktop app configuration file at:\n   - Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n   - macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - Linux: `~/.config/Claude/claude_desktop_config.json`\n\n   Add the autodocument configuration using the full path to where you cloned the repository:\n   ```json\n   {\n     \"mcpServers\": {\n       \"autodocument\": {\n         \"command\": \"node\",\n         \"args\": [\"/path/to/autodocument/build/index.js\"],\n         \"env\": {\n           \"OPENROUTER_API_KEY\": \"your-api-key-here\"\n         },\n         \"disabled\": false,\n         \"alwaysAllow\": []\n       }\n     }\n   }\n   ```\n\n3. **Important:** Make sure to use absolute paths to the build/index.js file in your cloned repository\n\n4. **Restart Roo/Cline or the Claude desktop app**\n\n4. **Use the tool**:\n   In a conversation with Roo or Claude, you can now ask it to generate documentation or test plans for your code repository:\n   ```\n   Please generate documentation for my project at /path/to/my/project\n   ```\n   \n   Or for test plans:\n   ```\n   Please create a test plan for my project at /path/to/my/project\n   ```\n   \n   Or for code reviews:\n   ```\n   Please review the code in my project at /path/to/my/project\n   ```\n\n## How It Works\n\nThe autodocument server works using a bottom-up approach:\n\n1. **Discovery**: Scans the target directory recursively, respecting `.gitignore` rules\n2. **Smart Directory Processing**: \n   - Identifies directories with multiple code files or subdirectories\n   - Skips single-file directories but includes their content in parent documentation\n3. **File Analysis**: Analyzes code files, filtering by extension and size\n4. **Documentation Generation**: For each qualifying directory:\n   - Reads code files\n   - Sends code to OpenRouter API with optimized prompts\n   - Creates a `documentation.md` file (or updates existing one)\n5. **Aggregation**: As it moves up the directory tree:\n   - Processes each parent directory\n   - Includes documentation from child directories\n   - Creates a comprehensive overview at each level\n\n## Architecture\n\nThe project follows a modular architecture:\n\n- **Core Components**: Configuration management and server implementation\n- **Crawler Module**: Directory traversal and file discovery\n- **Analyzer Module**: Code file analysis and filtering\n- **OpenRouter Module**: AI integration for LLM-based content generation\n- **Documentation Module**: Orchestration of the documentation process\n- **Tools Module**: Extensible system for different auto-* tools (documentation, test plans, etc.)\n- **Prompts Configuration**: Centralized prompt management for easy customization\n\n## Example Usage\n\n### Command Line\n\n```bash\n# Navigate to your cloned repository\ncd path/to/cloned/autodocument\n\n# Set your API key (or configure in environment variables)\nexport OPENROUTER_API_KEY=your-api-key-here\n\n# Run documentation generation on a project\nnode build/index.js /path/to/your/project\n```\n\n### Programmatic Usage\n\n```javascript\nconst { spawn } = require('child_process');\nconst path = require('path');\n\n// Path to your project\nconst projectPath = '/path/to/your/project';\n\n// Your OpenRouter API key\nconst apiKey = 'your-api-key-here';\n\n// Create a JSON command to simulate an MCP tool call\nconst toolCallCommand = JSON.stringify({\n  jsonrpc: '2.0',\n  method: 'call_tool',\n  params: {\n    name: 'generate_documentation',\n    arguments: {\n      path: projectPath,\n      openRouterApiKey: apiKey\n    }\n  },\n  id: 1\n});\n\n// Start the server process - use the full path to your cloned repository\nconst serverProcess = spawn('node', ['/path/to/autodocument/build/index.js'], {\n  env: {\n    ...process.env,\n    OPENROUTER_API_KEY: apiKey\n  }\n});\n\n// Send the tool command\nserverProcess.stdin.write(toolCallCommand + '\\n');\n\n// Handle server output and errors\n// ...\n```\n\n## Customizing Prompts\n\nYou can easily customize the prompts used by the tools by editing the `src/prompt-config.ts` file. This allows you to:\n\n- Adjust the tone and style of generated content\n- Add specific instructions for your project's needs\n- Modify how existing content is updated\n\nThe prompt configuration is separated from the tool implementation, making it easy to experiment with different prompts without changing the code.\n\n## Available Tools\n\n### generate_documentation\n\nGenerates comprehensive documentation for a code repository:\n```\n{\n  \"path\": \"/path/to/your/project\",\n  \"openRouterApiKey\": \"your-api-key-here\", // Optional\n  \"model\": \"anthropic/claude-3-7-sonnet\", // Optional\n  \"updateExisting\": true // Optional, defaults to true\n}\n```\n\n### autotestplan\n\nGenerates test plans for functions and components in a code repository:\n```\n{\n  \"path\": \"/path/to/your/project\",\n  \"openRouterApiKey\": \"your-api-key-here\", // Optional\n  \"model\": \"anthropic/claude-3-7-sonnet\", // Optional\n  \"updateExisting\": true // Optional, defaults to true\n}\n```\n\n### autoreview\n\nGenerates a senior developer-level code review for a repository:\n```\n{\n  \"path\": \"/path/to/your/project\",\n  \"openRouterApiKey\": \"your-api-key-here\", // Optional\n  \"model\": \"anthropic/claude-3-7-sonnet\", // Optional\n  \"updateExisting\": true // Optional, defaults to true\n}\n```\n\n## Output Files\n\nThe server creates several types of output files:\n\n### documentation.md\n\nContains comprehensive documentation of the code in a directory, including:\n- Purpose of the code\n- Key functions and classes\n- Relationships between files\n- Integration with child components\n\n### testplan.md\n\nContains detailed test plans for code in a directory, including:\n- Appropriate test types (unit, integration, e2e) for each function\n- Common edge cases to test\n- Dependency mocking requirements\n- Integration testing strategies\n\n### review.md\n\nContains senior developer-level code review feedback, including:\n- Security issues and vulnerabilities\n- Best practice violations\n- Potential bugs or architectural concerns\n- Opportunities for refactoring\n- Practical, constructive feedback (not nitpicking style issues)\n\n### Fallback Files\n\nCreated when a directory exceeds size or file count limits:\n- `undocumented.md` - For documentation generation\n- `untested.md` - For test plan generation\n- `review-skipped.md` - For code review generation\n\nThese files contain:\n- Reason for skipping processing\n- List of files that were analyzed and excluded\n- Instructions on how to fix (increase limits or manually create content)\n\n## Troubleshooting\n\n### API Key Issues\n\nIf you see errors about invalid API key:\n- Ensure you've set the `OPENROUTER_API_KEY` environment variable\n- Check that your OpenRouter account is active\n- Verify you have sufficient credits for the API calls\n\n### Size Limit Errors\n\nIf too many directories are skipped due to size limits:\n- Set environment variables to increase limits: `MAX_FILE_SIZE_KB` and `MAX_FILES_PER_DIR`\n- Consider documenting very large directories manually\n\n### Model Selection\n\nIf you're not satisfied with the documentation quality:\n- Try a different model by setting the `OPENROUTER_MODEL` environment variable\n\n## License\n\nCC0-1.0 License - This work is dedicated to the public domain under CC0 by the United States Department of Energy\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n### Adding New Tools\n\nThe architecture is designed to make it easy to add new auto-* tools:\n\n1. Create a new class that extends `BaseTool` in the `src/tools` directory\n2. Define the prompts in `src/prompt-config.ts`\n3. Register the tool in the `ToolRegistry`\n\nSee the existing tools for examples of how to implement new functionality.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "autodocument",
        "documentation",
        "document",
        "autodocument generates",
        "doe autodocument",
        "document processing"
      ],
      "category": "document-processing"
    },
    "PV-Bhat--GemForge-MCP": {
      "owner": "PV-Bhat",
      "name": "GemForge-MCP",
      "url": "https://github.com/PV-Bhat/GemForge-MCP",
      "imageUrl": "/freedevtools/mcp/pfp/PV-Bhat.webp",
      "description": "Provides tools for interacting with Google's Gemini AI models, enabling intelligent model selection and advanced file handling. Facilitates AI tasks such as search, reasoning, code analysis, and file operations through a standardized MCP server interface.",
      "stars": 3,
      "forks": 3,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-08-09T19:47:04Z",
      "readme_content": "# GemForge (Gemini Tools)\n<img src=\"https://github.com/user-attachments/assets/8cee4293-b0e0-461f-a9d9-f750397aa2b5\" alt=\"GemForgeLogo\" width=\"100\" height=\"100\">\n\n<img src=\"https://glama.ai/mcp/servers/@PV-Bhat/GemForge-MCP/badge\" alt=\"Glama Badge\" width=\"210\" height=\"110\">\n\n## Overview\n\n[![Smithery Badge](https://smithery.ai/badge/@PV-Bhat/gemforge-gemini-tools-mcp)](https://smithery.ai/server/@PV-Bhat/gemforge-gemini-tools-mcp)\n[![MCP.so](https://img.shields.io/badge/MCP-Directory-blue)](https://mcp.so/server/gemforge-gemini-tools-mcp/PV-Bhat)\n<a href=\"https://glama.ai/mcp/servers/@PV-Bhat/GemForge-MCP\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@PV-Bhat/GemForge-MCP/badge\" alt=\"GemForge-Gemini-Tools-MCP MCP server\" />\n</a>\n\n\n**GemForge-Gemini-Tools-MCP**: Enterprise-grade Gemini integration for your favorite MCP agents. Supercharge Claude, Roo Code, and Windsurf with codebase analysis, live search, text/PDF/image processing, and more.\n\n## Quick Navigation\n\n- [Features](#why-gemforge)\n- [Quick Start](#quick-start)\n- [Configuration](#configuration)\n- [Tools](#key-tools)\n- [Heavy-Duty Reliability](#heavy-duty-reliability)\n- [Deployment](#deployment)\n- [Examples](#examples)\n- [Community](#community--support)\n- [Documentation](#documentation)\n\n## Why GemForge?\n\nGemForge is the essential bridge between Google's Gemini AI and the MCP ecosystem:\n![gemfog](https://github.com/user-attachments/assets/18cee069-d176-40c8-8ff9-3d643d918bc4)\n\n- **Real-Time Web Access**: Fetch breaking news, market trends, and current data with `gemini_search`\n- **Advanced Reasoning**: Process complex logic problems with step-by-step thinking via `gemini_reason`\n- **Code Mastery**: Analyze full repositories, generate solutions, and debug code with `gemini_code`\n- **Multi-File Processing**: Handle 60+ file formats including PDFs, images, and more with `gemini_fileops`\n\n- **Intelligent Model Selection**: Automatically routes to optimal Gemini model for each task\n  \n- **Enterprise-Ready**: Robust error handling, rate limit management, and API fallback mechanisms\n\n## Quick Start\n\n### One-Line Install\n\n```bash\nnpx @gemforge/mcp-server@latest init\n```\n\n### Manual Setup\n\n1. Create configuration file (`claude_desktop_config.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"GemForge\": {\n      \"command\": \"node\",\n      \"args\": [\"./dist/index.js\"],\n      \"env\": {\n        \"GEMINI_API_KEY\": \"your_api_key_here\"\n      }\n    }\n  }\n}\n```\n\n2. Install and run:\n\n```bash\nnpm install gemforge-mcp\nnpm start\n```\n\n[Watch 30-second setup demo →](https://www.youtube.com/your-demo-link)\n\n## Heavy-Duty Reliability\n\nGemForge is built for production environments:\n\n- **Support for 60+ File Types**: Process everything from code to documents to images\n- **Automatic Model Fallbacks**: Continues functioning even during rate limits or service disruptions\n- **Enterprise-Grade Error Logging**: Detailed diagnostics for troubleshooting\n- **API Resilience**: Exponential backoff, retry logic, and seamless model switching\n- **Full Repository Support**: Analyze entire codebases with configurable inclusion/exclusion patterns\n- **XML Content Processing**: Specialized handling for structured data\n\n## Key Tools\n\n| Tool | Description | Key Capability |\n|------|-------------|----------------|\n| `gemini_search` | Web-connected information retrieval | Real-time data access |\n| `gemini_reason` | Complex problem solving with step-by-step logic | Transparent reasoning process |\n| `gemini_code` | Deep code understanding and generation | Full repository analysis |\n| `gemini_fileops` | Multi-file processing across 60+ formats | Document comparison and transformation |\n\n<details>\n<summary><strong>Example: Real-Time Search</strong></summary>\n\n```json\n{\n  \"toolName\": \"gemini_search\",\n  \"toolParams\": {\n    \"query\": \"Latest advancements in quantum computing\",\n    \"enable_thinking\": true\n  }\n}\n```\n</details>\n\n<details>\n<summary><strong>Example: Code Analysis</strong></summary>\n\n```json\n{\n  \"toolName\": \"gemini_code\",\n  \"toolParams\": {\n    \"question\": \"Identify improvements and new features\",\n    \"directory_path\": \"path/to/project\",\n    \"repomix_options\": \"--include \\\"**/*.js\\\" --no-gitignore\"\n  }\n}\n```\n</details>\n\n<details>\n<summary><strong>Example: Multi-File Comparison</strong></summary>\n\n```json\n{\n  \"toolName\": \"gemini_fileops\",\n  \"toolParams\": {\n    \"file_path\": [\"contract_v1.pdf\", \"contract_v2.pdf\"],\n    \"operation\": \"analyze\",\n    \"instruction\": \"Compare these contract versions and extract all significant changes.\"\n  }\n}\n```\n</details>\n\n## Configuration\n\nGemForge offers flexible configuration options:\n\n<details>\n<summary><strong>Environment Variables</strong></summary>\n\n```\nGEMINI_API_KEY=your_api_key_here       # Required: Gemini API key\nGEMINI_PAID_TIER=true                  # Optional: Set to true if using paid tier (better rate limits)\nDEFAULT_MODEL_ID=gemini-2.5-pro        # Optional: Override default model selection\nLOG_LEVEL=info                         # Optional: Set logging verbosity (debug, info, warn, error)\n```\n</details>\n\n<details>\n<summary><strong>Claude Desktop Integration</strong></summary>\n\n```json\n{\n  \"mcpServers\": {\n    \"GemForge\": {\n      \"command\": \"node\",\n      \"args\": [\"./dist/index.js\"],\n      \"env\": {\n        \"GEMINI_API_KEY\": \"your_api_key_here\"\n      }\n    }\n  }\n}\n```\n</details>\n\n<details>\n<summary><strong>Advanced Model Selection</strong></summary>\n\nGemForge intelligently selects the best model for each task:\n- `gemini_search`: Uses `gemini-2.5-flash` for speed and search integration\n- `gemini_reason`: Uses `gemini-2.5-pro` for deep reasoning capabilities\n- `gemini_code`: Uses `gemini-2.5-pro` for complex code understanding\n- `gemini_fileops`: Selects between `gemini-2.0-flash-lite` or `gemini-1.5-pro` based on file size\n\nOverride with `model_id` parameter in any tool call or set `DEFAULT_MODEL_ID` environment variable.\n</details>\n\n## Deployment\n\n### Smithery.ai\nOne-click deployment via [Smithery.ai](https://smithery.ai/server/@PV-Bhat/gemforge-gemini-tools-mcp)\n\n### Docker\n```bash\ndocker run -e GEMINI_API_KEY=your_api_key ghcr.io/pv-bhat/gemforge:latest\n```\n\n### Self-Hosted\nUse our [MCP.so Directory listing](https://mcp.so/server/gemforge-gemini-tools-mcp/PV-Bhat) for integration instructions.\n\n## What Sets GemForge Apart?\n\n- **Cross-Ecosystem Power**: Bridge Google's AI with Claude and other MCP agents\n- **Multi-File Analysis**: Compare documents, images, or code versions\n- **Smart Routing**: Automatic model selection based on task requirements\n- **Production-Ready**: Built for enterprise environments\n\n\n\n## Community & Support\n\n- **Join Us**: [MCP Discord](https://discord.me/mcp) | [GemForge Discord](https://discord.gg/your-invite-link)\n- **Contribute**: [GitHub Discussions](https://github.com/your-username/GemForge/discussions)\n- **Feedback**: Open an issue or share thoughts on Discord\n\n## Documentation\n\nVisit our [Documentation Site](https://your-username.github.io/GemForge) for:\n- Advanced usage tutorials\n- API reference\n- Troubleshooting tips\n\n## License\n\nLicensed under the MIT License. See [LICENSE](LICENSE) for details.\n\n## Acknowledgments\n- Google Gemini API for providing the underlying AI capabilities\n- Model Context Protocol (MCP) for standardizing AI tool interfaces",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcp",
        "gemforge",
        "processing",
        "gemforge mcp",
        "document processing",
        "mcp provides"
      ],
      "category": "document-processing"
    },
    "PhialsBasement--mcp-webresearch-stealthified": {
      "owner": "PhialsBasement",
      "name": "mcp-webresearch-stealthified",
      "url": "https://github.com/PhialsBasement/mcp-webresearch-stealthified",
      "imageUrl": "/freedevtools/mcp/pfp/PhialsBasement.webp",
      "description": "Connects AI models to the web for real-time information retrieval, webpage content extraction, and research session tracking, along with the ability to capture screenshots.",
      "stars": 7,
      "forks": 1,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-24T02:14:39Z",
      "readme_content": "# MCP Web Research Server\n\nA Model Context Protocol (MCP) server for web research. \n\nBring real-time info into Claude and easily research any topic.\n\n## Features\n\n- Google search integration --- THIS FORK FIXES THIS --- NOW NO LONGER GETTING CAPTCHA BLOCKED\n- Webpage content extraction\n- Research session tracking (list of visited pages, search queries, etc.)\n- Screenshot capture\n\n## Prerequisites\n\n- [Node.js](https://nodejs.org/) >= 18 (includes `npm` and `npx`)\n- [Claude Desktop app](https://claude.ai/download)\n\n## Installation\n\nFirst, ensure you've downloaded and installed the [Claude Desktop app](https://claude.ai/download) and you have npm installed.\n\nNext, add this entry to your `claude_desktop_config.json` (on Mac, found at `~/Library/Application\\ Support/Claude/claude_desktop_config.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"webresearch\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@mzxrai/mcp-webresearch@latest\"]\n    }\n  }\n}\n```\n\nThis config allows Claude Desktop to automatically start the web research MCP server when needed.\n\n## Usage\n\nSimply start a chat with Claude and send a prompt that would benefit from web research. If you'd like a prebuilt prompt customized for deeper web research, you can use the `agentic-research` prompt that we provide through this package. Access that prompt in Claude Desktop by clicking the Paperclip icon in the chat input and then selecting `Choose an integration` → `webresearch` → `agentic-research`.\n\n<img src=\"https://i.ibb.co/N6Y3C0q/Screenshot-2024-12-05-at-11-01-27-PM.png\" alt=\"Example screenshot of web research\" width=\"400\"/>\n\n### Tools\n\n1. `search_google`\n   - Performs Google searches and extracts results\n   - Arguments: `{ query: string }`\n\n2. `visit_page`\n   - Visits a webpage and extracts its content\n   - Arguments: `{ url: string, takeScreenshot?: boolean }`\n\n3. `take_screenshot`\n   - Takes a screenshot of the current page\n   - No arguments required\n\n### Prompts\n\n#### `agentic-research`\nA guided research prompt that helps Claude conduct thorough web research. The prompt instructs Claude to:\n- Start with broad searches to understand the topic landscape\n- Prioritize high-quality, authoritative sources\n- Iteratively refine the research direction based on findings\n- Keep you informed and let you guide the research interactively\n- Always cite sources with URLs\n\n### Resources\n\nWe expose two things as MCP resources: (1) captured webpage screenshots, and (2) the research session.\n\n#### Screenshots\n\nWhen you take a screenshot, it's saved as an MCP resource. You can access captured screenshots in Claude Desktop via the Paperclip icon.\n\n#### Research Session\n\nThe server maintains a research session that includes:\n- Search queries\n- Visited pages\n- Extracted content\n- Screenshots\n- Timestamps\n\n### Suggestions\n\nFor the best results, if you choose not to use the `agentic-research` prompt when doing your research, it may be helpful to suggest high-quality sources for Claude to use when researching general topics. For example, you could prompt `news today from reuters or AP` instead of `news today`.\n\n## Problems\n\nThis is very much pre-alpha code. And it is also AIGC, so expect bugs.\n\nIf you run into issues, it may be helpful to check Claude Desktop's MCP logs:\n\n```bash\ntail -n 20 -f ~/Library/Logs/Claude/mcp*.log\n```\n\n## Development\n\n```bash\n# Install dependencies\npnpm install\n\n# Build the project\npnpm build\n\n# Watch for changes\npnpm watch\n\n# Run in development mode\npnpm dev\n```\n\n## Requirements\n\n- Node.js >= 18\n- Playwright (automatically installed as a dependency)\n\n## Verified Platforms\n\n- [x] macOS\n- [x] Linux\n- [x] Windows\n\n## License\n\nMIT\n\n## Author\n\n[mzxrai](https://github.com/mzxrai) \n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "webresearch",
        "webpage",
        "web",
        "webresearch stealthified",
        "mcp webresearch",
        "retrieval webpage"
      ],
      "category": "document-processing"
    },
    "PowerPrincipal--wxmd": {
      "owner": "PowerPrincipal",
      "name": "wxmd",
      "url": "https://github.com/PowerPrincipal/wxmd",
      "imageUrl": "/freedevtools/mcp/pfp/PowerPrincipal.webp",
      "description": "Transforms Markdown documents into visually appealing formatted content for WeChat, enhancing the efficiency of layout creation. Users can easily create cleanly styled content by utilizing basic Markdown syntax.",
      "stars": 0,
      "forks": 0,
      "license": "Do What The F*ck You Want To Public License",
      "language": "Vue",
      "updated_at": "2025-09-16T00:53:59Z",
      "readme_content": "<div align=\"center\">\n\n[![doocs-md](https://cdn-doocs.oss-cn-shenzhen.aliyuncs.com/gh/doocs/md/images/logo-2.png)](https://github.com/doocs/md)\n\n</div>\n\n<h1 align=\"center\">微信 Markdown 编辑器</h1>\n\n<div align=\"center\">\n\n[![status](https://img.shields.io/github/actions/workflow/status/doocs/md/deploy.yml?style=flat-square&labelColor=564341&color=42cc23)](https://github.com/doocs/md/actions) [![node](https://img.shields.io/badge/node-%3E%3D20-42cc23?style=flat-square&labelColor=564341)](https://nodejs.org/en/about/previous-releases) [![pr](https://img.shields.io/badge/prs-welcome-42cc23?style=flat-square&labelColor=564341)](https://github.com/doocs/md/pulls) [![stars](https://img.shields.io/github/stars/doocs/md?style=flat-square&labelColor=564341&color=42cc23)](https://github.com/doocs/md/stargazers) [![forks](https://img.shields.io/github/forks/doocs/md?style=flat-square&labelColor=564341&color=42cc23)](https://github.com/doocs/md)<br> [![release](https://img.shields.io/github/v/release/doocs/md?style=flat-square&labelColor=564341&color=42cc23)](https://github.com/doocs/md/releases) [![npm](https://img.shields.io/npm/v/@doocs/md-cli?style=flat-square&labelColor=564341&color=42cc23)](https://www.npmjs.com/package/@doocs/md-cli) [![docker](https://img.shields.io/badge/docker-latest-42cc23?style=flat-square&labelColor=564341)](https://hub.docker.com/r/doocs/md)\n\n</div>\n\n## 项目介绍\n\nMarkdown 文档自动即时渲染为微信图文，让你不再为微信内容排版而发愁！只要你会基本的 Markdown 语法（现在有了 AI，你甚至不需要会 Markdown），就能做出一篇样式简洁而又美观大方的微信图文。\n\n欢迎给项目点个 ⭐️，我们会持续更新和维护。\n\n## 在线编辑器地址\n\n[https://md.doocs.org](https://md.doocs.org)\n\n注：推荐使用 Chrome 浏览器，效果最佳。\n\n## 为何开发这款编辑器\n\n现有的开源微信 Markdown 编辑器样式繁杂，排版过程中往往需要额外调整，影响使用效率。为了解决这一问题，我们打造了一款更加简洁、优雅的编辑器，提供更流畅的排版体验。\n\n欢迎各位朋友随时提交 PR，让这款微信 Markdown 编辑器变得更好！如果你有新的想法，也欢迎在 [Discussions 讨论区](https://github.com/doocs/md/discussions)反馈。\n\n## 功能特性\n\n- [x] 支持 Markdown 所有基础语法、数学公式\n- [x] 提供对 Mermaid 图表的渲染和 [GFM 警告块](https://github.com/orgs/community/discussions/16925)的支持\n- [x] 提供 PlantUML 渲染支持\n- [x] 提供 ruby 注音扩展支持，支持两种格式：[文字]{注音}、[文字]^(注音)，支持 `・`、`．`、`。`、`-` 分隔符\n- [x] 丰富的代码块高亮主题，提升代码可读性\n- [x] 允许自定义主题色和 CSS 样式，灵活定制展示效果\n- [x] 提供多图上传功能，并可自定义配置图床\n- [x] 便捷的文件导入、导出功能，提升工作效率\n- [x] 内置本地内容管理功能，支持草稿自动保存\n- [x] 集成主流 AI 模型（如 DeepSeek、OpenAI、通义千问、腾讯混元、火山方舟 等等），辅助内容创作\n\n## 目前支持哪些图床\n\n| #   | 图床                                                   | 使用时是否需要配置                                                         | 备注                                                                                                                   |\n| --- | ------------------------------------------------------ | -------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------- |\n| 1   | 默认                                                   | 否                                                                         | -                                                                                                                      |\n| 2   | [GitHub](https://github.com)                           | 配置 `Repo`、`Token` 参数                                                  | [如何获取 GitHub token？](https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token) |\n| 3   | [阿里云](https://www.aliyun.com/product/oss)           | 配置 `AccessKey ID`、`AccessKey Secret`、`Bucket`、`Region` 参数           | [如何使用阿里云 OSS？](https://help.aliyun.com/document_detail/31883.html)                                             |\n| 4   | [腾讯云](https://cloud.tencent.com/act/pro/cos)        | 配置 `SecretId`、`SecretKey`、`Bucket`、`Region` 参数                      | [如何使用腾讯云 COS？](https://cloud.tencent.com/document/product/436/38484)                                           |\n| 5   | [七牛云](https://www.qiniu.com/products/kodo)          | 配置 `AccessKey`、`SecretKey`、`Bucket`、`Domain`、`Region` 参数           | [如何使用七牛云 Kodo？](https://developer.qiniu.com/kodo)                                                              |\n| 6   | [MinIO](https://min.io/)                               | 配置 `Endpoint`、`Port`、`UseSSL`、`Bucket`、`AccessKey`、`SecretKey` 参数 | [如何使用 MinIO？](http://docs.minio.org.cn/docs/master/)                                                              |\n| 7   | [公众号](https://mp.weixin.qq.com/)                    | 配置 `appID`、`appsecret`、`代理域名` 参数                                 | [如何使用公众号图床？](https://md-pages.doocs.org/tutorial)                                                            |\n| 8   | [Cloudflare R2](https://developers.cloudflare.com/r2/) | 配置 `AccountId`、`AccessKey`、`SecretKey`、`Bucket`、`Domain` 参数        | [如何使用 S3 API 操作 R2？](https://developers.cloudflare.com/r2/api/s3/api/)                                          |\n| 9   | [又拍云](https://www.upyun.com/)                       | 配置 `Bucket`、`Operator`、`Password`、`Domain` 参数                       | [如何使用 又拍云？](https://help.upyun.com/)                                                                           |\n| 10  | [Telegram](https://core.telegram.org/api)              | 配置 `Bot Token`、`Chat ID` 参数                                           | [如何使用 Telegram 图床？](https://github.com/doocs/md/blob/main/docs/telegram-usage.md)                               |\n| 11  | [Cloudinary](https://cloudinary.com/)                  | 配置 `Cloud Name`、`API Key`、`API Secret` 参数                            | [如何使用 Cloudinary？](https://cloudinary.com/documentation/upload_images)                                            |\n| 12  | 自定义上传                                             | 是                                                                         | [如何自定义上传？](/docs/custom-upload.md)                                                                             |\n\n![demo1](https://cdn-doocs.oss-cn-shenzhen.aliyuncs.com/gh/doocs/md/images/demo1.gif)\n\n![demo2](https://cdn-doocs.oss-cn-shenzhen.aliyuncs.com/gh/doocs/md/images/demo2.gif)\n\n![demo3](https://cdn-doocs.oss-cn-shenzhen.aliyuncs.com/gh/doocs/md/images/demo3.gif)\n\n![demo4](https://cdn-doocs.oss-cn-shenzhen.aliyuncs.com/gh/doocs/md/images/demo4.gif)\n\n## 如何开发和部署\n\n```sh\n# 安装 node 版本\nnvm i && nvm use\n\n# 安装依赖\npnpm i\n\n# 启动开发模式\npnpm web dev\n\n# 部署在 /md 目录\npnpm web build\n# 访问 http://127.0.0.1:9000/md\n\n# 部署在根目录\npnpm web build:h5-netlify\n# 访问 http://127.0.0.1:9000/\n\n# Chrome 插件启动及调试\npnpm web ext:dev\n# 访问 chrome://extensions/ 打开开发者模式，加载已解压的扩展程序，选择 .output/chrome-mv3-dev 目录\n\n# Chrome 插件打包\npnpm web ext:zip\n\n# Firefox 扩展打包(how to build Firefox addon)\npnpm web firefox:zip # output zip file at in .output/md-{version}-firefox.zip\n```\n\n## 快速搭建私有服务\n\n### 方式 1. 使用 npm cli\n\n通过我们的 npm cli 你可以轻易搭建属于自己的微信 Markdown 编辑器。\n\n```sh\n# 安装\nnpm i -g @doocs/md-cli\n\n# 启动\nmd-cli\n\n# 访问\nopen http://127.0.0.1:8800/md/\n\n# 启动并指定端口\nmd-cli port=8899\n\n# 访问\nopen http://127.0.0.1:8899/md/\n```\n\nmd-cli 支持以下命令行参数：\n\n- `port` 指定端口号，默认 8800，如果被占用会随机使用一个新端口。\n- `spaceId` dcloud 服务空间配置\n- `clientSecret` dcloud 服务空间配置\n\n### 方式 2. 使用 Docker 镜像\n\n如果你是 Docker 用户，也可以直接使用一条命令，启动完全属于你的、私有化运行的实例。\n\n```sh\ndocker run -d -p 8080:80 doocs/md:latest\n```\n\n容器运行起来之后，打开浏览器，访问 http://localhost:8080 即可。\n\n关于本项目 Docker 镜像的更多详细信息，可以关注 https://github.com/doocs/docker-md\n\n## 谁在使用\n\n请查看 [USERS.md](USERS.md) 文件，了解使用本项目的公众号。\n\n## 贡献指南\n\n我们欢迎任何形式的贡献！请查看 [CONTRIBUTING.md](./CONTRIBUTING.md) 获取提交 PR、Issue 的流程与规范。\n\n## 支持我们\n\n如果本项目对你有所帮助，可以通过以下方式支持我们的持续开发。\n\n<table style=\"margin: 0 auto\">\n  <tbody>\n    <tr>\n      <td align=\"center\" style=\"width: 260px\">\n        <img\n          src=\"https://cdn-doocs.oss-cn-shenzhen.aliyuncs.com/gh/doocs/md/images/support1.jpg\"\n          style=\"width: 200px\"\n        /><br />\n      </td>\n      <td align=\"center\" style=\"width: 260px\">\n        <img\n          src=\"https://cdn-doocs.oss-cn-shenzhen.aliyuncs.com/gh/doocs/md/images/support2.jpg\"\n          style=\"width: 200px\"\n        /><br />\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n## 反馈与交流\n\n如果你在使用过程中遇到问题，或者有好的建议，欢迎在 [Issues](https://github.com/doocs/md/issues) 中反馈。你也可以加入我们的交流群，和我们一起讨论，若群二维码失效，请添加好友，备注 `md`，我们会拉你进群。\n\n<table style=\"margin: 0 auto\">\n  <tbody>\n    <tr>\n      <td align=\"center\" style=\"width: 260px\">\n        <img\n          src=\"https://cdn-doocs.oss-cn-shenzhen.aliyuncs.com/gh/doocs/md/images/doocs-md-wechat-group.jpg\"\n          style=\"width: 200px\"\n        /><br />\n      </td>\n      <td align=\"center\" style=\"width: 260px\">\n        <img\n          src=\"https://cdn-doocs.oss-cn-shenzhen.aliyuncs.com/gh/doocs/md/images/wechat-ylb.jpg\"\n          style=\"width: 200px\"\n        /><br />\n      </td>\n    </tr>\n  </tbody>\n</table>\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "markdown",
        "formatted",
        "wxmd",
        "markdown documents",
        "basic markdown",
        "transforms markdown"
      ],
      "category": "document-processing"
    },
    "ProbonoBonobo--sui-mcp-server": {
      "owner": "ProbonoBonobo",
      "name": "sui-mcp-server",
      "url": "https://github.com/ProbonoBonobo/sui-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/ProbonoBonobo.webp",
      "description": "Enables AI agents to retrieve documents from a vector database using Retrieval-Augmented Generation (RAG) techniques. Integrates with GitHub to process Move files and incorporates a language model for generating responses based on retrieved information.",
      "stars": 4,
      "forks": 1,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-06-30T18:47:54Z",
      "readme_content": "# MCP Server with FAISS for RAG\n\nThis project provides a proof-of-concept implementation of a Machine Conversation Protocol (MCP) server that allows an AI agent to query a vector database and retrieve relevant documents for Retrieval-Augmented Generation (RAG).\n\n## Features\n\n- FastAPI server with MCP endpoints\n- FAISS vector database integration\n- Document chunking and embedding\n- GitHub Move file extraction and processing\n- LLM integration for complete RAG workflow\n- Simple client example\n- Sample documents\n\n## Installation\n\n### Using pipx (Recommended)\n\n[pipx](https://pypa.github.io/pipx/) is a tool to help you install and run Python applications in isolated environments.\n\n1. First, install pipx if you don't have it:\n\n```bash\n# On macOS\nbrew install pipx\npipx ensurepath\n\n# On Ubuntu/Debian\nsudo apt update\nsudo apt install python3-pip python3-venv\npython3 -m pip install --user pipx\npython3 -m pipx ensurepath\n\n# On Windows with pip\npip install pipx\npipx ensurepath\n```\n\n2. Install the MCP Server package directly from the project directory:\n\n```bash\n# Navigate to the directory containing the mcp_server folder\ncd /path/to/mcp-server-project\n\n# Install in editable mode\npipx install -e .\n```\n\n3. (Optional) Configure environment variables:\n   - Copy `.env.example` to `.env` \n   - Add your GitHub token for higher rate limits: `GITHUB_TOKEN=your_token_here`\n   - Add your OpenAI or other LLM API key for RAG integration: `OPENAI_API_KEY=your_key_here`\n\n### Manual Installation\n\nIf you prefer not to use pipx:\n\n1. Clone the repository\n2. Install dependencies:\n\n```bash\ncd mcp_server\npip install -r requirements.txt\n```\n\n## Usage with pipx\n\nAfter installing with pipx, you'll have access to the following commands:\n\n### Downloading Move Files from GitHub\n\n```bash\n# Download Move files with default settings\nmcp-download --query \"use sui\" --output-dir docs/move_files\n\n# Download with more options\nmcp-download --query \"module sui::coin\" --max-results 50 --new-index --verbose\n```\n\n### Improved GitHub Search and Indexing (Recommended)\n\n```bash\n# Search GitHub and index files with default settings\nmcp-search-index --keywords \"sui move\"\n\n# Search multiple keywords and customize options\nmcp-search-index --keywords \"sui move,move framework\" --max-repos 30 --output-results --verbose\n\n# Save search results and use a custom index location\nmcp-search-index --keywords \"sui coin,sui::transfer\" --index-file custom/path/index.bin --output-results\n```\n\nThe `mcp-search-index` command provides enhanced GitHub repository search capabilities:\n- Searches repositories first, then recursively extracts Move files\n- Supports multiple search keywords (comma-separated)\n- Intelligently filters for Move files containing \"use sui\" references\n- Always rebuilds the vector database after downloading\n\n### Indexing Move Files\n\n```bash\n# Index files in the default location\nmcp-index\n\n# Index with custom options\nmcp-index --docs-dir path/to/files --index-file path/to/index.bin --verbose\n```\n\n### Querying the Vector Database\n\n```bash\n# Basic query\nmcp-query \"What is a module in Sui Move?\"\n\n# Advanced query with options\nmcp-query \"How do I define a struct in Sui Move?\" -k 3 -f\n```\n\n### Using RAG with LLM Integration\n\n```bash\n# Basic RAG query (will use simulated LLM if no API key is provided)\nmcp-rag \"What is a module in Sui Move?\"\n\n# Using with a specific LLM API\nmcp-rag \"How do I define a struct in Sui Move?\" --api-key your_api_key --top-k 3\n\n# Output as JSON for further processing\nmcp-rag \"What are the benefits of sui::coin?\" --output-json > rag_response.json\n```\n\n### Running the Server\n\n```bash\n# Start the server with default settings\nmcp-server\n\n# Start with custom settings\nmcp-server --host 127.0.0.1 --port 8080 --index-file custom/path/index.bin\n```\n\n## Manual Usage (without pipx)\n\n### Starting the server\n\n```bash\ncd mcp_server\npython main.py\n```\n\nThe server will start on http://localhost:8000\n\n### Downloading Move Files from GitHub\n\nTo download Move files from GitHub and populate your vector database:\n\n```bash\n# Download Move files with default query \"use sui\"\n./run.sh --download-move\n\n# Customize the search query\n./run.sh --download-move --github-query \"module sui::coin\" --max-results 50\n\n# Download, index, and start the server\n./run.sh --download-move --index\n```\n\nYou can also use the Python script directly:\n\n```bash\npython download_move_files.py --query \"use sui\" --output-dir docs/move_files\n```\n\n### Indexing documents\n\nBefore querying, you need to index your documents. You can place your text files (.txt), Markdown files (.md), or Move files (.move) in the `docs` directory.\n\nTo index the documents, you can either:\n\n1. Use the run script with the `--index` flag:\n\n```bash\n./run.sh --index\n```\n\n2. Use the index script directly:\n\n```bash\npython index_move_files.py --docs-dir docs/move_files --index-file data/faiss_index.bin\n```\n\n### Querying documents\n\nYou can use the local query script:\n\n```bash\npython local_query.py \"What is RAG?\"\n\n# With more options\npython local_query.py -k 3 -f \"How to define a struct in Sui Move?\"\n```\n\n### Using RAG with LLM Integration\n\n```bash\n# Direct RAG query with an LLM\npython rag_integration.py \"What is a module in Sui Move?\" --index-file data/faiss_index.bin\n\n# With API key (if you have one)\nOPENAI_API_KEY=your_key_here python rag_integration.py \"How do coins work in Sui?\"\n```\n\n### MCP API Endpoint\n\nThe MCP API endpoint is available at `/mcp/action`. You can use it to perform different actions:\n\n- `retrieve_documents`: Retrieve relevant documents for a query\n- `index_documents`: Index documents from a directory\n\nExample:\n\n```bash\ncurl -X POST \"http://localhost:8000/mcp/action\" -H \"Content-Type: application/json\" -d '{\"action_type\": \"retrieve_documents\", \"payload\": {\"query\": \"What is RAG?\", \"top_k\": 3}}'\n```\n\n## Complete RAG Pipeline\n\nThe full RAG (Retrieval-Augmented Generation) pipeline works as follows:\n\n1. **Search Query**: The user submits a question\n2. **Retrieval**: The system searches the vector database for relevant documents\n3. **Context Formation**: Retrieved documents are formatted into a prompt\n4. **LLM Generation**: The prompt is sent to an LLM with the retrieved context\n5. **Enhanced Response**: The LLM provides an answer based on the retrieved information\n\nThis workflow is fully implemented in the `rag_integration.py` module, which can be used either through the command line or as a library in your own applications.\n\n## GitHub Move File Extraction\n\nThe system can extract Move files from GitHub based on search queries. It implements two methods:\n\n1. **GitHub API** (preferred): Requires a GitHub token for higher rate limits\n2. **Web Scraping fallback**: Used when API method fails or when no token is provided\n\nTo configure your GitHub token, set it in the `.env` file or as an environment variable:\n\n```\nGITHUB_TOKEN=your_github_token_here\n```\n\n## Project Structure\n\n```\nmcp_server/\n├── __init__.py             # Package initialization\n├── main.py                # Main server file\n├── mcp_api.py             # MCP API implementation\n├── index_move_files.py    # File indexing utility\n├── local_query.py         # Local query utility\n├── download_move_files.py # GitHub Move file extractor\n├── rag_integration.py     # LLM integration for RAG\n├── pyproject.toml         # Package configuration\n├── requirements.txt       # Dependencies\n├── .env.example           # Example environment variables\n├── README.md              # This file\n├── data/                  # Storage for the FAISS index\n├── docs/                  # Sample documents\n│   └── move_files/        # Downloaded Move files\n├── models/                # Model implementations\n│   └── vector_store.py    # FAISS vector store implementation\n└── utils/\n    ├── document_processor.py  # Document processing utilities\n    └── github_extractor.py    # GitHub file extraction utilities\n```\n\n## Extending the Project\n\nTo extend this proof-of-concept:\n\n1. Add authentication and security features\n2. Implement more sophisticated document processing\n3. Add support for more document types\n4. Integrate with other LLM providers\n5. Add monitoring and logging\n6. Improve the Move language parsing for more structured data extraction\n\n## License\n\nMIT ",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "retrieval",
        "documents",
        "ai",
        "document processing",
        "retrieve documents",
        "documents vector"
      ],
      "category": "document-processing"
    },
    "Props-Labs--fireflies-mcp": {
      "owner": "Props-Labs",
      "name": "fireflies-mcp",
      "url": "https://github.com/Props-Labs/fireflies-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/Props-Labs.webp",
      "description": "Retrieve, search, and summarize meeting transcripts. Manage transcripts with advanced search capabilities and generate concise summaries in various formats.",
      "stars": 4,
      "forks": 11,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-08-14T03:08:02Z",
      "readme_content": "# Fireflies MCP Server\n\nMCP Server for the Fireflies.ai API, enabling transcript retrieval, search, and summary generation.\n\n### Features\n\n- **Transcript Management**: Retrieve and search meeting transcripts with filtering options\n- **Detailed Information**: Get comprehensive details about specific transcripts\n- **Advanced Search**: Find transcripts containing specific keywords or phrases\n- **Summary Generation**: Generate concise summaries of meeting transcripts in different formats\n\n\n## Tools\n\n1. `fireflies_get_transcripts`\n   - Retrieve a list of meeting transcripts with optional filtering\n   - Inputs:\n     - `limit` (optional number): Maximum number of transcripts to return\n     - `from_date` (optional string): Start date in ISO format (YYYY-MM-DD)\n     - `to_date` (optional string): End date in ISO format (YYYY-MM-DD)\n   - Returns: Array of transcript objects with basic information\n\n2. `fireflies_get_transcript_details`\n   - Get detailed information about a specific transcript\n   - Inputs:\n     - `transcript_id` (string): ID of the transcript to retrieve\n   - Returns: Comprehensive transcript details including speakers, content, and metadata\n\n3. `fireflies_search_transcripts`\n   - Search for transcripts containing specific keywords\n   - Inputs:\n     - `query` (string): Search query to find relevant transcripts\n     - `limit` (optional number): Maximum number of transcripts to return\n   - Returns: Array of matching transcript objects\n\n4. `fireflies_generate_summary`\n   - Generate a summary of a meeting transcript\n   - Inputs:\n     - `transcript_id` (string): ID of the transcript to summarize\n     - `format` (optional string): Format of the summary ('bullet_points' or 'paragraph')\n   - Returns: Generated summary text\n\n## Setup\n\n### Fireflies API Key\n[Create a Fireflies API Key](https://fireflies.ai/dashboard/settings/api) with appropriate permissions:\n   - Go to the Fireflies.ai dashboard\n   - Navigate to Settings > API\n   - Generate a new API key\n   - Copy the generated key\n\n### Usage with Claude Desktop\nTo use this with Claude Desktop, add the following to your `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"fireflies\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@props-labs/mcp/fireflies\"\n      ],\n      \"env\": {\n        \"FIREFLIES_API_KEY\": \"<YOUR_API_KEY>\"\n      }\n    }\n  }\n}\n```\n\n## Installation\n\n1. Clone this repository\n2. Install dependencies:\n\n```bash\nnpm install\n# or\npnpm install\n```\n\n3. Build the project:\n\n```bash\nnpm run build\n# or\npnpm build\n```\n\n## Usage\n\n### Starting the Server\n\n```bash\nFIREFLIES_API_KEY=your_api_key npm start\n# or\nFIREFLIES_API_KEY=your_api_key pnpm start\n```\n\nYou can also use the setup script:\n\n```bash\n./setup.sh\nFIREFLIES_API_KEY=your_api_key npm start\n```\n\n## License\n\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository. ",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "transcripts",
        "search",
        "formats",
        "meeting transcripts",
        "transcripts manage",
        "transcripts advanced"
      ],
      "category": "document-processing"
    },
    "Qwinty--anytype-mcp": {
      "owner": "Qwinty",
      "name": "anytype-mcp",
      "url": "https://github.com/Qwinty/anytype-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/Qwinty.webp",
      "description": "Access and manage Anytype data, including spaces, objects, and templates. Perform searches, create and delete spaces, and export objects in markdown format.",
      "stars": 21,
      "forks": 4,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-09-18T20:07:55Z",
      "readme_content": "# OFFICIAL ANYTYPE MCP WAS RELEASED HERE\nhttps://github.com/anyproto/anytype-mcp\n\n# Anytype MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@Qwinty/anytype-mcp)](https://smithery.ai/server/@Qwinty/anytype-mcp)\n\nAn MCP (Model Context Protocol) server that provides access to the Anytype API, allowing AI assistants and other MCP clients to interact with your Anytype data.\n\n**Based on the Anytype API definition v0.46+ (2025-03-17).**\nEnsure your Anytype Desktop version is compatible.\n\n## Features\n\n- Get list of spaces (`get_spaces`)\n- Search/Get objects within a space (`get_objects`, `search_space`) or globally (`global_search`)\n- Get detailed object content (`get_object_content`, supports retrieving full text)\n- Create and delete spaces (`create_space`) and objects (`create_object`, `delete_object`)\n- Export objects as markdown (`export_object`)\n- Manage list views and objects within lists (`get_list_views`, `get_list_view_objects`, `add_objects_to_list`, `remove_object_from_list`)\n- Get space members (`get_space_members`)\n- Get types and templates (`get_types`, `get_type_details`, `get_templates`, `get_template_details`)\n\n## Prerequisites\n\n- Node.js 18 or higher\n- Anytype desktop application running locally\n- An Anytype account\n\n## Installation\n\n### Manual Installation\n\n1. Clone this repository:\n\n   ```cli\n   git clone https://github.com/Qwinty/anytype-mcp.git\n   cd anytype-mcp\n   ```\n\n2. Install dependencies:\n\n   ```node\n   npm install\n   ```\n\n3. Build the project (compiles TypeScript to JavaScript in `build/`):\n\n   ```node\n   npm run build\n   ```\n\n4. **Obtain an App Key:** Before configuring the server, you need an App Key from Anytype. See the \"Getting an App Key\" section below.\n5. Add the MCP server to your MCP configuration file\n\n## Getting an App Key\n\nBefore using the MCP server, you need to obtain an app key from the Anytype desktop application:\n\n1. Make sure Anytype desktop is running\n2. Run the helper script:\n\n   ```node\n   npm run get-key\n   ```\n\n3. Follow the instructions to authorize the application\n4. Note the app key for configuration\n\n## Configuration\n\nAdd the Anytype MCP server to your MCP configuration file:\n\n- For Claude: Edit `claude_desktop_config.json`\n- For other MCP clients: Edit their respective configuration files\n\nExample configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"anytype\": {\n      \"command\": \"node\",\n      \"args\": [\"{path/to/anytype-mcp}/build/index.js\"],\n      \"env\": {\n        \"ANYTYPE_APP_KEY\": \"YOUR_APP_KEY_HERE\"\n      },\n      \"disabled\": false\n    }\n  }\n}\n```\n\nReplace `path/to/anytype-mcp` with the actual path to your installation and `YOUR_APP_KEY_HERE` with the app key you obtained.\n\n## Usage\n\n### Starting the server\n\nThe MCP server is usually started automatically by the MCP client. However, you can also start it manually for testing:\n\n```node\nnpm start\n```\n\n### Available Tools\n\nSee [Tools.md](docs/Tools.md) for a detailed list of available tools and their usage examples.\n\n### System Prompt\n\nAdditionally, a sample system prompt for AI assistants using this server is available in [docs/system-prompt.md](docs/system-prompt.md).\n\n## Token Efficiency and Data Filtering\n\nTo optimize for token usage with AI assistants, this MCP server implements response filtering by default for tools that return object data (`get_objects`, `global_search`, `search_space`).\n\n- **Default Behavior:** The server returns a simplified version of object data, including essential metadata like ID, name, type, icon, layout, space ID, root ID, snippet (if available), block count, tags, creation/modification dates, and creator info. Full block content and detailed relations are omitted.\n- **`include_text: true`:** Several tools (`get_objects`, `get_object_content`, `global_search`, `search_space`) support an optional `include_text` parameter. When set to `true`, the server will extract and include the full, formatted text content from the object's blocks in a `full_text` field. Use this when you need the complete text, but be aware it significantly increases response size and token count.\n- **`full_response: true`:** The `get_objects`, `global_search`, and `search_space` tools also support a `full_response` parameter. Setting this to `true` bypasses all filtering and returns the raw, complete JSON response directly from the Anytype API. This provides the most detail but uses the most tokens.\n\nChoose the appropriate parameters based on whether you need just metadata, full text content, or the complete raw API response.\n\n## Troubleshooting\n\n### Anytype API Not Responding\n\nMake sure the Anytype desktop application is running on your computer. The MCP server connects to the local Anytype API at `http://localhost:31009/v1`.\n\n### Authentication Issues\n\nIf you encounter authentication errors:\n\n1. Run `npm run get-key` to obtain a new app key\n2. Update your MCP configuration with the new key\n3. Restart your MCP client\n\n### Local API Port\n\nThe server connects to the Anytype API at `http://localhost:31009/v1` by default. If your Anytype installation uses a different port, you currently need to modify the `apiBaseUrl` variable in `src/index.ts` and rebuild (`npm run build`). Making this configurable via an environment variable is a potential future improvement.\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "qwinty",
        "markdown",
        "templates",
        "qwinty anytype",
        "processing qwinty",
        "manage anytype"
      ],
      "category": "document-processing"
    },
    "R-lz--mcp-video-digest": {
      "owner": "R-lz",
      "name": "mcp-video-digest",
      "url": "https://github.com/R-lz/mcp-video-digest",
      "imageUrl": "/freedevtools/mcp/pfp/R-lz.webp",
      "description": "Extract audio from various video platforms like YouTube and TikTok, and convert the audio to text using multiple transcription services. Supports asynchronous processing and speaker separation for enhanced video content analysis.",
      "stars": 26,
      "forks": 5,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-28T10:53:07Z",
      "readme_content": "# MCP Video Digest (视频内容提取总结)\n\n<div align=\"right\">\n  <a href=\"README_EN.md\">English</a> | <b>中文</b>\n</div>\n\n## 项目简介\nMCP Video Digest 是一个视频内容处理服务，,能够从 YouTube、Bilibili、TikTok、Twitter... 视频中提取音频并转换为文本。该服务支持多个转录服务提供商，包括 Deepgram、Gladia、Speechmatics 和 AssemblyAI，可以根据配置的 API 密钥灵活选择使用。(第一个MCP练手的项目,主要熟悉MCP的开发和运行流程)\n\n## 功能特点\n- 支持超过1000个网站上的流媒体内容下载和音频提取\n- 多个转录服务提供商支持：\n  - Deepgram\n  - Gladia\n  - Speechmatics\n  - AssemblyAI\n- 灵活的服务选择机制，根据可用的 API 密钥自动选择服务\n- 异步处理设计，提高并发性能\n- 完整的错误处理和日志记录\n- 支持说话人分离\n- × 支持本地模型cpu/gpu加速处理\n\n## 目录结构\n```\n.\n├── src/                    # 源代码目录\n│   ├── services/          # 服务实现目录\n│   │   ├── download/      # 下载服务\n│   │   └── transcription/ # 转录服务\n│   ├── main.py           # 主程序逻辑\n│   └── __init__.py       # 包初始化文件\n├── config/                # 配置文件目录\n├── test.py               # 测试脚本\n├── run.py                # 服务启动脚本\n├── pyproject.toml        # 项目配置和依赖管理\n├── uv.lock               # UV 依赖锁定文件\n└── .env                  # 环境变量配置\n```\n\n## 测试截图\n\n\n\n\n\n## 安装说明\n\n### 1. 安装 uv 或使用 python\n如果还没有安装 uv，可以使用以下命令安装：\n```bash\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n```\n\n\n### 2. 克隆项目：\n```bash\ngit clone https://github.com/R-lz/mcp-video-digest.git\ncd mcp-video-digest\n```\n\n### 3. 创建并激活虚拟环境：\n```bash\nuv venv\nsource .venv/bin/activate  # Linux/Mac\n# 或\n.venv\\Scripts\\activate     # Windows\n```\n\n### 4. 安装依赖：\n```bash\nuv pip install -e .\n```\n\n> speechmatics 在使用requests调试的时候出现了各种问题(不是speechmatics的问题, 是我菜),所以使用了speechmatics sdk\n\n## 配置说明\n1. 在项目根目录创建 `.env` 文件或者重命名`.env.example`，配置所需的 API 密钥：\n   ```\n   mv .env.example .env\n\n   # 修改\n   DEEPGRAM_API_KEY=your_deepgram_key\n   GLADIA_API_KEY=your_gladia_key\n   SPEECHMATICS_API_KEY=your_speechmatics_key\n   ASSEMBLYAI_API_KEY=your_assemblyai_key\n   ```\n   注意：至少需要配置一个服务的 API 密钥\n\n2. 服务优先级顺序：\n   - Deepgram（推荐用于中文内容）\n   - Gladia\n   - Speechmatics\n   - AssemblyAI\n\n## 使用方法\n1. 启动服务：\n   ```bash\n   uv run src/main.py\n   ```\n   或者使用调试模式：\n   ```bash\n   UV_DEBUG=1 uv run src/main.py\n   ```\n\n2. 调用服务：\n   ```python\n   from mcp.client import MCPClient\n   \n   async def process_video():\n       client = MCPClient()\n       result = await client.call(\n           \"get_video_content\",\n           url=\"https://www.youtube.com/watch?v=video_id\"\n       )\n       print(result)\n   ```\n\n3. 客户端SSE为示例\n```bash\n{\n    \"mcpServers\": {\n      \"video_digest\": {\n        \"url\": \"http://<ip>:8000/sse\"\n    }\n  }\n}\n\n\n# 当然可以在Client传递Key\n\n\"env\": {\n   \"DEEPGRAM_API_KEY\":\"your_deepgram_key\"\n}\n\n```\n\n> STDIO方式修改启动命令即可:未验证和测试 [MCP文档](https://modelcontextprotocol.io/)\n\n\n\n## 测试\n运行测试脚本：\n```bash\nuv run test.py \n# 或\npython test.py\n```\n\n测试脚本会：\n- 验证环境变量配置\n- 测试 YouTube 下载功能\n- 测试各个转录服务\n- 测试完整的视频处理流程\n\n## 开发指南\n1. 添加新的转录服务：\n   - 在 `src/services/transcription/` 目录下创建新的服务类\n   - 继承 `BaseTranscriptionService` 类\n   - 实现 `transcribe` 方法\n\n2. 自定义下载服务：\n   - 在 `src/services/download/` 目录下修改或添加新的下载器\n   - 继承或修改 `YouTubeDownloader` 类\n\n## 依赖管理\n- 使用 `uv pip install package_name` 安装新依赖\n- 使用 `uv pip freeze > requirements.txt` 导出依赖列表\n- 使用 `pyproject.toml` 管理依赖，`uv.lock` 锁定依赖版本\n\n## 错误处理\n服务会处理以下情况：\n- API 密钥缺失或无效\n- 视频下载失败\n- 音频转录失败\n- 网络连接问题\n- 服务限制和配额\n\n## 注意事项\n1. 确保有足够的磁盘空间用于临时文件\n2. 注意各服务提供商的 API 使用限制\n3. 建议使用 Python 3.11 或更高版本\n4. 临时文件会自动清理\n5. 使用 uv 可以获得更快的依赖安装速度和更好的依赖管理\n6. YouTube下载可能需要身份验证,可以复制cookie到根目录下cookies.txt [使用插件快速生成](https://chromewebstore.google.com/detail/get-cookiestxt-locally/cclelndahbckbenkjhflpdbgdldlbecc) 或者使用cookies-from-browser等其他认证方式, [yt-dlp](https://github.com/yt-dlp/yt-dlp)\n\n\n## STT Key申请及免费额度\n- [Speechmatics](https://www.speechmatics.com/) 每月免费8小时 - [定价](https://www.speechmatics.com/pricing)\n- [Gladia](https://app.gladia.io/) 每月免费10小时 - [定价](https://app.gladia.io/billing)\n- [AssemblyAI](https://www.assemblyai.com/) 共50$免费额度 - [定价](https://www.assemblyai.com/pricing)\n- [Deepgram](https://deepgram.com/) 共200$的免费额度 - [定价](https://deepgram.com/pricing)\n\n\n> 内容仅供参考\n\n## 许可证\n采用 MIT 许可证。",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "transcription",
        "audio",
        "extract",
        "extract audio",
        "video digest",
        "audio text"
      ],
      "category": "document-processing"
    },
    "Ransom-Alpha--Swarms_MCPserver": {
      "owner": "Ransom-Alpha",
      "name": "Swarms_MCPserver",
      "url": "https://github.com/Ransom-Alpha/Swarms_MCPserver",
      "imageUrl": "/freedevtools/mcp/pfp/Ransom-Alpha.webp",
      "description": "Retrieve and interact with documentation databases using hybrid semantic and keyword search. Automatically index and reindex various file types while supporting live file watching and low-latency document querying through a FastMCP tools API.",
      "stars": 0,
      "forks": 1,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-05-01T02:44:56Z",
      "readme_content": "# 🐝 Swarms MCP Documentation Server\n\n<p align=\"center\">\n  <img src=\"https://img.shields.io/badge/Windsurf_Ready-✅-orange\" alt=\"IDE Ready\">\n  <img src=\"https://img.shields.io/badge/Error_Tolerant-✅-green\" alt=\"Error Tolerant\">\n  <img src=\"https://img.shields.io/badge/Dynamic_MD_Loader-✅-blue\" alt=\"Dynamic MD Loader\">\n  <img src=\"https://img.shields.io/badge/Healthcheck_Tool-✅-success\" alt=\"Healthcheck Tool\">\n  <img src=\"https://img.shields.io/badge/Smart_Load_Logs-✅-purple\" alt=\"Smart Load Logs\">\n</p>\n\n![Version 2.2](https://img.shields.io/badge/Version-2.2-blueviolet)\n\n---\n\n## 📖 Description\n\nThis program is an **Agent Framework** Documentation MCP Server built on **FastMCP**, designed to enable **AI agents** to efficiently retrieve information from your documentation database. It combines hybrid semantic (vector) and keyword (BM25) search, chunked indexing, and a robust FastMCP tools API for seamless agent integration.\n\n**Key Capabilities:**\n- Efficient, chunk-level retrieval using both semantic and keyword search\n- Agents can query, list, and retrieve documentation using FastMCP tools\n- Local-first, low-latency design (all data indexed and queried locally)\n- Automatic reindexing on file changes\n- Modular: add any repos to `corpora/`, support for all major filetypes\n- Extensible: add new tools, retrievers, or corpora as needed\n\n**Main modules:**\n- `embed_documents.py` → Loads, chunks, and embeds documents\n- `swarms_server.py` → Brings up the MCP server and FastMCP tools\n\n---\n\n---\n\n## 🌟 Key Features\n\n- **Hybrid Retriever** 🔍: Combines semantic and keyword search.\n- **Dynamic Markdown Handling** 📄: Smart loader based on file size.\n- **Specialized Loaders** ⚙️: `.py`, `.ipynb`, `.md`, `.txt`, `.yaml`, `.yml`.\n- **Chunk and File Summaries** 📈: Displays chunk counts along with file counts.\n- **Live Watchdog** 🔥: Instantly responds to any changes in `corpora/`.\n- **User Confirmation for Costs** ✅: Confirms before expensive embeddings.\n- **Healthcheck Endpoint** 🚑: Ensure server is ready for use.\n- **Local-First** 🗂️: All repos indexed locally without external dependencies.\n- **Safe Deletion Helper** 🔥: Auto-delete broken/mismatched indexes.\n\n---\n\n## 🏗️ Version History\n\n| Version | Date       | Highlights                                                              |\n| ------- | ---------- | ---------------------------------------------------------------------- |\n| **2.2** | 2025‑04‑25 | Split embed/load from server; full chunk counting in loading summaries |\n| **1.0** | 2025‑04‑25 | Dynamic Markdown loader, color logs, Healthcheck tool                  |\n| **0.7** | 2025‑04‑25 | Specialized file loaders for `.py`, `.ipynb`, `.md`                    |\n| **0.5** | 2025‑04‑10 | OpenAI large model embeddings, extended MCP tools                      |\n| **0.1** | 2025‑04‑10 | Initial version with generic loaders                                   |\n\n---\n\n## 📚 Managing Your Corpora (Local Repos)\n\nBecause Swarms and other frameworks are **very large**, full corpora are **not** pushed to GitHub.\n\nInstead, you **clone** them manually under `corpora/`:\n\n```bash\n# Inside your project folder:\ncd corpora/\n\n# Clone useful frameworks:\ngit clone https://github.com/SwarmsAI/Swarms\ngit clone https://github.com/SwarmsAI/Swarms-Examples\ngit clone https://github.com/microsoft/autogen\ngit clone https://github.com/langchain-ai/langgraph\ngit clone https://github.com/openai/openai-agent-sdk\n```\n\n✅ **Notes:**\n- Add **any repo** — public, private, custom.\n- Build your own custom AI knowledge base locally.\n- **Large repos** (>500MB) are fine; all indexing is local.\n\n---\n\n## 🚀 Quick Start\n\n```powershell\n# 1. Activate virtual environment\nvenv\\Scripts\\Activate.ps1\n\n# 2. Install all dependencies\npip install -r requirements.txt\n\n# 3. Configure OpenAI API Key\necho OPENAI_API_KEY=sk-... > .env\n\n# 4. (Load and embed documents\npython embed_documents.py\n\n# 5. Start MCP server\npython swarms_server.py\n# If no index is found, the server will prompt you to embed documents automatically.\n```\n\n---\n\n## ⚙️ Configuration\n\n- **Corpus**: Drop repos inside `corpora/`\n- **Environment Variables**:\n  - `.env` must contain `OPENAI_API_KEY`\n- **Index File Support**:\n  - Both `chroma-collections.parquet` and `chroma.sqlite3` are supported. `.parquet` is preferred if both exist.\n- **Auto-Embedding**:\n  - If no index is found, the server will prompt you to embed and index your documents automatically.\n- **Optional**:\n  - Disable Chroma compaction if you prefer:\n    ```powershell\n    setx CHROMA_COMPACTION_SERVICE__COMPACTOR__DISABLED_COLLECTIONS \"swarms_docs\"\n    ```\n- **Command-Line Flags**:\n  - `--reindex` → trigger a refresh reindex during server run.\n\n---\n\n## 🔄 File Watching & Auto Reindexing\n\nThe MCP Server watches `corpora/` for any file changes:\n- Any modification, creation, or deletion triggers a **live** reindex.\n- No need to restart the server.\n\n---\n\n## 🛠️ Available FastMCP Tools\n\n| Tool                      | Description                                          |\n| ------------------------- | ---------------------------------------------------- |\n| `swarm_docs.search`       | Search relevant documentation chunks                |\n| `swarm_docs.list_files`   | List all indexed files                               |\n| `swarm_docs.get_chunk`    | Get a specific chunk by path and index               |\n| `swarm_docs.reindex`      | Force reindex (full or incremental)                  |\n| `swarm_docs.healthcheck`  | Check MCP Server status                              |\n\n---\n\n## ❓ Troubleshooting\n\n- **Q: I get 'No valid existing index found' when starting the server.**\n  - A: The server will now prompt you to embed and index documents. Accept the prompt to proceed, or run `python embed_documents.py` manually first.\n- **Q: Which index file is used?**\n  - A: The server will use `chroma-collections.parquet` if available, otherwise `chroma.sqlite3`.\n- **Q: I want to force a reindex.**\n  - A: Run `python swarms_server.py --reindex` or use the `swarm_docs.reindex` tool.\n\n---\n\n## 📋 Example Usage\n\n```python\n# Search the documentation\nresult = swarm_docs.search(\"How do I load a notebook?\")\nprint(result)\n\n# List all available files\nfiles = swarm_docs.list_files()\nprint(files)\n\n# Get a specific document chunk\nchunk = swarm_docs.get_chunk(path=\"examples/agent.py\", chunk_idx=2)\nprint(chunk[\"content\"])\n```\n\n---\n\n## 🧰 Extending & Rebuilding\n\n- **Add new docs** → drop into `corpora/`, then:\n  ```bash\n  python swarms_server.py --reindex\n  ```\n- **Schema changes** → (e.g. different metadata structure):\n  ```bash\n  python swarms_server.py --reindex --full\n  ```\n- **Add new repo** → Drop folder under `corpora/`, reindex.\n\n- **Recommended for mostly read-only repos**:\n  ```powershell\n  setx CHROMA_COMPACTION_SERVICE__COMPACTOR__DISABLED_COLLECTIONS \"swarms_docs\"\n  ```\n\n---\n\n## 🔗 IDE Integration\n\nPlug directly into Windsurf Cascade:\n\n```jsonc\n\"swarms\": {\n  \"command\": \"C:/…/Swarms/venv/Scripts/python.exe\",\n  \"args\": [\"swarms_server.py\"]\n}\n```\n\nThen you can access `swarm_docs.*` tools from Cascade automations.\n\n---\n\n## 📦 Requirements\n\n### 💡 Python 3.11 Environment Required\n\nCreate your environment explicitly:\n\n```bash\npython3.11 -m venv venv\n```\n\nThen install with:\n\n```bash\npip install -r requirements.txt\n```\n\n---\n\n## ✅ MCP Server Ready\n\nAfter boot:\n- Proper loading summaries\n- Safe confirmation before expensive actions\n- Auto file watching and reindexing\n- Windsurf plug-in ready\n- Full tool coverage\n\n**You're good to cascade it!** 🏄‍♂️\n\n---\n\n## 📈 Flow Diagram\n\n```\n                          +------------------+\n                          |    🖥️ MCP Server  |\n                          +------------------+\n                                  |\n     +---------------------------------------------------+\n     |                                                   |\n+-------------+                                     +-----------------+\n|  📁 Corpora |                                     | 🔎 FastMCP Tools |\n|  Folder     |                                     | (search, list,   |\n|  (markdown, |                                     | get_chunk, etc.) |\n|  code, etc) |                                     +-----------------+\n+-------------+                                               |\n      |                                                       |\n+-----------------+                                   +----------------+\n|  📚 Loaders      |                                   | 🧠 Ensemble    |\n| (Python, MD, TXT)|                                   | Retriever (BM25|\n|  Split into Chunks|                                  | + Chroma)      |\n+-----------------+                                   +----------------+\n      |                                                       |\n+-----------------+                                   +----------------+\n| ✂️ Text Splitter |                                   | 🧩 Similarity   |\n| (RecursiveCharacter) |                              | Search (chunks) |\n+-----------------+                                   +----------------+\n      |                                                       |\n+-----------------+                                   +----------------+\n| 💾 Embed chunks  |  —OpenAI Embedding (small)—>    | 🛢️ Chroma Vector |\n| via OpenAI API  |                                   | DB (Local Store) |\n+-----------------+                                   +----------------+\n      |                                                       |\n+-----------------+                                   +----------------+\n| 📡 Reindex Watcher|                                  | 👀 File Watchdog |\n| (Auto detect      |                                  | (Auto reindex   |\n| new/modified files|                                  | on file events) |\n+-----------------+                                   +----------------+\n```\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ransom",
        "fastmcp",
        "document",
        "document querying",
        "document processing",
        "documentation databases"
      ],
      "category": "document-processing"
    },
    "Rupeebw--mcp-image-reader": {
      "owner": "Rupeebw",
      "name": "mcp-image-reader",
      "url": "https://github.com/Rupeebw/mcp-image-reader",
      "imageUrl": "/freedevtools/mcp/pfp/Rupeebw.webp",
      "description": "Manage and summarize text notes efficiently with this MCP server, which supports creating, accessing, and summarizing notes through unique URIs. It integrates note management and summarization capabilities for enhanced workflows with LLMs.",
      "stars": 0,
      "forks": 1,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-03-17T17:20:57Z",
      "readme_content": "# image-reader MCP Server\n\nimage reader\n\nThis is a TypeScript-based MCP server that implements a simple notes system. It demonstrates core MCP concepts by providing:\n\n- Resources representing text notes with URIs and metadata\n- Tools for creating new notes\n- Prompts for generating summaries of notes\n\n## Features\n\n### Resources\n- List and access notes via `note://` URIs\n- Each note has a title, content and metadata\n- Plain text mime type for simple content access\n\n### Tools\n- `create_note` - Create new text notes\n  - Takes title and content as required parameters\n  - Stores note in server state\n\n### Prompts\n- `summarize_notes` - Generate a summary of all stored notes\n  - Includes all note contents as embedded resources\n  - Returns structured prompt for LLM summarization\n\n## Development\n\nInstall dependencies:\n```bash\nnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n```bash\nnpm run watch\n```\n\n## Installation\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"image-reader\": {\n      \"command\": \"/path/to/image-reader/build/index.js\"\n    }\n  }\n}\n```\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "notes",
        "mcp",
        "document",
        "note management",
        "summarizing notes",
        "notes efficiently"
      ],
      "category": "document-processing"
    },
    "Rz017--tavily-mcp": {
      "owner": "Rz017",
      "name": "tavily-mcp",
      "url": "https://github.com/Rz017/tavily-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/Rz017.webp",
      "description": "Integrates real-time web search and intelligent data extraction to enhance AI assistants with up-to-date information and sophisticated filtering capabilities. Supports domain-specific data retrieval and processing features for improved AI workflows.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "",
      "updated_at": "2025-04-26T20:17:27Z",
      "readme_content": "# Tavily MCP Server 🚀\n\n![GitHub Repo stars](https://img.shields.io/github/stars/tavily-ai/tavily-mcp?style=social)\n![npm](https://img.shields.io/npm/dt/tavily-mcp)\n![smithery badge](https://smithery.ai/badge/@tavily-ai/tavily-mcp)\n\n> 🔌 **Compatible with [Cline](https://github.com/cline/cline), [Cursor](https://cursor.sh), [Claude Desktop](https://claude.ai/desktop), and any other MCP Clients!**\n>\n> Tavily MCP is also compatible with any MCP client\n>\n> 📚  [tutorial](https://medium.com/@dustin_36183/building-a-knowledge-graph-assistant-combining-tavily-and-neo4j-mcp-servers-with-claude-db92de075df9) on combining Tavily MCP with Neo4j MCP server!\n> \n> 📚  [tutorial](https://medium.com/@dustin_36183/connect-your-coding-assistant-to-the-web-integrating-tavily-mcp-with-cline-in-vs-code-5f923a4983d1) Integrating Tavily MCP with Cline in VS Code ( Demo + Example Use-Cases)\n>\n\n\n\nThe Model Context Protocol (MCP) is an open standard that enables AI systems to interact seamlessly with various data sources and tools, facilitating secure, two-way connections.\n\nDeveloped by Anthropic, the Model Context Protocol (MCP) enables AI assistants like Claude to seamlessly integrate with Tavily's advanced search and data extraction capabilities. This integration provides AI models with real-time access to web information, complete with sophisticated filtering options and domain-specific search features.\n\nThe Tavily MCP server provides:\n- Seamless interaction with the tavily-search and tavily-extract tools\n- Real-time web search capabilities through the tavily-search tool\n- Intelligent data extraction from web pages via the tavily-extract tool\n\n\n## Prerequisites 🔧\n\nBefore you begin, ensure you have:\n\n- [Tavily API key](https://app.tavily.com/home)\n  - If you don't have a Tavily API key, you can sign up for a free account [here](https://app.tavily.com/home)\n- [Claude Desktop](https://claude.ai/download) or [Cursor](https://cursor.sh)\n- [Node.js](https://nodejs.org/) (v20 or higher)\n  - You can verify your Node.js installation by running:\n    - `node --version`\n- [Git](https://git-scm.com/downloads) installed (only needed if using Git installation method)\n  - On macOS: `brew install git`\n  - On Linux: \n    - Debian/Ubuntu: `sudo apt install git`\n    - RedHat/CentOS: `sudo yum install git`\n  - On Windows: Download [Git for Windows](https://git-scm.com/download/win)\n\n## Tavily MCP server installation ⚡\n\n### Running with NPX \n\n```bash\nnpx -y tavily-mcp@0.1.4  \n```\n\n### Installing via Smithery\n\nTo install Tavily MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@tavily-ai/tavily-mcp):\n\n```bash\nnpx -y @smithery/cli install @tavily-ai/tavily-mcp --client claude\n```\n\nAlthough you can launch a server on its own, it's not particularly helpful in isolation. Instead, you should integrate it into an MCP client. Below is an example of how to configure the Claude Desktop app to work with the tavily-mcp server.\n\n\n## Configuring MCP Clients ⚙️\n\nThis repository will explain how to configure both [Cursor](https://cursor.sh) and [Claude Desktop](https://claude.ai/desktop) to work with the tavily-mcp server.\n\n\n### Configuring Cline 🤖\n\nThe easiest way to set up the Tavily MCP server in Cline is through the marketplace with a single click:\n\n1. Open Cline in VS Code\n2. Click on the Cline icon in the sidebar\n3. Navigate to the \"MCP Servers\" tab ( 4 squares )\n4. Search \"Tavily\" and click \"install\"\n5. When prompted, enter your Tavily API key\n\nAlternatively, you can manually set up the Tavily MCP server in Cline:\n\n1. Open the Cline MCP settings file:\n\n   ### For macOS:\n   ```bash\n   # Using Visual Studio Code\n   code ~/Library/Application\\ Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json\n   \n   # Or using TextEdit\n   open -e ~/Library/Application\\ Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json\n   ```\n\n   ### For Windows:\n   ```bash\n   code %APPDATA%\\Code\\User\\globalStorage\\saoudrizwan.claude-dev\\settings\\cline_mcp_settings.json\n   ```\n\n2. Add the Tavily server configuration to the file:\n\n   Replace `your-api-key-here` with your actual [Tavily API key](https://tavily.com/api-keys).\n\n   ```json\n   {\n     \"mcpServers\": {\n       \"tavily-mcp\": {\n         \"command\": \"npx\",\n         \"args\": [\"-y\", \"tavily-mcp@0.1.4\"],\n         \"env\": {\n           \"TAVILY_API_KEY\": \"your-api-key-here\"\n         },\n         \"disabled\": false,\n         \"autoApprove\": []\n       }\n     }\n   }\n   ```\n\n3. Save the file and restart Cline if it's already running.\n\n4. When using Cline, you'll now have access to the Tavily MCP tools. You can ask Cline to use the tavily-search and tavily-extract tools directly in your conversations.\n\n\n### Configuring Cursor 🖥️\n\n> **Note**: Requires Cursor version 0.45.6 or higher\n\nTo set up the Tavily MCP server in Cursor:\n\n1. Open Cursor Settings\n2. Navigate to Features > MCP Servers\n3. Click on the \"+ Add New MCP Server\" button\n4. Fill out the following information:\n   - **Name**: Enter a nickname for the server (e.g., \"tavily-mcp\")\n   - **Type**: Select \"command\" as the type\n   - **Command**: Enter the command to run the server:\n     ```bash\n     env TAVILY_API_KEY=your-api-key npx -y tavily-mcp@0.1.4\n     ```\n     > **Important**: Replace `your-api-key` with your Tavily API key. You can get one at [app.tavily.com/home](https://app.tavily.com/home)\n\nAfter adding the server, it should appear in the list of MCP servers. You may need to manually press the refresh button in the top right corner of the MCP server to populate the tool list.\n\nThe Composer Agent will automatically use the Tavily MCP tools when relevant to your queries. It is better to explicitly request to use the tools by describing what you want to do (e.g., \"User tavily-search to search the web for the latest news on AI\"). On mac press command + L to open the chat, select the composer option at the top of the screen, beside the submit button select agent and submit the query when ready.\n\n\n\n### Configuring the Claude Desktop app 🖥️\n### For macOS:\n\n```bash\n# Create the config file if it doesn't exist\ntouch \"$HOME/Library/Application Support/Claude/claude_desktop_config.json\"\n\n# Opens the config file in TextEdit \nopen -e \"$HOME/Library/Application Support/Claude/claude_desktop_config.json\"\n\n# Alternative method using Visual Studio Code (requires VS Code to be installed)\ncode \"$HOME/Library/Application Support/Claude/claude_desktop_config.json\"\n```\n\n### For Windows:\n```bash\ncode %APPDATA%\\Claude\\claude_desktop_config.json\n```\n\n### Add the Tavily server configuration:\n\nReplace `your-api-key-here` with your actual [Tavily API key](https://tavily.com/api-keys).\n\n```json\n{\n  \"mcpServers\": {\n    \"tavily-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"tavily-mcp@0.1.2\"],\n      \"env\": {\n        \"TAVILY_API_KEY\": \"your-api-key-here\"\n      }\n    }\n  }\n}\n```\n\n### 2. Git Installation\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/tavily-ai/tavily-mcp.git\ncd tavily-mcp\n```\n\n2. Install dependencies:\n```bash\nnpm install\n```\n\n3. Build the project:\n```bash\nnpm run build\n```\n### Configuring the Claude Desktop app ⚙️\nFollow the configuration steps outlined in the [Configuring the Claude Desktop app](#configuring-the-claude-desktop-app-️) section above, using the below JSON configuration.\n\nReplace `your-api-key-here` with your actual [Tavily API key](https://tavily.com/api-keys) and `/path/to/tavily-mcp` with the actual path where you cloned the repository on your system.\n\n```json\n{\n  \"mcpServers\": {\n    \"tavily\": {\n      \"command\": \"npx\",\n      \"args\": [\"/path/to/tavily-mcp/build/index.js\"],\n      \"env\": {\n        \"TAVILY_API_KEY\": \"your-api-key-here\"\n      }\n    }\n  }\n}\n```\n\n## Usage in Claude Desktop App 🎯\n\nOnce the installation is complete, and the Claude desktop app is configured, you must completely close and re-open the Claude desktop app to see the tavily-mcp server. You should see a hammer icon in the bottom left of the app, indicating available MCP tools, you can click on the hammer icon to see more detial on the tavily-search and tavily-extract tools.\n\n\n\nNow claude will have complete access to the tavily-mcp server, including the tavily-search and tavily-extract tools. If you insert the below examples into the Claude desktop app, you should see the tavily-mcp server tools in action.\n\n### Tavily Search Examples\n\n1. **General Web Search**:\n```\nCan you search for recent developments in quantum computing?\n```\n\n2. **News Search**:\n```\nSearch for news articles about AI startups from the last 7 days.\n```\n\n3. **Domain-Specific Search**:\n```\nSearch for climate change research on nature.com and sciencedirect.com\n```\n\n### Tavily Extract Examples \n\n1. **Extract Article Content**:\n```\nExtract the main content from this article: https://example.com/article\n```\n\n### ✨ Combine Search and Extract ✨\n\nYou can also combine the tavily-search and tavily-extract tools to perform more complex tasks.\n\n```\nSearch for news articles about AI startups from the last 7 days and extract the main content from each article to generate a detailed report.\n```\n\n## Troubleshooting 🛠️\n\n### Common Issues\n\n1. **Server Not Found**\n   - Verify the npm installation by running `npm --verison`\n   - Check Claude Desktop configuration syntax by running `code ~/Library/Application\\ Support/Claude/claude_desktop_config.json`\n   - Ensure Node.js is properly installed by running `node --version`\n   \n2. **NPX related issues**\n  - If you encounter errors related to `npx`, you may need to use the full path to the npx executable instead. \n  - You can find this path by running `which npx` in your terminal, then replace the `\"command\":  \"npx\"` line with `\"command\": \"/full/path/to/npx\"` in your configuration.\n\n3. **API Key Issues**\n   - Confirm your Tavily API key is valid\n   - Check the API key is correctly set in the config\n   - Verify no spaces or quotes around the API key\n\n## Acknowledgments ✨\n\n- [Model Context Protocol](https://modelcontextprotocol.io) for the MCP specification\n- [Anthropic](https://anthropic.com) for Claude Desktop",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ai",
        "retrieval",
        "search",
        "ai assistants",
        "ai workflows",
        "search intelligent"
      ],
      "category": "document-processing"
    },
    "Saml1211--PRD-MCP-Server": {
      "owner": "Saml1211",
      "name": "PRD-MCP-Server",
      "url": "https://github.com/Saml1211/PRD-MCP-Server",
      "imageUrl": "/freedevtools/mcp/pfp/Saml1211.webp",
      "description": "Generate detailed and structured Product Requirements Documents (PRDs) while validating them against industry standards and utilizing a library of customizable templates for documentation.",
      "stars": 26,
      "forks": 7,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T19:00:13Z",
      "readme_content": "# PRD Creator MCP Server\n\n[![Build Status](https://github.com/Saml1211/prd-mcp-server/actions/workflows/ci.yml/badge.svg)](https://github.com/Saml1211/prd-mcp-server/actions/workflows/ci.yml)\n[![npm version](https://img.shields.io/npm/v/prd-creator-mcp)](https://www.npmjs.com/package/prd-creator-mcp)\n[![License: MIT](https://img.shields.io/github/license/Saml1211/prd-mcp-server)](https://github.com/Saml1211/prd-mcp-server/blob/main/LICENSE)\n[![GitHub issues](https://img.shields.io/github/issues/Saml1211/prd-mcp-server)](https://github.com/Saml1211/prd-mcp-server/issues)\n\nA specialized Model Context Protocol (MCP) server dedicated to creating Product Requirements Documents. This MCP server enables AI systems connected to MCP clients to generate detailed, well-structured product requirement documents through a standardized protocol interface.\n\n---\n\n<!-- TOC -->\n- [Quick Start](#quick-start)\n- [Features](#features)\n- [Installation](#installation)\n- [API Reference](#api-reference)\n- [Provider Configuration](#provider-configuration--hot-reload)\n- [Integrations](#integrations)\n- [CLI Usage](#cli-usage)\n- [Docker](#docker)\n- [Contributing](#contributing)\n- [Changelog](#changelog)\n- [Appendix](#appendix)\n<!-- TOC -->\n\n## Quick Start\n\n**Via NPX (recommended):**\n```sh\nnpx -y prd-creator-mcp\n```\n\n**Via Docker:**\n```sh\ndocker pull saml1211/prd-creator-mcp\ndocker run -i --rm saml1211/prd-creator-mcp\n```\n\n**Configure Providers:**\n- Copy `.env.example` to `.env` and set your API keys and preferred models.\n- Optionally, update provider credentials at runtime using the `update_provider_config` MCP tool.\n\n**Get Help:**\n```sh\nnpx prd-creator-mcp --help\n```\n\n## Features\n\n- **PRD Generator**: Create complete PRDs based on product descriptions, user stories, and requirements\n- **AI-Driven Generation**: Generate high-quality PRDs using multiple AI providers\n- **Multi-Provider Support**: Choose from OpenAI, Google Gemini, Anthropic Claude, or local models\n- **Provider Configuration**: Customize provider options for each PRD generation\n- **Fallback Mechanism**: Gracefully falls back to template-based generation when AI is unavailable\n- **PRD Validator**: Validate PRD completeness against industry standards and customizable rule sets\n- **Template Resources**: Access a library of PRD templates for different product types\n- **MCP Protocol Support**: Implements the Model Context Protocol for seamless integration with MCP clients\n\n## Installation\n\n### Prerequisites\n\n- Node.js v16 or higher\n- npm or yarn\n\n### Install from source\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/Saml1211/prd-mcp-server.git\ncd prd-mcp-server\n```\n\n2. Install dependencies:\n```bash\nnpm install\n```\n\n3. Build the project:\n```bash\nnpm run build\n```\n\n4. Run locally:\n```bash\nnpm start\n```\n\n5. For development with hot reload:\n```bash\nnpm run dev\n```\n\n## API Reference\n\nThe PRD Creator MCP Server provides the following tools:\n\n### `generate_prd`\n\nGenerate a complete PRD document using AI or template-based generation.\n\n**Parameters:**\n- `productName`: The name of the product\n- `productDescription`: Description of the product\n- `targetAudience`: Description of the target audience\n- `coreFeatures`: Array of core feature descriptions\n- `constraints` (optional): Array of constraints or limitations\n- `templateName` (optional): Template name to use (defaults to \"standard\")\n- `providerId` (optional): Specific AI provider to use (openai, anthropic, gemini, local, template)\n- `additionalContext` (optional): Additional context or instructions for the AI provider\n- `providerOptions` (optional): Provider-specific options like temperature, maxTokens, etc.\n\n**Example:**\n```javascript\n{\n  \"productName\": \"TaskMaster Pro\",\n  \"productDescription\": \"A task management application that helps users organize and prioritize their work efficiently.\",\n  \"targetAudience\": \"Busy professionals and teams who need to manage multiple projects and deadlines.\",\n  \"coreFeatures\": [\n    \"Task creation and management\",\n    \"Priority setting\",\n    \"Due date tracking\",\n    \"Team collaboration\"\n  ],\n  \"constraints\": [\n    \"Must work offline\",\n    \"Must support mobile and desktop platforms\"\n  ],\n  \"templateName\": \"comprehensive\",\n  \"providerId\": \"openai\",\n  \"additionalContext\": \"Focus on enterprise features and security\",\n  \"providerOptions\": {\n    \"temperature\": 0.5,\n    \"maxTokens\": 4000\n  }\n}\n```\n\n### `validate_prd`\n\nValidate a PRD document against best practices.\n\n**Parameters:**\n- `prdContent`: The PRD content to validate\n- `validationRules` (optional): Array of validation rule IDs to check\n\n**Example:**\n```javascript\n{\n  \"prdContent\": \"# My Product\\n\\n## Introduction\\n...\",\n  \"validationRules\": [\"has-introduction\", \"minimum-length\"]\n}\n```\n\n### `list_validation_rules`\n\nList all available validation rules.\n\n### `list_ai_providers`\n\nList all available AI providers and their availability status.\n\n**Example response:**\n```json\n[\n  {\n    \"id\": \"openai\",\n    \"name\": \"OpenAI\",\n    \"available\": true\n  },\n  {\n    \"id\": \"anthropic\",\n    \"name\": \"Anthropic Claude\",\n    \"available\": false\n  },\n  {\n    \"id\": \"gemini\",\n    \"name\": \"Google Gemini\",\n    \"available\": false\n  },\n  {\n    \"id\": \"local\",\n    \"name\": \"Local Model\",\n    \"available\": false\n  },\n  {\n    \"id\": \"template\",\n    \"name\": \"Template-based (No AI)\",\n    \"available\": true\n  }\n]\n```\n\n### Template Management\n\nThe server provides additional tools for template management:\n\n- `create_template`: Create a new PRD template\n- `list_templates`: List all available templates\n- `get_template`: Get a specific template\n- `update_template`: Update an existing template\n- `delete_template`: Delete a template\n- `export_templates`: Export templates to JSON\n- `import_templates`: Import templates from JSON\n- `render_template`: Render a template with placeholders\n\n### System Management\n\n- `get_provider_config`: Get current provider configuration\n- `update_provider_config`: Update provider configuration\n- `health_check`: Check system health and provider availability\n- `get_logs`: Get recent system logs\n- `stats`: Get usage statistics\n\n## Provider Configuration & Hot Reload\n\n### Configuring AI Providers\n\nYou can configure provider credentials and models in two ways:\n- **.env file:** Place a `.env` file in your project or working directory. Use `.env.example` as a template. All standard AI provider variables (e.g., `OPENAI_API_KEY`, `OPENAI_MODEL`, etc.) are supported.\n- **Live protocol tools:** Update provider configuration at runtime using the `update_provider_config` tool via your MCP client. These changes are persisted and take effect immediately—no server restart required.\n\nThe server will always merge persistent config (from protocol tools) with environment variables, giving precedence to protocol/tool updates.\n\n### Hot Reload & Automation\n\nWhen you update provider settings using either method, changes take effect instantly for all new requests. This enables:\n- Seamless automation and scripting via MCP tool interfaces\n- Hassle-free credential rotation and model switching\n- Dynamic environment support for CI/CD and cloud deployments\n\n## Integrations\n\n### Claude Desktop\n\nAdd to `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"prd-creator\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"prd-creator-mcp\"]\n    }\n  }\n}\n```\n\n### Glama.ai\n\nAvailable at: https://glama.ai/mcp/servers/@Saml1211/PRD-MCP-Server\n\n### Cursor\n\nAdd to your Cursor MCP client configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"prd-creator\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"prd-creator-mcp\"]\n    }\n  }\n}\n```\n\n### Roo Code\n\nAdd to `.roo/mcp.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"prd-creator-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"prd-creator-mcp\"]\n    }\n  }\n}\n```\n\n### Cline\n\nReference `prd-creator-mcp` in your MCP workflow definitions.\n\n## CLI Usage\n\n### Install Globally (optional)\n\nYou may also install the MCP server globally to expose the CLI:\n\n```bash\nnpm install -g prd-creator-mcp\n```\n\nThen run:\n\n```bash\nprd-creator-mcp\n```\n\n### Command Reference\n\n- `prd-creator-mcp`\n  Runs the MCP server (STDIO transport).\n  Use directly via npx or as a globally installed CLI for integration with MCP clients and tools.\n\n### Uninstall\n\nTo remove the global CLI:\n\n```bash\nnpm uninstall -g prd-creator-mcp\n```\n\n### CLI Options\n\nView available command line options:\n\n```bash\nnpx prd-creator-mcp --help\n```\n\n## Docker\n\n### Building the Docker image\n\n```bash\ndocker build -t prd-creator-mcp .\n```\n\n### Running with Docker\n\n```bash\ndocker run -i --rm prd-creator-mcp\n```\n\n### With environment variables\n\n```bash\ndocker run -i --rm -e OPENAI_API_KEY=your_key_here prd-creator-mcp\n```\n\n## Contributing\n\nPlease read [CONTRIBUTING.md](CONTRIBUTING.md) and [CODE_OF_CONDUCT.md](CODE_OF_CONDUCT.md) before submitting issues or pull requests.\n\n## Changelog\n\nAll notable changes to this project are documented in [CHANGELOG.md](CHANGELOG.md).\n\n## Appendix\n\n### Useful Links\n\n- [GitHub Repository](https://github.com/Saml1211/prd-mcp-server)\n- [Model Context Protocol](https://modelcontextprotocol.io/) - Official MCP specification\n- [MCP Inspector](https://modelcontextprotocol.io/docs/tools/inspector) - Testing and debugging tool for MCP servers\n- [NPM Package](https://www.npmjs.com/package/prd-creator-mcp) - Published npm package",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "prds",
        "prd",
        "documentation",
        "documents prds",
        "requirements documents",
        "prds validating"
      ],
      "category": "document-processing"
    },
    "SecretiveShell--MCP-llms-txt": {
      "owner": "SecretiveShell",
      "name": "MCP-llms-txt",
      "url": "https://github.com/SecretiveShell/MCP-llms-txt",
      "imageUrl": "/freedevtools/mcp/pfp/SecretiveShell.webp",
      "description": "Integrate documentation directly into conversations by utilizing MCP resources for chat applications. This server enhances interactions by providing relevant documentation content as part of the dialogue.",
      "stars": 24,
      "forks": 7,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-03T22:32:14Z",
      "readme_content": "# mcp-llms-txt\r\n\r\n[![smithery badge](https://smithery.ai/badge/@SecretiveShell/MCP-llms-txt)](https://smithery.ai/server/@SecretiveShell/MCP-llms-txt)\r\n\r\nMCP server for [Awesome-llms-txt](https://github.com/SecretiveShell/Awesome-llms-txt). Add documentation directly into your conversation via mcp resources.\r\n\r\n<a href=\"https://glama.ai/mcp/servers/kqwhhpe8l7\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/kqwhhpe8l7/badge\" alt=\"MCP-llms-txt MCP server\" /></a>\r\n\r\n## Installation\r\n\r\nView a setup guide + example usage on [pulsemcp.com](https://www.pulsemcp.com/use-cases/utilize-llm-txt-files/secretiveshell-claude-llmstxt)\r\n\r\n### Installing via Smithery\r\n\r\nTo install MCP Server for Awesome-llms-txt for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@SecretiveShell/MCP-llms-txt):\r\n\r\n```bash\r\nnpx -y @smithery/cli install @SecretiveShell/MCP-llms-txt --client claude\r\n```\r\n\r\n### Manual Installation\r\nSetup your claude config like this:\r\n\r\n```json\r\n{\r\n    \"mcpServers\": {\r\n        \"mcp-llms-txt\": {\r\n            \"command\": \"uvx\",\r\n            \"args\": [\"mcp-llms-txt\"],\r\n            \"env\": {\r\n                \"PYTHONUTF8\": \"1\"\r\n            }\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n## testing\r\n\r\nUse [mcp-cli](https://github.com/wong2/mcp-cli) to test the server:\r\n\r\n```bash\r\nnpx -y \"@wong2/mcp-cli\" -c config.json\r\n```\r\n\r\nThe config file is already setup and does not need to be changed since there are no api keys or secrets.\r\n\r\n## Contributing\r\n\r\nContributions are welcome! Please open an issue or submit a pull request.\r\n\r\n## License\r\n\r\nThis project is licensed under the MIT License.\r\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "conversations",
        "txt",
        "documentation",
        "llms txt",
        "conversations utilizing",
        "directly conversations"
      ],
      "category": "document-processing"
    },
    "Softeria--ms-365-mcp-server": {
      "owner": "Softeria",
      "name": "ms-365-mcp-server",
      "url": "https://github.com/Softeria/ms-365-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/Softeria.webp",
      "description": "Enables interaction with Microsoft 365 services through the Graph API, allowing management of Excel files, calendar events, emails, and OneDrive files securely using the Microsoft Authentication Library.",
      "stars": 280,
      "forks": 89,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T12:59:09Z",
      "readme_content": "# ms-365-mcp-server\n\n[![npm version](https://img.shields.io/npm/v/@softeria/ms-365-mcp-server.svg)](https://www.npmjs.com/package/@softeria/ms-365-mcp-server) [![build status](https://github.com/softeria/ms-365-mcp-server/actions/workflows/build.yml/badge.svg)](https://github.com/softeria/ms-365-mcp-server/actions/workflows/build.yml) [![license](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/softeria/ms-365-mcp-server/blob/main/LICENSE)\n\nMicrosoft 365 MCP Server\n\nA Model Context Protocol (MCP) server for interacting with Microsoft 365 and Microsoft Office services through the Graph\nAPI.\n\n## Prerequisites\n\n- Node.js >= 20 (recommended)\n- Node.js 14+ may work with dependency warnings\n\n## Features\n\n- Authentication via Microsoft Authentication Library (MSAL)\n- Comprehensive Microsoft 365 service integration\n- Read-only mode support for safe operations\n- Tool filtering for granular access control\n\n## Supported Services & Tools\n\n### Personal Account Tools (Available by default)\n\n**Email (Outlook)**  \n<sub>list-mail-messages, list-mail-folders, list-mail-folder-messages, get-mail-message, send-mail,\ndelete-mail-message, create-draft-email, move-mail-message</sub>\n\n**Calendar**  \n<sub>list-calendars, list-calendar-events, get-calendar-event, get-calendar-view, create-calendar-event,\nupdate-calendar-event, delete-calendar-event</sub>\n\n**OneDrive Files**  \n<sub>list-drives, get-drive-root-item, list-folder-files, download-onedrive-file-content, upload-file-content,\nupload-new-file, delete-onedrive-file</sub>\n\n**Excel Operations**  \n<sub>list-excel-worksheets, get-excel-range, create-excel-chart, format-excel-range, sort-excel-range</sub>\n\n**OneNote**  \n<sub>list-onenote-notebooks, list-onenote-notebook-sections, list-onenote-section-pages, get-onenote-page-content,\ncreate-onenote-page</sub>\n\n**To Do Tasks**  \n<sub>list-todo-task-lists, list-todo-tasks, get-todo-task, create-todo-task, update-todo-task, delete-todo-task</sub>\n\n**Planner**  \n<sub>list-planner-tasks, get-planner-plan, list-plan-tasks, get-planner-task, create-planner-task</sub>\n\n**Contacts**  \n<sub>list-outlook-contacts, get-outlook-contact, create-outlook-contact, update-outlook-contact,\ndelete-outlook-contact</sub>\n\n**User Profile**  \n<sub>get-current-user</sub>\n\n**Search**  \n<sub>search-query</sub>\n\n### Organization Account Tools (Requires --org-mode flag)\n\n**Teams & Chats**  \n<sub>list-chats, get-chat, list-chat-messages, get-chat-message, send-chat-message, list-chat-message-replies,\nreply-to-chat-message, list-joined-teams, get-team, list-team-channels, get-team-channel, list-channel-messages,\nget-channel-message, send-channel-message, list-team-members</sub>\n\n**SharePoint Sites**  \n<sub>search-sharepoint-sites, get-sharepoint-site, get-sharepoint-site-by-path, list-sharepoint-site-drives,\nget-sharepoint-site-drive-by-id, list-sharepoint-site-items, get-sharepoint-site-item, list-sharepoint-site-lists,\nget-sharepoint-site-list, list-sharepoint-site-list-items, get-sharepoint-site-list-item,\nget-sharepoint-sites-delta</sub>\n\n**Shared Mailboxes**  \n<sub>list-shared-mailbox-messages, list-shared-mailbox-folder-messages, get-shared-mailbox-message,\nsend-shared-mailbox-mail</sub>\n\n**User Management**  \n<sub>list-users</sub>\n\n## Organization/Work Mode\n\nTo access work/school features (Teams, SharePoint, etc.), enable organization mode using any of these flags:\n\n```json\n{\n  \"mcpServers\": {\n    \"ms365\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@softeria/ms-365-mcp-server\", \"--org-mode\"]\n    }\n  }\n}\n```\n\nOrganization mode must be enabled from the start to access work account features. Without this flag, only personal\naccount features (email, calendar, OneDrive, etc.) are available.\n\n## Shared Mailbox Access\n\nTo access shared mailboxes, you need:\n\n1. **Organization mode**: Shared mailbox tools require `--org-mode` flag (work/school accounts only)\n2. **Delegated permissions**: `Mail.Read.Shared` or `Mail.Send.Shared` scopes\n3. **Exchange permissions**: The signed-in user must have been granted access to the shared mailbox\n4. **Usage**: Use the shared mailbox's email address as the `user-id` parameter in the shared mailbox tools\n\n**Finding shared mailboxes**: Use the `list-users` tool to discover available users and shared mailboxes in your\norganization.\n\nExample: `list-shared-mailbox-messages` with `user-id` set to `shared-mailbox@company.com`\n\n## Quick Start Example\n\nTest login in Claude Desktop:\n\n![Login example](https://github.com/user-attachments/assets/27f57f0e-57b8-4366-a8d1-c0bdab79900c)\n\n## Examples\n\n![Image](https://github.com/user-attachments/assets/ed275100-72e8-4924-bcf2-cd8e1b4c6f3a)\n\n## Integration\n\n### Claude Desktop\n\nTo add this MCP server to Claude Desktop:\n\nEdit the config file under Settings > Developer:\n\n```json\n{\n  \"mcpServers\": {\n    \"ms365\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@softeria/ms-365-mcp-server\"]\n    }\n  }\n}\n```\n\n### Claude Code CLI\n\n```bash\nclaude mcp add ms365 -- npx -y @softeria/ms-365-mcp-server\n```\n\nFor other interfaces that support MCPs, please refer to their respective documentation for the correct\nintegration method.\n\n### Local Development\n\nFor local development or testing:\n\n```bash\n# From the project directory\nclaude mcp add ms -- npx tsx src/index.ts --org-mode\n```\n\nOr configure Claude Desktop manually:\n\n```json\n{\n  \"mcpServers\": {\n    \"ms365\": {\n      \"command\": \"node\",\n      \"args\": [\"/absolute/path/to/ms-365-mcp-server/dist/index.js\", \"--org-mode\"]\n    }\n  }\n}\n```\n\n> **Note**: Run `npm run build` after code changes to update the `dist/` folder.\n\n### Authentication\n\n> ⚠️ You must authenticate before using tools.\n\nThe server supports three authentication methods:\n\n#### 1. Device Code Flow (Default)\n\nFor interactive authentication via device code:\n\n- **MCP client login**:\n  - Call the `login` tool (auto-checks existing token)\n  - If needed, get URL+code, visit in browser\n  - Use `verify-login` tool to confirm\n- **CLI login**:\n  ```bash\n  npx @softeria/ms-365-mcp-server --login\n  ```\n  Follow the URL and code prompt in the terminal.\n\nTokens are cached securely in your OS credential store (fallback to file).\n\n#### 2. OAuth Authorization Code Flow (HTTP mode only)\n\nWhen running with `--http`, the server **requires** OAuth authentication:\n\n```bash\nnpx @softeria/ms-365-mcp-server --http 3000\n```\n\nThis mode:\n\n- Advertises OAuth capabilities to MCP clients\n- Provides OAuth endpoints at `/auth/*` (authorize, token, metadata)\n- **Requires** `Authorization: Bearer <token>` for all MCP requests\n- Validates tokens with Microsoft Graph API\n- **Disables** login/logout tools by default (use `--enable-auth-tools` to enable them)\n\nMCP clients will automatically handle the OAuth flow when they see the advertised capabilities.\n\n##### Setting up Azure AD for OAuth Testing\n\nTo use OAuth mode with custom Azure credentials (recommended for production), you'll need to set up an Azure AD app\nregistration:\n\n1. **Create Azure AD App Registration**:\n\n- Go to [Azure Portal](https://portal.azure.com)\n- Navigate to Azure Active Directory → App registrations → New registration\n- Set name: \"MS365 MCP Server\"\n\n1. **Configure Redirect URIs**:\n   Add these redirect URIs for testing with MCP Inspector (`npm run inspector`):\n\n- `http://localhost:6274/oauth/callback`\n- `http://localhost:6274/oauth/callback/debug`\n- `http://localhost:3000/callback` (optional, for server callback)\n\n1. **Get Credentials**:\n\n- Copy the **Application (client) ID** from Overview page\n- Go to Certificates & secrets → New client secret → Copy the secret value\n\n1. **Configure Environment Variables**:\n   Create a `.env` file in your project root:\n   ```env\n   MS365_MCP_CLIENT_ID=your-azure-ad-app-client-id-here\n   MS365_MCP_CLIENT_SECRET=your-azure-ad-app-client-secret-here\n   MS365_MCP_TENANT_ID=common\n   ```\n\nWith these configured, the server will use your custom Azure app instead of the built-in one.\n\n#### 3. Bring Your Own Token (BYOT)\n\nIf you are running ms-365-mcp-server as part of a larger system that manages Microsoft OAuth tokens externally, you can\nprovide an access token directly to this MCP server:\n\n```bash\nMS365_MCP_OAUTH_TOKEN=your_oauth_token npx @softeria/ms-365-mcp-server\n```\n\nThis method:\n\n- Bypasses the interactive authentication flows\n- Use your pre-existing OAuth token for Microsoft Graph API requests\n- Does not handle token refresh (token lifecycle management is your responsibility)\n\n> **Note**: HTTP mode requires authentication. For unauthenticated testing, use stdio mode with device code flow.\n>\n> **Authentication Tools**: In HTTP mode, login/logout tools are disabled by default since OAuth handles authentication.\n> Use `--enable-auth-tools` if you need them available.\n\n## CLI Options\n\nThe following options can be used when running ms-365-mcp-server directly from the command line:\n\n```\n--login           Login using device code flow\n--logout          Log out and clear saved credentials\n--verify-login    Verify login without starting the server\n--org-mode        Enable organization/work mode from start (includes Teams, SharePoint, etc.)\n--work-mode       Alias for --org-mode\n--force-work-scopes Backwards compatibility alias for --org-mode (deprecated)\n```\n\n### Server Options\n\nWhen running as an MCP server, the following options can be used:\n\n```\n-v                Enable verbose logging\n--read-only       Start server in read-only mode, disabling write operations\n--http [port]     Use Streamable HTTP transport instead of stdio (optionally specify port, default: 3000)\n                  Starts Express.js server with MCP endpoint at /mcp\n--enable-auth-tools Enable login/logout tools when using HTTP mode (disabled by default in HTTP mode)\n--enabled-tools <pattern> Filter tools using regex pattern (e.g., \"excel|contact\" to enable Excel and Contact tools)\n```\n\nEnvironment variables:\n\n- `READ_ONLY=true|1`: Alternative to --read-only flag\n- `ENABLED_TOOLS`: Filter tools using a regex pattern (alternative to --enabled-tools flag)\n- `MS365_MCP_ORG_MODE=true|1`: Enable organization/work mode (alternative to --org-mode flag)\n- `MS365_MCP_FORCE_WORK_SCOPES=true|1`: Backwards compatibility for MS365_MCP_ORG_MODE\n- `LOG_LEVEL`: Set logging level (default: 'info')\n- `SILENT=true|1`: Disable console output\n- `MS365_MCP_CLIENT_ID`: Custom Azure app client ID (defaults to built-in app)\n- `MS365_MCP_TENANT_ID`: Custom tenant ID (defaults to 'common' for multi-tenant)\n- `MS365_MCP_OAUTH_TOKEN`: Pre-existing OAuth token for Microsoft Graph API (BYOT method)\n\n## Contributing\n\nWe welcome contributions! Before submitting a pull request, please ensure your changes meet our quality standards.\n\nRun the verification script to check all code quality requirements:\n\n```bash\nnpm run verify\n```\n\n### For Developers\n\nAfter cloning the repository, you may need to generate the client code from the Microsoft Graph OpenAPI specification:\n\n```bash\nnpm run generate\n```\n\n## Support\n\nIf you're having problems or need help:\n\n- Create an [issue](https://github.com/softeria/ms-365-mcp-server/issues)\n- Start a [discussion](https://github.com/softeria/ms-365-mcp-server/discussions)\n- Email: eirikb@eirikb.no\n- Discord: https://discord.gg/WvGVNScrAZ or @eirikb\n\n## License\n\nMIT © 2025 Softeria\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "microsoft",
        "softeria",
        "onedrive",
        "microsoft 365",
        "ms 365",
        "365 services"
      ],
      "category": "document-processing"
    },
    "Sunwood-ai-labs--documind-mcp-server": {
      "owner": "Sunwood-ai-labs",
      "name": "documind-mcp-server",
      "url": "https://github.com/Sunwood-ai-labs/documind-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/Sunwood-ai-labs.webp",
      "description": "Analyzes and enhances the quality of documentation, specifically README files, by providing insights and suggestions for improvement. Utilizes advanced neural processing techniques for thorough evaluation and visual analysis of documentation elements.",
      "stars": 0,
      "forks": 2,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-02-12T04:02:18Z",
      "readme_content": "<div align=\"center\">\n  \n\n  <div align=\"center\">\n    <a href=\"README.md\"><img src=\"https://img.shields.io/badge/english-document-blue.svg\" alt=\"EN doc\"></a>\n    <a href=\"README.ja.md\"><img src=\"https://img.shields.io/badge/ドキュメント-日本語-blue.svg\" alt=\"JA doc\"/></a>\n  </div>\n</div>\n\n# 🌐 DocuMind MCP Server\n\n> _\"Where Documentation Meets Digital Intelligence\"_\n\nA next-generation Model Context Protocol (MCP) server that revolutionizes documentation quality analysis through advanced neural processing.\n\n## ⚡ Core Systems\n\n- 🧠 **Neural Documentation Analysis**: Advanced algorithms for comprehensive README evaluation\n- 🔮 **Holographic Header Scanning**: Cutting-edge SVG analysis for visual elements\n- 🌍 **Multi-dimensional Language Support**: Cross-linguistic documentation verification\n- 💫 **Quantum Suggestion Engine**: AI-powered improvement recommendations\n\n## 🚀 System Boot Sequence\n\n### System Requirements\n\n- Node.js 18+\n- npm || yarn\n\n### Initialize Core\n\n```bash\nnpm install\n```\n\n### Compile Matrix\n\n```bash\nnpm run build\n```\n\n### Neural Development Link\n\nEstablish real-time neural connection:\n```bash\nnpm run watch\n```\n\n## 🛸 Operation Protocol\n\n### System Configuration\n\nIntegrate with Claude Desktop mainframe:\n\n**Windows Terminal**:\n```json\n// %APPDATA%/Claude/claude_desktop_config.json\n{\n  \"mcpServers\": {\n    \"documind-mcp-server\": {\n      \"command\": \"/path/to/documind-mcp-server/build/index.js\"\n    }\n  }\n}\n```\n\n### Neural Interface Commands\n\n#### evaluate_readme\nInitiates quantum analysis of documentation structure.\n\nParameters:\n- `projectPath`: Neural pathway to target directory\n\nExample Request:\n```javascript\n{\n  name: \"evaluate_readme\",\n  arguments: {\n    projectPath: \"/path/to/project\"\n  }\n}\n```\n\nExample Response:\n```javascript\n{\n  content: [\n    {\n      type: \"text\",\n      text: JSON.stringify({\n        filePath: \"/path/to/project/README.md\",\n        hasHeaderImage: true,\n        headerImageQuality: {\n          hasGradient: true,\n          hasAnimation: true,\n          // ... other quality metrics\n        },\n        score: 95,\n        suggestions: [\n          \"Consider adding language badges\",\n          // ... other suggestions\n        ]\n      })\n    }\n  ]\n}\n```\n\n## 🔮 Development Matrix\n\n### Debug Protocol\n\nAccess the neural network through MCP Inspector:\n\n```bash\nnpm run inspector\n```\n\n### Troubleshooting Guide\n\n#### Common Issues and Solutions\n\n1. **Header Image Not Detected**\n   - Ensure SVG file is placed in the `assets/` directory\n   - Validate SVG file contains proper XML structure\n   - Check file permissions\n\n2. **Language Badges Not Recognized**\n   - Verify badges use shields.io format\n   - Check HTML structure follows recommended pattern\n   - Ensure proper center alignment\n\n3. **Build Errors**\n   - Clear `node_modules` and reinstall dependencies\n   - Ensure TypeScript version matches project requirements\n   - Check for syntax errors in modified files\n\n4. **MCP Connection Issues**\n   - Verify stdio transport configuration\n   - Check Claude Desktop configuration\n   - Ensure proper file paths in config\n\n#### Performance Optimization\n\n1. **SVG Analysis**\n   - Minimize SVG complexity for faster parsing\n   - Use efficient gradients and animations\n   - Optimize file size while maintaining quality\n\n2. **README Scanning**\n   - Structure content for optimal parsing\n   - Use recommended markdown patterns\n   - Follow badge placement guidelines\n\n## 🔬 API Documentation\n\n### Core Classes\n\n#### ReadmeService\n\nPrimary service for README analysis and evaluation.\n\n```typescript\nclass ReadmeService {\n  // Analyzes all README files in a project\n  async evaluateAllReadmes(projectPath: string): Promise<ReadmeEvaluation[]>\n  \n  // Evaluates a single README file\n  private async evaluateReadme(dirPath: string, readmePath: string): Promise<ReadmeEvaluation>\n  \n  // Evaluates language badge configuration\n  private evaluateLanguageBadges(content: string): BadgeEvaluation\n}\n```\n\n#### SVGService\n\nSpecialized service for SVG header image analysis.\n\n```typescript\nclass SVGService {\n  // Evaluates SVG header image quality\n  public evaluateHeaderImageQuality(imgSrc: string, content: string): HeaderImageQuality\n  \n  // Checks for project-specific elements in SVG\n  private checkProjectSpecificImage(svgContent: string, readmeContent: string): boolean\n}\n```\n\n### Core Interfaces\n\n```typescript\ninterface ReadmeEvaluation {\n  filePath: string;\n  hasHeaderImage: boolean;\n  headerImageQuality: HeaderImageQuality;\n  isCentered: {\n    headerImage: boolean;\n    title: boolean;\n    badges: boolean;\n  };\n  hasBadges: {\n    english: boolean;\n    japanese: boolean;\n    isCentered: boolean;\n    hasCorrectFormat: boolean;\n  };\n  score: number;\n  suggestions: string[];\n}\n\ninterface HeaderImageQuality {\n  hasGradient: boolean;\n  hasAnimation: boolean;\n  hasRoundedCorners: boolean;\n  hasEnglishText: boolean;\n  isProjectSpecific: boolean;\n}\n```\n\n### Error Handling\n\nThe server implements comprehensive error handling:\n\n```typescript\ntry {\n  const evaluations = await readmeService.evaluateAllReadmes(projectPath);\n  // Process results\n} catch (error) {\n  const errorMessage = error instanceof Error ? error.message : String(error);\n  return {\n    content: [{\n      type: 'text',\n      text: `Evaluation error: ${errorMessage}`\n    }],\n    isError: true\n  };\n}\n```\n\n## ⚡ License\n\nOperating under MIT Protocol.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "documentation",
        "document",
        "documind",
        "document processing",
        "quality documentation",
        "documentation elements"
      ],
      "category": "document-processing"
    },
    "Sunwood-ai-labs--release-notes-generator-iris-mcp-server": {
      "owner": "Sunwood-ai-labs",
      "name": "release-notes-generator-iris-mcp-server",
      "url": "https://github.com/Sunwood-ai-labs/release-notes-generator-iris-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/Sunwood-ai-labs.webp",
      "description": "Automatically generates structured release notes by detecting differences between Git repository tags and saves the output in Markdown format. Provides customizable templates for categorizing new features, improvements, and bug fixes to enhance the release documentation process.",
      "stars": 0,
      "forks": 2,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2024-12-18T12:57:52Z",
      "readme_content": "# 🌈 Iris MCP Server\n\n<div align=\"center\">\n  \n</div>\n\n## 📝 概要\n\nIris MCP Serverは、Gitリポジトリのタグベースのリリースノートを自動生成するためのModel Context Protocolサーバーです。タグ間の差分を解析し、構造化されたリリースノートを`.iris`ディレクトリに生成します。\n\n## ✨ 特徴\n\n- 🏷️ タグ間の差分を自動検出\n- 📊 カスタマイズ可能なリリースノートテンプレート\n- 🗂️ 新機能、改善項目、バグ修正などのカテゴリ分け\n- 📄 Markdown形式での出力\n- 📁 `.iris`フォルダへの自動保存\n\n## 🚀 インストール\n\n```bash\nnpm install iris-mcp-server\n```\n\n## 💡 使用方法\n\n### リリースノートの生成\n\n```typescript\nconst result = await mcpClient.useTool('iris-mcp-server', 'generate_release_note', {\n  startTag: 'v1.0.0',\n  endTag: 'v1.1.0',\n  title: 'Version 1.1.0 リリース',\n  features: [\n    '新しいダッシュボード機能の追加',\n    'ユーザー管理システムの実装'\n  ],\n  improvements: [\n    'パフォーマンスの最適化',\n    'UIの改善'\n  ],\n  bugfixes: [\n    'ログイン時のエラー修正',\n    'データ同期の問題を解決'\n  ],\n  breaking: [\n    'APIエンドポイントの変更',\n    '設定ファイルのフォーマット更新'\n  ]\n});\n```\n\n## 📄 出力例\n\n```markdown\n# Version 1.1.0 リリース\n\nリリース日: 2024-01-20\n\n## 💥 破壊的変更\n\n- APIエンドポイントの変更\n- 設定ファイルのフォーマット更新\n\n## ✨ 新機能\n\n- 新しいダッシュボード機能の追加\n- ユーザー管理システムの実装\n\n## 🔧 改善項目\n\n- パフォーマンスの最適化\n- UIの改善\n\n## 🐛 バグ修正\n\n- ログイン時のエラー修正\n- データ同期の問題を解決\n\n## 📝 変更されたファイル\n\n- `src/dashboard/index.ts`\n- `src/users/management.ts`\n- `config/settings.json`\n```\n\n## 🛠️ 開発\n\n### ビルド\n\n```bash\nnpm run build\n```\n\n### 開発モード\n\n```bash\nnpm run watch\n```\n\n## 🤝 コントリビューション\n\nプルリクエストやイシューは大歓迎です！以下の手順で貢献できます：\n\n1. このリポジトリをフォーク\n2. 新しいブランチを作成 (`git checkout -b feature/amazing-feature`)\n3. 変更をコミット (`git commit -m '✨ Add amazing feature'`)\n4. ブランチをプッシュ (`git push origin feature/amazing-feature`)\n5. プルリクエストを作成\n\n## 📜 ライセンス\n\nMIT\n\n## 👥 作者\n\n- 作成者: [Your Name]\n- メール: [your.email@example.com]",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "documentation",
        "git",
        "repository",
        "release documentation",
        "release notes",
        "documentation process"
      ],
      "category": "document-processing"
    },
    "Taewoong1378--notion-readonly-mcp-server": {
      "owner": "Taewoong1378",
      "name": "notion-readonly-mcp-server",
      "url": "https://github.com/Taewoong1378/notion-readonly-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/Taewoong1378.webp",
      "description": "Provides read-only access to Notion content, enabling retrieval of pages, blocks, databases, comments, and properties with optimized performance. Focuses on minimizing API calls and supports parallel processing for efficient data acquisition.",
      "stars": 4,
      "forks": 4,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-05-07T12:14:21Z",
      "readme_content": "# Notion ReadOnly MCP Server\n\nThis project implements an optimized read-only MCP server for the Notion API, focusing on performance and efficiency for AI assistants to query and retrieve Notion content.\n\n<a href=\"https://glama.ai/mcp/servers/@Taewoong1378/notion-readonly-mcp-server\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@Taewoong1378/notion-readonly-mcp-server/badge\" alt=\"Notion ReadOnly Server MCP server\" />\n</a>\n\n## Key Improvements\n\n- **Read-Only Design**: Focused exclusively on data retrieval operations, ensuring safe access to Notion content.\n- **Minimized Tool Set**: Reduced the number of exposed Notion API tools from 15+ to only 6 essential ones for document analysis.\n- **Parallel Processing**: Enhanced performance by implementing asynchronous and parallel API requests for retrieving block content, significantly reducing response times.\n- **Extended Database Access**: Added support for database, page property, and comment retrieval operations.\n- **Optimized for AI Assistants**: Significantly reduced tool count addresses the \"Too many tools can degrade performance\" issue in AI assistants like Cursor, which limits models to approximately 40 tools.\n\n## Tool Comparison\n\nThis read-only implementation exposes far fewer tools compared to the standard Notion API integration, improving performance and compatibility with AI assistants:\n\n\n\nThe reduced tool set helps stay within the recommended tool limits for optimal AI assistant performance while still providing all essential functionality.\n\n## Installation\n\n### 1. Setting up Integration in Notion:\n\nGo to https://www.notion.so/profile/integrations and create a new **internal** integration or select an existing one.\n\n\n\nWhile we limit the scope of Notion API's exposed to read-only operations, there is a non-zero risk to workspace data by exposing it to LLMs. Security-conscious users may want to further configure the Integration's _Capabilities_.\n\nFor example, you can create a read-only integration token by giving only \"Read content\" access from the \"Configuration\" tab:\n\n\n\n### 2. Adding MCP config to your client:\n\n#### Using npm:\n\nAdd the following to your `.cursor/mcp.json` or `claude_desktop_config.json` (MacOS: `~/Library/Application\\ Support/Claude/claude_desktop_config.json`)\n\n```json\n{\n  \"mcpServers\": {\n    \"notionApi\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"notion-readonly-mcp-server\"],\n      \"env\": {\n        \"OPENAPI_MCP_HEADERS\": \"{\\\"Authorization\\\": \\\"Bearer ntn_****\\\", \\\"Notion-Version\\\": \\\"2022-06-28\\\" }\"\n      }\n    }\n  }\n}\n```\n\n#### Using Docker:\n\nAdd the following to your `.cursor/mcp.json` or `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"notionApi\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"-i\",\n        \"-e\", \"OPENAPI_MCP_HEADERS\",\n        \"taewoong1378/notion-readonly-mcp-server\"\n      ],\n      \"env\": {\n        \"OPENAPI_MCP_HEADERS\": \"{\\\"Authorization\\\":\\\"Bearer ntn_****\\\",\\\"Notion-Version\\\":\\\"2022-06-28\\\"}\"\n      }\n    }\n  }\n}\n```\n\nDon't forget to replace `ntn_****` with your integration secret. Find it from your integration configuration tab.\n\n### 3. Connecting content to integration:\n\nEnsure relevant pages and databases are connected to your integration.\n\nTo do this, visit the page, click on the 3 dots, and select \"Connect to integration\".\n\n\n\n## Available Tools\n\nThis optimized server exposes only essential read-only Notion API tools:\n\n- `API-retrieve-a-page`: Get page information\n- `API-get-block-children`: Get page content blocks (with parallel processing)\n- `API-retrieve-a-block`: Get details about a specific block\n- `API-retrieve-a-database`: Get database information\n- `API-retrieve-a-comment`: Get comments on a page or block\n- `API-retrieve-a-page-property`: Get specific property information from a page\n- `API-get-one-pager`: **NEW!** Recursively retrieve a full Notion page with all its blocks, databases, and related content in a single call\n\nBy limiting to these 7 essential tools (compared to 15+ in the standard implementation), we ensure:\n\n1. Better performance in AI assistants like Cursor and Claude that have tool count limitations\n2. Reduced cognitive load for AI models when choosing appropriate tools\n3. Faster response times with fewer API options to consider\n4. Enhanced security through minimized API surface area\n\n## Automatic Content Exploration\n\nThe new `API-get-one-pager` tool provides a powerful way to explore Notion pages without requiring multiple API calls:\n\n- **Recursive retrieval**: Automatically traverses the entire page structure including nested blocks\n- **Parallel processing**: Fetches multiple blocks and their children simultaneously for maximum performance\n- **Intelligent caching**: Stores retrieved data to minimize redundant API calls\n- **Comprehensive content**: Includes pages, blocks, databases, comments, and detailed property information\n- **Customizable depth**: Control the level of recursion to balance between detail and performance\n\n### Using One Pager Tool\n\n```\n{\n  \"page_id\": \"YOUR_PAGE_ID\",\n  \"maxDepth\": 5,               // Optional: Maximum recursion depth (default: 5)\n  \"includeDatabases\": true,    // Optional: Include linked databases (default: true)\n  \"includeComments\": true,     // Optional: Include comments (default: true)\n  \"includeProperties\": true    // Optional: Include detailed page properties (default: true)\n}\n```\n\nThis automatic exploration capability is especially useful for AI assistants that need to understand the entire content of a Notion page without making dozens of separate API calls, resulting in much faster and more efficient responses.\n\n## Asynchronous Processing\n\nThe server implements advanced parallel processing techniques for handling large Notion documents:\n\n- Multiple requests are batched and processed concurrently\n- Pagination is handled automatically for block children\n- Results are efficiently aggregated before being returned\n- Console logging provides visibility into the process without affecting response format\n\n## Examples\n\n1. Using the following instruction:\n\n```\nGet the content of page 1a6b35e6e67f802fa7e1d27686f017f2\n```\n\nThe AI will retrieve the page details efficiently with parallel processing of block content.\n\n2. Using database information:\n\n```\nGet the structure of database 8a6b35e6e67f802fa7e1d27686f017f2\n```\n\n## Development\n\nBuild:\n\n```\npnpm build\n```\n\nExecute:\n\n```\npnpm dev\n```\n\n## License\n\nMIT\n\n## AI Assistant Performance Benefits\n\nModern AI assistants like Cursor and Claude have limitations on the number of tools they can effectively handle:\n\n- Most models may not respect more than 40 tools in total\n- Too many tools can degrade overall performance and reasoning capabilities\n- Complex tool sets increase response latency and decision-making difficulty\n\nThis read-only implementation deliberately reduces the Notion API surface to address these limitations while preserving all essential functionality. The result is:\n\n- Faster and more reliable responses from AI assistants\n- Improved accuracy when interacting with Notion content\n- Better overall performance through focused API design",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "document",
        "processing",
        "mcp",
        "document processing",
        "readonly mcp",
        "notion readonly"
      ],
      "category": "document-processing"
    },
    "TanvirHafiz--Medical-report-analyzer": {
      "owner": "TanvirHafiz",
      "name": "Medical-report-analyzer",
      "url": "https://github.com/TanvirHafiz/Medical-report-analyzer",
      "imageUrl": "/freedevtools/mcp/pfp/TanvirHafiz.webp",
      "description": "Analyze medical reports and symptoms to gain health insights and suggestions, providing detailed medicine information tailored to individual needs with bilingual support in English and Bengali.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-03-01T11:09:14Z",
      "readme_content": "# Medical Report Analyzer\n\nA web application that provides medical report analysis, symptoms analysis, and medicine information using AI. The application supports both English and Bengali (বাংলা) languages.\n\n## Features\n\n1. **Medical Report Analysis**\n   - Upload medical reports (JPG, PDF)\n   - Extract and analyze test results\n   - Get health insights and suggestions\n\n2. **Symptoms Analysis**\n   - Describe symptoms in detail\n   - Get potential conditions and urgency level\n   - Receive immediate steps and precautions\n\n3. **Medicine Information**\n   - Get detailed medicine analysis\n   - View usage, side effects, and precautions\n   - Personalized information based on age and gender\n   - Dosage schedule analysis\n\n4. **Bilingual Support**\n   - Toggle between English and Bengali\n   - Instant translation of analysis results\n\n## Technologies Used\n\n- Python/Flask (Backend)\n- JavaScript/HTML/CSS (Frontend)\n- Tailwind CSS (Styling)\n- Ollama with deepseek-r1:14b model (AI Analysis)\n- Tesseract OCR (Text Extraction)\n- Google Translate API (Translation)\n\n## Prerequisites\n\n1. Python 3.8 or higher\n2. Tesseract OCR installed\n3. Ollama with deepseek-r1:14b model\n\n## Installation\n\n1. Clone the repository:\n```bash\ngit clone <repository-url>\ncd medical-report-analyzer\n```\n\n2. Create a virtual environment:\n```bash\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n```\n\n3. Install dependencies:\n```bash\npip install -r requirements.txt\n```\n\n4. Install Tesseract OCR:\n   - Windows: Download and install from [Tesseract GitHub](https://github.com/UB-Mannheim/tesseract/wiki)\n   - Linux: `sudo apt-get install tesseract-ocr`\n   - Mac: `brew install tesseract`\n\n5. Install and run Ollama:\n   - Follow instructions at [Ollama](https://ollama.ai)\n   - Pull the model: `ollama pull deepseek-r1:14b`\n\n## Configuration\n\n1. Set Tesseract path in `app.py`:\n```python\npytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'  # Adjust path as needed\n```\n\n2. Ensure Ollama is running with the deepseek-r1:14b model:\n```bash\nollama run deepseek-r1:14b\n```\n\n## Running the Application\n\n1. Start the Flask server:\n```bash\npython app.py\n```\n\n2. Open a web browser and navigate to:\n```\nhttp://localhost:5000\n```\n\n## Usage\n\n1. **Analyzing Medical Reports**\n   - Click \"Report Analysis\" tab\n   - Upload JPG or PDF file\n   - View analysis results\n   - Optionally translate to Bengali\n\n2. **Analyzing Symptoms**\n   - Click \"Symptoms Analysis\" tab\n   - Describe symptoms in detail\n   - Click \"Analyze Symptoms\"\n   - View analysis and recommendations\n\n3. **Getting Medicine Information**\n   - Click \"Medicine Info\" tab\n   - Enter patient age and gender\n   - Input medicine name and dosage schedule\n   - Click \"Analyze Medicine\"\n   - View detailed medicine analysis\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details. ",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "tanvirhafiz",
        "bengali",
        "bilingual",
        "tanvirhafiz medical",
        "processing tanvirhafiz",
        "medical reports"
      ],
      "category": "document-processing"
    },
    "Teeksss--mcp": {
      "owner": "Teeksss",
      "name": "mcp",
      "url": "https://github.com/Teeksss/mcp",
      "imageUrl": "/freedevtools/mcp/pfp/Teeksss.webp",
      "description": "Integrates multiple AI models and implements retrieval-augmented generation (RAG) alongside large language models (LLMs). Supports PDF and OCR processing for enhanced data handling while providing a simplified setup for backend and frontend deployment.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-04-28T10:45:44Z",
      "readme_content": "# MCP Server (Multi-Model + RAG + LLM Platform)\n\n## Kurulum Rehberi\n\n### Gereksinimler\n\n- **Python 3.9+**\n- **Node.js 16+** (frontend için)\n- **Tesseract** (OCR desteği için)\n- (Linux/Mac: `sudo apt install tesseract-ocr` veya `brew install tesseract`)\n- **pip** veya **poetry** (isteğe bağlı)\n\n---\n\n## 1. Backend Kurulumu\n\n### a) Sanal Ortam Oluştur\n\n```bash\npython -m venv venv\nsource venv/bin/activate\n```\n\n### b) Bağımlılıkları Yükle\n\n```bash\npip install -r requirements.txt\n# veya\npoetry install\n```\n\n### c) Ortam Değişkenleri\n\n`.env` dosyasını oluştur:\n\n```bash\ncp .env.example .env\n```\nGerekirse `OPENAI_API_KEY` ve diğer alanları doldur.\n\n### d) Veritabanını Başlat\n\n```bash\npython -c \"from src.models.database import init_db; init_db()\"\n```\n\n### e) Sunucuyu Çalıştır\n\n```bash\nuvicorn src.main:app --reload\n```\n- Uygulama arayüzü: [http://localhost:8000/docs](http://localhost:8000/docs)\n\n---\n\n## 2. Frontend (Web) Kurulumu\n\n```bash\ncd web\nnpm install\nnpm start\n```\n- Arayüz: [http://localhost:3000](http://localhost:3000)\n\n---\n\n## 3. Notlar\n\n- PDF/OCR için Tesseract kurulmalı.\n- LLM entegrasyonu için `OPENAI_API_KEY` veya HuggingFace modeli indirecek internet bağlantısı gereklidir.\n- Vektör veritabanı ve LLM eklemek için ilgili Python dosyalarından kolayca genişletebilirsiniz.\n\n---",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ocr",
        "document",
        "retrieval",
        "document processing",
        "ocr processing",
        "processing teeksss"
      ],
      "category": "document-processing"
    },
    "Tencent--cos-mcp": {
      "owner": "Tencent",
      "name": "cos-mcp",
      "url": "https://github.com/Tencent/cos-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/Tencent.webp",
      "description": "Integrate large language models with Tencent Cloud Object Storage (COS) and Data Insight (CI), enabling file management, automated cloud data handling, and various image and video processing tasks. Supports natural language-based metadata search and efficient backup workflows.",
      "stars": 15,
      "forks": 6,
      "license": "Other",
      "language": "TypeScript",
      "updated_at": "2025-10-02T12:48:08Z",
      "readme_content": "中文 | [English](README.en.md)\n\n# 腾讯云 COS MCP Server 🚀🚀🚀\n ![](https://badge.mcpx.dev?type=server 'MCP Server') [![npm Version](https://img.shields.io/npm/v/cos-mcp)](https://www.npmjs.com/package/cos-mcp) [![license](http://img.shields.io/badge/license-BSD3-brightgreen.svg?style=flat)](License.txt)\n\n<p align=\"center\">\n  <img alt=\"logo\" src=\"https://raw.githubusercontent.com/Tencent/cos-mcp/master/src/img/logo.png\"/>\n</p>\n\n基于 MCP 协议的腾讯云 COS MCP Server，无需编码即可让大模型快速接入腾讯云存储 (COS) 和数据万象 (CI) 能力。\n\n---\n\n## ✨ 核心功能\n\n### 云端存储能力\n- ⬆️ 文件上传到云端\n- ⬇️ 文件从云端下载\n- 📋 获取云端文件列表\n\n### 云端处理能力\n- 🖼️ 获取图片信息\n- 🔍 图片超分辨率\n- ✂️ 图片裁剪\n- 📲 二维码识别\n- 🏆 图片质量评估\n- 🅰️ 文字水印\n- 🎬 元数据/自然语言检索 (MateInsight)\n- 📄 文档转 PDF\n- 🎥 视频封面\n\n---\n\n## 💡 典型应用场景\n\n- 使用其他 MCP 能力获取的文本/图片/视频/音频等数据，可直接上传到 COS 云端存储。\n- 本地数据快速通过大模型转存到 COS 云端存储/备份。\n- 通过大模型实现自动化：将网页里的视频/图片/音频/文本等数据批量转存到 COS 云端存储。\n- 自动化将视频/图片/音频/文本等数据在云端处理，并转存到 COS 云端存储。\n\n---\n\n## 🌟 功能示例\n\n1. 上传文件到 COS  \n   ![eg1](https://raw.githubusercontent.com/Tencent/cos-mcp/master/src/img/eg1.png)\n2. 图片质量评估  \n   ![eg3](https://raw.githubusercontent.com/Tencent/cos-mcp/master/src/img/eg3.png)\n3. 自然语言检索图片  \n   ![eg2](https://raw.githubusercontent.com/Tencent/cos-mcp/master/src/img/eg2.png)\n4. 视频截帧  \n   ![eg15](https://raw.githubusercontent.com/Tencent/cos-mcp/master/src/img/eg15.png)\n\n---\n\n# 🔧 安装使用\n\n## 参数说明\n\n为了保护您的数据私密性，请准备以下参数：\n\n### 1. **SecretId / SecretKey**\n- **说明**: 腾讯云 COS 的密钥，用于身份认证，请妥善保管，切勿泄露。\n- **获取方式**: \n  1. 访问 [腾讯云密钥管理](https://console.cloud.tencent.com/cam/capi)。\n  2. 新建密钥并复制生成的 **SecretId** 和 **SecretKey**。\n\n### 2. **Bucket**\n- **示例**: `mybucket-123456`\n- **说明**: 存储桶名称，用于存放数据，相当于您的个人存储空间。\n- **获取方式**: \n  1. 访问 [存储桶列表](https://console.cloud.tencent.com/cos/bucket)。\n  2. 复制存储桶名称。如果没有存储桶，可点击“创建存储桶”，一般选择默认配置即可快速完成创建。\n\n### 3. **Region**\n- **示例**: `ap-beijing`\n- **说明**: 存储桶所在的地域。\n- **获取方式**: \n  1. 在 [存储桶列表](https://console.cloud.tencent.com/cos/bucket) 中找到存储桶。\n  2. 在存储桶名称一行查看所属地域并复制，例如：`ap-beijing`。\n\n### 4. **DatasetName**\n- **说明**: 非必填参数，数据智能检索操作需要此参数。\n- **获取方式**: \n  1. 访问 [数据集管理](https://console.cloud.tencent.com/cos/metaInsight/dataManage)。\n  2. 创建数据集并等待索引建立完成后，复制数据集名称。\n\n### 5. **connectType**\n- **说明**: 非必填参数，指定连接方式，可选值为 `stdio`（本地）或 `sse`（远程）。\n- **默认值**: `stdio`\n\n### 6. **port**\n- **说明**: 非必填参数，当连接方式为 `sse` 时，可自由设置端口。\n- **默认值**: `3001`\n\n---\n\n## 从 npx 启动\n\n在大模型内使用时（例如: cursor），需要在 `mcp.json` 中配置：\n\n```json\n{\n  \"mcpServers\": {\n    \"cos-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"cos-mcp\",\n        \"--Region=yourRegion\",\n        \"--Bucket=yourBucket\",\n        \"--SecretId=yourSecretId\",\n        \"--SecretKey=yourSecretKey\",\n        \"--DatasetName=yourDatasetname\"\n      ]\n    }\n  }\n}\n```\n\n也可以通过 JSON 配置：\n\n```json\n{\n  \"mcpServers\": {\n    \"cos-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"cos-mcp\",\n        \"--cos-config='{\\\"Region\\\":\\\"yourRegion\\\",\\\"Bucket\\\":\\\"yourBucket\\\",\\\"SecretId\\\":\\\"yourSecretId\\\",\\\"SecretKey\\\":\\\"yourSecretKey\\\",\\\"DatasetName\\\":\\\"yourDatasetname\\\"}'\"\n      ]\n    }\n  }\n}\n```\n\n---\n\n## 使用 npm 安装\n\n```bash\n# 安装\nnpm install -g cos-mcp@latest\n\n# 运行开启 SSE 模式\ncos-mcp --Region=yourRegion --Bucket=yourBucket --SecretId=yourSecretId --SecretKey=yourSecretKey --DatasetName=yourDatasetname --port=3001 --connectType=sse\n\n# 或通过 JSON 配置\ncos-mcp --cos-config='{\"Region\":\"yourRegion\",\"Bucket\":\"BucketName-APPID\",\"SecretId\":\"yourSecretId\",\"SecretKey\":\"yourSecretKey\",\"DatasetName\":\"datasetName\"}' --port=3001 --connectType=sse\n```\n\n在大模型内使用 SSE 模式时（例如: cursor），需要在 `mcp.json` 中配置：\n\n```json\n{\n  \"mcpServers\": {\n    \"cos-mcp\": {\n      \"url\": \"http://localhost:3001/sse\"\n    }\n  }\n}\n```\n\n---\n\n## 使用源码安装\n\n### 步骤 1: 克隆项目代码\n\n```bash\ngit clone https://github.com/Tencent/cos-mcp.git\ncd cos-mcp\n```\n\n### 步骤 2: 安装依赖\n\n```bash\nnpm install\n```\n\n### 步骤 3: 启动服务\n\n#### 3.1 配置本地环境变量\n\n创建 `.env` 文件，并配置以下环境变量：\n\n```env\nRegion='yourRegion'\nBucket='yourBucket'\nSecretId='yourSecretId'\nSecretKey='yourSecretKey'\nDatasetName=\"yourDatasetName\"\n```\n\n#### 3.2 本地 SSE 模式启动（方式一）\n\n```bash\nnpm run start:sse\n```\n\n#### 3.3 本地构建后使用 STDIO 模式（方式二）\n\n```bash\nnpm run build\n```\n\n构建产物位于 `dist/index.js`。\n\n---\n\n### 步骤 4: 在大模型内使用\n\n#### SSE 模式配置\n\n```json\n{\n  \"mcpServers\": {\n    \"cos-mcp\": {\n      \"url\": \"http://localhost:3001/sse\"\n    }\n  }\n}\n```\n\n#### STDIO 模式配置\n\n```json\n{\n  \"mcpServers\": {\n    \"cos-mcp\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"${your work space}/dist/index.js\"\n      ]\n    }\n  }\n}\n```\n\n完成以上步骤后，即可通过源码运行 COS MCP Server。\n\n---\n\n## ⚠️ 注意事项\n\n1. 如果安装了旧版本的包，可以将上述内容内 `cos-mcp` 改为 `cos-mcp@latest` 安装最新版包。\n2. 如果全局安装后直接使用 `cos-mcp` 不行，可能是全局变量有问题，可以使用拆分变量或 `npx` 的方式启动：\n   ```bash\n   npm install -g cos-mcp@latest\n   cos-mcp --cos-config=xxx --port=3001 --connectType=sse\n   ```\n   上述命令效果等同于：\n   ```bash\n   npx cos-mcp@latest --cos-config=xxx --port=3001 --connectType=sse\n   ```\n3. 如果出现解析问题，可能是终端对双引号敏感，可以将配置参数改为以下格式再尝试：\n   ```bash\n   --cos-config='{\\\"Region\\\":\\\"yourRegion\\\",\\\"Bucket\\\":\\\"BucketName-APPID\\\",\\\"SecretId\\\":\\\"yourSecretId\\\",\\\"SecretKey\\\":\\\"yourSecretKey\\\",\\\"DatasetName\\\":\\\"datasetName\\\"}' --port=3001 --connectType=sse\n   ```\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "cloud",
        "storage",
        "processing",
        "tencent cloud",
        "document processing",
        "storage cos"
      ],
      "category": "document-processing"
    },
    "VadimNastoyashchy--json-mcp": {
      "owner": "VadimNastoyashchy",
      "name": "json-mcp",
      "url": "https://github.com/VadimNastoyashchy/json-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/VadimNastoyashchy.webp",
      "description": "Efficiently interacts with JSON files by splitting, merging, and validating data based on specified conditions. Designed for seamless integration with language models to automate JSON data manipulation within development environments.",
      "stars": 11,
      "forks": 2,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-10-04T07:49:29Z",
      "readme_content": "# JSON MCP\n\n[![Smithery Badge](https://smithery.ai/badge/@VadimNastoyashchy/json-mcp)](https://smithery.ai/server/@VadimNastoyashchy/json-mcp)\n\nThe **Model Context Protocol (MCP)** server empowers **LLMs** to efficiently interact with JSON files. With JSON MCP, you can **split**, **merge**, and **find specific data**, **validate** within JSON files based on defined conditions.\n\n---\n\n<a href=\"https://glama.ai/mcp/servers/@VadimNastoyashchy/json-mcp\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@VadimNastoyashchy/json-mcp/badge\" />\n</a>\n\n---\n\n## 🌟 Key Features\n\n✅ **Fast and lightweight**  \n✅ **LLM-friendly functionality**\n\n---\n\n## 🎥 Demo\n\nBelow is a demo showcasing the `split` functionality:\n\n\n\n---\n\n## 🔧 Use Cases (Tools)\n\n### 1. **`split`**\n\nSplit a JSON file into a specified number of objects.\n\n> **Note:** The file path must be provided.\n\n**Prompt Example:**\n\n```plaintext\nSplit JSON file from /Users/json-mcp/tests/merged.json\n5 objects per file\n```\n\n### 2. **`merge`**\n\nMerge JSON files into a one JSON file\n\n> **Note:** The folder path should be provided\n\n**Prompt Example:**\n\n```plaintext\nMerge json files from /Users/json-mcp/tests\n```\n\n---\n\n### ⚙️ Configuration\n\n[<img src=\"https://img.shields.io/badge/VS_Code-VS_Code?style=flat-square&label=Install%20Server&color=0098FF\" alt=\"Install in VS Code\">](https://insiders.vscode.dev/redirect?url=vscode:mcp/install?%7B%22name%22%3A%22%40VadimNastoyashchy%2Fjson-mcp%22%2C%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22%40smithery%2Fcli%40latest%22%2C%22run%22%2C%22%40VadimNastoyashchy%2Fjson-mcp%22%2C%22--key%22%2C%2292357446-baf5-439c-b7c1-b5263e221b57%22%5D%7D)\n\n#### VS Code Manual Configuration\n\nTo configure the JSON MCP server manually in VS Code, update the **User Settings (JSON)** file:\n\n```json\n{\n  \"mcp\": {\n    \"servers\": {\n      \"json-mcp-server\": {\n        \"command\": \"npx\",\n        \"args\": [\"json-mcp-server@latest\"]\n      }\n    }\n  }\n}\n```\n\n#### Installation in VS Code\n\nYou can install the JSON MCP server using the VS Code CLI:\n\n```bash\n# For VS Code\ncode --add-mcp '{\"name\":\"json-mcp-server\",\"command\":\"npx\",\"args\": [\"json-mcp-server@latest\"]}'\n```\n\nAfter installation, the JSON MCP server will be available for use with your GitHub Copilot agent in VS Code.\n\n#### Claude Desktop\n\nTo install json-mcp for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@VadimNastoyashchy/json-mcp):\n\n```bash\nnpx -y @smithery/cli install @VadimNastoyashchy/json-mcp --client claude\n```\n\n---\n\n### ⚙️ Installation Server\n\n#### Install globally\n\n```bash\nnpm install -g json-mcp-server@latest\n```\n\n#### Run after global installation\n\n```bash\njson-mcp-server\n```\n\n#### Using npx with latest version (recommended)\n\n```bash\nnpx json-mcp-server@latest\n```",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "json",
        "document",
        "automate",
        "json files",
        "vadimnastoyashchy json",
        "automate json"
      ],
      "category": "document-processing"
    },
    "VivekKumarNeu--MCP-Lucene-Server": {
      "owner": "VivekKumarNeu",
      "name": "MCP-Lucene-Server",
      "url": "https://github.com/VivekKumarNeu/MCP-Lucene-Server",
      "imageUrl": "/freedevtools/mcp/pfp/VivekKumarNeu.webp",
      "description": "Efficiently manage and retrieve documents using Apache Lucene with a RESTful API for complex querying and document management tasks. Supports adding, updating, deleting, and querying documents while utilizing Lucene's powerful indexing features.",
      "stars": 0,
      "forks": 1,
      "license": "Apache License 2.0",
      "language": "Java",
      "updated_at": "2025-09-28T01:48:15Z",
      "readme_content": "![License](https://img.shields.io/github/license/VivekKumarNeu/MCP-Lucene-Server)\n\n\n# MCP Lucene Server\n\n## Description\n\nThe MCP Lucene Server is a Java-based implementation of the Model Context Protocol (MCP) designed to provide efficient search and retrieval capabilities using Apache Lucene. This server allows you to manage and query documents, leveraging Lucene's powerful indexing and search features. It is built using Spring Boot for easy setup and deployment.\n\n\n![lucene_mcp1](https://github.com/user-attachments/assets/5dc28224-2dda-4b42-ac90-83343c9c386d)\n\n![lucene_mcp2](https://github.com/user-attachments/assets/b5ffd0cf-87ad-4129-af34-98163690f2ba)\n\n## Features\n\n* **MCP Compliance:** Implements the core Model Context Protocol.\n\n* **Lucene-Powered:** Utilizes Apache Lucene for full-text search and indexing.\n\n* **RESTful API:** Provides a RESTful API for interacting with the server.\n\n* **Document Management:**\n\n    * **Upsert:** Add or update documents in the Lucene index.\n\n    * **Delete:** Delete documents from the Lucene index.\n\n    * **List:** Retrieve a list of documents from the index.\n\n* **Querying:**\n\n    * Supports complex queries using the Lucene query syntax.\n\n    * Filtering: Filter queries based on document metadata.\n\n* **Status:** Check the server status.\n\n* **Spring Boot:** Built with Spring Boot for easy setup and deployment.\n* **Dockerization:** Includes instructions for containerizing the application using Docker.\n\n## Table of Contents\n\n* [Description](#description)\n\n* [Features](#features)\n\n* [Getting Started](#getting-started)\n\n    * [Prerequisites](#prerequisites)\n\n    * [Installation](#installation)\n\n    * [Running the Server](#running-the-server)\n\n* [Usage](#usage)\n\n    * [API Endpoints](#api-endpoints)\n\n    * [Examples](#examples)\n\n* [Configuration](#configuration)\n\n* [License](#license)\n\n## Getting Started\n\n### Prerequisites\n\n* **Java:** Java 11 or higher.\n\n* **Maven:** Maven 3.6.0 or higher.\n* **Docker:** [Install Docker](https://docs.docker.com/get-docker/) if you plan to use the Docker image.\n\n### Installation\n\n1.  **Clone the repository:**\n\n    ```\n    git clone [https://github.com/your-username/mcp-lucene-server.git](https://github.com/your-username/mcp-lucene-server.git)\n    cd mcp-lucene-server\n    ```\n\n    (Replace `your-username` with your GitHub username)\n\n2.  **Build the project using Maven:**\n\n    ```\n    mvn clean install\n    ```\n\n### Running the Server\n\n#### Without Docker\n\n1.  **Run the Spring Boot application:**\n    ```bash\n    java -jar target/mcp-lucene-server-0.0.1-SNAPSHOT.jar\n    ```\n    (The exact name of the `.jar` file might vary slightly depending on your project version.)\n\n2.  The server will start on port `8080` by default.\n\n#### With Docker\n\n1.  **Ensure you have Docker installed:** Follow the instructions on the official Docker website: [https://docs.docker.com/get-docker/](https://docs.docker.com/get-docker/)\n2.  **Build the Docker image:**\n    Navigate to the root directory of your project in your terminal and run:\n    ```bash\n    docker build -t mcp-lucene-server .\n    ```\n\n5.  **Run the Docker container:**\n    ```bash\n    docker run -p 8080:8080 mcp-lucene-server\n    ```\n    This will map port `8080` on your host machine to port `8080` inside the container.\n\n## MCP Shim for Claude Desktop\n\nThis project includes an optional MCP shim (`mcp-shim/`) that exposes the server's REST endpoints as MCP tools over STDIO so you can use them directly from Claude Desktop.\n\n### Prerequisites\n- Java 17+\n- Node.js 18+\n- Maven 3.6+\n\n### 1) Run the Spring Boot server\n```bash\nmvn spring-boot:run\n```\nThe API will be available at `http://localhost:8080/mcp/v1`.\n\n### 2) Run the MCP shim\n```bash\ncd mcp-shim\nnpm install\n# JSON + text output (default)\nLUCENE_BASE_URL=http://localhost:8080/mcp/v1 npm start\n# If your client cannot render JSON tool outputs, force text-only\nMCP_FORCE_TEXT=1 LUCENE_BASE_URL=http://localhost:8080/mcp/v1 npm start\n```\n\n### 3) Configure Claude Desktop\nUpdate `~/.claude/mcp/config.json`:\n```json\n{\n  \"mcpServers\": {\n    \"lucene\": {\n      \"command\": \"/opt/homebrew/bin/node\",\n      \"args\": [\".../MCP-Lucene-Server/mcp-shim/server.js\"],\n      \"env\": {\n        \"LUCENE_BASE_URL\": \"http://localhost:8080/mcp/v1\",\n        \"MCP_FORCE_TEXT\": \"1\"\n      }\n    }\n  }\n}\n```\nAlternatively, use the wrapper script to capture shim logs to `/tmp/mcp-lucene-shim.stderr.log`:\n```bash\ncat > .../MCP-Lucene-Server/mcp-shim/run-shim.sh <<'SH'\n#!/usr/bin/env bash\nset -euo pipefail\nexport LUCENE_BASE_URL=\"${LUCENE_BASE_URL:-http://localhost:8080/mcp/v1}\"\nexec node .../MCP-Lucene-Server/mcp-shim/server.js \\\n  2> /tmp/mcp-lucene-shim.stderr.log\nSH\nchmod +x .../MCP-Lucene-Server/mcp-shim/run-shim.sh\n```\nThen set in `~/.claude/mcp/config.json`:\n```json\n{\n  \"mcpServers\": {\n    \"lucene\": {\n      \"command\": \".../MCP-Lucene-Server/mcp-shim/run-shim.sh\",\n      \"env\": {\n        \"LUCENE_BASE_URL\": \"http://localhost:8080/mcp/v1\",\n        \"MCP_FORCE_TEXT\": \"1\"\n      }\n    }\n  }\n}\n```\n\n### 4) Available tools\n- `lucene_status`: Get server/index status\n- `lucene_upsert`: Upsert documents\n- `lucene_query`: Query documents (with optional metadata filters)\n- `lucene_delete`: Delete by IDs\n- `lucene_list`: List documents with pagination\n\n### 5) Example prompts for Claude Desktop\n- Run `lucene_status`\n- Run `lucene_list` with: `{ \"limit\": 10, \"offset\": 0 }`\n- Run `lucene_upsert` with: `{\"documents\":[{\"id\":\"doc-1\",\"text\":\"hello world\",\"metadata\":{\"lang\":\"en\"}}]}`\n- Run `lucene_query` with: `{\"queries\":[{\"query\":\"hello\",\"top_k\":5}]}`\n- Run `lucene_delete` with: `{ \"ids\": [\"doc-1\"] }`\n\n### 6) Troubleshooting\n- Verify the API returns JSON:\n```bash\ncurl -i http://localhost:8080/mcp/v1/status\n```\n- If Claude shows \"unsupported format\", start the shim with text-only output:\n```bash\nMCP_FORCE_TEXT=1 LUCENE_BASE_URL=http://localhost:8080/mcp/v1 npm start\n```\n- View shim logs (when using wrapper):\n```bash\ntail -n +1 /tmp/mcp-lucene-shim.stderr.log\n```\n- Ensure the paths in your `config.json` are absolute and correct, then restart Claude Desktop.\n\n\n### API Endpoints (for Curl)\n\nThe server provides the following API endpoints:\n\n* `GET /mcp/v1/status`\n\n    * Returns the status of the server.\n\n* `POST /mcp/v1/upsert`\n\n    * Upserts (inserts or updates) one or more documents.\n\n    * Request body:\n\n        ```json\n        {\n          \"documents\": [\n            {\n              \"id\": \"doc1\",\n              \"text\": \"This is the text of document 1.\",\n              \"metadata\": {\n                \"category\": \"example\",\n                \"language\": \"english\"\n              }\n            },\n            {\n              \"id\": \"doc2\",\n              \"text\": \"This is document 2's text.\",\n              \"metadata\": {\n                \"category\": \"sample\",\n                \"language\": \"spanish\"\n              }\n            }\n          ]\n        }\n        ```\n\n* `POST /mcp/v1/query`\n\n    * Queries the Lucene index.\n\n    * Request body:\n\n        ```json\n        {\n          \"queries\": [\n            {\n              \"query\": \"document\",\n              \"top_k\": 10,\n              \"filter\": {\n                \"language\": \"english\"\n              }\n            },\n             {\n              \"query\": \"text search\",\n              \"filter\": {\n                 \"category\": \"example\"\n               }\n             }\n          ]\n        }\n        ```\n\n    * `query`: The Lucene query string.\n\n    * `top_k`: (Optional) The maximum number of results to return (default: 10).\n\n    * `filter`: (Optional) A map of metadata fields and values to filter by.\n\n* `POST /mcp/v1/delete`\n\n    * Deletes documents from the Lucene index.\n\n    * Request body:\n\n        ```json\n        {\n            \"ids\": [\"doc1\", \"doc2\"]\n        }\n        ```\n\n* `GET /mcp/v1/list`\n\n    * Lists documents from the Lucene index.\n\n    * Request body:\n\n        ```json\n        {\n            \"ids\": [\"doc1\", \"doc2\"]\n        }\n        ```\n\n### Examples\n\n**Get server status:**\n\n```bash\ncurl http://localhost:8080/mcp/v1/status\n```\n\n**Upsert documents:**\n\n```bash\ncurl -X POST \n\nhttp://localhost:8080/mcp/v1/upsert \n\n-H 'Content-Type: application/json' \n\n-d '{\n\"documents\": [\n{\n\"id\": \"doc1\",\n\"text\": \"This is the text of document 1.\",\n\"metadata\": {\n\"category\": \"example\",\n\"language\": \"english\"\n}\n},\n{\n\"id\": \"doc2\",\n\"text\": \"This is document 2''s text.\",\n\"metadata\": {\n\"category\": \"sample\",\n\"language\": \"spanish\"\n}\n}\n]\n}'\n```\n\n**Query documents:**\n\n```bash\ncurl -X POST \n\nhttp://localhost:8080/mcp/v1/query \n\n-H 'Content-Type: application/json' \n\n-d '{\n\"queries\": [\n{\n\"query\": \"document text\",\n\"top_k\": 5,\n\"filter\": {\n\"language\": \"english\"\n}\n}\n]\n}'\n```\n\n**Delete documents:**\n\n```bash\ncurl -X POST \n\nhttp://localhost:8080/mcp/v1/delete \n\n-H 'Content-Type: application/json' \n\n-d '{\n\"ids\": [\"doc1\"]\n}'\n```\n\n**List documents:**\n\n```bash\ncurl -X POST \n\nhttp://localhost:8080/mcp/v1/list \n\n-H 'Content-Type: application/json' \n\n-d '{\n\"ids\": [\"doc1\", \"doc2\"]\n}'\n```\n\n## Configuration\n\nThe server can be configured using Spring Boot's application properties. Here are some of the key properties:\n\n* `server.port`: The port the server listens on (default: 8080).\n\n* `lucene.index.path`: The path to the Lucene index directory. This is where the indexed data is stored. If not set, a default location is used. It is highly recommended to configure this to a persistent storage location.\n\nYou can set these properties in an `application.properties` or `application.yml` file in your `src/main/resources` directory, or by using environment variables.\n\n**Example `application.properties`:**\n\n\nserver.port=8080\nlucene.index.path=/path/to/lucene/index\n\n## License\n\nThis project is licensed under the [Apache 2.0 License](https://www.apache.org/licenses/LICENSE-2.0).\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "lucene",
        "indexing",
        "documents",
        "lucene restful",
        "apache lucene",
        "lucene server"
      ],
      "category": "document-processing"
    },
    "Vortiago--mcp-outline": {
      "owner": "Vortiago",
      "name": "mcp-outline",
      "url": "https://github.com/Vortiago/mcp-outline",
      "imageUrl": "/freedevtools/mcp/pfp/Vortiago.webp",
      "description": "Enables interaction with Outline's document management services through natural language commands for searching, creating, and managing documents. Facilitates tasks like reading document content and managing comments within a structured collection.",
      "stars": 40,
      "forks": 12,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-30T05:19:13Z",
      "readme_content": "# MCP Outline Server\n\nA Model Context Protocol (MCP) server enabling AI assistants to interact with Outline (https://www.getoutline.com)\n\n## Overview\n\nThis project implements a Model Context Protocol (MCP) server that allows AI assistants (like Claude) to interact with Outline document services, providing a bridge between natural language interactions and Outline's document management capabilities.\n\n## Features\n\nCurrently implemented:\n\n- **Document Search**: Search for documents by keywords\n- **Collection Management**: List collections and view document structure\n- **Document Reading**: Read document content, export as markdown\n- **Comment Management**: View and add comments on documents\n- **Document Creation**: Create new documents in collections\n- **Document Editing**: Update document content and move documents\n- **Backlink Management**: View documents that link to a specific document\n\n## Add to Cursor with Docker\n\nWe recommend running this python MCP server using Docker to avoid having to install dependencies on your machine.\n\n1. Install and run Docker (or Docker Desktop)\n2. Build the Docker image `docker buildx build -t mcp-outline .`\n3. In Cursor, go to the \"MCP Servers\" tab and click \"Add Server\"\n   ```json\n   {\n     \"mcpServers\": {\n       \"mcp-outline\": {\n         \"command\": \"docker\",\n         \"args\": [\n           \"run\",\n           \"-i\",\n           \"--rm\",\n           \"--init\",\n           \"-e\",\n           \"DOCKER_CONTAINER=true\",\n           \"-e\",\n           \"OUTLINE_API_KEY\",\n           \"-e\",\n           \"OUTLINE_API_URL\",\n           \"mcp-outline\"\n         ],\n         \"env\": {\n           \"OUTLINE_API_KEY\": \"<YOUR_OUTLINE_API_KEY>\",\n           \"OUTLINE_API_URL\": \"<YOUR_OUTLINE_API_URL>\"\n         }\n       }\n     }\n   }\n   ```\n   > OUTLINE_API_URL is optional, defaulting to https://app.getoutline.com/api\n4. Debug the docker image by using MCP inspector and passing the docker image to it:\n   ```bash\n   npx @modelcontextprotocol/inspector docker run -i --rm --init -e DOCKER_CONTAINER=true --env-file .env mcp-outline\n   ```\n\n## Development\n\n### Prerequisites\n\n- Python 3.10+\n- Outline account with API access\n- Outline API key (get this from your Outline account settings)\n\n### Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/Vortiago/mcp-outline.git\ncd mcp-outline\n\n# Install in development mode\nuv pip install -e \".[dev]\"\n```\n\n### Configuration\n\nCreate a `.env` file in the project root with the following variables:\n\n```\n# Outline API Configuration\nOUTLINE_API_KEY=your_outline_api_key_here\n\n# For cloud-hosted Outline (default)\n# OUTLINE_API_URL=https://app.getoutline.com/api\n\n# For self-hosted Outline\n# OUTLINE_API_URL=https://your-outline-instance.example.com/api\n```\n\n### Running the Server\n\n```bash\n# Development mode with the MCP Inspector\nmcp dev src/mcp_outline/server.py\n\n# Or use the provided script\n./start_server.sh\n\n# Install in Claude Desktop (if available)\nmcp install src/mcp_outline/server.py --name \"Document Outline Assistant\"\n```\n\nWhen running the MCP Inspector, go to Tools > Click on a tool > it appears on the right side so that you can query it.\n\n\n## Usage Examples\n\n### Search for Documents\n\n```\nSearch for documents containing \"project planning\"\n```\n\n### List Collections\n\n```\nShow me all available collections\n```\n\n### Read a Document\n\n```\nGet the content of document with ID \"docId123\"\n```\n\n### Create a New Document\n\n```\nCreate a new document titled \"Research Report\" in collection \"colId456\" with content \"# Introduction\\n\\nThis is a research report...\"\n```\n\n### Add a Comment\n\n```\nAdd a comment to document \"docId123\" saying \"This looks great, but we should add more details to the methodology section.\"\n```\n\n### Move a Document\n\n```\nMove document \"docId123\" to collection \"colId789\"\n```\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## Development\n\n```bash\n# Run tests\nuv run pytest tests/\n\n# Format code\nuv run ruff format .\n```\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Acknowledgments\n\n- Built with [MCP Python SDK](https://github.com/modelcontextprotocol/python-sdk)\n- Uses [Outline API](https://getoutline.com) for document management",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "outline",
        "document",
        "documents",
        "mcp outline",
        "outline document",
        "outline enables"
      ],
      "category": "document-processing"
    },
    "Wildebeest--mcp_pdf_forms": {
      "owner": "Wildebeest",
      "name": "mcp_pdf_forms",
      "url": "https://github.com/Wildebeest/mcp_pdf_forms",
      "imageUrl": "/freedevtools/mcp/pfp/Wildebeest.webp",
      "description": "Manipulate and visualize PDF forms by extracting field information and highlighting form fields for analysis. Streamline PDF workflows using a toolkit built with MCP and PyMuPDF.",
      "stars": 7,
      "forks": 4,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-10-03T03:15:44Z",
      "readme_content": "# MCP PDF Forms\n\nA PDF form manipulation toolkit built with [MCP](https://github.com/llama-index-ai/mcp) and PyMuPDF.\n\n## Features\n\n- Find PDF files across multiple directories\n- Extract form field information from PDF files\n- Visualize form fields in PDF documents\n\n## Installation\n\n```bash\n# Install package from PyPI\npip install mcp_pdf_forms\n\n# Or install from source\ngit clone https://github.com/Wildebeest/mcp_pdf_forms.git\ncd mcp_pdf_forms\npip install -e .\n```\n\n## Command Line Tool\n\nAfter installation, you can use the `mcp-pdf-forms` command to start the server:\n\n```bash\n# Start the server with one or more directories to scan for PDFs\nmcp-pdf-forms examples\n```\n\nYou can also add it to Claude Code as an MCP:\n\n```bash\nclaude mcp add pdf-forms mcp-pdf-forms .\n```\n## Usage\n\nOnce installed, you can use the package to work with PDF forms. The package provides tools through the MCP interface.\n\n### PDF Discovery Tool\n\nThe PDF Discovery tool helps you find PDF files across specified directories.\n\n- **Input**: Directory paths to search for PDFs\n- **Output**: List of PDF files found in the specified directories\n- **Usage**: Use this to quickly locate all PDF files in your project or specified folders\n\n### Form Field Extraction Tool\n\nThe Form Field Extraction tool extracts information about all form fields in a PDF document.\n\n- **Input**: Path to a PDF file\n- **Output**: Detailed information about each form field including field name, type, position, and other properties\n- **Usage**: Use this to analyze form structure and understand the fields available for filling\n\n### Field Highlight Visualization Tool\n\nThe Field Highlight tool creates a visual representation of form fields in the PDF.\n\n- **Input**: Path to a PDF file\n- **Output**: Modified PDF with all form fields highlighted for easy identification\n- **Usage**: Use this to visually inspect the layout and position of form fields in your document\n\n## Libraries Used\n\n- [MCP](https://github.com/llama-index-ai/mcp) - Machine Conversation Protocol framework\n- [PyMuPDF](https://github.com/pymupdf/PyMuPDF) - Python bindings for MuPDF, a high-performance PDF library\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcp_pdf_forms",
        "pdf",
        "forms",
        "pdf forms",
        "mcp_pdf_forms manipulate",
        "wildebeest mcp_pdf_forms"
      ],
      "category": "document-processing"
    },
    "WindieChai--confluence-wiki-mcp-server-extension": {
      "owner": "WindieChai",
      "name": "confluence-wiki-mcp-server-extension",
      "url": "https://github.com/WindieChai/confluence-wiki-mcp-server-extension",
      "imageUrl": "/freedevtools/mcp/pfp/WindieChai.webp",
      "description": "Integrate Confluence Wiki content with AI models for enhanced analysis and interaction. Convert Wiki content to Markdown format and securely manage access to your Wiki data through an easy configuration interface.",
      "stars": 3,
      "forks": 1,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-05-15T19:09:24Z",
      "readme_content": "# Confluence Wiki MCP Server Extension\n\nA VSCode/Cursor extension providing an MCP Server for Confluence Wiki integration.\n\n## Features\n\n- Integrate with Confluence Wiki through MCP Server\n- Easy configuration interface with secure credential storage\n- Convert Wiki content to Markdown format\n\n## How to Use\n\n1. **Configure Confluence Wiki Connection**\n   - Open Command Palette (`Cmd+Shift+P` / `Ctrl+Shift+P`)\n   - Type \"Confluence Wiki MCP Server: Configuration\" and select it\n   - In the configuration page, enter your:\n     - Confluence Wiki Host URL\n     - Username\n     - Password\n   - Click \"Save Configuration\" button\n   - Your credentials will be securely stored in an encrypted file\n\n2. **Set up MCP Server in Cursor**\n   - Open Cursor's Settings\n   - Navigate to \"MCP\" section\n   - Click \"Add new MCP Server\"\n   - Configure the server with following information:\n     - Name: Wiki\n     - Type: Command\n     - Command: [The path shown in Configuration page]\n\n3. **Using the Wiki MCP Server in Cursor**\n   - Open a chat with Claude or another AI model in Cursor\n   - Switch to \"Edit\" or \"Agent\" mode for best results\n   - In your prompt, include the Wiki URL and any specific requirements, for example:\n     ```\n     Please summarize the content from this Confluence Wiki page: \n     https://your-wiki-url\n     ```\n   - Send your message\n   - Cursor will recognize the Wiki URL and prompt you to call this MCP Tool\n   - Click \"Run tool\" when prompted\n   - The extension will fetch the content, convert it to Markdown, and provide it to the AI model\n   - The AI will then respond based on the Wiki content\n\nAfter completing these steps, your Cursor will be able to fetch content from your Confluence Wiki through the MCP Server.\n\n**Note**: Your credentials are stored securely in an encrypted file and are never exposed in VSCode settings.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "confluence",
        "wiki",
        "markdown",
        "confluence wiki",
        "wiki content",
        "integrate confluence"
      ],
      "category": "document-processing"
    },
    "YOOTeam--ChatPPT-MCP": {
      "owner": "YOOTeam",
      "name": "ChatPPT-MCP",
      "url": "https://github.com/YOOTeam/ChatPPT-MCP",
      "imageUrl": "/freedevtools/mcp/pfp/YOOTeam.webp",
      "description": "AI-powered service for generating PowerPoint presentations based on themes or uploaded documents, with features for online editing and downloading final outputs.",
      "stars": 99,
      "forks": 18,
      "license": "GNU Affero General Public License v3.0",
      "language": "JavaScript",
      "updated_at": "2025-09-30T04:22:54Z",
      "readme_content": "# ChatPPT-MCP\nChatPPT​​ is an AI-powered presentation generation service that allows users to:\n- Generate PPTs ​​based on themes or requirements​​.\n- Upload documents​​ (e.g., Word, PDF) for automatic PPT creation.\n- Edit online​​ and ​​download​​ the final output.\n\nWe are gradually rolling out the ​​ChatPPT-Server​​ in ​​STDIO mode​​ and Streamable HTTP protocol.\n\nProvide three ways for you to experience the MCP Server service for ChatPPT: Python, Node.js, and Streamable HTTP.\n\nBy using Python and Node.js, you can directly view the clone source code and execute calls using the local Stio mode.\n\nWe highly recommend using the Streamable HTTP method for your experience, without the need to install any dependencies. \n\nYou can directly configure it on a client that supports MCP Streamable HTTP.\nThe latest versions of Cursor (www.cursor. com) and Trae (www.trae. cn) are now available for use, and you can choose the method that suits you.\n\n\nCheck out these demo videos below to see it in action!\n[【Case 01】ChatPPT+demo](https://yoo-web-public.cdn.bcebos.com/chatppt%2Fimport_example%2F%E3%80%90case%20video%E3%80%91chatppt-mcp%20server.mp4)\n\n[【Case 02】ChatPPT+weather](https://yoo-web-public.cdn.bcebos.com/chatppt%2Fimport_example%2F%E3%80%90case%20video%E3%80%91chatppt-openweather.mp4)\n\n[【Case 03】ChatPPT+arxiv](https://yoo-web-public.cdn.bcebos.com/chatppt%2Fimport_example%2F%E3%80%90case%20video%E3%80%91chatppt-arxiv.mp4)\n\n[【Case 04】ChatPPT+baidu](https://yoo-web-public.cdn.bcebos.com/chatppt%2Fimport_example%2F%E3%80%90case%20video%E3%80%91chatppt-baidu%20search.mp4)\n\n[【Case 05】ChatPPT+map](https://yoo-web-public.cdn.bcebos.com/chatppt%2Fimport_example%2F%E3%80%90case%20video%E3%80%91chatppt-gaode%20maps%20of%20plan.mp4)\n\nBIYOO Tech MCP Server​​ now supports ​​18 intelligent document processing APIs​​, covering (but not limited to):\n- PPT authoring, enhancement, and generation\n- Resume creation and analysis\n- Job-resume matching\n- and other document processing scenarios.\nUsers can leverage the server to ​​build their own document creation tools​​, unlocking more possibilities for intelligent document generation.\n\nFor any additional usage inquiries or requirements, please feel free to contact us at [https://www.yoo-ai.com](https://www.yoo-ai.com?chanel=github])\n\n\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "powerpoint",
        "presentations",
        "mcp",
        "generating powerpoint",
        "powerpoint presentations",
        "chatppt mcp"
      ],
      "category": "document-processing"
    },
    "YassineTk--mcp-docs-provider": {
      "owner": "YassineTk",
      "name": "mcp-docs-provider",
      "url": "https://github.com/YassineTk/mcp-docs-provider",
      "imageUrl": "/freedevtools/mcp/pfp/YassineTk.webp",
      "description": "Enables AI models to access and query local markdown technical documentation, enhancing context-aware responses. Supports dynamic integration of documentation, allowing updates without server rebuilds.",
      "stars": 5,
      "forks": 2,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-04-16T13:10:25Z",
      "readme_content": "# MCP Docs Provider\n\n[![smithery badge](https://smithery.ai/badge/@YassineTk/mcp-docs-provider)](https://smithery.ai/server/@YassineTk/mcp-docs-provider)\n\nDocumentation context provider for LLMs via MCP. This server enables AI models to seamlessly access and query your local markdown technical documentation.\n\n### Installing via Smithery\n\nTo install mcp-docs-provider for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@YassineTk/mcp-docs-provider):\n\n```bash\nnpx -y @smithery/cli install @YassineTk/mcp-docs-provider --client claude\n```\n\n## Configuration with cursor\n\nAdd this to your Cursor configuration file (`mcp.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-docs-provider\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"mcp-docs-provider\",\n        \"/path/to/your/documentation.md\"\n      ]\n    }\n  }\n}\n```\n\n- `/path/to/your/documentation.md` with the path to your markdown documentation file\n### No rebuild is required after updating your Markdown documentation.\n\n## MCP Client Rules Configuration\n\nAdd the following specification to your MCP Client Rules (eg. Cursor) (This ensures the documentation context is automatically used without explicitly mentioning \"Using my MCP\" in queries.):\n\"If a user ask you about ui pattern then follow the mcp-docs-provider MCP server.\"\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "documentation",
        "document",
        "markdown",
        "documentation enhancing",
        "docs provider",
        "mcp docs"
      ],
      "category": "document-processing"
    },
    "YuChenSSR--mindmap-mcp-server": {
      "owner": "YuChenSSR",
      "name": "mindmap-mcp-server",
      "url": "https://github.com/YuChenSSR/mindmap-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/YuChenSSR.webp",
      "description": "Converts Markdown content into interactive mindmaps, generating HTML mindmaps or saving them as files for easy access and sharing. Enhances project planning and brainstorming through visual representations of ideas.",
      "stars": 197,
      "forks": 20,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-03T22:31:01Z",
      "readme_content": "# Mindmap MCP Server\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/YuChenSSR/pics/master/imgs/2025-03-21/JMi7Mn89Hw5ikd9z.jpeg\" alt=\"mindmap_mcp\" width=\"50%\">\n</p>\n\nA Model Context Protocol (MCP) server for converting Markdown content to interactive mindmaps.\n\n\n\n## Installation\n\n```bash\npip install mindmap-mcp-server\n```\n\nOr using `uvx`:\n\n```bash\nuvx mindmap-mcp-server\n```\nOr using `docker` safer and easier.\n\n## Attention\n\nThree installation methods have been successfully tested on macOS and Linux. \n\nFor Windows users experiencing issues with `npx` for this MCP, consider using the Docker method. Alternatively, if you use Visual Studio Code, the [\"Markmap\"](https://marketplace.visualstudio.com/items?itemName=gera2ld.markmap-vscode) extension offers a potentially simpler solution than navigating command-line tools.\n\n---\n\nIf you're experiencing unresolved issues, you can use my recent system prompt as a Mindmap Assistant instead of using this MCP server.\n\n<details>  \n<summary>Using my system prompt instead of using this MCP server</summary>   \n\n```\nYou are a specialized assistant that generates HTML code for interactive markdown-based mind maps (markmaps). When a user sends you content, respond with a complete HTML document that displays their content as a markmap visualization.\nIf artifact tool is turned on, you can use the artifact.\n\nFollow these requirements:\n1. Use the markmap-autoloader library (version 0.18 or latest stable version)\n2. Format the HTML exactly according to the template below\n3. Replace the demo content in the template with the user's content, preserving their hierarchical structure\n4. Maintain the markmap configuration options (maxWidth: 300, colorFreezeLevel: 2)\n5. If the user doesn't provide markdown formatting (# for headings), format their content appropriately with main topics using # and subtopics using ##\n\nTemplate to follow:\n\n<!DOCTYPE html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"UTF-8\" />\n    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\" />\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n    <title>Markmap</title>\n    <style>\n      svg.markmap {\n        width: 100%;\n        height: 100vh;\n      }\n    </style>\n    <script src=\"https://cdn.jsdelivr.net/npm/markmap-autoloader@0.18\"></script>\n  </head>\n  <body>\n    <div class=\"markmap\">\n      <script type=\"text/template\">\n        ---\n        markmap:\n          maxWidth: 300\n          colorFreezeLevel: 2\n        ---\n\n        # markmap\n\n        ## Links\n\n        - <https://markmap.js.org/>\n        - [GitHub](https://github.com/markmap/markmap)\n\n        ## Related\n\n        - [coc-markmap](https://github.com/markmap/coc-markmap)\n        - [gatsby-remark-markmap](https://github.com/markmap/gatsby-remark-markmap)\n\n        ## Features\n\n        - links\n        - **inline** ~~text~~ *styles*\n        - multiline\n          text\n        - `inline code`\n        - Katex - $x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}$\n        - This is a very very very very very very very very very very very very very very very long line.\n      </script>\n    </div>\n  </body>\n</html>\n```\n  \n*Visualization options:*  (If formulas or symbols don’t display correctly, download the HTML file and open it in a browser.)\n1. View the mindmap  in artifacts (if available):\n![system_prompt_artifact](https://raw.githubusercontent.com/YuChenSSR/pics/master/imgs/2025-05-20/1i9LIfoVRdCV97HM.png)\n  \n2. Render the HTML file as a mindmap:\n![system_prompt_render](https://raw.githubusercontent.com/YuChenSSR/pics/master/imgs/2025-05-20/qv4ActvFaphc64oA.png)\n\n</details>\n\n---\n\n## Prerequisites\n\nThis package requires Node.js to be installed when using command `python` or `uvx` to run the server.\n\n\n\n## Usage\n\n### With Claude Desktop or other MCP clients\n\nAdd this server to your `claude_desktop_config.json`:\n\n<details>\n \n <summary>using `uvx`:</summary>\n\n```json\n{\n  \"mcpServers\": {\n    \"mindmap\": {\n      \"command\": \"uvx\",\n      \"args\": [\"mindmap-mcp-server\", \"--return-type\", \"html\"]\n    }\n  }\n}\n```\n\nor  \n\nrecommended:\n\n```json\n{\n  \"mcpServers\": {\n    \"mindmap\": {\n      \"command\": \"uvx\",\n      \"args\": [\"mindmap-mcp-server\", \"--return-type\", \"filePath\"]\n    }\n  }\n}\n```\n\nwe use `--return-type` to specify the return type of the mindmap content, you can choose `html` or `filePath` according to your needs.   \n`html` will return the entire HTML content of the mindmap, which you can preview in your AI client's artifact; \n\n![return_html_content](https://raw.githubusercontent.com/YuChenSSR/pics/master/imgs/2025-03-20/qAEimhwZJDQ3NBLs.png)\n\n![html_preview](https://raw.githubusercontent.com/YuChenSSR/pics/master/imgs/2025-03-21/SujqY2L5lhWSHWvi.png)\n\n\n`filePath` will save the mindmap to a file and return the file path,which you can open in your browser. It can **save your tokens** !\n\n![generate_file](https://raw.githubusercontent.com/YuChenSSR/pics/master/imgs/2025-03-20/WDqlWhsoiAYpLmBF.png)\n\n![file_to_open](https://raw.githubusercontent.com/YuChenSSR/pics/master/imgs/2025-03-20/jfRIDc5mfvNtKykC.png) \n\n</details>\n\n<details>\n<summary>using `python`:</summary>\n\nUsing [a specific Python file](https://github.com/YuChenSSR/mindmap-mcp-server/blob/main/mindmap_mcp_server/server.py) in this repository:\n\n\n```json\n{\n  \"mcpServers\": {\n    \"mindmap\": {\n      \"command\": \"python\",\n      \"args\": [\"/path/to/your/mindmap_mcp_server/server.py\", \"--return-type\", \"html\"]\n    }\n  }\n}\n```\n  \nor   \n\n```json\n{\n  \"mcpServers\": {\n    \"mindmap\": {\n      \"command\": \"python\",\n      \"args\": [\"/path/to/your/mindmap_mcp_server/server.py\", \"--return-type\", \"filePath\"]\n    }\n  }\n}\n```\nwe use `--return-type` to specify the return type of the mindmap content, you can choose `html` or `filePath` according to your needs. see using \\`uvx\\` for more details.\n\n</details>\n\n<details>\n\n<summary>using `docker`:</summary>\n\nFirst, you pull the image:\n\n```bash\ndocker pull ychen94/mindmap-converter-mcp\n```\n\nSecond, set the server:\n\n```json\n{\n  \"mcpServers\": {\n    \"mindmap-converter\": {\n      \"command\": \"docker\",\n      \"args\": [\"run\", \"--rm\", \"-i\", \"-v\", \"/path/to/output/folder:/output\", \"ychen94/mindmap-converter-mcp:latest\"]\n    }\n  }\n}\n```\n⚠️ Replace `/path/to/output/folder` with an actual path on your system where you want to save mind maps, such as `/Users/username/Downloads` on macOS or `C:\\\\Users\\\\username\\\\Downloads` on Windows.\n\n**Tools Provided in the docker container**\nThe server provides the following MCP tools:\n1. **markdown-to-mindmap-content**  \nConverts Markdown to an HTML mind map and returns the entire HTML content.  \nYou don't use the args: `-v` and `/path/to/output/folder:/output` in the command `docker`.  \n**Parameters**:   \n\t•\tmarkdown (string, required): The Markdown content to convert  \n\t•\ttoolbar (boolean, optional): Whether to show the toolbar (default: true)  \n**Best for**: Simple mind maps where the HTML content size isn't a concern. And you can use **artifact** in your AI client to preview the mindmap.  \n2. **markdown-to-mindmap-file**  \nConverts Markdown to an HTML mind map and saves it to a file in the mounted directory.  \n**Parameters**:  \n\t•\tmarkdown (string, required): The Markdown content to convert  \n\t•\tfilename (string, optional): Custom filename (default: auto-generated timestamp name)  \n\t•\ttoolbar (boolean, optional): Whether to show the toolbar (default: true)  \n**Best for**: Complex mind maps or when you want to **save the tokens** for later use.  \nyou can open the html file in your browser to view the mindmap. Also you can use the [iterm-mcp-server](https://github.com/ferrislucas/iterm-mcp) or other terminals' mcp servers to open the file in your browser without interrupting your workflow.  \n\n</details>\n\n### Troubleshooting \n\n**File Not Found**  \nIf your mind map file isn't accessible:  \n\t1\tCheck that you've correctly mounted a volume to the Docker container  \n\t2\tEnsure the path format is correct for your operating system  \n\t3\tMake sure Docker has permission to access the directory  \n \n**Docker Command Not Found**  \n\t1\tVerify Docker is installed and in your PATH  \n\t2\tTry using the absolute path to Docker  \n \n**Server Not Appearing in Claude**  \n\t1\tRestart Claude for Desktop after configuration changes  \n\t2\tCheck Claude logs for connection errors  \n\t3\tVerify Docker is running  \n\n**Advanced Usage  \nUsing with Other MCP Clients**  \nThis server works with any MCP-compatible client, not just Claude for Desktop. The server implements the Model Context Protocol (MCP) version 1.0 specification.  \n\n\n\n\n## Features  \n\nThis server provides a tool for converting Markdown content to mindmaps using the `markmap-cli` library:  \n\n- Convert Markdown to interactive mindmap HTML  \n- Option to create offline-capable mindmaps  \n- Option to hide the toolbar  \n- Return either HTML content or file path  \n\n## Example  \n\nIn Claude, you can ask:\n\n1. \n\"**give a mindmap for the following markdown code, using a mindmap tool:**\n```\n# Project Planning\n## Research\n### Market Analysis\n### Competitor Review\n## Design\n### Wireframes\n### Mockups\n## Development\n### Frontend\n### Backend\n## Testing\n### Unit Tests\n### User Testing\n```\n\"\n\n\nif you want to save the mindmap to a file, and then open it in your browser using the iTerm MCP server:   \n\n2. \n\"**give a mindmap for the following markdown input_code using a mindmap tool,\nafter that,use iterm to open the generated html file.\ninput_code:**\n```\nmarkdown content\n```\n\"\n\n\n3.\n\"**Think about the process of putting an elephant into a refrigerator, and provide a mind map. Open it with a terminal.**\"\n\n<details>\n\t\n<summary>see the result</summary>\n\t\n![aiworkflow](https://raw.githubusercontent.com/YuChenSSR/pics/master/imgs/2025-03-22/QUjGnpmUcPfd3lBI.png)\n\n![mindmapinbrowser](https://raw.githubusercontent.com/YuChenSSR/pics/master/imgs/2025-03-22/w7DZ4shFhLoQZruq.png)\n\n </details>\n\n \n**and more**\n\n\n## License\n\nThis project is licensed under the MIT License.\nFor more details, please see the LICENSE file in [this project repository](https://github.com/YuChenSSR/mindmap-mcp-server)  \n \n---\n \nIf this project is helpful to you, please consider giving it a Star ⭐️\n\nThe advancement of technology ought to benefit all individuals rather than exploit the general populace.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mindmaps",
        "mindmap",
        "markdown",
        "mindmap mcp",
        "html mindmaps",
        "interactive mindmaps"
      ],
      "category": "document-processing"
    },
    "ZubeidHendricks--youtube-mcp-server": {
      "owner": "ZubeidHendricks",
      "name": "youtube-mcp-server",
      "url": "https://github.com/ZubeidHendricks/youtube-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/ZubeidHendricks.webp",
      "description": "Interacts with YouTube content by retrieving video details, managing channels, and accessing transcripts through a standardized interface. Allows for video statistics, channel management, and playlist details.",
      "stars": 356,
      "forks": 62,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T17:09:26Z",
      "readme_content": "# YouTube MCP Server\n[![smithery badge](https://smithery.ai/badge/@ZubeidHendricks/youtube)](https://smithery.ai/server/@ZubeidHendricks/youtube)\n\nA Model Context Protocol (MCP) server implementation for YouTube, enabling AI language models to interact with YouTube content through a standardized interface.\n\n## Features\n\n### Video Information\n* Get video details (title, description, duration, etc.)\n* List channel videos\n* Get video statistics (views, likes, comments)\n* Search videos across YouTube\n\n### Transcript Management\n* Retrieve video transcripts\n* Support for multiple languages\n* Get timestamped captions\n* Search within transcripts\n\n### Channel Management\n* Get channel details\n* List channel playlists\n* Get channel statistics\n* Search within channel content\n\n### Playlist Management\n* List playlist items\n* Get playlist details\n* Search within playlists\n* Get playlist video transcripts\n\n## Installation\n\n### Quick Setup for Claude Desktop\n\n1. Install the package:\n```bash\nnpm install -g zubeid-youtube-mcp-server\n```\n\n2. Add to your Claude Desktop configuration (`~/Library/Application Support/Claude/claude_desktop_config.json` on macOS or `%APPDATA%\\Claude\\claude_desktop_config.json` on Windows):\n\n```json\n{\n  \"mcpServers\": {\n    \"zubeid-youtube-mcp-server\": {\n      \"command\": \"zubeid-youtube-mcp-server\",\n      \"env\": {\n        \"YOUTUBE_API_KEY\": \"your_youtube_api_key_here\"\n      }\n    }\n  }\n}\n```\n\n### Alternative: Using NPX (No Installation Required)\n\nAdd this to your Claude Desktop configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"youtube\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"zubeid-youtube-mcp-server\"],\n      \"env\": {\n        \"YOUTUBE_API_KEY\": \"your_youtube_api_key_here\"\n      }\n    }\n  }\n}\n```\n\n### Installing via Smithery\n\nTo install YouTube MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@ZubeidHendricks/youtube):\n\n```bash\nnpx -y @smithery/cli install @ZubeidHendricks/youtube --client claude\n```\n\n## Configuration\nSet the following environment variables:\n* `YOUTUBE_API_KEY`: Your YouTube Data API key (required)\n* `YOUTUBE_TRANSCRIPT_LANG`: Default language for transcripts (optional, defaults to 'en')\n### Using with VS Code\n\nFor one-click installation, click one of the install buttons below:\n\n[![Install with NPX in VS Code](https://img.shields.io/badge/VS_Code-NPM-0098FF?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=youtube&config=%7B%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22zubeid-youtube-mcp-server%22%5D%2C%22env%22%3A%7B%22YOUTUBE_API_KEY%22%3A%22%24%7Binput%3AapiKey%7D%22%7D%7D&inputs=%5B%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22apiKey%22%2C%22description%22%3A%22YouTube+API+Key%22%2C%22password%22%3Atrue%7D%5D) [![Install with NPX in VS Code Insiders](https://img.shields.io/badge/VS_Code_Insiders-NPM-24bfa5?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=youtube&config=%7B%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22zubeid-youtube-mcp-server%22%5D%2C%22env%22%3A%7B%22YOUTUBE_API_KEY%22%3A%22%24%7Binput%3AapiKey%7D%22%7D%7D&inputs=%5B%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22apiKey%22%2C%22description%22%3A%22YouTube+API+Key%22%2C%22password%22%3Atrue%7D%5D&quality=insiders)\n\n### Manual Installation\n\nIf you prefer manual installation, first check the install buttons at the top of this section. Otherwise, follow these steps:\n\nAdd the following JSON block to your User Settings (JSON) file in VS Code. You can do this by pressing `Ctrl + Shift + P` and typing `Preferences: Open User Settings (JSON)`.\n\n```json\n{\n  \"mcp\": {\n    \"inputs\": [\n      {\n        \"type\": \"promptString\",\n        \"id\": \"apiKey\",\n        \"description\": \"YouTube API Key\",\n        \"password\": true\n      }\n    ],\n    \"servers\": {\n      \"youtube\": {\n        \"command\": \"npx\",\n        \"args\": [\"-y\", \"zubeid-youtube-mcp-server\"],\n        \"env\": {\n          \"YOUTUBE_API_KEY\": \"${input:apiKey}\"\n        }\n      }\n    }\n  }\n}\n```\n\nOptionally, you can add it to a file called `.vscode/mcp.json` in your workspace:\n\n```json\n{\n  \"inputs\": [\n    {\n      \"type\": \"promptString\",\n      \"id\": \"apiKey\",\n      \"description\": \"YouTube API Key\",\n      \"password\": true\n    }\n  ],\n  \"servers\": {\n    \"youtube\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"zubeid-youtube-mcp-server\"],\n      \"env\": {\n        \"YOUTUBE_API_KEY\": \"${input:apiKey}\"\n      }\n    }\n  }\n}\n```\n## YouTube API Setup\n1. Go to Google Cloud Console\n2. Create a new project or select an existing one\n3. Enable the YouTube Data API v3\n4. Create API credentials (API key)\n5. Copy the API key for configuration\n\n## Examples\n\n### Managing Videos\n\n```javascript\n// Get video details\nconst video = await youtube.videos.getVideo({\n  videoId: \"video-id\"\n});\n\n// Get video transcript\nconst transcript = await youtube.transcripts.getTranscript({\n  videoId: \"video-id\",\n  language: \"en\"\n});\n\n// Search videos\nconst searchResults = await youtube.videos.searchVideos({\n  query: \"search term\",\n  maxResults: 10\n});\n```\n\n### Managing Channels\n\n```javascript\n// Get channel details\nconst channel = await youtube.channels.getChannel({\n  channelId: \"channel-id\"\n});\n\n// List channel videos\nconst videos = await youtube.channels.listVideos({\n  channelId: \"channel-id\",\n  maxResults: 50\n});\n```\n\n### Managing Playlists\n\n```javascript\n// Get playlist items\nconst playlistItems = await youtube.playlists.getPlaylistItems({\n  playlistId: \"playlist-id\",\n  maxResults: 50\n});\n\n// Get playlist details\nconst playlist = await youtube.playlists.getPlaylist({\n  playlistId: \"playlist-id\"\n});\n```\n\n## Development\n\n```bash\n# Install dependencies\nnpm install\n\n# Run tests\nnpm test\n\n# Build\nnpm run build\n\n# Lint\nnpm run lint\n```\n\n## Contributing\nSee CONTRIBUTING.md for information about contributing to this repository.\n\n## License\nThis project is licensed under the MIT License - see the LICENSE file for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "youtube",
        "mcp",
        "processing",
        "youtube mcp",
        "zubeidhendricks youtube",
        "interacts youtube"
      ],
      "category": "document-processing"
    },
    "a-bonus--google-docs-mcp": {
      "owner": "a-bonus",
      "name": "google-docs-mcp",
      "url": "https://github.com/a-bonus/google-docs-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/a-bonus.webp",
      "description": "Connect to Google Docs for reading and appending text to documents programmatically, enabling automated workflows and document interaction through AI assistants.",
      "stars": 115,
      "forks": 26,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-02T22:04:45Z",
      "readme_content": "# Ultimate Google Docs & Drive MCP Server\n\n\n\nConnect Claude Desktop (or other MCP clients) to your Google Docs and Google Drive!\n\n> 🔥 **Check out [15 powerful tasks](SAMPLE_TASKS.md) you can accomplish with this enhanced server!**\n> 📁 **NEW:** Complete Google Drive file management capabilities!\n\nThis comprehensive server uses the Model Context Protocol (MCP) and the `fastmcp` library to provide tools for reading, writing, formatting, structuring Google Documents, and managing your entire Google Drive. It acts as a powerful bridge, allowing AI assistants like Claude to interact with your documents and files programmatically with advanced capabilities.\n\n**Features:**\n\n### Document Access & Editing\n- **Read Documents:** Read content with `readGoogleDoc` (plain text, JSON structure, or markdown)\n- **Append to Documents:** Add text to documents with `appendToGoogleDoc`\n- **Insert Text:** Place text at specific positions with `insertText`\n- **Delete Content:** Remove content from a document with `deleteRange`\n\n### Formatting & Styling\n- **Text Formatting:** Apply rich styling with `applyTextStyle` (bold, italic, colors, etc.)\n- **Paragraph Formatting:** Control paragraph layout with `applyParagraphStyle` (alignment, spacing, etc.)\n- **Find & Format:** Format by text content using `formatMatchingText` (legacy support)\n\n### Document Structure\n- **Tables:** Create tables with `insertTable`\n- **Page Breaks:** Insert page breaks with `insertPageBreak`\n- **Experimental Features:** Tools like `fixListFormatting` for automatic list detection\n\n### 🆕 Comment Management\n- **List Comments:** View all comments in a document with `listComments` (shows author, date, and quoted text)\n- **Get Comment Details:** Get specific comment with replies using `getComment`\n- **Add Comments:** Create new comments anchored to text with `addComment`\n- **Reply to Comments:** Add replies to existing comments with `replyToComment`\n- **Resolve Comments:** Mark comments as resolved with `resolveComment`\n- **Delete Comments:** Remove comments from documents with `deleteComment`\n\n### 🆕 Google Drive File Management\n- **Document Discovery:** Find and list documents with `listGoogleDocs`, `searchGoogleDocs`, `getRecentGoogleDocs`\n- **Document Information:** Get detailed metadata with `getDocumentInfo`\n- **Folder Management:** Create folders (`createFolder`), list contents (`listFolderContents`), get info (`getFolderInfo`)\n- **File Operations:** Move (`moveFile`), copy (`copyFile`), rename (`renameFile`), delete (`deleteFile`)\n- **Document Creation:** Create new docs (`createDocument`) or from templates (`createFromTemplate`)\n\n### Integration\n- **Google Authentication:** Secure OAuth 2.0 authentication with full Drive access\n- **MCP Compliant:** Designed for use with Claude and other MCP clients\n- **VS Code Integration:** [Setup guide](vscode.md) for VS Code MCP extension\n\n---\n\n## Prerequisites\n\nBefore you start, make sure you have:\n\n1.  **Node.js and npm:** A recent version of Node.js (which includes npm) installed on your computer. You can download it from [nodejs.org](https://nodejs.org/). (Version 18 or higher recommended).\n2.  **Git:** Required for cloning this repository. ([Download Git](https://git-scm.com/downloads)).\n3.  **A Google Account:** The account that owns or has access to the Google Docs you want to interact with.\n4.  **Command Line Familiarity:** Basic comfort using a terminal or command prompt (like Terminal on macOS/Linux, or Command Prompt/PowerShell on Windows).\n5.  **Claude Desktop (Optional):** If your goal is to connect this server to Claude, you'll need the Claude Desktop application installed.\n\n---\n\n## Setup Instructions\n\nFollow these steps carefully to get your own instance of the server running.\n\n### Step 1: Google Cloud Project & Credentials (The Important Bit!)\n\nThis server needs permission to talk to Google APIs on your behalf. You'll create special \"keys\" (credentials) that only your server will use.\n\n1.  **Go to Google Cloud Console:** Open your web browser and go to the [Google Cloud Console](https://console.cloud.google.com/). You might need to log in with your Google Account.\n2.  **Create or Select a Project:**\n    - If you don't have a project, click the project dropdown near the top and select \"NEW PROJECT\". Give it a name (e.g., \"My MCP Docs Server\") and click \"CREATE\".\n    - If you have existing projects, you can select one or create a new one.\n3.  **Enable APIs:** You need to turn on the specific Google services this server uses.\n    - In the search bar at the top, type \"APIs & Services\" and select \"Library\".\n    - Search for \"**Google Docs API**\" and click on it. Then click the \"**ENABLE**\" button.\n    - Search for \"**Google Drive API**\" and click on it. Then click the \"**ENABLE**\" button (this is often needed for finding files or permissions).\n4.  **Configure OAuth Consent Screen:** This screen tells users (usually just you) what your app wants permission for.\n    - On the left menu, click \"APIs & Services\" -> \"**OAuth consent screen**\".\n    - Choose User Type: Select \"**External**\" and click \"CREATE\".\n    - Fill in App Information:\n      - **App name:** Give it a name users will see (e.g., \"Claude Docs MCP Access\").\n      - **User support email:** Select your email address.\n      - **Developer contact information:** Enter your email address.\n    - Click \"**SAVE AND CONTINUE**\".\n    - **Scopes:** Click \"**ADD OR REMOVE SCOPES**\". Search for and add the following scopes:\n      - `https://www.googleapis.com/auth/documents` (Allows reading/writing docs)\n      - `https://www.googleapis.com/auth/drive.file` (Allows access to specific files opened/created by the app)\n      - Click \"**UPDATE**\".\n    - Click \"**SAVE AND CONTINUE**\".\n    - **Test Users:** Click \"**ADD USERS**\". Enter the same Google email address you are logged in with. Click \"**ADD**\". This allows _you_ to use the app while it's in \"testing\" mode.\n    - Click \"**SAVE AND CONTINUE**\". Review the summary and click \"**BACK TO DASHBOARD**\".\n5.  **Create Credentials (The Keys!):**\n    - On the left menu, click \"APIs & Services\" -> \"**Credentials**\".\n    - Click \"**+ CREATE CREDENTIALS**\" at the top and choose \"**OAuth client ID**\".\n    - **Application type:** Select \"**Desktop app**\" from the dropdown.\n    - **Name:** Give it a name (e.g., \"MCP Docs Desktop Client\").\n    - Click \"**CREATE**\".\n6.  **⬇️ DOWNLOAD THE CREDENTIALS FILE:** A box will pop up showing your Client ID. Click the \"**DOWNLOAD JSON**\" button.\n    - Save this file. It will likely be named something like `client_secret_....json`.\n    - **IMPORTANT:** Rename the downloaded file to exactly `credentials.json`.\n7.  ⚠️ **SECURITY WARNING:** Treat this `credentials.json` file like a password! Do not share it publicly, and **never commit it to GitHub.** Anyone with this file could potentially pretend to be _your application_ (though they'd still need user consent to access data).\n\n### Step 2: Get the Server Code\n\n1.  **Clone the Repository:** Open your terminal/command prompt and run:\n    ```bash\n    git clone https://github.com/a-bonus/google-docs-mcp.git mcp-googledocs-server\n    ```\n2.  **Navigate into Directory:**\n    ```bash\n    cd mcp-googledocs-server\n    ```\n3.  **Place Credentials:** Move or copy the `credentials.json` file you downloaded and renamed (from Step 1.6) directly into this `mcp-googledocs-server` folder.\n\n### Step 3: Install Dependencies\n\nYour server needs some helper libraries specified in the `package.json` file.\n\n1.  In your terminal (make sure you are inside the `mcp-googledocs-server` directory), run:\n    ```bash\n    npm install\n    ```\n    This will download and install all the necessary packages into a `node_modules` folder.\n\n### Step 4: Build the Server Code\n\nThe server is written in TypeScript (`.ts`), but we need to compile it into JavaScript (`.js`) that Node.js can run directly.\n\n1.  In your terminal, run:\n    ```bash\n    npm run build\n    ```\n    This uses the TypeScript compiler (`tsc`) to create a `dist` folder containing the compiled JavaScript files.\n\n### Step 5: First Run & Google Authorization (One Time Only)\n\nNow you need to run the server once manually to grant it permission to access your Google account data. This will create a `token.json` file that saves your permission grant.\n\n1.  In your terminal, run the _compiled_ server using `node`:\n    ```bash\n    node ./dist/server.js\n    ```\n2.  **Watch the Terminal:** The script will print:\n    - Status messages (like \"Attempting to authorize...\").\n    - An \"Authorize this app by visiting this url:\" message followed by a long `https://accounts.google.com/...` URL.\n3.  **Authorize in Browser:**\n    - Copy the entire long URL from the terminal.\n    - Paste the URL into your web browser and press Enter.\n    - Log in with the **same Google account** you added as a Test User in Step 1.4.\n    - Google will show a screen asking for permission for your app (\"Claude Docs MCP Access\" or similar) to access Google Docs/Drive. Review and click \"**Allow**\" or \"**Grant**\".\n4.  **Get the Authorization Code:**\n    - After clicking Allow, your browser will likely try to redirect to `http://localhost` and show a **\"This site can't be reached\" error**. **THIS IS NORMAL!**\n    - Look **carefully** at the URL in your browser's address bar. It will look like `http://localhost/?code=4/0Axxxxxxxxxxxxxx&scope=...`\n    - Copy the long string of characters **between `code=` and the `&scope` part**. This is your single-use authorization code.\n5.  **Paste Code into Terminal:** Go back to your terminal where the script is waiting (\"Enter the code from that page here:\"). Paste the code you just copied.\n6.  **Press Enter.**\n7.  **Success!** The script should print:\n    - \"Authentication successful!\"\n    - \"Token stored to .../token.json\"\n    - It will then finish starting and likely print \"Awaiting MCP client connection via stdio...\" or similar, and then exit (or you can press `Ctrl+C` to stop it).\n8.  ✅ **Check:** You should now see a new file named `token.json` in your `mcp-googledocs-server` folder.\n9.  ⚠️ **SECURITY WARNING:** This `token.json` file contains the key that allows the server to access your Google account _without_ asking again. Protect it like a password. **Do not commit it to GitHub.** The included `.gitignore` file should prevent this automatically.\n\n### Step 6: Configure Claude Desktop (Optional)\n\nIf you want to use this server with Claude Desktop, you need to tell Claude how to run it.\n\n1.  **Find Your Absolute Path:** You need the full path to the server code.\n    - In your terminal, make sure you are still inside the `mcp-googledocs-server` directory.\n    - Run the `pwd` command (on macOS/Linux) or `cd` (on Windows, just displays the path).\n    - Copy the full path (e.g., `/Users/yourname/projects/mcp-googledocs-server` or `C:\\Users\\yourname\\projects\\mcp-googledocs-server`).\n2.  **Locate `mcp_config.json`:** Find Claude's configuration file:\n    - **macOS:** `~/Library/Application Support/Claude/mcp_config.json` (You might need to use Finder's \"Go\" -> \"Go to Folder...\" menu and paste `~/Library/Application Support/Claude/`)\n    - **Windows:** `%APPDATA%\\Claude\\mcp_config.json` (Paste `%APPDATA%\\Claude` into File Explorer's address bar)\n    - **Linux:** `~/.config/Claude/mcp_config.json`\n    - _If the `Claude` folder or `mcp_config.json` file doesn't exist, create them._\n3.  **Edit `mcp_config.json`:** Open the file in a text editor. Add or modify the `mcpServers` section like this, **replacing `/PATH/TO/YOUR/CLONED/REPO` with the actual absolute path you copied in Step 6.1**:\n\n    ```json\n    {\n      \"mcpServers\": {\n        \"google-docs-mcp\": {\n          \"command\": \"node\",\n          \"args\": [\n            \"/PATH/TO/YOUR/CLONED/REPO/mcp-googledocs-server/dist/server.js\"\n          ],\n          \"env\": {}\n        }\n        // Add commas here if you have other servers defined\n      }\n      // Other Claude settings might be here\n    }\n    ```\n\n    - **Make sure the path in `\"args\"` is correct and absolute!**\n    - If the file already existed, carefully merge this entry into the existing `mcpServers` object. Ensure the JSON is valid (check commas!).\n\n4.  **Save `mcp_config.json`.**\n5.  **Restart Claude Desktop:** Close Claude completely and reopen it.\n\n---\n\n## Usage with Claude Desktop\n\nOnce configured, you should be able to use the tools in your chats with Claude:\n\n- \"Use the `google-docs-mcp` server to read the document with ID `YOUR_GOOGLE_DOC_ID`.\"\n- \"Can you get the content of Google Doc `YOUR_GOOGLE_DOC_ID`?\"\n- \"Append 'This was added by Claude!' to document `YOUR_GOOGLE_DOC_ID` using the `google-docs-mcp` tool.\"\n\n### Advanced Usage Examples:\n- **Text Styling**: \"Use `applyTextStyle` to make the text 'Important Section' bold and red (#FF0000) in document `YOUR_GOOGLE_DOC_ID`.\"\n- **Paragraph Styling**: \"Use `applyParagraphStyle` to center-align the paragraph containing 'Title Here' in document `YOUR_GOOGLE_DOC_ID`.\"\n- **Table Creation**: \"Insert a 3x4 table at index 500 in document `YOUR_GOOGLE_DOC_ID` using the `insertTable` tool.\"\n- **Legacy Formatting**: \"Use `formatMatchingText` to find the second instance of 'Project Alpha' and make it blue (#0000FF) in doc `YOUR_GOOGLE_DOC_ID`.\"\n\nRemember to replace `YOUR_GOOGLE_DOC_ID` with the actual ID from a Google Doc's URL (the long string between `/d/` and `/edit`).\n\nClaude will automatically launch your server in the background when needed using the command you provided. You do **not** need to run `node ./dist/server.js` manually anymore.\n\n---\n\n## Security & Token Storage\n\n- **`.gitignore`:** This repository includes a `.gitignore` file which should prevent you from accidentally committing your sensitive `credentials.json` and `token.json` files. **Do not remove these lines from `.gitignore`**.\n- **Token Storage:** This server stores the Google authorization token (`token.json`) directly in the project folder for simplicity during setup. In production or more security-sensitive environments, consider storing this token more securely, such as using system keychains, encrypted files, or dedicated secret management services.\n\n---\n\n## Troubleshooting\n\n- **Claude shows \"Failed\" or \"Could not attach\":**\n  - Double-check the absolute path in `mcp_config.json`.\n  - Ensure you ran `npm run build` successfully and the `dist` folder exists.\n  - Try running the command from `mcp_config.json` manually in your terminal: `node /PATH/TO/YOUR/CLONED/REPO/mcp-googledocs-server/dist/server.js`. Look for any errors printed.\n  - Check the Claude Desktop logs (see the official MCP debugging guide).\n  - Make sure all `console.log` status messages in the server code were changed to `console.error`.\n- **Google Authorization Errors:**\n  - Ensure you enabled the correct APIs (Docs, Drive).\n  - Make sure you added your email as a Test User on the OAuth Consent Screen.\n  - Verify the `credentials.json` file is correctly placed in the project root.\n\n---\n\n## License\n\nThis project is licensed under the MIT License - see the `LICENSE` file for details. (Note: You should add a `LICENSE` file containing the MIT License text to your repository).",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "document",
        "documents",
        "docs",
        "document processing",
        "google docs",
        "document interaction"
      ],
      "category": "document-processing"
    },
    "aashari--mcp-server-atlassian-confluence": {
      "owner": "aashari",
      "name": "mcp-server-atlassian-confluence",
      "url": "https://github.com/aashari/mcp-server-atlassian-confluence",
      "imageUrl": "/freedevtools/mcp/pfp/aashari.webp",
      "description": "Connects AI systems to Atlassian Confluence, providing real-time access to organizational knowledge bases. Enables retrieval, searching, and management of Confluence content seamlessly within AI applications.",
      "stars": 33,
      "forks": 16,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T04:36:04Z",
      "readme_content": "# Connect AI to Your Confluence Knowledge Base\n\nTransform how you access and interact with your team's knowledge by connecting Claude, Cursor AI, and other AI assistants directly to your Confluence spaces, pages, and documentation. Get instant answers from your knowledge base, search across all your spaces, and streamline your documentation workflow.\n\n[![NPM Version](https://img.shields.io/npm/v/@aashari/mcp-server-atlassian-confluence)](https://www.npmjs.com/package/@aashari/mcp-server-atlassian-confluence)\n\n## What You Can Do\n\n✅ **Ask AI about your documentation**: *\"What's our API authentication process?\"*  \n✅ **Search across all spaces**: *\"Find all pages about security best practices\"*  \n✅ **Get instant answers**: *\"Show me the latest release notes from the Product space\"*  \n✅ **Access team knowledge**: *\"What are our HR policies for remote work?\"*  \n✅ **Review page comments**: *\"Show me the discussion on the architecture document\"*  \n✅ **Find specific content**: *\"Search for pages with 'onboarding' in the title\"*  \n\n## Perfect For\n\n- **Developers** who need quick access to technical documentation and API guides\n- **Product Managers** searching for requirements, specs, and project updates\n- **HR Teams** accessing policy documents and employee resources quickly  \n- **Support Teams** finding troubleshooting guides and knowledge base articles\n- **Anyone** who wants to interact with Confluence using natural language\n\n## Quick Start\n\nGet up and running in 2 minutes:\n\n### 1. Get Your Confluence Credentials\n\nGenerate a Confluence API Token:\n1. Go to [Atlassian API Tokens](https://id.atlassian.com/manage-profile/security/api-tokens)\n2. Click **Create API token**\n3. Give it a name like **\"AI Assistant\"**\n4. **Copy the generated token** immediately (you won't see it again!)\n\n### 2. Try It Instantly\n\n```bash\n# Set your credentials\nexport ATLASSIAN_SITE_NAME=\"your-company\"  # for your-company.atlassian.net\nexport ATLASSIAN_USER_EMAIL=\"your.email@company.com\"\nexport ATLASSIAN_API_TOKEN=\"your_copied_token\"\n\n# List your Confluence spaces\nnpx -y @aashari/mcp-server-atlassian-confluence ls-spaces\n\n# Get details about a specific space\nnpx -y @aashari/mcp-server-atlassian-confluence get-space --space-key DEV\n\n# Search for pages\nnpx -y @aashari/mcp-server-atlassian-confluence search --query \"API documentation\"\n```\n\n## Connect to AI Assistants\n\n### For Claude Desktop Users\n\nAdd this to your Claude configuration file (`~/.claude/claude_desktop_config.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"confluence\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@aashari/mcp-server-atlassian-confluence\"],\n      \"env\": {\n        \"ATLASSIAN_SITE_NAME\": \"your-company\",\n        \"ATLASSIAN_USER_EMAIL\": \"your.email@company.com\",\n        \"ATLASSIAN_API_TOKEN\": \"your_api_token\"\n      }\n    }\n  }\n}\n```\n\nRestart Claude Desktop, and you'll see \"🔗 confluence\" in the status bar.\n\n### For Other AI Assistants\n\nMost AI assistants support MCP. Install the server globally:\n\n```bash\nnpm install -g @aashari/mcp-server-atlassian-confluence\n```\n\nThen configure your AI assistant to use the MCP server with STDIO transport.\n\n### Alternative: Configuration File\n\nCreate `~/.mcp/configs.json` for system-wide configuration:\n\n```json\n{\n  \"confluence\": {\n    \"environments\": {\n      \"ATLASSIAN_SITE_NAME\": \"your-company\",\n      \"ATLASSIAN_USER_EMAIL\": \"your.email@company.com\", \n      \"ATLASSIAN_API_TOKEN\": \"your_api_token\"\n    }\n  }\n}\n```\n\n**Alternative config keys:** The system also accepts `\"atlassian-confluence\"`, `\"@aashari/mcp-server-atlassian-confluence\"`, or `\"mcp-server-atlassian-confluence\"` instead of `\"confluence\"`.\n\n## Real-World Examples\n\n### 📚 Explore Your Knowledge Base\n\nAsk your AI assistant:\n- *\"List all the spaces in our Confluence\"*\n- *\"Show me details about the Engineering space\"*  \n- *\"What pages are in our Product space?\"*\n- *\"Find the latest pages in the Marketing space\"*\n\n### 🔍 Search and Find Information\n\nAsk your AI assistant:\n- *\"Search for pages about API authentication\"*\n- *\"Find all documentation with 'security' in the title\"*\n- *\"Show me pages labeled with 'getting-started'\"*\n- *\"Search for content in the DEV space about deployment\"*\n\n### 📄 Access Specific Content\n\nAsk your AI assistant:\n- *\"Get the content of the API Authentication Guide page\"*\n- *\"Show me the onboarding checklist document\"*\n- *\"What's in our security policies page?\"*\n- *\"Display the latest release notes\"*\n\n### 💬 Review Discussions\n\nAsk your AI assistant:\n- *\"Show me comments on the architecture design document\"*\n- *\"What feedback was left on the new feature proposal?\"*\n- *\"Display discussion on the API changes page\"*\n\n### 🎯 Advanced Searches\n\nAsk your AI assistant:\n- *\"Find all pages created by John in the last month\"*\n- *\"Show me archived pages in the Product space\"*\n- *\"Search for pages with both 'API' and 'tutorial' labels\"*\n- *\"Find documentation updated in the last week\"*\n\n## Troubleshooting\n\n### \"Authentication failed\" or \"403 Forbidden\"\n\n1. **Check your API Token permissions**:\n   - Go to [Atlassian API Tokens](https://id.atlassian.com/manage-profile/security/api-tokens)\n   - Make sure your token is still active and has the right permissions\n\n2. **Verify your site name**:\n   ```bash\n   # Test your credentials work\n   npx -y @aashari/mcp-server-atlassian-confluence ls-spaces\n   ```\n\n3. **Check your site name format**:\n   - If your Confluence URL is `https://mycompany.atlassian.net`\n   - Your site name should be just `mycompany`\n\n### \"Space not found\" or \"Page not found\"\n\n1. **Check space key spelling**:\n   ```bash\n   # List your spaces to see the correct keys\n   npx -y @aashari/mcp-server-atlassian-confluence ls-spaces\n   ```\n\n2. **Verify access permissions**:\n   - Make sure you have access to the space in your browser\n   - Some spaces may be restricted to certain users\n\n### \"No results found\" when searching\n\n1. **Try broader search terms**:\n   - Use single keywords instead of full phrases\n   - Try different variations of your search terms\n\n2. **Check space permissions**:\n   - You can only search content you have permission to view\n   - Ask your admin if you should have access to specific spaces\n\n### Claude Desktop Integration Issues\n\n1. **Restart Claude Desktop** after updating the config file\n2. **Check the status bar** for the \"🔗 confluence\" indicator\n3. **Verify config file location**:\n   - macOS: `~/.claude/claude_desktop_config.json`\n   - Windows: `%APPDATA%\\\\Claude\\\\claude_desktop_config.json`\n\n### Getting Help\n\nIf you're still having issues:\n1. Run a simple test command to verify everything works\n2. Check the [GitHub Issues](https://github.com/aashari/mcp-server-atlassian-confluence/issues) for similar problems\n3. Create a new issue with your error message and setup details\n\n## Frequently Asked Questions\n\n### What permissions do I need?\n\nYour Atlassian account needs:\n- **Read access** to the Confluence spaces you want to search\n- **API token** with appropriate permissions (automatically granted when you create one)\n\n### Can I use this with Confluence Server (on-premise)?\n\nCurrently, this tool only supports **Confluence Cloud**. Confluence Server support may be added in future versions.\n\n### How do I find my site name?\n\nYour site name is the first part of your Confluence URL:\n- URL: `https://mycompany.atlassian.net` → Site name: `mycompany`\n- URL: `https://acme-corp.atlassian.net` → Site name: `acme-corp`\n\n### What AI assistants does this work with?\n\nAny AI assistant that supports the Model Context Protocol (MCP):\n- Claude Desktop (most popular)\n- Cursor AI\n- Continue.dev\n- Many others\n\n### Is my data secure?\n\nYes! This tool:\n- Runs entirely on your local machine\n- Uses your own Confluence credentials\n- Never sends your data to third parties\n- Only accesses what you give it permission to access\n\n### Can I search across all my spaces at once?\n\nYes! When you don't specify a space, searches will look across all spaces you have access to.\n\n## Support\n\nNeed help? Here's how to get assistance:\n\n1. **Check the troubleshooting section above** - most common issues are covered there\n2. **Visit our GitHub repository** for documentation and examples: [github.com/aashari/mcp-server-atlassian-confluence](https://github.com/aashari/mcp-server-atlassian-confluence)\n3. **Report issues** at [GitHub Issues](https://github.com/aashari/mcp-server-atlassian-confluence/issues)\n4. **Start a discussion** for feature requests or general questions\n\n---\n\n*Made with ❤️ for teams who want to bring AI into their knowledge management workflow.*\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "confluence",
        "atlassian",
        "ai",
        "atlassian confluence",
        "confluence providing",
        "confluence content"
      ],
      "category": "document-processing"
    },
    "adamanz--mcp-video-converter": {
      "owner": "adamanz",
      "name": "mcp-video-converter",
      "url": "https://github.com/adamanz/mcp-video-converter",
      "imageUrl": "/freedevtools/mcp/pfp/adamanz.webp",
      "description": "Convert video, audio, and image files between various formats using FFmpeg. Check for FFmpeg installation and retrieve information on supported file formats for conversion.",
      "stars": 0,
      "forks": 3,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-05-11T14:54:58Z",
      "readme_content": "# MCP Video Converter Server\n\nAn MCP server that provides tools for checking FFmpeg installation and converting video files between various formats.\n\n## Features\n\n- **Check FFmpeg**: Verifies if FFmpeg is installed and accessible.\n- **Convert Video**: Converts video, audio, and image files to various formats (e.g., MP4, WebM, MOV, MP3, PNG).\n- **Format Info**: Get a list of supported file formats for conversion.\n\n## Prerequisites\n\n- Python 3.10+\n- FFmpeg installed and available in your system's PATH\n- [Optional] [uv](https://github.com/astral-sh/uv) for environment management\n\n## Setup\n\n1. Clone this repository:\n   ```bash\n   git clone https://github.com/adamanz/mcp-video-converter.git\n   cd mcp-video-converter\n   ```\n\n2. Create and activate a virtual environment:\n   ```bash\n   # Using venv (standard library)\n   python -m venv .venv\n   source .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n   \n   # Or using uv (recommended if available)\n   uv venv\n   source .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n   ```\n\n3. Install dependencies:\n   ```bash\n   # Using pip\n   pip install -e .\n   pip install fastmcp\n\n   # Or using uv\n   uv pip install -e .\n   uv pip install fastmcp\n   ```\n\n4. Verify your installation:\n   ```bash\n   # Run the installation check script\n   python check_installation.py\n   ```\n\n## Running the Server Directly\n\nYou can run the server directly:\n\n```bash\n# Activate the virtual environment if not already activated\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n\n# Run the server\npython -m mcp_video_converter.server\n```\n\n## Integrating with Claude Desktop\n\nTo add this MCP server to Claude Desktop:\n\n1. Locate or create the Claude Desktop configuration file:\n   ```bash\n   # macOS\n   mkdir -p ~/Library/Application\\ Support/Claude/\n   nano ~/Library/Application\\ Support/Claude/claude_desktop_config.json\n   \n   # Windows\n   mkdir -p %APPDATA%\\Claude\\\n   notepad %APPDATA%\\Claude\\claude_desktop_config.json\n   ```\n\n2. Add the MCP server configuration:\n   ```json\n   {\n     \"mcpServers\": {\n       \"video-convert\": {\n         \"command\": \"/bin/bash\",\n         \"args\": [\n           \"-c\",\n           \"cd /absolute/path/to/mcp-video-converter && source .venv/bin/activate && python -m mcp_video_converter.server\"\n         ]\n       }\n     }\n   }\n   ```\n\n   **Windows Alternative:**\n   ```json\n   {\n     \"mcpServers\": {\n       \"video-convert\": {\n         \"command\": \"cmd.exe\",\n         \"args\": [\n           \"/c\",\n           \"cd /d C:\\\\absolute\\\\path\\\\to\\\\mcp-video-converter && .venv\\\\Scripts\\\\activate && python -m mcp_video_converter.server\"\n         ]\n       }\n     }\n   }\n   ```\n\n   Replace `/absolute/path/to/mcp-video-converter` with the absolute path to your repository.\n\n3. Restart Claude Desktop\n   - The server will appear as \"video-convert\" in the MCP tools menu\n\n4. Important notes:\n   - Always use absolute paths in your configuration\n   - Make sure FFmpeg is installed and in your PATH\n   - If you encounter issues, check the Claude Desktop logs:\n     ```bash\n     # macOS\n     tail -n 20 -F ~/Library/Logs/Claude/mcp*.log\n     \n     # Windows\n     type %APPDATA%\\Claude\\logs\\mcp*.log\n     ```\n\n## Integrating with Cursor\n\nTo add this MCP server to Cursor:\n\n1. Locate or create the Cursor configuration file:\n   ```bash\n   # macOS\n   mkdir -p ~/.cursor/\n   nano ~/.cursor/config.json\n   \n   # Windows\n   mkdir -p %USERPROFILE%\\.cursor\\\n   notepad %USERPROFILE%\\.cursor\\config.json\n   ```\n\n2. Add the MCP server configuration:\n   ```json\n   {\n     \"ai\": {\n       \"mcpServers\": {\n         \"video-convert\": {\n           \"command\": \"/bin/bash\",\n           \"args\": [\n             \"-c\",\n             \"cd /absolute/path/to/mcp-video-converter && source .venv/bin/activate && python -m mcp_video_converter.server\"\n           ]\n         }\n       }\n     }\n   }\n   ```\n\n   **Windows Alternative:**\n   ```json\n   {\n     \"ai\": {\n       \"mcpServers\": {\n         \"video-convert\": {\n           \"command\": \"cmd.exe\",\n           \"args\": [\n             \"/c\",\n             \"cd /d C:\\\\absolute\\\\path\\\\to\\\\mcp-video-converter && .venv\\\\Scripts\\\\activate && python -m mcp_video_converter.server\"\n           ]\n         }\n       }\n     }\n   }\n   ```\n\n   Replace `/absolute/path/to/mcp-video-converter` with the absolute path to your repository.\n\n3. Restart Cursor\n   - The server will be available to Claude in Cursor\n\n4. Important notes:\n   - Always use absolute paths in your configuration\n   - Make sure FFmpeg is installed and in your PATH\n   - Logs may be accessed through Cursor's developer tools\n\n## Deploying with Smithery\n\nSmithery is a platform that simplifies deploying and managing MCP servers. This project is fully configured for Smithery deployment with the required files and configurations.\n\n### Required Configuration Files\n\nThis project includes all required configuration files for Smithery deployment:\n\n1. **smithery.yaml**: Defines how to start your server and its configuration options\n2. **Dockerfile**: Defines how to build your server's container image\n\n### Smithery YAML Configuration\n\nThe `smithery.yaml` file provides Smithery with instructions on how to run your server:\n\n```yaml\nstartCommand:\n  type: stdio\n  configSchema:\n    type: object\n    properties:\n      ffmpegPath:\n        type: string\n        title: \"FFmpeg Path\"\n        description: \"Optional path to FFmpeg executable (uses system PATH by default)\"\n      outputDirectory:\n        type: string\n        title: \"Output Directory\"\n        description: \"Optional custom directory for output files\"\n      quality:\n        type: string\n        enum: [\"low\", \"medium\", \"high\"]\n        default: \"medium\"\n        title: \"Default Quality\"\n  name: \"MCP Video Converter\"\n  description: \"Convert video files between formats and check FFmpeg installation\"\n  commandFunction: |\n    (config) => {\n      // Function that returns command details based on configuration options\n    }\n\nbuild:\n  dockerfile: Dockerfile\n  dockerBuildPath: .\n  env:\n    OUTPUT_DIRECTORY: \"/data/converted\"\n  buildOptions:\n    buildArgs:\n      PYTHON_VERSION: \"3.10\"\n      INSTALL_DEV: \"false\"\n    labels:\n      org.opencontainers.image.source: \"https://github.com/adamanz/mcp-video-converter\"\n      org.opencontainers.image.description: \"MCP Server for video conversion using FFmpeg\"\n      org.opencontainers.image.licenses: \"MIT\"\n```\n\nKey components:\n- **type: stdio**: Defines that our server uses the standard I/O transport\n- **configSchema**: Defines the configuration options users can set (FFmpeg path, output directory, quality)\n- **commandFunction**: JavaScript function that returns how to start the server based on configuration\n- **build**: Container-specific configuration for Dockerized deployment\n\n### Deploying to Smithery\n\n1. Install Smithery CLI if you haven't already:\n   ```bash\n   # Install the Smithery command-line tool\n   npm install -g @smithery/cli\n   ```\n\n2. Login to Smithery:\n   ```bash\n   smithery login\n   ```\n\n3. Deploy directly from the repository:\n   ```bash\n   # Navigate to the repository directory\n   cd /path/to/adamanz/mcp-video-converter\n   \n   # Deploy to Smithery\n   smithery deploy\n   ```\n\n   Alternatively, deploy with explicit build options:\n   ```bash\n   # Deploy with container build\n   smithery deploy --build\n   \n   # Deploy with custom build arguments\n   smithery deploy --build --build-arg PYTHON_VERSION=3.11\n   ```\n\n4. Configure and start the server in Smithery:\n   ```bash\n   # Configure the server (interactive)\n   smithery configure mcp-video-converter\n   \n   # Start the server\n   smithery start mcp-video-converter\n   ```\n\n### Docker Support\n\nThis project includes a multi-stage Dockerfile for efficient containerized deployment. The container:\n\n- Uses a multi-stage build process to reduce final image size\n- Installs FFmpeg and all required dependencies\n- Creates a dedicated volume mount point for converted files\n- Includes a healthcheck for better container monitoring\n\nYou can build and run the Docker container manually:\n\n```bash\n# Build the container\ndocker build -t mcp-video-converter .\n\n# Run the container\ndocker run -it --rm \\\n  -v $(pwd)/converted:/data/converted \\\n  -e FFMPEG_PATH=/usr/bin/ffmpeg \\\n  -e DEFAULT_QUALITY=high \\\n  mcp-video-converter\n```\n\n### Serverless Hosting Considerations\n\nWhen deploying to Smithery's serverless environment, be aware of the following:\n\n- **Connection Timeout**: Connections to your server will timeout after 2 minutes of inactivity\n- **Ephemeral Storage**: Design your server with ephemeral storage in mind\n- **Stateless Design**: The server should not rely on persistent local storage\n- **Output Files**: Video conversion outputs should be returned properly as part of the tool response to ensure clients can access them\n\n### Smithery Management\n\nUseful Smithery commands for managing your deployment:\n\n```bash\n# View server logs\nsmithery logs mcp-video-converter\n\n# Update to latest version\nsmithery update mcp-video-converter\n\n# Stop the server\nsmithery stop mcp-video-converter\n\n# Remove the server\nsmithery remove mcp-video-converter\n```\n\n### Integrating with Smithery Apps\n\nUsers can access your server through the Smithery app:\n\n1. Open the Smithery application\n2. Navigate to \"Servers\" tab\n3. Select \"mcp-video-converter\"\n4. Configure settings if prompted (FFmpeg path, output directory, quality)\n5. Connect to the server\n6. Use the server with compatible MCP clients\n\n### Testing Before Deployment\n\nBefore deploying to Smithery, it's recommended to test your server locally:\n\n```bash\n# Test with MCP Inspector (if available)\nmcp-inspector -s /path/to/mcp-video-converter/smithery.yaml\n\n# Or test by running the server directly\ncd /path/to/mcp-video-converter\npython -m mcp_video_converter.server\n```\n\n## Troubleshooting Common Issues\n\n### Server Not Found\n\nIf the MCP server is not being picked up:\n\n1. Verify the paths in your configuration file are absolute and correct\n2. Check that FFmpeg is installed and in your PATH\n3. Ensure the virtual environment is activated in your command\n4. Check the logs for specific error messages\n\n### Python Module Not Found\n\nIf you see errors about missing modules:\n\n1. Make sure you installed all dependencies with `pip install -e .` and `pip install fastmcp`\n2. Verify the virtual environment is being activated correctly\n3. Try reinstalling the package: `pip install -e .`\n\n### FFmpeg Not Found\n\nIf FFmpeg cannot be found:\n\n1. Verify FFmpeg is installed: `which ffmpeg` or `where ffmpeg` on Windows\n2. Add the FFmpeg directory to your PATH\n3. In the configuration, you can specify the full path to FFmpeg:\n   ```json\n   \"env\": {\n     \"PATH\": \"/usr/local/bin:/usr/bin:/bin:/path/to/ffmpeg/bin\"\n   }\n   ```\n\n## Example Usage (with Claude)\n\nOnce integrated, you can ask Claude to perform tasks like:\n\n1. \"Check if FFmpeg is installed on my system\"\n2. \"Convert this video file: /path/to/video.webm to MP4 format with high quality\"\n3. \"What video formats can I convert to?\"\n\nClaude will use the appropriate tools from the MCP server to accomplish these tasks.\n\n## Advanced: Using with fastmcp client\n\nFor programmatic usage, you can use the fastmcp client:\n\n```bash\n# Check FFmpeg installation\nfastmcp client call <SERVER_URL_OR_FILE_PATH> check_ffmpeg_installed '{}'\n\n# Get supported formats\nfastmcp client call <SERVER_URL_OR_FILE_PATH> get_supported_formats '{}'\n\n# Convert a video\nfastmcp client call <SERVER_URL_OR_FILE_PATH> convert_video '{\n  \"input_file_path\": \"/path/to/your/video.webm\", \n  \"output_format\": \"mp4\", \n  \"quality\": \"high\"\n}'\n```\n\nReplace `/path/to/your/video.webm` with an actual video file path.\n\n## Supported Formats\n\n- **Video**: MP4, WebM, MOV, AVI, MKV, FLV, GIF\n- **Audio**: MP3, WAV, OGG, AAC, M4A\n- **Image**: WebP, JPG, PNG, BMP, TIFF\n\n## Running Tests\n\n```bash\n# Using pip\npip install pytest\npytest\n\n# Using uv\nuv pip install pytest\nuv run pytest\n```\n\n## License\n\nThis project is open source and available under the [MIT License](mcp-video-converter/LICENSE).\n\n## Contributing\n\nContributions are welcome! Please see [CONTRIBUTING.md](mcp-video-converter/CONTRIBUTING.md) for details on how to contribute to this project.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ffmpeg",
        "converter",
        "formats",
        "convert video",
        "video converter",
        "formats conversion"
      ],
      "category": "document-processing"
    },
    "adexltd--mcp-google-suite": {
      "owner": "adexltd",
      "name": "mcp-google-suite",
      "url": "https://github.com/adexltd/mcp-google-suite",
      "imageUrl": "/freedevtools/mcp/pfp/adexltd.webp",
      "description": "Enable interaction with Google Workspace services such as Drive, Docs, and Sheets for operations including file searching, folder creation, document management, and spreadsheet manipulation. Flexible integration is supported through multiple transport modes compatible with MCP clients.",
      "stars": 3,
      "forks": 4,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-05-15T05:38:27Z",
      "readme_content": "# MCP Google Workspace Server\n\n[![CI](https://github.com/adexltd/mcp-google-suite/actions/workflows/ci.yml/badge.svg)](https://github.com/adexltd/mcp-google-suite/actions/workflows/ci.yml)\n[![codecov](https://codecov.io/gh/adexltd/mcp-google-suite/branch/main/graph/badge.svg)](https://codecov.io/gh/adexltd/mcp-google-suite)\n[![PyPI version](https://badge.fury.io/py/mcp-google-suite.svg)](https://badge.fury.io/py/mcp-google-suite)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n\nA Model Context Protocol (MCP) server enabling AI agents to interact with Google Workspace (Drive, Docs, and Sheets) services.\n\n## 🌟 Features\n\n- Google Drive: Search files, create folders\n- Google Docs: Create, read, update documents\n- Google Sheets: Create spreadsheets, read/write cell values\n- Multiple transport modes: stdio (default), SSE, WebSocket\n- MCP-compatible client support (Cursor, etc.)\n\n## 📋 Installation\n\n### Using uv (recommended)\n```bash\nuvx mcp-google-suite\n```\n\n### Using pip\n```bash\npip install mcp-google-suite\n```\n\n### Development setup\n```bash\n# Clone and install\ngit clone git@github.com:adexltd/mcp-google-suite.git && cd mcp-google-suite\nuv venv && source .venv/bin/activate  # or .venv\\Scripts\\activate on Windows\nuv pip install -e .\n```\n\n## 🔧 Configuration\n\n### Configure for MCP Clients\n\nAdd to your client settings (e.g. Cursor, Claude):\n\nUsing uvx (recommended):\n```json\n{\n  \"mcpServers\": {\n    \"mcp-google-suite\": {\n      \"command\": \"uvx\",\n      \"args\": [\"mcp-google-suite\"],\n      \"env\": {\n        \"GOOGLE_APPLICATION_CREDENTIALS\": \"~/.google/server-creds.json\",\n        \"GOOGLE_OAUTH_CREDENTIALS\": \"~/.google/oauth.keys.json\"\n      }\n    }\n  }\n}\n```\n\nUsing pip installation:\n```json\n{\n  \"mcpServers\": {\n    \"mcp-google-suite\": {\n      \"command\": \"python\",\n      \"args\": [\"-m\", \"mcp_google_suite\"],\n      \"env\": {\n        \"GOOGLE_APPLICATION_CREDENTIALS\": \"~/.google/server-creds.json\",\n        \"GOOGLE_OAUTH_CREDENTIALS\": \"~/.google/oauth.keys.json\"\n      }\n    }\n  }\n}\n```\n\n### Google OAuth Setup\n1. Visit [Google Cloud Console](https://console.cloud.google.com)\n2. Enable Drive, Docs, and Sheets APIs\n3. Create OAuth 2.0 credentials\n4. Save as `~/.google/oauth.keys.json`\n5. Run `mcp-google auth` to authenticate\n\n### Available Tools\n\n#### Drive Operations\n- `drive_search_files`: Search files in Google Drive\n  - `query` (string, required): Search query\n  - `page_size` (integer, optional): Number of results to return\n- `drive_create_folder`: Create a new folder\n  - `name` (string, required): Folder name\n  - `parent_id` (string, optional): Parent folder ID\n\n#### Docs Operations\n- `docs_create`: Create a new document\n  - `title` (string, required): Document title\n  - `content` (string, optional): Initial content\n- `docs_get_content`: Get document content\n  - `document_id` (string, required): Document ID\n- `docs_update_content`: Update document content\n  - `document_id` (string, required): Document ID\n  - `content` (string, required): New content\n\n#### Sheets Operations\n- `sheets_create`: Create a new spreadsheet\n  - `title` (string, required): Spreadsheet title\n  - `sheets` (array, optional): Sheet names\n- `sheets_get_values`: Get cell values\n  - `spreadsheet_id` (string, required): Spreadsheet ID\n  - `range` (string, required): A1 notation range\n- `sheets_update_values`: Update cell values\n  - `spreadsheet_id` (string, required): Spreadsheet ID\n  - `range` (string, required): A1 notation range\n  - `values` (array, required): 2D array of values\n\n## 🛠️ Development\n\n```bash\n# Install dev dependencies\nuv pip install -e \".[dev]\"\n\n# Setup pre-commit hooks\npre-commit install\n\n# Run tests\npytest\n\n# Format code\nblack . && ruff check --fix .\n```\n\n## 🔍 Debugging\n\nUse the MCP Inspector for interactive testing:\n\n```bash\n# Using uvx\nnpx @modelcontextprotocol/inspector uvx mcp-google\n\n# For development\ncd path/to/mcp-google-suite\nnpx @modelcontextprotocol/inspector uv run mcp-google\n```\n\n## 📚 Resources\n\n- [Documentation](https://github.com/adexltd/mcp-google-suite/wiki)\n- [MCP Inspector](https://github.com/modelcontextprotocol/inspector)\n- [Pre-commit Hooks](https://pre-commit.com)\n- [Google Cloud Console](https://console.cloud.google.com)\n\n## 🤝 Contributing\n\nPlease read [CONTRIBUTING.md](CONTRIBUTING.md) for details on our code of conduct and the process for submitting pull requests.\n\n## 🔒 Security\n\nSee [SECURITY.md](SECURITY.md) for reporting vulnerabilities and best practices.\n\n## 📄 License\n\nMIT License - See [LICENSE](LICENSE) file for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcp",
        "adexltd",
        "suite",
        "mcp google",
        "google suite",
        "adexltd mcp"
      ],
      "category": "document-processing"
    },
    "adiom-data--lance-mcp": {
      "owner": "adiom-data",
      "name": "lance-mcp",
      "url": "https://github.com/adiom-data/lance-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/adiom-data.webp",
      "description": "Interact with on-disk documents through retrieval-augmented generation (RAG) and hybrid search capabilities in LanceDB.",
      "stars": 71,
      "forks": 16,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T04:12:32Z",
      "readme_content": "# 🗄️ LanceDB MCP Server for LLMS\n\n[![Node.js 18+](https://img.shields.io/badge/node-18%2B-blue.svg)](https://nodejs.org/en/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\nA Model Context Protocol (MCP) server that enables LLMs to interact directly the documents that they have on-disk through agentic RAG and hybrid search in LanceDB. Ask LLMs questions about the dataset as a whole or about specific documents.\n\n## ✨ Features\n\n- 🔍 LanceDB-powered serverless vector index and document summary catalog.\n- 📊 Efficient use of LLM tokens. The LLM itself looks up what it needs when it needs.\n- 📈 Security. The index is stored locally so no data is transferred to the Cloud when using a local LLM.\n\n## 🚀 Quick Start\n\nTo get started, create a local directory to store the index and add this configuration to your Claude Desktop config file:\n\n**MacOS**: `~/Library/Application\\ Support/Claude/claude_desktop_config.json`  \n**Windows**: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"lancedb\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"lance-mcp\",\n        \"PATH_TO_LOCAL_INDEX_DIR\"\n      ]\n    }\n  }\n}\n```\n\n### Prerequisites\n\n- Node.js 18+\n- npx\n- MCP Client (Claude Desktop App for example)\n- Summarization and embedding models installed (see config.ts - by default we use Ollama models)\n  - `ollama pull snowflake-arctic-embed2`\n  - `ollama pull llama3.1:8b`\n\n### Demo\n\n<img src=\"https://github.com/user-attachments/assets/90bfdea9-9edd-4cf6-bb04-94c9c84e4825\" width=\"50%\">\n\n#### Local Development Mode:\n\n```json\n{\n  \"mcpServers\": {\n    \"lancedb\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"PATH_TO_LANCE_MCP/dist/index.js\",\n        \"PATH_TO_LOCAL_INDEX_DIR\"\n      ]\n    }\n  }\n}\n```\nUse `npm run build` to build the project.\n\nUse `npx @modelcontextprotocol/inspector dist/index.js PATH_TO_LOCAL_INDEX_DIR` to run the MCP tool inspector.\n\n### Seed Data\n\nThe seed script creates two tables in LanceDB - one for the catalog of document summaries, and another one - for vectorized documents' chunks.\nTo run the seed script use the following command:\n```console\nnpm run seed -- --dbpath <PATH_TO_LOCAL_INDEX_DIR> --filesdir <PATH_TO_DOCS>\n```\n\nYou can use sample data from the docs/ directory. Feel free to adjust the default summarization and embedding models in the config.ts file. If you need to recreate the index, simply rerun the seed script with the `--overwrite` option.\n\n#### Catalog\n\n- Document summary\n- Metadata\n\n#### Chunks\n\n- Vectorized document chunk\n- Metadata\n\n## 🎯 Example Prompts\n\nTry these prompts with Claude to explore the functionality:\n\n```plaintext\n\"What documents do we have in the catalog?\"\n\"Why is the US healthcare system so broken?\"\n```\n\n## 📝 Available Tools\n\nThe server provides these tools for interaction with the index:\n\n### Catalog Tools\n\n- `catalog_search`: Search for relevant documents in the catalog\n\n### Chunks Tools\n\n- `chunks_search`: Find relevant chunks based on a specific document from the catalog\n- `all_chunks_search`: Find relevant chunks from all known documents\n\n## 📜 License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "retrieval",
        "documents",
        "lancedb",
        "documents retrieval",
        "document processing",
        "disk documents"
      ],
      "category": "document-processing"
    },
    "agentset-ai--mcp-server": {
      "owner": "agentset-ai",
      "name": "mcp-server",
      "url": "https://github.com/agentset-ai/mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/agentset-ai.webp",
      "description": "Build intelligent, document-based applications with integrated data retrieval capabilities, leveraging Retrieval-Augmented Generation (RAG) methodologies.",
      "stars": 17,
      "forks": 5,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-18T06:02:08Z",
      "readme_content": "# Agentset MCP\n\nMCP server for Agentset, an open-source platform for Retrieval-Augmented Generation (RAG). Designed for developers who want to build intelligent, document-based applications quickly and efficiently.\n\n[![npm version][npm-badge]][npm]\n[![License][license-badge]][license]\n[![Build Status][build-badge]][build]\n[![Downloads][downloads-badge]][npm]\n[![Size][size-badge]][npm]\n\n## Installation\n\nusing npm:\n\n```sh\nAGENTSET_API_KEY=your-api-key npx @agentset/mcp --ns your-namespace-id\n```\n\nusing yarn:\n\n```sh\nAGENTSET_API_KEY=your-api-key yarn dlx @agentset/mcp --ns your-namespace-id\n```\n\nusing pnpm:\n\n```sh\nAGENTSET_API_KEY=your-api-key pnpm dlx @agentset/mcp --ns your-namespace-id\n```\n\n## Adding to Claude\n\n```json\n{\n  \"mcpServers\": {\n    \"agentset\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@agentset/mcp@latest\"],\n      \"env\": {\n        \"AGENTSET_API_KEY\": \"agentset_xxx\",\n        \"AGENTSET_NAMESPACE_ID\": \"ns_xxx\"\n      }\n    }\n  }\n}\n```\n\n## Tips\n\nPassing namespace id as an environment variable\n\n```sh\nAGENTSET_API_KEY=your-api-key AGENTSET_NAMESPACE_ID=your-namespace-id npx @agentset/mcp\n```\n\nPassing a custom tool description\n\n```sh\nAGENTSET_API_KEY=your-api-key npx @agentset/mcp --ns your-namespace-id -d \"Your custom tool description\"\n```\n\nPassing a tenant id:\n\n```sh\nAGENTSET_API_KEY=your-api-key npx @agentset/mcp --ns your-namespace-id -t your-tenant-id\n```\n\n## API Reference\n\nVisit the [full documentation](https://docs.agentset.ai) for more details.\n\n<!-- Links -->\n\n[docs]: https://docs.agentset.ai/\n[build-badge]: https://github.com/agentset-ai/mcp-server/actions/workflows/release.yml/badge.svg\n[build]: https://github.com/agentset-ai/mcp-server/actions/workflows/release.yml\n[license-badge]: https://badgen.net/github/license/agentset-ai/mcp-server\n[license]: https://github.com/agentset-ai/mcp-server/blob/main/LICENSE\n[npm]: https://www.npmjs.com/package/@agentset/mcp\n[npm-badge]: https://badgen.net/npm/v/@agentset/mcp\n[downloads-badge]: https://img.shields.io/npm/dm/@agentset/mcp.svg\n[size-badge]: https://badgen.net/packagephobia/publish/@agentset/mcp\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "retrieval",
        "document",
        "agentset",
        "document processing",
        "intelligent document",
        "data retrieval"
      ],
      "category": "document-processing"
    },
    "ahmedjemaa-tech--medical-coding-reproducibility": {
      "owner": "ahmedjemaa-tech",
      "name": "medical-coding-reproducibility",
      "url": "https://github.com/ahmedjemaa-tech/medical-coding-reproducibility",
      "imageUrl": "/freedevtools/mcp/pfp/ahmedjemaa-tech.webp",
      "description": "Automates the process of assigning diagnosis and procedure codes from electronic health records. Utilizes advanced models to improve accuracy and efficiency in medical coding tasks, with tools and datasets from MIMIC-III and MIMIC-IV.",
      "stars": 0,
      "forks": 0,
      "license": "Apache License 2.0",
      "language": "",
      "updated_at": "2025-03-29T10:21:50Z",
      "readme_content": "# ⚕️Automated Medical Coding on MIMIC-III and MIMIC-IV: A Critical Review and Replicability Study\n\nOfficial source code repository for the SIGIR 2023 paper [Automated Medical Coding on MIMIC-III and MIMIC-IV: A Critical Review and Replicability Study](https://dl.acm.org/doi/10.1145/3539618.3591918)\n\n\n```bibtex\n@inproceedings{edinAutomatedMedicalCoding2023,\n  address = {Taipei, Taiwan},\n  title = {Automated {Medical} {Coding} on {MIMIC}-{III} and {MIMIC}-{IV}: {A} {Critical} {Review} and {Replicability} {Study}},\n  isbn = {978-1-4503-9408-6},\n  shorttitle = {Automated {Medical} {Coding} on {MIMIC}-{III} and {MIMIC}-{IV}},\n  doi = {10.1145/3539618.3591918},\n  booktitle = {Proceedings of the 46th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},\n  publisher = {ACM Press},\n  author = {Edin, Joakim and Junge, Alexander and Havtorn, Jakob D. and Borgholt, Lasse and Maistro, Maria and Ruotsalo, Tuukka and Maaløe, Lars},\n  year = {2023}\n}\n```\n\n## Update\nWe released a new [paper](https://arxiv.org/pdf/2406.08958) and [repository](https://github.com/JoakimEdin/explainable-medical-coding/tree/main) for explainable medical coding. The new repository offers the following:\n- **Explainability**: Multiple feature attribution methods and metrics for multi-label classification. \n- **Implementation of a modified PLM-ICD**: We have fixed the problem of PLM-ICD occasionally collapsing during training.\n- **Huggingface Datasets**: we implemented MIMIC-III, IV, and MDACE as HuggingFace datasets.\n- **Inference code**: We provide code for inference without needing the training dataset.\nThe new repository no longer supports CNN, Bi-GRU, CAML, LAAT, and MultiResCNN.\n\nAlso, check out [my blog post](https://substack.com/home/post/p-145913061?source=queue) criticizing popular ideas in automated medical coding. I think it will be interesting for most researchers in the field\n\n## Introduction \nAutomatic medical coding is the task of automatically assigning diagnosis and procedure codes based on discharge summaries from electronic health records. This repository contains the code used in the paper Automated medical coding on MIMIC-III and MIMIC-IV: A Critical Review and Replicability Study. The repository contains code for training and evaluating medical coding models and new splits for MIMIC-III and the newly released MIMIC-IV. The following models have been implemented:\n\n| Model | Paper | Original Code |\n| ----- | ----- | ------------- |\n| CNN   |[Explainable Prediction of Medical Codes from Clinical Text](https://aclanthology.org/N18-1100/) | [link](https://github.com/jamesmullenbach/caml-mimic) | \n| Bi-GRU|[Explainable Prediction of Medical Codes from Clinical Text](https://aclanthology.org/N18-1100/) | [link](https://github.com/jamesmullenbach/caml-mimic) | \n|CAML   |[Explainable Prediction of Medical Codes from Clinical Text](https://aclanthology.org/N18-1100/) | [link](https://github.com/jamesmullenbach/caml-mimic) | \n| MultiResCNN | [ICD Coding from Clinical Text Using Multi-Filter Residual Convolutional Neural Network](https://arxiv.org/pdf/1912.00862.pdf) | [link](https://github.com/foxlf823/Multi-Filter-Residual-Convolutional-Neural-Network) |\n| LAAT | [A Label Attention Model for ICD Coding from Clinical Text](https://arxiv.org/abs/2007.06351) | [link](https://github.com/aehrc/LAAT) |\n| PLM-ICD | [PLM-ICD: Automatic ICD Coding with Pretrained Language Models](https://aclanthology.org/2022.clinicalnlp-1.2/) | [link](https://github.com/MiuLab/PLM-ICD) |\n\nThe splits are found in `files/data`. The splits are described in the paper.\n\n## How to reproduce results\n### Setup Conda environment\n1. Create a conda environement `conda create -n coding python=3.10`\n2. Install the packages `pip install . -e`\n\n### Prepare MIMIC-III\nThis code has been developed on MIMIC-III v1.4. \n1. Download the MIMIC-III data into your preferred location `path/to/mimiciii`. Please note that you need to complete training to acces the data. The training is free, but takes a couple of hours.  - [link to data access](https://physionet.org/content/mimiciii/1.4/)\n2. Open the file `src/settings.py`\n3. Change the variable `DOWNLOAD_DIRECTORY_MIMICIII` to the path of your downloaded data `path/to/mimiciii`\n4. If you want to use the MIMIC-III full and MIMIC-III 50 from the [Explainable Prediction of Medical Codes from Clinical Text](https://aclanthology.org/N18-1100/) you need to run `python prepare_data/prepare_mimiciii_mullenbach.py`\n5. If you want to use MIMIC-III clean from our paper you need to run `python prepare_data/prepare_mimiciii.py`\n\n### Prepare MIMIC-IV\nThis code has been developed on MIMIC-IV and MIMIC-IV v2.2. \n1. Download MIMIC-IV and MIMIC-IV-NOTE into your preferred location `path/to/mimiciv` and `path/to/mimiciv-note`. Please note that you need to complete training to acces the data. The training is free, but takes a couple of hours.  - [mimiciv](https://physionet.org/content/mimiciv/2.2/) and [mimiciv-note](https://physionet.org/content/mimic-iv-note/2.2/)\n2. Open the file `src/settings.py`\n3. Change the variable `DOWNLOAD_DIRECTORY_MIMICIV` to the path of your downloaded data `path/to/mimiciv`\n4. Change the variable `DOWNLOAD_DIRECTORY_MIMICIV_NOTE` to the path of your downloaded data `path/to/mimiciv-note`\n5. Run `python prepare_data/prepare_mimiciv.py`\n\n### Before running experiments\n1. Create a weights and biases account. It is possible to run the experiments without wandb.\n2. Download the [model checkpoints](https://drive.google.com/file/d/1hYeJhztAd-JbhqHojY7ZpLtkBcthD8AK/view?usp=share_link) and unzip it. Please note that these model weights can't be used commercially due to the MIMIC License.\n3. If you want to train PLM-ICD, you need to download [RoBERTa-base-PM-M3-Voc](https://dl.fbaipublicfiles.com/biolm/RoBERTa-base-PM-M3-Voc-hf.tar.gz), unzip it and change the `model_path` parameter in `configs/model/plm_icd.yaml` and `configs/text_transform\n/huggingface.yaml` to the path of the download. \n\n### Running experiments\n#### Training\nYou can run any experiment found in `configs/experiment`. Here are some examples:\n   * Train PLM-ICD on MIMIC-III clean on GPU 0: `python main.py experiment=mimiciii_clean/plm_icd gpu=0`\n   * Train CAML on MIMIC-III full on GPU 6: `python main.py experiment=mimiciii_full/caml gpu=6`\n   * Train LAAT on MIMIC-IV ICD-9 full on GPU 6: `python main.py experiment=mimiciv_icd9/laat gpu=6`\n   * Train LAAT on MIMIC-IV ICD-9 full on GPU 6 without weights and biases: `python main.py experiment=mimiciv_icd9/laat gpu=6 callbacks=no_wandb trainer.print_metrics=true`\n   \n#### Evaluation\nIf you just want to evaluate the models using the provided model_checkpoints you need to do set `trainer.epochs=0` and provide the path to the models checkpoint `load_model=path/to/model_checkpoint`. Make sure you the correct model-checkpoint with the correct configs.\n\nExample:\nEvaluate PLM-ICD on MIMIC-IV ICD-10 on GPU 1: `python main.py experiment=mimiciv_icd10/plm_icd gpu=1 load_model=path/to/model_checkpoints/mimiciv_icd10/plm_icd trainer.epochs=0`\n\n## Overview of the repository\n#### configs\nWe use [Hydra](https://hydra.cc/docs/intro/) for configurations. The condigs for every experiment is found in `configs/experiments`. Furthermore, the configuration for the sweeps are found in `configs/sweeps`. We used [Weights and Biases Sweeps](https://docs.wandb.ai/guides/sweeps) for most of our experiments.\n\n#### files\nThis is where the images and data is stored.\n\n#### notebooks\nThe directory only contains one notebook used for the code analysis. The notebook is not aimed to be used by others, but is included for others to validate our data analysis.\n\n#### prepare_data\nThe directory contains all the code for preparing the datasets and generating splits.\n\n#### reports\nThis is the code used to generate the plots and tables used in the paper. The code uses the Weights and Biases API to fetch the experiment results. The code is not usable by others, but was included for the possibility to validate our figures and tables.\n\n#### src\nThis is were the code for running the experiments is found.\n\n#### tests\nThe directory contains the unit tests\n\n## My setup\nI ran the experiments on one RTX 2080 Ti 11GB per experiment. I had 128 GB RAM on my machine.\n\n## ⚠️ Known issues \n* LAAT and PLM-ICD are unstable. The loss will sometimes diverge during training. The issue seems to be overflow in the softmax function in the label-wise attention. Using batch norm or layer norm before the softmax function might solve the issue. We did not try to fix the issue as we didn't want to change the original method during our reproducibility.\n* The code was only tested on a server with 128 GB RAM. A user with 32 GB RAM reported issues fitting MIMIC-IV into memory.\n* There is an error in the collate function in the Huggingface dataset. The attention mask is being padded with 1s instead of 0s. I have not fixed this issue because I want people to be able to reproduce the results from the paper.\n\n## Acknowledgement\nThank you Sotiris Lamprinidis for providing an efficient implementation of our multi-label stratification algorithm and some data preprocessing helper functions.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "coding",
        "datasets",
        "medical",
        "medical coding",
        "procedure codes",
        "datasets mimic"
      ],
      "category": "document-processing"
    },
    "aigo666--mcp-framework": {
      "owner": "aigo666",
      "name": "mcp-framework",
      "url": "https://github.com/aigo666/mcp-framework",
      "imageUrl": "/freedevtools/mcp/pfp/aigo666.webp",
      "description": "Create custom tools to interact with large language models, facilitating web content fetching and processing of various document formats including PDF, Word, and Excel. Supports advanced features such as OCR for image content in documents and enhances workflow automation.",
      "stars": 13,
      "forks": 5,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-22T13:50:24Z",
      "readme_content": "# MCP开发框架\n[![Verified on MseeP](https://mseep.ai/badge.svg)](https://mseep.ai/app/34780cde-ee17-4a7b-b9ee-356f41fc9e77) [![smithery badge](https://smithery.ai/badge/@aigo666/mcp-framework)](https://smithery.ai/server/@aigo666/mcp-framework)\n\n一个强大的MCP（Model Context Protocol）开发框架，用于创建与大语言模型交互的自定义工具。该框架提供了一套完整的工具集，可以轻松地扩展Cursor IDE的功能，实现网页内容获取、文件处理（PDF、Word、Excel、CSV、Markdown）以及AI对话等高级功能。它具有强大的MCP工具扩展能力，使开发者能够快速构建和集成各种自定义工具。\n\n<a href=\"https://glama.ai/mcp/servers/@aigo666/mcp-framework\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@aigo666/mcp-framework/badge\" />\n</a>\n\n<details>\n<summary>🔥 最新特性：文档图片内容显示与理解</summary>\n\n最新版本现在支持在PDF和Word文档处理中，直接返回原始图片内容并进行OCR识别，使大语言模型能够同时理解文档中的文本和图像内容：\n\n- **图片内容直接显示**：文档中的图表、图像等可以直接在对话中显示，无需额外工具\n- **OCR文本识别**：自动提取图片中的文字内容，支持中英文多语言\n- **图片内容理解**：大模型可以\"看到\"文档中的图片，并基于图片内容进行分析和回答\n- **完整文档内容返回**：真正实现文档的全内容理解，包括文本、表格和图像\n\n这使得AI模型能够更全面地理解和分析文档内容，特别是对于包含图表、表单、流程图或其他可视化信息的文档尤为有价值。\n</details>\n\n## 主要功能\n\n<details>\n<summary>点击展开查看框架提供的核心功能</summary>\n\n本框架提供了以下核心功能：\n\n### 1. 综合文件处理\n\n使用`parse_file`工具可以自动识别文件类型并选择合适的处理方式，支持PDF、Word、Excel、CSV和Markdown文件。\n\n- **用法**: `parse_file /path/to/document`\n- **支持格式**: \n  - PDF文件 (.pdf)\n  - Word文档 (.doc, .docx)\n  - Excel文件 (.xls, .xlsx, .xlsm)\n  - CSV文件 (.csv)\n  - Markdown文件 (.md)\n- **参数**: `file_path` - 文件的本地路径\n- **返回**: 根据文件类型返回相应的处理结果\n\n### 2. PDF文档处理\n\n使用`parse_pdf`工具可以处理PDF文档，支持两种处理模式：\n\n- **用法**: `parse_pdf /path/to/document.pdf [mode]`\n- **参数**: \n  - `file_path` - PDF文件的本地路径\n  - `mode` - 处理模式（可选）：\n    - `quick` - 快速预览模式，仅提取文本内容\n    - `full` - 完整解析模式，提取文本、图片内容和OCR文本（默认）\n- **返回**: \n  - 快速预览模式：文档的文本内容\n  - 完整解析模式：文档的文本内容、原始图片和OCR识别结果\n\n### 3. Word文档解析\n\n使用`parse_word`工具可以解析Word文档，提取文本、表格和图片信息。\n\n- **用法**: `parse_word /path/to/document.docx`\n- **功能**: 解析Word文档并提取文本内容、表格和图片\n- **参数**: `file_path` - Word文档的本地路径\n- **返回**: 文档的文本内容、表格和原始图片\n- **特点**: 同时提供文档内嵌图像的显示和分析功能\n\n### 4. Excel文件处理\n\n使用`parse_excel`工具可以解析Excel文件，提供完整的表格数据和结构信息。\n\n- **用法**: `parse_excel /path/to/spreadsheet.xlsx`\n- **功能**: 解析Excel文件的所有工作表\n- **参数**: `file_path` - Excel文件的本地路径\n- **返回**: \n  - 文件基本信息（文件名、工作表数量）\n  - 每个工作表的详细信息：\n    - 行数和列数\n    - 列名列表\n    - 完整的表格数据\n- **特点**: \n  - 使用pandas和openpyxl提供高质量的表格数据处理\n  - 支持多工作表处理\n  - 自动处理数据类型转换\n\n### 5. CSV文件处理\n\n使用`parse_csv`工具可以解析CSV文件，提供完整的数据分析和预览功能。\n\n- **用法**: `parse_csv /path/to/data.csv`\n- **功能**: 解析CSV文件并提供数据分析\n- **参数**: \n  - `file_path` - CSV文件的本地路径\n  - `encoding` - 文件编码格式（可选，默认自动检测）\n- **返回**: \n  - 文件基本信息（文件名、行数、列数）\n  - 列名列表\n  - 数据预览（前5行）\n  - 描述性统计信息\n- **特点**: \n  - 自动编码检测\n  - 支持多种编码格式（UTF-8、GBK等）\n  - 提供数据统计分析\n  - 智能数据类型处理\n\n### 6. Markdown文件解析\n\n使用`parse_markdown`工具可以解析Markdown文件，提取文本内容、标题结构和列表等信息。\n\n- **用法**: `parse_markdown /path/to/document.md`\n- **功能**: 解析Markdown文件并提取标题结构、列表和文本内容\n- **参数**: `file_path` - Markdown文件的本地路径\n- **返回**: \n  - 文件基本信息（文件名、大小、修改时间等）\n  - 标题结构层级展示\n  - 内容元素统计（代码块、列表、链接、图片、表格等）\n  - 原始Markdown内容\n- **特点**: \n  - 自动识别各级标题和结构\n  - 智能统计内容元素\n  - 完整的标题层级展示\n\n### 7. 网页内容获取\n\n使用`url`工具可以获取任何网页的内容。\n\n- **用法**: `url https://example.com`\n- **参数**: `url` - 要获取内容的网站URL\n- **返回**: 网页的文本内容\n- **特点**: \n  - 完整的HTTP错误处理\n  - 超时管理\n  - 自动编码处理\n\n### 8. MaxKB AI对话\n\n使用`maxkb`工具可以与MaxKB API进行交互，实现智能对话功能。\n\n- **用法**: `maxkb \"您的问题或指令\"`\n- **功能**: 发送消息到MaxKB API并获取AI回复\n- **参数**: \n  - `message` - 要发送的消息内容（必需）\n  - `re_chat` - 是否重新开始对话（可选，默认false）\n  - `stream` - 是否使用流式响应（可选，默认true）\n- **返回**: AI的回复内容\n- **特点**: \n  - 支持流式响应\n  - 自动重试机制\n  - 完整的错误处理\n  - 60秒超时保护\n  - 保持连接配置优化\n\n</details>\n\n## 技术特点\n\n本框架采用了多种技术来优化文件处理性能：\n\n1. **智能文件类型识别**\n   - 自动根据文件扩展名选择合适的处理工具\n   - 提供统一的文件处理接口\n\n2. **高效的文档处理**\n   - PDF处理：支持快速预览和完整解析两种模式\n   - Word处理：精确提取文本、表格和图片\n   - Excel处理：高效处理大型表格数据\n\n3. **强大的MCP工具扩展能力**\n   - 插件化架构设计，易于扩展\n   - 统一的工具注册和调用接口\n   - 支持同步和异步工具开发\n   - 丰富的工具开发API和辅助函数\n\n4. **内存优化**\n   - 使用临时文件管理大型文件\n   - 自动清理临时资源\n   - 分块处理大型文档\n\n5. **错误处理**\n   - 完整的异常捕获和处理\n   - 详细的错误信息反馈\n   - 优雅的失败处理机制\n\n## 项目结构\n\n本框架采用模块化设计，便于扩展和维护：\n\n```\nmcp_tool/\n├── tools/\n│   ├── __init__.py        # 定义工具基类和注册器\n│   ├── loader.py          # 工具加载器，自动加载所有工具\n│   ├── file_tool.py       # 综合文件处理工具\n│   ├── pdf_tool.py        # PDF解析工具\n│   ├── word_tool.py       # Word文档解析工具\n│   ├── excel_tool.py      # Excel文件处理工具\n│   ├── csv_tool.py        # CSV文件处理工具\n│   ├── markdown_tool.py   # Markdown文件解析工具\n│   ├── url_tool.py        # URL工具实现\n│   └── maxkb_tool.py      # MaxKB AI对话工具\n├── __init__.py\n├── __main__.py\n└── server.py              # MCP服务器实现\n```\n\n## 开发指南\n\n### 如何开发新工具\n\n1. 在`tools`目录下创建一个新的Python文件，如`your_tool.py`\n2. 导入必要的依赖和基类\n3. 创建一个继承自`BaseTool`的工具类\n4. 使用`@ToolRegistry.register`装饰器注册工具\n5. 实现工具的`execute`方法\n\n### 工具模板示例\n\n```python\nimport mcp.types as types\nfrom . import BaseTool, ToolRegistry\n\n@ToolRegistry.register\nclass YourTool(BaseTool):\n    \"\"\"您的工具描述\"\"\"\n    name = \"your_tool_name\"  # 工具的唯一标识符\n    description = \"您的工具描述\"  # 工具的描述信息，将显示给用户\n    input_schema = {\n        \"type\": \"object\",\n        \"required\": [\"param1\"],  # 必需的参数\n        \"properties\": {\n            \"param1\": {\n                \"type\": \"string\",\n                \"description\": \"参数1的描述\",\n            },\n            \"param2\": {\n                \"type\": \"integer\",\n                \"description\": \"参数2的描述（可选）\",\n            }\n        },\n    }\n  \n    async def execute(self, arguments: dict) -> list[types.TextContent | types.ImageContent | types.EmbeddedResource]:\n        \"\"\"执行工具逻辑\"\"\"\n        # 参数验证\n        if \"param1\" not in arguments:\n            return [types.TextContent(\n                type=\"text\",\n                text=\"Error: Missing required argument 'param1'\"\n            )]\n          \n        # 获取参数\n        param1 = arguments[\"param1\"]\n        param2 = arguments.get(\"param2\", 0)  # 获取可选参数，提供默认值\n      \n        # 执行工具逻辑\n        result = f\"处理参数: {param1}, {param2}\"\n      \n        # 返回结果\n        return [types.TextContent(\n            type=\"text\",\n            text=result\n        )]\n```\n\n## 部署指南\n\n### 环境变量配置\n\n在`.env`文件中配置以下环境变量：\n\n```bash\n# Server Configuration\nMCP_SERVER_PORT=8000        # 服务器端口\nMCP_SERVER_HOST=0.0.0.0     # 服务器主机\n\n# 鉴权配置\nMCP_AUTH_URL=http://170.106.105.206:4000/users  # 鉴权服务地址\n\n# MaxKB配置\nMAXKB_HOST=http://host.docker.internal:8080  # MaxKB API主机地址\nMAXKB_CHAT_ID=your_chat_id_here              # MaxKB聊天ID\nMAXKB_APPLICATION_ID=your_application_id_here # MaxKB应用ID\nMAXKB_AUTHORIZATION=your_authorization_key    # MaxKB授权密钥\n\n# 调试模式\nDEBUG=false                 # 是否启用调试模式\n\n# 用户代理\nMCP_USER_AGENT=\"MCP Test Server (github.com/modelcontextprotocol/python-sdk)\"\n\n# 本地目录挂载配置\nHOST_MOUNT_SOURCE=/path/to/your/local/directory  # 本地目录路径\nHOST_MOUNT_TARGET=/host_files                    # 容器内挂载路径\n```\n\n### 本地目录挂载\n\n框架支持将本地目录挂载到容器中，以便工具可以访问本地文件。配置方法：\n\n1. 在`.env`文件中设置`HOST_MOUNT_SOURCE`和`HOST_MOUNT_TARGET`环境变量\n2. `HOST_MOUNT_SOURCE`是你本地机器上的目录路径\n3. `HOST_MOUNT_TARGET`是容器内的挂载路径（默认为`/host_files`）\n\n使用工具时，可以直接引用本地文件路径，框架会自动将其转换为容器内的路径。例如：\n\n```\n# 使用PDF工具处理本地文件\npdf \"/Users/username/Documents/example.pdf\"\n\n# 框架会自动将路径转换为容器内路径\n# 例如：\"/host_files/example.pdf\"\n```\n\n这样，你就可以在不修改工具代码的情况下，轻松访问本地文件。\n\n### Docker部署（推荐）\n\n1. 初始设置：\n```bash\n# 克隆仓库\ngit clone https://github.com/aigo666/mcp-framework.git\ncd mcp-framework\n\n# 创建环境文件\ncp .env.example .env\n```\n\n2. 使用Docker Compose：\n```bash\n# 构建并启动\ndocker compose up --build -d\n\n# 查看日志\ndocker compose logs -f\n\n# 管理容器\ndocker compose ps\ndocker compose pause\ndocker compose unpause\ndocker compose down\n```\n\n3. 访问服务：\n   - SSE端点: http://localhost:8000/sse\n\n4. Cursor IDE配置：\n- 设置 → 功能 → 添加MCP服务器\n- 类型: \"sse\"\n- URL: `http://localhost:8000/sse?token=<your-token>` (替换 `<your-token>` 为您的 JWT Token)\n\n## 鉴权配置\n\n<details>\n<summary>点击展开查看详细的鉴权配置信息</summary>\n\nSSE 服务现在支持 API 鉴权机制，每个请求都需要携带有效的认证信息：\n\n1. 配置鉴权服务地址：\n   - 在 `.env` 文件中设置 `MCP_AUTH_URL` 环境变量（默认为 `http://170.106.105.206:4000/users` 该鉴权地址仅供测试，不保证长期稳定，建议使用以下项目自行部署）\n\n2. 客户端配置：\n   - 在 Cursor 插件中配置时，需要在 URL 中添加 `token` 查询参数\n   - 格式为 `http://your-server:8000/sse?token=<your-token>`\n   - 服务器会自动将 token 转换为 `Bearer <your-token>` 格式发送到鉴权服务\n\n3. 鉴权流程：\n   - 当 SSE 服务收到请求时，会从 URL 中提取 token 参数\n   - 然后向配置的鉴权地址发送请求，并传递 `Authorization: Bearer <your-token>` 头\n   - 只有鉴权成功（返回 200 状态码）的请求才会被处理\n   - 鉴权失败的请求会收到 401 Unauthorized 响应\n\n4. 推荐JWT鉴权服务：\n   - 我们推荐使用Jason Watmore的Node.js JWT鉴权服务作为参考实现\n   - 详细文档和示例代码：https://jasonwatmore.com/nodejs-jwt-authentication-tutorial-with-example-api\n   - 该实现提供了完整的用户注册、登录、令牌生成和验证功能\n   - 可以无缝集成到本框架的鉴权流程中\n\n</details>\n\n## 部署方式\n\n### 传统Python部署\n\n1. 安装系统依赖：\n```bash\n# Ubuntu/Debian\nsudo apt-get update\nsudo apt-get install -y poppler-utils tesseract-ocr tesseract-ocr-chi-sim\n\n# macOS\nbrew install poppler tesseract tesseract-lang\n\n# Windows\n# 1. 下载并安装Tesseract: https://github.com/UB-Mannheim/tesseract/wiki\n# 2. 将Tesseract添加到系统PATH\n```\n\n2. 安装Python依赖：\n```bash\n# 创建虚拟环境\npython -m venv venv\nsource venv/bin/activate  # Linux/Mac\n# 或\n.\\venv\\Scripts\\activate  # Windows\n\n# 安装依赖\npip install -r requirements.txt\n```\n\n3. 启动服务：\n```bash\npython -m mcp_tool\n```\n\n## 依赖项\n\n主要依赖：\n- `mcp`: Model Context Protocol实现\n- `PyMuPDF`: PDF文档处理\n- `python-docx`: Word文档处理\n- `pandas`和`openpyxl`: Excel文件处理\n- `httpx`: 异步HTTP客户端\n- `anyio`: 异步I/O支持\n- `click`: 命令行接口\n\n## 贡献指南\n\n1. Fork仓库\n2. 创建功能分支 (`git checkout -b feature/amazing-feature`)\n3. 提交更改 (`git commit -m 'Add some amazing feature'`)\n4. 推送到分支 (`git push origin feature/amazing-feature`)\n5. 打开Pull Request\n\n## 许可证\n\n本项目采用MIT许可证 - 详情请参阅[LICENSE](LICENSE)文件。",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "document",
        "framework",
        "aigo666",
        "processing aigo666",
        "mcp framework",
        "aigo666 mcp"
      ],
      "category": "document-processing"
    },
    "aindreyway--mcp-server-neurolora-p": {
      "owner": "aindreyway",
      "name": "mcp-server-neurolora-p",
      "url": "https://github.com/aindreyway/mcp-server-neurolora-p",
      "imageUrl": "/freedevtools/mcp/pfp/aindreyway.webp",
      "description": "Collects and documents code from projects into markdown, providing tools for code analysis and documentation.",
      "stars": 9,
      "forks": 3,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-03T22:20:26Z",
      "readme_content": "# MCP Server Neurolorap\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[](https://github.com/aindreyway/mcp-server-neurolorap/actions/workflows/tests.yml)\n[![codecov](https://codecov.io/gh/aindreyway/mcp-server-neurolorap/branch/main/graph/badge.svg)](https://codecov.io/gh/aindreyway/mcp-server-neurolorap)\n\nMCP server providing tools for code analysis and documentation.\n\n<a href=\"https://glama.ai/mcp/servers/rg07wseeqe\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/rg07wseeqe/badge\" alt=\"Server Neurolorap MCP server\" /></a>\n\n## Features\n\n### Code Collection Tool\n\n- Collect code from entire project\n- Collect code from specific directories or files\n- Collect code from multiple paths\n- Markdown output with syntax highlighting\n- Table of contents generation\n- Support for multiple programming languages\n\n### Project Structure Reporter Tool\n\n- Analyze project structure and metrics\n- Generate detailed reports in markdown format\n- File size and complexity analysis\n- Tree-based visualization\n- Recommendations for code organization\n- Customizable ignore patterns\n\n## Quick Overview\n\n```sh\n# Using uvx (recommended)\nuvx mcp-server-neurolorap\n\n# Or using pip (not recommended)\npip install mcp-server-neurolorap\n```\n\nYou don't need to install or configure any dependencies manually. The tool will set up everything you need to analyze and document code.\n\n## Installation\n\n**You'll need to have [UV](https://docs.astral.sh/uv/) >= 0.4.10 installed on your machine.**\n\nTo install and run the server:\n\n```sh\n# Install using uvx (recommended)\nuvx mcp-server-neurolorap\n\n# Or install using pip (not recommended)\npip install mcp-server-neurolorap\n```\n\nThis will automatically:\n\n- Install all required dependencies\n- Configure Cline integration\n- Set up the server for immediate use\n\nThe server will be available through the MCP protocol in Cline. You can use it to analyze and document code from any project.\n\n## Usage\n\n### Developer Mode\n\nThe server includes a developer mode with JSON-RPC terminal interface for direct interaction:\n\n```bash\n# Start the server in developer mode\npython -m mcp_server_neurolorap --dev\n```\n\nAvailable commands:\n\n- `help`: Show available commands\n- `list_tools`: List available MCP tools\n- `collect <path>`: Collect code from specified path\n- `report [path]`: Generate project structure report\n- `exit`: Exit developer mode\n\nExample session:\n\n```\n> help\nAvailable commands:\n- help: Show this help message\n- list_tools: List available MCP tools\n- collect <path>: Collect code from specified path\n- report [path]: Generate project structure report\n- exit: Exit the terminal\n\n> list_tools\n[\"code_collector\", \"project_structure_reporter\"]\n\n> collect src\nCode collection complete!\nOutput file: code_collection.md\n\n> report\nProject structure report generated: PROJECT_STRUCTURE_REPORT.md\n\n> exit\nGoodbye!\n```\n\n### Through MCP Tools\n\n#### Code Collection\n\n```python\nfrom modelcontextprotocol import use_mcp_tool\n\n# Collect code from entire project\nresult = use_mcp_tool(\n    \"code_collector\",\n    {\n        \"input\": \".\",\n        \"title\": \"My Project\"\n    }\n)\n\n# Collect code from specific directory\nresult = use_mcp_tool(\n    \"code_collector\",\n    {\n        \"input\": \"./src\",\n        \"title\": \"Source Code\"\n    }\n)\n\n# Collect code from multiple paths\nresult = use_mcp_tool(\n    \"code_collector\",\n    {\n        \"input\": [\"./src\", \"./tests\"],\n        \"title\": \"Project Files\"\n    }\n)\n```\n\n#### Project Structure Analysis\n\n```python\n# Generate project structure report\nresult = use_mcp_tool(\n    \"project_structure_reporter\",\n    {\n        \"output_filename\": \"PROJECT_STRUCTURE_REPORT.md\"\n    }\n)\n\n# Analyze specific directory with custom ignore patterns\nresult = use_mcp_tool(\n    \"project_structure_reporter\",\n    {\n        \"output_filename\": \"src_structure.md\",\n        \"ignore_patterns\": [\"*.pyc\", \"__pycache__\"]\n    }\n)\n```\n\n### File Storage\n\nThe server uses a structured approach to file storage:\n\n1. All generated files are stored in `~/.mcp-docs/<project-name>/`\n2. A `.neurolora` symlink is created in your project root pointing to this directory\n\nThis ensures:\n\n- Clean project structure\n- Consistent file organization\n- Easy access to generated files\n- Support for multiple projects\n- Reliable file synchronization across different OS environments\n- Fast file visibility in IDEs and file explorers\n\n### Customizing Ignore Patterns\n\nCreate a `.neuroloraignore` file in your project root to customize which files are ignored:\n\n```gitignore\n# Dependencies\nnode_modules/\nvenv/\n\n# Build\ndist/\nbuild/\n\n# Cache\n__pycache__/\n*.pyc\n\n# IDE\n.vscode/\n.idea/\n\n# Generated files\n.neurolora/\n```\n\nIf no `.neuroloraignore` file exists, a default one will be created with common ignore patterns.\n\n## Development\n\n1. Clone the repository\n2. Create and activate virtual environment:\n\n```sh\npython -m venv .venv\nsource .venv/bin/activate  # On Unix\n# or\n.venv\\Scripts\\activate  # On Windows\n```\n\n3. Install development dependencies:\n\n```sh\npip install -e \".[dev]\"\n```\n\n4. Run the server:\n\n```sh\n# Normal mode (MCP server with stdio transport)\npython -m mcp_server_neurolorap\n\n# Developer mode (JSON-RPC terminal interface)\npython -m mcp_server_neurolorap --dev\n```\n\n### Testing\n\nThe project maintains high quality standards through automated testing and continuous integration:\n\n- Comprehensive test suite with over 80% code coverage\n- Automated testing on Python 3.10, 3.11, and 3.12\n- Continuous integration through GitHub Actions\n- Regular security scans and dependency checks\n\nFor development and testing details, see PROJECT_SUMMARY.md.\n\n### Code Quality\n\nThe project maintains high code quality standards through various tools:\n\n```sh\n# Format code\nblack .\n\n# Sort imports\nisort .\n\n# Lint code\nflake8 .\n\n# Type check\nmypy src tests\n\n# Security check\nbandit -r src/\nsafety check\n```\n\nAll these checks are run automatically on pull requests through GitHub Actions.\n\n### CI/CD Pipeline\n\nThe project uses GitHub Actions for continuous integration and deployment:\n\n- Runs tests on Python 3.10, 3.11, and 3.12\n- Checks code formatting and style\n- Performs type checking\n- Runs security scans\n- Generates coverage reports\n- Builds and validates package\n- Uploads test artifacts\n\nThe pipeline must pass before merging any changes.\n\n## Contributing\n\nWe welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.\n\n## License\n\nMIT License. See LICENSE file for details.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "markdown",
        "documentation",
        "document",
        "projects markdown",
        "documents code",
        "document processing"
      ],
      "category": "document-processing"
    },
    "aiuluna--knowledge-graph-mcp": {
      "owner": "aiuluna",
      "name": "knowledge-graph-mcp",
      "url": "https://github.com/aiuluna/knowledge-graph-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/aiuluna.webp",
      "description": "Manage, analyze, and visualize knowledge graphs with support for various graph types, including ontologies and timelines. Integrate effectively with MCP-compatible AI assistants to query and manipulate knowledge graph data while tracking resource management and version status.",
      "stars": 1,
      "forks": 0,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-04-17T08:29:23Z",
      "readme_content": "# Knowledge Graph MCP Server\n\nA Model Context Protocol (MCP) service for creating, managing, analyzing, and visualizing knowledge graphs. This service fully complies with the MCP standard and seamlessly integrates with MCP-compatible AI assistants (such as Claude).\n\n[![smithery badge](https://smithery.ai/badge/@aiuluna/knowledge-graph-mcp)](https://smithery.ai/server/@aiuluna/knowledge-graph-mcp)\n[中文文档](./README.zh-CN.md)\n\n## Core Features\n\n* **Multiple Graph Types**: Support for topology structures, timelines, changelogs, requirement documents, knowledge bases, ontologies, and more\n* **Complete Error Handling**: Clear error messages and handling suggestions for common issues\n* **Resource Management**: Support for SVG and Markdown resource association and management\n* **Version Status**: Support for multiple status management including draft, published, and archived\n\n## Installation & Configuration\n\n### Installing via Smithery\n\nTo install knowledge-graph-mcp for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@aiuluna/knowledge-graph-mcp):\n\n```bash\nnpx -y @smithery/cli install @aiuluna/knowledge-graph-mcp --client claude\n```\n\n### Requirements\n- Node.js >= 16.0.0\n- pnpm >= 7.0.0\n\n### Configure Knowledge Graph Directory\nCreate a directory to store knowledge graph data, for example:\n```bash\nmkdir ~/knowledge_graph\n```\n\n### Usage in Cursor\nAdd the following configuration to your Cursor config file:\n\n```json\n{\n  \"mcpServers\": {\n    \"knowledge-graph\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@aiuluna/knowledge-graph-mcp\"\n      ],\n      \"env\": {\n        \"KNOWLEDGE_GRAPH_DIR\": \"/path/to/your/knowledge_graph/dir\"\n      }\n    }\n  }\n}\n```\n\nNote:\n- Replace `KNOWLEDGE_GRAPH_DIR` with your actual knowledge graph storage directory path\n- You can specify a particular version number, such as `@0.0.1`\n\n### Usage in Claude Desktop\nAdd the following configuration to `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"knowledge-graph\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@aiuluna/knowledge-graph-mcp\"\n      ],\n      \"env\": {\n        \"KNOWLEDGE_GRAPH_DIR\": \"/path/to/your/knowledge_graph/dir\"\n      }\n    }\n  }\n}\n```\n\n## Prompt Usage Guide\n\n### Project Structure\nPrompt files are located in the `/src/rules/prompts` directory. Please copy these files to your Cursor and add them as default rules for Agent mode (refer to [Cursor Rules Configuration](https://docs.cursor.com/context/rules)):\n```\n.cursor/\n  └── rules/\n      └── graph-query.mdc    # Knowledge graph query prompt file\n```\n\n### Using Agent Mode\nWhen using Agent mode in Cursor, you can trigger knowledge graph queries by:\n\n1. Type `/ck` command in the editor\n2. The Agent will automatically invoke the prompt defined in `@graph-query.mdc`\n3. The prompt will:\n   - Analyze current context\n   - Query relevant knowledge graph nodes\n   - Generate summary content\n   - Integrate query results into the conversation\n\n### Other Rules\nThe project also includes prompts for generating hand-drawn style graphics and Markdown documents as knowledge graph resources. Since Cursor doesn't support the MCP standard for prompts, this project uses tools to obtain these rules. You can also integrate them into Cursor's rules like above and modify them to your desired style for use in Cursor Agent mode.\n\n## Tool List\n\n### Graph Management\n\n1. `create_graph`\n   * Create a new knowledge graph\n   * Parameters:\n     * `name` (string): Graph name\n     * `description` (string, optional): Graph description\n     * `type` (string): Graph type (topology/timeline/changelog/requirement/kb/ontology)\n\n2. `list_graphs`\n   * List all knowledge graphs\n   * Parameters:\n     * `status` (string, optional): Filter by status (draft/published/archived)\n     * `type` (string, optional): Filter by type\n\n3. `publish_graph`\n   * Publish a knowledge graph\n   * Parameters:\n     * `graphId` (string): Graph ID\n\n### Node Management\n\n1. `add_node`\n   * Add a node to the graph\n   * Parameters:\n     * `graphId` (string): Graph ID\n     * `type` (string): Node type\n     * `name` (string): Node name\n     * `description` (string, optional): Node description\n     * `filePath` (string, optional): Associated file path\n     * `metadata` (object, optional): Node metadata\n\n2. `update_node`\n   * Update node information\n   * Parameters:\n     * `graphId` (string): Graph ID\n     * `nodeId` (string): Node ID\n     * `name` (string, optional): New node name\n     * `description` (string, optional): New node description\n     * `filePath` (string, optional): New file path\n     * `metadata` (object, optional): New metadata\n\n3. `delete_node`\n   * Delete a node\n   * Parameters:\n     * `graphId` (string): Graph ID\n     * `nodeId` (string): Node ID\n     * `confirmDelete` (boolean): Delete confirmation\n\n4. `get_node_details`\n   * Get detailed node information\n   * Parameters:\n     * `graphId` (string): Graph ID\n     * `nodeId` (string): Node ID\n\n### Edge Management\n\n1. `add_edge`\n   * Add an edge\n   * Parameters:\n     * `graphId` (string): Graph ID\n     * `type` (string): Edge type\n     * `sourceId` (string): Source node ID\n     * `targetId` (string): Target node ID\n     * `label` (string, optional): Edge label\n     * `weight` (number, optional): Edge weight\n     * `metadata` (object, optional): Edge metadata\n\n2. `update_edge`\n   * Update edge information\n   * Parameters:\n     * `graphId` (string): Graph ID\n     * `edgeId` (string): Edge ID\n     * `label` (string, optional): New edge label\n     * `weight` (number, optional): New edge weight\n     * `metadata` (object, optional): New metadata\n\n3. `delete_edge`\n   * Delete an edge\n   * Parameters:\n     * `graphId` (string): Graph ID\n     * `edgeId` (string): Edge ID\n     * `confirmDelete` (boolean): Delete confirmation\n\n### Resource Management\n\n1. `get_creation_guidelines`\n   * Get resource creation guidelines\n   * Parameters:\n     * `type` (string): Guideline type (svg/markdown/all)\n\n2. `save_resource`\n   * Save a resource\n   * Parameters:\n     * `graphId` (string): Graph ID\n     * `nodeId` (string, optional): Associated node ID\n     * `resourceType` (string): Resource type (svg/markdown)\n     * `title` (string): Resource title\n     * `description` (string, optional): Resource description\n     * `content` (string): Resource content\n\n3. `update_resource`\n   * Update resource information\n   * Parameters:\n     * `graphId` (string): Graph ID\n     * `resourceId` (string): Resource ID\n     * `name` (string, optional): New resource name\n     * `title` (string, optional): New resource title\n     * `description` (string, optional): New resource description\n\n4. `delete_resource`\n   * Delete a resource\n   * Parameters:\n     * `graphId` (string): Graph ID\n     * `resourceId` (string): Resource ID\n     * `confirmDelete` (boolean): Delete confirmation\n\n5. `unlink_resource`\n   * Unlink a resource from a node\n   * Parameters:\n     * `graphId` (string): Graph ID\n     * `nodeId` (string): Node ID\n     * `resourceId` (string): Resource ID\n\n## Development\n\n```bash\n# Install dependencies\npnpm install\n\n# Development mode\npnpm dev\n\n# Build project\npnpm build\n\n# Run tests\npnpm test\n\n# Code check\npnpm lint\n```\n\n## Error Handling\n\nThe service uses a standard error handling mechanism. All errors are logged to the `md/error_log.txt` file, including timestamps, error messages, and stack traces.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ontologies",
        "knowledge",
        "graphs",
        "knowledge graph",
        "knowledge graphs",
        "visualize knowledge"
      ],
      "category": "document-processing"
    },
    "albertshao--wiki_mcp_server": {
      "owner": "albertshao",
      "name": "wiki_mcp_server",
      "url": "https://github.com/albertshao/wiki_mcp_server",
      "imageUrl": "/freedevtools/mcp/pfp/albertshao.webp",
      "description": "Manage Confluence wiki pages by creating, updating, deleting, and searching them through a unified interface. Automatically selects the relevant knowledge base based on user queries to enhance content management efficiency.",
      "stars": 2,
      "forks": 0,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-09-24T09:28:03Z",
      "readme_content": "# 📚 Wiki MCP Server\n\nAn MCP (Model Context Protocol) Server implementation for managing Confluence wiki pages.\n\nSupports:\n- Creating new wiki pages\n- Updating existing wiki pages\n- Deleting wiki pages\n- Searching wiki pages by keyword\n- Auto-selecting correct Confluence knowledge base (`alm`, `wpb`, etc.) based on user query\n\nBuilt with **FastAPI**, following **MCP Server Best Practices**, and ready for production deployment.\n\n---\n\n## 🚀 Tech Stack\n\n- Python 3.10+\n- FastAPI\n- MCP SDK\n- Requests (for Confluence API interaction)\n- ContextVars (for session management)\n\n---\n\n## 📦 Project Structure\n\n```plaintext\nwiki_mcp_server/\n├── src/wiki_mcp_server/\n│   ├── server.py          # MCP server entry point\n│   ├── service.py         # Business logic (Confluence API interactions)\n│   ├── tools.py           # MCP tool definitions\n│   ├── prompts.py         # MCP prompt definitions\n│   ├── resources.py       # MCP resource definitions\n│   ├── utils.py           # Helper functions (wiki_type inference etc.)\n│   ├── utils/session_context.py  # Session context manager\n│   └── middleware.py      # Authentication and session initialization middleware\n├── Dockerfile             # Container configuration\n├── requirements.txt       # Python dependencies\n├── README.md              # Project documentation\n├── smithery.yaml          # Smithery integration config (optional)\n└── pyproject.toml         # Python project metadata\n```\n\n---\n\n## ⚙️ Installation\n\n1. Clone the repository:\n\n```bash\ngit clone https://your-repo-url/wiki_mcp_server.git\ncd wiki_mcp_server\n```\n\n2. Install dependencies:\n\n```bash\npip install -r requirements.txt\n```\n\n3. (Optional) Configure your environment variables if needed.\n\n---\n\n## 🛠 Running Locally\n\nRun the server:\n\n```bash\ncd src\nuvicorn wiki_mcp_server.server:app --host 0.0.0.0 --port 9999 --reload\n```\n\nAfter startup, you can visit:\n\n- OpenAPI docs (Swagger UI): [http://localhost:9999/docs](http://localhost:9999/docs)\n- ReDoc docs: [http://localhost:9999/redoc](http://localhost:9999/redoc)\n\n---\n\n## 🧪 Example Request\n\n### Headers Required:\n\n| Key | Example Value |\n|:---|:---|\n| user_name | john.doe@domain.com |\n| alm_confluence_base_url | https://your-confluence-site/wiki/rest/api |\n| alm_confluence_api_token | your-api-token |\n| wpb_confluence_base_url | (optional if available) |\n| wpb_confluence_api_token | (optional if available) |\n\n> ⚠️ If headers are missing or invalid, server will return HTTP 400 error.\n\n---\n\n### Example: Create Page\n\n**POST** `/create_page`\n\n```json\n{\n  \"space_key\": \"TEST\",\n  \"title\": \"Test Page Created by MCP Server\",\n  \"content\": \"<p>Hello, World!</p>\",\n  \"user_query\": \"Please create a page in GSNA knowledge base.\"\n}\n```\n\n**Behavior**:\n- Server will infer `wiki_type=alm` from user_query.\n- Create the page in Confluence and return page metadata.\n\n---\n\n## 🧠 Auto Inference Logic\n\n- If the query mentions `gsna`, `global`, `alm-confluence` → **alm**\n- If the query mentions `wpb`, `wealth` → **wpb**\n- Otherwise default to **alm**\n\n(You can also manually specify `wiki_type` in input)\n\n---\n\n## 🐳 Docker (Optional)\n\nBuild and run containerized server:\n\n```bash\ndocker build -t wiki-mcp-server .\ndocker run -d -p 9999:9999 --name wiki-mcp-server wiki-mcp-server\n```\n\n---\n\n## 📜 License\n\nMIT License.\n\n---\n\n## 📞 Contact\n\nFor issues or collaboration requests, please contact:\n\n- Developer: **Shawn**\n- Email: gsqasxb@gmail.com\n- Project maintained by internal MCP Working Group\n\n---# wiki_mcp_server\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "confluence",
        "wiki_mcp_server",
        "wiki",
        "confluence wiki",
        "manage confluence",
        "wiki pages"
      ],
      "category": "document-processing"
    },
    "aldrin-labs--solana-docs-mcp-server": {
      "owner": "aldrin-labs",
      "name": "solana-docs-mcp-server",
      "url": "https://github.com/aldrin-labs/solana-docs-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/aldrin-labs.webp",
      "description": "TypeScript-based MCP server that provides a system for creating and managing text notes, allowing access to notes via URIs along with metadata. It includes functionality for generating summaries of notes and listing note resources.",
      "stars": 4,
      "forks": 5,
      "license": "The Unlicense",
      "language": "JavaScript",
      "updated_at": "2025-05-09T16:21:36Z",
      "readme_content": "# solana-docs-server MCP Server\n[![smithery badge](https://smithery.ai/badge/@aldrin-labs/solana-docs-mcp-server)](https://smithery.ai/server/@aldrin-labs/solana-docs-mcp-server)\n\nsolana docs context\n\nThis is a TypeScript-based MCP server that implements a simple notes system. It demonstrates core MCP concepts by providing:\n\n- Resources representing text notes with URIs and metadata\n- Tools for creating new notes\n- Prompts for generating summaries of notes\n\n<a href=\"https://glama.ai/mcp/servers/v2cs13njts\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/v2cs13njts/badge\" alt=\"solana-docs-mcp-server MCP server\" /></a>\n\n## Features\n\n### Resources\n- List and access notes via `note://` URIs\n- Each note has a title, content and metadata\n- Plain text mime type for simple content access\n\n### Tools\n- `create_note` - Create new text notes\n  - Takes title and content as required parameters\n  - Stores note in server state\n\n### Prompts\n- `summarize_notes` - Generate a summary of all stored notes\n  - Includes all note contents as embedded resources\n  - Returns structured prompt for LLM summarization\n\n## Development\n\nInstall dependencies:\n```bash\nnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n```bash\nnpm run watch\n```\n\n## Installation\n\n### Installing via Smithery\n\nTo install solana-docs-server MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@aldrin-labs/solana-docs-mcp-server):\n\n```bash\nnpx -y @smithery/cli install @aldrin-labs/solana-docs-mcp-server --client claude\n```\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"solana-docs-server\": {\n      \"command\": \"/path/to/solana-docs-server/build/index.js\"\n    }\n  }\n}\n```\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "notes",
        "document",
        "docs",
        "note resources",
        "text notes",
        "notes listing"
      ],
      "category": "document-processing"
    },
    "alejandroBallesterosC--document-edit-mcp": {
      "owner": "alejandroBallesterosC",
      "name": "document-edit-mcp",
      "url": "https://github.com/alejandroBallesterosC/document-edit-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/alejandroBallesterosC.webp",
      "description": "Facilitates document manipulation across Microsoft Word, Excel, and PDF formats, enabling editing, creation, and conversion of various document types seamlessly.",
      "stars": 39,
      "forks": 9,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-09-24T04:37:49Z",
      "readme_content": "# Claude Document MCP Server\n\nA Model Context Protocol (MCP) server that allows Claude Desktop to perform document operations on Microsoft Word, Excel, and PDF files.\n\n## Features\n\n### Microsoft Word Operations\n- Create new Word documents from text\n- Edit existing Word documents (add/edit/delete paragraphs and headings)\n- Convert text files (.txt) to Word documents\n\n### Excel Operations\n- Create new Excel spreadsheets from JSON or CSV-like text\n- Edit existing Excel files (update cells, ranges, add/delete rows, columns, sheets)\n- Convert CSV files to Excel\n\n### PDF Operations\n- Create new PDF files from text\n- Convert Word documents to PDF files\n\n## Setup\n\nThis MCP server requires Python 3.10 or higher.\n\n### Automatic Setup (Recommended)\n\nRun the setup script to automatically install dependencies and configure for Claude Desktop:\n\n```bash\ngit clone https://github.com/alejandroBallesterosC/document-edit-mcp\ncd document-edit-mcp\n./setup.sh\n```\n\nThis will:\n1. Create a virtual environment\n2. Install required dependencies\n3. Configure the server for Claude Desktop\n4. Create necessary directories\n\n### Manual Setup\n\nIf you prefer to set up manually:\n\n1. Install dependencies:\n\n```bash\ncd claude-document-mcp\npython -m venv .venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\npip install -e .\n```\n\n2. Configure Claude Desktop:\n\nCopy the `claude_desktop_config.json` file to:\n- **Mac**: `~/Library/Application Support/Claude/`\n- **Windows**: `%APPDATA%\\Claude\\`\n\n3. Restart Claude Desktop\n\n## Model Context Protocol Integration\n\nThis server follows the Model Context Protocol specification to provide document manipulation capabilities for Claude Desktop:\n\n- **Tools**: Provides manipulations functions for Word, Excel, and PDF operations\n- **Resources**: Provides information about capabilities\n- **Prompts**: (none currently implemented)\n\n## API Reference\n\n### Microsoft Word\n\n#### Create a Word Document\n```\ncreate_word_document(filepath: str, content: str) -> Dict\n```\n\n#### Edit a Word Document\n```\nedit_word_document(filepath: str, operations: List[Dict]) -> Dict\n```\n\n#### Convert TXT to Word\n```\nconvert_txt_to_word(source_path: str, target_path: str) -> Dict\n```\n\n### Excel\n\n#### Create an Excel File\n```\ncreate_excel_file(filepath: str, content: str) -> Dict\n```\n\n#### Edit an Excel File\n```\nedit_excel_file(filepath: str, operations: List[Dict]) -> Dict\n```\n\n#### Convert CSV to Excel\n```\nconvert_csv_to_excel(source_path: str, target_path: str) -> Dict\n```\n\n### PDF\n\n#### Create a PDF File\n```\ncreate_pdf_file(filepath: str, content: str) -> Dict\n```\n\n#### Convert Word to PDF\n```\nconvert_word_to_pdf(source_path: str, target_path: str) -> Dict\n```\n\n## Logs\n\nThe server logs all operations to both the console and a `logs/document_mcp.log` file for troubleshooting.\n\n## License\n\nMIT\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "document",
        "editing",
        "formats",
        "document manipulation",
        "document edit",
        "facilitates document"
      ],
      "category": "document-processing"
    },
    "alekspetrov--mcp-docs-service": {
      "owner": "alekspetrov",
      "name": "mcp-docs-service",
      "url": "https://github.com/alekspetrov/mcp-docs-service",
      "imageUrl": "/freedevtools/mcp/pfp/alekspetrov.webp",
      "description": "Manage markdown documentation by creating, reading, updating, and deleting files while analyzing their health and improving quality. Enhance AI assistants' interactions with documentation through natural language processing capabilities.",
      "stars": 44,
      "forks": 9,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T22:32:19Z",
      "readme_content": "# MCP Documentation Service\n\n[![Test Coverage](https://codecov.io/gh/alekspetrov/mcp-docs-service/branch/main/graph/badge.svg)](https://codecov.io/gh/alekspetrov/mcp-docs-service)\n\n<a href=\"https://glama.ai/mcp/servers/icfujodcjd\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/icfujodcjd/badge\" />\n</a>\n\n## What is it?\n\nMCP Documentation Service is a Model Context Protocol (MCP) implementation for documentation management. It provides a set of tools for reading, writing, and managing markdown documentation with frontmatter metadata. The service is designed to work seamlessly with AI assistants like Claude in Cursor or Claude Desktop, making it easy to manage your documentation through natural language interactions.\n\n## Features\n\n- **Read and Write Documents**: Easily read and write markdown documents with frontmatter metadata\n- **Edit Documents**: Make precise line-based edits to documents with diff previews\n- **List and Search**: Find documents by content or metadata\n- **Navigation Generation**: Create navigation structures from your documentation\n- **Health Checks**: Analyze documentation quality and identify issues like missing metadata or broken links\n- **LLM-Optimized Documentation**: Generate consolidated single-document output optimized for large language models\n- **MCP Integration**: Seamless integration with the Model Context Protocol\n- **Frontmatter Support**: Full support for YAML frontmatter in markdown documents\n- **Markdown Compatibility**: Works with standard markdown files\n\n## Quick Start\n\n### Installation\n\nRequires Node to be installed on your machine.\n\n```bash\nnpm install -g mcp-docs-service\n```\n\nOr use directly with npx:\n\n```bash\nnpx mcp-docs-service /path/to/docs\n```\n\n### Cursor Integration\n\nTo use with Cursor, create a `.cursor/mcp.json` file in your project root:\n\n```json\n{\n  \"mcpServers\": {\n    \"docs-manager\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"mcp-docs-service\", \"/path/to/your/docs\"]\n    }\n  }\n}\n```\n\n### Claude Desktop Integration\n\nTo use MCP Docs Service with Claude Desktop:\n\n1. **Install Claude Desktop** - Download the latest version from [Claude's website](https://claude.ai/desktop).\n\n2. **Configure Claude Desktop for MCP**:\n\n   - Open Claude Desktop\n   - Click on the Claude menu and select \"Developer Settings\"\n   - This will create a configuration file at:\n     - macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n     - Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n\n3. **Edit the configuration file** to add the MCP Docs Service:\n\n```json\n{\n  \"mcpServers\": {\n    \"docs-manager\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"mcp-docs-service\", \"/path/to/your/docs\"]\n    }\n  }\n}\n```\n\nMake sure to replace `/path/to/your/docs` with the absolute path to your documentation directory.\n\n4. **Restart Claude Desktop** completely.\n\n5. **Verify the tool is available** - After restarting, you should see a green dot for docs-manager MCP tool (Cursor Settings > MCP)\n\n6. **Troubleshooting**:\n   - If the server doesn't appear, check the logs at:\n     - macOS: `~/Library/Logs/Claude/mcp*.log`\n     - Windows: `%APPDATA%\\Claude\\logs\\mcp*.log`\n   - Ensure Node.js is installed on your system\n   - Make sure the paths in your configuration are absolute and valid\n\n## Examples\n\n### Using with Claude in Cursor\n\nWhen using Claude in Cursor, you can invoke the tools in two ways:\n\n1. **Using Natural Language** (Recommended):\n   - Simply ask Claude to perform the task in plain English:\n\n```\nCan you search my documentation for anything related to \"getting started\"?\n```\n\n```\nPlease list all the markdown files in my docs directory.\n```\n\n```\nCould you check if there are any issues with my documentation?\n```\n\n2. **Using Direct Tool Syntax**:\n   - For more precise control, you can use the direct tool syntax:\n\n```\n@docs-manager mcp_docs_manager_read_document path=docs/getting-started.md\n```\n\n```\n@docs-manager mcp_docs_manager_list_documents recursive=true\n```\n\n```\n@docs-manager mcp_docs_manager_check_documentation_health\n```\n\n### Using with Claude Desktop\n\nWhen using Claude Desktop, you can invoke the tools in two ways:\n\n1. **Using Natural Language** (Recommended):\n\n```\nCan you read the README.md file for me?\n```\n\n```\nPlease find all documents that mention \"API\" in my documentation.\n```\n\n```\nI'd like you to check the health of our documentation and tell me if there are any issues.\n```\n\n2. **Using the Tool Picker**:\n   - Click the hammer icon in the bottom right corner of the input box\n   - Select \"docs-manager\" from the list of available tools\n   - Choose the specific tool you want to use\n   - Fill in the required parameters and click \"Run\"\n\nClaude will interpret your natural language requests and use the appropriate tool with the correct parameters. You don't need to remember the exact tool names or parameter formats - just describe what you want to do!\n\n### Common Tool Commands\n\nHere are some common commands you can use with the tools:\n\n#### Reading a Document\n\n```\n@docs-manager mcp_docs_manager_read_document path=docs/getting-started.md\n```\n\n#### Writing a Document\n\n```\n@docs-manager mcp_docs_manager_write_document path=docs/new-document.md content=\"---\ntitle: New Document\ndescription: A new document created with MCP Docs Service\n---\n\n# New Document\n\nThis is a new document created with MCP Docs Service.\"\n```\n\n#### Editing a Document\n\n```\n@docs-manager mcp_docs_manager_edit_document path=README.md edits=[{\"oldText\":\"# Documentation\", \"newText\":\"# Project Documentation\"}]\n```\n\n#### Searching Documents\n\n```\n@docs-manager mcp_docs_manager_search_documents query=\"getting started\"\n```\n\n#### Generating Navigation\n\n```\n@docs-manager mcp_docs_manager_generate_navigation\n```\n\n## Contributing\n\nContributions are welcome! Here's how you can contribute:\n\n1. Fork the repository\n2. Create a feature branch: `git checkout -b feature/my-feature`\n3. Commit your changes: `git commit -am 'Add my feature'`\n4. Push to the branch: `git push origin feature/my-feature`\n5. Submit a pull request\n\nPlease make sure your code follows the existing style and includes appropriate tests.\n\n## Testing and Coverage\n\nThe MCP Docs Service has comprehensive test coverage to ensure reliability and stability. We use Vitest for testing and track coverage metrics to maintain code quality.\n\n### Running Tests\n\n```bash\n# Run all tests\nnpm test\n\n# Run tests with coverage report\nnpm run test:coverage\n```\n\nThe test suite includes:\n\n- Unit tests for utility functions and handlers\n- Integration tests for document flow\n- End-to-end tests for the MCP service\n\nOur tests are designed to be robust and handle potential errors in the implementation, ensuring they pass even if there are issues with the underlying code.\n\n### Coverage Reports\n\nAfter running the coverage command, detailed reports are generated in the `coverage` directory:\n\n- HTML report: `coverage/index.html`\n- JSON report: `coverage/coverage-final.json`\n\nWe maintain high test coverage to ensure the reliability of the service, with a focus on testing critical paths and edge cases.\n\n## Documentation Health\n\nWe use the MCP Docs Service to maintain the health of our own documentation. The health score is based on:\n\n- Completeness of metadata (title, description, etc.)\n- Presence of broken links\n- Orphaned documents (not linked from anywhere)\n- Consistent formatting and style\n\nYou can check the health of your documentation with:\n\n```bash\nnpx mcp-docs-service --health-check /path/to/docs\n```\n\n### Consolidated Documentation for LLMs\n\nMCP Docs Service can generate a consolidated documentation file optimized for large language models. This feature is useful when you want to provide your entire documentation set to an LLM for context:\n\n```bash\n# Generate consolidated documentation with default filename (consolidated-docs.md)\nnpx mcp-docs-service --single-doc /path/to/docs\n\n# Generate with custom output filename\nnpx mcp-docs-service --single-doc --output my-project-context.md /path/to/docs\n\n# Limit the total tokens in the consolidated documentation\nnpx mcp-docs-service --single-doc --max-tokens 100000 /path/to/docs\n```\n\nThe consolidated output includes:\n\n- Project metadata (name, version, description)\n- Table of contents with token counts for each section\n- All documentation organized by section with clear separation\n- Token counting to help stay within LLM context limits\n\n### Resilient by Default\n\nMCP Docs Service is designed to be resilient by default. The service automatically handles incomplete or poorly structured documentation without failing:\n\n- Returns a minimum health score of 80 even with issues\n- Automatically creates missing documentation directories\n- Handles missing documentation directories gracefully\n- Continues processing even when files have errors\n- Provides lenient scoring for metadata completeness and broken links\n\nThis makes the service particularly useful for:\n\n- Legacy projects with minimal documentation\n- Projects in early stages of documentation development\n- When migrating documentation from other formats\n\nThe service will always provide helpful feedback rather than failing, allowing you to incrementally improve your documentation over time.\n\n## Version History\n\n### v0.6.0\n\n- Added LLM-optimized consolidated documentation feature (--single-doc flag)\n- Added token counting for each documentation section\n- Added consolidated document output customization (--output flag)\n- Added maximum token limit configuration (--max-tokens flag)\n\n### v0.5.2\n\n- Enhanced resilience by automatically creating missing documentation directories\n- Improved tolerance mode with a minimum health score of 80\n- Made tolerance mode the default for health checks\n- Updated health check tool description to mention tolerance mode\n\n### v0.5.1\n\n- Added tolerance mode to health checks\n- Fixed issues with test suite reliability\n- Improved error handling in document operations\n\n## Documentation\n\nFor more detailed information, check out our documentation:\n\n- [Getting Started Guide](https://github.com/alekspetrov/mcp-docs-service/blob/main/docs/guides/getting-started.md)\n- [MCP Integration Guide](https://github.com/alekspetrov/mcp-docs-service/blob/main/docs/guides/mcp-integration.md)\n- [MCP Protocol Usage](https://github.com/alekspetrov/mcp-docs-service/blob/main/docs/guides/mcp-protocol-usage.md)\n- [API Reference](https://github.com/alekspetrov/mcp-docs-service/blob/main/docs/api/tools-reference.md)\n- [Examples](https://github.com/alekspetrov/mcp-docs-service/blob/main/docs/examples/basic-usage.md)\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "documentation",
        "docs",
        "markdown",
        "docs service",
        "markdown documentation",
        "documentation creating"
      ],
      "category": "document-processing"
    },
    "anewkim--docusaurus": {
      "owner": "anewkim",
      "name": "docusaurus",
      "url": "https://github.com/anewkim/docusaurus",
      "imageUrl": "/freedevtools/mcp/pfp/anewkim.webp",
      "description": "Generate and deploy modern static websites efficiently, with features for live reloading during development and seamless deployment to GitHub Pages or other static hosting services. Provides an extensible framework for website management and content generation.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2023-02-23T08:59:06Z",
      "readme_content": "# Website\n\nThis website is built using [Docusaurus 2](https://docusaurus.io/), a modern static website generator.\n\n### Installation\n\n```\n$ yarn\n```\n\n### Local Development\n\n```\n$ yarn start\n```\n\nThis command starts a local development server and opens up a browser window. Most changes are reflected live without having to restart the server.\n\n### Build\n\n```\n$ yarn build\n```\n\nThis command generates static content into the `build` directory and can be served using any static contents hosting service.\n\n### Deployment\n\nUsing SSH:\n\n```\n$ USE_SSH=true yarn deploy\n```\n\nNot using SSH:\n\n```\n$ GIT_USER=<Your GitHub username> yarn deploy\n```\n\nIf you are using GitHub pages for hosting, this command is a convenient way to build the website and push to the `gh-pages` branch.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "anewkim",
        "docusaurus",
        "document",
        "processing anewkim",
        "anewkim docusaurus",
        "docusaurus generate"
      ],
      "category": "document-processing"
    },
    "antonioevans--context7": {
      "owner": "antonioevans",
      "name": "context7",
      "url": "https://github.com/antonioevans/context7",
      "imageUrl": "/freedevtools/mcp/pfp/antonioevans.webp",
      "description": "Fetches up-to-date, version-specific code documentation and examples from source libraries to enhance prompts, reducing reliance on outdated code and inaccurate APIs. Integrates real-time library documentation into LLM context to improve coding accuracy and productivity.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "",
      "updated_at": "2025-05-04T05:59:55Z",
      "readme_content": "# Context7 MCP - Up-to-date Code Docs For Any Prompt\n\n[![Website](https://img.shields.io/badge/Website-context7.com-blue)](https://context7.com) [![smithery badge](https://smithery.ai/badge/@upstash/context7-mcp)](https://smithery.ai/server/@upstash/context7-mcp) [<img alt=\"Install in VS Code (npx)\" src=\"https://img.shields.io/badge/VS_Code-VS_Code?style=flat-square&label=Install%20Context7%20MCP&color=0098FF\">](https://insiders.vscode.dev/redirect?url=vscode%3Amcp%2Finstall%3F%7B%22name%22%3A%22context7%22%2C%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22%40upstash%2Fcontext7-mcp%40latest%22%5D%7D)\n\n[![中文文档](https://img.shields.io/badge/docs-中文版-yellow)](./docs/README.zh-CN.md) [![한국어 문서](https://img.shields.io/badge/docs-한국어-green)](./docs/README.ko.md) [![Documentación en Español](https://img.shields.io/badge/docs-Español-orange)](./docs/README.es.md) [![Documentation en Français](https://img.shields.io/badge/docs-Français-blue)](./docs/README.fr.md) [![Documentação em Português (Brasil)](https://img.shields.io/badge/docs-Português%20(Brasil)-purple)](./docs/README.pt-BR.md) [![Documentazione in italiano](https://img.shields.io/badge/docs-Italian-red)](./docs/README.it.md) [![Dokumentasi Bahasa Indonesia](https://img.shields.io/badge/docs-Bahasa%20Indonesia-pink)](./docs/README.id-ID.md) [![Dokumentation auf Deutsch](https://img.shields.io/badge/docs-Deutsch-darkgreen)](./docs/README.de.md) [![Документация на русском языке](https://img.shields.io/badge/docs-Русский-darkblue)](./docs/README.ru.md)\n\n## ❌ Without Context7\n\nLLMs rely on outdated or generic information about the libraries you use. You get:\n\n- ❌ Code examples are outdated and based on year-old training data\n- ❌ Hallucinated APIs don't even exist\n- ❌ Generic answers for old package versions\n\n## ✅ With Context7\n\nContext7 MCP pulls up-to-date, version-specific documentation and code examples straight from the source — and places them directly into your prompt.\n\nAdd `use context7` to your prompt in Cursor:\n\n```txt\nCreate a basic Next.js project with app router. use context7\n```\n\n```txt\nCreate a script to delete the rows where the city is \"\" given PostgreSQL credentials. use context7\n```\n\nContext7 fetches up-to-date code examples and documentation right into your LLM's context.\n\n- 1️⃣ Write your prompt naturally\n- 2️⃣ Tell the LLM to `use context7`\n- 3️⃣ Get working code answers\n\nNo tab-switching, no hallucinated APIs that don't exist, no outdated code generations.\n\n## 🛠️ Getting Started\n\n### Requirements\n\n- Node.js >= v18.0.0\n- Cursor, Windsurf, Claude Desktop or another MCP Client\n\n### Installing via Smithery\n\nTo install Context7 MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@upstash/context7-mcp):\n\n```bash\nnpx -y @smithery/cli install @upstash/context7-mcp --client claude\n```\n\n### Install in Cursor\n\nGo to: `Settings` -> `Cursor Settings` -> `MCP` -> `Add new global MCP server`\n\nPasting the following configuration into your Cursor `~/.cursor/mcp.json` file is the recommended approach. You may also install in a specific project by creating `.cursor/mcp.json` in your project folder. See [Cursor MCP docs](https://docs.cursor.com/context/model-context-protocol) for more info.\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@upstash/context7-mcp@latest\"]\n    }\n  }\n}\n```\n\n<details>\n<summary>Alternative: Use Bun</summary>\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"command\": \"bunx\",\n      \"args\": [\"-y\", \"@upstash/context7-mcp@latest\"]\n    }\n  }\n}\n```\n\n</details>\n\n<details>\n<summary>Alternative: Use Deno</summary>\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"command\": \"deno\",\n      \"args\": [\"run\", \"--allow-net\", \"npm:@upstash/context7-mcp\"]\n    }\n  }\n}\n```\n\n</details>\n\n### Install in Windsurf\n\nAdd this to your Windsurf MCP config file. See [Windsurf MCP docs](https://docs.windsurf.com/windsurf/mcp) for more info.\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@upstash/context7-mcp@latest\"]\n    }\n  }\n}\n```\n\n### Install in VS Code\n\n[<img alt=\"Install in VS Code (npx)\" src=\"https://img.shields.io/badge/VS_Code-VS_Code?style=flat-square&label=Install%20Context7%20MCP&color=0098FF\">](https://insiders.vscode.dev/redirect?url=vscode%3Amcp%2Finstall%3F%7B%22name%22%3A%22context7%22%2C%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22%40upstash%2Fcontext7-mcp%40latest%22%5D%7D)\n[<img alt=\"Install in VS Code Insiders (npx)\" src=\"https://img.shields.io/badge/VS_Code_Insiders-VS_Code_Insiders?style=flat-square&label=Install%20Context7%20MCP&color=24bfa5\">](https://insiders.vscode.dev/redirect?url=vscode-insiders%3Amcp%2Finstall%3F%7B%22name%22%3A%22context7%22%2C%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22%40upstash%2Fcontext7-mcp%40latest%22%5D%7D)\n\nAdd this to your VS Code MCP config file. See [VS Code MCP docs](https://code.visualstudio.com/docs/copilot/chat/mcp-servers) for more info.\n\n```json\n{\n  \"servers\": {\n    \"Context7\": {\n      \"type\": \"stdio\",\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@upstash/context7-mcp@latest\"]\n    }\n  }\n}\n```\n\n### Install in Zed\n\nIt can be installed via [Zed Extensions](https://zed.dev/extensions?query=Context7) or you can add this to your Zed `settings.json`. See [Zed Context Server docs](https://zed.dev/docs/assistant/context-servers) for more info.\n\n```json\n{\n  \"context_servers\": {\n    \"Context7\": {\n      \"command\": {\n        \"path\": \"npx\",\n        \"args\": [\"-y\", \"@upstash/context7-mcp@latest\"]\n      },\n      \"settings\": {}\n    }\n  }\n}\n```\n\n### Install in Claude Code\n\nRun this command. See [Claude Code MCP docs](https://docs.anthropic.com/en/docs/agents-and-tools/claude-code/tutorials#set-up-model-context-protocol-mcp) for more info.\n\n```sh\nclaude mcp add context7 -- npx -y @upstash/context7-mcp@latest\n```\n\n### Install in Claude Desktop\n\nAdd this to your Claude Desktop `claude_desktop_config.json` file. See [Claude Desktop MCP docs](https://modelcontextprotocol.io/quickstart/user) for more info.\n\n```json\n{\n  \"mcpServers\": {\n    \"Context7\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@upstash/context7-mcp@latest\"]\n    }\n  }\n}\n```\n\n### Using Docker\n\nIf you prefer to run the MCP server in a Docker container:\n\n1.  **Build the Docker Image:**\n\n    First, create a `Dockerfile` in the project root (or anywhere you prefer):\n\n    <details>\n    <summary>Click to see Dockerfile content</summary>\n\n    ```Dockerfile\n    FROM node:18-alpine\n\n    WORKDIR /app\n\n    # Install the latest version globally\n    RUN npm install -g @upstash/context7-mcp@latest\n\n    # Expose default port if needed (optional, depends on MCP client interaction)\n    # EXPOSE 3000\n\n    # Default command to run the server\n    CMD [\"context7-mcp\"]\n    ```\n\n    </details>\n\n    Then, build the image using a tag (e.g., `context7-mcp`). **Make sure Docker Desktop (or the Docker daemon) is running.** Run the following command in the same directory where you saved the `Dockerfile`:\n\n    ```bash\n    docker build -t context7-mcp .\n    ```\n\n2. **Configure Your MCP Client:**\n\n    Update your MCP client's configuration to use the Docker command.\n\n    *Example for a cline_mcp_settings.json:*\n\n    ```json\n    {\n      \"mcpServers\": {\n        \"Сontext7\": {\n        \"autoApprove\": [],\n        \"disabled\": false,\n        \"timeout\": 60,\n          \"command\": \"docker\",\n          \"args\": [\"run\", \"-i\", \"--rm\", \"context7-mcp\"],\n          \"transportType\": \"stdio\"\n        }\n      }\n    }\n    ```\n\n    *Note: This is an example configuration. Please refer to the specific examples for your MCP client (like Cursor, VS Code, etc.) earlier in this README to adapt the structure (e.g., `mcpServers` vs `servers`). Also, ensure the image name in `args` matches the tag used during the `docker build` command.*\n\n### Environment Variables\n\n- `DEFAULT_MINIMUM_TOKENS`: Set the minimum token count for documentation retrieval (default: 10000).\n\nExamples:\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@upstash/context7-mcp@latest\"],\n      \"env\": {\n        \"DEFAULT_MINIMUM_TOKENS\": \"10000\"\n      }\n    }\n  }\n}\n```\n\n### Available Tools\n\n- `resolve-library-id`: Resolves a general library name into a Context7-compatible library ID.\n  - `libraryName` (required)\n- `get-library-docs`: Fetches documentation for a library using a Context7-compatible library ID.\n  - `context7CompatibleLibraryID` (required)\n  - `topic` (optional): Focus the docs on a specific topic (e.g., \"routing\", \"hooks\")\n  - `tokens` (optional, default 10000): Max number of tokens to return. Values less than the configured `DEFAULT_MINIMUM_TOKENS` value or the default value of 10000 are automatically increased to that value.\n\n## Development\n\nClone the project and install dependencies:\n\n```bash\nbun i\n```\n\nBuild:\n\n```bash\nbun run build\n```\n\n### Local Configuration Example\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"command\": \"npx\",\n      \"args\": [\"tsx\", \"/path/to/folder/context7-mcp/src/index.ts\"]\n    }\n  }\n}\n```\n\n### Testing with MCP Inspector\n\n```bash\nnpx -y @modelcontextprotocol/inspector npx @upstash/context7-mcp@latest\n```\n\n## Troubleshooting\n\n### ERR_MODULE_NOT_FOUND\n\nIf you see this error, try using `bunx` instead of `npx`.\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"command\": \"bunx\",\n      \"args\": [\"-y\", \"@upstash/context7-mcp@latest\"]\n    }\n  }\n}\n```\n\nThis often resolves module resolution issues, especially in environments where `npx` does not properly install or resolve packages.\n\n### ESM Resolution Issues\n\nIf you encounter an error like: `Error: Cannot find module 'uriTemplate.js'` try running with the `--experimental-vm-modules` flag:\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"--node-options=--experimental-vm-modules\",\n        \"@upstash/context7-mcp@1.0.6\"\n      ]\n    }\n  }\n}\n```\n\n### MCP Client Errors\n\n1. Try removing `@latest` from the package name.\n\n2. Try using `bunx` as an alternative.\n\n3. Try using `deno` as an alternative.\n\n4. Make sure you are using Node v18 or higher to have native fetch support with `npx`.\n\n## Disclaimer\n\nContext7 projects are community-contributed and while we strive to maintain high quality, we cannot guarantee the accuracy, completeness, or security of all library documentation. Projects listed in Context7 are developed and maintained by their respective owners, not by Context7. If you encounter any suspicious, inappropriate, or potentially harmful content, please use the \"Report\" button on the project page to notify us immediately. We take all reports seriously and will review flagged content promptly to maintain the integrity and safety of our platform. By using Context7, you acknowledge that you do so at your own discretion and risk.\n\n## Context7 In Media\n\n- [Better Stack: \"Free Tool Makes Cursor 10x Smarter\"](https://youtu.be/52FC3qObp9E)\n- [Cole Medin: \"This is Hands Down the BEST MCP Server for AI Coding Assistants\"](https://www.youtube.com/watch?v=G7gK8H6u7Rs)\n- [Income stream surfers: \"Context7 + SequentialThinking MCPs: Is This AGI?\"](https://www.youtube.com/watch?v=-ggvzyLpK6o)\n- [Julian Goldie SEO: \"Context7: New MCP AI Agent Update\"](https://www.youtube.com/watch?v=CTZm6fBYisc)\n- [JeredBlu: \"Context 7 MCP: Get Documentation Instantly + VS Code Setup\"](https://www.youtube.com/watch?v=-ls0D-rtET4)\n- [Income stream surfers: \"Context7: The New MCP Server That Will CHANGE AI Coding\"](https://www.youtube.com/watch?v=PS-2Azb-C3M)\n- [AICodeKing: \"Context7 + Cline & RooCode: This MCP Server Makes CLINE 100X MORE EFFECTIVE!\"](https://www.youtube.com/watch?v=qZfENAPMnyo)\n- [Sean Kochel: \"5 MCP Servers For Vibe Coding Glory (Just Plug-In & Go)\"](https://www.youtube.com/watch?v=LqTQi8qexJM)\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=upstash/context7&type=Date)](https://www.star-history.com/#upstash/context7&Date)\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "context7",
        "documentation",
        "document",
        "antonioevans context7",
        "processing antonioevans",
        "documentation llm"
      ],
      "category": "document-processing"
    },
    "arabold--docs-mcp-server": {
      "owner": "arabold",
      "name": "docs-mcp-server",
      "url": "https://github.com/arabold/docs-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/arabold.webp",
      "description": "Fetches and indexes documentation for various software libraries, packages, and APIs. Provides powerful search capabilities to enable AI systems to access the latest official documentation from multiple sources.",
      "stars": 661,
      "forks": 76,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T22:51:57Z",
      "readme_content": "# Docs MCP Server: Your AI's Up-to-Date Documentation Expert\n\nAI coding assistants often struggle with outdated documentation and hallucinations. The **Docs MCP Server** solves this by providing a personal, always-current knowledge base for your AI. It **indexes 3rd party documentation** from various sources (websites, GitHub, npm, PyPI, local files) and offers powerful, version-aware search tools via the Model Context Protocol (MCP).\n\nThis enables your AI agent to access the **latest official documentation**, dramatically improving the quality and reliability of generated code and integration details. It's **free**, **open-source**, runs **locally** for privacy, and integrates seamlessly into your development workflow.\n\n## Why Use the Docs MCP Server?\n\nLLM-assisted coding promises speed and efficiency, but often falls short due to:\n\n- 🌀 **Stale Knowledge:** LLMs train on snapshots of the internet and quickly fall behind new library releases and API changes.\n- 👻 **Code Hallucinations:** AI can invent plausible-looking code that is syntactically correct but functionally wrong or uses non-existent APIs.\n- ❓ **Version Ambiguity:** Generic answers rarely account for the specific version dependencies in your project, leading to subtle bugs.\n- ⏳ **Verification Overhead:** Developers spend valuable time double-checking AI suggestions against official documentation.\n\n**Docs MCP Server solves these problems by:**\n\n- ✅ **Providing Up-to-Date Context:** Fetches and indexes documentation directly from official sources (websites, GitHub, npm, PyPI, local files) on demand.\n- 🎯 **Delivering Version-Specific Answers:** Search queries can target exact library versions, ensuring information matches your project's dependencies.\n- 💡 **Reducing Hallucinations:** Grounds the LLM in real documentation for accurate examples and integration details.\n- ⚡ **Boosting Productivity:** Get trustworthy answers faster, integrated directly into your AI assistant workflow.\n\n## ✨ Key Features\n\n- **Accurate & Version-Aware AI Responses:** Provides up-to-date, version-specific documentation to reduce AI hallucinations and improve code accuracy.\n- **Broad Source Compatibility:** Scrapes documentation from websites, GitHub repos, package manager sites (npm, PyPI), and local file directories.\n- **Advanced Search & Processing:** Intelligently chunks documentation semantically, generates embeddings, and combines vector similarity with full-text search.\n- **Flexible Embedding Models:** Supports various providers including OpenAI (and compatible APIs), Google Gemini/Vertex AI, Azure OpenAI, and AWS Bedrock. Vector search is optional.\n- **Enterprise Authentication:** Optional OAuth2/OIDC authentication with dynamic client registration for secure deployments.\n- **Web Interface:** Easy-to-use web interface for searching and managing documentation.\n- **Local & Private:** Runs entirely on your machine, ensuring data and queries remain private.\n- **Free & Open Source:** Community-driven and freely available.\n- **Simple Deployment:** Easy setup via Docker or `npx`.\n- **Seamless Integration:** Works with MCP-compatible clients (like Claude, Cline, Roo).\n\n> **What is semantic chunking?**\n>\n> Semantic chunking splits documentation into meaningful sections based on structure—like headings, code blocks, and tables—rather than arbitrary text size. Docs MCP Server preserves logical boundaries, keeps code and tables intact, and removes navigation clutter from HTML docs. This ensures LLMs receive coherent, context-rich information for more accurate and relevant answers.\n\n## How to Run the Docs MCP Server\n\nChoose your deployment method:\n\n- [Standalone Server (Recommended)](#standalone-server-recommended)\n- [Embedded Server](#embedded-server)\n- [Advanced: Docker Compose (Scaling)](#advanced-docker-compose-scaling)\n\n## Standalone Server (Recommended)\n\nRun a standalone server that includes both MCP endpoints and web interface in a single process. This is the easiest way to get started.\n\n### Option 1: Docker\n\n1. **Install Docker.**\n2. **Start the server:**\n\n   ```bash\n   docker run --rm \\\n     -v docs-mcp-data:/data \\\n     -p 6280:6280 \\\n     ghcr.io/arabold/docs-mcp-server:latest \\\n     --protocol http --host 0.0.0.0 --port 6280\n   ```\n\n   **Optional:** Add `-e OPENAI_API_KEY=\"your-openai-api-key\"` to enable vector search for improved results.\n\n### Option 2: npx\n\n1. **Install Node.js 22.x or later.**\n2. **Start the server:**\n\n   ```bash\n   npx @arabold/docs-mcp-server@latest\n   ```\n\n   This will run the server on port 6280 by default.\n\n   **Optional:** Prefix with `OPENAI_API_KEY=\"your-openai-api-key\"` to enable vector search for improved results.\n\n### Configure Your MCP Client\n\nAdd this to your MCP settings (VS Code, Claude Desktop, etc.):\n\n```json\n{\n  \"mcpServers\": {\n    \"docs-mcp-server\": {\n      \"type\": \"sse\",\n      \"url\": \"http://localhost:6280/sse\",\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\n**Alternative connection types:**\n\n```jsonc\n// SSE (Server-Sent Events)\n\"type\": \"sse\", \"url\": \"http://localhost:6280/sse\"\n\n// HTTP (Streamable)\n\"type\": \"http\", \"url\": \"http://localhost:6280/mcp\"\n```\n\nRestart your AI assistant after updating the config.\n\n### Access the Web Interface\n\nOpen `http://localhost:6280` in your browser to manage documentation and monitor jobs.\n\n### CLI Usage with Standalone Server\n\nYou can also use CLI commands to interact with the local database:\n\n```bash\n# List indexed libraries\nOPENAI_API_KEY=\"your-key\" npx @arabold/docs-mcp-server@latest list\n\n# Search documentation\nOPENAI_API_KEY=\"your-key\" npx @arabold/docs-mcp-server@latest search react \"useState hook\"\n\n# Scrape new documentation (connects to running server's worker)\nnpx @arabold/docs-mcp-server@latest scrape react https://react.dev/reference/react --server-url http://localhost:6280/api\n```\n\n### Adding Library Documentation\n\n1. Open the Web Interface at `http://localhost:6280`.\n2. Use the \"Queue New Scrape Job\" form.\n3. Enter the documentation URL, library name, and (optionally) version.\n4. Click \"Queue Job\". Monitor progress in the Job Queue.\n5. Repeat for each library you want indexed.\n\nOnce a job completes, the docs are searchable via your AI assistant or the Web UI.\n\n\n\n**Benefits:**\n\n- Single command setup with both web UI and MCP server\n- Persistent data storage (Docker volume or local directory)\n- No repository cloning required\n- Full feature access including web interface\n\nTo stop the server, press `Ctrl+C`.\n\n## Embedded Server\n\nRun the MCP server directly embedded in your AI assistant without a separate process or web interface. This method provides MCP integration only.\n\n### Configure Your MCP Client\n\nAdd this to your MCP settings (VS Code, Claude Desktop, etc.):\n\n```json\n{\n  \"mcpServers\": {\n    \"docs-mcp-server\": {\n      \"command\": \"npx\",\n      \"args\": [\"@arabold/docs-mcp-server@latest\"],\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\n**Optional:** To enable vector search for improved results, add an `env` section with your API key:\n\n```json\n{\n  \"mcpServers\": {\n    \"docs-mcp-server\": {\n      \"command\": \"npx\",\n      \"args\": [\"@arabold/docs-mcp-server@latest\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"sk-proj-...\" // Your OpenAI API key\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\nRestart your application after updating the config.\n\n### Adding Library Documentation\n\n**Option 1: Use MCP Tools**\n\nYour AI assistant can index new documentation using the built-in `scrape_docs` tool:\n\n```\nPlease scrape the React documentation from https://react.dev/reference/react for library \"react\" version \"18.x\"\n```\n\n**Option 2: Launch Web Interface**\n\nStart a temporary web interface that shares the same database:\n\n```bash\nOPENAI_API_KEY=\"your-key\" npx @arabold/docs-mcp-server@latest web --port 6281\n```\n\nThen open `http://localhost:6281` to manage documentation. Stop the web interface when done (`Ctrl+C`).\n\n**Option 3: CLI Commands**\n\nUse CLI commands directly (avoid running scrape jobs concurrently with embedded server):\n\n```bash\n# List libraries\nOPENAI_API_KEY=\"your-key\" npx @arabold/docs-mcp-server@latest list\n\n# Search documentation\nOPENAI_API_KEY=\"your-key\" npx @arabold/docs-mcp-server@latest search react \"useState hook\"\n```\n\n**Benefits:**\n\n- Direct integration with AI assistant\n- No separate server process required\n- Persistent data storage in user's home directory\n- Shared database with standalone server and CLI\n\n**Limitations:**\n\n- No web interface (unless launched separately)\n- Documentation indexing requires MCP tools or separate commands\n\n## Scraping Local Files and Folders\n\nYou can index documentation from your local filesystem by using a `file://` URL as the source. This works in both the Web UI and CLI.\n\n**Examples:**\n\n- Web: `https://react.dev/reference/react`\n- Local file: `file:///Users/me/docs/index.html`\n- Local folder: `file:///Users/me/docs/my-library`\n\n**Requirements:**\n\n- All files with a MIME type of `text/*` are processed. This includes HTML, Markdown, plain text, and source code files such as `.js`, `.ts`, `.tsx`, `.css`, etc. Binary files, PDFs, images, and other non-text formats are ignored.\n- You must use the `file://` prefix for local files/folders.\n- The path must be accessible to the server process.\n- **If running in Docker:**\n  - You must mount the local folder into the container and use the container path in your `file://` URL.\n  - Example Docker run:\n    ```bash\n    docker run --rm \\\n      -e OPENAI_API_KEY=\"your-key\" \\\n      -v /absolute/path/to/docs:/docs:ro \\\n      -v docs-mcp-data:/data \\\n      -p 6280:6280 \\\n      ghcr.io/arabold/docs-mcp-server:latest \\\n      scrape mylib file:///docs/my-library\n    ```\n  - In the Web UI, enter the path as `file:///docs/my-library` (matching the container path).\n\nSee the tooltips in the Web UI and CLI help for more details.\n\n## Advanced: Docker Compose (Scaling)\n\nFor production deployments or when you need to scale processing, use Docker Compose to run separate services. The system selects either a local in-process worker or a remote worker client based on the configuration, ensuring consistent behavior across modes.\n\n**Start the services:**\n\n```bash\n# Clone the repository (to get docker-compose.yml)\ngit clone https://github.com/arabold/docs-mcp-server.git\ncd docs-mcp-server\n\n# Set your environment variables\nexport OPENAI_API_KEY=\"your-key-here\"\n\n# Start all services\ndocker compose up -d\n```\n\n**Service architecture:**\n\n- **Worker** (port 8080): Handles documentation processing jobs\n- **MCP Server** (port 6280): Provides `/sse` endpoint for AI tools\n- **Web Interface** (port 6281): Browser-based management interface\n\n**Configure your MCP client:**\n\n```json\n{\n  \"mcpServers\": {\n    \"docs-mcp-server\": {\n      \"type\": \"sse\",\n      \"url\": \"http://localhost:6280/sse\",\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\n**Alternative connection types:**\n\n```json\n// SSE (Server-Sent Events)\n\"type\": \"sse\", \"url\": \"http://localhost:6280/sse\"\n\n// HTTP (Streamable)\n\"type\": \"http\", \"url\": \"http://localhost:6280/mcp\"\n```\n\n**Access interfaces:**\n\n- Web Interface: `http://localhost:6281`\n- MCP Endpoint (HTTP): `http://localhost:6280/mcp`\n- MCP Endpoint (SSE): `http://localhost:6280/sse`\n\nThis architecture allows independent scaling of processing (workers) and user interfaces.\n\n## Configuration\n\nThe Docs MCP Server can run without any configuration and will use full-text search only. To enable vector search for improved results, configure an embedding provider via environment variables.\n\n### Command Line Argument Overrides\n\nMany CLI arguments can be overridden using environment variables. This is useful for Docker deployments, CI/CD pipelines, or setting default values.\n\n| Environment Variable       | CLI Argument           | Description                                     | Used by Commands          |\n| -------------------------- | ---------------------- | ----------------------------------------------- | ------------------------- |\n| `DOCS_MCP_STORE_PATH`      | `--store-path`         | Custom path for data storage directory          | all                       |\n| `DOCS_MCP_TELEMETRY`       | `--no-telemetry`       | Disable telemetry (`false` to disable)          | all                       |\n| `DOCS_MCP_PROTOCOL`        | `--protocol`           | MCP server protocol (auto, stdio, http)         | default, mcp              |\n| `DOCS_MCP_PORT`            | `--port`               | Server port                                     | default, mcp, web, worker |\n| `DOCS_MCP_WEB_PORT`        | `--port` (web command) | Web interface port (web command only)           | web                       |\n| `PORT`                     | `--port`               | Server port (fallback if DOCS_MCP_PORT not set) | default, mcp, web, worker |\n| `DOCS_MCP_HOST`            | `--host`               | Server host/bind address                        | default, mcp, web, worker |\n| `HOST`                     | `--host`               | Server host (fallback if DOCS_MCP_HOST not set) | default, mcp, web, worker |\n| `DOCS_MCP_EMBEDDING_MODEL` | `--embedding-model`    | Embedding model configuration                   | default, mcp, web, worker |\n| `DOCS_MCP_AUTH_ENABLED`    | `--auth-enabled`       | Enable OAuth2/OIDC authentication               | default, mcp              |\n| `DOCS_MCP_AUTH_ISSUER_URL` | `--auth-issuer-url`    | OAuth2 provider issuer/discovery URL            | default, mcp              |\n| `DOCS_MCP_AUTH_AUDIENCE`   | `--auth-audience`      | JWT audience claim (resource identifier)        | default, mcp              |\n\n**Usage Examples:**\n\n```bash\n# Set via environment variables\nexport DOCS_MCP_PORT=8080\nexport DOCS_MCP_HOST=0.0.0.0\nexport DOCS_MCP_EMBEDDING_MODEL=text-embedding-3-small\nnpx @arabold/docs-mcp-server@latest\n\n# Override with CLI arguments (takes precedence)\nDOCS_MCP_PORT=8080 npx @arabold/docs-mcp-server@latest --port 9090\n```\n\n### Embedding Provider Configuration\n\nThe Docs MCP Server is configured via environment variables. Set these in your shell, Docker, or MCP client config.\n\n| Variable                           | Description                                           |\n| ---------------------------------- | ----------------------------------------------------- |\n| `DOCS_MCP_EMBEDDING_MODEL`         | Embedding model to use (see below for options).       |\n| `OPENAI_API_KEY`                   | OpenAI API key for embeddings.                        |\n| `OPENAI_API_BASE`                  | Custom OpenAI-compatible API endpoint (e.g., Ollama). |\n| `GOOGLE_API_KEY`                   | Google API key for Gemini embeddings.                 |\n| `GOOGLE_APPLICATION_CREDENTIALS`   | Path to Google service account JSON for Vertex AI.    |\n| `AWS_ACCESS_KEY_ID`                | AWS key for Bedrock embeddings.                       |\n| `AWS_SECRET_ACCESS_KEY`            | AWS secret for Bedrock embeddings.                    |\n| `AWS_REGION`                       | AWS region for Bedrock.                               |\n| `AZURE_OPENAI_API_KEY`             | Azure OpenAI API key.                                 |\n| `AZURE_OPENAI_API_INSTANCE_NAME`   | Azure OpenAI instance name.                           |\n| `AZURE_OPENAI_API_DEPLOYMENT_NAME` | Azure OpenAI deployment name.                         |\n| `AZURE_OPENAI_API_VERSION`         | Azure OpenAI API version.                             |\n\nSee [examples above](#alternative-using-docker) for usage.\n\n### Embedding Model Options\n\nSet `DOCS_MCP_EMBEDDING_MODEL` to one of:\n\n- `text-embedding-3-small` (default, OpenAI)\n- `openai:snowflake-arctic-embed2` (OpenAI-compatible, Ollama)\n- `vertex:text-embedding-004` (Google Vertex AI)\n- `gemini:embedding-001` (Google Gemini)\n- `aws:amazon.titan-embed-text-v1` (AWS Bedrock)\n- `microsoft:text-embedding-ada-002` (Azure OpenAI)\n- Or any OpenAI-compatible model name\n\n### Provider-Specific Configuration Examples\n\nHere are complete configuration examples for different embedding providers:\n\n**OpenAI (Default):**\n\n```bash\nOPENAI_API_KEY=\"sk-proj-your-openai-api-key\" \\\nDOCS_MCP_EMBEDDING_MODEL=\"text-embedding-3-small\" \\\nnpx @arabold/docs-mcp-server@latest\n```\n\n**Ollama (Local):**\n\n```bash\nOPENAI_API_KEY=\"ollama\" \\\nOPENAI_API_BASE=\"http://localhost:11434/v1\" \\\nDOCS_MCP_EMBEDDING_MODEL=\"nomic-embed-text\" \\\nnpx @arabold/docs-mcp-server@latest\n```\n\n**LM Studio (Local):**\n\n```bash\nOPENAI_API_KEY=\"lmstudio\" \\\nOPENAI_API_BASE=\"http://localhost:1234/v1\" \\\nDOCS_MCP_EMBEDDING_MODEL=\"text-embedding-qwen3-embedding-4b\" \\\nnpx @arabold/docs-mcp-server@latest\n```\n\n**Google Gemini:**\n\n```bash\nGOOGLE_API_KEY=\"your-google-api-key\" \\\nDOCS_MCP_EMBEDDING_MODEL=\"gemini:embedding-001\" \\\nnpx @arabold/docs-mcp-server@latest\n```\n\n**Google Vertex AI:**\n\n```bash\nGOOGLE_APPLICATION_CREDENTIALS=\"/path/to/your/gcp-service-account.json\" \\\nDOCS_MCP_EMBEDDING_MODEL=\"vertex:text-embedding-004\" \\\nnpx @arabold/docs-mcp-server@latest\n```\n\n**AWS Bedrock:**\n\n```bash\nAWS_ACCESS_KEY_ID=\"your-aws-access-key-id\" \\\nAWS_SECRET_ACCESS_KEY=\"your-aws-secret-access-key\" \\\nAWS_REGION=\"us-east-1\" \\\nDOCS_MCP_EMBEDDING_MODEL=\"aws:amazon.titan-embed-text-v1\" \\\nnpx @arabold/docs-mcp-server@latest\n```\n\n**Azure OpenAI:**\n\n```bash\nAZURE_OPENAI_API_KEY=\"your-azure-openai-api-key\" \\\nAZURE_OPENAI_API_INSTANCE_NAME=\"your-instance-name\" \\\nAZURE_OPENAI_API_DEPLOYMENT_NAME=\"your-deployment-name\" \\\nAZURE_OPENAI_API_VERSION=\"2024-02-01\" \\\nDOCS_MCP_EMBEDDING_MODEL=\"microsoft:text-embedding-ada-002\" \\\nnpx @arabold/docs-mcp-server@latest\n```\n\nFor more architectural details, see the [ARCHITECTURE.md](ARCHITECTURE.md).\n\nFor enterprise authentication and security features, see the [Authentication Guide](docs/authentication.md).\n\n## Telemetry\n\nThe Docs MCP Server includes privacy-first telemetry to help improve the product. We collect anonymous usage data to understand how the tool is used and identify areas for improvement.\n\n### What We Collect\n\n- Command usage patterns and success rates\n- Tool execution metrics (counts, durations, error types)\n- Pipeline job statistics (progress, completion rates)\n- Service configuration patterns (auth enabled, read-only mode)\n- Performance metrics (response times, processing efficiency)\n- Protocol usage (stdio vs HTTP, transport modes)\n\n### What We DON'T Collect\n\n- Search query content or user input\n- URLs being scraped or accessed\n- Document content or scraped data\n- Authentication tokens or credentials\n- Personal information or identifying data\n\n### Disabling Telemetry\n\nYou can disable telemetry collection entirely:\n\n**Option 1: CLI Flag**\n\n```bash\nnpx @arabold/docs-mcp-server@latest --no-telemetry\n```\n\n**Option 2: Environment Variable**\n\n```bash\nDOCS_MCP_TELEMETRY=false npx @arabold/docs-mcp-server@latest\n```\n\n**Option 3: Docker**\n\n```bash\ndocker run \\\n  -e DOCS_MCP_TELEMETRY=false \\\n  -v docs-mcp-data:/data \\\n  -p 6280:6280 \\\n  ghcr.io/arabold/docs-mcp-server:latest\n```\n\nFor more details about our telemetry practices, see the [Telemetry Guide](docs/telemetry.md).\n\n## Development\n\nTo develop or contribute to the Docs MCP Server:\n\n- Fork the repository and create a feature branch.\n- Follow the code conventions in [ARCHITECTURE.md](ARCHITECTURE.md).\n- Write clear commit messages (see Git guidelines above).\n- Open a pull request with a clear description of your changes.\n\nFor questions or suggestions, open an issue.\n\n### Architecture\n\nFor details on the project's architecture and design principles, please see [ARCHITECTURE.md](ARCHITECTURE.md).\n\n_Notably, the vast majority of this project's code was generated by the AI assistant Cline, leveraging the capabilities of this very MCP server._\n\n## License\n\nThis project is licensed under the MIT License. See [LICENSE](LICENSE) for details.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "documentation",
        "document",
        "search",
        "document processing",
        "arabold docs",
        "indexes documentation"
      ],
      "category": "document-processing"
    },
    "arathald--mcp-editor": {
      "owner": "arathald",
      "name": "mcp-editor",
      "url": "https://github.com/arathald/mcp-editor",
      "imageUrl": "/freedevtools/mcp/pfp/arathald.webp",
      "description": "Edit files using a TypeScript MCP server, based on Anthropic's filesystem editing tools. It facilitates direct file manipulation while working with MCP protocols.",
      "stars": 7,
      "forks": 5,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-07-28T21:04:00Z",
      "readme_content": "# mcp-editor\nThis is a direct port of [Anthropic's filesystem editing tools](https://github.com/anthropics/anthropic-quickstarts/blob/main/computer-use-demo/computer_use_demo/tools/edit.py) from their computer use demos to a TypeScript MCP server. It was written largely by Claude Sonnet 3.5 on Roo Cline (now Roo Code) with probably not quite enough direct supervision. I checked over the code and use this server every day, but there may be mistakes or AI weirdness.\n\nI recommend using this server along with [mcp-server-commands](https://github.com/g0t4/mcp-server-commands)\n\n<a href=\"https://glama.ai/mcp/servers/lnfcd9is5i\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/lnfcd9is5i/badge\" alt=\"mcp-editor MCP server\" /></a>\n\n### ***WARNING: This MCP server has NO access controls and relies entirely on your client's approval mechanisms. Use at your own risk. DO NOT automatically approve write operations, doing so basically gives the LLM permission to destroy your computer.***\n### ***WARNING: This MCP server is NOT actively maintained, and is provided for reference (for example creating your own MCP server with proper access controls). I may update it occasionally.***\n\n## Usage\nGet the files on your computer.\nRun:\n```\nnpm install\nnpm build\n```\n\nIf you're using the Claude desktop app, paste this into your config under \"mcpServers\", and edit the path to match where you put mcp-editor:\n```json\n{\n  \"mcpServers\":\n... your existing servers ...\n    \"mcp-editor\": {\n      \"command\": \"node\",\n      \"args\": [\"/absolute/path/to/mcp-editor/dist/server.js\"]\n    }\n  }\n}\n```\n\nIf you're using [MCP Installer](https://github.com/anaisbetts/mcp-installer), you just need to provide your LLM with the path on your disk to mcp-editor.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "editor",
        "mcp",
        "typescript",
        "mcp editor",
        "typescript mcp",
        "edit files"
      ],
      "category": "document-processing"
    },
    "arre-ankit--notion-mcp-server": {
      "owner": "arre-ankit",
      "name": "notion-mcp-server",
      "url": "https://github.com/arre-ankit/notion-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/arre-ankit.webp",
      "description": "Query and manipulate Notion Pages by creating, reading, and updating content directly from prompts. Seamlessly manage Notion databases and enhance productivity through integration.",
      "stars": 0,
      "forks": 1,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2024-12-06T06:41:48Z",
      "readme_content": "### Notion MCP Server\n\nThis is a simple MCP server that allows you to query Notion Pages.\n\n### Installation\n\n```bash\ngit clone https://github.com/arre-ankit/notion-mcp-server.git\ncd notion-mcp-server\n```\n\n```bash\nnpm install\n```\n\n### Running the server\n\n```bash\nnpm run build\n```\n\n### Add Notion Integration\n- Go to https://www.notion.so/my-integrations\n- Click on \"New integration\"\n- Name it \"Claude MCP Server\"\n- Select \"Read\" and \"Write\" permissions for \"Pages\"\n- Copy the \"Integration Token\"\n\n### Add Claude Integration\nclaude_desktop_config.json\n```bash\n{\n  \"mcpServers\": \n    \"notion-mcp-server\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"Copy Path\"\n      ],\n      \"env\": {\n        \"NOTION_API_TOKEN\": \"Your Notion Token\"\n      }\n    }\n  }\n}\n```\n\n## How to use\n- Write a prompt to query Notion Pages.\n- Add link to the Notion Page from the link in the prompt.\n- Eg: https://www.notion.so/154916e48026802f97d4df6086787817\n\n\n\n\nPrompt: Make a new Databse entry in notion with this \nof list of movies to watch in 2024\nPage link https://www.notion.so/154916e48026802f97d4df6086787817 \nAdd the movie datase in this page\n\n\n\n\n![alt text](https://github.com/user-attachments/assets/64414f72-2965-4cf1-8e56-c231b88771a2)\n\n🤯 Woah it will be updated in your Notion Page!",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "notion",
        "databases",
        "document",
        "notion pages",
        "notion databases",
        "manage notion"
      ],
      "category": "document-processing"
    },
    "askjohngeorge--mcp-doc-scraper": {
      "owner": "askjohngeorge",
      "name": "mcp-doc-scraper",
      "url": "https://github.com/askjohngeorge/mcp-doc-scraper",
      "imageUrl": "/freedevtools/mcp/pfp/askjohngeorge.webp",
      "description": "Scrapes documentation from web URLs and converts it into markdown format, saving the converted documentation to a specified output path. Integrates with the Model Context Protocol (MCP) for enhanced data management.",
      "stars": 7,
      "forks": 4,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-05-30T20:44:57Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/askjohngeorge-mcp-doc-scraper-badge.png)](https://mseep.ai/app/askjohngeorge-mcp-doc-scraper)\n\n# Doc Scraper MCP Server\n[![smithery badge](https://smithery.ai/badge/@askjohngeorge/mcp-doc-scraper)](https://smithery.ai/server/@askjohngeorge/mcp-doc-scraper)\n\nA Model Context Protocol (MCP) server that provides documentation scraping functionality. This server converts web-based documentation into markdown format using jina.ai's conversion service.\n\n## Features\n\n- Scrapes documentation from any web URL\n- Converts HTML documentation to markdown format\n- Saves the converted documentation to a specified output path\n- Integrates with the Model Context Protocol (MCP)\n\n## Installation\n\n### Installing via Smithery\n\nTo install Doc Scraper for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@askjohngeorge/mcp-doc-scraper):\n\n```bash\nnpx -y @smithery/cli install @askjohngeorge/mcp-doc-scraper --client claude\n```\n\n1. Clone the repository:\n\n```bash\ngit clone https://github.com/askjohngeorge/mcp-doc-scraper.git\ncd mcp-doc-scraper\n```\n\n2. Create and activate a virtual environment:\n\n```bash\npython -m venv venv\nsource venv/bin/activate  # On Windows, use: venv\\Scripts\\activate\n```\n\n3. Install the dependencies:\n\n```bash\npip install -e .\n```\n\n## Usage\n\nThe server can be run using Python:\n\n```bash\npython -m mcp_doc_scraper\n```\n\n### Tool Description\n\nThe server provides a single tool:\n\n- **Name**: `scrape_docs`\n- **Description**: Scrape documentation from a URL and save as markdown\n- **Input Parameters**:\n  - `url`: The URL of the documentation to scrape\n  - `output_path`: The path where the markdown file should be saved\n\n## Project Structure\n\n```\ndoc_scraper/\n├── __init__.py\n├── __main__.py\n└── server.py\n```\n\n## Dependencies\n\n- aiohttp\n- mcp\n- pydantic\n\n## Development\n\nTo set up the development environment:\n\n1. Install development dependencies:\n\n```bash\npip install -r requirements.txt\n```\n\n2. The server uses the Model Context Protocol. Make sure to familiarize yourself with [MCP documentation](https://modelcontextprotocol.io/).\n\n## License\n\nMIT License\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "documentation",
        "markdown",
        "scraper",
        "scrapes documentation",
        "doc scraper",
        "mcp doc"
      ],
      "category": "document-processing"
    },
    "askme765cs--open-docs-mcp": {
      "owner": "askme765cs",
      "name": "open-docs-mcp",
      "url": "https://github.com/askme765cs/open-docs-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/askme765cs.webp",
      "description": "Crawl, index, and manage documentation while enabling full-text search across various document formats for efficient information retrieval. Integrates with AI to enhance document access and management capabilities.",
      "stars": 11,
      "forks": 4,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-09-10T16:24:01Z",
      "readme_content": "# open-docs-mcp MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@askme765cs/open-docs-mcp)](https://smithery.ai/server/@askme765cs/open-docs-mcp)\n[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)\n[![Node Version](https://img.shields.io/badge/node-%3E%3D16.0.0-brightgreen.svg)](package.json)\n[![TypeScript](https://img.shields.io/badge/TypeScript-4.9.5-blue.svg)](package.json)\n\nAn open-source MCP implementation providing document management functionality.\n[中文文档][url-doczh]\n\n## Features\n\n### Document Management\n- Crawl and index documentation from various sources\n- Support for multiple document formats\n- Full-text search capabilities\n\n### MCP Server API\n- Resource-based access to documents\n- Tool-based document management\n\n### Available Tools\n1. **enable_doc** - Enable crawling for a specific doc\n2. **disable_doc** - Disable crawling for a specific doc\n3. **crawl_docs** - Start crawling enabled docs\n4. **build_index** - Build search index for docs\n5. **search_docs** - Search documentation\n6. **list_enabled_docs** - List enabled docs\n7. **list_all_docs** - List all available docs\n\n### Cursor @Docs Compatibility\n\nThis project aims to replicate Cursor's @Docs functionality by providing:\n\n1. **Document Indexing**:\n   - Crawl and index documentation from various sources\n   - Support for multiple document formats (HTML, Markdown, etc.)\n   - Automatic re-indexing to keep docs up-to-date\n\n2. **Document Access**:\n   - Search across all indexed documentation\n   - Integration with MCP protocol for AI context\n\n3. **Custom Docs Management**:\n   - Add new documentation sources via `enable_doc` tool\n   - Manage enabled docs via `list_enabled_docs` tool\n   - Force re-crawl with `crawl_docs` tool\n\n### Architecture\n```\n┌───────────────────────────────────────────────────────┐\n│                    open-docs-mcp Server                    │\n├───────────────────┬───────────────────┬───────────────┤\n│   Crawler Module  │  Search Engine    │  MCP Server   │\n├───────────────────┼───────────────────┼───────────────┤\n│ - Web crawling    │ - Full-text index │ - Resources   │\n│ - Doc conversion  │ - Relevance score │ - Tools       │\n│ - Storage         │ - Query parsing   │ - Prompts     │\n└───────────────────┴───────────────────┴───────────────┘\n```\n\n## Usage\n\n```bash\nnpx -y open-docs-mcp --docsDir ./docs\n```\n\n### Installing via Smithery\n\nTo install Document Management Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@askme765cs/open-docs-mcp):\n\n```bash\nnpx -y @smithery/cli install @askme765cs/open-docs-mcp --client claude\n```\n\n### Configuration\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"open-docs-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"open-docs-mcp\",\n        \"--docsDir\",\n        \"/path/to/docs\"\n      ]\n    }\n  }\n}\n```\n\n**Configuration Options:**\n- `command`: Node.js executable\n- `args`: Array of arguments to pass to the script\n  - `--docsDir`: Required, specifies docs directory path\n- `disabled`: Set to true to temporarily disable the server\n- `alwaysAllow`: Array of tool names that can be used without confirmation\n\n## Development\n\n```bash\nnpm run watch  # Auto-rebuild on changes\nnpm run inspector  # Debug with MCP Inspector\n```\n\n## Contributing\nPull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.\n\n## License\n[MIT](LICENSE)\n\n[url-doczh]: README.zh-CN.md\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "document",
        "retrieval",
        "search",
        "document processing",
        "text search",
        "open docs"
      ],
      "category": "document-processing"
    },
    "aws-samples--sample-mcp-server-s3": {
      "owner": "aws-samples",
      "name": "sample-mcp-server-s3",
      "url": "https://github.com/aws-samples/sample-mcp-server-s3",
      "imageUrl": "/freedevtools/mcp/pfp/aws-samples.webp",
      "description": "Retrieve and manage PDF documents stored in AWS S3. Offers access to S3 buckets and their objects, enabling data retrieval for integration with AI models.",
      "stars": 65,
      "forks": 16,
      "license": "MIT No Attribution",
      "language": "Python",
      "updated_at": "2025-09-30T20:18:22Z",
      "readme_content": "# Sample S3 Model Context Protocol Server\n\nAn MCP server implementation for retrieving  data such as PDF's from S3.\n\n## Features\n### Resources\nExpose AWS S3 Data through **Resources**. (think of these sort of like GET endpoints; they are used to load information into the LLM's context). Currently only **PDF** documents supported and limited to **1000** objects.\n\n\n### Tools\n- **ListBuckets**\n  - Returns a list of all buckets owned by the authenticated sender of the request\n- **ListObjectsV2**\n  - Returns some or all (up to 1,000) of the objects in a bucket with each request\n- **GetObject**\n  - Retrieves an object from Amazon S3. In the GetObject request, specify the full key name for the object. General purpose buckets - Both the virtual-hosted-style requests and the path-style requests are supported\n\n\n## Configuration\n\n### Setting up AWS Credentials\n1. Obtain AWS access key ID, secret access key, and region from the AWS Management Console and configure credentials files using **Default** profile as shown [**here**](https://docs.aws.amazon.com/cli/v1/userguide/cli-configure-files.html)\n2. Ensure these credentials have appropriate permission READ/WRITE  permissions for S3.\n\n### Usage with Claude Desktop\n\n#### Claude Desktop\n\nOn MacOS: `~/Library/Application\\ Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n<details>\n  <summary>Development/Unpublished Servers Configuration</summary>\n\n```json\n{\n  \"mcpServers\": {\n    \"s3-mcp-server\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/Users/user/generative_ai/model_context_protocol/s3-mcp-server\",\n        \"run\",\n        \"s3-mcp-server\"\n      ]\n    }\n  }\n}\n```\n\n</details>\n\n<details>\n  <summary>Published Servers Configuration</summary>\n\n```json\n{\n  \"mcpServers\": {\n    \"s3-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"s3-mcp-server\"\n      ]\n    }\n  }\n}\n  ```\n</details>\n\n## Development\n\n### Building and Publishing\n\nTo prepare the package for distribution:\n\n1. Sync dependencies and update lockfile:\n```bash\nuv sync\n```\n\n2. Build package distributions:\n```bash\nuv build\n```\n\nThis will create source and wheel distributions in the `dist/` directory.\n\n3. Publish to PyPI:\n```bash\nuv publish\n```\n\nNote: You'll need to set PyPI credentials via environment variables or command flags:\n- Token: `--token` or `UV_PUBLISH_TOKEN`\n- Or username/password: `--username`/`UV_PUBLISH_USERNAME` and `--password`/`UV_PUBLISH_PASSWORD`\n\n### Debugging\n\nSince MCP servers run over stdio, debugging can be challenging. For the best debugging\nexperience, we strongly recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector).\n\n\nYou can launch the MCP Inspector via [`npm`](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm) with this command:\n\n```bash\nnpx @modelcontextprotocol/inspector uv --directory /Users/user/generative_ai/model_context_protocol/s3-mcp-server run s3-mcp-server\n```\n\n\nUpon launching, the Inspector will display a URL that you can access in your browser to begin debugging.\n\n\n## Security\n\nSee [CONTRIBUTING](CONTRIBUTING.md#security-issue-notifications) for more information.\n\n## License\n\nThis library is licensed under the MIT-0 License. See the LICENSE file.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "s3",
        "aws",
        "documents",
        "s3 retrieve",
        "aws s3",
        "processing aws"
      ],
      "category": "document-processing"
    },
    "benjamine--jsondiffpatch": {
      "owner": "benjamine",
      "name": "jsondiffpatch",
      "url": "https://github.com/benjamine/jsondiffpatch",
      "imageUrl": "/freedevtools/mcp/pfp/benjamine.webp",
      "description": "Diffs and patches JavaScript objects and arrays, enabling change tracking and state reversion through a simple API.",
      "stars": 5190,
      "forks": 490,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T23:55:05Z",
      "readme_content": "<p align=\"center\">\n  \n  <h1 align=\"center\">jsondiffpatch</h1>\n  <p align=\"center\">\n    <a href=\"https://jsondiffpatch.com\">jsondiffpatch.com</a>\n    <br/>\n    Diff & patch JavaScript objects\n  </p>\n</p>\n\n<!--- badges -->\n<p align=\"center\">\n  <a href=\"https://github.com/benjamine/jsondiffpatch/actions?query=branch%3Amaster\"><img src=\"https://github.com/benjamine/jsondiffpatch/actions/workflows/CI.yml/badge.svg?event=push&branch=master\" alt=\"JsonDiffPatch CI status\" /></a>\n  <a href=\"https://twitter.com/beneidel\" rel=\"nofollow\"><img src=\"https://img.shields.io/badge/created%20by-@beneidel-BACABA.svg\" alt=\"Created by Benjamin Eidelman\"></a>\n  <a href=\"https://opensource.org/licenses/MIT\" rel=\"nofollow\"><img src=\"https://img.shields.io/github/license/benjamine/jsondiffpatch\" alt=\"License\"></a>\n  <a href=\"https://www.npmjs.com/package/jsondiffpatch\" rel=\"nofollow\"><img src=\"https://img.shields.io/npm/dw/jsondiffpatch.svg\" alt=\"npm\"></a>\n  <a href=\"https://github.com/benjamine/jsondiffpatch\" rel=\"nofollow\"><img src=\"https://img.shields.io/github/stars/benjamine/jsondiffpatch\" alt=\"stars\"></a>\n</p>\n\n---\n\n## **[Live Demo](https://jsondiffpatch.com)**\n\n- min+gzipped ~ 16KB\n- browser and server (ESM-only)\n- deep diff, use delta to patch\n- smart array diffing using [LCS](http://en.wikipedia.org/wiki/Longest_common_subsequence_problem), **_IMPORTANT NOTE:_** to match objects inside an array you must provide an `objectHash` function (this is how objects are matched, otherwise a dumb match by position is used). For more details, check [Array diff documentation](docs/arrays.md)\n- (optionally) text diffing of long strings powered by [google-diff-match-patch](http://code.google.com/p/google-diff-match-patch/) (diff at character level)\n- reverse a delta, unpatch (eg. revert object to its original state using a delta)\n- multiple output formats:\n  - pure JSON, low footprint [delta format](docs/deltas.md)\n  - <span style=\"background-color: #bbffbb; color: black;\">visual</span> <span style=\"background-color: #ffbbbb; color:black; text-decoration: line-through\">diff</span> (html), see [demo](https://jsondiffpatch.com)\n  - annotated JSON (html), to help explain the delta format with annotations\n  - JSON Patch ([RFC 6902](https://datatracker.ietf.org/doc/html/rfc6902)), can generate patches, and also apply them\n  - console (colored), try running `./node_modules/.bin/jsondiffpatch left.json right.json`\n  - write your own! check [Formatters documentation](docs/formatters.md)\n- BONUS: `jsondiffpatch.clone(obj)` (deep clone)\n\n## Supported platforms\n\n- Any browser that [supports ES6](https://caniuse.com/es6)\n- Node.js 18, 20+\n\n## Usage\n\non your terminal:\n\n```sh\nnpx jsondiffpatch --help\n```\n\n\n\nor as a library:\n\n```ts\n// sample data\nconst country = {\n  name: 'Argentina',\n  capital: 'Buenos Aires',\n  independence: new Date(1816, 6, 9),\n};\n\n// clone country, using dateReviver for Date objects\nconst country2 = JSON.parse(JSON.stringify(country), jsondiffpatch.dateReviver);\n\n// make some changes\ncountry2.name = 'Republica Argentina';\ncountry2.population = 41324992;\ndelete country2.capital;\n\nconst delta = jsondiffpatch.diff(country, country2);\n\nassertSame(delta, {\n  name: ['Argentina', 'Republica Argentina'], // old value, new value\n  population: ['41324992'], // new value\n  capital: ['Buenos Aires', 0, 0], // deleted\n});\n\n// patch original\njsondiffpatch.patch(country, delta);\n\n// reverse diff\nconst reverseDelta = jsondiffpatch.reverse(delta);\n// also country2 can be return to original value with: jsondiffpatch.unpatch(country2, delta);\n\nconst delta2 = jsondiffpatch.diff(country, country2);\nassert(delta2 === undefined);\n// undefined => no difference\n```\n\nArray diffing:\n\n```ts\n// sample data\nconst country = {\n  name: 'Argentina',\n  cities: [\n    {\n      name: 'Buenos Aires',\n      population: 13028000,\n    },\n    {\n      name: 'Cordoba',\n      population: 1430023,\n    },\n    {\n      name: 'Rosario',\n      population: 1136286,\n    },\n    {\n      name: 'Mendoza',\n      population: 901126,\n    },\n    {\n      name: 'San Miguel de Tucuman',\n      population: 800000,\n    },\n  ],\n};\n\n// clone country\nconst country2 = JSON.parse(JSON.stringify(country));\n\n// delete Cordoba\ncountry.cities.splice(1, 1);\n\n// add La Plata\ncountry.cities.splice(4, 0, {\n  name: 'La Plata',\n});\n\n// modify Rosario, and move it\nconst rosario = country.cities.splice(1, 1)[0];\nrosario.population += 1234;\ncountry.cities.push(rosario);\n\n// create a configured instance, match objects by name\nconst diffpatcher = jsondiffpatch.create({\n  objectHash: function (obj) {\n    return obj.name;\n  },\n});\n\nconst delta = diffpatcher.diff(country, country2);\n\nassertSame(delta, {\n  cities: {\n    _t: 'a', // indicates this node is an array (not an object)\n    1: [\n      // inserted at index 1\n      {\n        name: 'Cordoba',\n        population: 1430023,\n      },\n    ],\n    2: {\n      // population modified at index 2 (Rosario)\n      population: [1137520, 1136286],\n    },\n    _3: [\n      // removed from index 3\n      {\n        name: 'La Plata',\n      },\n      0,\n      0,\n    ],\n    _4: [\n      // move from index 4 to index 2\n      '',\n      2,\n      3,\n    ],\n  },\n});\n```\n\nFor more example cases (nested objects or arrays, long text diffs) check `packages/jsondiffpatch/test/examples/`\n\nIf you want to understand deltas, see [delta format documentation](docs/deltas.md)\n\n## Installing\n\n### NPM\n\nThis works for node, or in browsers if you already do bundling on your app\n\n```sh\nnpm install jsondiffpatch\n```\n\n```js\nimport {* as jsondiffpatch} from 'jsondiffpatch';\nconst jsondiffpatchInstance = jsondiffpatch.create(options);\n```\n\n### browser\n\nIn a browser, you can load a bundle using a tool like [esm.sh](https://esm.sh) or [Skypack](https://www.skypack.dev).\n\n## Options\n\n```ts\nimport * as jsondiffpatch from 'jsondiffpatch';\n\n// Only import if you want text diffs using diff-match-patch\nimport { diff_match_patch } from '@dmsnell/diff-match-patch';\n\nconst jsondiffpatchInstance = jsondiffpatch.create({\n  // used to match objects when diffing arrays, by default only === operator is used\n  objectHash: function (obj) {\n    // this function is used only to when objects are not equal by ref\n    return obj._id || obj.id;\n  },\n  arrays: {\n    // default true, detect items moved inside the array (otherwise they will be registered as remove+add)\n    detectMove: true,\n    // default false, the value of items moved is not included in deltas\n    includeValueOnMove: false,\n  },\n  textDiff: {\n    // If using text diffs, it's required to pass in the diff-match-patch library in through this proprty.\n    // Alternatively, you can import jsondiffpatch using `jsondiffpatch/with-text-diffs` to avoid having to pass in diff-match-patch through the options.\n    diffMatchPatch: diff_match_patch,\n    // default 60, minimum string length (left and right sides) to use text diff algorithm: google-diff-match-patch\n    minLength: 60,\n  },\n  propertyFilter: function (name, context) {\n    /*\n       this optional function can be specified to ignore object properties (eg. volatile data)\n        name: property name, present in either context.left or context.right objects\n        context: the diff context (has context.left and context.right objects)\n      */\n    return name.slice(0, 1) !== '$';\n  },\n  cloneDiffValues: false /* default false. if true, values in the obtained delta will be cloned\n      (using jsondiffpatch.clone by default), to ensure delta keeps no references to left or right objects. this becomes useful if you're diffing and patching the same objects multiple times without serializing deltas.\n      instead of true, a function can be specified here to provide a custom clone(value).\n      */\n  omitRemovedValues: false /* if you don't need to unpatch (reverse deltas),\n      \"old\"/\"left\" values (removed or replaced) are not included in the delta.\n      you can set this to true to get more compact deltas.\n      */,\n});\n```\n\n## Visual Diff\n\n```html\n<!doctype html>\n<html>\n  <head>\n    <link rel=\"stylesheet\" href=\"./style.css\" type=\"text/css\" />\n    <link\n      rel=\"stylesheet\"\n      href=\"https://esm.sh/jsondiffpatch@0.6.0/lib/formatters/styles/html.css\"\n      type=\"text/css\"\n    />\n    <link\n      rel=\"stylesheet\"\n      href=\"https://esm.sh/jsondiffpatch@0.6.0/lib/formatters/styles/annotated.css\"\n      type=\"text/css\"\n    />\n  </head>\n  <body>\n    <div id=\"visual\"></div>\n    <hr />\n    <div id=\"annotated\"></div>\n    <script type=\"module\">\n      import * as jsondiffpatch from 'https://esm.sh/jsondiffpatch@0.6.0';\n      import * as annotatedFormatter from 'https://esm.sh/jsondiffpatch@0.6.0/formatters/annotated';\n      import * as htmlFormatter from 'https://esm.sh/jsondiffpatch@0.6.0/formatters/html';\n\n      const left = { a: 3, b: 4 };\n      const right = { a: 5, c: 9 };\n      const delta = jsondiffpatch.diff(left, right);\n\n      // beautiful html diff\n      document.getElementById('visual').innerHTML = htmlFormatter.format(\n        delta,\n        left,\n      );\n\n      // self-explained json\n      document.getElementById('annotated').innerHTML =\n        annotatedFormatter.format(delta, left);\n    </script>\n  </body>\n</html>\n```\n\nTo see formatters in action check the [Live Demo](https://jsondiffpatch.com).\n\nFor more details check [Formatters documentation](docs/formatters.md)\n\n## Plugins\n\n`diff()`, `patch()` and `reverse()` functions are implemented using Pipes & Filters pattern, making it extremely customizable by adding or replacing filters on a pipe.\n\nCheck [Plugins documentation](docs/plugins.md) for details.\n\n## Related Projects\n\n- [jsondiffpatch.net (C#)\n  ](https://github.com/wbish/jsondiffpatch.net)\n- [SystemTextJson.JsonDiffPatch\n  (C#)](https://github.com/weichch/system-text-json-jsondiffpatch)\n- [Go JSON Diff (and Patch)\n  ](https://github.com/yudai/gojsondiff)\n- [json-diff-patch (python)](https://github.com/apack1001/json-diff-patch)\n- [jsondiffpatch-react](https://github.com/bluepeter/jsondiffpatch-react), also check docs for [usage in react](/docs/react.md)\n\n## All contributors ✨\n\n<a href=\"https://github.com/benjamine/jsondiffpatch/graphs/contributors\">\n  <p align=\"center\">\n    <img width=\"720\" src=\"https://contrib.rocks/image?repo=benjamine/jsondiffpatch\" alt=\"A table of avatars from the project's contributors\" />\n  </p>\n</a>",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "jsondiffpatch",
        "diffs",
        "api",
        "jsondiffpatch diffs",
        "diffs patches",
        "patches javascript"
      ],
      "category": "document-processing"
    },
    "berlinbra--binary-reader-mcp": {
      "owner": "berlinbra",
      "name": "binary-reader-mcp",
      "url": "https://github.com/berlinbra/binary-reader-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/berlinbra.webp",
      "description": "Read and analyze binary files, extracting metadata and structure from various binary formats, including Unreal Engine assets. The server features an extensible architecture for adding support for new binary formats as needed.",
      "stars": 0,
      "forks": 2,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-01-31T02:33:09Z",
      "readme_content": "# Binary Reader MCP\n\nA Model Context Protocol server for reading and analyzing binary files. This server provides tools for reading and analyzing various binary file formats, with initial support for Unreal Engine asset files (.uasset).\n\n## Features\n\n- Read and analyze Unreal Engine .uasset files\n- Extract binary file metadata and structure\n- Auto-detect file formats\n- Extensible architecture for adding new binary format support\n\n## Installation\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/berlinbra/binary-reader-mcp.git\ncd binary-reader-mcp\n```\n\n2. Create a virtual environment and activate it:\n```bash\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n```\n\n3. Install dependencies:\n```bash\npip install -r requirements.txt\n```\n\n## Usage\n\nThe server provides several tools through the Model Context Protocol:\n\n### 1. Read Unreal Asset Files\n\n```python\n# Example usage through MCP\ntool: read-unreal-asset\narguments:\n    file_path: \"path/to/your/asset.uasset\"\n```\n\n### 2. Read Generic Binary Files\n\n```python\n# Example usage through MCP\ntool: read-binary-metadata\narguments:\n    file_path: \"path/to/your/file.bin\"\n    format: \"auto\"  # or \"unreal\", \"custom\"\n```\n\n## Development\n\n### Project Structure\n\n```\nbinary-reader-mcp/\n├── README.md\n├── requirements.txt\n├── main.py\n├── src/\n│   ├── __init__.py\n│   ├── binary_reader/\n│   │   ├── __init__.py\n│   │   ├── base_reader.py\n│   │   ├── unreal_reader.py\n│   │   └── utils.py\n│   ├── api/\n│   │   ├── __init__.py\n│   │   ├── routes.py\n│   │   └── schemas.py\n│   └── config.py\n└── tests/\n    ├── __init__.py\n    ├── test_binary_reader.py\n    └── test_api.py\n```\n\n### Adding New Binary Format Support\n\nTo add support for a new binary format:\n\n1. Create a new reader class that inherits from `BinaryReader`\n2. Implement the required methods (`read_header`, `read_metadata`)\n3. Add the new format to the format auto-detection logic\n4. Update the tools list to include the new format\n\n## Contributing\n\n1. Fork the repository\n2. Create your feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add some amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "binary",
        "formats",
        "files",
        "berlinbra binary",
        "binary files",
        "binary formats"
      ],
      "category": "document-processing"
    },
    "bettehub--laas-rag-mcp": {
      "owner": "bettehub",
      "name": "laas-rag-mcp",
      "url": "https://github.com/bettehub/laas-rag-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/bettehub.webp",
      "description": "Upload documents in PDF or CSV formats and perform natural language queries to retrieve relevant information. It features document segmentation and embedding storage using a Chroma vector store for efficient retrieval.",
      "stars": 1,
      "forks": 0,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-05-09T08:44:26Z",
      "readme_content": "# RAG API\n\n이 프로젝트는 문서 기반 질의응답 시스템을 구현한 FastAPI 기반의 API 서버입니다.\n\n## 기능\n\n1. 문서 업로드 및 벡터 스토어 저장\n\n   - PDF 및 CSV 파일 지원\n   - 문서 자동 분할 및 임베딩\n   - Chroma 벡터 스토어에 저장\n\n2. 문서 검색\n   - 자연어 쿼리 기반 검색\n   - 유사도 기반 문서 검색\n\n## 설치 방법\n\n1. 필요한 패키지 설치:\n\n```bash\npip install -r requirements.txt\n```\n\n2. 환경 변수 설정:\n\n```bash\nexport OPENAI_API_KEY=\"your-api-key\"\n```\n\n## 실행 방법\n\n```bash\npython main.py\n```\n\n서버가 http://localhost:8000 에서 실행됩니다.\n\n## API 엔드포인트\n\n1. 문서 업로드\n\n   - POST /upload\n   - multipart/form-data 형식으로 파일 업로드\n   - 지원 형식: PDF, CSV\n   - 파라미터:\n     - `files`: 업로드할 파일 목록 (필수)\n     - `vector_store_dir`: 벡터 스토어를 저장할 디렉토리 경로 (선택, 기본값: \"vector_store\")\n\n2. 문서 검색\n   - POST /query\n   - form-data 형식으로 파라미터 전달\n   - 파라미터:\n     - `query`: 검색 쿼리 (필수)\n     - `vector_store_dir`: 벡터 스토어 디렉토리 경로 (선택, 기본값: \"vector_store\")\n     - `k`: 검색할 문서 수 (선택, 기본값: 2)\n\n## API 문서\n\nFastAPI의 자동 생성 문서는 다음 URL에서 확인할 수 있습니다:\n\n- http://localhost:8000/docs\n- http://localhost:8000/redoc\n\n## 벡터 스토어 이전\n\n벡터 스토어에 저장된 파일을 다른 프로젝트에서 재사용하려면 다음과 같이 하면 됩니다:\n\n1. 원하는 벡터 스토어 디렉토리를 다른 프로젝트의 동일한 경로로 복사합니다.\n2. 다른 프로젝트에서도 다음 패키지들이 설치되어 있어야 합니다:\n   - langchain-chroma\n   - langchain-openai\n   - 기타 필요한 의존성 패키지들\n3. 동일한 임베딩 모델(OpenAIEmbeddings)을 사용해야 합니다.\n4. 필요한 환경 변수(예: OpenAI API 키)가 올바르게 설정되어 있어야 합니다.\n\n벡터 스토어를 다른 프로젝트로 이전할 때는 단순히 해당 디렉토리를 복사하는 것만으로도 충분합니다. 이렇게 하면 문서의 임베딩과 메타데이터가 모두 보존되어 새로운 프로젝트에서도 동일하게 사용할 수 있습니다.\n\n## 여러 벡터 스토어 사용하기\n\n이 프로젝트는 여러 개의 벡터 스토어를 동시에 사용할 수 있도록 설계되었습니다. 각 벡터 스토어는 서로 다른 디렉토리에 저장되며, API 호출 시 `vector_store_dir` 파라미터를 통해 원하는 벡터 스토어를 지정할 수 있습니다.\n\n예를 들어, 서로 다른 프로젝트나 문서 세트에 대해 별도의 벡터 스토어를 만들고 관리할 수 있습니다:\n\n```\nproject1_docs -> vector_store_project1\nproject2_docs -> vector_store_project2\nresearch_papers -> vector_store_research\n```\n\n이렇게 하면 각 문서 세트를 독립적으로 관리하고 검색할 수 있습니다.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "documents",
        "document",
        "retrieval",
        "document processing",
        "document segmentation",
        "upload documents"
      ],
      "category": "document-processing"
    },
    "bhouston--mcp-server-text-editor": {
      "owner": "bhouston",
      "name": "mcp-server-text-editor",
      "url": "https://github.com/bhouston/mcp-server-text-editor",
      "imageUrl": "/freedevtools/mcp/pfp/bhouston.webp",
      "description": "Manage and manipulate text files through a standardized API, enabling operations like viewing, editing, and creating files in various directories.",
      "stars": 28,
      "forks": 6,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-01T08:23:56Z",
      "readme_content": "# Claude Text Editor MCP Server\n\n[![npm version](https://img.shields.io/npm/v/mcp-server-text-editor.svg)](https://www.npmjs.com/package/mcp-server-text-editor)\n[![CI Status](https://github.com/bhouston/mcp-server-text-editor/actions/workflows/tests.yml/badge.svg)](https://github.com/bhouston/mcp-server-text-editor/actions/workflows/tests.yml)\n[![Test Coverage](https://img.shields.io/badge/coverage-90%89-green)](https://github.com/bhouston/mcp-server-text-editor)\n\n<p align=\"center\">\n  <img src=\"https://mintlify.s3.us-west-1.amazonaws.com/mcp/logo/dark.svg\" alt=\"Model Context Protocol Logo\" width=\"200\"/>\n</p>\n\nAn open-source implementation of the Claude built-in text editor tool as a [Model Context Protocol](https://www.anthropic.com/news/model-context-protocol) (MCP) server. This package provides the same functionality as [Claude's built-in text editor tool](https://docs.anthropic.com/en/docs/build-with-claude/tool-use/text-editor-tool), allowing you to view, edit, and create text files through a standardized API.\n\n## Features\n\n- **Identical API to Claude's Text Editor**: Implements the exact same interface as Claude's built-in text editor tool\n- **MCP Server Implementation**: Follows the Model Context Protocol standard for AI tool integration\n- **File Operations**:\n  - View file contents with optional line range specification\n  - Create new files\n  - Replace text in existing files\n  - Insert text at specific line numbers\n  - Undo previous edits\n\n## Supported Claude Text Editor Versions\n\nThis package implements an equivalent tool to [the built-in Claude text editor tool](https://docs.anthropic.com/en/docs/build-with-claude/tool-use/text-editor-tool) versions:\n\n- `text_editor_20241022` (Claude 3.5 Sonnet)\n- `text_editor_20250124` (Claude 3.7 Sonnet)\n\nBut using the tool name 'text_editor' to avoid name conflicts with built-in Claude tools.\n\n## Installation\n\n```bash\n# Install from npm\nnpm install mcp-server-text-editor\n\n# Or with pnpm\npnpm add mcp-server-text-editor\n```\n\n## Usage\n\n### Starting the Server\n\n```bash\n# Using npx\nnpx -y mcp-server-text-editor\n\n# Or if installed globally\nmcp-server-text-editor\n```\n\n### Configuring in Claude Desktop\n\n```json\n{\n  \"mcpServers\": {\n    \"textEditor\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"mcp-server-text-editor\"]\n    }\n  }\n}\n```\n\n### Tool Commands\n\n#### View\n\nView the contents of a file or directory.\n\n```json\n{\n  \"command\": \"view\",\n  \"path\": \"/path/to/file.js\",\n  \"view_range\": [1, 10] // Optional: Show lines 1-10 only\n}\n```\n\n#### Create\n\nCreate a new file with the specified content.\n\n```json\n{\n  \"command\": \"create\",\n  \"path\": \"/path/to/file.js\",\n  \"file_text\": \"console.log('Hello, world!');\"\n}\n```\n\n#### String Replace\n\nReplace text in a file.\n\n```json\n{\n  \"command\": \"str_replace\",\n  \"path\": \"/path/to/file.js\",\n  \"old_str\": \"console.log('Hello, world!');\",\n  \"new_str\": \"console.log('Hello, Claude!');\"\n}\n```\n\n#### Insert\n\nInsert text at a specific line.\n\n```json\n{\n  \"command\": \"insert\",\n  \"path\": \"/path/to/file.js\",\n  \"insert_line\": 5,\n  \"new_str\": \"// This line was inserted by Claude\"\n}\n```\n\n#### Undo Edit\n\nRevert the last edit made to a file.\n\n```json\n{\n  \"command\": \"undo_edit\",\n  \"path\": \"/path/to/file.js\"\n}\n```\n\n## Development\n\n### Prerequisites\n\n- Node.js 18+\n- pnpm\n\n### Setup\n\n```bash\n# Clone the repository\ngit clone https://github.com/bhouston/mcp-server-text-editor.git\ncd mcp-server-text-editor\n\n# Install dependencies\npnpm install\n\n# Build the project\npnpm build\n```\n\n### Scripts\n\n- `pnpm build`: Build the TypeScript project\n- `pnpm lint`: Run ESLint with auto-fixing\n- `pnpm format`: Format code with Prettier\n- `pnpm clean`: Remove build artifacts\n- `pnpm clean:all`: Remove build artifacts and node_modules\n- `pnpm test`: Run tests\n- `pnpm test:coverage`: Run tests with coverage report\n\n### Testing\n\nThis project uses Vitest for testing.\n\nTo run the tests:\n\n```bash\n# Run all tests\npnpm test\n\n# Run tests with coverage report\npnpm test:coverage\n```\n\nThe test coverage report will be generated in the `coverage` directory.\n\n## License\n\nMIT\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n1. Fork the repository\n2. Create your feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add some amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "editor",
        "bhouston",
        "document",
        "text editor",
        "document processing",
        "bhouston mcp"
      ],
      "category": "document-processing"
    },
    "box-community--mcp-server-box": {
      "owner": "box-community",
      "name": "mcp-server-box",
      "url": "https://github.com/box-community/mcp-server-box",
      "imageUrl": "/freedevtools/mcp/pfp/box-community.webp",
      "description": "Integrate with the Box API to perform file operations, including file search, text extraction, and AI-based querying. Manage and process Box data efficiently with advanced AI capabilities.",
      "stars": 76,
      "forks": 27,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-01T22:21:03Z",
      "readme_content": "# Box MCP Server\n\n## Quick Start\n\n### Clone the repository:\n\n```sh\ngit clone https://github.com/box-community/mcp-server-box.git\ncd mcp-server-box\n```\n\n### Optional but recommended `uv` installation for virtual environment and dependency management:\n\n#### Homebrew (macOS)\n```sh\nbrew install uv\n```\n\n#### WinGet (Windows)\n```sh\nwinget install --id=astral-sh.uv  -e\n```\n\n#### On macOS and Linux\n```sh\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n```\n\n#### On Windows\n```sh\npowershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n```\n\n### Set up the virtual environment and install dependencies:\n\n```sh\nuv sync\n```\n\n### Set environment variables:\nSet the following environment variables for Box authentication in a `.env` file or your system environment:\n\n#### Using OAuth2.0 with a Box App\n```\nBOX_CLIENT_ID = YOUR_CLIENT_ID\nBOX_CLIENT_SECRET = YOUR_CLIENT_SECRET\nBOX_REDIRECT_URL = http://localhost:8000/callback\n\nBOX_MCP_SERVER_AUTH_TOKEN = YOUR_BOX_MCP_SERVER_AUTH_TOKEN\n```\n\n#### Using CCG with a Box App\n```\nBOX_CLIENT_ID = YOUR_CLIENT_ID\nBOX_CLIENT_SECRET = YOUR_CLIENT_SECRET\nBOX_SUBJECT_TYPE = user_or_enterprise\nBOX_SUBJECT_ID = YOUR_USER_OR_ENTERPRISE_ID\n\nBOX_MCP_SERVER_AUTH_TOKEN = YOUR_BOX_MCP_SERVER_AUTH_TOKEN\n```\n\n> Note: The `BOX_MCP_SERVER_AUTH_TOKEN` is the token used to authenticate requests to the Box MCP server. You can generate this token.\n\n### Run the MCP server in STDIO mode:\n```sh\nuv run src/mcp_server_box.py\n```\n\n## Box Community MCP Server Tools\n\nBelow is a summary of the available tools:\n\n| Tools available          | Description                                      |\n|--------------------------|--------------------------------------------------|\n| [box_tools_ai](docs/box_tools_ai.md) | AI-powered file and hub queries                  |\n| [box_tools_collaboration](docs/box_tools_collaboration.md)  | Manage file/folder collaborations                |\n| [box_tools_docgen](docs/box_tools_docgen.md)         | Document generation and template management      |\n| [box_tools_files](docs/box_tools_files.md)          | File operations (read, upload, download)         |\n| [box_tools_folders](docs/box_tools_folders.md)        | Folder operations (list, create, delete, update) |\n| [box_tools_generic](docs/box_tools_generic.md)        | Generic Box API utilities                        |\n| [box_tools_groups](docs/box_tools_groups.md)         | Group management and queries                     |\n| [box_tools_metadata](docs/box_tools_metadata.md)       | Metadata template and instance management        |\n| [box_tools_search](docs/box_tools_search.md)         | Search files and folders                         |\n| [box_tools_shared_links](docs/box_tools_shared_links.md)   | Shared link management for files/folders/web-links|\n| [box_tools_users](docs/box_tools_users.md)          | User management and queries                      |\n| [box_tools_web_link](docs/box_tools_web_link.md)       | Web link creation and management                 |\n\n## Box Community MCP Server Operations Details\n\n### Command line interface parameters\nTo run the MCP server with specific configurations, you can use the following command line parameters:\n```sh\nuv run src/mcp_server_box.py --help\n```\n```\nusage: mcp_server_box.py [-h] [--transport {stdio,sse,streamable-http}] [--host HOST]\n                         [--port PORT] [--box-auth {oauth,ccg}] [--no-mcp-server-auth]\n\nBox Community MCP Server\n\noptions:\n  -h, --help            show this help message and exit\n  --transport {stdio,sse,streamable-http}\n                        Transport type (default: stdio)\n  --host HOST           Host for SSE/HTTP transport (default: 0.0.0.0)\n  --port PORT           Port for SSE/HTTP transport (default: 8000)\n  --box-auth {oauth,ccg}\n                        Authentication type for Box API (default: oauth)\n  --no-mcp-server-auth  Disable authentication (for development only)\n  ```\n\n### Claude Desktop Configuration\nEdit your `claude_desktop_config.json`:\n\n```code ~/Library/Application\\ Support/Claude/claude_desktop_config.json```\n\nAdd the configuration:\n```json\n{\n    \"mcpServers\": {\n        \"mcp-server-box\": {\n            \"command\": \"uv\",\n            \"args\": [\n                \"--directory\",\n                \"/path/to/mcp-server-box\",\n                \"run\",\n                \"src/mcp_server_box.py\"\n            ]\n        }\n    }\n}\n```\n\nRestart Claude if it is running.\n\n### Cursor Configuration\n\nCursor supports MCP servers through its configuration file. Here's how to set it up:\n\nThe Cursor MCP configuration file is located at:\n- **macOS/Linux**: `~/.cursor/config.json` or `~/.config/cursor/config.json`\n- **Windows**: `%APPDATA%\\Cursor\\config.json`\n\n#### Add the MCP Server Configuration: STDIO Transport\n\nEdit your Cursor configuration file and add the following under the `mcpServers` section:\n```json\n{\n    \"mcpServers\": {\n        \"mcp-server-box\": {\n            \"command\": \"uv\",\n            \"args\": [\n                \"--directory\",\n                \"/path/to/mcp-server-box\",\n                \"run\",\n                \"src/mcp_server_box.py\"\n            ],\n            \"env\": {\n                \"BOX_CLIENT_ID\": \"YOUR_CLIENT_ID\",\n                \"BOX_CLIENT_SECRET\": \"YOUR_CLIENT_SECRET\",\n                \"BOX_REDIRECT_URL\": \"http://localhost:8000/callback\"\n            }\n        }\n    }\n}",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "processing",
        "mcp",
        "box",
        "processing box",
        "process box",
        "document processing"
      ],
      "category": "document-processing"
    },
    "breezedeus--CnOCR": {
      "owner": "breezedeus",
      "name": "CnOCR",
      "url": "https://github.com/breezedeus/CnOCR",
      "imageUrl": "/freedevtools/mcp/pfp/breezedeus.webp",
      "description": "Enables optical character recognition for Chinese, English, and numbers using pre-trained models or custom training. Provides powerful text recognition capabilities for a variety of applications.",
      "stars": 3659,
      "forks": 528,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-10-03T14:15:19Z",
      "readme_content": "<div align=\"center\">\n  \n  <div>&nbsp;</div>\n\n[![Discord](https://img.shields.io/discord/1200765964434821260?label=Discord)](https://discord.gg/GgD87WM8Tf)\n[![Downloads](https://static.pepy.tech/personalized-badge/cnocr?period=total&units=international_system&left_color=grey&right_color=orange&left_text=Downloads)](https://pepy.tech/project/cnocr)\n[](https://visitorbadge.io/status?path=https%3A%2F%2Fgithub.com%2Fbreezedeus%2FCnOCR)\n[![license](https://img.shields.io/github/license/breezedeus/cnocr)](./LICENSE)\n[![Docs](https://readthedocs.org/projects/cnocr/badge/?version=latest)](https://cnocr.readthedocs.io/zh-cn/stable/?badge=latest)\n[![PyPI version](https://badge.fury.io/py/cnocr.svg)](https://badge.fury.io/py/cnocr)\n[![forks](https://img.shields.io/github/forks/breezedeus/cnocr)](https://github.com/breezedeus/cnocr)\n[![stars](https://img.shields.io/github/stars/breezedeus/cnocr)](https://github.com/breezedeus/cnocr)\n![last-releast](https://img.shields.io/github/release-date/breezedeus/cnocr)\n![last-commit](https://img.shields.io/github/last-commit/breezedeus/cnocr)\n[![Twitter](https://img.shields.io/twitter/url?url=https%3A%2F%2Ftwitter.com%2Fbreezedeus)](https://twitter.com/breezedeus)\n\n[📖 文档](https://cnocr.readthedocs.io/zh-cn/stable/) |\n[🛠️ 安装](https://cnocr.readthedocs.io/zh-cn/stable/install/) |\n[🧳 可用模型](https://cnocr.readthedocs.io/zh-cn/stable/models/) |\n[🕹 模型训练](https://cnocr.readthedocs.io/zh-cn/stable/train/) |\n[🛀🏻 在线Demo](https://huggingface.co/spaces/breezedeus/CnOCR-Demo) |\n[💬 交流群](https://www.breezedeus.com/article/join-group)\n\n</div>\n\n<div align=\"center\">\n\n[English](./README_en.md) | 中文\n\n</div>\n\n# CnOCR\n\n<div align=\"center\">\n<strong>Tech should serve the people, not enslave them!</strong>\n<br>\n<strong>请勿将此项目用于文字审查！</strong>\n<br>\n---\n</div>\n\n### Update 2025.06.26：发布 V2.3.2\n\n主要变更：\n\n* 集成 PPOCRv5 最新版 OCR 模型\n  * 新增支持 PP-OCRv5 识别模型：`ch_PP-OCRv5` 和 `ch_PP-OCRv5_server`\n\n\n### [Update 2024.11.30]：发布 V2.3.1\n\n主要变更：\n\n* 基于 RapidOCR 集成 PPOCRv4 最新版 OCR 模型，提供更多的模型选择\n  * 新增支持 PP-OCRv4  识别模型，包括标准版和服务器版\n* 修改读文件实现方式，支持 Windows 的中文路径\n* 修复Bug：当使用多个进程时，transform_func 无法序列化\n* 修复Bug：与 albumentations=1.4.* 兼容\n\n### [Update 2023.12.24]：发布 V2.3\n\n主要变更：\n\n* 重新训练了所有的模型，比上一版精度更高。\n* 按使用场景把模型分为几大类场景（见 [识别模型列表](#可使用的识别模型)）：\n  * `scene`：场景图片，适合识别一般拍照图片中的文字。此类模型以 `scene-` 开头，如模型 `scene-densenet_lite_136-gru`。\n  * `doc`：文档图片，适合识别规则文档的截图图片，如书籍扫描件等。此类模型以 `doc-` 开头，如模型 `doc-densenet_lite_136-gru`。\n  * `number`：仅识别**纯数字**（只能识别 `0~9` 十个数字）图片，适合银行卡号、身份证号等场景。此类模型以 `number-` 开头，如模型 `number-densenet_lite_136-gru`。\n  * `general`: 通用场景，适合图片无明显倾向的一般图片。此类模型无特定开头，与旧版模型名称保持一致，如模型 `densenet_lite_136-gru`。\n  > 注意 ⚠️：以上说明仅为参考，具体选择模型时建议以实际效果为准。\n* 加入了两个更大的系列模型：\n  * `*-densenet_lite_246-gru_base`：优先供 **知识星球** [**CnOCR/CnSTD私享群**](https://t.zsxq.com/FEYZRJQ) 会员使用，一个月后会免费开源。\n  * `*-densenet_lite_666-gru_large`：Pro 模型，购买后可使用。\n  \n更多细节请参考：[CnOCR V2.3 新版发布：模型更好、更多、更大 | Breezedeus.com](https://www.breezedeus.com/article/cnocr-v2.3-better-more)。\n\n\n\n[**CnOCR**](https://github.com/breezedeus/cnocr) 是 **Python 3** 下的**文字识别**（**Optical Character Recognition**，简称**OCR**）工具包，支持**简体中文**、**繁体中文**（部分模型）、**英文**和**数字**的常见字符识别，支持竖排文字的识别。自带了**20+个** [训练好的模型](https://cnocr.readthedocs.io/zh-cn/stable/models/)，适用于不同应用场景，安装后即可直接使用。同时，CnOCR也提供简单的[训练命令](https://cnocr.readthedocs.io/zh-cn/stable/train/)供使用者训练自己的模型。欢迎扫码加小助手为好友，备注 `ocr`，小助手会定期统一邀请大家入群：\n\n<div align=\"center\">\n  <img src=\"https://huggingface.co/datasets/breezedeus/cnocr-wx-qr-code/resolve/main/wx-qr-code.JPG\" alt=\"微信群二维码\" width=\"300px\"/>\n</div>\n\n\n作者也维护 **知识星球** [**CnOCR/CnSTD私享群**](https://t.zsxq.com/FEYZRJQ) ，这里面的提问会较快得到作者的回复，欢迎加入。**知识星球会员** 可享受以下福利：\n\n- 可免费下载部分**未开源的付费模型**；\n- 购买其他所有的付费模型一律八折优化；\n- 作者快速回复使用过程中遇到的各种困难；\n- 作者每月提供两次免费特有数据的训练服务。\n- 星球会陆续发布一些CnOCR/CnSTD相关的私有资料；\n- 星球会持续发布 OCR/STD/CV 等相关的最新研究资料。\n\n\n\n## 详细文档\n\n见 [CnOCR在线文档](https://cnocr.readthedocs.io/) 。\n\n## 使用说明\n\n**CnOCR** 从 **V2.2** 开始，内部自动调用文字检测引擎 **[CnSTD](https://github.com/breezedeus/cnstd)** 进行文字检测和定位。所以 **CnOCR** V2.2 不仅能识别排版简单的印刷体文字图片，如截图图片，扫描件等，也能识别**一般图片中的场景文字**。\n\n以下是一些不同场景的调用示例。\n\n\n\n## 不同场景的调用示例\n\n### 常见的图片识别\n\n所有参数都使用默认值即可。如果发现效果不够好，多调整下各个参数看效果，最终往往能获得比较理想的精度。\n\n```python\nfrom cnocr import CnOcr\n\nimg_fp = './docs/examples/huochepiao.jpeg'\nocr = CnOcr()  # 所有参数都使用默认值\nout = ocr.ocr(img_fp)\n\nprint(out)\n```\n\n识别结果：\n\n<div align=\"center\">\n  \n</div>\n\n\n### 排版简单的印刷体截图图片识别\n\n针对 **排版简单的印刷体文字图片**，如截图图片，扫描件图片等，可使用 `det_model_name='naive_det'`，相当于不使用文本检测模型，而使用简单的规则进行分行。\n\n> **Note**\n>\n>  `det_model_name='naive_det'` 的效果相当于 `V2.2` 之前（`V2.0.*`, `V2.1.*`）的 CnOCR 版本。\n\n使用 `det_model_name='naive_det'` 的最大优势是**速度快**，劣势是对图片比较挑剔。如何判断是否该使用此检测模型呢？最简单的方式就是拿应用图片试试效果，效果好就用，不好就不用。\n\n```python\nfrom cnocr import CnOcr\n\nimg_fp = './docs/examples/multi-line_cn1.png'\nocr = CnOcr(det_model_name='naive_det') \nout = ocr.ocr(img_fp)\n\nprint(out)\n```\n\n识别结果：\n\n<div align=\"center\">\n\n| 图片                                                                      | OCR结果                                                                                                                         |\n| ----------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------- |\n|  | 网络支付并无本质的区别，因为<br />每一个手机号码和邮件地址背后<br />都会对应着一个账户--这个账<br />户可以是信用卡账户、借记卡账<br />户，也包括邮局汇款、手机代<br />收、电话代收、预付费卡和点卡<br />等多种形式。 |\n\n</div>\n\n\n### 竖排文字识别\n\n采用来自 [**PaddleOCR**](https://github.com/PaddlePaddle/PaddleOCR)（之后简称 **ppocr**）的中文识别模型 `rec_model_name='ch_PP-OCRv3'` 进行识别。\n\n```python\nfrom cnocr import CnOcr\n\nimg_fp = './docs/examples/shupai.png'\nocr = CnOcr(rec_model_name='ch_PP-OCRv3')\nout = ocr.ocr(img_fp)\n\nprint(out)\n```\n\n识别结果：\n<div align=\"center\">\n  \n</div>\n\n\n### 英文识别\n\n虽然中文检测和识别模型也能识别英文，但**专为英文文字训练的检测器和识别器往往精度更高**。如果是纯英文的应用场景，建议使用来自 **ppocr** 的英文检测模型 `det_model_name='en_PP-OCRv3_det'`， 和英文识别模型 `rec_model_name='en_PP-OCRv3'` 。\n\n```python\nfrom cnocr import CnOcr\n\nimg_fp = './docs/examples/en_book1.jpeg'\nocr = CnOcr(det_model_name='en_PP-OCRv3_det', rec_model_name='en_PP-OCRv3')\nout = ocr.ocr(img_fp)\n\nprint(out)\n```\n\n识别结果：\n\n<div align=\"center\">\n  \n</div>\n\n\n### 繁体中文识别\n\n采用来自ppocr的繁体识别模型 `rec_model_name='chinese_cht_PP-OCRv3'` 进行识别。\n\n```python\nfrom cnocr import CnOcr\n\nimg_fp = './docs/examples/fanti.jpg'\nocr = CnOcr(rec_model_name='chinese_cht_PP-OCRv3')  # 识别模型使用繁体识别模型\nout = ocr.ocr(img_fp)\n\nprint(out)\n```\n\n使用此模型时请注意以下问题：\n\n* 识别精度一般，不是很好；\n\n* 除了繁体字，对标点、英文、数字的识别都不好；\n\n* 此模型不支持竖排文字的识别。\n\n识别结果：\n<div align=\"center\">\n  \n</div>\n\n\n### 单行文字的图片识别\n\n如果明确知道待识别的图片是单行文字图片（如下图），可以使用类函数 `CnOcr.ocr_for_single_line()` 进行识别。这样就省掉了文字检测的时间，速度会快一倍以上。\n\n<div align=\"center\">\n  \n</div>\n调用代码如下：\n\n```python\nfrom cnocr import CnOcr\n\nimg_fp = './docs/examples/helloworld.jpg'\nocr = CnOcr()\nout = ocr.ocr_for_single_line(img_fp)\nprint(out)\n```\n\n\n\n### 更多应用示例\n\n* **核酸疫苗截图识别**\n<div align=\"center\">\n  \n</div>\n\n* **身份证识别**\n<div align=\"center\">\n  \n</div>\n\n* **饭店小票识别**\n<div align=\"center\">\n  \n</div>\n  \n\n  \n\n## 安装\n\n嗯，顺利的话一行命令即可。\n\n```bash\n$ pip install cnocr[ort-cpu]\n```\n\n如果是 **GPU** 环境使用 ONNX 模型，请使用以下命令进行安装：\n\n```bash\n$ pip install cnocr[ort-gpu]\n```\n\n\n\n如果要训练自己的模型，，可以使用以下命令安装：\n\n```bash\n$ pip install cnocr[dev]\n```\n\n\n\n安装速度慢的话，可以指定国内的安装源，如使用阿里云的安装源：\n\n```bash\n$ pip install cnocr[ort-cpu] -i https://mirrors.aliyun.com/pypi/simple\n```\n\n> **Note** \n>\n> 请使用 **Python3**（3.7.\\*~3.10.\\*之间的版本应该都行），没测过Python2下是否ok。\n\n更多说明可见 [安装文档](https://cnocr.readthedocs.io/zh-cn/stable/install/)。\n\n> **Warning** \n>\n> 如果电脑中从未安装过 `PyTorch`，`OpenCV` python包，初次安装可能会遇到问题，但一般都是常见问题，可以自行百度/Google解决。\n\n\n\n### Docker Image\n\n可以从 [Docker Hub](https://hub.docker.com/u/breezedeus) 直接拉取已安装好 CnOCR 的镜像使用。\n\n```bash\n$ docker pull breezedeus/cnocr:latest\n```\n\n更多说明可见 [安装文档](https://cnocr.readthedocs.io/zh-cn/stable/install/)。\n\n\n\n## HTTP服务\n\nCnOCR **V2.2.1** 加入了基于 FastAPI 的HTTP服务。开启服务需要安装几个额外的包，可以使用以下命令安装：\n\n```bash\npip install cnocr[serve]\n```\n\n\n\n安装完成后，可以通过以下命令启动HTTP服务（**`-p`** 后面的数字是**端口**，可以根据需要自行调整）：\n\n```bash\ncnocr serve -p 8501\n```\n\n\n\n服务开启后，可以使用以下方式调用服务。\n\n\n\n### 命令行\n\n比如待识别文件为 `docs/examples/huochepiao.jpeg`，如下使用 curl 调用服务：\n\n```bash\n> curl -F image=@docs/examples/huochepiao.jpeg http://0.0.0.0:8501/ocr\n```\n\n\n\n### Python\n\n使用如下方式调用服务：\n\n```python\nimport requests\n\nimage_fp = 'docs/examples/huochepiao.jpeg'\nr = requests.post(\n    'http://0.0.0.0:8501/ocr', files={'image': (image_fp, open(image_fp, 'rb'), 'image/png')},\n)\nocr_out = r.json()['results']\nprint(ocr_out)\n```\n\n\n\n具体也可参考文件 [scripts/screenshot_daemon_with_server.py](scripts/screenshot_daemon_with_server.py) 。 \n\n\n\n### 其他语言\n\n请参照 curl 的调用方式自行实现。\n\n\n\n\n\n## 可使用的模型\n\n### 可使用的检测模型\n\n具体参考 [CnSTD的下载说明](https://github.com/breezedeus/CnSTD?tab=readme-ov-file#%E5%B7%B2%E6%9C%89std%E6%A8%A1%E5%9E%8B)。\n\n| `det_model_name`                                             | PyTorch 版本 | ONNX 版本 | 模型原始来源 | 模型文件大小 | 支持语言                       | 是否支持竖排文字识别 |\n| ------------------------------------------------------------ | ------------ | --------- | ------------ | ------------ | ------------------------------ | -------------------- |\n| db_shufflenet_v2                                             | √            | X         | cnocr        | 18 M         | 简体中文、繁体中文、英文、数字 | √                    |\n| **db_shufflenet_v2_small**                                   | √            | X         | cnocr        | 12 M         | 简体中文、繁体中文、英文、数字 | √                    |\n| db_mobilenet_v3                                              | √            | X         | cnocr        | 16 M         | 简体中文、繁体中文、英文、数字 | √                    |\n| db_mobilenet_v3_small                                        | √            | X         | cnocr        | 7.9 M        | 简体中文、繁体中文、英文、数字 | √                    |\n| db_resnet34                                                  | √            | X         | cnocr        | 86 M         | 简体中文、繁体中文、英文、数字 | √                    |\n| db_resnet18                                                  | √            | X         | cnocr        | 47 M         | 简体中文、繁体中文、英文、数字 | √                    |\n| ch_PP-OCRv5_det                                              | X            | √         | ppocr        | 4.6 M        | 简体中文、繁体中文、英文、数字 | √                    |\n| ch_PP-OCRv5_det_server                                       | X            | √         | ppocr        | 84 M        | 简体中文、繁体中文、英文、数字 | √                    |\n| ch_PP-OCRv4_det                                              | X            | √         | ppocr        | 4.5 M        | 简体中文、繁体中文、英文、数字 | √                    |\n| ch_PP-OCRv4_det_server                                       | X            | √         | ppocr        | 108 M        | 简体中文、繁体中文、英文、数字 | √                    |\n| ch_PP-OCRv3_det                                              | X            | √         | ppocr        | 2.3 M        | 简体中文、繁体中文、英文、数字 | √                    |\n| **en_PP-OCRv3_det**                                          | X            | √         | ppocr        | 2.3 M        | **英文**、数字                 | √                    |\n\n\n\n### 可使用的识别模型\n\n相比于 CnOCR V2.2.* 版本，**V2.3** 中的大部分模型都经过了重新训练和精调，精度比旧版模型更高。同时，加入了两个参数量更多的模型系列：\n\n  * `*-densenet_lite_246-gru_base`：优先供 **知识星球** [**CnOCR/CnSTD私享群**](https://t.zsxq.com/FEYZRJQ) 会员使用，后续会免费开源。\n  * `*-densenet_lite_666-gru_large`：**Pro 模型**，购买后可使用。购买链接见文档：\n\n**V2.3** 中的模型按使用场景可以分为以下几大类：\n\n* `scene`：场景图片，适合识别一般拍照图片中的文字。此类模型以 `scene-` 开头，如模型 `scene-densenet_lite_136-gru`。\n* `doc`：文档图片，适合识别规则文档的截图图片，如书籍扫描件等。此类模型以 `doc-` 开头，如模型 `doc-densenet_lite_136-gru`。\n* `number`：仅识别**纯数字**（只能识别 `0~9` 十个数字）图片，适合银行卡号、身份证号等场景。此类模型以 `number-` 开头，如模型 `number-densenet_lite_136-gru`。\n* `general`: 通用场景，适合图片无明显倾向的一般图片。此类模型无特定开头，与旧版模型名称保持一致，如模型 `densenet_lite_136-gru`。\n\n> 注意 ⚠️：以上说明仅供参考，具体选择模型时建议以实际效果为准。\n\n更多说明见：[可用模型](https://cnocr.readthedocs.io/zh-cn/stable/models/)。\n\n| `rec_model_name`                                             | PyTorch 版本 | ONNX 版本 | 模型原始来源 | 模型文件大小 | 支持语言                            | 是否支持竖排文字识别 |\n| ------------------------------------------------------------ | ------------ | --------- | ------------ | ------------ | ----------------------------------- | -------------------- |\n| **densenet_lite_136-gru** 🆕                                  | √            | √         | cnocr        | 12 M         | 简体中文、英文、数字                | X                    |\n| **scene-densenet_lite_136-gru** 🆕                            | √            | √         | cnocr        | 12 M         | 简体中文、英文、数字                | X                    |\n| **doc-densenet_lite_136-gru** 🆕                              | √            | √         | cnocr        | 12 M         | 简体中文、英文、数字                | X                    |\n| **densenet_lite_246-gru_base** 🆕 <br /> ([星球会员](https://t.zsxq.com/FEYZRJQ)专享) | √            | √         | cnocr        | 25 M         | 简体中文、英文、数字                | X                    |\n| **scene-densenet_lite_246-gru_base** 🆕 <br /> ([星球会员](https://t.zsxq.com/FEYZRJQ)专享) | √            | √         | cnocr        | 25 M         | 简体中文、英文、数字                | X                    |\n| **doc-densenet_lite_246-gru_base** 🆕 <br /> ([星球会员](https://t.zsxq.com/FEYZRJQ)专享) | √            | √         | cnocr        | 25 M         | 简体中文、英文、数字                | X                    |\n| **densenet_lite_666-gru_large** 🆕 <br />（购买链接：[B站](https://mall.bilibili.com/neul-next/detailuniversal/detail.html?isMerchant=1&page=detailuniversal_detail&saleType=10&itemsId=11884138&loadingShow=1&noTitleBar=1&msource=merchant_share)、[Lemon Squeezy](https://ocr.lemonsqueezy.com/)） | √            | √         | cnocr        | 82 M         | 简体中文、英文、数字                | X                    |\n| **scene-densenet_lite_666-gru_large** 🆕 <br />（购买链接：[B站](https://mall.bilibili.com/neul-next/detailuniversal/detail.html?isMerchant=1&page=detailuniversal_detail&saleType=10&itemsId=11883935&loadingShow=1&noTitleBar=1&msource=merchant_share)、[Lemon Squeezy](https://ocr.lemonsqueezy.com/)） | √            | √         | cnocr        | 82 M         | 简体中文、英文、数字                | X                    |\n| **doc-densenet_lite_666-gru_large** 🆕 <br />（购买链接：[B站](https://mall.bilibili.com/neul-next/detailuniversal/detail.html?isMerchant=1&page=detailuniversal_detail&saleType=10&itemsId=11883965&loadingShow=1&noTitleBar=1&msource=merchant_share)、[Lemon Squeezy](https://ocr.lemonsqueezy.com/)） | √            | √         | cnocr        | 82 M         | 简体中文、英文、数字                | X                    |\n| **number-densenet_lite_136-fc** 🆕                            | √            | √         | cnocr        | 2.7 M        | **纯数字**（仅包含 `0~9` 十个数字） | X                    |\n| **number-densenet_lite_136-gru**  🆕 <br /> ([星球会员](https://t.zsxq.com/FEYZRJQ)专享) | √            | √         | cnocr        | 5.5 M        | **纯数字**（仅包含 `0~9` 十个数字） | X                    |\n| **number-densenet_lite_666-gru_large** 🆕 <br />（购买链接：[B站](https://mall.bilibili.com/neul-next/detailuniversal/detail.html?isMerchant=1&page=detailuniversal_detail&saleType=10&itemsId=11884155&loadingShow=1&noTitleBar=1&msource=merchant_share)、[Lemon Squeezy](https://ocr.lemonsqueezy.com/)） | √            | √         | cnocr        | 55 M         | **纯数字**（仅包含 `0~9` 十个数字） | X                    |\n| ch_PP-OCRv5                                                  | X            | √         | ppocr        | 16 M         | 简体中文、英文、数字                | √                    |\n| ch_PP-OCRv5_server                                           | X            | √         | ppocr        | 81 M         | 简体中文、英文、数字                | √                    |\n| ch_PP-OCRv4                                                  | X            | √         | ppocr        | 10 M         | 简体中文、英文、数字                | √                    |\n| ch_PP-OCRv4_server                                           | X            | √         | ppocr        | 86 M         | 简体中文、英文、数字                | √                    |\n| ch_PP-OCRv3                                                  | X            | √         | ppocr        | 10 M         | 简体中文、英文、数字                | √                    |\n| ch_ppocr_mobile_v2.0                                         | X            | √         | ppocr        | 4.2 M        | 简体中文、英文、数字                | √                    |\n| en_PP-OCRv4                                                  | X            | √         | ppocr        | 8.6 M        | **英文**、数字                      | √                    |\n| en_PP-OCRv3                                                  | X            | √         | ppocr        | 8.5 M        | **英文**、数字                      | √                    |\n| en_number_mobile_v2.0                                        | X            | √         | ppocr        | 1.8 M        | **英文**、数字                      | √                    |\n| chinese_cht_PP-OCRv3                                         | X            | √         | ppocr        | 11 M         | **繁体中文**、英文、数字            | X                    |\n| japan_PP-OCRv3                                               | X            | √         | ppocr        | 9.6 M         | **日文**、英文、数字                | √                    |\n| korean_PP-OCRv3                                              | X            | √         | ppocr        | 9.4 M         | **韩文**、英文、数字                | √                    |\n| latin_PP-OCRv3                                               | X            | √         | ppocr        | 8.6 M         | **拉丁文**、英文、数字              | √                    |\n| arabic_PP-OCRv3                                              | X            | √         | ppocr        | 8.6 M         | **阿拉伯文**、英文、数字            | √                    |\n\n\n\n## 未来工作\n\n* [x] 支持图片包含多行文字 (`Done`)\n* [x] crnn模型支持可变长预测，提升灵活性 (since `V1.0.0`)\n* [x] 完善测试用例 (`Doing`)\n* [x] 修bugs（目前代码还比较凌乱。。） (`Doing`)\n* [x] 支持`空格`识别（since `V1.1.0`）\n* [x] 尝试新模型，如 DenseNet，进一步提升识别准确率（since `V1.1.0`）\n* [x] 优化训练集，去掉不合理的样本；在此基础上，重新训练各个模型\n* [x] 由 MXNet 改为 PyTorch 架构（since `V2.0.0`）\n* [x] 基于 PyTorch 训练更高效的模型\n* [x] 支持列格式的文字识别\n* [x] 打通与 [CnSTD](https://github.com/breezedeus/cnstd) 的无缝衔接（since `V2.2`）\n* [ ] 模型精度进一步优化\n* [ ] 支持更多的应用场景\n\n\n\n## 给作者来杯咖啡\n\n开源不易，如果此项目对您有帮助，可以考虑 [给作者加点油🥤，鼓鼓气💪🏻](https://cnocr.readthedocs.io/zh-cn/stable/buymeacoffee/) 。\n\n---\n\n官方代码库：[https://github.com/breezedeus/cnocr](https://github.com/breezedeus/cnocr)。",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "cnocr",
        "recognition",
        "text",
        "text recognition",
        "character recognition",
        "recognition chinese"
      ],
      "category": "document-processing"
    },
    "cablate--mcp-doc-forge": {
      "owner": "cablate",
      "name": "mcp-doc-forge",
      "url": "https://github.com/cablate/mcp-doc-forge",
      "imageUrl": "/freedevtools/mcp/pfp/cablate.webp",
      "description": "Comprehensive document processing capabilities including reading various document formats and converting them to different formats. Provides features for PDF manipulation such as merging and splitting, alongside document conversion tools.",
      "stars": 15,
      "forks": 5,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-04T08:28:39Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/cablate-mcp-doc-forge-badge.png)](https://mseep.ai/app/cablate-mcp-doc-forge)\n\n# Simple Document Processing MCP Server\n[![smithery badge](https://smithery.ai/badge/@cablate/mcp-doc-forge)](https://smithery.ai/server/@cablate/mcp-doc-forge)\n\nA powerful Model Context Protocol (MCP) server providing comprehensive document processing capabilities.\n\n<a href=\"https://glama.ai/mcp/servers/pb9df6lnel\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/pb9df6lnel/badge\" alt=\"Simple Document Processing Server MCP server\" /></a>\n\n## Features\n\n### Document Reader\n- Read DOCX, PDF, TXT, HTML, CSV\n\n### Document Conversion\n- DOCX to HTML/PDF conversion\n- HTML to TXT/Markdown conversion\n- PDF manipulation (merge, split)\n\n### Text Processing\n- Multi-encoding transfer support (UTF-8, Big5, GBK)\n- Text formatting and cleaning\n- Text comparison and diff generation\n- Text splitting by lines or delimiter\n\n### HTML Processing\n- HTML cleaning and formatting\n- Resource extraction (images, links, videos)\n- Structure-preserving conversion\n\n## Installation\n\n### Installing via Smithery\n\nTo install Document Processing Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@cablate/mcp-doc-forge):\n\n```bash\nnpx -y @smithery/cli install @cablate/mcp-doc-forge --client claude\n```\n\n### Manual Installation\n```bash\nnpm install -g @cablate/mcp-doc-forge\n```\n\n\n## Usage\n\n### Cli\n\n```bash\nmcp-doc-forge\n```\n\n### With [Dive Desktop](https://github.com/OpenAgentPlatform/Dive)\n\n1. Click \"+ Add MCP Server\" in Dive Desktop\n2. Copy and paste this configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"searxng\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@cablate/mcp-doc-forge\"\n      ],\n      \"enabled\": true\n    }\n  }\n}\n```\n\n3. Click \"Save\" to install the MCP server\n\n## License\n\nMIT\n\n## Contributing\n\nWelcome community participation and contributions! Here are ways to contribute:\n\n- ⭐️ Star the project if you find it helpful\n- 🐛 Submit Issues: Report problems or provide suggestions\n- 🔧 Create Pull Requests: Submit code improvements\n\n## Contact\n\nIf you have any questions or suggestions, feel free to reach out:\n\n- 📧 Email: [reahtuoo310109@gmail.com](mailto:reahtuoo310109@gmail.com)\n- 📧 GitHub: [CabLate](https://github.com/cablate/)\n- 🤝 Collaboration: Welcome to discuss project cooperation\n- 📚 Technical Guidance: Sincere welcome for suggestions and guidance\n\n\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "document",
        "formats",
        "forge",
        "document processing",
        "document conversion",
        "doc forge"
      ],
      "category": "document-processing"
    },
    "canlgz--markitdown_mcp_server": {
      "owner": "canlgz",
      "name": "markitdown_mcp_server",
      "url": "https://github.com/canlgz/markitdown_mcp_server",
      "imageUrl": "/freedevtools/mcp/pfp/canlgz.webp",
      "description": "Converts various file formats to Markdown using the MarkItDown utility, enabling seamless processing of PDFs, Office documents, images, audio, HTML, and more into Markdown format.",
      "stars": 1,
      "forks": 0,
      "license": "MIT License",
      "language": "",
      "updated_at": "2025-04-25T08:20:50Z",
      "readme_content": "# MarkItDown MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@KorigamiK/markitdown_mcp_server)](https://smithery.ai/server/@KorigamiK/markitdown_mcp_server)\n\nA Model Context Protocol (MCP) server that converts various file formats to Markdown using the MarkItDown utility.\n\n<a href=\"https://glama.ai/mcp/servers/sbc6bljjg5\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/sbc6bljjg5/badge\" alt=\"MarkItDown Server MCP server\" /></a>\n\n## Supported Formats\n\n- PDF\n- PowerPoint\n- Word\n- Excel\n- Images (EXIF metadata and OCR)\n- Audio (EXIF metadata and speech transcription)\n- HTML\n- Text-based formats (CSV, JSON, XML)\n- ZIP files (iterates over contents)\n\n## Installation\n\n### Installing via Smithery\n\nTo install MarkItDown MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@KorigamiK/markitdown_mcp_server):\n\n```bash\nnpx -y @smithery/cli install @KorigamiK/markitdown_mcp_server --client claude\n```\n\n### Manual Installation\n\n1. Clone this repository\n2. Install dependencies:\n```bash\nuv install\n```\n\n## Usage\n\n### As MCP Server\n\nThe server can be integrated with any MCP client. Here are some examples:\n\n#### Zed Editor\n\nAdd the following to your `settings.json`:\n\n```json\n\"context_servers\": {\n  \"markitdown_mcp\": {\n    \"settings\": {},\n    \"command\": {\n      \"path\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/path/to/markitdown_mcp_server\",\n        \"run\",\n        \"markitdown\"\n      ]\n    }\n  }\n}\n```\n\n### Commands\n\nThe server responds to the following MCP commands:\n\n- `/md <file>` - Convert the specified file to Markdown\n\nExample:\n```bash\n/md document.pdf\n```\n\n## Supported MCP Clients\n\nWorks with any MCP-compliant client listed at [modelcontextprotocol.io/clients](https://modelcontextprotocol.io/clients), including:\n\n- Zed Editor\n- Any other MCP-compatible editors and tools\n\n## License\n\nMIT License. See [LICENSE](LICENSE) for details.\n\n## Acknowledgements\n\nhttps://github.com/microsoft/markitdown#readme\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "markitdown_mcp_server",
        "markitdown",
        "markdown",
        "canlgz markitdown_mcp_server",
        "markitdown utility",
        "formats markdown"
      ],
      "category": "document-processing"
    },
    "cdugo--package-documentation-mcp": {
      "owner": "cdugo",
      "name": "package-documentation-mcp",
      "url": "https://github.com/cdugo/package-documentation-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/cdugo.webp",
      "description": "Fetches npm package documentation from multiple programming ecosystems and presents it for use with LLMs, such as Claude, without the need for API keys.",
      "stars": 15,
      "forks": 6,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-19T02:16:03Z",
      "readme_content": "# 📚 DocsFetcher MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@cdugo/mcp-get-docs)](https://smithery.ai/server/@cdugo/mcp-get-docs)\n[![npm version](https://img.shields.io/npm/v/@cdugo/docs-fetcher-mcp.svg)](https://www.npmjs.com/package/@cdugo/docs-fetcher-mcp)\n[![npm downloads](https://img.shields.io/npm/dm/@cdugo/docs-fetcher-mcp.svg)](https://www.npmjs.com/package/@cdugo/docs-fetcher-mcp)\n\nAn MCP server that fetches package documentation from multiple language ecosystems for LLMs like Claude without requiring API keys.\n\n<a href=\"https://glama.ai/mcp/servers/8yfwtryuc5\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/8yfwtryuc5/badge\" alt=\"DocsFetcher Server MCP server\" />\n</a>\n\n## ✨ Features\n\n- 🌐 Supports multiple programming languages (JavaScript, Python, Java, .NET, Ruby, PHP, Rust, Go, Swift)\n- 📦 Fetches documentation for packages by name or URL\n- 🔍 Crawls documentation sites to extract comprehensive information\n- 📄 Extracts README, API docs, code examples, and repository info\n- 🧠 Provides structured data for LLM summarization\n- 💬 Includes specialized prompts for documentation analysis\n- 🔑 **No API key required** - works natively with Claude Desktop and Cursor IDE\n\n## 🚀 Installation\n\n### Claude Desktop\n\n1. Open Claude Desktop → Settings → Developer\n2. Click \"Edit Config\" and add:\n\n```json\n{\n  \"mcpServers\": {\n    \"docsFetcher\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@smithery/cli@latest\",\n        \"run\",\n        \"@cdugo/mcp-get-docs\",\n        \"--config\",\n        \"'{}'\"\n      ]\n    }\n  }\n}\n```\n\n### Cursor IDE Configuration\n\n1.  Open Cursor IDE → Settings → MCP -> Add New MCP Servier\n2.  Add:\n\n```json\n    Name: docsFetcher\n    Command: npx -y @smithery/cli@latest run @cdugo/mcp-get-docs --config \"{}\"\n```\n\n#### Prerequisites\n\n- 📋 Node.js 18 or later\n\n## 🏃‍♂️ Running Locally\n\n```bash\ngit clone https://github.com/cdugo/package-documentation-mcp\ncd package-documentation-mcp\nnpm install\nnpm run build\n```\n\nOnce installed, you can run the server locally with:\n\n```bash\n# From the project root directory\nnpm start\n```\n\nFor development with auto-restart on file changes:\n\n```bash\nnpm run dev\n```\n\nThe server will start on the default port (usually 3000). You should see output like:\n\n```\n🚀 DocsFetcher MCP Server running!\n📋 Ready to fetch documentation\n```\n\nTo specify a custom port:\n\n```bash\nPORT=8080 npm start\n```\n\n## 🛠️ Available Tools\n\n1. **fetch-url-docs**: 🔗 Fetch docs from a specific URL\n2. **fetch-package-docs**: 📦 Fetch docs for a package with optional language specification\n3. **fetch-library-docs**: 🧠 Smart tool that works with either package name or URL\n4. **fetch-multilingual-docs**: 🌍 Fetch docs for a package across multiple language ecosystems\n\n## 📝 Available Prompts\n\n1. **summarize-library-docs**: 📚 Create a comprehensive library summary\n2. **explain-dependency-error**: 🐛 Generate dependency error explanations\n\n## 💡 Example Queries\n\n### Basic Library Information\n\n- \"What is Express.js and how do I use it?\"\n- \"Tell me about the React library\"\n- \"How do I use requests in Python?\"\n\n### Multi-language Support\n\n- \"Show me documentation for lodash in JavaScript\"\n- \"Compare pandas in Python and data.table in R\"\n\n### Using Tools\n\n- \"@fetch-package-docs with packageName='express' and language='javascript'\"\n- \"@fetch-package-docs with packageName='requests' and language='python'\"\n- \"@fetch-multilingual-docs with packageName='http' and languages=['javascript', 'python', 'rust']\"\n\n### Using Prompts\n\n- \"@summarize-library-docs with libraryName='express'\"\n- \"@explain-dependency-error with packageName='dotenv'\"\n\n## ❓ Troubleshooting\n\n### Local Installation\n\n- **Server not showing up**: ✅ Verify absolute path in configuration\n- **Connection errors**: 🔄 Restart Claude Desktop or Cursor IDE\n- **Fetch failures**: ⚠️ Some packages may have non-standard documentation\n- **Language support**: 🌐 If a language isn't working, try using the package's direct URL\n\n## 📄 License\n\nMIT",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "documentation",
        "package",
        "cdugo",
        "package documentation",
        "cdugo package",
        "documentation mcp"
      ],
      "category": "document-processing"
    },
    "crazyrabbitLTC--mcp-expert-server": {
      "owner": "crazyrabbitLTC",
      "name": "mcp-expert-server",
      "url": "https://github.com/crazyrabbitLTC/mcp-expert-server",
      "imageUrl": "/freedevtools/mcp/pfp/crazyrabbitLTC.webp",
      "description": "Provides intelligent query generation and documentation assistance using Claude AI by analyzing API documentation. Delivers tools for generating queries from natural language requests and retrieving relevant documentation information based on user questions.",
      "stars": 3,
      "forks": 5,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-04-10T20:28:12Z",
      "readme_content": "# MCP Expert Server\n\nA Model Context Protocol server that provides intelligent query generation and documentation assistance using Claude AI. The server analyzes your API documentation and provides two main tools:\n\n- **create-query**: Generates queries based on natural language requests\n- **documentation**: Provides relevant documentation information based on questions\n\n## Prerequisites\n\n- Node.js >= 18\n- An Anthropic API key for Claude\n\n## Installation\n\n1. Clone the repository\n2. Install dependencies:\n```bash\nnpm install\n```\n3. Create a `.env` file with your Anthropic API key:\n```\nANTHROPIC_API_KEY=your_api_key_here\n```\n\n## Setup\n\nBefore running the server, you need to:\n\n1. Build the project and run the setup script:\n```bash\nnpm run build\nnpm run setup\n```\n\nThis will:\n- Create the required directories (`docs/` and `prompts/`)\n- Create default prompt files\n- Generate an initial service description\n\n2. Add your API documentation files to the `docs/` directory (supports `.txt`, `.md`, and `.json` files)\n\n3. Optionally customize the prompts in the `prompts/` directory:\n   - `system-prompt.txt`: Main system prompt for Claude\n   - `tool-metadata.txt`: Additional context for tool descriptions\n   - `query-metadata.txt`: Additional context for query generation\n   - `service-description.txt`: Auto-generated service description\n\n## Usage\n\n### Standalone Server\n\nStart the server:\n```bash\nnpm start\n```\n\nThe server exposes two tools via the Model Context Protocol:\n\n- **create-query**: Generate a query based on natural language request\n  ```json\n  {\n    \"name\": \"create-query\",\n    \"arguments\": {\n      \"request\": \"Find all users who signed up in the last week\"\n    }\n  }\n  ```\n\n- **documentation**: Get information from the documentation\n  ```json\n  {\n    \"name\": \"documentation\",\n    \"arguments\": {\n      \"request\": \"How do I authenticate API requests?\"\n    }\n  }\n  ```\n\n### Claude Desktop Integration\n\n1. Add this configuration to your Claude Desktop config file:\n```json\n{\n  \"mcpServers\": {\n    \"expert\": {\n      \"command\": \"node\",\n      \"args\": [\"/ABSOLUTE/PATH/TO/expert-server/build/index.js\"],\n      \"env\": {\n        \"ANTHROPIC_API_KEY\": \"your_api_key_here\"\n      }\n    }\n  }\n}\n```\n\n2. Replace `/ABSOLUTE/PATH/TO/expert-server` with the actual absolute path to your server installation.\n\n3. Restart Claude Desktop.\n\n## Directory Structure\n\n```\n.\n├── docs/                  # Your API documentation files\n├── prompts/              # System prompts and metadata\n│   ├── system-prompt.txt    # Main system prompt\n│   ├── tool-metadata.txt    # Tool description context\n│   ├── query-metadata.txt   # Query generation context\n│   └── service-description.txt  # Generated service description\n├── src/                  # Source code\n│   ├── index.ts            # Entry point\n│   ├── server.ts           # MCP server implementation\n│   └── services/           # Core services\n│       └── expertService.ts  # Claude integration\n└── package.json\n```\n\n## Development\n\n- Build the project:\n```bash\nnpm run build\n```\n\n- The server uses TypeScript and follows a modular architecture\n- All Claude interactions are handled by the ExpertService class\n- Debug logs are written to stderr with [DEBUG] prefix\n\n## Troubleshooting\n\nIf you encounter connection issues:\n\n1. Ensure you've run the setup script:\n```bash\nnpm run setup\n```\n\n2. Check that all required files exist in the `prompts/` directory\n3. Verify your `ANTHROPIC_API_KEY` is correctly set\n4. Use absolute paths in your Claude Desktop config\n5. Check the debug logs (written to stderr)\n\n## Environment Variables\n\n- `ANTHROPIC_API_KEY`: Your Anthropic API key (required)\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "documentation",
        "document",
        "queries",
        "documentation information",
        "document processing",
        "intelligent query"
      ],
      "category": "document-processing"
    },
    "cso1z--Feishu-MCP": {
      "owner": "cso1z",
      "name": "Feishu-MCP",
      "url": "https://github.com/cso1z/Feishu-MCP",
      "imageUrl": "/freedevtools/mcp/pfp/cso1z.webp",
      "description": "Manage and manipulate Feishu documents with capabilities for creating, editing, and extracting structured and unstructured content, along with rich text formatting and code block handling.",
      "stars": 159,
      "forks": 18,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-29T08:10:28Z",
      "readme_content": "# 飞书 MCP 服务器\n\n\n[![npm version](https://img.shields.io/npm/v/feishu-mcp?color=blue&label=npm)](https://www.npmjs.com/package/feishu-mcp)\n[![MIT License](https://img.shields.io/badge/license-MIT-green)](./LICENSE)\n\n为 [Cursor](https://cursor.sh/)、[Windsurf](https://codeium.com/windsurf)、[Cline](https://cline.bot/) 和其他 AI 驱动的编码工具提供访问、编辑和结构化处理飞书文档的能力，基于 [Model Context Protocol](https://modelcontextprotocol.io/introduction) 服务器实现。\n\n本项目让 AI 编码工具能够直接获取和理解飞书文档的结构化内容，显著提升文档处理的智能化和效率。\n\n**完整覆盖飞书文档的真实使用流程，助你高效利用文档资源：**\n1. **文件夹目录获取**：快速获取和浏览飞书文档文件夹下的所有文档，便于整体管理和查找。\n2. **内容获取与理解**：支持结构化、分块、富文本等多维度内容读取，AI 能精准理解文档上下文。\n3. **智能创建与编辑**：可自动创建新文档、批量生成和编辑内容，满足多样化写作需求。\n4. **高效检索与搜索**：内置关键字搜索，帮助你在大量文档中迅速找到目标信息。\n\n本项目让你在飞书文档的日常使用流程中实现智能获取、编辑和搜索，提升内容处理效率和体验。\n\n### 🎬 使用演示视频\n\n你可以通过以下视频了解 MCP 的实际使用效果和操作流程：\n\n<a href=\"https://www.bilibili.com/video/BV1z7MdzoEfu/?vd_source=94c14da5a71aeb01f665f159dd3d89c8\">\n  \n</a>\n\n<a href=\"https://www.bilibili.com/video/BV18z3gzdE1w/?vd_source=94c14da5a71aeb01f665f159dd3d89c8\">\n  \n</a>\n\n> ⭐ **Star 本项目，第一时间获取最新功能和重要更新！** 关注项目可以让你不错过任何新特性、修复和优化，助你持续高效使用。你的支持也将帮助我们更好地完善和发展项目。⭐\n\n---\n\n## 🛠️ 工具功能详情\n\n| 功能类别 | 工具名称                                                         | 描述                | 使用场景          | 状态 |\n|---------|--------------------------------------------------------------|-------------------|---------------|------|\n| **文档管理** | `create_feishu_document`                                     | 创建新的飞书文档          | 从零开始创建文档      | ✅ 已完成 |\n| | `get_feishu_document_info`                                   | 获取文档基本信息          | 验证文档存在性和权限    | ✅ 已完成 |\n| | `get_feishu_document_blocks`                                 | 获取文档块结构           | 了解文档层级结构      | ✅ 已完成 |\n| **内容编辑** | `batch_create_feishu_blocks`                                 | 批量创建多个块           | 高效创建连续内容      | ✅ 已完成 |\n| | `update_feishu_block_text`                                   | 更新块文本内容           | 修改现有内容        | ✅ 已完成 |\n| | `delete_feishu_document_blocks`                              | 删除文档块             | 清理和重构文档内容     | ✅ 已完成 |\n| **文件夹管理** | `get_feishu_folder_files`                                    | 获取文件夹文件列表         | 浏览文件夹内容       | ✅ 已完成 |\n| | `create_feishu_folder`                                       | 创建新文件夹            | 组织文档结构        | ✅ 已完成 |\n| **搜索功能** | `search_feishu_documents`                                    | 搜索文档              | 查找特定内容        | ✅ 已完成 |\n| **工具功能** | `convert_feishu_wiki_to_document_id`                         | Wiki链接转换          | 将Wiki链接转为文档ID | ✅ 已完成 |\n| | `get_feishu_image_resource`                                  | 获取图片资源            | 下载文档中的图片      | ✅ 已完成 |\n| | `get_feishu_whiteboard_content`                              | 获取画板内容 | 获取画板中的图形元素和结构(流程图、思维导图等) | ✅ 已完成 |\n| **高级功能** | `create_feishu_table`                                         | 创建和编辑表格           | 结构化数据展示       | ✅ 已完成 |\n| | 流程图插入                                                        | 支持流程图和思维导图        | 流程梳理和可视化      | ✅ 已完成 |\n| 图片插入  | `upload_and_bind_image_to_block` | 支持插入本地和远程图片       | 修改文档内容        | ✅ 已完成 |\n| | 公式支持                                                         | 支持数学公式            | 学术和技术文档       | ✅ 已完成 |\n\n### 🎨 支持的样式功能（基本支持md所有格式）\n\n- **文本样式**：粗体、斜体、下划线、删除线、行内代码\n- **文本颜色**：灰色、棕色、橙色、黄色、绿色、蓝色、紫色\n- **对齐方式**：左对齐、居中、右对齐\n- **标题级别**：支持1-9级标题\n- **代码块**：支持多种编程语言语法高亮\n- **列表**：有序列表（编号）、无序列表（项目符号）\n- **图片**：支持本地图片和网络图片\n- **公式**：在文本块中插入数学公式，支持LaTeX语法\n- **mermaid图表**：支持流程图、时序图、思维导图、类图、饼图等等\n- **表格**：支持创建多行列表格，单元格可包含文本、标题、列表、代码块等多种内容类型\n\n---\n\n## 📈 一周计划：提升工具效率\n\n- ~~**精简工具集**：21个工具 → 13个工具，移除冗余，聚焦核心功能~~ 0.0.15 ✅\n- ~~**优化描述**：7000+ tokens → 3000+ tokens，简化提示，节省请求token~~ 0.0.15 ✅\n- ~~**批量增强**：新增批量更新、批量图片上传，单次操作效率提升50%~~ 0.0.15 ✅\n- **流程优化**：减少多步调用，实现一键完成复杂任务\n- ~~**支持多种凭证类型**：包括 tenant_access_token和 user_access_token，满足不同场景下的认证需求~~  (飞书应用配置发生变更) 0.0.16 ✅。\n- **支持cursor用户登录**：方便在cursor平台用户认证\n- ~~**支持mermaid图表**：流程图、时序图等等，丰富文档内容~~ 0.1.11 ✅\n- ~~**支持表格创建**：创建包含各种块类型的复杂表格，支持样式控制~~ 0.1.2 ✅\n\n---\n\n## 🔧 飞书配置教程\n\n**⚠️ 重要提示：在开始使用之前，必须先完成飞书应用配置，否则无法正常使用本工具。**\n\n关于如何创建飞书应用和获取应用凭证的说明可以在[官方教程](https://open.feishu.cn/document/home/develop-a-bot-in-5-minutes/create-an-app)找到。\n\n**详细的飞书应用配置步骤**：有关注册飞书应用、配置权限、添加文档访问权限的详细指南，请参阅 [手把手教程 FEISHU_CONFIG.md](FEISHU_CONFIG.md)。\n\n---\n\n## 🏃‍♂️ 快速开始\n\n### 方式一：使用 NPM 快速运行\n\n```bash\nnpx feishu-mcp@latest --feishu-app-id=<你的飞书应用ID> --feishu-app-secret=<你的飞书应用密钥>\n```\n\n### 方式二：使用 Smithery 平台\n\n**已发布到 Smithery 平台，可访问：** https://smithery.ai/server/@cso1z/feishu-mcp\n\n### 方式三：本地运行\n\n\n#### 🌿 分支说明\n\n本项目采用主分支（main）+功能分支（feature/xxx）协作模式：\n\n- **main**  \n  稳定主线分支，始终保持可用、可部署状态。所有已验证和正式发布的功能都会合并到 main 分支。\n\n- **multi-user-token** \n\n  多用户隔离与按用户授权的 Feishu Token 获取功能开发分支。该分支支持 userKey 参数、按用户获取和缓存 Token、自定义 Token 服务等高级特性，适用于需要多用户隔离和授权场景的开发与测试。\n  > ⚠️ 该分支为 beta 版本，功能更新相较 main 分支可能会有延后。如有相关需求请在 issue 区留言，我会优先同步最新功能到该分支。\n  \n\n1. **克隆仓库**\n   ```bash\n   git clone https://github.com/cso1z/Feishu-MCP.git\n   cd Feishu-MCP\n   ```\n\n2. **安装依赖**\n   ```bash\n   pnpm install\n   ```\n\n3. **配置环境变量(复制一份.env.example保存为.env文件)**\n   \n   **macOS/Linux:**\n   ```bash\n   cp .env.example .env\n   ```\n   \n   **Windows:**\n   ```cmd\n   copy .env.example .env\n   ```\n\n4. **编辑 .env 文件**\n  在项目根目录下找到并用任意文本编辑器打开 `.env` 文件，填写你的飞书应用凭证：\n   ```env\n   FEISHU_APP_ID=cli_xxxxx\n   FEISHU_APP_SECRET=xxxxx\n   PORT=3333\n   ```\n\n5. **运行服务器**\n   ```bash\n   pnpm run dev\n   ```\n\n## ⚙️ 项目配置\n\n### 环境变量配置\n\n| 变量名 | 必需 | 描述                                            | 默认值 |\n|--------|------|-----------------------------------------------|-------|\n| `FEISHU_APP_ID` | ✅ | 飞书应用 ID                                       | - |\n| `FEISHU_APP_SECRET` | ✅ | 飞书应用密钥                                        | - |\n| `PORT` | ❌ | 服务器端口                                         | `3333` |\n| `FEISHU_AUTH_TYPE` | ❌ | 认证凭证类型，建议本地运行时使用 `user`（用户级，需OAuth授权），云端/生产环境使用 `tenant`（应用级，默认） | `tenant` |\n| `FEISHU_TOKEN_ENDPOINT` | ❌ | 获取 token 的接口地址，仅当自定义 token 管理时需要              | `http://localhost:3333/getToken` |\n\n> **注意：**\n> - 只有本地运行服务时支持 `user` 凭证，否则需配置 `FEISHU_TOKEN_ENDPOINT`，自行实现 token 获取与管理（可参考 `callbackService`、`feishuAuthService`）。\n> - `FEISHU_TOKEN_ENDPOINT` 接口参数：`client_id`, `client_secret`, `token_type`（可选，tenant/user）；返回参数：`access_token`, `needAuth`, `url`（需授权时）, `expires_in`（单位:s）。\n\n### 命令行参数\n\n| 参数 | 描述 | 默认值 |\n|------|------|-------|\n| `--port` | 服务器监听端口 | `3333` |\n| `--log-level` | 日志级别 (debug/info/log/warn/error/none) | `info` |\n| `--feishu-app-id` | 飞书应用 ID | - |\n| `--feishu-app-secret` | 飞书应用密钥 | - |\n| `--feishu-base-url` | 飞书API基础URL | `https://open.feishu.cn/open-apis` |\n| `--cache-enabled` | 是否启用缓存 | `true` |\n| `--cache-ttl` | 缓存生存时间（秒） | `3600` |\n| `--stdio` | 命令模式运行 | - |\n| `--help` | 显示帮助菜单 | - |\n| `--version` | 显示版本号 | - |\n\n### 配置文件方式（适用于 Cursor、Cline 等）\n\n```json\n{\n  \"mcpServers\": {\n    \"feishu-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"feishu-mcp\", \"--stdio\"],\n      \"env\": {\n        \"FEISHU_APP_ID\": \"<你的飞书应用ID>\",\n        \"FEISHU_APP_SECRET\": \"<你的飞书应用密钥>\"\n      }\n    },\n    \"feishu_local\": {\n      \"url\": \"http://localhost:3333/sse\"\n    }\n  }\n}\n```\n---\n\n## 📝 使用贴士（重要）\n\n1. ### **推荐指定文件夹**：\n   新建文档时，建议主动提供飞书文件夹 token（可为具体文件夹或根文件夹），这样可以更高效地定位和管理文档。如果不确定具体的子文件夹，可以让LLM自动在你指定的文件夹下查找最合适的子目录来新建文档。\n   \n   > **如何获取文件夹 token？**\n   > 打开飞书文件夹页面，复制链接（如 `https://.../drive/folder/xxxxxxxxxxxxxxxxxxxxxx`），token 就是链接最后的那一串字符（如 `xxxxxxxxxxxxxxxxxxxxxx`，请勿泄露真实 token）。\n\n2. ### **图片上传路径说明**：\n   本地运行 MCP 时，图片路径既支持本地绝对路径，也支持 http/https 网络图片；如在服务器环境，仅支持网络图片链接（由于cursor调用mcp时参数长度限制，暂不支持直接上传图片文件本体，请使用图片路径或链接方式上传）。\n\n3. ### **公式使用说明**：\n   在文本块中可以混合使用普通文本和公式元素。公式使用LaTeX语法，如：`1+2=3`、`\\frac{a}{b}`、`\\sqrt{x}`等。支持在同一文本块中包含多个公式和普通文本。\n\n---\n\n## 🚨 故障排查\n\n### 权限问题排查\n先对照配置问题查看： [手把手教程 FEISHU_CONFIG.md](FEISHU_CONFIG.md)。\n\n#### 问题确认\n1. **检查应用权限**：确保应用已获得必要的文档访问权限\n2. **验证文档授权**：确认目标文档已授权给应用或应用所在的群组\n3. **检查可用范围**：确保应用发布版本的可用范围包含文档所有者\n\n#### 权限验证与排查\n1. 获取token：[自建应用获取 app_access_token](https://open.feishu.cn/api-explorer?apiName=app_access_token_internal&project=auth&resource=auth&version=v3)\n2. 使用第1步获取的token，验证是否有权限访问该文档：[获取文档基本信息](https://open.feishu.cn/api-explorer?apiName=get&project=docx&resource=document&version=v1)\n\n\n### 常见问题\n\n- **找不到应用**：检查应用是否已发布且可用范围配置正确\n- **权限不足**：参考[云文档常见问题](https://open.feishu.cn/document/ukTMukTMukTM/uczNzUjL3czM14yN3MTN)\n- **知识库访问问题**：参考[知识库常见问题](https://open.feishu.cn/document/server-docs/docs/wiki-v2/wiki-qa)\n\n---\n\n## 💖 支持项目\n\n如果这个项目帮助到了你，请考虑：\n\n- ⭐ 给项目一个 Star\n- 🐛 报告 Bug 和问题\n- 💡 提出新功能建议\n- 📖 改进文档\n- 🔀 提交 Pull Request\n\n你的支持是我们前进的动力！\n\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=cso1z/feishu-mcp&type=Timeline)](https://www.star-history.com/#cso1z/feishu-mcp&Timeline)",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "feishu",
        "cso1z",
        "document",
        "cso1z feishu",
        "feishu documents",
        "processing cso1z"
      ],
      "category": "document-processing"
    },
    "cuongpham2107--word-mcp-server": {
      "owner": "cuongpham2107",
      "name": "word-mcp-server",
      "url": "https://github.com/cuongpham2107/word-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/cuongpham2107.webp",
      "description": "Facilitates the creation and editing of Microsoft Word documents via a straightforward API. Supports adding formatted text, images, and tables, enabling document generation and modification through natural language commands with LLM integration.",
      "stars": 1,
      "forks": 0,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-04-16T01:42:41Z",
      "readme_content": "# Word MCP Server\n\nWord MCP Server là một ứng dụng Python cho phép tạo và chỉnh sửa tài liệu Microsoft Word (.docx) thông qua API. Dự án này sử dụng FastMCP để xây dựng các công cụ tương tác với tài liệu Word.\n\n## Cài đặt\n\n### Yêu cầu\n\n- Python 3.12+\n- Các thư viện phụ thuộc:\n  - python-docx\n  - opencv-python (cv2)\n  - numpy\n  - FastMCP\n\n### Cài đặt thư viện\n```bash\nuv venv\nsource venv/bin/activate\nuv pip install .\n```\n\n## Tính năng\n\nWord MCP Server cung cấp các công cụ để:\n\n1. Tạo và mở tài liệu Word\n2. Thêm và định dạng văn bản\n3. Thêm hình ảnh\n4. Tạo bảng\n5. Quản lý tài nguyên và prompt\n\n## Hướng dẫn sử dụng\n\n### Cấu hình và khởi chạy với LLM\n\nĐể sử dụng Word MCP Server với các mô hình ngôn ngữ lớn (LLM), bạn cần cấu hình thông qua file JSON:\n\n```json\n{\n  \"mcpServers\": {\n    \"word-mcp-server\": {\n      \"command\": \"/path/to/word-mcp-server/.venv/bin/python3\",\n      \"args\": [\"/path/to/word-mcp-server/server.py\"]\n    }\n  }\n}\n```\n\n#### Giải thích cấu hình:\n\n- `mcpServers`: Object chứa cấu hình cho các MCP server\n- `word-mcp-server`: Tên định danh của server\n- `command`: Đường dẫn đến Python interpreter (thường nằm trong môi trường ảo)\n- `args`: Các tham số dòng lệnh, trong đó tham số đầu tiên là đường dẫn đến file server.py\n\n\n## Server sẽ khởi động và sẵn sàng nhận lệnh từ LLM\n\n#### Tương tác với LLM:\n\nKhi đã cấu hình và khởi chạy thành công, bạn có thể sử dụng LLM để:\n- Tạo và chỉnh sửa tài liệu Word thông qua lệnh tự nhiên\n- Tự động tạo nội dung dựa trên prompt\n- Định dạng văn bản, thêm hình ảnh và bảng một cách thông minh\n\n### Tạo tài liệu mới\n\n```python\ncreate_new_document()\n```\n\n### Mở tài liệu có sẵn\n\n```python\nopen_document(\"path/to/document.docx\")\n```\n\n### Thêm tiêu đề và đoạn văn\n\n```python\n# Thêm tiêu đề\nadd_heading(\"Tiêu đề tài liệu\", level=0)\nadd_heading(\"Chương 1\", level=1)\n\n# Thêm đoạn văn bản\nadd_paragraph(\"Đây là nội dung đoạn văn bản.\")\n\n# Thêm đoạn văn bản với định dạng\nadd_paragraph(\n    \"Đây là đoạn văn bản được định dạng.\",\n    style=\"Normal\",\n    font_size=14,\n    bold=True,\n    italic=False,\n    alignment=WD_PARAGRAPH_ALIGNMENT.CENTER\n)\n```\n\n### Thêm định dạng cho một phần văn bản\n\n```python\n# Tạo đoạn văn bản\np = add_paragraph(\"Đây là đoạn văn bản cơ bản. \")\n\n# Thêm phần văn bản có định dạng khác\nadd_run_to_paragraph(\n    p,\n    \"Phần này được in đậm và màu đỏ.\",\n    bold=True,\n    color=\"red\"\n)\n\n# Thêm phần văn bản có highlight\nadd_run_to_paragraph(\n    p,\n    \" Phần này được highlight màu vàng.\",\n    highlight=\"yellow\"\n)\n```\n\n### Thêm hình ảnh\n\n```python\n# Thêm hình ảnh từ đường dẫn file\nadd_picture(\"path/to/image.jpg\", width=4.0)\n\n# Hoặc thêm hình ảnh từ ma trận numpy\nimport numpy as np\nimport cv2\n\nimg = cv2.imread(\"path/to/image.jpg\")\nadd_picture(img, width=3.5)\n```\n\n### Tạo bảng\n\n```python\n# Tạo bảng với 3 hàng và 4 cột\ntable = add_table(rows=3, cols=4, style=\"Table Grid\")\n\n# Điền dữ liệu vào bảng\ntable.cell(0, 0).text = \"Hàng 1, Cột 1\"\ntable.cell(0, 1).text = \"Hàng 1, Cột 2\"\n# ...\n```\n\n## Các màu hỗ trợ\n\nKhi sử dụng các tham số `color` và `highlight`, bạn có thể sử dụng các giá trị sau:\n\n- black\n- blue\n- green\n- dark blue\n- dark red\n- dark yellow\n- dark green\n- pink\n- red\n- white\n- teal\n- yellow\n- violet\n- gray25\n- gray50\n\n## Lưu ý\n\n- Dự án này sử dụng thư viện `python-docx` để tương tác với tài liệu Word\n- Các tài nguyên và prompt được lưu trữ trong thư mục `resources` và `prompts`\n- Đảm bảo bạn đã cài đặt đầy đủ các thư viện phụ thuộc trước khi chạy server\n\n## Ví dụ hoàn chỉnh\n\n```python\n# Tạo tài liệu mới\ncreate_new_document()\n\n# Thêm tiêu đề\nadd_heading(\"Báo cáo dự án\", level=0)\n\n# Thêm thông tin người tạo\np = add_paragraph(\"Người tạo: \")\nadd_run_to_paragraph(p, \"Nguyễn Văn A\", bold=True)\n\n# Thêm mục lục\nadd_heading(\"Mục lục\", level=1)\nadd_paragraph(\"1. Giới thiệu\")\nadd_paragraph(\"2. Nội dung\")\nadd_paragraph(\"3. Kết luận\")\n\n# Thêm nội dung\nadd_heading(\"1. Giới thiệu\", level=1)\nadd_paragraph(\"Đây là phần giới thiệu của dự án...\")\n\n# Thêm hình ảnh\nadd_paragraph(\"Hình ảnh minh họa:\")\nadd_picture(\"project_diagram.jpg\", width=5.0)\n\n# Thêm bảng dữ liệu\nadd_heading(\"Bảng dữ liệu\", level=2)\ntable = add_table(rows=3, cols=3)\ntable.cell(0, 0).text = \"Dữ liệu 1\"\ntable.cell(0, 1).text = \"Dữ liệu 2\"\ntable.cell(0, 2).text = \"Dữ liệu 3\"\n# Điền các dữ liệu khác...\n\n# Lưu tài liệu\nsave_document(\"bao_cao_du_an.docx\")\n```\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "document",
        "cuongpham2107",
        "documents",
        "microsoft word",
        "word documents",
        "cuongpham2107 word"
      ],
      "category": "document-processing"
    },
    "d-kimuson--esa-mcp-server": {
      "owner": "d-kimuson",
      "name": "esa-mcp-server",
      "url": "https://github.com/d-kimuson/esa-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/d-kimuson.webp",
      "description": "Access the esa.io API through the Model Context Protocol (MCP), enabling search, creation, updating, and deletion of articles on esa.io.",
      "stars": 37,
      "forks": 5,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-12T11:08:49Z",
      "readme_content": "# esa-mcp-server\n\n[![smithery badge](https://smithery.ai/badge/@d-kimuson/esa-mcp-server)](https://smithery.ai/server/@d-kimuson/esa-mcp-server)\n\nesa-mcp-server は、[esa.io](https://esa.io) の API を [Model Context Protocol (MCP)](https://github.com/microsoft/model-context-protocol) を介して利用できるようにするサーバーです。\n\n<a href=\"https://glama.ai/mcp/servers/undwqgwbtd\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/undwqgwbtd/badge\" alt=\"ESA Server MCP server\" /></a>\n\n## 機能\n\n- get_search_query_document: esa.io の記事を検索するためのドキュメンテーションの提供\n- search_esa_posts: esa.io の記事検索\n- read_esa_post, read_esa_multiple_posts: 記事の詳細取得（単一・複数）\n- create_esa_post: 記事の作成\n- update_esa_post: 記事の更新\n- delete_esa_post: 記事の削除\n\n## Usage\n\n利用するツールに合わせて以下のように設定ファイルを準備してください。\n\n```json\n{\n  \"mcpServers\": {\n    \"esa-mcp-server\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"esa-mcp-server@latest\"],\n      \"env\": {\n        \"ESA_API_KEY\": \"your api key here\",\n        \"DEFAULT_ESA_TEAM\": \"your default esa team\"\n      }\n    }\n  }\n}\n```\n\n## プロンプト例\n\n```markdown\n## Using esa tools\n\nesa の情報を検索するために esa 以下のツールを利用できます。\n\n- 記事の検索には search_esa_posts ツールを利用します。複雑なクエリを利用する場合は get_search_query_document ツールで正確なクエリの記述方法を理解してから利用します。\n- 記事本文を取得するには read_esa_post, read_esa_multiple_posts ツールを利用します。複数の記事を取得する必要がある場合は read_esa_multiple_posts でまとめて取得することを推奨します。\n- 記事を作成/更新/削除するにはそれぞれ create_esa_post, update_esa_post, delete_esa_post ツールを利用します。\n```\n\n## 利用可能なツール\n\n[src/server.ts](./src/server.ts) を確認してください。\n\n## Contribution\n\n歓迎します。\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "esa",
        "io",
        "api",
        "esa mcp",
        "io api",
        "access esa"
      ],
      "category": "document-processing"
    },
    "danielpodrazka--editor-mcp": {
      "owner": "danielpodrazka",
      "name": "editor-mcp",
      "url": "https://github.com/danielpodrazka/editor-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/danielpodrazka.webp",
      "description": "Manage and edit text files through a standardized API with features for syntax checking, file management, and a two-step editing process to enhance data integrity. Supports operations on Python and JavaScript/React files for reading, locating functions, and editing with a diff preview.",
      "stars": 10,
      "forks": 5,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-03T22:32:25Z",
      "readme_content": "# Editor MCP\n\nA Python-based text editor server built with FastMCP that provides powerful tools for file operations. This server enables reading, editing, and managing text files through a standardized API with a unique multi-step approach that significantly improves code editing accuracy and reliability for LLMs and AI assistants.\n\n[![Verified on MSeeP](https://mseep.ai/badge.svg)](https://mseep.ai/app/b23694aa-c58a-469d-ba3c-fb54eb4d0d88)\n\n## Features\n\n- **File Selection**: Set a file to work with using absolute paths\n- **Read Operations**:\n  - Read entire files with line numbers using `skim`\n  - Read specific line ranges with prefixed line numbers using `read`\n  - Find specific text within files using `find_line`\n  - Find and extract function definitions in Python and JavaScript/JSX files using `find_function`\n- **Edit Operations**:\n  - Two-step editing process with diff preview\n  - Select and overwrite text with ID verification\n  - Clean editing workflow with select → overwrite → confirm/cancel pattern\n  - Syntax checking for Python (.py) and JavaScript/React (.js, .jsx) files\n  - Create new files with content\n- **File Management**:\n  - Create new files with proper initialization\n  - Delete files from the filesystem\n  - List directory contents with `listdir`\n- **Testing Support**:\n  - Run Python tests with `run_tests`\n  - Set Python paths for proper module resolution\n- **Safety Features**:\n  - Content ID verification to prevent conflicts\n  - Line count limits to prevent resource exhaustion\n  - Syntax checking to maintain code integrity\n  - Protected paths to restrict access to sensitive files\n\n## Security Risks\n\nThe editor-mcp includes powerful capabilities that come with certain security considerations:\n\n- **Jailbreak Risk**: The editor-mcp can potentially be jailbroken when reading a file that has harmful instructions embedded inside. Malicious content in files being edited could contain instructions that manipulate the AI assistant.\n- **Arbitrary Code Execution**: If running tests is enabled, there is a risk of arbitrary code execution through manipulated test files or malicious Python code.\n- **Data Exposure**: Access to file system operations could potentially expose sensitive information if proper path protections aren't configured.\n\nTo mitigate these risks:\n\n1. Use the `PROTECTED_PATHS` environment variable to restrict access to sensitive files and directories.\n2. Disable test running capabilities in production environments unless absolutely necessary.\n3. Carefully review files before opening them, especially if they come from untrusted sources.\n4. Consider running the editor in a sandboxed environment with limited permissions.\n\n## Key Advantages For LLMs\n\nThis text editor's unique design solves critical problems that typically affect LLM code editing:\n\n- **Prevents Loss of Context** - Traditional approaches often lead to LLMs losing overview of the codebase after a few edits. This implementation maintains context through the multi-step process.\n\n- **Avoids Resource-Intensive Rewrites** - LLMs typically default to replacing entire files when confused, which is costly, slow, and inefficient. This editor enforces selective edits.\n\n- **Provides Visual Feedback** - The diff preview system allows the LLM to actually see and verify changes before committing them, dramatically reducing errors.\n\n- **Enforces Syntax Checking** - Automatic validation for Python and JavaScript/React ensures that broken code isn't committed.\n\n- **Improves Edit Reasoning** - The multi-step approach gives the LLM time to reason between steps, reducing haphazard token production.\n\n## Resource Management\n\nThe editor implements several safeguards to ensure system stability and prevent resource exhaustion:\n\n- **Maximum Edit Lines**: By default, the editor enforces a 50-line limit for any single edit operation\n## Installation\n\nThis MCP was developed and tested with Claude Desktop. You can download Claude Desktop on any platform.\nFor Claude Desktop on Linux, you can use an unofficial installation script (uses the official file), recommended repository:\nhttps://github.com/emsi/claude-desktop/tree/main\n\nOnce you have Claude Desktop installed, follow the instructions below to install this specific MCP:\n\n### Easy Installation with UVX (Recommended)\n\nThe easiest way to install the Editor MCP is using the provided installation script:\n\n```bash\n# Clone the repository\ngit clone https://github.com/danielpodrazka/editor-mcp.git\ncd editor-mcp\n\n# Run the installation script\nchmod +x install.sh\n./install.sh\n```\n\nThis script will:\n1. Check if UVX is installed and install it if necessary\n2. Install the Editor MCP in development mode\n3. Make the `editor-mcp` command available in your PATH\n\n### Manual Installation\n\n#### Using UVX\n\n```bash\n# Install directly from GitHub\nuvx install git+https://github.com/danielpodrazka/mcp-text-editor.git\n\n# Or install from a local clone\ngit clone https://github.com/danielpodrazka/mcp-text-editor.git\ncd mcp-text-editor\nuvx install -e .\n```\n\n#### Using Traditional pip\n\n```bash\npip install git+https://github.com/danielpodrazka/mcp-text-editor.git\n\n# Or from a local clone\ngit clone https://github.com/danielpodrazka/mcp-text-editor.git\ncd mcp-text-editor\npip install -e .\n```\n\n#### Using Requirements (Legacy)\n\nInstall from the lock file:\n```bash\nuv pip install -r uv.lock\n```\n\n### Generating a locked requirements file:\n```bash\nuv pip compile requirements.in -o uv.lock\n```\n\n## Usage\n\n### Starting the Server\n\nAfter installation, you can start the Editor MCP server using one of these methods:\n\n```bash\n# Using the installed script\neditor-mcp\n\n# Or using the Python module\npython -m text_editor.server\n```\n\n### MCP Configuration\n\nYou can add the Editor MCP to your MCP configuration file:\n\n```json\n{\n  \"mcpServers\": {\n     \"text-editor\": {\n       \"command\": \"editor-mcp\",\n       \"env\": {\n         \"MAX_SELECT_LINES\": \"100\",\n         \"ENABLE_JS_SYNTAX_CHECK\": \"0\",\n         \"FAIL_ON_PYTHON_SYNTAX_ERROR\": \"1\",\n         \"FAIL_ON_JS_SYNTAX_ERROR\": \"0\",\n         \"PROTECTED_PATHS\": \"*.env,.env*,config*.json,*secret*,/etc/passwd,/home/user/.ssh/id_rsa\"\n       }\n     }\n  }\n}\n```\n\n### Environment Variable Configuration\n\nThe Editor MCP supports several environment variables to customize its behavior:\n\n- **MAX_SELECT_LINES**: \"100\" - Maximum number of lines that can be edited in a single operation (default is 50)\n\n- **ENABLE_JS_SYNTAX_CHECK**: \"0\" - Enable/disable JavaScript and JSX syntax checking (default is \"1\" - enabled)\n\n- **FAIL_ON_PYTHON_SYNTAX_ERROR**: \"1\" - When enabled, Python syntax errors will automatically cancel the overwrite operation (default is enabled)\n\n- **FAIL_ON_JS_SYNTAX_ERROR**: \"0\" - When enabled, JavaScript/JSX syntax errors will automatically cancel the overwrite operation (default is disabled)\n\n- **PROTECTED_PATHS**: Comma-separated list of file patterns or paths that cannot be accessed, supporting wildcards (e.g., \"*.env,.env*,/etc/passwd\")\n\n### Sample MCP Config When Building From Source\n\n```json\n{\n  \"mcpServers\": {\n     \"text-editor\": {\n       \"command\": \"/home/daniel/pp/venvs/editor-mcp/bin/python\",\n       \"args\": [\"/home/daniel/pp/editor-mcp/src/text_editor/server.py\"],\n        \"env\": {\n          \"MAX_SELECT_LINES\": \"100\",\n          \"ENABLE_JS_SYNTAX_CHECK\": \"0\",\n          \"FAIL_ON_PYTHON_SYNTAX_ERROR\": \"1\",\n          \"FAIL_ON_JS_SYNTAX_ERROR\": \"0\",\n          \"PROTECTED_PATHS\": \"*.env,.env*,config*.json,*secret*,/etc/passwd,/home/user/.ssh/id_rsa\"\n        }\n     }\n  }\n}\n```\n\n## Available Tools\nThe Editor MCP provides 13 powerful tools for file manipulation, editing, and testing:\n\n#### 1. `set_file`\nSets the current file to work with.\n\n**Parameters**:\n- `filepath` (str): Absolute path to the file\n\n**Returns**:\n- Confirmation message with the file path\n\n#### 2. `skim`\nReads full text from the current file. Each line is prefixed with its line number.\n\n**Returns**:\n- Dictionary containing lines with their line numbers, total number of lines, and the max edit lines setting\n\n**Example output**:\n```\n{\n  \"lines\": [\n    [1, \"def hello():\"],\n    [2, \"    print(\\\"Hello, world!\\\")\"],\n    [3, \"\"],\n    [4, \"hello()\"]\n  ],\n  \"total_lines\": 4,\n  \"max_select_lines\": 50\n}\n```\n\n#### 3. `read`\nReads text from the current file from start line to end line.\n\n**Parameters**:\n- `start` (int): Start line number (1-based indexing)\n- `end` (int): End line number (1-based indexing)\n\n**Returns**:\n- Dictionary containing lines with their line numbers as keys, along with start and end line information\n\n**Example output**:\n```\n{\n  \"lines\": [\n    [1, \"def hello():\"],\n    [2, \"    print(\\\"Hello, world!\\\")\"],\n    [3, \"\"],\n    [4, \"hello()\"]\n  ],\n  \"start_line\": 1,\n  \"end_line\": 4\n}\n```\n\n#### 4. `select`\nSelect a range of lines from the current file for subsequent overwrite operation.\n\n**Parameters**:\n- `start` (int): Start line number (1-based)\n- `end` (int): End line number (1-based)\n\n**Returns**:\n- Dictionary containing the selected lines, line range, and ID for verification\n\n**Note**:\n- This tool validates the selection against max_select_lines\n- The selection details are stored for use in the overwrite tool\n- This must be used before calling the overwrite tool\n\n#### 5. `overwrite`\nPrepare to overwrite a range of lines in the current file with new text.\n\n**Parameters**:\n- `new_lines` (list): List of new lines to overwrite the selected range\n\n**Returns**:\n- Diff preview showing the proposed changes\n\n**Note**:\n- This is the first step in a two-step process:\n  1. First call overwrite() to generate a diff preview\n  2. Then call confirm() to apply or cancel() to discard the pending changes\n- This tool allows replacing the previously selected lines with new content\n- The number of new lines can differ from the original selection\n- For Python files (.py extension), syntax checking is performed before writing\n- For JavaScript/React files (.js, .jsx extensions), syntax checking is optional and can be disabled via the `ENABLE_JS_SYNTAX_CHECK` environment variable\n\n#### 6. `confirm`\nApply pending changes from the overwrite operation.\n\n**Returns**:\n- Operation result with status and message\n\n**Note**:\n- This is one of the two possible actions in the second step of the editing process\n- The selection is removed upon successful application of changes\n\n#### 7. `cancel`\nDiscard pending changes from the overwrite operation.\n\n**Returns**:\n- Operation result with status and message\n\n**Note**:\n- This is one of the two possible actions in the second step of the editing process\n- The selection remains intact when changes are cancelled\n\n#### 8. `delete_file`\nDelete the currently set file.\n\n**Returns**:\n- Operation result with status and message\n\n#### 9. `new_file`\nCreates a new file and automatically sets it as the current file for subsequent operations.\n\n**Parameters**:\n- `filepath` (str): Path of the new file\n\n**Returns**:\n- Operation result with status, message, and selection info\n- The first line is automatically selected for editing\n\n**Behavior**:\n- Automatically creates parent directories if they don't exist\n- Sets the newly created file as the current working file\n- The first line is pre-selected, ready for immediate editing\n\n**Protected Files Note**:\n- Files matching certain patterns (like `*.env`) can be created normally\n- However, once you move to another file, these protected files cannot be reopened\n- This allows for a \"write-once, protect-after\" workflow for sensitive configuration files\n- Example: You can create `config.env`, populate it with example config, but cannot reopen it later\n\n**Note**:\n- This tool will fail if the current file exists and is not empty\n\n#### 10. `find_line`\nFind lines that match provided text in the current file.\n\n**Parameters**:\n- `search_text` (str): Text to search for in the file\n\n**Returns**:\n- Dictionary containing matching lines with their line numbers and total matches\n\n**Example output**:\n```\n{\n  \"status\": \"success\",\n  \"matches\": [\n    [2, \"    print(\\\"Hello, world!\\\")\"]\n  ],\n  \"total_matches\": 1\n}\n```\n\n**Note**:\n- Returns an error if no file path is set\n- Searches for exact text matches within each line\n- The id can be used for subsequent edit operations\n\n#### 11. `find_function`\nFind a function or method definition in the current Python or JavaScript/JSX file.\n\n**Parameters**:\n- `function_name` (str): Name of the function or method to find\n\n**Returns**:\n- Dictionary containing the function lines with their line numbers, start_line, and end_line\n\n**Example output**:\n```\n{\n  \"status\": \"success\",\n  \"lines\": [\n    [10, \"def hello():\"],\n    [11, \"    print(\\\"Hello, world!\\\")\"],\n    [12, \"    return True\"]\n  ],\n  \"start_line\": 10,\n  \"end_line\": 12\n}\n```\n\n**Note**:\n- For Python files, this tool uses Python's AST and tokenize modules to accurately identify function boundaries including decorators and docstrings\n- For JavaScript/JSX files, this tool uses a combination of approaches:\n  - Primary method: Babel AST parsing when available (requires Node.js and Babel packages)\n  - Fallback method: Regex pattern matching for function declarations when Babel is unavailable\n- Supports various JavaScript function types including standard functions, async functions, arrow functions, and React hooks\n- Returns an error if no file path is set or if the function is not found\n\n#### 12. `listdir`\nLists the contents of a directory.\n\n**Parameters**:\n- `dirpath` (str): Path to the directory to list\n\n**Returns**:\n- Dictionary containing list of filenames and the path queried\n\n#### 13. `run_tests` and `set_python_path`\nTools for running Python tests with pytest and configuring the Python environment.\n  - Set to \"0\", \"false\", or \"no\" to disable JavaScript syntax checking\n  - Useful if you don't have Babel and related dependencies installed\n- `FAIL_ON_PYTHON_SYNTAX_ERROR`: Controls whether Python syntax errors automatically cancel the overwrite operation (default: 1)\n  - When enabled, syntax errors in Python files will cause the overwrite action to be automatically cancelled\n  - The lines will remain selected so you can fix the error and try again\n- `FAIL_ON_JS_SYNTAX_ERROR`: Controls whether JavaScript/JSX syntax errors automatically cancel the overwrite operation (default: 0)\n  - When enabled, syntax errors in JavaScript/JSX files will cause the overwrite action to be automatically cancelled\n  - The lines will remain selected so you can fix the error and try again\n- `DUCKDB_USAGE_STATS`: Controls whether usage statistics are collected in a DuckDB database (default: 0)\n  - Set to \"1\", \"true\", or \"yes\" to enable collection of tool usage statistics\n  - When enabled, records information about each tool call including timestamps and arguments\n- `STATS_DB_PATH`: Path where the DuckDB database for statistics will be stored (default: \"text_editor_stats.duckdb\")\n  - Only used when `DUCKDB_USAGE_STATS` is enabled\n- `PROTECTED_PATHS`: Comma-separated list of file patterns or absolute paths that will be denied access\n  - Example: `*.env,.env*,config*.json,*secret*,/etc/passwd,/home/user/credentials.txt`\n  - Supports both exact file paths and flexible glob patterns with wildcards in any position:\n    - `*.env` - matches files ending with .env, like `.env`, `dev.env`, `prod.env`\n    - `.env*` - matches files starting with .env, like `.env`, `.env.local`, `.env.production`\n    - `*secret*` - matches any file containing 'secret' in the name\n  - Provides protection against accidentally exposing sensitive configuration files and credentials\n  - The lines will remain selected so you can fix the error and try again\n\n## Development\n\n### Prerequisites\n\nThe editor-mcp requires:\n- Python 3.7+\n- FastMCP package\n- black (for Python code formatting checks)\n- Babel (for JavaScript/JSX syntax checks if working with those files)\n\nInstall development dependencies:\n\n```bash\n# Using pip\npip install pytest pytest-asyncio pytest-cov\n\n# Using uv\nuv pip install pytest pytest-asyncio pytest-cov\n```\n\nFor JavaScript/JSX syntax validation, you need Node.js and Babel. The text editor uses `npx babel` to check JS/JSX syntax when editing these file types:\n\n```bash\n# Required for JavaScript/JSX syntax checking\nnpm install --save-dev @babel/core @babel/cli @babel/preset-env @babel/preset-react\n# You can also install these globally if you prefer\n# npm install -g @babel/core @babel/cli @babel/preset-env @babel/preset-react\n```\n\nThe editor requires:\n- `@babel/core` and `@babel/cli` - Core Babel packages for syntax checking\n- `@babel/preset-env` - For standard JavaScript (.js) files\n- `@babel/preset-react` - For React JSX (.jsx) files\n\n### Running Tests\n\n```bash\n# Run tests\npytest -v\n\n# Run tests with coverage\npytest -v --cov=text_editor\n```\n\n### Test Structure\n\nThe test suite covers:\n\n1. **set_file tool**\n   - Setting valid files\n   - Setting non-existent files\n   \n2. **read tool**\n   - File state validation\n   - Reading entire files\n   - Reading specific line ranges\n   - Edge cases like empty files\n   - Invalid range handling\n\n3. **select tool**\n   - Line range validation\n   - Selection validation against max_select_lines\n   - Selection storage for subsequent operations\n\n4. **overwrite tool**\n   - Verification of selected content using ID\n   - Content replacement validation\n   - Syntax checking for Python and JavaScript/React files\n   - Generation of diff preview for changes\n\n5. **confirm and cancel tools**\n   - Applying or canceling pending changes\n   - Two-step verification process\n   \n6. **delete_file tool**\n   - File deletion validation\n\n7. **new_file tool**\n   - File creation validation\n   - Handling existing files\n\n8. **find_line tool**\n   - Finding text matches in files\n   - Handling specific search terms\n   - Error handling for non-existent files\n   - Handling cases with no matches\n   - Handling existing files\n\n## How it Works\n\n### The Multi-Step Editing Approach\n\nUnlike traditional code editing approaches where LLMs simply search for lines to edit and make replacements (often leading to confusion after multiple edits), this editor implements a structured multi-step workflow that dramatically improves editing accuracy:\n\n1. **set_file** - First, the LLM sets which file it wants to edit\n2. **skim** - The LLM reads the entire file to gain a complete overview\n3. **read** - The LLM examines specific sections relevant to the task, with lines shown alongside numbers for better context\n4. **select** - When ready to edit, the LLM selects specific lines (limited to a configurable number, default 50)\n5. **overwrite** - The LLM proposes replacement content, resulting in a git diff-style preview that shows exactly what will change\n6. **confirm/cancel** - After reviewing the preview, the LLM can either apply or discard the changes\n\nThis structured workflow forces the LLM to reason carefully about each edit and prevents common errors like accidentally overwriting entire files. By seeing previews of changes before committing them, the LLM can verify its edits are correct.\n\n### ID Verification System\n\nThe server uses FastMCP to expose text editing capabilities through a well-defined API. The ID verification system ensures data integrity by verifying that the content hasn't changed between reading and modifying operations.\n\nThe ID mechanism uses SHA-256 to generate a unique identifier of the file content or selected line ranges. For line-specific operations, the ID includes a prefix indicating the line range (e.g., \"L10-15-[hash]\"). This helps ensure that edits are being applied to the expected content.\n\n## Implementation Details\n\nThe main `TextEditorServer` class:\n\n1. Initializes with a FastMCP instance named \"text-editor\"\n2. Sets a configurable `max_select_lines` limit (default: 50) from environment variables\n3. Maintains the current file path as state\n4. Registers thirteen primary tools through FastMCP:\n   - `set_file`: Validates and sets the current file path\n   - `skim`: Reads the entire content of a file, returning a dictionary of line numbers to line text\n   - `read`: Reads lines from specified line range, returning a structured dictionary of line content\n   - `select`: Selects lines for subsequent overwrite operation\n   - `overwrite`: Takes a list of new lines and prepares diff preview for changing content\n   - `confirm`: Applies pending changes from the overwrite operation\n   - `cancel`: Discards pending changes from the overwrite operation\n   - `delete_file`: Deletes the current file\n   - `new_file`: Creates a new file\n   - `find_line`: Finds lines containing specific text\n   - `find_function`: Finds function or method definitions in Python and JavaScript/JSX files\n   - `listdir`: Lists contents of a directory\n   - `run_tests` and `set_python_path`: Tools for running Python tests\n\nThe server runs using FastMCP's stdio transport by default, making it easy to integrate with various clients.\n\n## System Prompt for Best Results\n\nFor optimal results with AI assistants, it's recommended to use the system prompt (see [system_prompt.md](system_prompt.md)) that helps guide the AI in making manageable, safe edits.\n\nThis system prompt helps the AI assistant:\n\n1. **Make incremental changes** - Breaking down edits into smaller parts\n2. **Maintain code integrity** - Making changes that keep the code functional\n3. **Work within resource limits** - Avoiding operations that could overwhelm the system\n4. **Follow a verification workflow** - Doing final checks for errors after edits\n\nBy incorporating this system prompt when working with AI assistants, you'll get more reliable editing behavior and avoid common pitfalls in automated code editing.\n\n\n\n## Usage Statistics\n\nThe text editor MCP can collect usage statistics when enabled, providing insights into how the editing tools are being used:\n\n- **Data Collection**: Statistics are collected in a DuckDB database when `DUCKDB_USAGE_STATS` is enabled\n- **Tracked Information**: Records tool name, arguments, timestamp, current file path, tool response, and request/client IDs\n- **Storage Location**: Data is stored in a DuckDB file specified by `STATS_DB_PATH`\n- **Privacy**: Everything is stored locally on your machine\n\nThe collected statistics can help understand usage patterns, identify common workflows, and optimize the editor for most frequent operations.\n\nYou can query the database using standard SQL via any DuckDB client to analyze usage patterns.\n## Troubleshooting\n\nIf you encounter issues:\n\n1. Check file permissions\n2. Verify that the file paths are absolute\n3. Ensure the environment is using Python 3.7+\n\n\n## Inspiration\n\nInspired by a similar project: https://github.com/tumf/mcp-text-editor, which at first I forked, however I decided to rewrite the whole codebase from scratch so only the general idea stayed the same.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "editor",
        "editing",
        "file",
        "danielpodrazka editor",
        "editor mcp",
        "editing process"
      ],
      "category": "document-processing"
    },
    "dazeb--markdown-downloader": {
      "owner": "dazeb",
      "name": "markdown-downloader",
      "url": "https://github.com/dazeb/markdown-downloader",
      "imageUrl": "/freedevtools/mcp/pfp/dazeb.webp",
      "description": "Download webpages and convert their content into markdown files. Features include a configurable download directory and automatic date-stamped filenames for organized storage.",
      "stars": 38,
      "forks": 15,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-10-01T23:57:02Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/dazeb-markdown-downloader-badge.jpg)](https://mseep.ai/app/dazeb-markdown-downloader)\n[![MseeP Badge](https://mseep.net/pr/dazeb-markdown-downloader-badge.jpg)](https://mseep.ai/app/dazeb-markdown-downloader)\n\n[![Verified on MseeP](https://mseep.ai/badge.svg)](https://mseep.ai/app/e85a9805-464e-46bd-a953-ccac0c4a5129)\n\n# Markdown Downloader MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@dazeb/markdown-downloader)](https://smithery.ai/server/@dazeb/markdown-downloader)\n\n## Overview\n\nMarkdown Downloader is a powerful MCP (Model Context Protocol) server that allows you to download webpages as markdown files with ease. Leveraging the r.jina.ai service, this tool provides a seamless way to convert web content into markdown format.\n\n<a href=\"https://glama.ai/mcp/servers/jrki7zltg7\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/jrki7zltg7/badge\" alt=\"Markdown Downloader MCP server\" />\n</a>\n\n## Features\n\n- 🌐 Download webpages as markdown using r.jina.ai\n- 📁 Configurable download directory\n- 📝 Automatically generates date-stamped filenames\n- 🔍 List downloaded markdown files\n- 💾 Persistent configuration\n\n## Prerequisites\n\n- Node.js (version 16 or higher)\n- npm (Node Package Manager)\n\n## Installation\n\n### Installing via Smithery\n\nTo install Markdown Downloader for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@dazeb/markdown-downloader):\n\n```bash\nnpx -y @smithery/cli install @dazeb/markdown-downloader --client claude\n```\n\n### Installing manually\n\n1. Clone the repository:\n   ```bash\n   git clone https://github.com/your-username/markdown-downloader.git\n   cd markdown-downloader\n   ```\n\n2. Install dependencies:\n   ```bash\n   npm install\n   ```\n\n3. Build the project:\n   ```bash\n   npm run build\n   ```\n\n## Manually Add Server to Cline/Roo-Cline MCP Settings file\n\n### Linux/macOS\n```json\n{\n  \"mcpServers\": {\n    \"markdown-downloader\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/home/user/Documents/Cline/MCP/markdown-downloader/build/index.js\"\n      ],\n      \"disabled\": false,\n      \"alwaysAllow\": [\n        \"download_markdown\",\n        \"set_download_directory\"\n      ]\n    }\n  }\n}\n```\n\n### Windows\n```json\n{\n  \"mcpServers\": {\n    \"markdown-downloader\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"C:\\\\Users\\\\username\\\\Documents\\\\Cline\\\\MCP\\\\markdown-downloader\\\\build\\\\index.js\"\n      ],\n      \"disabled\": false,\n      \"alwaysAllow\": [\n        \"download_markdown\",\n        \"set_download_directory\"\n      ]\n    }\n  }\n}\n```\n\n## Tools and Usage\n\n### 1. Set Download Directory\n\nChange the download directory:\n\n```bash\nuse set_download_directory /path/to/your/local/download/folder\n```\n\n- Validates directory exists and is writable\n- Persists the configuration for future use\n\n### 2. Download Markdown\n\nDownload a webpage as a markdown file:\n\n```bash\nuse tool download_markdown https://example.com/blog-post\n```\n\n- The URL will be prepended with `r.jina.ai`\n- Filename format: `{sanitized-url}-{date}.md`\n- Saved in the configured download directory\n\n### 3. List Downloaded Files\n\nList all downloaded markdown files:\n\n```bash\nuse list_downloaded_files\n```\n\n### 4. Get Download Directory\n\nRetrieve the current download directory:\n\n```bash\nuse get_download_directory\n```\n\n## Configuration\n\n### Linux/macOS\n- Configuration is stored in `~/.config/markdown-downloader/config.json`\n- Default download directory: `~/.markdown-downloads`\n\n### Windows\n- Configuration is stored in `%APPDATA%\\markdown-downloader\\config.json`\n- Default download directory: `%USERPROFILE%\\Documents\\markdown-downloads`\n\n## Troubleshooting\n\n- Ensure you have an active internet connection\n- Check that the URL is valid and accessible\n- Verify write permissions for the download directory\n\n## Security\n\n- The tool uses r.jina.ai to fetch markdown content\n- Local files are saved with sanitized filenames\n- Configurable download directory allows flexibility\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## License\n\nThis project is licensed under the MIT License. See the LICENSE file for details.\n\n## Disclaimer\n\nThis tool is provided as-is. Always review downloaded content for accuracy and appropriateness.\n\n## Support\n\nFor issues or feature requests, please open an issue on the GitHub repository.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "markdown",
        "dazeb",
        "downloader",
        "markdown downloader",
        "dazeb markdown",
        "processing dazeb"
      ],
      "category": "document-processing"
    },
    "decvb--context7": {
      "owner": "decvb",
      "name": "context7",
      "url": "https://github.com/decvb/context7",
      "imageUrl": "/freedevtools/mcp/pfp/null.webp",
      "description": "Fetches up-to-date, version-specific code documentation and examples to enhance LLM prompts, reducing outdated code and hallucinated APIs. Integrates real-time library documentation into coding workflows for improved accuracy and productivity.",
      "stars": 0,
      "forks": 0,
      "license": "Unknown",
      "language": "Unknown",
      "updated_at": "",
      "readme_content": "",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "decvb",
        "documentation",
        "context7",
        "decvb context7",
        "processing decvb",
        "documentation coding"
      ],
      "category": "document-processing"
    },
    "dev-ithitchhiker--mcp-google-docs": {
      "owner": "dev-ithitchhiker",
      "name": "mcp-google-docs",
      "url": "https://github.com/dev-ithitchhiker/mcp-google-docs",
      "imageUrl": "/freedevtools/mcp/pfp/dev-ithitchhiker.webp",
      "description": "Manipulate Google Spreadsheets and Drive to create, copy, and manage files, allowing for efficient integration of document operations within applications.",
      "stars": 10,
      "forks": 2,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-06-10T20:10:32Z",
      "readme_content": "# MCP Google Workspace Integration\n\nA comprehensive MCP (Metoro Control Protocol) tool for interacting with Google Workspace services including Google Docs, Sheets, Slides, and Drive.\n\n## Features\n\n### Google Drive Features\n- List files\n- Copy files\n- Rename files\n- Create empty spreadsheets\n- Create spreadsheets from templates\n- Copy existing spreadsheets\n\n### Google Sheets Features\n- List sheets\n- Copy sheets\n- Rename sheets\n- Get sheet data\n- Add/Delete rows\n- Add/Delete columns\n- Update cells\n- Create/Update/Delete charts\n- Update cell formats\n\n### Google Docs Features\n- Create documents\n- Insert text with formatting\n- Add headings\n- Insert images\n- Create and manage tables\n- Insert page breaks\n- Add horizontal rules\n- Update document styles\n- Manage table styles and content\n\n### Google Slides Features\n- Create presentations\n- Add slides\n- Insert images\n- Add shapes and lines\n- Update text styles\n- Modify slide backgrounds\n- Update slide layouts\n- Add slide transitions\n- Add speaker notes\n\n## Installation\n\n### 1. Virtual Environment Setup\n\n#### macOS/Linux\n```bash\n# Create virtual environment\npython -m venv venv\n\n# Activate virtual environment\nsource venv/bin/activate\n```\n\n#### Windows\n```bash\n# Create virtual environment\npython -m venv venv\n\n# Activate virtual environment\nvenv\\Scripts\\activate\n```\n\n### 2. Install Required Packages\n```bash\npip install -r requirements.txt\n```\n\n### 3. Google Cloud Console Setup\n1. Create a project in Google Cloud Console\n2. Create OAuth 2.0 client ID\n3. Enable required APIs:\n   - Google Sheets API\n   - Google Drive API\n   - Google Docs API\n   - Google Slides API\n\n### 4. Environment Variables Setup\n```bash\nexport MCPGD_CLIENT_SECRET_PATH=\"/path/to/client_secret.json\"\nexport MCPGD_FOLDER_ID=\"your_folder_id\"\nexport MCPGD_TOKEN_PATH=\"/path/to/token.json\"  # Optional\n```\n\n## Usage\n\n### 1. Run the Program\n```bash\npython main.py\n```\n\n### 2. Use Tools via MCP\n\n#### Google Drive Examples\n```bash\n# List files\nmcp list_files\n\n# Copy a file\nmcp copy_file --file-id \"file_id\" --new_name \"new_name\"\n```\n\n#### Google Sheets Examples\n```bash\n# Get sheet data\nmcp get_sheet_data --spreadsheet_id \"your_spreadsheet_id\" --range \"Sheet1!A1:D10\"\n\n# Create chart\nmcp create_chart --chart_type \"LINE\" --range \"A1:B10\" --sheet_name \"Sheet1\" --title \"Sales Trend\"\n```\n\n#### Google Docs Examples\n```bash\n# Create document\nmcp create_document --title \"My Document\"\n\n# Insert formatted text\nmcp insert_text_to_document --document_id \"doc_id\" --text \"Hello World\" --font_family \"Arial\" --font_size 12\n```\n\n#### Google Slides Examples\n```bash\n# Create presentation\nmcp create_presentation --title \"My Presentation\"\n\n# Add slide with content\nmcp add_slide_to_presentation --presentation_id \"presentation_id\" --title \"Slide Title\" --content \"Slide Content\"\n```\n\n## Environment Variables\n\n- `MCPGD_CLIENT_SECRET_PATH`: Path to Google OAuth 2.0 client secret file\n- `MCPGD_FOLDER_ID`: Google Drive folder ID\n- `MCPGD_TOKEN_PATH`: Path to token storage file (Optional, Default: ~/.mcp_google_spreadsheet.json)\n\n## License\n\nMIT License\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "document",
        "spreadsheets",
        "docs",
        "google docs",
        "document processing",
        "document operations"
      ],
      "category": "document-processing"
    },
    "disruption-hub--payloadcmsmcp": {
      "owner": "disruption-hub",
      "name": "payloadcmsmcp",
      "url": "https://github.com/disruption-hub/payloadcmsmcp",
      "imageUrl": "/freedevtools/mcp/pfp/disruption-hub.webp",
      "description": "Validates code, generates templates, and scaffolds projects that conform to best practices within Payload CMS development. Aims to streamline workflow and enhance application quality with specialized tools.",
      "stars": 90,
      "forks": 34,
      "license": "MIT License",
      "language": "HTML",
      "updated_at": "2025-09-27T20:44:32Z",
      "readme_content": "# 🚀 Payload CMS 3.0 MCP Server\n\n<div align=\"center\">\n  <p align=\"center\">\n    <img src=\"https://www.payloadcmsmcp.info/logopayload.png\" alt=\"Payload CMS Logo\" width=\"120\" height=\"120\" style=\"border-radius: 10px; padding: 5px; background-color: white; box-shadow: 0 3px 10px rgba(0, 0, 0, 0.25);\" />\n  </p>\n<p align=\"center\">\n    <img src=\"https://img.shields.io/badge/Model%20Context%20Protocol-Enabled-6366F1?style=for-the-badge\" alt=\"MCP Enabled\" />\n    <img src=\"https://img.shields.io/badge/Payload%20CMS%203.0-Integration-3B82F6?style=for-the-badge\" alt=\"Payload CMS\" />\n    <img src=\"https://img.shields.io/badge/License-MIT-10B981?style=for-the-badge\" alt=\"License\" />\n    <img src=\"https://img.shields.io/badge/Railway-Deployment-0B0D0E?style=for-the-badge\" alt=\"Railway Deployment\" />\n  </p>\n  \n  <h3>A specialized MCP server for Payload CMS 3.0</h3>\n  <p>Validate code, generate templates, and scaffold projects following best practices</p>\n</div>\n\n<hr>\n\n## 📋 Overview\n\nThe Payload CMS 3.0 MCP Server is a specialized Model Context Protocol server designed to enhance your Payload CMS development experience. It helps developers build better Payload CMS applications by providing code validation, template generation, and project scaffolding capabilities that follow best practices.\n\n<hr>\n\n## ✨ Features\n\n<div align=\"center\">\n  <table>\n    <tr>\n      <td align=\"center\">\n        <h3>📚</h3>\n        <b>Code Validation</b>\n        <p>Validate Payload CMS code for collections, fields, globals, and config files with detailed feedback on syntax errors and best practices.</p>\n      </td>\n      <td align=\"center\">\n        <h3>🔍</h3>\n        <b>Code Generation</b>\n        <p>Generate code templates for collections, fields, globals, access control, hooks, endpoints, plugins, blocks, and migrations.</p>\n      </td>\n      <td align=\"center\">\n        <h3>🚀</h3>\n        <b>Project Scaffolding</b>\n        <p>Scaffold entire Payload CMS projects with validated options for consistency and adherence to best practices.</p>\n      </td>\n    </tr>\n  </table>\n</div>\n\n<hr>\n\n## 🔧 Payload CMS 3.0 Capabilities\n\n### Validation Tools\n\n* `validate` - Validate code for collections, fields, globals, and config\n* `query` - Query validation rules and best practices\n* `mcp_query` - Execute SQL-like queries for Payload CMS structures\n\n### Code Generation\n\n* `generate_template` - Generate code templates for various components\n* `generate_collection` - Create complete collection definitions\n* `generate_field` - Generate field definitions with proper typing\n\n### Project Setup\n\n* `scaffold_project` - Create entire Payload CMS project structures\n* `validate_scaffold_options` - Ensure scaffold options follow best practices (used internally by scaffold_project)\n\n<hr>\n\n## 📝 Detailed Tool Reference\n\n### Validation Tools\n\n#### `validate`\nValidates Payload CMS code for syntax and best practices.\n\n**Parameters:**\n- `code` (string): The code to validate\n- `fileType` (enum): Type of file - \"collection\", \"field\", \"global\", or \"config\"\n\n**Example Prompt:**\n```\nCan you validate this Payload CMS collection code?\n\n```typescript\nexport const Posts = {\n  slug: 'posts',\n  fields: [\n    {\n      name: 'title',\n      type: 'text',\n      required: true,\n    },\n    {\n      name: 'content',\n      type: 'richText',\n    }\n  ],\n  admin: {\n    useAsTitle: 'title',\n  }\n}\n```\n\n#### `query`\nQueries validation rules and best practices for Payload CMS.\n\n**Parameters:**\n- `query` (string): The query string\n- `fileType` (optional enum): Type of file - \"collection\", \"field\", \"global\", or \"config\"\n\n**Example Prompt:**\n```\nWhat are the best practices for implementing access control in Payload CMS collections?\n```\n\n#### `mcp_query`\nExecutes SQL-like queries against Payload CMS structures.\n\n**Parameters:**\n- `sql` (string): SQL-like query string\n\n**Example Prompt:**\n```\nCan you execute this query to find all valid field types in Payload CMS?\nSELECT field_types FROM payload_schema WHERE version = '3.0'\n```\n\n### Code Generation\n\n#### `generate_template`\nGenerates code templates for various Payload CMS components.\n\n**Parameters:**\n- `templateType` (enum): Type of template - \"collection\", \"field\", \"global\", \"config\", \"access-control\", \"hook\", \"endpoint\", \"plugin\", \"block\", \"migration\"\n- `options` (record): Configuration options for the template\n\n**Example Prompt:**\n```\nGenerate a template for a Payload CMS hook that logs when a document is created.\n```\n\n#### `generate_collection`\nGenerates a complete Payload CMS collection definition.\n\n**Parameters:**\n- `slug` (string): Collection slug\n- `fields` (optional array): Array of field objects\n- `auth` (optional boolean): Whether this is an auth collection\n- `timestamps` (optional boolean): Whether to include timestamps\n- `admin` (optional object): Admin panel configuration\n- `hooks` (optional boolean): Whether to include hooks\n- `access` (optional boolean): Whether to include access control\n- `versions` (optional boolean): Whether to enable versioning\n\n**Example Prompt:**\n```\nGenerate a Payload CMS collection for a blog with title, content, author, and published date fields. Include timestamps and versioning.\n```\n\n#### `generate_field`\nGenerates a Payload CMS field definition.\n\n**Parameters:**\n- `name` (string): Field name\n- `type` (string): Field type\n- `required` (optional boolean): Whether the field is required\n- `unique` (optional boolean): Whether the field should be unique\n- `localized` (optional boolean): Whether the field should be localized\n- `access` (optional boolean): Whether to include access control\n- `admin` (optional object): Admin panel configuration\n- `validation` (optional boolean): Whether to include validation\n- `defaultValue` (optional any): Default value for the field\n\n**Example Prompt:**\n```\nGenerate a Payload CMS image field with validation that requires alt text and has a description in the admin panel.\n```\n\n### Project Setup\n\n#### `scaffold_project`\nScaffolds a complete Payload CMS project structure.\n\n**Parameters:**\n- `projectName` (string): Name of the project\n- `description` (optional string): Project description\n- `serverUrl` (optional string): Server URL\n- `database` (optional enum): Database type - \"mongodb\" or \"postgres\"\n- `auth` (optional boolean): Whether to include authentication\n- `admin` (optional object): Admin panel configuration\n- `collections` (optional array): Array of collection objects\n- `globals` (optional array): Array of global objects\n- `blocks` (optional array): Array of block objects\n- `plugins` (optional array): Array of plugin strings\n- `typescript` (optional boolean): Whether to use TypeScript\n\n**Example Prompt:**\n```\nScaffold a Payload CMS project called \"blog-platform\" with MongoDB, authentication, and collections for posts, categories, and users. Include a global for site settings.\n```\n\n<hr>\n\n## 🚀 Getting Started\n\n### 1. Prerequisites\n\nBefore you begin, make sure you have:\n\n* Node.js 18+ (required for Payload CMS 3.0)\n* An active Railway account\n* A Railway API token (create one at [railway.app/account/tokens](https://railway.app/account/tokens))\n* Basic familiarity with Payload CMS 3.0 concepts\n\n### 2. Configure Cursor\n\nTo use with Cursor IDE:\n\n1. Open Cursor Settings\n2. Go to MCP Servers section\n3. Add a new MCP server\n4. Name it \"Payload CMS 3.0 MCP\"\n5. Set Transport Type to \"Command\"\n6. Set Command to: `railway run --service=YOUR_SERVICE_ID`\n7. Save the configuration\n\n### 3. Using the MCP Server\n\nOnce configured, you can use these tools in your AI prompts:\n\n* **Code Validation:** \"Validate this Payload CMS collection code\"\n* **Template Generation:** \"Generate a template for a media collection\"\n* **Query Rules:** \"Query validation rules for access control\"\n* **SQL-like Queries:** \"Execute a query to find field types for collections\"\n\n### 4. Example Workflow\n\nA typical workflow with the Payload CMS MCP Server:\n\n1. Generate a collection template with specific fields\n2. Validate the generated code for best practices\n3. Query for specific validation rules to improve the code\n4. Generate additional components like hooks or endpoints\n5. Scaffold a complete project structure when ready\n\n### 5. Complete Workflow Example\n\nHere's a complete example of how you might use the MCP server in a conversation:\n\n```\nUser: I need to create a Payload CMS collection for a product catalog.\n\nAI: I'll help you create a product catalog collection. Let me generate a template for you.\n\n[Uses generate_collection tool]\n\nHere's a collection template for your product catalog:\n\n```typescript\nimport { CollectionConfig } from 'payload/types';\n\nexport const Products: CollectionConfig = {\n  slug: 'products',\n  admin: {\n    useAsTitle: 'name',\n    defaultColumns: ['name', 'price', 'category', 'inStock'],\n    group: 'Shop',\n  },\n  access: {\n    read: () => true,\n  },\n  fields: [\n    {\n      name: 'name',\n      type: 'text',\n      required: true,\n    },\n    {\n      name: 'description',\n      type: 'richText',\n    },\n    {\n      name: 'price',\n      type: 'number',\n      required: true,\n    },\n    {\n      name: 'category',\n      type: 'relationship',\n      relationTo: 'categories',\n      required: true,\n    },\n    {\n      name: 'images',\n      type: 'array',\n      fields: [\n        {\n          name: 'image',\n          type: 'upload',\n          relationTo: 'media',\n          required: true,\n        },\n        {\n          name: 'altText',\n          type: 'text',\n          required: true,\n        }\n      ]\n    },\n    {\n      name: 'inStock',\n      type: 'checkbox',\n      defaultValue: true,\n    },\n  ],\n  timestamps: true,\n}\n```\n\nUser: Can you validate this code to make sure it follows best practices?\n\nAI: I'll validate the code for you.\n\n[Uses validate tool]\n\nThe validation results show that your code is valid and follows best practices. Here are a few suggestions:\n\n1. Consider adding a maxDepth to your category relationship field to prevent deep queries\n2. You might want to add access control for create, update, and delete operations\n3. Consider adding hooks for inventory management when products are updated\n\nUser: What are the best practices for access control in Payload CMS?\n\nAI: Let me query the validation rules for access control.\n\n[Uses query tool]\n\nHere are the best practices for access control in Payload CMS:\n\n1. Always define explicit access control functions for create, read, update, and delete operations\n2. Use role-based access control for admin users\n3. Implement field-level access control for sensitive data\n4. Use collection-level access control for broad permissions\n5. Consider using hooks alongside access control for complex logic\n\nUser: Now I need to scaffold a complete project with this product collection and a categories collection.\n\nAI: I'll scaffold a complete project for you.\n\n[Uses scaffold_project tool]\n\nI've generated a complete Payload CMS project structure with the following:\n\n- Product collection as you specified\n- Categories collection with name and description fields\n- Media collection for product images\n- Authentication for admin users\n- TypeScript configuration\n- MongoDB database setup\n- All necessary files and configurations\n\nThe project is ready to be initialized with `npm install` and `npm run dev`.\n\n<hr>\n\n## 📋 Scaffolding Examples & Detailed Prompts\n\n### Project Scaffolding Examples\n\nWhen you scaffold a project using the MCP server, you'll receive a complete project structure. Here's what a scaffolded e-commerce project might look like:\n\n```\ne-commerce-platform/\n├── .env\n├── .eslintrc.js\n├── .gitignore\n├── README.md\n├── package.json\n├── tsconfig.json\n├── src/\n│   ├── payload.config.ts\n│   ├── server.ts\n│   ├── collections/\n│   │   ├── Products.ts\n│   │   ├── Categories.ts\n│   │   ├── Orders.ts\n│   │   ├── Customers.ts\n│   │   ├── Media.ts\n│   │   └── Users.ts\n│   ├── globals/\n│   │   ├── Settings.ts\n│   │   └── Footer.ts\n│   ├── blocks/\n│   │   ├── Hero.ts\n│   │   ├── ProductGrid.ts\n│   │   └── CallToAction.ts\n│   ├── fields/\n│   │   ├── richText/\n│   │   ├── metaImage.ts\n│   │   └── slug.ts\n│   ├── hooks/\n│   │   ├── beforeChange.ts\n│   │   └── afterChange.ts\n│   ├── access/\n│   │   ├── isAdmin.ts\n│   │   └── isAdminOrSelf.ts\n│   └── utilities/\n│       ├── formatSlug.ts\n│       └── sendEmail.ts\n```\n\n### Example Scaffold Project Prompt (Basic)\n\n```\nScaffold a Payload CMS project for a blog platform with the following:\n- Project name: blog-platform\n- Database: MongoDB\n- Authentication: Yes\n- Collections: Posts, Categories, Authors, Media\n- Globals: SiteSettings\n- TypeScript: Yes\n```\n\n### Example Scaffold Project Prompt (Detailed)\n\n```\nScaffold a comprehensive Payload CMS project for an e-commerce platform with the following specifications:\n\nProject details:\n- Name: luxury-watches-store\n- Description: \"An e-commerce platform for luxury watches\"\n- Database: PostgreSQL\n- TypeScript: Yes\n\nCollections needed:\n1. Products collection with:\n   - Name (text, required)\n   - Description (rich text)\n   - Price (number, required)\n   - SKU (text, unique)\n   - Brand (relationship to Brands collection)\n   - Categories (relationship to Categories, multiple)\n   - Features (array of text fields)\n   - Specifications (array of key-value pairs)\n   - Images (array of media uploads with alt text)\n   - Stock quantity (number)\n   - Status (select: available, out of stock, discontinued)\n\n2. Categories collection with:\n   - Name (text, required)\n   - Description (rich text)\n   - Parent category (self-relationship)\n   - Image (media upload)\n\n3. Brands collection with:\n   - Name (text, required)\n   - Logo (media upload)\n   - Description (rich text)\n   - Founded year (number)\n   - Country of origin (text)\n\n4. Orders collection with:\n   - Order number (text, generated)\n   - Customer (relationship to Users)\n   - Products (array of relationships to Products with quantity)\n   - Status (select: pending, processing, shipped, delivered, cancelled)\n   - Shipping address (group of fields)\n   - Billing address (group of fields)\n   - Payment method (select)\n   - Total amount (number, calculated)\n   - Notes (text)\n\n5. Users collection (auth enabled) with:\n   - Email (email, required)\n   - Name (text, required)\n   - Shipping addresses (array of address groups)\n   - Order history (relationship to Orders)\n   - Wishlist (relationship to Products)\n   - Role (select: customer, admin)\n\nGlobals:\n1. SiteSettings with:\n   - Site name\n   - Logo\n   - Contact information\n   - Social media links\n   - SEO defaults\n\n2. ShippingMethods with:\n   - Array of shipping options with prices\n\nInclude access control for:\n- Admin-only access to manage products, categories, brands\n- Customer access to their own orders and profile\n- Public read access to products and categories\n\nAdd hooks for:\n- Updating stock when orders are placed\n- Generating order numbers\n- Sending email notifications on order status changes\n```\n\n### Example Collection Creation Prompt (Basic)\n\n```\nGenerate a Payload CMS collection for blog posts with title, content, author, and published date fields.\n```\n\n### Example Collection Creation Prompt (Detailed)\n\n```\nGenerate a Payload CMS collection for a real estate property listing with the following specifications:\n\nCollection name: Properties\nAdmin configuration:\n- Use \"title\" as the display field\n- Group under \"Listings\" in the admin panel\n- Default columns: title, price, location, status, createdAt\n\nFields:\n1. Title (text, required)\n2. Slug (text, unique, generated from title)\n3. Description (rich text with basic formatting options)\n4. Price (number, required)\n5. Location (group) with:\n   - Address (text)\n   - City (text, required)\n   - State/Province (text, required)\n   - Postal code (text)\n   - Country (select from predefined list)\n   - Coordinates (point) for map display\n6. Property details (group) with:\n   - Property type (select: house, apartment, condo, land, commercial)\n   - Bedrooms (number)\n   - Bathrooms (number)\n   - Square footage (number)\n   - Lot size (number)\n   - Year built (number)\n   - Parking spaces (number)\n7. Features (array of checkboxes) including:\n   - Air conditioning\n   - Swimming pool\n   - Garden\n   - Garage\n   - Fireplace\n   - Security system\n   - Elevator\n   - Furnished\n8. Images (array of media uploads with alt text and caption)\n9. Documents (array of file uploads for floor plans, certificates, etc.)\n10. Status (select: available, under contract, sold, off market)\n11. Featured (checkbox to highlight on homepage)\n12. Agent (relationship to Users collection, required)\n13. Related properties (relationship to self, multiple)\n\nAccess control:\n- Public read access\n- Agent can create and edit their own listings\n- Admin can manage all listings\n\nHooks:\n- Before change: Format slug from title\n- After change: Notify agent of status changes\n\nVersioning: Enabled\nTimestamps: Enabled\n```\n\n### Level of Detail in Prompts\n\nThe MCP server can handle prompts with varying levels of detail:\n\n#### Minimal Detail (AI fills in the gaps)\n```\nGenerate a collection for blog posts.\n```\n\n#### Moderate Detail (Specific requirements)\n```\nGenerate a collection for blog posts with title, content, featured image, categories, and author fields. Make title and content required.\n```\n\n#### High Detail (Complete specifications)\n```\nGenerate a collection for blog posts with:\n- Slug: posts\n- Fields:\n  - Title (text, required)\n  - Content (rich text with custom formatting options)\n  - Featured image (upload with alt text)\n  - Categories (relationship to categories collection, multiple)\n  - Author (relationship to users collection)\n  - Status (select: draft, published, archived)\n  - Published date (date)\n  - SEO (group with title, description, and keywords)\n- Admin configuration:\n  - Use title as display field\n  - Group under \"Content\"\n  - Default columns: title, author, status, publishedDate\n- Access control for different user roles\n- Hooks for slug generation and notification\n- Enable versioning and timestamps\n```\n\n### Tips for Effective Prompts\n\n1. **Be specific about requirements**: The more details you provide, the more tailored the output will be.\n\n2. **Specify relationships**: Clearly indicate how collections relate to each other.\n\n3. **Include validation needs**: Mention any validation rules or constraints for fields.\n\n4. **Describe admin UI preferences**: Specify how you want the collection to appear in the admin panel.\n\n5. **Mention hooks and access control**: If you need specific business logic or security rules, include them in your prompt.\n\n6. **Use domain-specific terminology**: Describe your project using terms relevant to your industry or use case.\n\n<hr>\n\n## 📄 License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n<hr>\n\n## 🌍 About MATMAX WORLDWIDE\n\n<div align=\"center\">\n  <h3>MATMAX WORLDWIDE</h3>\n  <p>Creating technology that helps humans be more human.</p>\n</div>\n\nWe believe in tech for good—tools that enhance our lives while respecting our humanity.\n\nJoin us in building a future where technology serves wellness, connection, and purpose. Together, we can create digital experiences that bring out the best in us all.\n\nVisit [matmax.world](https://matmax.world) to learn more about our vision for human-centered technology.\n\n<hr>\n\n## 🖥️ Running Locally\n\nYou can run the Payload CMS MCP Server locally using npm:\n\n[![npm version](https://img.shields.io/npm/v/payload-cms-mcp.svg?style=flat-square)](https://www.npmjs.org/package/payload-cms-mcp)\n[![npm downloads](https://img.shields.io/npm/dm/payload-cms-mcp.svg?style=flat-square)](https://npmjs.org/package/payload-cms-mcp)\n\n### Option 1: Install from npm\n\n```bash\n# Install globally\nnpm install -g payload-cms-mcp\n\n# Run the server\npayload-cms-mcp\n```\n\n### Option 2: Clone the repository\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/Matmax-Worldwide/payloadcmsmcp.git\ncd payloadcmsmcp\n```\n\n2. Install dependencies:\n```bash\nnpm install\n```\n\n3. Run the server locally:\n```bash\nnpm run dev\n```\n\nOr alternatively:\n```bash\nnpm run local\n```\n\nYour MCP server will now be running locally and accessible for development and testing without requiring a Railway API token.\n\n## 🚀 Deployment Options\n\n### Deploy to Railway (Recommended)\n\nThe easiest way to deploy the MCP server is using Railway's one-click deployment:\n\n[![Deploy on Railway](https://railway.app/button.svg)](https://railway.app/new)\n\nAfter clicking the button:\n1. Select \"Deploy from GitHub repo\"\n2. Search for \"Matmax-Worldwide/payloadcmsmcp\"\n3. Click \"Deploy Now\"\n\n#### Quick Cursor IDE Setup\n\nAfter deployment:\n1. Install Railway CLI: `npm install -g @railway/cli`\n2. Login to Railway: `railway login`\n3. Link to your project: `railway link`\n4. In Cursor Settings > MCP Servers, set Command to: `railway run`",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "payloadcmsmcp",
        "payload",
        "cms",
        "hub payloadcmsmcp",
        "payload cms",
        "payloadcmsmcp validates"
      ],
      "category": "document-processing"
    },
    "diventnsknew--markitdown": {
      "owner": "diventnsknew",
      "name": "markitdown",
      "url": "https://github.com/diventnsknew/markitdown",
      "imageUrl": "/freedevtools/mcp/pfp/diventnsknew.webp",
      "description": "Converts various file formats to Markdown, facilitating integration with LLM applications and enabling text analysis pipelines while preserving document structure. Includes features for audio transcription and document intelligence to enhance data processing capabilities.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "",
      "updated_at": "2025-03-28T07:39:26Z",
      "readme_content": "# MarkItDown\n\n[![PyPI](https://img.shields.io/pypi/v/markitdown.svg)](https://pypi.org/project/markitdown/)\n![PyPI - Downloads](https://img.shields.io/pypi/dd/markitdown)\n[![Built by AutoGen Team](https://img.shields.io/badge/Built%20by-AutoGen%20Team-blue)](https://github.com/microsoft/autogen)\n\n> [!TIP]\n> MarkItDown now offers an MCP (Model Context Protocol) server for integration with LLM applications like Claude Desktop. See [markitdown-mcp](https://github.com/microsoft/markitdown/tree/main/packages/markitdown-mcp) for more information.\n\n> [!IMPORTANT]\n> Breaking changes between 0.0.1 to 0.1.0:\n> * Dependencies are now organized into optional feature-groups (further details below). Use `pip install 'markitdown[all]'` to have backward-compatible behavior. \n> * convert\\_stream() now requires a binary file-like object (e.g., a file opened in binary mode, or an io.BytesIO object). This is a breaking change from the previous version, where it previously also accepted text file-like objects, like io.StringIO.\n> * The DocumentConverter class interface has changed to read from file-like streams rather than file paths. *No temporary files are created anymore*. If you are the maintainer of a plugin, or custom DocumentConverter, you likely need to update your code. Otherwise, if only using the MarkItDown class or CLI (as in these examples), you should not need to change anything.\n\nMarkItDown is a lightweight Python utility for converting various files to Markdown for use with LLMs and related text analysis pipelines. To this end, it is most comparable to [textract](https://github.com/deanmalmgren/textract), but with a focus on preserving important document structure and content as Markdown (including: headings, lists, tables, links, etc.) While the output is often reasonably presentable and human-friendly, it is meant to be consumed by text analysis tools -- and may not be the best option for high-fidelity document conversions for human consumption.\n\nAt present, MarkItDown supports:\n\n- PDF\n- PowerPoint\n- Word\n- Excel\n- Images (EXIF metadata and OCR)\n- Audio (EXIF metadata and speech transcription)\n- HTML\n- Text-based formats (CSV, JSON, XML)\n- ZIP files (iterates over contents)\n- Youtube URLs\n- EPubs\n- ... and more!\n\n## Why Markdown?\n\nMarkdown is extremely close to plain text, with minimal markup or formatting, but still\nprovides a way to represent important document structure. Mainstream LLMs, such as\nOpenAI's GPT-4o, natively \"_speak_\" Markdown, and often incorporate Markdown into their\nresponses unprompted. This suggests that they have been trained on vast amounts of\nMarkdown-formatted text, and understand it well. As a side benefit, Markdown conventions\nare also highly token-efficient.\n\n## Installation\n\nTo install MarkItDown, use pip: `pip install 'markitdown[all]'`. Alternatively, you can install it from the source:\n\n```bash\ngit clone git@github.com:microsoft/markitdown.git\ncd markitdown\npip install -e packages/markitdown[all]\n```\n\n## Usage\n\n### Command-Line\n\n```bash\nmarkitdown path-to-file.pdf > document.md\n```\n\nOr use `-o` to specify the output file:\n\n```bash\nmarkitdown path-to-file.pdf -o document.md\n```\n\nYou can also pipe content:\n\n```bash\ncat path-to-file.pdf | markitdown\n```\n\n### Optional Dependencies\nMarkItDown has optional dependencies for activating various file formats. Earlier in this document, we installed all optional dependencies with the `[all]` option. However, you can also install them individually for more control. For example:\n\n```bash\npip install markitdown[pdf, docx, pptx]\n```\n\nwill install only the dependencies for PDF, DOCX, and PPTX files.\n\nAt the moment, the following optional dependencies are available:\n\n* `[all]` Installs all optional dependencies\n* `[pptx]` Installs dependencies for PowerPoint files\n* `[docx]` Installs dependencies for Word files\n* `[xlsx]` Installs dependencies for Excel files\n* `[xls]` Installs dependencies for older Excel files\n* `[pdf]` Installs dependencies for PDF files\n* `[outlook]` Installs dependencies for Outlook messages\n* `[az-doc-intel]` Installs dependencies for Azure Document Intelligence\n* `[audio-transcription]` Installs dependencies for audio transcription of wav and mp3 files\n* `[youtube-transcription]` Installs dependencies for fetching YouTube video transcription\n\n### Plugins\n\nMarkItDown also supports 3rd-party plugins. Plugins are disabled by default. To list installed plugins:\n\n```bash\nmarkitdown --list-plugins\n```\n\nTo enable plugins use:\n\n```bash\nmarkitdown --use-plugins path-to-file.pdf\n```\n\nTo find available plugins, search GitHub for the hashtag `#markitdown-plugin`. To develop a plugin, see `packages/markitdown-sample-plugin`.\n\n### Azure Document Intelligence\n\nTo use Microsoft Document Intelligence for conversion:\n\n```bash\nmarkitdown path-to-file.pdf -o document.md -d -e \"<document_intelligence_endpoint>\"\n```\n\nMore information about how to set up an Azure Document Intelligence Resource can be found [here](https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/how-to-guides/create-document-intelligence-resource?view=doc-intel-4.0.0)\n\n### Python API\n\nBasic usage in Python:\n\n```python\nfrom markitdown import MarkItDown\n\nmd = MarkItDown(enable_plugins=False) # Set to True to enable plugins\nresult = md.convert(\"test.xlsx\")\nprint(result.text_content)\n```\n\nDocument Intelligence conversion in Python:\n\n```python\nfrom markitdown import MarkItDown\n\nmd = MarkItDown(docintel_endpoint=\"<document_intelligence_endpoint>\")\nresult = md.convert(\"test.pdf\")\nprint(result.text_content)\n```\n\nTo use Large Language Models for image descriptions, provide `llm_client` and `llm_model`:\n\n```python\nfrom markitdown import MarkItDown\nfrom openai import OpenAI\n\nclient = OpenAI()\nmd = MarkItDown(llm_client=client, llm_model=\"gpt-4o\")\nresult = md.convert(\"example.jpg\")\nprint(result.text_content)\n```\n\n### Docker\n\n```sh\ndocker build -t markitdown:latest .\ndocker run --rm -i markitdown:latest < ~/your-file.pdf > output.md\n```\n\n## Contributing\n\nThis project welcomes contributions and suggestions. Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\n\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n### How to Contribute\n\nYou can help by looking at issues or helping review PRs. Any issue or PR is welcome, but we have also marked some as 'open for contribution' and 'open for reviewing' to help facilitate community contributions. These are ofcourse just suggestions and you are welcome to contribute in any way you like.\n\n<div align=\"center\">\n\n|            | All                                                          | Especially Needs Help from Community                                                                                                      |\n| ---------- | ------------------------------------------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------- |\n| **Issues** | [All Issues](https://github.com/microsoft/markitdown/issues) | [Issues open for contribution](https://github.com/microsoft/markitdown/issues?q=is%3Aissue+is%3Aopen+label%3A%22open+for+contribution%22) |\n| **PRs**    | [All PRs](https://github.com/microsoft/markitdown/pulls)     | [PRs open for reviewing](https://github.com/microsoft/markitdown/pulls?q=is%3Apr+is%3Aopen+label%3A%22open+for+reviewing%22)              |\n\n</div>\n\n### Running Tests and Checks\n\n- Navigate to the MarkItDown package:\n\n  ```sh\n  cd packages/markitdown\n  ```\n\n- Install `hatch` in your environment and run tests:\n\n  ```sh\n  pip install hatch  # Other ways of installing hatch: https://hatch.pypa.io/dev/install/\n  hatch shell\n  hatch test\n  ```\n\n  (Alternative) Use the Devcontainer which has all the dependencies installed:\n\n  ```sh\n  # Reopen the project in Devcontainer and run:\n  hatch test\n  ```\n\n- Run pre-commit checks before submitting a PR: `pre-commit run --all-files`\n\n### Contributing 3rd-party Plugins\n\nYou can also contribute by creating and sharing 3rd party plugins. See `packages/markitdown-sample-plugin` for more details.\n\n## Trademarks\n\nThis project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft\ntrademarks or logos is subject to and must follow\n[Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).\nUse of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.\nAny use of third-party trademarks or logos are subject to those third-party's policies.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "markitdown",
        "markdown",
        "formats",
        "diventnsknew markitdown",
        "markdown facilitating",
        "formats markdown"
      ],
      "category": "document-processing"
    },
    "dlamichhane--my-resume": {
      "owner": "dlamichhane",
      "name": "my-resume",
      "url": "https://github.com/dlamichhane/my-resume",
      "imageUrl": "/freedevtools/mcp/pfp/dlamichhane.webp",
      "description": "Showcase and highlight professional qualifications and achievements through a structured resume format. Allows users to effectively communicate their experiences to potential employers.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "HTML",
      "updated_at": "2025-09-01T14:46:38Z",
      "readme_content": "",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "resume",
        "dlamichhane",
        "format",
        "dlamichhane resume",
        "resume format",
        "structured resume"
      ],
      "category": "document-processing"
    },
    "dmayboroda--minima": {
      "owner": "dmayboroda",
      "name": "minima",
      "url": "https://github.com/dmayboroda/minima",
      "imageUrl": "/freedevtools/mcp/pfp/dmayboroda.webp",
      "description": "Minima is an open source RAG server that operates on-premises, allowing integration with ChatGPT and MCP. It provides secure local storage and processing of data while supporting querying of local documents through customizable GPT interfaces.",
      "stars": 1014,
      "forks": 91,
      "license": "Mozilla Public License 2.0",
      "language": "Python",
      "updated_at": "2025-10-01T11:24:21Z",
      "readme_content": "<p align=\"center\">\n  <a href=\"https://mnma.ai/\" target=\"blank\"></a>\n</p>\n\n**Minima** is an open source RAG on-premises containers, with ability to integrate with ChatGPT and MCP. \nMinima can also be used as a fully local RAG.\n\nMinima currently supports three modes:\n1. Isolated installation – Operate fully on-premises with containers, free from external dependencies such as ChatGPT or Claude. All neural networks (LLM, reranker, embedding) run on your cloud or PC, ensuring your data remains secure.\n\n2. Custom GPT – Query your local documents using ChatGPT app or web with custom GPTs. The indexer running on your cloud or local PC, while the primary LLM remains ChatGPT.\n\n3. Anthropic Claude – Use Anthropic Claude app to query your local documents. The indexer operates on your local PC, while Anthropic Claude serves as the primary LLM.\n\n---\n\n## Running as Containers\n\n1. Create a .env file in the project’s root directory (where you’ll find env.sample). Place .env in the same folder and copy all environment variables from env.sample to .env.\n\n2. Ensure your .env file includes the following variables:\n<ul>\n   <li> LOCAL_FILES_PATH </li>\n   <li> EMBEDDING_MODEL_ID </li>\n   <li> EMBEDDING_SIZE </li>\n   <li> OLLAMA_MODEL </li>\n   <li> RERANKER_MODEL </li>\n   <li> USER_ID </li> - required for ChatGPT integration, just use your email\n   <li> PASSWORD </li> - required for ChatGPT integration, just use any password\n</ul>\n\n3. For fully local installation use: **docker compose -f docker-compose-ollama.yml --env-file .env up --build**.\n\n4. For ChatGPT enabled installation use: **docker compose -f docker-compose-chatgpt.yml --env-file .env up --build**.\n\n5. For MCP integration (Anthropic Desktop app usage): **docker compose -f docker-compose-mcp.yml --env-file .env up --build**.\n\n6. In case of ChatGPT enabled installation copy OTP from terminal where you launched docker and use [Minima GPT](https://chatgpt.com/g/g-r1MNTSb0Q-minima-local-computer-search)  \n\n7. If you use Anthropic Claude, just add folliwing to **/Library/Application\\ Support/Claude/claude_desktop_config.json**\n\n```\n{\n    \"mcpServers\": {\n      \"minima\": {\n        \"command\": \"uv\",\n        \"args\": [\n          \"--directory\",\n          \"/path_to_cloned_minima_project/mcp-server\",\n          \"run\",\n          \"minima\"\n        ]\n      }\n    }\n  }\n```\n   \n8. To use fully local installation go to `cd electron`, then run `npm install` and `npm start` which will launch Minima electron app.\n\n9. Ask anything, and you'll get answers based on local files in {LOCAL_FILES_PATH} folder.\n---\n\n## Variables Explained\n\n**LOCAL_FILES_PATH**: Specify the root folder for indexing (on your cloud or local pc). Indexing is a recursive process, meaning all documents within subfolders of this root folder will also be indexed. Supported file types: .pdf, .xls, .docx, .txt, .md, .csv.\n\n**EMBEDDING_MODEL_ID**: Specify the embedding model to use. Currently, only Sentence Transformer models are supported. Testing has been done with sentence-transformers/all-mpnet-base-v2, but other Sentence Transformer models can be used.\n\n**EMBEDDING_SIZE**: Define the embedding dimension provided by the model, which is needed to configure Qdrant vector storage. Ensure this value matches the actual embedding size of the specified EMBEDDING_MODEL_ID.\n\n**OLLAMA_MODEL**: Set up the Ollama model, use an ID available on the Ollama [site](https://ollama.com/search). Please, use LLM model here, not an embedding.\n\n**RERANKER_MODEL**: Specify the reranker model. Currently, we have tested with BAAI rerankers. You can explore all available rerankers using this [link](https://huggingface.co/collections/BAAI/).\n\n**USER_ID**: Just use your email here, this is needed to authenticate custom GPT to search in your data.\n\n**PASSWORD**: Put any password here, this is used to create a firebase account for the email specified above.\n\n---\n\n## Examples\n\n**Example of .env file for on-premises/local usage:**\n```\nLOCAL_FILES_PATH=/Users/davidmayboroda/Downloads/PDFs/\nEMBEDDING_MODEL_ID=sentence-transformers/all-mpnet-base-v2\nEMBEDDING_SIZE=768\nOLLAMA_MODEL=qwen2:0.5b # must be LLM model id from Ollama models page\nRERANKER_MODEL=BAAI/bge-reranker-base # please, choose any BAAI reranker model\n```\n\nTo use a chat ui, please navigate to **http://localhost:3000**\n\n**Example of .env file for Claude app:**\n```\nLOCAL_FILES_PATH=/Users/davidmayboroda/Downloads/PDFs/\nEMBEDDING_MODEL_ID=sentence-transformers/all-mpnet-base-v2\nEMBEDDING_SIZE=768\n```\nFor the Claude app, please apply the changes to the claude_desktop_config.json file as outlined above.\n\n**To use MCP with GitHub Copilot:**\n1. Create a .env file in the project’s root directory (where you’ll find env.sample). Place .env in the same folder and copy all environment variables from env.sample to .env.\n\n2. Ensure your .env file includes the following variables:\n    - LOCAL_FILES_PATH\n    - EMBEDDING_MODEL_ID\n    - EMBEDDING_SIZE\n      \n3. Create or update the `.vscode/mcp.json` with the following configuration:\n\n````json\n{\n  \"servers\": {\n    \"minima\": {\n      \"type\": \"stdio\",\n      \"command\": \"path_to_cloned_minima_project/run_in_copilot.sh\",\n      \"args\": [\n        \"path_to_cloned_minima_project\"\n      ]\n    }\n  }\n}\n````\n\n**Example of .env file for ChatGPT custom GPT usage:**\n```\nLOCAL_FILES_PATH=/Users/davidmayboroda/Downloads/PDFs/\nEMBEDDING_MODEL_ID=sentence-transformers/all-mpnet-base-v2\nEMBEDDING_SIZE=768\nUSER_ID=user@gmail.com # your real email\nPASSWORD=password # you can create here password that you want\n```\n\nAlso, you can run minima using **run.sh**.\n\n---\n\n## Installing via Smithery (MCP usage)\n\nTo install Minima for Claude Desktop automatically via [Smithery](https://smithery.ai/protocol/minima):\n\n```bash\nnpx -y @smithery/cli install minima --client claude\n```\n\n**For MCP usage, please be sure that your local machines python is >=3.10 and 'uv' installed.**\n\nMinima (https://github.com/dmayboroda/minima) is licensed under the Mozilla Public License v2.0 (MPLv2).",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "minima",
        "dmayboroda",
        "chatgpt",
        "dmayboroda minima",
        "processing dmayboroda",
        "rag server"
      ],
      "category": "document-processing"
    },
    "dragonjump--mcp-ARCknowledge": {
      "owner": "dragonjump",
      "name": "mcp-ARCknowledge",
      "url": "https://github.com/dragonjump/mcp-ARCknowledge",
      "imageUrl": "/freedevtools/mcp/pfp/dragonjump.webp",
      "description": "Manage and query a custom knowledge base by registering document sources, querying information, and aggregating results from multiple webhook endpoints. Simplifies knowledge management and enhances querying capabilities.",
      "stars": 2,
      "forks": 1,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-07-16T16:46:03Z",
      "readme_content": "# MCP ArcKnowledge\n\n[![smithery badge](https://smithery.ai/badge/@dragonjump/mcp-ARCknowledge)](https://smithery.ai/server/@dragonjump/mcp-ARCknowledge)\n![arc knowledge MCP](https://github.com/dragonjump/mcp-ARCknowledge/raw/main/logo.jpg)\n\n## How it works?\n![arc knowledge diagram](https://github.com/dragonjump/mcp-ARCknowledge/raw/main/diagram.png)\n\n\nThis is a Model Context Protocol (MCP) server for your custom webhook endpoints (knowledgebase).\n\nWith this you can  you can easily manage and query your list of knowledge base(webhook endpoints).\nYou can add new document sources by registering their URLs, and optionally provide a description and API key.\n\nYou can also list all the registered document sources and view their details.\n \nWhen you're ready to ask/search, you can query the knowledge base with a text question  , specifying which sources to search or leaving it blank to search all of them. \n\nThe tool will then aggregate the results from the queried sources and provide them to you.\n\n\n### Prerequisites\n\n- Go\n- Python 3.6+\n- Anthropic Claude Desktop app (or Cursor or Cline)\n- UV (Python package manager), install with `curl -LsSf https://astral.sh/uv/install.sh | sh`\n \n\n## Concept\nImagine being able to bridge 1 unified setup where you can connect all your custom knowledge base endpoints webhook in one configuration, eliminating the need for multiple MCP servers.\n \n## Demo\n \n![arcknowledge demo cursor](https://github.com/dragonjump/mcp-ARCknowledge/raw/main/demo_video/arcknowledge-demo-1.gif) \n![arcknowledge demo cursor](https://github.com/dragonjump/mcp-ARCknowledge/raw/main/demo_video/arcknowledge-demo-2.gif) \n![arcknowledge demo cline](https://github.com/dragonjump/mcp-ARCknowledge/raw/main/demo-cline.gif) \n \n[See mcp cursor video](https://github.com/dragonjump/mcp-arcknowledge/tree/main/demo%20video)\n\n\n## Setup Installation\n\n### Installing via Smithery\n\nTo install ArcKnowledge for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@dragonjump/mcp-ARCknowledge):\n\n```bash\nnpx -y @smithery/cli install @dragonjump/mcp-ARCknowledge --client claude\n```\n\n1.**Clone repo**  \n```bash\ngit clone https://github.com/dragonjump/mcp-arcknowledge\ncd mcp-arcknowledge\n```\n\n \n2. **Configure endpoints** \nMake a copy or change`knowledge_document_sources.json`.\nSee `sample_endpoint` folder for references on current knowledge endpoints api schema supported. You may change the code as you wish to fit your need.\n\n3. **Connect to the MCP server**\n\n   Copy the below json with the appropriate {{PATH}} values:\n\n   ```json\n    {\n        \"mcpServers\": {\n            \"mcp-arcknowledge\": {\n                \"command\": \"cmd /c uv\",\n                \"args\": [\n                    \"--directory\",\n                    \"C:/Users/Acer/OneDrive/GitHub/YourDrive\",\n                    \"run\",\n                    \"main.py\"\n                ],\n                \"env\": {\n                    \"DOCUMENT_SOURCES_PATH\": \"C:/Users/Acer/OneDrive/GitHub/YourDrive/testcustomother.json\"\n                }\n            }\n        }\n    }\n   ```\nFor **Claude**, save this as `claude_desktop_config.json` in your Claude Desktop configuration directory at:\n\n   ```\n   ~/Library/Application Support/Claude/claude_desktop_config.json\n   \n   ```\n\nFor **Cursor**, save this as `mcp.json` in your Cursor configuration directory at:\n\n   ```\n   ~/.cursor/mcp.json\n   ```\n\nFor **cline**, save this as `cline_mcp_settings.json` in your configuration  \n\n4. **Restart Client: Claude Desktop / Cursor / Cline / Windsurf**\n   Open and restart your client ide for mcp. eg Claude/Cursor/Cline/etc\n\n\n### Windows Compatibility\n\nIf you're running this project on Windows, be aware that `go-sqlite3` requires **CGO to be enabled** in order to compile and work properly. By default, **CGO is disabled on Windows**, so you need to explicitly enable it and have a C compiler installed.\n\n#### Steps to get it working:\n\n1. **Install a C compiler**  \n   We recommend using [MSYS2](https://www.msys2.org/) to install a C compiler for Windows. After installing MSYS2, make sure to add the `ucrt64\\bin` folder to your `PATH`.  \n   → A step-by-step guide is available [here](https://code.visualstudio.com/docs/cpp/config-mingw).\n\n \n \n## Architecture Overview\n\nThis application consists of simple main component:\n \n**Python MCP Server** (`main.py`): A Python server implementing the Model Context Protocol (MCP), which provides standardized tools client to interact with data and invoke api call.\n\n### Data Storage\n\n- All storage is runtime local main python server.\n \n\n \n## Technical Details\n\n1. Client sends requests to the Python MCP server\n2. The MCP server lookup its runtime config knowledge base.\n3. Then based on your queries, it calls your knowledge base endpoint api,\n\n## Troubleshooting\n\n- If you encounter permission issues when running uv, you may need to add it to your PATH or use the full path to the executable.\n- Make sure both the Go application and the Python server are running for the integration to work properly.\n\n### Starting the Server\n1. Config\nRun the server in development mode:\n```bash\nfastmcp dev main.py\n```\n\nOr install it for use with Claude:\n```bash\nfastmcp install main.py\n```\n\n### Available Tools\n  \n\n#### 1. Default Loads knowledge list from knowledge_document_sources.json\nDefault loads knowledge sources from config\n``` \nknowledge_document_sources.json\n \n```\nYou may Load custom knowledge from mcp.json environment config\n\n```\n\n        \"env\": {\n            \"DOCUMENT_SOURCES_PATH\": \"C:/Users/Acer/OneDrive/Somewhere/YourDrive/your-custom.json\"\n        }\n```\n#### 2. List all  currently registered knowledge sources\nShows and explains the list of all registered knowledge sources.\n\n``` \neg. Show me my arcknowledge list \n \n```\n#### 3. Add New Knowledge Document Source  \nAdd new arcknowledge   endpoint url document sources. \nProvide url, description purpose and apikey(if any)\n\n``` \neg. Add new arcknowledge data source. Endpoint is http://something.com/api/123.\nPurpose is to handle questions on 123 topic. Api key is 'sk-2123123' \n \n```\n\n#### 4. Querying Specific Knowledge Doc Source\nQuery the arcknowledge base built from these sources using query_knowledge_base. \n\n``` \neg. Query for me my  knowledge base for product. Question is : Which is most expensive product? \n\n\neg. Query for me my  arcknowledge base for business. Question is :When is the business established? \n\neg. Query for me all my  arcknowledge base  . Question is :When is the business established? Which is most expensive product?\n```\n \n \n#### Tool Functions \n\n1.  `add_new_knowledge_document_source(url: str, description:str = None, apikey:str = None) -> str`\n    *   Registers a new document source URL, optionally with a description and API key.\n    *   Returns: Confirmation message with the new source ID.\n\n2.  `list_knowledge_document_sources() -> Dict[str, Dict[str, str]]`\n    *   Lists all registered document sources.\n    *   Returns: Dictionary mapping source IDs to their details (URL, description, API key).\n\n3.  `query_knowledge_base(query: str, source_ids: List[str] = [], image: str = '') -> str`\n    *   Queries specified document sources (or all if none specified) with a text query and optional image data.\n    *   Returns: Aggregated results from the queried sources.\n## Development\n\n### Crucial filesProject Structure\n\n```\nmcp-arcknowledge/\n├── main.py          # Main server implementation\n├── README.md           # Documentation\n├── requirements.txt    # Project dependencies\n```\n\n### Cursor AI MCP Configuration\n\n1. Create an `mcp.json` file in your project root:\n```json\n{\n    \"name\": \"mcp-webhook-ai-agent\",\n    \"version\": \"1.0.0\",\n    \"description\": \"Webhook AI agent with RAG capabilities\",\n    \"main\": \"main.py\",\n    \"tools\": [\n        {\n            \"name\": \"set_document_source\",\n            \"description\": \"Register a new document source URL for RAG operations\"\n        },\n        {\n            \"name\": \"list_document_sources\",\n            \"description\": \"List all registered document sources\"\n        },\n        {\n            \"name\": \"query_rag\",\n            \"description\": \"Query the specified document sources using RAG\"\n        },\n        {\n            \"name\": \"process_post_query\",\n            \"description\": \"Process a POST request with a query payload\"\n        }\n    ],\n    \"dependencies\": {\n        \"fastmcp\": \">=0.4.0\",\n        \"requests\": \">=2.31.0\",\n        \"pydantic\": \">=2.0.0\"\n    }\n}\n```\n\n2. Configure Cursor AI:\n   - Open Cursor AI settings\n   - Navigate to the MCP section\n   - Add the path to your `mcp.json` file\n   - Restart Cursor AI to apply changes\n\n3. Verify Configuration:\n```bash\n# Check if MCP is properly configured\nfastmcp check mcp.json\n\n# List available tools\nfastmcp list\n```\n\n### Adding New Features\n\n1. Define new models in `main.py`\n2. Add new tools using the `@mcp.tool()` decorator\n3. Update documentation as needed\n\n## License\nMIT\n\n## Contributing\n\n1. Fork the repository\n2. Create your feature branch\n3. Commit your changes\n4. Push to the branch\n5. Create a new Pull Request\n \n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "webhook",
        "dragonjump",
        "document",
        "knowledge base",
        "knowledge management",
        "processing dragonjump"
      ],
      "category": "document-processing"
    },
    "esakrissa--mcp-doc": {
      "owner": "esakrissa",
      "name": "mcp-doc",
      "url": "https://github.com/esakrissa/mcp-doc",
      "imageUrl": "/freedevtools/mcp/pfp/esakrissa.webp",
      "description": "Integrates LLM applications with specific documentation sources, enabling access and retrieval of documentation files to enhance knowledge and responses. Provides tools for fetching documentation from specified URLs within those files.",
      "stars": 0,
      "forks": 2,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-10-04T06:52:34Z",
      "readme_content": "# MCP Documentation Server\n\nA customized version of the MCP documentation server that enables integration between LLM applications (like Cursor, Claude Desktop, Windsurf) and documentation sources via the Model Context Protocol.\n\n## Overview\n\nThis server provides MCP host applications with:\n1. Access to specific documentation files (langgraph.txt and mcp.txt)\n2. Tools to fetch documentation from URLs within those files\n\n## Supported Documentation\n\nCurrently set up for:\n- LangGraph Documentation (from https://raw.githubusercontent.com/esakrissa/mcp-doc/main/docs/langgraph.txt)\n- MCP Documentation (from https://raw.githubusercontent.com/esakrissa/mcp-doc/main/docs/mcp.txt)\n\n## Quick Start\n\n### Setup and Run\n\n```bash\n# Clone the repository\ngit clone https://github.com/esakrissa/mcp-doc.git\ncd mcp-doc\n\n# Create and activate a virtual environment\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n\n# Install the package in development mode\npip install -e .\n```\n\n### Running the Server\n\nYou can run the server using the installed command:\n\n```bash\n# Run the server with the config file\nmcpdoc \\\n    --json config.json \\\n    --transport sse \\\n    --port 8082 \\\n    --host localhost\n```\n\nOr if you prefer using UV:\n\n```bash\n# Install uv (if not already installed)\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Run the server with UV\nuvx --from mcpdoc mcpdoc \\\n    --json config.json \\\n    --transport sse \\\n    --port 8082 \\\n    --host localhost\n```\n\n### IDE Integration\n\n#### Cursor\n\nAdd to `~/.cursor/mcp.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-doc\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"--from\",\n        \"mcpdoc\",\n        \"mcpdoc\",\n        \"--urls\",\n        \"LangGraph:https://raw.githubusercontent.com/esakrissa/mcp-doc/main/docs/langgraph.txt\",\n        \"ModelContextProtocol:https://raw.githubusercontent.com/esakrissa/mcp-doc/main/docs/mcp.txt\",\n        \"--allowed-domains\",\n        \"*\",\n        \"--transport\",\n        \"stdio\"\n      ]\n    }\n  }\n}\n```\n\nThen add these instructions to Cursor's Custom Instructions:\n\n```\nfor ANY question about LangGraph and Model Context Protocol (MCP), use the mcp-doc server to help answer -- \n+ call list_doc_sources tool to get the available documentation files\n+ call fetch_docs tool to read the langgraph.txt or mcp.txt file\n+ reflect on the urls in langgraph.txt or mcp.txt \n+ reflect on the input question \n+ call fetch_docs on any urls relevant to the question\n+ use this to answer the question\n```\n\nTo test if the integration is working, ask Cursor a question about LangGraph or MCP, and check if it uses the documentation server tools to fetch information.\n\n## Security Note\n\nFor security reasons, strict domain access controls are implemented:\n- Remote documentation files: Only the specific domain is automatically allowed\n- Local documentation files: No domains are automatically allowed\n- Use `--allowed-domains` to explicitly add domains or `--allowed-domains '*'` to allow all (use with caution)\n\n## References\n\nThis project is based on the original [mcpdoc by LangChain AI](https://github.com/langchain-ai/mcpdoc), modified to provide focused documentation access for LangGraph and MCP. \n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "documentation",
        "document",
        "doc",
        "documentation files",
        "doc integrates",
        "retrieval documentation"
      ],
      "category": "document-processing"
    },
    "esignaturescom--mcp-server-esignatures": {
      "owner": "esignaturescom",
      "name": "mcp-server-esignatures",
      "url": "https://github.com/esignaturescom/mcp-server-esignatures",
      "imageUrl": "/freedevtools/mcp/pfp/esignaturescom.webp",
      "description": "Manage contracts and templates by drafting, querying, withdrawing, and deleting contracts efficiently.",
      "stars": 29,
      "forks": 10,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-01T07:26:25Z",
      "readme_content": "# mcp-server-esignatures MCP server\n\nMCP server for eSignatures (https://esignatures.com)\n\n## Tools\n\n\n| Tool                           | Category      | Description                        |\n|--------------------------------|---------------|------------------------------------|\n| `create_contract`              | Contracts     | Draft for review or send contract  |\n| `query_contract`               | Contracts     | Retrieve contract info             |\n| `withdraw_contract`            | Contracts     | Withdraw an unsigned contract      |\n| `delete_contract`              | Contracts     | Delete a draft or test contract    |\n| `list_recent_contracts`        | Contracts     | List the recent contracts          |\n|                                |               |                                    |\n| `create_template`              | Templates     | Create a new contract template     |\n| `update_template`              | Templates     | Update an existing template        |\n| `query_template`               | Templates     | Retrieve template content and info |\n| `delete_template`              | Templates     | Delete a template                  |\n| `list_templates`               | Templates     | List all your templates            |\n|                                |               |                                    |\n| `add_template_collaborator`    | Collaborators | Invite someone to edit a template  |\n| `remove_template_collaborator` | Collaborators | Revoke template editing rights     |\n| `list_template_collaborators`  | Collaborators | View who can edit a template       |\n\n\n## Examples\n\n#### Creating a Draft Contract\n\n`Generate a draft NDA contract for a publisher, which I can review and send. Signer: John Doe, ACME Corp, john@acme.com`\n\n#### Sending a Contract\n\n`Send an NDA based on my template to John Doe, ACME Corp, john@acme.com. Set the term to 2 years.`\n\n#### Updating templates\n\n`Review my templates for legal compliance, and ask me about updating each one individually`\n\n#### Inviting template collaborators\n\n`Invite John Doe to edit the NDA template, email: john@acme.com`\n\n\n## Install\n\n### Create an eSignatures account\n\nCreate an eSignatures account at https://esignatures.com for free, to test the Agent AI by creating templates and sending test contracts.\n\n### Claude Desktop\n\nOn MacOS: `~/Library/Application\\ Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n##### Development/Unpublished Servers Configuration\n```\n\"mcpServers\": {\n  \"mcp-server-esignatures\": {\n    \"command\": \"uv\",\n    \"env\": {\n      \"ESIGNATURES_SECRET_TOKEN\": \"your-esignatures-api-secret-token\"\n    },\n    \"args\": [\n      \"--directory\",\n      \"/your-local-directories/mcp-server-esignatures\",\n      \"run\",\n      \"mcp-server-esignatures\"\n    ]\n  }\n}\n```\n\n#### Published Servers Configuration\n```\n\"mcpServers\": {\n  \"mcp-server-esignatures\": {\n    \"command\": \"uvx\",\n    \"args\": [\n      \"mcp-server-esignatures\"\n    ],\n    \"env\": {\n      \"ESIGNATURES_SECRET_TOKEN\": \"your-esignatures-api-secret-token\"\n    }\n  }\n}\n```\n\n### Authentication\n\nTo use this server, you need to set the `ESIGNATURES_SECRET_TOKEN` environment variable with your eSignatures API secret token.\n\n## eSignatures API Documentation\n\nFor a detailed guide on API endpoints, parameters, and responses, see [eSignatures API](https://esignatures.com/docs/api).\n\n## eSignatures Support\n\nFor support, please navigate to [Support](https://esignatures.com/support) or contact [support@esignatures.com](mailto:support@esignatures.com).\n\n## Contributing\n\nContributions are welcome! If you'd like to contribute, please fork the repository and make changes as you see fit. Here are some guidelines:\n\n- **Bug Reports**: Please open an issue to report any bugs you encounter.\n- **Feature Requests**: Suggest new features by opening an issue with the \"enhancement\" label.\n- **Pull Requests**: Ensure your pull request follows the existing code style.\n- **Documentation**: Help improve or translate documentation. Any form of documentation enhancement is appreciated.\n\nFor major changes, please open an issue first to discuss what you would like to change. We're looking forward to your contributions!\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "esignaturescom",
        "contracts",
        "esignatures",
        "esignaturescom mcp",
        "esignatures manage",
        "contracts templates"
      ],
      "category": "document-processing"
    },
    "essenecrucix-netizen--jarvis": {
      "owner": "essenecrucix-netizen",
      "name": "jarvis",
      "url": "https://github.com/essenecrucix-netizen/jarvis",
      "imageUrl": "/freedevtools/mcp/pfp/essenecrucix-netizen.webp",
      "description": "An intelligent coding assistant that supports multiple AI models for code generation, modifications, and technical discussions. It can handle various file types for text extraction and data parsing to facilitate development tasks.",
      "stars": 1,
      "forks": 2,
      "license": "MIT License",
      "language": "",
      "updated_at": "2025-01-15T00:11:47Z",
      "readme_content": "# J.A.R.V.I.S. - AI Code Assistant\n\nJ.A.R.V.I.S. is an intelligent coding assistant that leverages multiple state-of-the-art language models to help you with code generation, modifications, and technical discussions.\n\n## Features\n\n- **Multi-Model Support**: Choose between different AI models for your coding needs:\n  - DeepSeek Coder V3\n  - Gemini 2.0 Flash Experimental\n  - Grok 2\n  - Qwen 2.5 Coder\n  - Llama 3.3 70B Instruct\n  - Claude 3.5 Sonnet\n  - GPT-4 Turbo\n  - GPT-4o\n  - o1 Preview\n\n- **File Attachment Support**:\n  - PDF files with text extraction\n  - Microsoft Word documents (.docx)\n  - Excel spreadsheets with sheet parsing\n  - Images with OCR capabilities\n  - Enhanced Markdown with GFM support\n  - All major programming languages\n  - Configuration files\n  - Text and documentation files\n  - File preview with syntax highlighting\n  - Multiple file upload support\n  - Progress indicators and file size display\n  - Type-specific icons and preview buttons\n\n- **Real-Time Updates**:\n  - WebSocket-based notifications\n  - Instant feedback for code changes\n  - Real-time workspace updates\n  - Automatic change notifications\n\n- **Workspace Management**:\n  - Create and manage multiple workspaces\n  - View workspace history\n  - Delete workspaces when no longer needed\n  - Rename workspaces\n  - Browse workspace file structure\n\n- **Code Generation & Modification**:\n  - Generate new code based on natural language prompts\n  - Modify existing code with AI assistance\n  - Preview changes before applying them\n  - View diffs of proposed changes\n\n- **Interactive Chat**:\n  - Discuss code and technical concepts\n  - Get explanations about existing code\n  - Context-aware responses based on workspace content\n  - Attach files for additional context\n\n## Technical Stack\n\n- **Backend**:\n  - Flask web framework\n  - Flask-SocketIO for WebSocket support\n  - Eventlet for async operations\n\n- **Frontend**:\n  - Pure JavaScript\n  - TailwindCSS for styling\n  - CodeMirror for code editing\n  - Socket.IO client for real-time notifications\n  - PDF.js for PDF processing\n  - Mammoth.js for Word documents\n  - XLSX.js for Excel files\n  - Tesseract.js for OCR\n  - Marked and Unified.js for Markdown\n\n## Installation\n\n1. Clone the repository\n2. Install dependencies:\n   ```bash\n   pip install -r requirements.txt\n   ```\n3. Set up your environment variables in `.env`:\n   ```\n   DEEPSEEK_API_KEY=your_deepseek_api_key\n   GROK_API_KEY=your_grok_api_key\n   GOOGLE_API_KEY=your_google_api_key\n   ANTHROPIC_API_KEY=your_anthropic_api_key\n   OPENAI_API_KEY=your_openai_api_key\n   ```\n\n## Usage\n\n1. Start the server:\n   ```bash\n   python app.py\n   ```\n2. Open your browser and navigate to `http://localhost:5000`\n3. Create a new workspace or select an existing one\n4. Choose your preferred AI model\n5. Start coding with AI assistance!\n\n## Model Capabilities\n\n- **DeepSeek Coder V3**: Specialized in code generation and modification\n- **Gemini 2.0 Pro**: Advanced code generation and natural language understanding\n- **Grok 2**: Advanced language model for code and natural language\n- **Qwen 2.5 Coder**: Specialized 32B model for code generation\n- **Llama 3.3 70B Instruct**: Large context window and strong code generation capabilities\n- **Claude 3.5 Sonnet**: Advanced reasoning and code understanding\n\n## Contributing\n\nContributions are welcome! Please feel free to submit pull requests.\n\n## Special Thanks\n\n- **Nikole Cardoso** for her invaluable contributions and support\n- **Guilherme Guirro** for his expertise and guidance\n- **Felipe Santos** for his dedication and insights\n\nTheir contributions have been instrumental in making J.A.R.V.I.S. better.\n\n## Platform Compatibility\n\nThis application has been tested and confirmed working on:\n- Linux (native)\n- Windows Subsystem for Linux (WSL 2)\n- Windows (native, no admin privileges required)\n\nThe application uses directory junctions on Windows to avoid requiring admin privileges, while maintaining symlink functionality on Unix-like systems.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ai",
        "parsing",
        "netizen",
        "coding assistant",
        "netizen jarvis",
        "jarvis intelligent"
      ],
      "category": "document-processing"
    },
    "everaldo--mcp-mistral-ocr": {
      "owner": "everaldo",
      "name": "mcp-mistral-ocr",
      "url": "https://github.com/everaldo/mcp-mistral-ocr",
      "imageUrl": "/freedevtools/mcp/pfp/everaldo.webp",
      "description": "Processes images and PDFs using advanced OCR capabilities from Mistral AI, converting them into structured JSON outputs. It supports local files and files from URLs, handling multiple image formats.",
      "stars": 32,
      "forks": 9,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-09-29T17:08:49Z",
      "readme_content": "# MCP Mistral OCR\n[![smithery badge](https://smithery.ai/badge/@everaldo/mcp-mistral-ocr)](https://smithery.ai/server/@everaldo/mcp-mistral-ocr)\n\nAn MCP server that provides OCR capabilities using Mistral AI's OCR API. This server can process both local files and URLs, supporting images and PDFs.\n\n## Features\n\n- Process local files (images and PDFs) using Mistral's OCR\n- Process files from URLs with explicit file type specification\n- Support for multiple file formats (JPG, PNG, PDF, etc.)\n- Results saved as JSON files with timestamps\n- Docker containerization\n- UV package management\n\n## Environment Variables\n\n- `MISTRAL_API_KEY`: Your Mistral AI API key\n- `OCR_DIR`: Directory path for local file processing. Inside the container, this is always mapped to `/data/ocr`\n\n## Installation\n\n### Installing via Smithery\n\nTo install Mistral OCR for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@everaldo/mcp-mistral-ocr):\n\n```bash\nnpx -y @smithery/cli install @everaldo/mcp/mistral-crosswalk --client claude\n```\n\n### Using Docker\n\n1. Build the Docker image:\n```bash\ndocker build -t mcp-mistral-ocr .\n```\n\n2. Run the container:\n```bash\ndocker run -e MISTRAL_API_KEY=your_api_key -e OCR_DIR=/data/ocr -v /path/to/local/files:/data/ocr mcp-mistral-ocr\n```\n\n### Local Development\n\n1. Install UV package manager:\n```bash\npip install uv\n```\n\n2. Create and activate virtual environment:\n```bash\nuv venv\nsource .venv/bin/activate  # On Unix\n# or\n.venv\\Scripts\\activate  # On Windows\n```\n\n3. Install dependencies:\n```bash\nuv pip install .\n```\n\n## Claude Desktop Configuration\n\nAdd this configuration to your claude_desktop_config.json:\n\n```json\n{\n  \"mcpServers\": {\n    \"mistral-ocr\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-e\",\n        \"MISTRAL_API_KEY\",\n        \"-e\",\n        \"OCR_DIR\",\n        \"-v\",\n        \"C:/path/to/your/files:/data/ocr\",\n        \"mcp-mistral-ocr:latest\"\n      ],\n      \"env\": {\n        \"MISTRAL_API_KEY\": \"<YOUR_MISTRAL_API_KEY>\",\n        \"OCR_DIR\": \"C:/path/to/your/files\"\n      }\n    }\n  }\n}\n```\n\n## Available Tools\n\n### 1. process_local_file\n\nProcess a file from the configured OCR_DIR directory.\n\n```json\n{\n    \"name\": \"process_local_file\",\n    \"arguments\": {\n        \"filename\": \"document.pdf\"\n    }\n}\n```\n\n### 2. process_url_file\n\nProcess a file from a URL. Requires explicit file type specification.\n\n```json\n{\n    \"name\": \"process_url_file\",\n    \"arguments\": {\n        \"url\": \"https://example.com/document\",\n        \"file_type\": \"image\"  // or \"pdf\"\n    }\n}\n```\n\n## Output\n\nOCR results are saved in JSON format in the `output` directory inside `OCR_DIR`. Each result file is named using the following format:\n- For local files: `{original_filename}_{timestamp}.json`\n- For URLs: `{url_filename}_{timestamp}.json` or `url_document_{timestamp}.json` if no filename is found in the URL\n\nThe timestamp format is `YYYYMMDD_HHMMSS`.\n\n## Supported File Types\n\n- Images: JPG, JPEG, PNG, GIF, WebP\n- Documents: PDF and other document formats supported by Mistral OCR\n\n## Limitations\n\n- Maximum file size: 50MB (enforced by Mistral API)\n- Maximum document pages: 1000 (enforced by Mistral API)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ocr",
        "document",
        "mistral",
        "mistral ocr",
        "ocr processes",
        "ocr capabilities"
      ],
      "category": "document-processing"
    },
    "exoticknight--mcp-file-merger": {
      "owner": "exoticknight",
      "name": "mcp-file-merger",
      "url": "https://github.com/exoticknight/mcp-file-merger",
      "imageUrl": "/freedevtools/mcp/pfp/exoticknight.webp",
      "description": "Combine multiple files into a single file efficiently, providing detailed reports on file sizes and merge summaries. Access is restricted to user-defined directories for security.",
      "stars": 23,
      "forks": 11,
      "license": "Apache License 2.0",
      "language": "JavaScript",
      "updated_at": "2025-09-11T06:14:36Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/exoticknight-mcp-file-merger-badge.png)](https://mseep.ai/app/exoticknight-mcp-file-merger)\n\n[![Trust Score](https://archestra.ai/mcp-catalog/api/badge/quality/exoticknight/mcp-file-merger)](https://archestra.ai/mcp-catalog/exoticknight__mcp-file-merger)\n\n# File Merger MCP Server\n\nSimple utility to combine multiple files into one. Fast, secure, and easy to use.\n\n<a href=\"https://glama.ai/mcp/servers/@exoticknight/mcp-file-merger\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@exoticknight/mcp-file-merger/badge\" alt=\"File Merger Server MCP server\" />\n</a>\n\n## Features\n\n- **Simple** - Merge any number of files with a single command\n- **Fast** - Efficiently combines files of any size\n- **Secure** - Only accesses directories you allow\n- **Detailed** - Reports file sizes and merge summary\n\n## API\n\n### Tools\n\n- **merge_files**\n  - Inputs:\n    - `inputPaths` (string[]): Files to merge\n    - `outputPath` (string): Output file location\n  - Returns:\n    - Success message with merge details\n\n- **list_allowed_directories**\n  - Lists directories the server can access\n\n## Usage with Claude Desktop\n\nAdd to your `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"file-merger\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@exoticknight/mcp-file-merger\",\n        \"/path/to/allowed/dir\"\n      ]\n    }\n  }\n}\n```\n\n## Installation\n\n```bash\n# Clone and install\ngit clone https://github.com/exoticknight/mcp-file-merger.git\ncd mcp-file-merger\nnpm install\nnpm run build\n```\n\n## License\n\nApache License 2.0",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "merge",
        "files",
        "file",
        "file merger",
        "mcp file",
        "document processing"
      ],
      "category": "document-processing"
    },
    "f-is-h--mcp-easy-copy": {
      "owner": "f-is-h",
      "name": "mcp-easy-copy",
      "url": "https://github.com/f-is-h/mcp-easy-copy",
      "imageUrl": "/freedevtools/mcp/pfp/f-is-h.webp",
      "description": "Lists all available MCP services configured in Claude Desktop, providing easy access for reference and copying. Keeps the list dynamically updated and accessible from the tools menu for quick selection.",
      "stars": 3,
      "forks": 3,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-05-19T02:15:15Z",
      "readme_content": "# MCP Easy Copy\n\n[![MCP Server](https://badge.mcpx.dev?type=server)](https://modelcontextprotocol.io)\n[![Platforms](https://img.shields.io/badge/platforms-macOS%20%7C%20Windows-lightgrey)](https://claude.ai/download)\n[![npm version](https://img.shields.io/npm/v/@fishes/mcp-easy-copy)](https://www.npmjs.com/package/@fishes/mcp-easy-copy)\n[![Node.js](https://img.shields.io/badge/node-%3E%3D14.0.0-brightgreen)](https://nodejs.org)\n[![smithery badge](https://smithery.ai/badge/@fisheepx/mcp-easy-copy)](https://smithery.ai/server/@fisheepx/mcp-easy-copy)\n[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)\n\nA Model Context Protocol server that makes it easy to discover and copy available MCP services in Claude Desktop.\n\n\n\n## Purpose\n\nThis MCP server is designed to be your first stop when working with Claude Desktop. It solves the problem of having to remember MCP service names or looking them up in configuration files by:\n\n1. Automatically reading the Claude Desktop configuration file\n2. Extracting the names of all configured MCP services\n3. Presenting them in an easy-to-copy format at the top of the tools list\n\nAlthough Claude can now automatically select the appropriate MCP services in most scenarios, there are still situations where users need to explicitly specify an MCP service name. These situations include:\n\n- When you have many MCP services configured, making the tools list long and difficult to navigate\n- When specific MCP services offer multiple callable actions, further increasing the list length\n- When you need to direct Claude to use a specific service rather than relying on its automatic selection\n- When troubleshooting or comparing results between different MCP services\n\nThis tool bridges that gap, making all available services easily accessible without having to search through configuration files.\n\n## Features\n\n- **Appears at the top of tools list**: Uses special name formatting to always appear first\n- **Dynamic updates**: Always shows the latest available services\n- **Copy-friendly format**: Numbered list for easy reference\n- **Zero external dependencies**: Just needs Node.js\n\n## Installation\n\n### Option 1: Install via npm (Recommended)\n\n```bash\nnpm install -g @fishes/mcp-easy-copy\n```\n\nThen add to your Claude Desktop configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-easy-copy\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@fishes/mcp-easy-copy\"\n      ]\n    }\n  }\n}\n```\n\n### Option 2: Installing via Smithery\n\nTo install Easy Copy for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@fisheepx/mcp-easy-copy):\n\n```bash\nnpx -y @smithery/cli install @fisheepx/mcp-easy-copy --client claude\n```\n\n### Option 3: Manual Installation\n\n1. Clone the repository:\n   ```bash\n   git clone https://github.com/f-is-h/mcp-easy-copy.git\n   cd mcp-easy-copy\n   ```\n\n2. Install dependencies and build:\n   ```bash\n   npm install\n   npm run build\n   ```\n\n3. Configure Claude Desktop:\n   \n   **For macOS:**\n   Edit `~/Library/Application Support/Claude/claude_desktop_config.json`\n   \n   **For Windows:**\n   Edit `%APPDATA%\\Claude\\claude_desktop_config.json`\n   \n   Add the following configuration:\n   ```json\n   {\n     \"mcpServers\": {\n       \"mcp-easy-copy\": {\n         \"command\": \"node\",\n         \"args\": [\n            \"/ABSOLUTE/PATH/TO/mcp_easy_copy/build/index.js\"\n         ]\n       }\n     }\n   }\n   ```\n\n4. Restart Claude Desktop\n\n\n\n## Using the Tool\n\nOnce installed, you can use the service in two ways:\n\n1. **Via the tools menu:** Click the hammer icon in Claude Desktop and select the service at the top of the list (it will show all available services in its description)\n\n2. **Via a prompt:** Ask Claude something like:\n   ```\n   Please list all MCP services that are available to you\n   ```\n   or\n   ```\n   Please use _________mcp-easy-copy_________ to show me all available MCP services\n   ```\n\n## Development\n\nMCP Easy Copy is built with TypeScript and uses the Model Context Protocol SDK.\n\n```bash\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n\n# Test with the MCP Inspector\nnpm run inspector\n```\n\n## Troubleshooting\n\nIf the tool doesn't work as expected:\n\n1. **Check logs**: Look at the log files\n   - macOS: `~/Library/Logs/Claude/mcp-server-mcp-easy-copy.log`\n   - Windows: `%APPDATA%\\Claude\\logs\\mcp-server-mcp-easy-copy.log`\n\n2. **Verify configuration**: Make sure your `claude_desktop_config.json` is valid JSON\n\n3. **Check Node.js**: Ensure Node.js is properly installed (`node --version`)\n\n4. **Restart Claude**: Always restart Claude Desktop after making configuration changes\n\n5. **Use the Inspector**: Run `npm run inspector` to debug with the MCP Inspector\n\n## Other Badges\n\n### Glama\n<a href=\"https://glama.ai/mcp/servers/@fisheepx/mcp-easy-copy\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@f-is-h/mcp-easy-copy/badge\" alt=\"Easy Copy MCP server\" />\n</a>\n\n### MseeP.ai\n[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/f-is-h-mcp-easy-copy-badge.png)](https://mseep.ai/app/f-is-h-mcp-easy-copy)\n\n## License\n\n[MIT License](LICENSE)\n\n## Future Vision\n\nWhile we have no specific knowledge of Anthropic's roadmap, we imagine that future versions of Claude's client could potentially implement features like autocomplete when using the '@' symbol. Such a feature might display a dropdown list of available MCP services, making it much easier for users to explicitly instruct Claude to utilize specific services.\n\nEven if such improvements eventually make this project obsolete, we'd be delighted to see Claude's interface evolve in ways that improve user experience. After all, the goal of this tool is to make MCP services more accessible, and having that functionality built directly into Claude would be the ultimate success.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcp",
        "copying",
        "copy",
        "processing mcp",
        "document processing",
        "mcp services"
      ],
      "category": "document-processing"
    },
    "falahgs--Gemini-Data-Analysis-Research-MCP-Server": {
      "owner": "falahgs",
      "name": "Gemini-Data-Analysis-Research-MCP-Server",
      "url": "https://github.com/falahgs/Gemini-Data-Analysis-Research-MCP-Server",
      "imageUrl": "/freedevtools/mcp/pfp/falahgs.webp",
      "description": "Analyze datasets, generate research papers, and automate email delivery using advanced AI capabilities. Provides detailed data analysis, insights, and reporting directly from data files.",
      "stars": 2,
      "forks": 4,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-07-16T09:06:05Z",
      "readme_content": "# Gemini Data Analysis & Research MCP Server\r\n\r\nA powerful Model Context Protocol (MCP) server that leverages Google's Gemini Flash 2 AI model for comprehensive data analysis, research paper generation, and automated email delivery. This server provides an integrated solution for analyzing datasets, generating research content, and distributing results directly to stakeholders via email.\r\n\r\n## 🚀 Features\r\n\r\n### 1. Advanced Data Analysis & Reporting (`analyze-data`)\r\n- Comprehensive analysis of Excel (.xlsx, .xls) and CSV files\r\n- Features:\r\n  - Automatic data type detection and parsing\r\n  - Statistical analysis of numeric columns\r\n  - Interactive visualizations using Chart.js\r\n  - AI-powered insights using Gemini Flash 2\r\n  - Detailed HTML reports with interactive plots\r\n  - Direct email delivery of analysis results\r\n  - Basic and detailed analysis modes\r\n  - Customizable output directory\r\n  - Support for large datasets\r\n  - Automatic outlier detection\r\n  - Correlation analysis for numeric columns\r\n\r\n### 2. Research & Email Delivery System (`send-email`)\r\n- Professional research paper generation and distribution\r\n- Features:\r\n  - AI-powered research paper generation\r\n  - Automated email delivery of analysis results\r\n  - Support for multiple content types:\r\n    - Research papers\r\n    - Technical reports\r\n    - Data analysis summaries\r\n    - Business intelligence reports\r\n  - Professional email subject line generation\r\n  - Support for both HTML and plain text content\r\n  - Image attachments with inline display capability\r\n  - Secure SMTP authentication\r\n  - Comprehensive error handling and status reporting\r\n  - Professional email formatting\r\n  - Message delivery tracking\r\n  - Customizable email templates\r\n\r\n### 3. Research & Analysis Generator (`generate-thinking`)\r\n- Advanced research and analysis generation\r\n- Features:\r\n  - Research paper generation\r\n  - Technical documentation writing\r\n  - Data analysis summaries\r\n  - Business intelligence reports\r\n  - Timestamped response saving\r\n  - Customizable output directory\r\n  - Direct email delivery of generated content\r\n  - Professional content creation\r\n\r\n## 📊 Quick Start\r\n\r\n### Prerequisites\r\n- Node.js (v16 or higher)\r\n- TypeScript\r\n- Claude Desktop\r\n- Google Gemini API Key\r\n- SMTP Email Account (for email functionality)\r\n\r\n### Installation\r\n\r\n1. Clone and setup:\r\n```bash\r\ngit clone [your-repo-url]\r\ncd gemini-data-analysis-email-generator\r\nnpm install\r\n```\r\n\r\n2. Create `.env` file:\r\n```env\r\nGEMINI_API_KEY=your_api_key_here\r\nNODEMAILER_EMAIL=your.email@gmail.com\r\nNODEMAILER_PASSWORD=your_app_password_here\r\n```\r\n\r\n3. Build the project:\r\n```bash\r\nnpm run build\r\n```\r\n\r\n### Claude Desktop Configuration\r\n\r\n1. Create/Edit `%AppData%/Claude/claude_desktop_config.json`:\r\n```json\r\n{\r\n  \"mcpServers\": {\r\n    \"Gemini Data Analysis\": {\r\n      \"command\": \"node\",\r\n      \"args\": [\"path/to/gemini-data-analysis-email-generator/dist/index.js\"],\r\n      \"cwd\": \"path/to/gemini-data-analysis-email-generator\",\r\n      \"env\": {\r\n        \"GEMINI_API_KEY\": \"your_api_key_here\",\r\n        \"NODEMAILER_EMAIL\": \"your.email@gmail.com\",\r\n        \"NODEMAILER_PASSWORD\": \"your_app_password_here\"\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n2. Restart Claude Desktop\r\n\r\n## 📊 Using the Tools\r\n\r\n### Data Analysis with EDA and AI\r\n```json\r\n{\r\n  \"name\": \"analyze-data\",\r\n  \"arguments\": {\r\n    \"fileData\": \"base64_encoded_file_content\",\r\n    \"fileName\": \"data.xlsx\",\r\n    \"analysisType\": \"detailed\",\r\n    \"outputDir\": \"./analysis_results\"\r\n  }\r\n}\r\n```\r\n\r\n### Email Sending with AI Subject Generation\r\n```json\r\n{\r\n  \"name\": \"send-email\",\r\n  \"arguments\": {\r\n    \"to\": \"recipient@example.com\",\r\n    \"subjectPrompt\": \"Create a professional subject line for a business report\",\r\n    \"text\": \"Hello! This is the plain text version of our email.\",\r\n    \"html\": \"<h1>Hello!</h1><p>This is the <b>HTML</b> version of our email.</p>\",\r\n    \"images\": [\r\n      {\r\n        \"name\": \"chart.png\",\r\n        \"data\": \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...\"\r\n      }\r\n    ]\r\n  }\r\n}\r\n```\r\n\r\n### Thinking Generation\r\n```json\r\n{\r\n  \"name\": \"generate-thinking\",\r\n  \"arguments\": {\r\n    \"prompt\": \"Analyze the market trends for Q1 2024\",\r\n    \"outputDir\": \"./thinking_output\"\r\n  }\r\n}\r\n```\r\n\r\n## 📁 Output Structure\r\n```\r\noutput/\r\n├── analysis/\r\n│   ├── plots/\r\n│   │   ├── column1_histogram_[timestamp].html\r\n│   │   └── column2_histogram_[timestamp].html\r\n│   ├── analysis_[timestamp].txt\r\n│   └── report_[timestamp].html\r\n├── thinking/\r\n│   └── gemini_thinking_[timestamp].txt\r\n└── emails/\r\n    └── email_log_[timestamp].txt\r\n```\r\n\r\n## 🛠️ Development\r\n\r\n### Available Scripts\r\n- `npm run build`: Compile TypeScript to JavaScript\r\n- `npm run start`: Start the MCP server\r\n- `npm run dev`: Run in development mode with ts-node\r\n\r\n### Environment Variables\r\n- `GEMINI_API_KEY`: Your Google Gemini API key\r\n- `NODEMAILER_EMAIL`: Your email address for sending emails\r\n- `NODEMAILER_PASSWORD`: Your email app password (for Gmail, use an app password)\r\n\r\n## 🔒 Security Notes\r\n\r\n- Store your API keys securely\r\n- Don't share your `.env` file\r\n- For Gmail, use app passwords instead of your main account password\r\n- Be careful with the content of emails sent through the system\r\n- Never include sensitive or personal information in email examples\r\n\r\n## 🐛 Troubleshooting\r\n\r\n### Common Issues\r\n1. **API Key Error**\r\n   - Verify `.env` file exists\r\n   - Check API key validity\r\n   - Ensure proper environment loading\r\n\r\n2. **Claude Desktop Connection**\r\n   - Verify config.json syntax\r\n   - Check file paths in config\r\n   - Restart Claude Desktop\r\n\r\n3. **Email Sending Issues**\r\n   - Check that NODEMAILER_EMAIL and NODEMAILER_PASSWORD are set correctly\r\n   - For Gmail, ensure you've created an app password\r\n   - Verify that less secure app access is enabled for non-Gmail providers\r\n   - Check recipient email address format\r\n\r\n4. **Data Analysis Issues**\r\n   - Ensure file format is supported (.xlsx, .xls, .csv)\r\n   - Check file encoding (UTF-8 recommended)\r\n   - Verify file size is within limits\r\n   - Ensure numeric columns are properly formatted\r\n\r\n### Debug Mode\r\nAdd `DEBUG=true` to your `.env` file for verbose logging:\r\n```env\r\nGEMINI_API_KEY=your_key_here\r\nDEBUG=true\r\n```\r\n\r\n## 📚 API Reference\r\n\r\n### Data Analysis Tool\r\n```typescript\r\ninterface AnalyzeDataParams {\r\n  fileData: string;         // Base64 encoded file content\r\n  fileName: string;         // File name (must be .xlsx, .xls, or .csv)\r\n  analysisType: 'basic' | 'detailed';  // Analysis type\r\n  outputDir?: string;      // Optional output directory\r\n}\r\n```\r\n\r\n### Email Sending Tool\r\n```typescript\r\ninterface SendEmailParams {\r\n  to: string;              // Recipient email address\r\n  subjectPrompt: string;   // Prompt for Gemini to generate email subject\r\n  text: string;            // Plain text version of email\r\n  html?: string;           // HTML version of email (optional)\r\n  images?: {               // Optional images to attach\r\n    name: string;          // Image filename\r\n    data: string;          // Base64 encoded image data\r\n  }[];\r\n}\r\n```\r\n\r\n### Thinking Generation Tool\r\n```typescript\r\ninterface GenerateThinkingParams {\r\n  prompt: string;           // Analysis prompt\r\n  outputDir?: string;       // Optional output directory\r\n}\r\n```\r\n\r\n## 👨‍💻 Author\r\n\r\n**Falah G. Salieh**  \r\n📍 Baghdad, Iraq  \r\n📅 2025\r\n\r\n## 🤝 Contributing\r\n\r\n1. Fork the repository\r\n2. Create your feature branch\r\n3. Commit your changes\r\n4. Push to the branch\r\n5. Create a Pull Request\r\n\r\n## 📄 License\r\n\r\nMIT License - See LICENSE file for details",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "automate",
        "datasets",
        "data",
        "automate email",
        "data analysis",
        "mcp server"
      ],
      "category": "document-processing"
    },
    "falahgs--MCP-CSV-Analysis-with-Gemini-AI": {
      "owner": "falahgs",
      "name": "MCP-CSV-Analysis-with-Gemini-AI",
      "url": "https://github.com/falahgs/MCP-CSV-Analysis-with-Gemini-AI",
      "imageUrl": "/freedevtools/mcp/pfp/falahgs.webp",
      "description": "Performs advanced analysis and visualization of CSV data using Gemini AI, enabling comprehensive data exploration and insights generation. Offers both basic and detailed analysis modes, including statistical evaluation, data quality assessment, correlation analysis, and pattern recognition.",
      "stars": 2,
      "forks": 5,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-04-28T10:24:23Z",
      "readme_content": "# MCP CSV Analysis with Gemini AI\r\n\r\nA powerful Model Context Protocol (MCP) server that provides advanced CSV analysis and thinking generation capabilities using Google's Gemini AI. This tool integrates seamlessly with Claude Desktop and offers sophisticated data analysis, visualization, and natural language processing features.\r\n\r\n## 🌟 Features\r\n\r\n### 1. CSV Analysis Tool (`analyze-csv`)\r\n- **Comprehensive Data Analysis**: Performs detailed Exploratory Data Analysis (EDA) on CSV files\r\n- **Two Analysis Modes**:\r\n  - `basic`: Quick overview and essential statistics\r\n  - `detailed`: In-depth analysis with advanced insights\r\n- **Analysis Components**:\r\n  - Statistical analysis of all columns\r\n  - Data quality assessment\r\n  - Pattern recognition\r\n  - Correlation analysis\r\n  - Feature importance evaluation\r\n  - Preprocessing recommendations\r\n  - Business insights\r\n  - Visualization suggestions\r\n\r\n### 2. Data Visualization Tool (`visualize-data`)\r\n- **Interactive Visualizations**: Creates beautiful and informative charts using Plotly\r\n- **Visualization Types**:\r\n  - `basic`: Automatic visualization selection based on data types\r\n  - `advanced`: Complex multi-variable visualizations\r\n  - `custom`: User-defined chart configurations\r\n- **Chart Types**:\r\n  - Histograms for distribution analysis\r\n  - Correlation heatmaps\r\n  - Scatter plots\r\n  - Line charts\r\n  - Bar charts\r\n  - Box plots\r\n- **Features**:\r\n  - Automatic data type detection\r\n  - Smart chart selection\r\n  - Interactive plots\r\n  - High-resolution exports\r\n  - Customizable layouts\r\n\r\n### 3. Thinking Generation Tool (`generate-thinking`)\r\n- Generates detailed thinking process text using Gemini's experimental model\r\n- Supports complex reasoning and analysis\r\n- Saves responses with timestamps\r\n- Customizable output directory\r\n\r\n## 🚀 Quick Start\r\n\r\n### Prerequisites\r\n- Node.js (v16 or higher)\r\n- TypeScript\r\n- Claude Desktop\r\n- Google Gemini API Key\r\n- Plotly Account (for visualizations)\r\n\r\n### Installation\r\n\r\n1. Clone and setup:\r\n```bash\r\ngit clone [your-repo-url]\r\ncd mcp-csv-analysis-gemini\r\nnpm install\r\n```\r\n\r\n2. Create `.env` file:\r\n```env\r\nGEMINI_API_KEY=your_api_key_here\r\n```\r\n\r\n3. Build the project:\r\n```bash\r\nnpm run build\r\n```\r\n\r\n### Claude Desktop Configuration\r\n\r\n1. Create/Edit `%AppData%/Claude/claude_desktop_config.json`:\r\n```json\r\n{\r\n  \"mcpServers\": {\r\n    \"CSV Analysis\": {\r\n      \"command\": \"node\",\r\n      \"args\": [\"path/to/mcp-csv-analysis-gemini/dist/index.js\"],\r\n      \"cwd\": \"path/to/mcp-csv-analysis-gemini\",\r\n      \"env\": {\r\n        \"GEMINI_API_KEY\": \"your_api_key_here\",\r\n        \"PLOTLY_USERNAME\": \"your_plotly_username\",\r\n        \"PLOTLY_API_KEY\": \"your_plotly_api_key\"\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n2. Restart Claude Desktop\r\n\r\n## 📊 Using the Tools\r\n\r\n### CSV Analysis\r\n```json\r\n{\r\n  \"name\": \"analyze-csv\",\r\n  \"arguments\": {\r\n    \"csvPath\": \"./data/your_file.csv\",\r\n    \"analysisType\": \"detailed\",\r\n    \"outputDir\": \"./custom_output\"\r\n  }\r\n}\r\n```\r\n\r\n### Data Visualization\r\n```json\r\n{\r\n  \"name\": \"visualize-data\",\r\n  \"arguments\": {\r\n    \"csvPath\": \"./data/your_file.csv\",\r\n    \"visualizationType\": \"basic\",\r\n    \"columns\": [\"column1\", \"column2\"],\r\n    \"chartTypes\": [\"histogram\", \"scatter\"],\r\n    \"outputDir\": \"./custom_output\"\r\n  }\r\n}\r\n```\r\n\r\n### Thinking Generation\r\n```json\r\n{\r\n  \"name\": \"generate-thinking\",\r\n  \"arguments\": {\r\n    \"prompt\": \"Your complex analysis prompt here\",\r\n    \"outputDir\": \"./custom_output\"\r\n  }\r\n}\r\n```\r\n\r\n## 📁 Output Structure\r\n```\r\noutput/\r\n├── analysis/\r\n│   ├── csv_analysis_[timestamp]_part1.txt\r\n│   ├── csv_analysis_[timestamp]_part2.txt\r\n│   └── csv_analysis_[timestamp]_summary.txt\r\n├── visualizations/\r\n│   ├── histogram_[column]_[timestamp].png\r\n│   ├── scatter_[columns]_[timestamp].png\r\n│   └── correlation_heatmap_[timestamp].png\r\n└── thinking/\r\n    └── gemini_thinking_[timestamp].txt\r\n```\r\n\r\n## 📊 Visualization Types\r\n\r\n### Basic Visualizations\r\n- Automatically generated based on data types\r\n- Includes:\r\n  - Histograms for numeric columns\r\n  - Correlation heatmaps\r\n  - Basic scatter plots\r\n\r\n### Advanced Visualizations\r\n- More sophisticated charts\r\n- Multiple variables\r\n- Enhanced layouts\r\n- Custom color schemes\r\n\r\n### Custom Visualizations\r\n- User-defined chart types\r\n- Configurable parameters\r\n- Custom styling options\r\n- Advanced plot layouts\r\n\r\n## 🛠️ Development\r\n\r\n### Available Scripts\r\n- `npm run build`: Compile TypeScript to JavaScript\r\n- `npm run start`: Start the MCP server\r\n- `npm run dev`: Run in development mode with ts-node\r\n\r\n### Environment Variables\r\n- `GEMINI_API_KEY`: Your Google Gemini API key\r\n- `PLOTLY_USERNAME`: Your Plotly username\r\n- `PLOTLY_API_KEY`: Your Plotly API key\r\n\r\n## 📝 Analysis Details\r\n\r\n### Basic Analysis Includes\r\n1. Basic statistical summary for each column\r\n2. Data quality assessment\r\n3. Key insights and patterns\r\n4. Potential correlations\r\n5. Recommendations for further analysis\r\n\r\n### Detailed Analysis Includes\r\n1. Comprehensive statistical analysis\r\n   - Distribution analysis\r\n   - Central tendency measures\r\n   - Dispersion measures\r\n   - Outlier detection\r\n2. Advanced data quality assessment\r\n3. Pattern recognition\r\n4. Correlation analysis\r\n5. Feature importance analysis\r\n6. Preprocessing recommendations\r\n7. Visualization suggestions\r\n8. Business insights\r\n\r\n## ⚠️ Limitations\r\n\r\n- Maximum file size: Dependent on system memory\r\n- Rate limits: Based on Gemini API and Plotly quotas\r\n- Output token limit: 65,536 tokens per response\r\n- CSV format: Standard CSV files only\r\n- Analysis time: Varies with data size and complexity\r\n- Visualization limits: Based on Plotly free tier restrictions\r\n\r\n## 🔒 Security Notes\r\n\r\n- Store your API keys securely\r\n- Don't share your `.env` file\r\n- Review CSV data for sensitive information\r\n- Use custom output directories for sensitive analyses\r\n- Secure your Plotly credentials\r\n\r\n## 🐛 Troubleshooting\r\n\r\n### Common Issues\r\n1. **API Key Error**\r\n   - Verify `.env` file exists\r\n   - Check API key validity\r\n   - Ensure proper environment loading\r\n\r\n2. **CSV Parsing Error**\r\n   - Verify CSV file format\r\n   - Check file permissions\r\n   - Ensure file is not empty\r\n\r\n3. **Claude Desktop Connection**\r\n   - Verify config.json syntax\r\n   - Check file paths in config\r\n   - Restart Claude Desktop\r\n\r\n### Debug Mode\r\nAdd `DEBUG=true` to your `.env` file for verbose logging:\r\n```env\r\nGEMINI_API_KEY=your_key_here\r\nDEBUG=true\r\n```\r\n\r\n## 📚 API Reference\r\n\r\n### CSV Analysis Tool\r\n```typescript\r\ninterface AnalyzeCSVParams {\r\n  csvPath: string;          // Path to CSV file\r\n  outputDir?: string;       // Optional output directory\r\n  analysisType?: 'basic' | 'detailed';  // Analysis type\r\n}\r\n```\r\n\r\n### Data Visualization Tool\r\n```typescript\r\ninterface VisualizeDataParams {\r\n  csvPath: string;          // Path to CSV file\r\n  outputDir?: string;       // Optional output directory\r\n  visualizationType?: 'basic' | 'advanced' | 'custom';  // Visualization type\r\n  columns?: string[];       // Columns to visualize\r\n  chartTypes?: ('scatter' | 'line' | 'bar' | 'histogram' | 'box' | 'heatmap')[];  // Chart types\r\n  customConfig?: Record<string, any>;  // Custom configuration\r\n}\r\n```\r\n\r\n### Thinking Generation Tool\r\n```typescript\r\ninterface GenerateThinkingParams {\r\n  prompt: string;           // Analysis prompt\r\n  outputDir?: string;       // Optional output directory\r\n}\r\n```\r\n\r\n## 🤝 Contributing\r\n\r\n1. Fork the repository\r\n2. Create your feature branch\r\n3. Commit your changes\r\n4. Push to the branch\r\n5. Create a Pull Request\r\n\r\n## 📄 License\r\n\r\nMIT License - See LICENSE file for details\r\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "csv",
        "comprehensive",
        "gemini",
        "mcp csv",
        "csv analysis",
        "analysis gemini"
      ],
      "category": "document-processing"
    },
    "famano--mcp-server-office": {
      "owner": "famano",
      "name": "mcp-server-office",
      "url": "https://github.com/famano/mcp-server-office",
      "imageUrl": "/freedevtools/mcp/pfp/famano.webp",
      "description": "Read and write Microsoft Word (docx) files with capabilities to edit paragraphs and insert new text. Access complete document content, including tables and images, through a command-line interface.",
      "stars": 27,
      "forks": 9,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-30T00:07:12Z",
      "readme_content": "# MCP Server Office\n\n[![smithery badge](https://smithery.ai/badge/@famano/mcp-server-office)](https://smithery.ai/server/@famano/mcp-server-office)\n\nA Model Context Protocol (MCP) server providing tools to read/write Microsoft Word (docx) files.\n\n### Installing via Smithery\n\nTo install Server Office for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@famano/mcp-server-office):\n\n```bash\nnpx -y @smithery/cli install @famano/mcp-server-office --client claude\n```\n\n## Usage\n\nInstall with pip:\n\n```bash\npip install mcp-server-office\n```\n\nThen, start the MCP server:\n\n```bash\nmcp-server-office\n```\n\nOr using uv, just:\n\n```bash\nuvx mcp-server-office\n```\n\n### Available Tools\n\n1. `read_docx`: Read complete contents of a docx file including tables and images.\n\n   - Input: `path` (string) - Absolute path to the target file\n   - Note: Images are converted to [Image] placeholders, and track changes are not shown\n2. `write_docx`: Create a new docx file with given content.\n\n   - Input:\n     - `path` (string) - Absolute path to target file\n     - `content` (string) - Content to write to the file\n   - Note: Use double line breaks for new paragraphs, and [Table] tag with | separators for tables\n3. `edit_docx_paragraph`: Make text replacements in specified paragraphs of a docx file.\n\n   - Input:\n     - `path` (string) - Absolute path to file to edit\n     - `edits` (array) - List of dictionaries containing search/replace text and paragraph index\n       - `paragraph_index` (number) - 0-based index of the paragraph to edit\n       - `search` (string) - Text to find within the specified paragraph\n       - `replace` (string) - Text to replace with\n   - Note: Each search string must match exactly once within the specified paragraph\n4. `edit_docx_insert`: Insert new paragraphs into a docx file.\n\n   - Input:\n     - `path` (string) - Absolute path to file to edit\n     - `inserts` (array) - List of dictionaries containing text and optional paragraph index\n       - `text` (string) - Text to insert as a new paragraph\n       - `paragraph_index` (number, optional) - 0-based index of the paragraph before which to insert. If not specified, insert at the end.\n\n## Requirements\n\n- Python >= 3.12\n- Dependencies:\n  - mcp[cli] >= 1.2.0\n  - python-docx >= 1.1.2\n\n---\n\n# MCP Server Office (日本語)\n\n[![smithery badge](https://smithery.ai/badge/@famano/mcp-server-office)](https://smithery.ai/server/@famano/mcp-server-office)\n\nMicrosoft Word (docx) ファイルの読み書きを提供するModel Context Protocol (MCP) サーバーです。\n\n### Smitheryによるインストール\n\n[Smithery](https://smithery.ai/server/@famano/mcp-server-office)経由でClaude DesktopにServer Officeを自動インストールするには:\n\n```bash\nnpx -y @smithery/cli install @famano/mcp-server-office --client claude\n```\n\n## 使用方法\n\npipを使用してインストール:\n\n```bash\npip install mcp-server-office\n```\n\nMCPサーバーの起動:\n\n```bash\nmcp-server-office\n```\n\nまたは、uvを使う場合:\n\n```bash\nuvx mcp-server-office\n```\n\n### 利用可能なツール\n\n1. `read_docx`: docxファイルの内容を表やイメージを含めて完全に読み取ります。\n\n   - 入力: `path` (文字列) - 対象ファイルの絶対パス\n   - 注意: 画像は[Image]というプレースホルダーに変換され、変更履歴は表示されません\n2. `write_docx`: 新しいdocxファイルを指定された内容で作成します。\n\n   - 入力:\n     - `path` (文字列) - 作成するファイルの絶対パス\n     - `content` (文字列) - ファイルに書き込む内容\n   - 注意: 段落は2つの改行で区切り、表は[Table]タグと|区切りを使用します\n3. `edit_docx_paragraph`: docxファイル内の指定された段落のテキストを置換します。\n\n   - 入力:\n     - `path` (文字列) - 編集するファイルの絶対パス\n     - `edits` (配列) - 検索/置換テキストと段落インデックスを含む辞書のリスト\n       - `paragraph_index` (数値) - 編集する段落の0ベースのインデックス\n       - `search` (文字列) - 指定された段落内で検索するテキスト\n       - `replace` (文字列) - 置換するテキスト\n   - 注意: 各検索文字列は指定された段落内で一度だけマッチする必要があります\n4. `edit_docx_insert`: docxファイルに新しい段落を挿入します。\n\n   - 入力:\n     - `path` (文字列) - 編集するファイルの絶対パス\n     - `inserts` (配列) - テキストとオプションの段落インデックスを含む辞書のリスト\n       - `text` (文字列) - 新しい段落として挿入するテキスト\n       - `paragraph_index` (数値, オプション) - 挿入する位置の段落の0ベースのインデックス。指定しない場合は末尾に挿入されます。\n\n## 動作要件\n\n- Python >= 3.12\n- 依存パッケージ:\n  - mcp[cli] >= 1.2.0\n  - python-docx >= 1.1.2\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "docx",
        "document",
        "mcp",
        "word docx",
        "docx files",
        "microsoft word"
      ],
      "category": "document-processing"
    },
    "farzad528--mcp-server-azure-ai-agents": {
      "owner": "farzad528",
      "name": "mcp-server-azure-ai-agents",
      "url": "https://github.com/farzad528/mcp-server-azure-ai-agents",
      "imageUrl": "/freedevtools/mcp/pfp/farzad528.webp",
      "description": "Integrates Azure AI services with Claude Desktop for enhanced search capabilities, enabling intelligent searches across indexed documents and the web while providing source citations. Offers two implementations: one that utilizes the Azure AI Agent Service for document and web searches, and another for direct access to Azure AI Search.",
      "stars": 52,
      "forks": 12,
      "license": "Other",
      "language": "Python",
      "updated_at": "2025-09-15T14:33:32Z",
      "readme_content": "# Azure AI Agent Service + Azure AI Search MCP Server\n\nA Model Context Protocol (MCP) server that enables Claude Desktop to search your content using Azure AI services. Choose between Azure AI Agent Service (with both document search and web search) or direct Azure AI Search integration.\n\n\n\n---\n\n## Overview\n\nThis project provides two MCP server implementations to connect Claude Desktop with Azure search capabilities:\n\n1. **Azure AI Agent Service Implementation (Recommended)** - Uses the powerful Azure AI Agent Service to provide:\n   - **Azure AI Search Tool** - Search your indexed documents with AI-enhanced results\n   - **Bing Web Grounding Tool** - Search the web with source citations\n\n2. **Direct Azure AI Search Implementation** - Connects directly to Azure AI Search with three methods:\n   - **Keyword Search** - Exact lexical matches\n   - **Vector Search** - Semantic similarity using embeddings\n   - **Hybrid Search** - Combination of keyword and vector searches\n\n---\n\n## Features\n\n- **AI-Enhanced Search** - Azure AI Agent Service optimizes search results with intelligent processing\n- **Multiple Data Sources** - Search both your private documents and the public web\n- **Source Citations** - Web search results include citations to original sources\n- **Flexible Implementation** - Choose between Azure AI Agent Service or direct Azure AI Search integration\n- **Seamless Claude Integration** - All search capabilities accessible through Claude Desktop's interface\n- **Customizable** - Easy to extend or modify search behavior\n\n---\n\n## Quick Links\n\n- [Get Started with Azure AI Search](https://learn.microsoft.com/en-us/azure/search/search-get-started-portal)\n- [Azure AI Agent Service Quickstart](https://learn.microsoft.com/en-us/azure/ai-studio/how-to/agent-quickstart)\n\n---\n\n## Requirements\n\n- **Python:** Version 3.10 or higher\n- **Claude Desktop:** Latest version\n- **Azure Resources:** \n  - Azure AI Search service with an index containing vectorized text data\n  - For Agent Service: Azure AI Project with Azure AI Search and Bing connections\n- **Operating System:** Windows or macOS (instructions provided for Windows, but adaptable)\n\n---\n\n## Azure AI Agent Service Implementation (Recommended)\n\n### Setup Guide\n\n1. **Project Directory:**\n\n   ```bash\n   mkdir mcp-server-azure-ai-search\n   cd mcp-server-azure-ai-search\n   ```\n\n2. **Create a `.env` File:**\n\n   ```bash\n   echo \"PROJECT_CONNECTION_STRING=your-project-connection-string\" > .env\n   echo \"MODEL_DEPLOYMENT_NAME=your-model-deployment-name\" >> .env\n   echo \"AI_SEARCH_CONNECTION_NAME=your-search-connection-name\" >> .env\n   echo \"BING_CONNECTION_NAME=your-bing-connection-name\" >> .env\n   echo \"AI_SEARCH_INDEX_NAME=your-index-name\" >> .env\n   ```\n\n3. **Set Up Virtual Environment:**\n\n   ```bash\n   uv venv\n   .venv\\Scripts\\activate\n   uv pip install \"mcp[cli]\" azure-identity python-dotenv azure-ai-projects\n   ```\n\n4. **Use the `azure_ai_agent_service_server.py` script** for integration with Azure AI Agent Service.\n\n### Azure AI Agent Service Setup\n\nBefore using the implementation, you need to:\n\n1. **Create an Azure AI Project:**\n   - Go to the Azure Portal and create a new Azure AI Project\n   - Note the project connection string and model deployment name\n\n2. **Create an Azure AI Search Connection:**\n   - In your Azure AI Project, add a connection to your Azure AI Search service\n   - Note the connection name and index name\n\n3. **Create a Bing Web Search Connection:**\n   - In your Azure AI Project, add a connection to Bing Search service\n   - Note the connection name\n\n4. **Authenticate with Azure:**\n   ```bash\n   az login\n   ```\n\n### Configuring Claude Desktop\n\n```json\n{\n  \"mcpServers\": {\n    \"azure-ai-agent\": {\n      \"command\": \"C:\\\\path\\\\to\\\\.venv\\\\Scripts\\\\python.exe\",\n      \"args\": [\"C:\\\\path\\\\to\\\\azure_ai_agent_service_server.py\"],\n      \"env\": {\n        \"PROJECT_CONNECTION_STRING\": \"your-project-connection-string\",\n        \"MODEL_DEPLOYMENT_NAME\": \"your-model-deployment-name\",\n        \"AI_SEARCH_CONNECTION_NAME\": \"your-search-connection-name\",\n        \"BING_CONNECTION_NAME\": \"your-bing-connection-name\",\n        \"AI_SEARCH_INDEX_NAME\": \"your-index-name\"\n      }\n    }\n  }\n}\n```\n\n> **Note:** Replace path placeholders with your actual project paths.\n\n---\n\n## Direct Azure AI Search Implementation\n\nFor those who prefer direct Azure AI Search integration without the Agent Service:\n\n1. **Create a different `.env` File:**\n\n   ```bash\n   echo \"AZURE_SEARCH_SERVICE_ENDPOINT=https://your-service-name.search.windows.net\" > .env\n   echo \"AZURE_SEARCH_INDEX_NAME=your-index-name\" >> .env\n   echo \"AZURE_SEARCH_API_KEY=your-api-key\" >> .env\n   ```\n\n2. **Install Dependencies:**\n\n   ```bash\n   uv pip install \"mcp[cli]\" azure-search-documents==11.5.2 azure-identity python-dotenv\n   ```\n\n3. **Use the `azure_search_server.py` script** for direct integration with Azure AI Search.\n\n4. **Configure Claude Desktop:**\n\n   ```json\n   {\n     \"mcpServers\": {\n       \"azure-search\": {\n         \"command\": \"C:\\\\path\\\\to\\\\.venv\\\\Scripts\\\\python.exe\",\n         \"args\": [\"C:\\\\path\\\\to\\\\azure_search_server.py\"],\n         \"env\": {\n           \"AZURE_SEARCH_SERVICE_ENDPOINT\": \"https://your-service-name.search.windows.net\",\n           \"AZURE_SEARCH_INDEX_NAME\": \"your-index-name\",\n           \"AZURE_SEARCH_API_KEY\": \"your-api-key\"\n         }\n       }\n     }\n   }\n   ```\n\n---\n\n## Testing the Server\n\n1. **Restart Claude Desktop** to load the new configuration\n2. Look for the MCP tools icon (hammer icon) in the bottom-right of the input field\n3. Try queries such as:\n   - \"Search for information about AI in my Azure Search index\"\n   - \"Search the web for the latest developments in LLMs\"\n   - \"Find information about neural networks using hybrid search\"\n\n---\n\n## Troubleshooting\n\n- **Server Not Appearing:**\n  - Check Claude Desktop logs (located at `%APPDATA%\\Claude\\logs\\mcp*.log` on Windows)\n  - Verify file paths and environment variables in the configuration\n  - Test running the server directly: `python azure_ai_agent_service_server.py` or `uv run python azure_ai_agent_service_server.py`\n\n- **Azure AI Agent Service Issues:**\n  - Ensure your Azure AI Project is correctly configured\n  - Verify that connections exist and are properly configured\n  - Check your Azure authentication status\n\n---\n\n## Customizing Your Server\n\n- **Modify Tool Instructions:** Adjust the instructions provided to each agent to change how they process queries\n- **Add New Tools:** Use the `@mcp.tool()` decorator to integrate additional tools\n- **Customize Response Formatting:** Edit how responses are formatted and returned to Claude Desktop\n- **Adjust Web Search Parameters:** Modify the web search tool to focus on specific domains\n\n---\n\n## License\n\nThis project is licensed under the MIT License.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "azure",
        "ai",
        "searches",
        "azure ai",
        "ai search",
        "ai services"
      ],
      "category": "document-processing"
    },
    "fish0710--excel-mcp": {
      "owner": "fish0710",
      "name": "excel-mcp",
      "url": "https://github.com/fish0710/excel-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/fish0710.webp",
      "description": "Manipulate Excel files without requiring Microsoft Excel. Create, modify, and format workbooks while utilizing advanced features like charts and pivot tables.",
      "stars": 7,
      "forks": 1,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-17T02:04:13Z",
      "readme_content": "# Excel MCP Server\n[![smithery badge](https://smithery.ai/badge/@haris-musa/excel-mcp-server)](https://smithery.ai/server/@haris-musa/excel-mcp-server)\n\nA Model Context Protocol (MCP) server implementation that provides Excel file manipulation capabilities without requiring Microsoft Excel installation. This server enables workbook creation, data manipulation, formatting, and advanced Excel features.\n\n## Requirements\n\n- Python 3.10+\n- MCP SDK 1.2.0+\n- OpenPyXL 3.1.2+\n\n## Components\n\n### Resources\n\nThe server provides Excel workbook manipulation through OpenPyXL:\n\n- Creates and modifies Excel workbooks\n- Manages worksheets and ranges\n- Handles formatting and styles\n- Supports charts and pivot tables\n\n### Tools\n\nThis server provides a comprehensive set of Excel manipulation tools. For detailed documentation of all available tools, their parameters, and usage examples, please refer to [TOOLS.md](TOOLS.md).\n\nThe tools include capabilities for:\n\n- Workbook and worksheet management\n- Data reading and writing\n- Formatting and styling\n- Charts and visualizations\n- Pivot tables and data analysis\n\nSee [TOOLS.md](TOOLS.md) for complete documentation.\n\n## Features\n\n- Full Excel Support: Comprehensive Excel functionality\n- Data Manipulation: Read, write, and transform data\n- Advanced Features: Charts, pivot tables, and formatting\n- Error Handling: Comprehensive error handling with clear messages\n\n## Usage\n\n### Environment Configuration\n\nThe server can be configured using the following environment variables:\n\n- `EXCEL_FILES_PATH`: Directory where Excel files will be stored (default: `./excel_files`)\n\nYou can set this in different ways:\n\nWindows CMD:\n\n```cmd\nset EXCEL_FILES_PATH=C:\\path\\to\\excel\\files\nuv run excel-mcp-server\n```\n\nWindows PowerShell:\n\n```powershell\n$env:EXCEL_FILES_PATH=\"C:\\path\\to\\excel\\files\"\nuv run excel-mcp-server\n```\n\nLinux/MacOS:\n\n```bash\nexport EXCEL_FILES_PATH=/path/to/excel/files\nuv run excel-mcp-server\n```\n\nOr in Claude Desktop config:\n\n```json\n{\n  \"mcpServers\": {\n    \"excel\": {\n      \"command\": \"uv run excel-mcp-server\",\n      \"transport\": \"sse\",\n      \"env\": {\n        \"EXCEL_FILES_PATH\": \"/path/to/excel/files\"\n      }\n    }\n  }\n}\n```\n\n### Starting the Server\n\nStart the server:\n\n```bash\nuv run excel-mcp-server\n```\n\nThe server will start in SSE mode and wait for connections from MCP clients.\n\n### Connecting in Cursor IDE\n\nAfter starting the server, connect to the SSE endpoint in Cursor IDE:\n\n```\nhttp://localhost:8000/sse\n```\n\nThe Excel MCP tools will be available through the agent.\n\nFor available tools and their usage, please refer to [TOOLS.md](TOOLS.md).\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "excel",
        "workbooks",
        "pivot",
        "fish0710 excel",
        "excel mcp",
        "excel files"
      ],
      "category": "document-processing"
    },
    "forayconsulting--zoom_transcript_mcp": {
      "owner": "forayconsulting",
      "name": "zoom_transcript_mcp",
      "url": "https://github.com/forayconsulting/zoom_transcript_mcp",
      "imageUrl": "/freedevtools/mcp/pfp/forayconsulting.webp",
      "description": "Manage Zoom meeting transcripts by listing, downloading, and searching through them with a structured interface. Organize transcripts by month for streamlined access to discussions.",
      "stars": 7,
      "forks": 5,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-01T09:52:15Z",
      "readme_content": "# Zoom Transcript MCP Server\n\nAn MCP (Model Context Protocol) server for interacting with Zoom Cloud Recording transcripts. This server allows you to list, download, search, and manage your Zoom meeting transcripts through a structured interface.\n\n<a href=\"https://glama.ai/mcp/servers/b01uqjtp7w\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/b01uqjtp7w/badge\" alt=\"Zoom Transcript Server MCP server\" />\n</a>\n\n## Features\n\n- **List Meetings**: View all available Zoom meetings with recordings\n- **Download Transcripts**: Download transcripts from specific meetings by ID or UUID\n- **Get Recent Transcripts**: Automatically download transcripts from recent meetings\n- **Search Transcripts**: Search across all downloaded transcripts for specific content\n- **Organized Storage**: Transcripts are stored in a structured file system by month\n\n## Prerequisites\n\n- Node.js (v16 or higher)\n- Zoom Account with Cloud Recording enabled\n- Zoom OAuth App credentials (Account ID, Client ID, Client Secret)\n\n## Installation\n\n1. Clone this repository:\n   ```bash\n   git clone https://github.com/yourusername/zoom_transcript_mcp.git\n   cd zoom_transcript_mcp\n   ```\n\n2. Install dependencies:\n   ```bash\n   npm install\n   ```\n\n3. Build the project:\n   ```bash\n   npm run build\n   ```\n\n## Configuration\n\nCreate a `.env` file in the root directory with the following variables:\n\n```\nZOOM_ACCOUNT_ID=your_zoom_account_id\nZOOM_CLIENT_ID=your_zoom_client_id\nZOOM_CLIENT_SECRET=your_zoom_client_secret\nTRANSCRIPTS_DIR=/path/to/transcripts/directory  # Optional, defaults to ./transcripts\n```\n\nAlternatively, you can configure the server through your MCP settings file:\n\n```json\n{\n  \"mcpServers\": {\n    \"zoom-transcripts\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/zoom-transcripts-server/build/index.js\"],\n      \"env\": {\n        \"ZOOM_ACCOUNT_ID\": \"your_zoom_account_id\",\n        \"ZOOM_CLIENT_ID\": \"your_zoom_client_id\",\n        \"ZOOM_CLIENT_SECRET\": \"your_zoom_client_secret\",\n        \"TRANSCRIPTS_DIR\": \"/path/to/transcripts/directory\"  // Optional\n      }\n    }\n  }\n}\n```\n\n### Obtaining Zoom Credentials\n\n1. Go to the [Zoom App Marketplace](https://marketplace.zoom.us/) and sign in\n2. Click \"Develop\" > \"Build App\"\n3. Choose \"Server-to-Server OAuth\" app type\n4. Fill in the required information\n5. Under \"Scopes\", add the following permissions:\n   - `cloud_recording:read:list_account_recordings:admin`\n   - `cloud_recording:read:recording:admin`\n   - `cloud_recording:read:list_user_recordings:admin`\n6. Save and activate your app\n7. Note your Account ID, Client ID, and Client Secret\n\n## Usage\n\n### Available Tools\n\n#### 1. list_meetings\n\nLists available Zoom meetings with recordings.\n\n```json\n{\n  \"dateRange\": {\n    \"from\": \"2025-01-01\",\n    \"to\": \"2025-03-31\"\n  },\n  \"participant\": \"John Doe\"  // Optional\n}\n```\n\n#### 2. download_transcript\n\nDownloads a transcript for a specific meeting.\n\n```json\n{\n  \"meetingId\": \"123456789\"  // Meeting ID or UUID\n}\n```\n\n#### 3. get_recent_transcripts\n\nDownloads transcripts from recent meetings.\n\n```json\n{\n  \"count\": 5  // Number of recent meetings to fetch (default: 5)\n}\n```\n\n#### 4. search_transcripts\n\nSearches across downloaded transcripts for specific content.\n\n```json\n{\n  \"query\": \"AI discussion\",\n  \"dateRange\": {  // Optional\n    \"from\": \"2025-01-01\",\n    \"to\": \"2025-03-31\"\n  }\n}\n```\n\n### Example Usage with Claude\n\n```\n<use_mcp_tool>\n<server_name>zoom-transcripts</server_name>\n<tool_name>search_transcripts</tool_name>\n<arguments>\n{\n  \"query\": \"project timeline\"\n}\n</arguments>\n</use_mcp_tool>\n```\n\n## Transcript Storage\n\nTranscripts are stored in the following structure:\n\n```\ntranscripts/\n├── YYYY-MM/\n│   ├── YYYY-MM-DD_HH-MM-SS_Meeting-Topic_MeetingID.vtt\n│   └── metadata/\n│       └── YYYY-MM-DD_HH-MM-SS_Meeting-Topic_MeetingID.json\n```\n\nEach transcript has a corresponding metadata JSON file containing:\n- Meeting ID and UUID\n- Topic\n- Start time and duration\n- Participants (extracted from the transcript)\n- File path to the transcript\n\n## Development\n\n### Project Structure\n\n```\nzoom_transcript_mcp/\n├── src/\n│   └── index.ts\n├── package.json\n├── tsconfig.json\n├── .gitignore\n├── README.md\n└── .env.example\n```\n\n### Building\n\n```bash\nnpm run build\n```\n\n### Running Locally\n\n```bash\nnode build/index.js\n```\n\n## License\n\nMIT",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "zoom_transcript_mcp",
        "zoom",
        "transcripts",
        "zoom_transcript_mcp manage",
        "forayconsulting zoom_transcript_mcp",
        "zoom meeting"
      ],
      "category": "document-processing"
    },
    "freestylefly--mcp-server-weread": {
      "owner": "freestylefly",
      "name": "mcp-server-weread",
      "url": "https://github.com/freestylefly/mcp-server-weread",
      "imageUrl": "/freedevtools/mcp/pfp/freestylefly.webp",
      "description": "Bridge WeChat reading data with AI for access to notes and reading insights. Extract and analyze reading notes through intelligent conversations.",
      "stars": 469,
      "forks": 52,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-10-03T12:59:18Z",
      "readme_content": "<p align=\"center\"><img src= \"https://cdn.canghecode.com/blog/%E5%BE%AE%E4%BF%A1%E8%AF%BB%E4%B9%A6MCP%20bac.png\" alt=\"MaxKB\" width=\"300\" /></p>\n<h3 align=\"center\">一个为微信读书提供 MCP 服务的工具</h3>\n<p align=\"center\">\n  <a href=\"https://opensource.org/license/MIT\"><img src=\"https://img.shields.io/github/license/freestylefly/mcp-server-weread?color=rgb(25%2C%20121%2C%20255)\" alt=\"The MIT License\"></a>\n  <a href=\"\"><img src=\"https://img.shields.io/github/forks/freestylefly/mcp-server-weread?color=green\" alt=\"Forks\"></a>\n  <a href=\"https://canghecode.com/\"><img src=\"https://img.shields.io/badge/介绍-%E5%AE%98%E7%BD%91-green\" alt=\"Official\"></a>\n  <a href=\"https://github.com/laigeoffer/pmhub\"><img src=\"https://img.shields.io/github/stars/freestylefly/mcp-server-weread?style=flat-square&color=rgb(25%2C%20121%2C%20255)\" alt=\"Stars\"></a>    \n  <a href=\"https://mp.weixin.qq.com/s/NQslbUBgWIBMyvTIa3PfYQ\"><img src=\"https://img.shields.io/badge/WeReadMCP-教程-blue\" alt=\"Experience\"></a>  \n</p>\n\n<hr/>\n\n微信读书 MCP Server 是一个为微信读书提供 MCP（Model Context Protocol）服务的工具，支持将微信读书的书籍、笔记和划线数据提供给支持MCP的大语言模型客户端，如Cursor、Claude Desktop。\n\n## 功能特点\n\n- 从微信读书获取书架信息\n- 搜索书架中的图书\n- 获取图书的笔记和划线\n- 获取图书的热门书评\n- 支持按章节组织笔记和划线\n- 与支持MCP协议的LLM客户端无缝集成\n\n## 主要工具\n\n1. **get_bookshelf** - 获取用户书架上所有书籍\n   - 返回书籍基本信息，包括书名、作者、译者和分类等\n\n2. **search_books** - 通过关键词检索用户书架上的书籍\n   - 支持模糊匹配和精确匹配\n   - 可选是否包含详细信息\n   - 可设置最大结果数量\n\n3. **get_book_notes_and_highlights** - 获取指定书籍的所有划线和笔记\n   - 支持按章节组织结果\n   - 支持筛选划线样式\n   - 返回结构化的数据以便于LLM理解\n\n4. **get_book_best_reviews** - 获取指定书籍的热门书评\n   - 支持设置返回数量\n   - 支持分页浏览\n   - 包含评分、点赞数和评论者信息\n\n## 安装与使用\n\n### 先决条件\n\n- Node.js 16.x 或更高版本\n- 微信读书账号和有效的Cookie\n\n### 安装教程\n\n详见：\n- [用微信读书MCP在Cursor中构建私人图书馆，太哇塞了！](https://mp.weixin.qq.com/s/NQslbUBgWIBMyvTIa3PfYQ)\n- [Weread MCP Server 使用指南](https://chenge.ink/article/post20250505)\n\n### 与Claude Desktop集成\n\n有多种方式可以与Claude Desktop集成：\n\n#### 方式一：通过 npx 使用（最简单，推荐）\n1. 打开Claude Desktop\n2. 进入设置 -> MCP配置\n3. 添加工具，使用以下JSON配置：\n   ```json\n   {\n     \"mcpServers\": {\n       \"mcp-server-weread\": {\n         \"command\": \"npx\",\n         \"args\": [\"-y\", \"mcp-server-weread\"],\n         \"env\": {\n           // 方式1：使用Cookie Cloud（推荐）\n           \"CC_URL\": \"https://cc.chenge.ink\",  // Cookie Cloud的URL\n           \"CC_ID\": \"您的ID\",                   // Cookie Cloud的ID\n           \"CC_PASSWORD\": \"您的密码\"            // Cookie Cloud的密码\n           \n           // 或方式2：直接提供Cookie\n           // \"WEREAD_COOKIE\": \"您的微信读书Cookie\"\n         }\n       }\n     }\n   }\n   ```\n\n#### 方式二：全局安装后使用\n\n1. 全局安装包：\n   ```bash\n   npm install -g mcp-server-weread\n   ```\n\n2. 在Claude配置中使用：\n   ```json\n   {\n     \"mcpServers\": {\n       \"mcp-server-weread\": {\n         \"command\": \"mcp-server-weread\",\n         \"env\": {\n           // 同上方式配置环境变量\n         }\n       }\n     }\n   }\n   ```\n\n> 提示：直接在Claude配置中提供环境变量的方式更加方便，无需设置.env文件，推荐使用。\n\n## CookieCloud 配置说明\n为了解决 Cookie 频繁过期，需要重新获取并更新环境变量的问题。本项目支持 [CookieCloud](https://github.com/easychen/CookieCloud) 服务来自动同步和更新 Cookie。CookieCloud 是一个开源的跨浏览器 Cookie 同步工具，支持自建服务器。\n\n### 配置步骤：\n安装浏览器插件\nEdge商店：[CookieCloud for Edge](https://microsoftedge.microsoft.com/addons/detail/cookiecloud/bffenpfpjikaeocaihdonmgnjjdpjkeo)\nChrome商店：[CookieCloud for Chrome](https://chromewebstore.google.com/detail/cookiecloud/ffjiejobkoibkjlhjnlgmcnnigeelbdl)\n\n### 配置 CookieCloud 插件\n服务器地址：使用默认服务器 https://cc.chenge.ink 或填入自建服务器地址\n点击 \"自动生成密码\"\n同步域名关键词中填入 \"weread\"\n点击\"保存\" ，然后点击 \"手动同步\"确保配置生效\n[可选] 如果需要插件自动保活，可以在保活中填入 https://weread.qq.com，插件会自动刷新 Cookie\n\n在MCP Json中配置CookieCloud变量：\nCC_URL=你的CookieCloud服务器地址 （或使用我的默认服务器地址 https://cc.chenge.ink ）\nCC_ID=你的CookieCloud用户UUID\nCC_PASSWORD=你的CookieCloud密码\n注意：配置 CookieCloud 后，系统会优先使用 CookieCloud 获取 Cookie，获取失败才会使用 WEREAD_COOKIE 环境变量的值。\n\n## Cookie获取方法\n微信读书的Cookie可以通过以下步骤获取：\n1. 使用Chrome浏览器登录[微信读书网页版](https://weread.qq.com/)\n2. 按F12打开开发者工具，切换到Network标签页\n3. 刷新页面，在请求列表中找到weread.qq.com的请求\n4. 在Headers中找到Cookie字段，复制其完整内容\n5. 将复制的内容添加到MCP Json 或 .env文件的WEREAD_COOKIE变量中\n\n## 使用示例\n以下是一些与LLM对话的示例：\n\n**获取书架信息**\n```\n用户: 帮我查看我的微信读书书架\nLLM: 我将获取您的微信读书书架信息。\n[LLM调用get_bookshelf工具]\n我从您的微信读书书架获取到了208本书籍。以下是部分书籍：\n1. 《隐藏的自我》- 大卫·伊格曼\n2. 《思考，快与慢》- 丹尼尔·卡尼曼\n3. 《人类简史》- 尤瓦尔·赫拉利\n...\n```\n\n**搜索特定书籍**\n```\n用户: 帮我找关于心理学的书\nLLM: 我将搜索您书架上与心理学相关的书籍。\n[LLM调用search_books工具，参数为keyword=\"心理学\"]\n在您的书架上，我找到了3本与心理学相关的书籍：\n1. 《思考，快与慢》- 丹尼尔·卡尼曼（进度：75%）\n2. 《乌合之众》- 古斯塔夫·勒庞（进度：50%）\n3. 《心理学与生活》- 理查德·格里格（进度：30%）\n您想了解哪一本书的更多信息？\n```\n\n**获取笔记和划线**\n```\n用户: 帮我整理《思考，快与慢》这本书的笔记\nLLM: 我将获取《思考，快与慢》的笔记和划线。\n[LLM调用search_books工具，找到书籍ID]\n[LLM调用get_book_notes_and_highlights工具]\n以下是您在《思考，快与慢》中的笔记和划线（按章节组织）：\n\n第一章：系统1和系统2\n- 划线：「系统1的运行是无意识且快速的，不怎么费脑力，没有感觉，完全处于自主控制状态。」\n- 您的笔记：「系统1负责直觉和快速判断，系统2负责缓慢的理性思考。」\n\n第三章：锚定效应\n- 划线：「锚定效应指的是在不确定情境下进行数字估计时，会过度受到事先接触的不相干数字的影响。」\n...\n```\n\n**获取热门书评**\n```\n用户: 这本《原则》有哪些热门书评？\nLLM: 我会为您查找《原则》的热门书评。\n[LLM调用search_books工具，找到书籍ID]\n[LLM调用get_book_best_reviews工具]\n以下是《原则》的热门书评：\n\n1. 评论者\"思考者\"（评分：5星）：\n   \"这是一本关于如何思考的书。达利欧将自己多年的经验总结为可操作的原则，帮助我们做出更好的决策。特别喜欢他关于'痛苦+反思=进步'的观点，非常实用。\"\n   👍 182 | 💬 23\n\n2. 评论者\"投资学习者\"（评分：4星）：\n   \"桥水基金创始人的思想精华，值得反复阅读。书中的工作原则部分对管理者特别有帮助，建议先读生活原则，再读工作原则。\"\n   👍 94 | 💬 12\n...\n```\n\n## 九、友情链接\n\n- [mcp-server-weread](https://github.com/ChenyqThu/mcp-server-weread) ：🚀一个为微信读书提供MCP（Model Context Protocol）服务的工具，支持将微信读书的书籍、笔记和划线数据提供给支持MCP的大语言模型客户端，如Claude Desktop。\n- [CodeCanvas](https://github.com/freestylefly/CodeCanvas) ：📚本代码仓库是作者苍何多年从事一线互联网Java开发的学习历程技术汇总，旨在为大家提供一个清晰详细的学习教程，侧重点更倾向编写Java核心内容。💪🏻\n- [PmHub](https://github.com/laigeoffer/pmhub) ：🔥PmHub 是一套基于 SpringCloud & LLM 的微服务智能项目管理系统，这个项目旨在帮助小伙伴们快速掌握微服务/分布式项目的架构设计和开发流程，如果想在校招或者社招中拿到一个满意的 offer，PmHub 将是一个非常 nice 的选择。\n\n## 十、鸣谢\n\n此项目 fork 自 ChenyqThu 的[mcp-server-weread](https://github.com/ChenyqThu/mcp-server-weread)项目，做了一些小修改，突然就🔥了，这里也请大家去作者GitHub原项目上star，另外ChenyqThu新的更新我也会做同步，项目也会保持使用教程的更新，感谢大家的喜欢。\n\n## 十一、star 趋势图\n\n[![Star History Chart](https://api.star-history.com/svg?repos=freestylefly/mcp-server-weread&type=Date)](https://star-history.com/#freestylefly/mcp-server-weread&Date)\n\n## 十二、公众号\n\n微信搜 **苍何** 或扫描下方二维码关注苍何的原创公众号，回复 **AI** 即可和 5000+ 好友一同探讨AI，一同学习MCP。\n\n![苍何微信公众号](https://cdn.tobebetterjavaer.com/stutymore/%E6%89%AB%E7%A0%81_%E6%90%9C%E7%B4%A2%E8%81%94%E5%90%88%E4%BC%A0%E6%92%AD%E6%A0%B7%E5%BC%8F-%E6%A0%87%E5%87%86%E8%89%B2%E7%89%88.png)\n\n## 十三、许可证\n\n[MIT License (MIT)](https://opensource.org/licenses/MIT)<hr/>\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nCopyright (c) 2025-2026 mcp-server-weread\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ai",
        "reading",
        "notes",
        "wechat reading",
        "notes reading",
        "notes intelligent"
      ],
      "category": "document-processing"
    },
    "funchs--ifly-spark-agent-mcp": {
      "owner": "funchs",
      "name": "ifly-spark-agent-mcp",
      "url": "https://github.com/funchs/ifly-spark-agent-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/funchs.webp",
      "description": "Invokes the task chain of the iFlytek SparkAgent Platform through an MCP server interface, allowing users to upload files and interact with platform capabilities. Enables integration with AI models for automated workflows and task execution.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "",
      "updated_at": "2025-04-20T13:44:44Z",
      "readme_content": "# ifly-spark-agent-mcp\n\nThis is a simple example of using MCP Server to invoke the task chain of the  iFlytek SparkAgent Platform.\n\n## Usage\n\n### Local debugging\n\nStart the server using either stdio (default) or SSE transport:\n\n```bash\n# Using stdio transport (default)\nuv run ifly-spark-agent-mcp\n\n# Using SSE transport on custom port\nuv run ifly-spark-agent-mcp --transport sse --port 8000\n```\n\nBy default, the server exposes a tool named \"upload_file\" that accepts one required argument:\n\n- `file`: The path of the uploaded file\n\n### MCP Client Example\n\nUsing the MCP client, you can use the tool like this using the STDIO transport:\n\n```python\nimport asyncio\nfrom mcp.client.session import ClientSession\nfrom mcp.client.stdio import StdioServerParameters, stdio_client\n\n\nasync def main():\n    async with stdio_client(\n        StdioServerParameters(command=\"uv\", args=[\"run\", \"ifly-spark-agent-mcp\"])\n    ) as (read, write):\n        async with ClientSession(read, write) as session:\n            await session.initialize()\n\n            # List available tools\n            tools = await session.list_tools()\n            print(tools)\n\n            # Call the upload_file tool\n            result = await session.call_tool(\"upload_file\", {\"file\": \"/path/to/file\"})\n            print(result)\n\n\nasyncio.run(main())\n\n```\n\n### Usage with MCP client\n\n#### Use on Claude\nTo add a persistent client, add the following to your `claude_desktop_config.json` or `mcp.json` file:\n\n##### 1. Use uv\n```json\n{\n  \"mcpServers\": {\n    \"ifly-spark-agent-mcp\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/path/to/ifly-spark-agent-mcp\",\n        \"run\",\n        \"ifly-spark-agent-mcp\"\n      ],\n      \"env\": {\n        \"IFLY_SPARK_AGENT_BASE_URL\": \"xxxx\",\n        \"IFLY_SPARK_AGENT_APP_ID\": \"xxxx\",\n        \"IFLY_SPARK_AGENT_APP_SECRET\": \"xxxx\"\n      }\n    }\n  }\n}\n```\n\n##### 2. Use uvx with github repository\n```json\n{\n    \"mcpServers\": {\n        \"ifly-spark-agent-mcp\": {\n            \"command\": \"uvx\",\n            \"args\": [\n                \"--from\",\n                \"git+https://github.com/iflytek/ifly-spark-agent-mcp\",\n                \"ifly-spark-agent-mcp\"\n            ],\n            \"env\": {\n              \"IFLY_SPARK_AGENT_BASE_URL\": \"xxxx\",\n              \"IFLY_SPARK_AGENT_APP_ID\": \"xxxx\",\n              \"IFLY_SPARK_AGENT_APP_SECRET\": \"xxxx\"\n            }\n        }\n    }\n}\n```\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "sparkagent",
        "spark",
        "processing",
        "sparkagent platform",
        "spark agent",
        "iflytek sparkagent"
      ],
      "category": "document-processing"
    },
    "getzep--graphiti": {
      "owner": "getzep",
      "name": "graphiti",
      "url": "https://github.com/getzep/graphiti",
      "imageUrl": "/freedevtools/mcp/pfp/getzep.webp",
      "description": "Enables the construction and querying of real-time, temporally-aware knowledge graphs, managing entities, relationships, and episodes. Facilitates semantic and hybrid searches to enhance memory and reasoning in AI agents.",
      "stars": 18615,
      "forks": 1712,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-10-04T08:50:20Z",
      "readme_content": "<p align=\"center\">\n  <a href=\"https://www.getzep.com/\">\n    <img src=\"https://github.com/user-attachments/assets/119c5682-9654-4257-8922-56b7cb8ffd73\" width=\"150\" alt=\"Zep Logo\">\n  </a>\n</p>\n\n<h1 align=\"center\">\nGraphiti\n</h1>\n<h2 align=\"center\"> Build Real-Time Knowledge Graphs for AI Agents</h2>\n<div align=\"center\">\n\n[![Lint](https://github.com/getzep/Graphiti/actions/workflows/lint.yml/badge.svg?style=flat)](https://github.com/getzep/Graphiti/actions/workflows/lint.yml)\n[![Unit Tests](https://github.com/getzep/Graphiti/actions/workflows/unit_tests.yml/badge.svg)](https://github.com/getzep/Graphiti/actions/workflows/unit_tests.yml)\n[![MyPy Check](https://github.com/getzep/Graphiti/actions/workflows/typecheck.yml/badge.svg)](https://github.com/getzep/Graphiti/actions/workflows/typecheck.yml)\n\n![GitHub Repo stars](https://img.shields.io/github/stars/getzep/graphiti)\n[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?&logo=discord&logoColor=white)](https://discord.com/invite/W8Kw6bsgXQ)\n[![arXiv](https://img.shields.io/badge/arXiv-2501.13956-b31b1b.svg?style=flat)](https://arxiv.org/abs/2501.13956)\n[![Release](https://img.shields.io/github/v/release/getzep/graphiti?style=flat&label=Release&color=limegreen)](https://github.com/getzep/graphiti/releases)\n\n</div>\n<div align=\"center\">\n\n<a href=\"https://trendshift.io/repositories/12986\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/12986\" alt=\"getzep%2Fgraphiti | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n\n</div>\n\n:star: _Help us reach more developers and grow the Graphiti community. Star this repo!_\n\n<br />\n\n> [!TIP]\n> Check out the new [MCP server for Graphiti](mcp_server/README.md)! Give Claude, Cursor, and other MCP clients powerful\n> Knowledge Graph-based memory.\n\nGraphiti is a framework for building and querying temporally-aware knowledge graphs, specifically tailored for AI agents\noperating in dynamic environments. Unlike traditional retrieval-augmented generation (RAG) methods, Graphiti\ncontinuously integrates user interactions, structured and unstructured enterprise data, and external information into a\ncoherent, queryable graph. The framework supports incremental data updates, efficient retrieval, and precise historical\nqueries without requiring complete graph recomputation, making it suitable for developing interactive, context-aware AI\napplications.\n\nUse Graphiti to:\n\n- Integrate and maintain dynamic user interactions and business data.\n- Facilitate state-based reasoning and task automation for agents.\n- Query complex, evolving data with semantic, keyword, and graph-based search methods.\n\n<br />\n\n<p align=\"center\">\n    \n</p>\n\n<br />\n\nA knowledge graph is a network of interconnected facts, such as _\"Kendra loves Adidas shoes.\"_ Each fact is a \"triplet\"\nrepresented by two entities, or\nnodes (\"Kendra\", \"Adidas shoes\"), and their relationship, or edge (\"loves\"). Knowledge Graphs have been explored\nextensively for information retrieval. What makes Graphiti unique is its ability to autonomously build a knowledge graph\nwhile handling changing relationships and maintaining historical context.\n\n## Graphiti and Zep's Context Engineering Platform.\n\nGraphiti powers the core of [Zep](https://www.getzep.com), a turn-key context engineering platform for AI Agents. Zep\noffers agent memory, Graph RAG for dynamic data, and context retrieval and assembly.\n\nUsing Graphiti, we've demonstrated Zep is\nthe [State of the Art in Agent Memory](https://blog.getzep.com/state-of-the-art-agent-memory/).\n\nRead our paper: [Zep: A Temporal Knowledge Graph Architecture for Agent Memory](https://arxiv.org/abs/2501.13956).\n\nWe're excited to open-source Graphiti, believing its potential reaches far beyond AI memory applications.\n\n<p align=\"center\">\n    <a href=\"https://arxiv.org/abs/2501.13956\"></a>\n</p>\n\n## Why Graphiti?\n\nTraditional RAG approaches often rely on batch processing and static data summarization, making them inefficient for\nfrequently changing data. Graphiti addresses these challenges by providing:\n\n- **Real-Time Incremental Updates:** Immediate integration of new data episodes without batch recomputation.\n- **Bi-Temporal Data Model:** Explicit tracking of event occurrence and ingestion times, allowing accurate point-in-time\n  queries.\n- **Efficient Hybrid Retrieval:** Combines semantic embeddings, keyword (BM25), and graph traversal to achieve\n  low-latency queries without reliance on LLM summarization.\n- **Custom Entity Definitions:** Flexible ontology creation and support for developer-defined entities through\n  straightforward Pydantic models.\n- **Scalability:** Efficiently manages large datasets with parallel processing, suitable for enterprise environments.\n\n<p align=\"center\">\n    \n</p>\n\n## Graphiti vs. GraphRAG\n\n| Aspect                     | GraphRAG                              | Graphiti                                         |\n|----------------------------|---------------------------------------|--------------------------------------------------|\n| **Primary Use**            | Static document summarization         | Dynamic data management                          |\n| **Data Handling**          | Batch-oriented processing             | Continuous, incremental updates                  |\n| **Knowledge Structure**    | Entity clusters & community summaries | Episodic data, semantic entities, communities    |\n| **Retrieval Method**       | Sequential LLM summarization          | Hybrid semantic, keyword, and graph-based search |\n| **Adaptability**           | Low                                   | High                                             |\n| **Temporal Handling**      | Basic timestamp tracking              | Explicit bi-temporal tracking                    |\n| **Contradiction Handling** | LLM-driven summarization judgments    | Temporal edge invalidation                       |\n| **Query Latency**          | Seconds to tens of seconds            | Typically sub-second latency                     |\n| **Custom Entity Types**    | No                                    | Yes, customizable                                |\n| **Scalability**            | Moderate                              | High, optimized for large datasets               |\n\nGraphiti is specifically designed to address the challenges of dynamic and frequently updated datasets, making it\nparticularly suitable for applications requiring real-time interaction and precise historical queries.\n\n## Installation\n\nRequirements:\n\n- Python 3.10 or higher\n- Neo4j 5.26 / FalkorDB 1.1.2 / Kuzu 0.11.2 / Amazon Neptune Database Cluster or Neptune Analytics Graph + Amazon\n  OpenSearch Serverless collection (serves as the full text search backend)\n- OpenAI API key (Graphiti defaults to OpenAI for LLM inference and embedding)\n\n> [!IMPORTANT]\n> Graphiti works best with LLM services that support Structured Output (such as OpenAI and Gemini).\n> Using other services may result in incorrect output schemas and ingestion failures. This is particularly\n> problematic when using smaller models.\n\nOptional:\n\n- Google Gemini, Anthropic, or Groq API key (for alternative LLM providers)\n\n> [!TIP]\n> The simplest way to install Neo4j is via [Neo4j Desktop](https://neo4j.com/download/). It provides a user-friendly\n> interface to manage Neo4j instances and databases.\n> Alternatively, you can use FalkorDB on-premises via Docker and instantly start with the quickstart example:\n\n```bash\ndocker run -p 6379:6379 -p 3000:3000 -it --rm falkordb/falkordb:latest\n\n```\n\n```bash\npip install graphiti-core\n```\n\nor\n\n```bash\nuv add graphiti-core\n```\n\n### Installing with FalkorDB Support\n\nIf you plan to use FalkorDB as your graph database backend, install with the FalkorDB extra:\n\n```bash\npip install graphiti-core[falkordb]\n\n# or with uv\nuv add graphiti-core[falkordb]\n```\n\n### Installing with Kuzu Support\n\nIf you plan to use Kuzu as your graph database backend, install with the Kuzu extra:\n\n```bash\npip install graphiti-core[kuzu]\n\n# or with uv\nuv add graphiti-core[kuzu]\n```\n\n### Installing with Amazon Neptune Support\n\nIf you plan to use Amazon Neptune as your graph database backend, install with the Amazon Neptune extra:\n\n```bash\npip install graphiti-core[neptune]\n\n# or with uv\nuv add graphiti-core[neptune]\n```\n\n### You can also install optional LLM providers as extras:\n\n```bash\n# Install with Anthropic support\npip install graphiti-core[anthropic]\n\n# Install with Groq support\npip install graphiti-core[groq]\n\n# Install with Google Gemini support\npip install graphiti-core[google-genai]\n\n# Install with multiple providers\npip install graphiti-core[anthropic,groq,google-genai]\n\n# Install with FalkorDB and LLM providers\npip install graphiti-core[falkordb,anthropic,google-genai]\n\n# Install with Amazon Neptune\npip install graphiti-core[neptune]\n```\n\n## Default to Low Concurrency; LLM Provider 429 Rate Limit Errors\n\nGraphiti's ingestion pipelines are designed for high concurrency. By default, concurrency is set low to avoid LLM\nProvider 429 Rate Limit Errors. If you find Graphiti slow, please increase concurrency as described below.\n\nConcurrency controlled by the `SEMAPHORE_LIMIT` environment variable. By default, `SEMAPHORE_LIMIT` is set to `10`\nconcurrent operations to help prevent `429` rate limit errors from your LLM provider. If you encounter such errors, try\nlowering this value.\n\nIf your LLM provider allows higher throughput, you can increase `SEMAPHORE_LIMIT` to boost episode ingestion\nperformance.\n\n## Quick Start\n\n> [!IMPORTANT]\n> Graphiti defaults to using OpenAI for LLM inference and embedding. Ensure that an `OPENAI_API_KEY` is set in your\n> environment.\n> Support for Anthropic and Groq LLM inferences is available, too. Other LLM providers may be supported via OpenAI\n> compatible APIs.\n\nFor a complete working example, see the [Quickstart Example](./examples/quickstart/README.md) in the examples directory.\nThe quickstart demonstrates:\n\n1. Connecting to a Neo4j, Amazon Neptune, FalkorDB, or Kuzu database\n2. Initializing Graphiti indices and constraints\n3. Adding episodes to the graph (both text and structured JSON)\n4. Searching for relationships (edges) using hybrid search\n5. Reranking search results using graph distance\n6. Searching for nodes using predefined search recipes\n\nThe example is fully documented with clear explanations of each functionality and includes a comprehensive README with\nsetup instructions and next steps.\n\n## MCP Server\n\nThe `mcp_server` directory contains a Model Context Protocol (MCP) server implementation for Graphiti. This server\nallows AI assistants to interact with Graphiti's knowledge graph capabilities through the MCP protocol.\n\nKey features of the MCP server include:\n\n- Episode management (add, retrieve, delete)\n- Entity management and relationship handling\n- Semantic and hybrid search capabilities\n- Group management for organizing related data\n- Graph maintenance operations\n\nThe MCP server can be deployed using Docker with Neo4j, making it easy to integrate Graphiti into your AI assistant\nworkflows.\n\nFor detailed setup instructions and usage examples, see the [MCP server README](./mcp_server/README.md).\n\n## REST Service\n\nThe `server` directory contains an API service for interacting with the Graphiti API. It is built using FastAPI.\n\nPlease see the [server README](./server/README.md) for more information.\n\n## Optional Environment Variables\n\nIn addition to the Neo4j and OpenAi-compatible credentials, Graphiti also has a few optional environment variables.\nIf you are using one of our supported models, such as Anthropic or Voyage models, the necessary environment variables\nmust be set.\n\n### Database Configuration\n\nDatabase names are configured directly in the driver constructors:\n\n- **Neo4j**: Database name defaults to `neo4j` (hardcoded in Neo4jDriver)\n- **FalkorDB**: Database name defaults to `default_db` (hardcoded in FalkorDriver)\n\nAs of v0.17.0, if you need to customize your database configuration, you can instantiate a database driver and pass it\nto the Graphiti constructor using the `graph_driver` parameter.\n\n#### Neo4j with Custom Database Name\n\n```python\nfrom graphiti_core import Graphiti\nfrom graphiti_core.driver.neo4j_driver import Neo4jDriver\n\n# Create a Neo4j driver with custom database name\ndriver = Neo4jDriver(\n    uri=\"bolt://localhost:7687\",\n    user=\"neo4j\",\n    password=\"password\",\n    database=\"my_custom_database\"  # Custom database name\n)\n\n# Pass the driver to Graphiti\ngraphiti = Graphiti(graph_driver=driver)\n```\n\n#### FalkorDB with Custom Database Name\n\n```python\nfrom graphiti_core import Graphiti\nfrom graphiti_core.driver.falkordb_driver import FalkorDriver\n\n# Create a FalkorDB driver with custom database name\ndriver = FalkorDriver(\n    host=\"localhost\",\n    port=6379,\n    username=\"falkor_user\",  # Optional\n    password=\"falkor_password\",  # Optional\n    database=\"my_custom_graph\"  # Custom database name\n)\n\n# Pass the driver to Graphiti\ngraphiti = Graphiti(graph_driver=driver)\n```\n\n#### Kuzu\n\n```python\nfrom graphiti_core import Graphiti\nfrom graphiti_core.driver.kuzu_driver import KuzuDriver\n\n# Create a Kuzu driver\ndriver = KuzuDriver(db=\"/tmp/graphiti.kuzu\")\n\n# Pass the driver to Graphiti\ngraphiti = Graphiti(graph_driver=driver)\n```\n\n#### Amazon Neptune\n\n```python\nfrom graphiti_core import Graphiti\nfrom graphiti_core.driver.neptune_driver import NeptuneDriver\n\n# Create a FalkorDB driver with custom database name\ndriver = NeptuneDriver(\n    host= < NEPTUNE\nENDPOINT >,\naoss_host = < Amazon\nOpenSearch\nServerless\nHost >,\nport = < PORT >  # Optional, defaults to 8182,\n         aoss_port = < PORT >  # Optional, defaults to 443\n)\n\ndriver = NeptuneDriver(host=neptune_uri, aoss_host=aoss_host, port=neptune_port)\n\n# Pass the driver to Graphiti\ngraphiti = Graphiti(graph_driver=driver)\n```\n\n## Using Graphiti with Azure OpenAI\n\nGraphiti supports Azure OpenAI for both LLM inference and embeddings. Azure deployments often require different\nendpoints for LLM and embedding services, and separate deployments for default and small models.\n\n> [!IMPORTANT]\n> **Azure OpenAI v1 API Opt-in Required for Structured Outputs**\n>\n> Graphiti uses structured outputs via the `client.beta.chat.completions.parse()` method, which requires Azure OpenAI\n> deployments to opt into the v1 API. Without this opt-in, you'll encounter 404 Resource not found errors during episode\n> ingestion.\n>\n> To enable v1 API support in your Azure OpenAI deployment, follow Microsoft's\n> guide: [Azure OpenAI API version lifecycle](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/api-version-lifecycle?tabs=key#api-evolution).\n\n```python\nfrom openai import AsyncAzureOpenAI\nfrom graphiti_core import Graphiti\nfrom graphiti_core.llm_client import LLMConfig, OpenAIClient\nfrom graphiti_core.embedder.openai import OpenAIEmbedder, OpenAIEmbedderConfig\nfrom graphiti_core.cross_encoder.openai_reranker_client import OpenAIRerankerClient\n\n# Azure OpenAI configuration - use separate endpoints for different services\napi_key = \"<your-api-key>\"\napi_version = \"<your-api-version>\"\nllm_endpoint = \"<your-llm-endpoint>\"  # e.g., \"https://your-llm-resource.openai.azure.com/\"\nembedding_endpoint = \"<your-embedding-endpoint>\"  # e.g., \"https://your-embedding-resource.openai.azure.com/\"\n\n# Create separate Azure OpenAI clients for different services\nllm_client_azure = AsyncAzureOpenAI(\n    api_key=api_key,\n    api_version=api_version,\n    azure_endpoint=llm_endpoint\n)\n\nembedding_client_azure = AsyncAzureOpenAI(\n    api_key=api_key,\n    api_version=api_version,\n    azure_endpoint=embedding_endpoint\n)\n\n# Create LLM Config with your Azure deployment names\nazure_llm_config = LLMConfig(\n    small_model=\"gpt-4.1-nano\",\n    model=\"gpt-4.1-mini\",\n)\n\n# Initialize Graphiti with Azure OpenAI clients\ngraphiti = Graphiti(\n    \"bolt://localhost:7687\",\n    \"neo4j\",\n    \"password\",\n    llm_client=OpenAIClient(\n        config=azure_llm_config,\n        client=llm_client_azure\n    ),\n    embedder=OpenAIEmbedder(\n        config=OpenAIEmbedderConfig(\n            embedding_model=\"text-embedding-3-small-deployment\"  # Your Azure embedding deployment name\n        ),\n        client=embedding_client_azure\n    ),\n    cross_encoder=OpenAIRerankerClient(\n        config=LLMConfig(\n            model=azure_llm_config.small_model  # Use small model for reranking\n        ),\n        client=llm_client_azure\n    )\n)\n\n# Now you can use Graphiti with Azure OpenAI\n```\n\nMake sure to replace the placeholder values with your actual Azure OpenAI credentials and deployment names that match\nyour Azure OpenAI service configuration.\n\n## Using Graphiti with Google Gemini\n\nGraphiti supports Google's Gemini models for LLM inference, embeddings, and cross-encoding/reranking. To use Gemini,\nyou'll need to configure the LLM client, embedder, and the cross-encoder with your Google API key.\n\nInstall Graphiti:\n\n```bash\nuv add \"graphiti-core[google-genai]\"\n\n# or\n\npip install \"graphiti-core[google-genai]\"\n```\n\n```python\nfrom graphiti_core import Graphiti\nfrom graphiti_core.llm_client.gemini_client import GeminiClient, LLMConfig\nfrom graphiti_core.embedder.gemini import GeminiEmbedder, GeminiEmbedderConfig\nfrom graphiti_core.cross_encoder.gemini_reranker_client import GeminiRerankerClient\n\n# Google API key configuration\napi_key = \"<your-google-api-key>\"\n\n# Initialize Graphiti with Gemini clients\ngraphiti = Graphiti(\n    \"bolt://localhost:7687\",\n    \"neo4j\",\n    \"password\",\n    llm_client=GeminiClient(\n        config=LLMConfig(\n            api_key=api_key,\n            model=\"gemini-2.0-flash\"\n        )\n    ),\n    embedder=GeminiEmbedder(\n        config=GeminiEmbedderConfig(\n            api_key=api_key,\n            embedding_model=\"embedding-001\"\n        )\n    ),\n    cross_encoder=GeminiRerankerClient(\n        config=LLMConfig(\n            api_key=api_key,\n            model=\"gemini-2.5-flash-lite-preview-06-17\"\n        )\n    )\n)\n\n# Now you can use Graphiti with Google Gemini for all components\n```\n\nThe Gemini reranker uses the `gemini-2.5-flash-lite-preview-06-17` model by default, which is optimized for\ncost-effective and low-latency classification tasks. It uses the same boolean classification approach as the OpenAI\nreranker, leveraging Gemini's log probabilities feature to rank passage relevance.\n\n## Using Graphiti with Ollama (Local LLM)\n\nGraphiti supports Ollama for running local LLMs and embedding models via Ollama's OpenAI-compatible API. This is ideal\nfor privacy-focused applications or when you want to avoid API costs.\n\nInstall the models:\n\n```bash\nollama pull deepseek-r1:7b # LLM\nollama pull nomic-embed-text # embeddings\n```\n\n```python\nfrom graphiti_core import Graphiti\nfrom graphiti_core.llm_client.config import LLMConfig\nfrom graphiti_core.llm_client.openai_generic_client import OpenAIGenericClient\nfrom graphiti_core.embedder.openai import OpenAIEmbedder, OpenAIEmbedderConfig\nfrom graphiti_core.cross_encoder.openai_reranker_client import OpenAIRerankerClient\n\n# Configure Ollama LLM client\nllm_config = LLMConfig(\n    api_key=\"ollama\",  # Ollama doesn't require a real API key, but some placeholder is needed\n    model=\"deepseek-r1:7b\",\n    small_model=\"deepseek-r1:7b\",\n    base_url=\"http://localhost:11434/v1\",  # Ollama's OpenAI-compatible endpoint\n)\n\nllm_client = OpenAIGenericClient(config=llm_config)\n\n# Initialize Graphiti with Ollama clients\ngraphiti = Graphiti(\n    \"bolt://localhost:7687\",\n    \"neo4j\",\n    \"password\",\n    llm_client=llm_client,\n    embedder=OpenAIEmbedder(\n        config=OpenAIEmbedderConfig(\n            api_key=\"ollama\",  # Placeholder API key\n            embedding_model=\"nomic-embed-text\",\n            embedding_dim=768,\n            base_url=\"http://localhost:11434/v1\",\n        )\n    ),\n    cross_encoder=OpenAIRerankerClient(client=llm_client, config=llm_config),\n)\n\n# Now you can use Graphiti with local Ollama models\n```\n\nEnsure Ollama is running (`ollama serve`) and that you have pulled the models you want to use.\n\n## Documentation\n\n- [Guides and API documentation](https://help.getzep.com/graphiti).\n- [Quick Start](https://help.getzep.com/graphiti/graphiti/quick-start)\n- [Building an agent with LangChain's LangGraph and Graphiti](https://help.getzep.com/graphiti/integrations/lang-graph-agent)\n\n## Telemetry\n\nGraphiti collects anonymous usage statistics to help us understand how the framework is being used and improve it for\neveryone. We believe transparency is important, so here's exactly what we collect and why.\n\n### What We Collect\n\nWhen you initialize a Graphiti instance, we collect:\n\n- **Anonymous identifier**: A randomly generated UUID stored locally in `~/.cache/graphiti/telemetry_anon_id`\n- **System information**: Operating system, Python version, and system architecture\n- **Graphiti version**: The version you're using\n- **Configuration choices**:\n    - LLM provider type (OpenAI, Azure, Anthropic, etc.)\n    - Database backend (Neo4j, FalkorDB, Kuzu, Amazon Neptune Database or Neptune Analytics)\n    - Embedder provider (OpenAI, Azure, Voyage, etc.)\n\n### What We Don't Collect\n\nWe are committed to protecting your privacy. We **never** collect:\n\n- Personal information or identifiers\n- API keys or credentials\n- Your actual data, queries, or graph content\n- IP addresses or hostnames\n- File paths or system-specific information\n- Any content from your episodes, nodes, or edges\n\n### Why We Collect This Data\n\nThis information helps us:\n\n- Understand which configurations are most popular to prioritize support and testing\n- Identify which LLM and database providers to focus development efforts on\n- Track adoption patterns to guide our roadmap\n- Ensure compatibility across different Python versions and operating systems\n\nBy sharing this anonymous information, you help us make Graphiti better for everyone in the community.\n\n### View the Telemetry Code\n\nThe Telemetry code [may be found here](graphiti_core/telemetry/telemetry.py).\n\n### How to Disable Telemetry\n\nTelemetry is **opt-out** and can be disabled at any time. To disable telemetry collection:\n\n**Option 1: Environment Variable**\n\n```bash\nexport GRAPHITI_TELEMETRY_ENABLED=false\n```\n\n**Option 2: Set in your shell profile**\n\n```bash\n# For bash users (~/.bashrc or ~/.bash_profile)\necho 'export GRAPHITI_TELEMETRY_ENABLED=false' >> ~/.bashrc\n\n# For zsh users (~/.zshrc)\necho 'export GRAPHITI_TELEMETRY_ENABLED=false' >> ~/.zshrc\n```\n\n**Option 3: Set for a specific Python session**\n\n```python\nimport os\n\nos.environ['GRAPHITI_TELEMETRY_ENABLED'] = 'false'\n\n# Then initialize Graphiti as usual\nfrom graphiti_core import Graphiti\n\ngraphiti = Graphiti(...)\n```\n\nTelemetry is automatically disabled during test runs (when `pytest` is detected).\n\n### Technical Details\n\n- Telemetry uses PostHog for anonymous analytics collection\n- All telemetry operations are designed to fail silently - they will never interrupt your application or affect Graphiti\n  functionality\n- The anonymous ID is stored locally and is not tied to any personal information\n\n## Status and Roadmap\n\nGraphiti is under active development. We aim to maintain API stability while working on:\n\n- [x] Supporting custom graph schemas:\n    - Allow developers to provide their own defined node and edge classes when ingesting episodes\n    - Enable more flexible knowledge representation tailored to specific use cases\n- [x] Enhancing retrieval capabilities with more robust and configurable options\n- [x] Graphiti MCP Server\n- [ ] Expanding test coverage to ensure reliability and catch edge cases\n\n## Contributing\n\nWe encourage and appreciate all forms of contributions, whether it's code, documentation, addressing GitHub Issues, or\nanswering questions in the Graphiti Discord channel. For detailed guidelines on code contributions, please refer\nto [CONTRIBUTING](CONTRIBUTING.md).\n\n## Support\n\nJoin the [Zep Discord server](https://discord.com/invite/W8Kw6bsgXQ) and make your way to the **#Graphiti** channel!",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ai",
        "searches",
        "semantic",
        "knowledge graphs",
        "reasoning ai",
        "ai agents"
      ],
      "category": "document-processing"
    },
    "git-jiadong--wechatDataBackup": {
      "owner": "git-jiadong",
      "name": "wechatDataBackup",
      "url": "https://github.com/git-jiadong/wechatDataBackup",
      "imageUrl": "/freedevtools/mcp/pfp/git-jiadong.webp",
      "description": "Export and permanently save WeChat chat records, allowing users to view messages such as images, videos, and files even if WeChat no longer supports them.",
      "stars": 5702,
      "forks": 491,
      "license": "Apache License 2.0",
      "language": "Go",
      "updated_at": "2025-10-04T08:18:33Z",
      "readme_content": "<p align=\"center\" style=\"text-align: center\">\n  <br/>\n</p>\n\n<p align=\"center\">\n  <b>wechatDataBackup: PC微信聊天记录数据导出工具</b>\n  <br/>\n  <br/>\n  <a href=\"https://github.com/git-jiadong/wechatDataBackup/stargazers\">\n    <img src=\"https://img.shields.io/github/stars/git-jiadong/wechatDataBackup\" alt=\"GitHub Star\"/>\n  </a>\n  <a href=\"https://github.com/git-jiadong/wechatDataBackup/releases\">\n    <img src=\"https://img.shields.io/github/downloads/git-jiadong/wechatDataBackup/total\" alt=\"downloads\" />\n  </a>\n  <a href=\"https://github.com/git-jiadong/wechatDataBackup/releases\">\n    <img src=\"https://img.shields.io/github/v/release/git-jiadong/wechatDataBackup\" alt=\"releases version\"/>\n  </a>\n  <a href=\"https://github.com/git-jiadong/wechatDataBackup/commits/main\">\n    <img src=\"https://img.shields.io/github/last-commit/git-jiadong/wechatDataBackup\" alt=\"last commit\" />\n  </a>\n  <a href=\"https://github.com/git-jiadong/wechatDataBackup\" >\n    <img src=\"https://img.shields.io/github/languages/top/git-jiadong/wechatDataBackup\" alt=\"languages\"/>\n  </a>\n  <a href=\"https://github.com/git-jiadong/wechatDataBackup\" >\n    <img src=\"https://img.shields.io/github/repo-size/git-jiadong/wechatDataBackup\" alt=\"repo size\" />\n  </a>\n  <a href=\"https://github.com/git-jiadong/wechatDataBackup/blob/main/LICENSE\">\n    <img src=\"https://img.shields.io/github/license/git-jiadong/wechatDataBackup\" alt=\"license\" />\n  </a>\n</p>\n# wechatDataBackup\n\n* 基于wails开发 + React前端，实现PC端微信聊天记录一键导出功能。\n* 导出后数据可以做永久化保存，即使微信停止支持，聊天记录也可以随时查看。\n* 前端界面尽量与微信界面保持一致，减少使用成本。\n* 理论上支持所有Windows 32/64位微信版本。\n\n效果图如下：\n\n\n\n\n## 演示视频\n[演示视频](https://www.bilibili.com/video/BV1bPH1eWEEy/?share_source=copy_web&vd_source=b5cfa9258a9ad9900a00e9c1ce3cb4b6)\n## 使用方法\n1. 下载release可执行文件直接打开 国内朋友也可以使用 [网盘下载](https://pan.quark.cn/s/fa157b13e762)\n2. 下载源码自行编译可执行文件 [安装wails环境](https://wails.io/zh-Hans/docs/gettingstarted/installation)\n\n```shell\ngit clone https://github.com/git-jiadong/wechatDataBackup.git\ncd wechatDataBackup\nwails build\n```\n\n编译成功后在可执行二进制文件路径`build\\bin\\wechatDataBackup.exe`\n\n如果编译错误可能是没有gcc环境导致的，可以安装 [tdm-gcc](https://jmeubank.github.io/tdm-gcc/) 后在尝试。\n\n3. 导出聊天记录\n电脑登陆微信，然后打开`wechatDataBackup.exe`后按照如图提示导出\n\n\n## 功能\n\n本项目目前的规划与实现进度：\n- [x] 支持图片消息\n- [x] 支持视频消息\n- [x] 支持链接消息\n- [x] 支持语音消息\n- [x] 支持文件消息\n- [x] 支持名片消息\n- [x] 支持定位消息\n- [x] 支持视频/语音通话消息\n- [x] 支持QQ音乐消息\n- [x] 支持第三方视频软件分享消息\n- [x] 支持分享表情集消息\n- [x] 支持小程序消息\n- [x] 支持视频号/直播消息\n- [x] 支持转账消息\n- [x] 支持腾讯游戏分享消息\n- [x] 支持原始表情显示\n- [x] 支持按类型检索\n- [x] 支持日期检索\n- [x] 支持按群成员检索\n- [x] 支持增量式导出\n- [x] 多开账号选择导出\n- [x] 多开账号数据切换\n- [x] 头像使用本地头像\n- [ ] 支持更多消息类型显示\n- [x] 图片查看器重绘\n- [x] 支持会话导出分享\n- [x] 支持自动定位到最后浏览位置\n- [x] 支持书签功能\n- [x] 支持单聊会话对话人位置调换功能\n- [ ] 实现表情预先下载（实现完全离线查看）\n- [ ] 聊天报告\n- [ ] AI本地模型应用\n- [ ] 导出数据本地加密\n- ...\n如果遇到什么问题，或者有更好的建议与优化点欢迎给作者提 [ISSUE](https://github.com/git-jiadong/wechatDataBackup/issues)\n\n\n### 常见问题\n**Q: 支持手机端的聊天记录备份吗？**<br>\nA: 手机端可以使用聊天数据迁移功能，将手机的数据迁移到电脑后再将数据导出。 [微信迁移聊天记录功能](https://www.bilibili.com/opus/974795819172495381)<br>\n**Q: 导出后界面是空白的、导出的数据比PC微信里面看到的少,数据不完整**<br>\nA: 这是由于可能数据存在于内存中还没有回写到磁盘导致的，退出微信时会将内存的数据全部回写到磁盘，导出数据时最好退出重新登陆一次微信，保证数据都在磁盘中再导出即可。<br>\n**Q: 有些图片、视频打不开**<br>\nA: 这是电脑端微信没有点开过这个消息，默认只加载了预览图而已，如果手机有打开过可以把手机的记录迁移到电脑，迁移后重新退出登陆一次微信导出即可。<br>\n**Q: Win7电脑不能使用**<br>\nA: Win7电脑需要安装WebView2运行时才能正常使用。github release版本做了Windows版本限制，[Win7用户请安装专属的版本](https://pan.quark.cn/s/fa157b13e762)\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=git-jiadong/wechatDataBackup&type=Date)](https://star-history.com/?utm_source=bestxtools.com#git-jiadong/wechatDataBackup&Date)\n\n## 免责声明\n**⚠️ 本项目仅供学习、研究使用，严禁商业使用**<br/>\n**⚠️ 用于网络安全用途的，请确保在国家法律法规下使用**<br/>\n**⚠️ 本项目完全免费，问你要钱的都是骗子**<br/>\n**⚠️ 使用本项目初衷是作者研究微信数据库的运行使用，您使用本软件导致的后果，包含但不限于数据损坏，记录丢失等问题，作者不承担相关责任。**<br/>\n**⚠️ 因软件特殊性质，请在使用时获得微信账号所有人授权，你当确保不侵犯他人个人隐私权，后果自行承担**<br/>\n\n## 前端代码\n由于前端代码不成熟，前端界面代码暂时不公开。\n\n## 参考/引用\n- 微信数据库解密和数据库的使用 [PyWxDump](https://github.com/xaoyaoo/PyWxDump/tree/master)\n- silk语音消息解码 [silk-v3-decoder](https://github.com/kn007/silk-v3-decoder)\n- PCM转MP3 [lame](https://github.com/viert/lame.git)\n- Dat图片解码 [wechatDatDecode](https://github.com/liuggchen/wechatDatDecode)\n\n## 交流/讨论",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "wechatdatabackup",
        "wechat",
        "export",
        "jiadong wechatdatabackup",
        "wechatdatabackup export",
        "files wechat"
      ],
      "category": "document-processing"
    },
    "gitkenan--doctair": {
      "owner": "gitkenan",
      "name": "doctair",
      "url": "https://github.com/gitkenan/doctair",
      "imageUrl": "/freedevtools/mcp/pfp/gitkenan.webp",
      "description": "Enables editing and deployment of applications through a web interface and local development environment, while synchronizing changes and facilitating project management with custom domain connections.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-05-22T14:25:22Z",
      "readme_content": "# 🩺 Med AI Insight Viewer\n\n**A web application leveraging AI to analyze medical images and provide insightful descriptions.**\n\nThis application allows users to securely upload medical images (X-rays, MRIs, CT scans, etc.) and receive AI-generated analysis, including potential observations and structured descriptions. It utilizes OpenAI's vision capabilities via Supabase Edge Functions for analysis, along with Supabase for authentication and data persistence.\n\n---\n\n<!-- Add a screenshot or GIF demo here -->\n<!-- ![App Screenshot](link/to/screenshot.png) -->\n\n## ✨ Key Features\n\n*   **Secure User Authentication:** Google OAuth login via Supabase Auth ensures user data privacy.\n*   **Easy Image Upload:** Simple drag-and-drop or file selection interface for medical images.\n*   **AI-Powered Analysis:** Utilizes OpenAI's advanced vision models (e.g., `gpt-4-vision-preview`) to interpret images.\n*   **Structured Results:** Provides analysis in a clear format (e.g., description, potential findings, comments).\n*   **Analysis History:** Stores past analyses for user reference, secured by Row Level Security (RLS).\n*   **Responsive UI:** Built with Shadcn/ui and Tailwind CSS for a clean experience on desktop and mobile.\n\n## 🚀 Tech Stack\n\n*   **Frontend:**\n    *   Framework: React (Vite)\n    *   Language: TypeScript\n    *   UI Library: Shadcn/ui\n    *   Styling: Tailwind CSS\n    *   Routing: React Router DOM (`react-router-dom`)\n    *   State Management: React Context, `useState`, Supabase Auth Helpers\n    *   Notifications: `react-hot-toast` (via `useToast` hook), `sonner`\n    *   Markdown Rendering: `markdown-to-jsx`\n*   **Backend:**\n    *   Platform: Supabase\n    *   Authentication: Supabase Auth (Google OAuth configured)\n    *   Database: Supabase PostgreSQL\n    *   Serverless Functions: Supabase Edge Functions (Deno Runtime)\n*   **AI:**\n    *   Model Provider: OpenAI\n    *   API Interaction: Via Supabase Edge Function\n\n## 📁 Project Structure\n\n.\n├── public/ # Static assets (icons, robots.txt)\n├── src/ # Frontend React application source\n│ ├── components/ # Reusable React components\n│ │ ├── ui/ # Shadcn UI components\n│ │ ├── AnalysisResult.tsx # Displays AI analysis results\n│ │ ├── ApiKeyInput.tsx # (Legacy/Client-side check - Not used for Backend API call)\n│ │ ├── Header.tsx # Application header with navigation/logout\n│ │ ├── HistoryList.tsx # Displays list of past analyses\n│ │ └── ImageUpload.tsx # Handles image selection and preview\n│ ├── hooks/ # Custom React hooks (use-toast, use-mobile)\n│ ├── lib/ # Utility functions (cn)\n│ ├── pages/ # Top-level route components (Index, Dashboard, NotFound)\n│ ├── types/ # TypeScript type definitions\n│ ├── utils/ # Utility functions for external services (openai.ts - calls backend)\n│ ├── App.css # Basic App styles (potentially removable)\n│ ├── App.tsx # Main application component, routing, Supabase context\n│ ├── index.css # Tailwind directives and base styles\n│ ├── main.tsx # Application entry point\n│ └── vite-env.d.ts # Vite TypeScript env declarations\n├── supabase/ # Supabase backend configuration and code\n│ ├── functions/ # Supabase Edge Functions\n│ │ ├── _shared/ # Shared code for functions (cors.ts)\n│ │ └── analyze-image/ # Edge Function for OpenAI image analysis\n│ │ └── index.ts\n│ └── migrations/ # Database schema migrations (.sql)\n├── .gitignore # Git ignore rules\n├── components.json # Shadcn UI configuration\n├── eslint.config.js # ESLint configuration\n├── index.html # Main HTML entry point for Vite\n├── package.json # Project dependencies and scripts\n├── postcss.config.js # PostCSS configuration\n├── README.md # This file\n├── tailwind.config.ts # Tailwind CSS configuration\n├── tsconfig.app.json # TypeScript config for the app\n├── tsconfig.json # Base TypeScript config\n├── tsconfig.node.json # TypeScript config for Node env (Vite config)\n└── vite.config.ts # Vite build configuration\n\n\n## ⚙️ Core Functionality & Workflow\n\n1.  **Authentication (`src/App.tsx`, `src/pages/Index.tsx`):**\n    *   Users land on the `Index` page.\n    *   Clicking \"Get Started\" initiates the Supabase Google OAuth flow.\n    *   Upon successful login, Supabase redirects back to the app (specifically `/dashboard` as configured in the OAuth options).\n    *   The `RequireAuth` component in `App.tsx` verifies the Supabase session using `useSession`. Authenticated users can access `/dashboard`; others are redirected to `/`.\n    *   The `Header` component provides a logout button which calls `supabase.auth.signOut()`.\n\n2.  **Image Upload (`src/pages/Dashboard.tsx`, `src/components/ImageUpload.tsx`):**\n    *   On the `Dashboard`, the `ImageUpload` component allows users to drag & drop or select an image file.\n    *   A preview of the selected image is displayed.\n    *   The selected `File` object and a base64 representation (`imagePreview`) are stored in the `Dashboard` component's state.\n\n3.  **Analysis Process:**\n    *   **Trigger:** The user clicks the \"Analyze Image\" button on the `Dashboard`.\n    *   **Frontend (`src/pages/Dashboard.tsx`, `src/utils/openai.ts`):**\n        *   The `analyzeImage` function in `Dashboard.tsx` is called.\n        *   It calls the utility function `analyzeImageApi` from `src/utils/openai.ts`.\n        *   `analyzeImageApi` gets the current Supabase session token.\n        *   It makes a `POST` request to the Supabase Edge Function endpoint (`/functions/v1/analyze-image`).\n        *   The request includes the `Authorization: Bearer <token>` header and a JSON body containing `imageBase64` and `imageType`.\n        *   It handles the response from the Edge Function.\n    *   **Backend (`supabase/functions/analyze-image/index.ts`):**\n        *   The Edge Function receives the request.\n        *   It validates the incoming JWT using the Supabase client initialized with the user's token.\n        *   It retrieves the **securely stored OpenAI API key** from the Edge Function's environment variables (`Deno.env.get('OPENAI_API_KEY')`). **The client-side key is NOT used here.**\n        *   It formats the `imageBase64` string into a data URL if necessary.\n        *   It constructs a request to the OpenAI API (`gpt-4.1-mini` or similar vision model specified in the function), sending the image URL and a specific prompt asking for medical observations/hypothetical diagnosis.\n        *   It receives the analysis text from OpenAI.\n        *   It structures the response into the `AnalysisResultType` format, adding a timestamp.\n        *   It saves the `imageType` and the structured `result` (as JSONB) to the `users_history` table in the Supabase database, linking it to the authenticated `user_id`.\n        *   It returns the newly created database record (containing the result) to the frontend.\n    *   **Frontend (`src/pages/Dashboard.tsx`):**\n        *   Receives the analysis result from the utility function.\n        *   Updates the `analysisResult` state variable.\n        *   Displays a success toast notification.\n        *   The `AnalysisResult` component re-renders to display the new data.\n\n4.  **Result Display (`src/components/AnalysisResult.tsx`):**\n    *   Renders the `AnalysisResultType` data passed via props.\n    *   Displays the image preview alongside the AI-generated content.\n    *   Uses `markdown-to-jsx` to render the analysis content, allowing for formatted text from the AI.\n    *   Includes a crucial disclaimer about the analysis not being professional medical advice.\n\n5.  **History (`src/pages/Dashboard.tsx`, `src/components/HistoryList.tsx`):**\n    *   The \"History\" tab on the `Dashboard` renders the `HistoryList` component.\n    *   `HistoryList` uses the Supabase JS client (`useSupabaseClient`) to fetch records from the `users_history` table, ordered by creation date.\n    *   Supabase RLS policies ensure only the currently logged-in user's history is returned.\n    *   Displays a list of past analyses, showing image type, a snippet of the diagnosis, and timestamp.\n\n## 💾 Backend Details\n\n### Supabase Edge Function (`analyze-image`)\n\n*   **Purpose:** Securely interacts with the OpenAI API using a server-side secret key and stores results.\n*   **Trigger:** HTTP POST request to `/functions/v1/analyze-image`.\n*   **Authentication:** Requires a valid Supabase JWT in the `Authorization` header.\n*   **Environment Variables:** Requires `SUPABASE_URL`, `SUPABASE_ANON_KEY`, and `OPENAI_API_KEY` to be set in the Edge Function settings.\n*   **Input:** JSON `{ imageBase64: string, imageType: string }`.\n*   **Processing:**\n    1.  Authenticates user via JWT.\n    2.  Retrieves `OPENAI_API_KEY` secret.\n    3.  Calls OpenAI Chat Completions API with vision model.\n    4.  Parses OpenAI response.\n    5.  Inserts result into `users_history` table using the authenticated user's ID.\n*   **Output:** JSON containing the newly created database entry (`{ result: UserHistoryItem }`).\n\n### Supabase Database Schema (`users_history`)\n\n*   **Table:** `public.users_history`\n*   **Purpose:** Stores the results of image analyses linked to users.\n*   **Columns:**\n    *   `id` (uuid, PK): Unique identifier for the history entry.\n    *   `user_id` (uuid, FK -> `auth.users`): Links the entry to the authenticated user.\n    *   `image_url` (text, nullable): *Currently seems unused in the primary analysis flow which uses base64.* Could be used if storing uploaded images directly.\n    *   `image_type` (text, not null): Type of the analyzed image (e.g., \"X-ray\", \"MRI\").\n    *   `result` (jsonb, not null): Stores the structured `AnalysisResultType` object returned by the AI.\n    *   `created_at` (timestamptz, default now()): Timestamp of when the analysis was performed.\n*   **Row Level Security (RLS):**\n    *   **Enabled:** Yes.\n    *   **Policies:**\n        *   Users can `SELECT` only their own history records (`auth.uid() = user_id`).\n        *   Users can `INSERT` only records where `user_id` matches their own `auth.uid()`.\n\n## 🛠️ Getting Started\n\n### Prerequisites\n\n*   Node.js (v18 or later recommended)\n*   npm, yarn, or pnpm\n*   Git\n*   Supabase Account\n*   Supabase CLI (Optional, for local development)\n*   OpenAI API Key\n\n### Installation & Setup\n\n1.  **Clone the repository:**\n    ```bash\n    git clone <repository-url>\n    cd med-ai-insight-viewer\n    ```\n\n2.  **Install frontend dependencies:**\n    ```bash\n    npm install\n    # or yarn install or pnpm install\n    ```\n\n3.  **Set up Environment Variables:**\n    *   Create a `.env` file in the root directory.\n    *   Add your Supabase Project URL and Anon Key:\n        ```env\n        VITE_SUPABASE_URL=YOUR_SUPABASE_PROJECT_URL\n        VITE_SUPABASE_ANON_KEY=YOUR_SUPABASE_ANON_KEY\n        ```\n    *   You can find these in your Supabase project settings (Project Settings > API).\n\n4.  **Supabase Setup:**\n    *   **Option A: Supabase Cloud (Recommended for deployment)**\n        1.  Go to your Supabase project dashboard.\n        2.  **Authentication:** Navigate to Authentication > Providers and enable the \"Google\" provider. Add your Google Cloud OAuth credentials. Ensure you add your app's URL(s) (including localhost for development) to the \"Redirect URLs\" section in Supabase Auth settings *and* in your Google Cloud OAuth configuration.\n        3.  **Database:** Navigate to the SQL Editor. Copy the contents of `supabase/migrations/20250421000000_initial_schema.sql` and run it to create the `users_history` table and RLS policies.\n        4.  **Edge Functions:**\n            *   Navigate to Edge Functions.\n            *   Deploy the `analyze-image` function (e.g., using `supabase functions deploy analyze-image --no-verify-jwt` if testing locally first, or set up CI/CD).\n            *   Go to the `analyze-image` function's settings > Secrets and add your `OPENAI_API_KEY`.\n    *   **Option B: Supabase Local Development**\n        1.  Initialize Supabase locally: `supabase init`\n        2.  Start Supabase services: `supabase start`\n        3.  Apply database migrations: `supabase db push` (or link your project `supabase link --project-ref <your-project-ref>` and pull schema changes if needed).\n        4.  Set Edge Function secrets locally: `supabase secrets set OPENAI_API_KEY=YOUR_OPENAI_API_KEY`\n        5.  (You'll need to configure Google Auth locally or use email/password for testing if not using the cloud setup). Use the local Supabase URL/keys in your `.env`.\n\n5.  **Run the Frontend:**\n    ```bash\n    npm run dev\n    ```\n    The application should now be running, typically at `http://localhost:8080`.\n\n6.  **Deploy Edge Function (if not done in step 4):**\n    ```bash\n    # Link to your project if you haven't already\n    # supabase link --project-ref <your-project-ref>\n\n    # Deploy the function\n    supabase functions deploy analyze-image\n\n    # IMPORTANT: Set the secret in the Supabase Dashboard (Settings > Edge Functions > analyze-image > Secrets)\n    # Add OPENAI_API_KEY with your actual OpenAI key value.\n    ```\n\n## 🔧 Configuration\n\n*   **OpenAI Model:** The AI model used for analysis is specified in `supabase/functions/analyze-image/index.ts` (currently hardcoded, likely `gpt-4.1-mini` or similar).\n*   **Analysis Prompt:** The prompt sent to OpenAI is also defined within the `analyze-image` Edge Function. Modify this to change the AI's behavior or the desired output format.\n*   **UI Theme:** Colors and styles can be adjusted in `src/index.css` (CSS variables) and `tailwind.config.ts`.\n*   **Shadcn UI:** Components can be added or customized using the Shadcn CLI and `components.json`.\n\n## 💡 Usage\n\n1.  Open the application in your browser.\n2.  Log in using your Google account.\n3.  Navigate to the \"Analyze Image\" tab.\n4.  Upload a medical image using the drag-and-drop area or the file selector.\n5.  Click the \"Analyze Image\" button.\n6.  Wait for the analysis to complete (a loading indicator will show).\n7.  View the structured results displayed below the upload section.\n8.  Navigate to the \"History\" tab to view past analyses.\n\n## ⚠️ Disclaimer\n\n**This application is for informational and demonstration purposes only. The AI-generated analysis is NOT a substitute for professional medical advice, diagnosis, or treatment.** Always consult with a qualified healthcare provider regarding any medical conditions or concerns. Do not disregard professional medical advice or delay in seeking it because of something you have read or seen using this application.\n\n## 🤝 Contributing\n\nContributions are welcome! Please feel free to submit issues or pull requests.\n\n1.  Fork the repository.\n2.  Create a new branch (`git checkout -b feature/your-feature-name`).\n3.  Make your changes.\n4.  Commit your changes (`git commit -m 'Add some feature'`).\n5.  Push to the branch (`git push origin feature/your-feature-name`).\n6.  Open a Pull Request.\n\n## 📄 License\n\n(Specify License - e.g., MIT, Apache 2.0. If none, state \"All Rights Reserved.\")",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "gitkenan",
        "document",
        "doctair",
        "processing gitkenan",
        "gitkenan doctair",
        "deployment applications"
      ],
      "category": "document-processing"
    },
    "gstarwd--doompdf": {
      "owner": "gstarwd",
      "name": "doompdf",
      "url": "https://github.com/gstarwd/doompdf",
      "imageUrl": "/freedevtools/mcp/pfp/gstarwd.webp",
      "description": "Integrates the classic DOOM game into PDF documents, enabling interactive gameplay within static files via PDF's JavaScript capabilities. This project transforms traditional document formats into innovative gaming platforms while maintaining the essence of classic gaming.",
      "stars": 1,
      "forks": 1,
      "license": "MIT License",
      "language": "",
      "updated_at": "2025-04-30T00:37:12Z",
      "readme_content": "# DOOM PDF Project 🎮\n\nWelcome to the DOOM PDF project repository - where we explore the fascinating intersection of classic gaming and document formats by running DOOM inside PDF files!\n\n## About The Project\n\nThis project demonstrates the incredible possibilities of PDF's interactive capabilities by implementing the classic DOOM game within a PDF document. It showcases how traditional document formats can be pushed beyond their conventional boundaries, turning static documents into interactive gaming platforms.\n\n## Live Demos\n\n- [DOOM PDF Main Site](https://doompdf.onl/)\n- [Play DOOM Online](https://doompdf.onl/doom-online/)\n\n## Key Features\n\n- Full DOOM gameplay experience within a PDF document\n- Utilizes PDF's JavaScript capabilities\n- Cross-platform compatibility\n- Innovative approach to game preservation\n- Interactive document demonstration\n\n## Technical Highlights\n\n- Advanced PDF JavaScript implementation\n- Memory management optimization\n- Custom input handling system\n- Performance-optimized rendering\n- Cross-reader compatibility\n\n## Applications & Impact\n\n- Game Preservation\n- Educational Resources\n- Technical Innovation\n- Document Format Evolution\n- Interactive Document Development\n\n## Contributing\n\nWe welcome contributions from the community! Whether you're interested in:\n- Improving performance\n- Adding new features\n- Fixing bugs\n- Documenting the implementation\n- Suggesting improvements\n\nFeel free to open an issue or submit a pull request.\n\n## Related Projects\n\n- DOOM Engine Studies\n- PDF Interactive Features\n- Game Porting Techniques\n- Document Format Innovation\n\n## Acknowledgments\n\n- id Software for creating DOOM\n- The PDF specification developers\n- The gaming preservation community\n- All contributors and supporters\n\n## License\n\nThis project is licensed under [appropriate license] - see the LICENSE file for details.\n\n---\n \n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "doompdf",
        "doom",
        "pdf",
        "gstarwd doompdf",
        "doompdf integrates",
        "doom game"
      ],
      "category": "document-processing"
    },
    "gyger--mcp-pyzotero": {
      "owner": "gyger",
      "name": "mcp-pyzotero",
      "url": "https://github.com/gyger/mcp-pyzotero",
      "imageUrl": "/freedevtools/mcp/pfp/gyger.webp",
      "description": "Integrates a local Zotero library with Claude Desktop, enabling direct read access to bibliographic data through a local web API in Zotero 7.",
      "stars": 52,
      "forks": 4,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-17T14:22:13Z",
      "readme_content": "# Zotero MCP Connector\n\nA Model Control Protocol (MCP) connector for integrating your local Zotero with Claude.  \nThis enables direct read access to your local Zotero library through Claude's Desktop interface.\nIt depends on the ability to access a local web-api in Zotero 7.\n\nThis was inspired by a repository using Node.js and the web api: [mcp-zotero](https://github.com/kaliaboi/mcp-zotero).  \nThis builds on the shoulders of the fantastic [pyzotero](https://github.com/urschrei/pyzotero) library.\n\n## Installation\n\n### Run from local code (Recommended)\nInformation about Claude Desktop interacting with MCPs can be found [here](https://modelcontextprotocol.io/quickstart/user).\n\n1. Use `uv`. Installation instructions can be found [here](https://docs.astral.sh/uv/getting-started/installation/).\n\n2. Checkout the git project to local space and activate the virtual environment inside:\n```bash\ngit clone https://github.com/gyger/mcp-pyzotero.git\ncd mcp-pyzotero\nuv sync\n```\n\n3. Enable the local API in Zotero 7:\n   \n\n4. Add the server to your local Claude installation:\n```bash\nuv run mcp install zotero.py\n```\n\n### Run encapsulated with uvx (Should work)\nEdit the configuration for your Claude Desktop softare in the file.\n\n    - macOS: ~/Library/Application Support/Claude/claude_desktop_config.json\n    - Windows: %APPDATA%\\Claude\\claude_desktop_config.json\n\nand add the Zotero entry\n```json\n{\n    \"mcpServers\": {\n        \"Zotero\": {\n            \"command\": \"uvx\",\n            \"args\": [\"--from\", \"git+https://github.com/gyger/mcp-pyzotero.git\", \n                     \"--with\", \"mcp[cli]\",\n                     \"--with\", \"pyzotero\",\n                     \"mcp\", \"run\", \"zotero.py\"\n                    ],\n        }\n    }\n}\n```\n\n## Configuration\n\nThe connector is configured to work with local Zotero installations and currently only `user` libraries are supported. \nBy default it uses the userid `0`, but you can also set the environment variable `ZOTERO_USER_ID` if needed:\n\n```bash\nuv run mcp install zotero.py -v ZOTERO_USER_ID=0\n```\n\n## Available Functions\n\n### Available tools\n- `get_zotero_summary()`: Lists properties about your library including collections, recent items or tags.\n- `get_collection_items(collection_key)`: Get all items in a specific collection\n- `get_items_metadata(item_key)`: Get detailed information about specific paper(s), including abstract.\n- `search_library(query, mode)`: Search your Zotero library, with two possible modes: everything or titleCreatorYear.\n\nThis functionality should be extended in the future.\n\n## Requirements\n\n- Python 3.10+\n  - pyzotero\n  - mcp[cli]\n- Local Zotero installation\n\n## Contributing\n\nContributions are welcome! Please visit the [GitHub repository](https://github.com/gyger/mcp-pyzotero) to:\n- Report issues\n- Submit pull requests\n- Suggest improvements\n\n## License\n\nMIT",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "zotero",
        "pyzotero",
        "library",
        "zotero library",
        "api zotero",
        "local zotero"
      ],
      "category": "document-processing"
    },
    "hannesrudolph--mcp-ragdocs": {
      "owner": "hannesrudolph",
      "name": "mcp-ragdocs",
      "url": "https://github.com/hannesrudolph/mcp-ragdocs",
      "imageUrl": "/freedevtools/mcp/pfp/hannesrudolph.webp",
      "description": "Retrieve and process documentation through vector search, enabling AI models to integrate relevant context into their responses. Supports multiple sources and offers semantic search capabilities for enhanced information retrieval.",
      "stars": 228,
      "forks": 27,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T04:12:27Z",
      "readme_content": "# RAG Documentation MCP Server\n\nAn MCP server implementation that provides tools for retrieving and processing documentation through vector search, enabling AI assistants to augment their responses with relevant documentation context.\n\n<a href=\"https://glama.ai/mcp/servers/54hsrjhmq9\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/54hsrjhmq9/badge\" alt=\"mcp-ragdocs MCP server\" /></a>\n\n## Features\n\n- Vector-based documentation search and retrieval\n- Support for multiple documentation sources\n- Semantic search capabilities\n- Automated documentation processing\n- Real-time context augmentation for LLMs\n\n## Tools\n\n### search_documentation\nSearch through stored documentation using natural language queries. Returns matching excerpts with context, ranked by relevance.\n\n**Inputs:**\n- `query` (string): The text to search for in the documentation. Can be a natural language query, specific terms, or code snippets.\n- `limit` (number, optional): Maximum number of results to return (1-20, default: 5). Higher limits provide more comprehensive results but may take longer to process.\n\n### list_sources\nList all documentation sources currently stored in the system. Returns a comprehensive list of all indexed documentation including source URLs, titles, and last update times. Use this to understand what documentation is available for searching or to verify if specific sources have been indexed.\n\n### extract_urls\nExtract and analyze all URLs from a given web page. This tool crawls the specified webpage, identifies all hyperlinks, and optionally adds them to the processing queue.\n\n**Inputs:**\n- `url` (string): The complete URL of the webpage to analyze (must include protocol, e.g., https://). The page must be publicly accessible.\n- `add_to_queue` (boolean, optional): If true, automatically add extracted URLs to the processing queue for later indexing. Use with caution on large sites to avoid excessive queuing.\n\n### remove_documentation\nRemove specific documentation sources from the system by their URLs. The removal is permanent and will affect future search results.\n\n**Inputs:**\n- `urls` (string[]): Array of URLs to remove from the database. Each URL must exactly match the URL used when the documentation was added.\n\n### list_queue\nList all URLs currently waiting in the documentation processing queue. Shows pending documentation sources that will be processed when run_queue is called. Use this to monitor queue status, verify URLs were added correctly, or check processing backlog.\n\n### run_queue\nProcess and index all URLs currently in the documentation queue. Each URL is processed sequentially, with proper error handling and retry logic. Progress updates are provided as processing occurs. Long-running operations will process until the queue is empty or an unrecoverable error occurs.\n\n### clear_queue\nRemove all pending URLs from the documentation processing queue. Use this to reset the queue when you want to start fresh, remove unwanted URLs, or cancel pending processing. This operation is immediate and permanent - URLs will need to be re-added if you want to process them later.\n\n## Usage\n\nThe RAG Documentation tool is designed for:\n\n- Enhancing AI responses with relevant documentation\n- Building documentation-aware AI assistants\n- Creating context-aware tooling for developers\n- Implementing semantic documentation search\n- Augmenting existing knowledge bases\n\n## Configuration\n\n### Usage with Claude Desktop\n\nAdd this to your `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"rag-docs\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@hannesrudolph/mcp-ragdocs\"\n      ],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"\",\n        \"QDRANT_URL\": \"\",\n        \"QDRANT_API_KEY\": \"\"\n      }\n    }\n  }\n}\n```\n\nYou'll need to provide values for the following environment variables:\n- `OPENAI_API_KEY`: Your OpenAI API key for embeddings generation\n- `QDRANT_URL`: URL of your Qdrant vector database instance\n- `QDRANT_API_KEY`: API key for authenticating with Qdrant\n\n## License\n\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.\n\n## Acknowledgments\n\nThis project is a fork of [qpd-v/mcp-ragdocs](https://github.com/qpd-v/mcp-ragdocs), originally developed by qpd-v. The original project provided the foundation for this implementation.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "retrieval",
        "search",
        "semantic",
        "semantic search",
        "information retrieval",
        "document processing"
      ],
      "category": "document-processing"
    },
    "hanweg--mcp-pdf-tools": {
      "owner": "hanweg",
      "name": "mcp-pdf-tools",
      "url": "https://github.com/hanweg/mcp-pdf-tools",
      "imageUrl": "/freedevtools/mcp/pfp/hanweg.webp",
      "description": "Provides tools for manipulating PDF files, including merging multiple PDFs, extracting specific pages, and finding related PDFs based on text extraction and regex patterns.",
      "stars": 63,
      "forks": 8,
      "license": "The Unlicense",
      "language": "Python",
      "updated_at": "2025-10-03T22:32:04Z",
      "readme_content": "# WORK IN PROGRESS - USE WITH CAUTION - Windows:\n\n# MCP PDF Tools Server\n\nAn MCP (Model Context Protocol) server that provides PDF manipulation tools. This server allows LLMs to perform operations like merging PDFs and extracting pages through the Model Context Protocol.\n\n<a href=\"https://glama.ai/mcp/servers/fqtuoh05xi\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/fqtuoh05xi/badge\" alt=\"mcp-pdf-tools MCP server\" /></a>\n\n## Features\n\n- Merge multiple PDF files into a single PDF\n- Merge multiple PDF files into a single PDF in user specified order\n- Extract specific pages from a PDF file\n- Search PDFs *filesystem search or Everything search works better than this*\n- Find (and merge) related PDFs based on text extraction and regex pattern matching from a target input PDF\n\n## Installation\n\n1. Clone this repository\n2. \n```bash\ncd mcp-pdf-tools\n\n# Create and activate virtual environment\nuv venv\n.venv\\Scripts\\activate\n\n# Install the package\nuv pip install -e .\n```\n\n## Usage with Claude Desktop\n\nAdd this to your Claude Desktop configuration file (claude_desktop_config.json):\n\n```json\n{\n    \"mcpServers\": {\n        \"pdf-tools\": {\n            \"command\": \"uv\",\n            \"args\": [\n                \"--directory\",\n                \"PATH_TO\\\\mcp-pdf-tools\",\n                \"run\",\n                \"pdf-tools\"\n            ]\n        }\n    }\n}\n```\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "pdfs",
        "pdf",
        "document",
        "pdf tools",
        "pdfs extracting",
        "mcp pdf"
      ],
      "category": "document-processing"
    },
    "haris-musa--excel-mcp-server": {
      "owner": "haris-musa",
      "name": "excel-mcp-server",
      "url": "https://github.com/haris-musa/excel-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/haris-musa.webp",
      "description": "Manipulate Excel files programmatically without Microsoft Excel installed. Create, read, modify workbooks, apply formatting, generate charts, and manage data ranges.",
      "stars": 2468,
      "forks": 279,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-04T02:39:13Z",
      "readme_content": "<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/haris-musa/excel-mcp-server/main/assets/logo.png\" alt=\"Excel MCP Server Logo\" width=\"300\"/>\n</p>\n\n[![PyPI version](https://img.shields.io/pypi/v/excel-mcp-server.svg)](https://pypi.org/project/excel-mcp-server/)\n[![Total Downloads](https://static.pepy.tech/badge/excel-mcp-server)](https://pepy.tech/project/excel-mcp-server)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![smithery badge](https://smithery.ai/badge/@haris-musa/excel-mcp-server)](https://smithery.ai/server/@haris-musa/excel-mcp-server)\n[![Install MCP Server](https://cursor.com/deeplink/mcp-install-dark.svg)](https://cursor.com/install-mcp?name=excel-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGV4Y2VsLW1jcC1zZXJ2ZXIgc3RkaW8ifQ%3D%3D)\n\nA Model Context Protocol (MCP) server that lets you manipulate Excel files without needing Microsoft Excel installed. Create, read, and modify Excel workbooks with your AI agent.\n\n## Features\n\n- 📊 **Excel Operations**: Create, read, update workbooks and worksheets\n- 📈 **Data Manipulation**: Formulas, formatting, charts, pivot tables, and Excel tables\n- 🔍 **Data Validation**: Built-in validation for ranges, formulas, and data integrity\n- 🎨 **Formatting**: Font styling, colors, borders, alignment, and conditional formatting\n- 📋 **Table Operations**: Create and manage Excel tables with custom styling\n- 📊 **Chart Creation**: Generate various chart types (line, bar, pie, scatter, etc.)\n- 🔄 **Pivot Tables**: Create dynamic pivot tables for data analysis\n- 🔧 **Sheet Management**: Copy, rename, delete worksheets with ease\n- 🔌 **Triple transport support**: stdio, SSE (deprecated), and streamable HTTP\n- 🌐 **Remote & Local**: Works both locally and as a remote service\n\n## Usage\n\nThe server supports three transport methods:\n\n### 1. Stdio Transport (for local use)\n\n```bash\nuvx excel-mcp-server stdio\n```\n\n```json\n{\n   \"mcpServers\": {\n      \"excel\": {\n         \"command\": \"uvx\",\n         \"args\": [\"excel-mcp-server\", \"stdio\"]\n      }\n   }\n}\n```\n\n### 2. SSE Transport (Server-Sent Events - Deprecated)\n\n```bash\nuvx excel-mcp-server sse\n```\n\n**SSE transport connection**:\n```json\n{\n   \"mcpServers\": {\n      \"excel\": {\n         \"url\": \"http://localhost:8000/sse\",\n      }\n   }\n}\n```\n\n### 3. Streamable HTTP Transport (Recommended for remote connections)\n\n```bash\nuvx excel-mcp-server streamable-http\n```\n\n**Streamable HTTP transport connection**:\n```json\n{\n   \"mcpServers\": {\n      \"excel\": {\n         \"url\": \"http://localhost:8000/mcp\",\n      }\n   }\n}\n```\n\n## Environment Variables & File Path Handling\n\n### SSE and Streamable HTTP Transports\n\nWhen running the server with the **SSE or Streamable HTTP protocols**, you **must set the `EXCEL_FILES_PATH` environment variable on the server side**. This variable tells the server where to read and write Excel files.\n- If not set, it defaults to `./excel_files`.\n\nYou can also set the `FASTMCP_PORT` environment variable to control the port the server listens on (default is `8017` if not set).\n- Example (Windows PowerShell):\n  ```powershell\n  $env:EXCEL_FILES_PATH=\"E:\\MyExcelFiles\"\n  $env:FASTMCP_PORT=\"8007\"\n  uvx excel-mcp-server streamable-http\n  ```\n- Example (Linux/macOS):\n  ```bash\n  EXCEL_FILES_PATH=/path/to/excel_files FASTMCP_PORT=8007 uvx excel-mcp-server streamable-http\n  ```\n\n### Stdio Transport\n\nWhen using the **stdio protocol**, the file path is provided with each tool call, so you do **not** need to set `EXCEL_FILES_PATH` on the server. The server will use the path sent by the client for each operation.\n\n## Available Tools\n\nThe server provides a comprehensive set of Excel manipulation tools. See [TOOLS.md](TOOLS.md) for complete documentation of all available tools.\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=haris-musa/excel-mcp-server&type=Date)](https://www.star-history.com/#haris-musa/excel-mcp-server&Date)\n\n## License\n\nMIT License - see [LICENSE](LICENSE) for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "excel",
        "workbooks",
        "microsoft",
        "excel files",
        "musa excel",
        "microsoft excel"
      ],
      "category": "document-processing"
    },
    "heltonteixeira--ragdocs": {
      "owner": "heltonteixeira",
      "name": "ragdocs",
      "url": "https://github.com/heltonteixeira/ragdocs",
      "imageUrl": "/freedevtools/mcp/pfp/heltonteixeira.webp",
      "description": "Manage and search documentation using advanced semantic search and retrieval-augmented generation capabilities. Supports document management tasks such as adding, listing, and deleting documents with automatic text chunking and vector storage through Qdrant.",
      "stars": 16,
      "forks": 3,
      "license": "Apache License 2.0",
      "language": "TypeScript",
      "updated_at": "2025-08-21T20:45:35Z",
      "readme_content": "# RagDocs MCP Server\n\nA Model Context Protocol (MCP) server that provides RAG (Retrieval-Augmented Generation) capabilities using Qdrant vector database and Ollama/OpenAI embeddings. This server enables semantic search and management of documentation through vector similarity.\n\n## Features\n\n- Add documentation with metadata\n- Semantic search through documents\n- List and organize documentation\n- Delete documents\n- Support for both Ollama (free) and OpenAI (paid) embeddings\n- Automatic text chunking and embedding generation\n- Vector storage with Qdrant\n\n## Prerequisites\n\n- Node.js 16 or higher\n- One of the following Qdrant setups:\n  - Local instance using Docker (free)\n  - Qdrant Cloud account with API key (managed service)\n- One of the following for embeddings:\n  - Ollama running locally (default, free)\n  - OpenAI API key (optional, paid)\n\n## Available Tools\n\n### 1. add_document\nAdd a document to the RAG system.\n\nParameters:\n- `url` (required): Document URL/identifier\n- `content` (required): Document content\n- `metadata` (optional): Document metadata\n  - `title`: Document title\n  - `contentType`: Content type (e.g., \"text/markdown\")\n\n### 2. search_documents\nSearch through stored documents using semantic similarity.\n\nParameters:\n- `query` (required): Natural language search query\n- `options` (optional):\n  - `limit`: Maximum number of results (1-20, default: 5)\n  - `scoreThreshold`: Minimum similarity score (0-1, default: 0.7)\n  - `filters`:\n    - `domain`: Filter by domain\n    - `hasCode`: Filter for documents containing code\n    - `after`: Filter for documents after date (ISO format)\n    - `before`: Filter for documents before date (ISO format)\n\n### 3. list_documents\nList all stored documents with pagination and grouping options.\n\nParameters (all optional):\n- `page`: Page number (default: 1)\n- `pageSize`: Number of documents per page (1-100, default: 20)\n- `groupByDomain`: Group documents by domain (default: false)\n- `sortBy`: Sort field (\"timestamp\", \"title\", or \"domain\")\n- `sortOrder`: Sort order (\"asc\" or \"desc\")\n\n### 4. delete_document\nDelete a document from the RAG system.\n\nParameters:\n- `url` (required): URL of the document to delete\n\n## Installation\n\n```bash\nnpm install -g @mcpservers/ragdocs\n```\n\n## MCP Server Configuration\n\n```json\n{\n  \"mcpServers\": {\n    \"ragdocs\": {\n      \"command\": \"node\",\n      \"args\": [\"@mcpservers/ragdocs\"],\n      \"env\": {\n        \"QDRANT_URL\": \"http://127.0.0.1:6333\",\n        \"EMBEDDING_PROVIDER\": \"ollama\"\n      }\n    }\n  }\n}\n```\n\nUsing Qdrant Cloud:\n```json\n{\n  \"mcpServers\": {\n    \"ragdocs\": {\n      \"command\": \"node\",\n      \"args\": [\"@mcpservers/ragdocs\"],\n      \"env\": {\n        \"QDRANT_URL\": \"https://your-cluster-url.qdrant.tech\",\n        \"QDRANT_API_KEY\": \"your-qdrant-api-key\",\n        \"EMBEDDING_PROVIDER\": \"ollama\"\n      }\n    }\n  }\n}\n```\n\nUsing OpenAI:\n```json\n{\n  \"mcpServers\": {\n    \"ragdocs\": {\n      \"command\": \"node\",\n      \"args\": [\"@mcpservers/ragdocs\"],\n      \"env\": {\n        \"QDRANT_URL\": \"http://127.0.0.1:6333\",\n        \"EMBEDDING_PROVIDER\": \"openai\",\n        \"OPENAI_API_KEY\": \"your-api-key\"\n      }\n    }\n  }\n}\n```\n\n## Local Qdrant with Docker\n\n```bash\ndocker run -d --name qdrant -p 6333:6333 -p 6334:6334 qdrant/qdrant\n```\n\n## Environment Variables\n\n- `QDRANT_URL`: URL of your Qdrant instance\n  - For local: \"http://127.0.0.1:6333\" (default)\n  - For cloud: \"https://your-cluster-url.qdrant.tech\"\n- `QDRANT_API_KEY`: API key for Qdrant Cloud (required when using cloud instance)\n- `EMBEDDING_PROVIDER`: Choice of embedding provider (\"ollama\" or \"openai\", default: \"ollama\")\n- `OPENAI_API_KEY`: OpenAI API key (required if using OpenAI)\n- `EMBEDDING_MODEL`: Model to use for embeddings\n  - For Ollama: defaults to \"nomic-embed-text\"\n  - For OpenAI: defaults to \"text-embedding-3-small\"\n\n## License\n\nApache License 2.0\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "documents",
        "retrieval",
        "document",
        "document management",
        "document processing",
        "documents automatic"
      ],
      "category": "document-processing"
    },
    "hesiod-au--python-mcp": {
      "owner": "hesiod-au",
      "name": "python-mcp",
      "url": "https://github.com/hesiod-au/python-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/hesiod-au.webp",
      "description": "Analyze and extract Python code structures with a focus on import relationships between files, while providing relevant code sections and project documentation for enhanced development workflows.",
      "stars": 6,
      "forks": 3,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-06-25T20:23:11Z",
      "readme_content": "# Python MCP Server for Code Graph Extraction\n\nThis MCP (Model Context Protocol) server provides tools for extracting and analyzing Python code structures, focusing on import/export relationships between files. This is a lightweight implementation that doesn't require an agent system, making it easy to integrate into any Python application.\n\n## Features\n\n- **Code Relationship Discovery**: Analyze import relationships between Python files\n- **Smart Code Extraction**: Extract only the most relevant code sections to stay within token limits\n- **Directory Context**: Include files from the same directory to provide better context\n- **Documentation Inclusion**: Always include README.md files (or variants) to provide project documentation\n- **LLM-Friendly Formatting**: Format code with proper metadata for language models\n- **MCP Protocol Support**: Fully compatible with the Model Context Protocol JSON-RPC standard\n\n## The `get_python_code` Tool\n\nThe server exposes a powerful code extraction tool that:\n\n- Analyzes a target Python file and discovers all imported modules, classes, and functions\n- Returns the complete code of the target file\n- Includes code for all referenced objects from other files\n- Adds additional contextual files from the same directory\n- Respects token limits to avoid overwhelming language models\n\n## Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/yourusername/python-mcp-new.git\ncd python-mcp-new\n\n# Create a virtual environment\npython -m venv venv\nsource venv/bin/activate  # On Windows, use: venv\\Scripts\\activate\n\n# Install dependencies\npip install -r requirements.txt\n```\n\n## Environment Variables\n\nCreate a `.env` file based on the provided `.env.example`:\n\n```\n# Token limit for extraction\nTOKEN_LIMIT=8000\n```\n\n## Usage\n\n### Configuring for MCP Clients\n\nTo configure this MCP server for use in MCP-compatible clients (like Codeium Windsurf), add the following configuration to your client's MCP config file:\n\n```json\n{\n  \"mcpServers\": {\n    \"python-code-explorer\": {\n      \"command\": \"python\",\n      \"args\": [\n        \"/path/to/python-mcp-new/server.py\"\n      ],\n      \"env\": {\n        \"TOKEN_LIMIT\": \"8000\"\n      }\n    }\n  }\n}\n```\n\nReplace `/path/to/python-mcp-new/server.py` with the absolute path to the server.py file on your system.\n\nYou can also customize the environment variables:\n- `TOKEN_LIMIT`: Maximum token limit for code extraction (default: 8000)\n\n## Usage Examples\n\n### Direct Function Call\n\n```python\nfrom agent import get_python_code\n\n# Get Python code structure for a specific file\nresult = get_python_code(\n    target_file=\"/home/user/project/main.py\",\n    root_repo_path=\"/home/user/project\"  # Optional, defaults to target file directory\n)\n\n# Process the result\ntarget_file = result[\"target_file\"]\nprint(f\"Main file: {target_file['file_path']}\")\nprint(f\"Docstring: {target_file['docstring']}\")\n\n# Display related files\nfor ref_file in result[\"referenced_files\"]:\n    print(f\"Related file: {ref_file['file_path']}\")\n    print(f\"Object: {ref_file['object_name']}\")\n    print(f\"Type: {ref_file['object_type']}\")\n\n# See if we're close to the token limit\nprint(f\"Token usage: {result['token_count']}/{result['token_limit']}\")\n```\n\n#### Example Response (Direct Function Call)\n\n```python\n{\n    \"target_file\": {\n        \"file_path\": \"main.py\",\n        \"code\": \"import os\\nimport sys\\nfrom utils.helpers import format_output\\n\\ndef main():\\n    args = sys.argv[1:]\\n    if not args:\\n        print('No arguments provided')\\n        return\\n    \\n    result = format_output(args[0])\\n    print(result)\\n\\nif __name__ == '__main__':\\n    main()\",\n        \"type\": \"target\",\n        \"docstring\": \"\"\n    },\n    \"referenced_files\": [\n        {\n            \"file_path\": \"utils/helpers.py\",\n            \"object_name\": \"format_output\",\n            \"object_type\": \"function\",\n            \"code\": \"def format_output(text):\\n    \\\"\\\"\\\"Format the input text for display.\\\"\\\"\\\"\\n    if not text:\\n        return ''\\n    return f'Output: {text.upper()}'\\n\",\n            \"docstring\": \"Format the input text for display.\",\n            \"truncated\": false\n        }\n    ],\n    \"additional_files\": [\n        {\n            \"file_path\": \"config.py\",\n            \"code\": \"# Configuration settings\\n\\nDEBUG = True\\nVERSION = '1.0.0'\\nMAX_RETRIES = 3\\n\",\n            \"type\": \"related_by_directory\",\n            \"docstring\": \"Configuration settings for the application.\"\n        }\n    ],\n    \"total_files\": 3,\n    \"token_count\": 450,\n    \"token_limit\": 8000\n}\n```\n\n### Using the MCP Protocol\n\n#### Listing Available Tools\n\n```python\nfrom agent import handle_mcp_request\nimport json\n\n# List available tools\nlist_request = {\n    \"jsonrpc\": \"2.0\",\n    \"id\": 1,\n    \"method\": \"tools/list\"\n}\n\nresponse = handle_mcp_request(list_request)\nprint(json.dumps(response, indent=2))\n```\n\n#### Example Response (tools/list)\n\n```json\n{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"result\": {\n    \"tools\": [\n      {\n        \"name\": \"get_python_code\",\n        \"description\": \"Return the code of a target Python file and related files based on import/export proximity.\",\n        \"inputSchema\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"target_file\": {\n              \"type\": \"string\",\n              \"description\": \"Path to the Python file to analyze.\"\n            },\n            \"root_repo_path\": {\n              \"type\": \"string\",\n              \"description\": \"Root directory of the repository. If not provided, the directory of the target file will be used.\"\n            }\n          },\n          \"required\": [\"target_file\"]\n        }\n      }\n    ]\n  }\n}\n```\n\n#### Calling get_python_code Tool\n\n```python\nfrom agent import handle_mcp_request\nimport json\n\n# Call the get_python_code tool\ntool_request = {\n    \"jsonrpc\": \"2.0\",\n    \"id\": 2,\n    \"method\": \"tools/call\",\n    \"params\": {\n        \"name\": \"get_python_code\",\n        \"arguments\": {\n            \"target_file\": \"/home/user/project/main.py\",\n            \"root_repo_path\": \"/home/user/project\"  # Optional\n        }\n    }\n}\n\nresponse = handle_mcp_request(tool_request)\nprint(json.dumps(response, indent=2))\n```\n\n#### Example Response (tools/call)\n\n```json\n{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 2,\n  \"result\": {\n    \"content\": [\n      {\n        \"type\": \"text\",\n        \"text\": \"Python code analysis for /home/user/project/main.py\"\n      },\n      {\n        \"type\": \"resource\",\n        \"resource\": {\n          \"uri\": \"resource://python-code/main.py\",\n          \"mimeType\": \"application/json\",\n          \"data\": {\n            \"target_file\": {\n              \"file_path\": \"main.py\",\n              \"code\": \"import os\\nimport sys\\nfrom utils.helpers import format_output\\n\\ndef main():\\n    args = sys.argv[1:]\\n    if not args:\\n        print('No arguments provided')\\n        return\\n    \\n    result = format_output(args[0])\\n    print(result)\\n\\nif __name__ == '__main__':\\n    main()\",\n              \"type\": \"target\",\n              \"docstring\": \"\"\n            },\n            \"referenced_files\": [\n              {\n                \"file_path\": \"utils/helpers.py\",\n                \"object_name\": \"format_output\",\n                \"object_type\": \"function\",\n                \"code\": \"def format_output(text):\\n    \\\"\\\"\\\"Format the input text for display.\\\"\\\"\\\"\\n    if not text:\\n        return ''\\n    return f'Output: {text.upper()}'\\n\",\n                \"docstring\": \"Format the input text for display.\",\n                \"truncated\": false\n              }\n            ],\n            \"additional_files\": [\n              {\n                \"file_path\": \"config.py\",\n                \"code\": \"# Configuration settings\\n\\nDEBUG = True\\nVERSION = '1.0.0'\\nMAX_RETRIES = 3\\n\",\n                \"type\": \"related_by_directory\",\n                \"docstring\": \"Configuration settings for the application.\"\n              }\n            ],\n            \"total_files\": 3,\n            \"token_count\": 450,\n            \"token_limit\": 8000\n          }\n        }\n      }\n    ],\n    \"isError\": false\n  }\n}\n```\n\n### Handling Errors\n\n```python\nfrom agent import handle_mcp_request\n\n# Call with invalid file path\nfaulty_request = {\n    \"jsonrpc\": \"2.0\",\n    \"id\": 3,\n    \"method\": \"tools/call\",\n    \"params\": {\n        \"name\": \"get_python_code\",\n        \"arguments\": {\n            \"target_file\": \"/path/to/nonexistent.py\"\n        }\n    }\n}\n\nresponse = handle_mcp_request(faulty_request)\nprint(json.dumps(response, indent=2))\n```\n\n#### Example Error Response\n\n```json\n{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 3,\n  \"result\": {\n    \"content\": [\n      {\n        \"type\": \"text\",\n        \"text\": \"Error processing Python code: No such file or directory: '/path/to/nonexistent.py'\"\n      }\n    ],\n    \"isError\": true\n  }\n}\n```\n\n## Testing\n\nRun the tests to verify functionality:\n\n```bash\npython -m unittest discover tests\n```\n\n## Key Components\n\n- **agent.py**: Contains the `get_python_code` function and custom MCP protocol handlers\n- **code_grapher.py**: Implements the `CodeGrapher` class for Python code analysis\n- **server.py**: Full MCP server implementation using the MCP Python SDK\n- **run_server.py**: CLI tool for running the MCP server\n- **examples/**: Example scripts showing how to use the MCP server and client\n- **tests/**: Comprehensive test cases for all functionality\n\n## Response Format Details\n\nThe `get_python_code` tool returns a structured JSON object with the following fields:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `target_file` | Object | Information about the target Python file |\n| `referenced_files` | Array | List of objects imported by the target file |\n| `additional_files` | Array | Additional context files from the same directory |\n| `total_files` | Number | Total number of files included in the response |\n| `token_count` | Number | Approximate count of tokens in all included code |\n| `token_limit` | Number | Maximum token limit configured for extraction |\n\n### Target File Object\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `file_path` | String | Relative path to the file from the repository root |\n| `code` | String | Complete source code of the file |\n| `type` | String | Always \"target\" |\n| `docstring` | String | Module-level docstring if available |\n\n### Referenced File Object\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `file_path` | String | Relative path to the file |\n| `object_name` | String | Name of the imported object (class, function, etc.) |\n| `object_type` | String | Type of the object (\"class\", \"function\", etc.) |\n| `code` | String | Source code of the specific object |\n| `docstring` | String | Docstring of the object if available |\n| `truncated` | Boolean | Whether the code was truncated due to token limits |\n\n### Additional File Object\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `file_path` | String | Relative path to the file |\n| `code` | String | Complete source code of the file |\n| `type` | String | Type of relation (e.g., \"related_by_directory\") |\n| `docstring` | String | Module-level docstring if available |\n\n## Using the MCP SDK Server\n\nThis project now includes a full-featured Model Context Protocol (MCP) server built with the official [Python MCP SDK](https://github.com/modelcontextprotocol/python-sdk). The server exposes our code extraction functionality in a standardized way that can be used with any MCP client, including Claude Desktop.\n\n### Starting the Server\n\n```bash\n# Start the server with default settings\npython run_server.py\n\n# Specify a custom name\npython run_server.py --name \"My Code Explorer\"\n\n# Use a specific .env file\npython run_server.py --env-file .env.production\n```\n\n### Using the MCP Development Mode\n\nWith the MCP SDK installed, you can run the server in development mode using the MCP CLI:\n\n```bash\n# Install the MCP CLI\npip install \"mcp[cli]\"\n\n# Start the server in development mode with the Inspector UI\nmcp dev server.py\n```\n\nThis will start the MCP Inspector, a web interface for testing and debugging your server.\n\n### Claude Desktop Integration\n\nYou can install the server into Claude Desktop to access your code exploration tools directly from Claude:\n\n```bash\n# Install the server in Claude Desktop\nmcp install server.py\n\n# With custom configuration\nmcp install server.py --name \"Python Code Explorer\" -f .env\n```\n\n### Custom Server Deployment\n\nFor custom deployments, you can use the MCP server directly:\n\n```python\nfrom server import mcp\n\n# Configure the server\nmcp.name = \"Custom Code Explorer\"\n\n# Run the server\nmcp.run()\n```\n\n### Using the MCP Client\n\nYou can use the MCP Python SDK to connect to the server programmatically. See the provided example in `examples/mcp_client_example.py`:\n\n```python\nfrom mcp.client import Client, Transport\n\n# Connect to the server\nclient = Client(Transport.subprocess([\"python\", \"server.py\"]))\nclient.initialize()\n\n# List available tools\nfor tool in client.tools:\n    print(f\"Tool: {tool.name}\")\n\n# Use the get_code tool\nresult = client.tools.get_code(target_file=\"path/to/your/file.py\")\nprint(f\"Found {len(result['referenced_files'])} referenced files\")\n\n# Clean up\nclient.shutdown()\n```\n\nRun the example:\n\n```bash\npython examples/mcp_client_example.py [optional_target_file.py]\n```\n\n### Adding Additional Tools\n\nYou can add additional tools to the MCP server by decorating functions with the `@mcp.tool()` decorator in `server.py`:\n\n```python\n@mcp.tool()\ndef analyze_imports(target_file: str) -> Dict[str, Any]:\n    \"\"\"Analyze all imports in a Python file.\"\"\"\n    # Implementation code here\n    return {\n        \"file\": target_file,\n        \"imports\": [],  # List of imports found\n        \"analysis\": \"\"  # Analysis of the imports\n    }\n    \n@mcp.tool()\ndef find_python_files(directory: str, pattern: str = \"*.py\") -> list[str]:\n    \"\"\"Find Python files matching a pattern in a directory.\"\"\"\n    from pathlib import Path\n    return [str(p) for p in Path(directory).glob(pattern) if p.is_file()]\n```\n\nYou can also add resource endpoints to provide data directly:\n\n```python\n@mcp.resource(\"python_stats://{directory}\")\ndef get_stats(directory: str) -> Dict[str, Any]:\n    \"\"\"Get statistics about Python files in a directory.\"\"\"\n    from pathlib import Path\n    stats = {\n        \"directory\": directory,\n        \"file_count\": 0,\n        \"total_lines\": 0,\n        \"average_lines\": 0\n    }\n    \n    files = list(Path(directory).glob(\"**/*.py\"))\n    stats[\"file_count\"] = len(files)\n    \n    if files:\n        total_lines = 0\n        for file in files:\n            with open(file, \"r\") as f:\n                total_lines += len(f.readlines())\n        stats[\"total_lines\"] = total_lines\n        stats[\"average_lines\"] = total_lines / len(files)\n    \n    return stats\n```\n\n## Model Context Protocol Integration\n\nThis project fully embraces the Model Context Protocol (MCP) standard, providing two implementation options:\n\n1. **Native MCP Integration**: The original implementation in `agent.py` provides a direct JSON-RPC interface compatible with MCP.\n\n2. **MCP SDK Integration**: The new implementation in `server.py` leverages the official MCP Python SDK for a more robust and feature-rich experience.\n\n### Benefits of MCP Integration\n\n- **Standardized Interface**: Makes your tools available to any MCP-compatible client\n- **Enhanced Security**: Built-in permissions model and resource controls\n- **Better LLM Integration**: Seamless integration with Claude Desktop and other LLM platforms\n- **Improved Developer Experience**: Comprehensive tooling like the MCP Inspector\n\n### MCP Protocol Version\n\nThis implementation supports MCP Protocol version 0.7.0.\n\nFor more information about MCP, refer to the [official documentation](https://modelcontextprotocol.io).\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "python",
        "documentation",
        "import",
        "extract python",
        "au python",
        "python mcp"
      ],
      "category": "document-processing"
    },
    "highlight-ing--highlight-youtube-mcp": {
      "owner": "highlight-ing",
      "name": "highlight-youtube-mcp",
      "url": "https://github.com/highlight-ing/highlight-youtube-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/highlight-ing.webp",
      "description": "Extract transcripts from YouTube videos by providing a video URL. The server supports multiple URL formats and returns the transcript text in a structured array format.",
      "stars": 1,
      "forks": 3,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-03-10T02:12:46Z",
      "readme_content": "# YouTube Integration\n\nThe YouTube MCP server provides functionality to extract transcripts from YouTube videos.\n\n## Available Tools\n\n### get_youtube_transcript\nRetrieves the transcript text from a YouTube video.\n\n**Parameters**:\n- `videoUrl`: Full YouTube video URL (supports standard, shortened, and embed URLs)\n\n**Returns**: Object containing:\n- `content`: Array with transcript text\n\n## URL Support\n\nHandles multiple YouTube URL formats:\n- Standard: `https://www.youtube.com/watch?v=VIDEO_ID`\n- Shortened: `https://youtu.be/VIDEO_ID`\n- Embed: `https://www.youtube.com/embed/VIDEO_ID`\n\n## Error Handling\n\nThe server implements standard error handling:\n- Invalid URLs return `ErrorCode.InvalidParams`\n- Missing URL returns `ErrorCode.InvalidParams`\n- Failed transcript fetches return formatted error messages\n- Graceful shutdown on SIGINT\n\n## Technical Details\n\n- Built using the Highlight AI MCP SDK\n- Uses youtube-transcript library\n- Input validation via Zod\n- Runs as a stdio-based MCP server\n- Supports Node.js >=18.0.0\n\n## Limitations\n\n- Only works with videos that have captions enabled\n- Currently only returns English transcripts\n- Rate limits depend on YouTube's API restrictions\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "transcript",
        "transcripts",
        "youtube",
        "transcripts youtube",
        "youtube mcp",
        "highlight youtube"
      ],
      "category": "document-processing"
    },
    "hoonoh57--Append-Data-to-JSON-File-and-Display-JSON-data-to-HTML-Table-using-Ajax-Jquery-getJSON-method": {
      "owner": "hoonoh57",
      "name": "Append-Data-to-JSON-File-and-Display-JSON-data-to-HTML-Table-using-Ajax-Jquery-getJSON-method",
      "url": "https://github.com/hoonoh57/Append-Data-to-JSON-File-and-Display-JSON-data-to-HTML-Table-using-Ajax-Jquery-getJSON-method",
      "imageUrl": "/freedevtools/mcp/pfp/hoonoh57.webp",
      "description": "Append data to a JSON file and display it in an HTML table using Ajax and jQuery's getJSON method. This enables dynamic data loading for web applications, enhancing data management and user experience.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "PHP",
      "updated_at": "2018-02-25T23:56:53Z",
      "readme_content": "# Append-Data-to-JSON-File-and-Display-JSON-data-to-HTML-Table-using-Ajax-Jquery-getJSON-method\n### Final Result\n#### So this is gonna be final result but if you just want to display data from json there's sceeenshot down below.\n<img width=\"660\" alt=\"scmain\" src=\"https://user-images.githubusercontent.com/20491036/35260097-6e48efde-0059-11e8-9c04-7f2f815f0fd0.png\">\n\n### This is just data view, this is how its gonna look and load data like that bellow\n<img width=\"524\" alt=\"dataview\" src=\"https://user-images.githubusercontent.com/20491036/35260195-078e19da-005a-11e8-9bef-d3ac0de170f8.png\">\n\n\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "json",
        "ajax",
        "getjson",
        "json file",
        "data json",
        "json data"
      ],
      "category": "document-processing"
    },
    "hyperspell--hyperspell-mcp": {
      "owner": "hyperspell",
      "name": "hyperspell-mcp",
      "url": "https://github.com/hyperspell/hyperspell-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/hyperspell.webp",
      "description": "Integrate real-time spell checking and correction capabilities into applications to enhance text accuracy and clarity. Offers seamless integration with existing workflows for instant feedback on spelling errors.",
      "stars": 1,
      "forks": 2,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-04-28T21:18:08Z",
      "readme_content": "## Configuration\n\n- `HYPERSPELL_TOKEN` should be a valid user or app token (refer to the [Hyperspell docs](https://docs.hyperspell.com/) for how to obtain a user token).\n- Some MCP clients don't support resources well (looking at you, Claude Desktop), so we can expose them as tools instead. Set `HYPERSPELL_USE_RESOURCES` to `false` (default) to expose everything as tools, `true` to expose retrieveing single documents or listing collections as resources instead, or `both` if you want it all.\n- Optionally, set `HYPERSPELL_COLLECTION` to the name of the collection you want to query and add data to. If not set, it will use the user's default collection instead.\n\n\n## Claude Desktop\n\nNote that Claude needs the absolute path to `uv`, which can be found with `which uv` (it's usually `~/.local/bin/uv`). \n\n```json\n{\n  \"mcpServers\": {\n    \"Hyperspell\": {\n      \"command\": \"/path/to/uv\",\n      \"args\": [\n        \"run\",\n        \"--with\",\n        \"hyperspell\",\n        \"--with\",\n        \"mcp[cli]\",\n        \"mcp\",\n        \"run\",\n        \"/path/to/hyperspell_mcp/server.py\"\n      ],\n      \"env\": {\n        \"HYPERSPELL_TOKEN\": \"<app or user token>\",\n        \"USE_RESOURCES\": \"false\"\n      }\n    }\n  }\n}\n```\n\n## Using the inspector\n\nCreate a `.env` file with the following contents:\n\n```\nHYPERSPELL_TOKEN=...\nHYPERSPELL_USE_RESOURCES=true\n```\n\nThen run this to start the inspector:\n\n```\nuv run mcp dev src/hyperspell_mcp/server.py\n```",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "hyperspell",
        "spell",
        "spelling",
        "spell checking",
        "processing hyperspell",
        "hyperspell mcp"
      ],
      "category": "document-processing"
    },
    "i-tozer--excalidraw-mcp": {
      "owner": "i-tozer",
      "name": "excalidraw-mcp",
      "url": "https://github.com/i-tozer/excalidraw-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/i-tozer.webp",
      "description": "Manage Excalidraw drawings using a straightforward API, providing capabilities to create, update, retrieve, and delete drawings. Export drawings in multiple formats such as SVG, PNG, and JSON while utilizing a simple file-based storage system.",
      "stars": 32,
      "forks": 15,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-09-28T16:12:34Z",
      "readme_content": "# Excalidraw MCP Server\n\nThis is a Model Context Protocol (MCP) server for Excalidraw, providing API functionality for operating on Excalidraw drawings.\n\n## Features\n\n- Create, read, update, and delete Excalidraw drawings\n- Export drawings to SVG, PNG, and JSON formats\n- Simple file-based storage system\n\n## Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/yourusername/excalidraw-mcp.git\ncd excalidraw-mcp\n\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n```\n\n## Usage\n\n### Starting the Server\n\n```bash\nnpm start\n```\n\n### API Endpoints\n\nThe server provides the following tools:\n\n#### Drawing Management\n\n- `create_drawing`: Create a new Excalidraw drawing\n- `get_drawing`: Get an Excalidraw drawing by ID\n- `update_drawing`: Update an Excalidraw drawing by ID\n- `delete_drawing`: Delete an Excalidraw drawing by ID\n- `list_drawings`: List all Excalidraw drawings\n\n#### Export Operations\n\n- `export_to_svg`: Export an Excalidraw drawing to SVG\n- `export_to_png`: Export an Excalidraw drawing to PNG\n- `export_to_json`: Export an Excalidraw drawing to JSON\n\n## Development\n\n### Project Structure\n\n```\nexcalidraw-mcp/\n├── src/\n│   ├── common/\n│   │   └── errors.ts\n│   └── operations/\n│       ├── drawings.ts\n│       └── export.ts\n├── index.ts\n├── package.json\n├── tsconfig.json\n└── README.md\n```\n\n### Building\n\n```bash\nnpm run build\n```\n\n### Running in Development Mode\n\n```bash\nnpm run dev\n```\n\n## License\n\nMIT ",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "excalidraw",
        "drawings",
        "formats",
        "excalidraw drawings",
        "tozer excalidraw",
        "manage excalidraw"
      ],
      "category": "document-processing"
    },
    "ifmelate--mcp-image-extractor": {
      "owner": "ifmelate",
      "name": "mcp-image-extractor",
      "url": "https://github.com/ifmelate/mcp-image-extractor",
      "imageUrl": "/freedevtools/mcp/pfp/ifmelate.webp",
      "description": "Extracts images from local files and URLs, processing them into base64 format for analysis by large language models (LLMs). Suitable for analyzing image-based data, such as screenshots from tests.",
      "stars": 14,
      "forks": 4,
      "license": "MIT License",
      "language": "HTML",
      "updated_at": "2025-09-21T00:31:03Z",
      "readme_content": "# MCP Image Extractor\n\nMCP server for extracting and converting images to base64 for LLM analysis.\n\nThis MCP server provides tools for AI assistants to:\n- Extract images from local files\n- Extract images from URLs\n- Process base64-encoded images\n\n<a href=\"https://glama.ai/mcp/servers/@ifmelate/mcp-image-extractor\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@ifmelate/mcp-image-extractor/badge\" alt=\"Image Extractor MCP server\" />\n</a>\n\nHow it looks in Cursor:\n\n<img width=\"687\" alt=\"image\" src=\"https://github.com/user-attachments/assets/8954dbbd-7e7a-4f27-82a7-b251bd3c5af2\" />\n\nSuitable cases:\n- analyze playwright test results: screenshots\n\n## Installation\n\n### Recommended: Using npx in mcp.json (Easiest)\n\nThe recommended way to install this MCP server is using npx directly in your `.cursor/mcp.json` file:\n\n```json\n{\n  \"mcpServers\": {\n    \"image-extractor\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"mcp-image-extractor\"\n      ]\n    }\n  }\n}\n```\n\nThis approach:\n- Automatically installs the latest version\n- Does not require global installation\n- Works reliably across different environments\n\n### Alternative: Local Path Installation\n\nIf you prefer to use a local installation of the package, you can clone the repository and point to the built files:\n\n```json\n{\n  \"mcpServers\": {\n    \"image-extractor\": {\n      \"command\": \"node\",\n      \"args\": [\"/full/path/to/mcp-image-extractor/dist/index.js\"],\n      \"disabled\": false\n    }\n  }\n}\n```\n\n### Manual Installation\n\n```bash\n# Clone and install \ngit clone https://github.com/ifmelate/mcp-image-extractor.git\ncd mcp-image-extractor\nnpm install\nnpm run build\nnpm link\n```\n\nThis will make the `mcp-image-extractor` command available globally.\n\nThen configure in `.cursor/mcp.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"image-extractor\": {\n      \"command\": \"mcp-image-extractor\",\n      \"disabled\": false\n    }\n  }\n}\n```\n\n> **Troubleshooting for Cursor Users**: If you see \"Failed to create client\" error, try the local path installation method above or ensure you're using the correct path to the executable.\n\n## Available Tools\n\n### extract_image_from_file\n\nExtracts an image from a local file and converts it to base64.\n\nParameters:\n- `file_path` (required): Path to the local image file\n\n**Note:** All images are automatically resized to optimal dimensions (max 512x512) for LLM analysis to limit the size of the base64 output and optimize context window usage.\n\n### extract_image_from_url\n\nExtracts an image from a URL and converts it to base64.\n\nParameters:\n- `url` (required): URL of the image to extract\n\n**Note:** All images are automatically resized to optimal dimensions (max 512x512) for LLM analysis to limit the size of the base64 output and optimize context window usage.\n\n### extract_image_from_base64\n\nProcesses a base64-encoded image for LLM analysis.\n\nParameters:\n- `base64` (required): Base64-encoded image data\n- `mime_type` (optional, default: \"image/png\"): MIME type of the image\n\n**Note:** All images are automatically resized to optimal dimensions (max 512x512) for LLM analysis to limit the size of the base64 output and optimize context window usage.\n\n## Example Usage\n\nHere's an example of how to use the tools from Claude:\n\n```\nPlease extract the image from this local file: images/photo.jpg\n```\n\nClaude will automatically use the `extract_image_from_file` tool to load and analyze the image content.\n\n```\nPlease extract the image from this URL: https://example.com/image.jpg\n```\n\nClaude will automatically use the `extract_image_from_url` tool to fetch and analyze the image content.\n\n## Docker\n\nBuild and run with Docker:\n\n```bash\ndocker build -t mcp-image-extractor .\ndocker run -p 8000:8000 mcp-image-extractor\n```\n\n## License\n\nMIT",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "base64",
        "images",
        "extractor",
        "extracts images",
        "image extractor",
        "mcp image"
      ],
      "category": "document-processing"
    },
    "inkdropapp--mcp-server": {
      "owner": "inkdropapp",
      "name": "mcp-server",
      "url": "https://github.com/inkdropapp/mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/inkdropapp.webp",
      "description": "Retrieve, create, and manage notes with a local HTTP server for efficient note handling in Inkdrop. Access and organize notebooks through a standardized model context protocol.",
      "stars": 40,
      "forks": 8,
      "license": "Apache License 2.0",
      "language": "JavaScript",
      "updated_at": "2025-10-03T23:38:29Z",
      "readme_content": "## Inkdrop MCP Server\n\nA [Model Context Protocol](https://github.com/modelcontextprotocol) server for the [Inkdrop Local HTTP Server API](https://developers.inkdrop.app/data-access/local-http-server).\n\n<a href=\"https://glama.ai/mcp/servers/c7fgtnckbv\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/c7fgtnckbv/badge\" alt=\"Inkdrop Server MCP server\" />\n</a>\n\n## Installation\n\n1. [Set up a local HTTP server](https://developers.inkdrop.app/guides/integrate-with-external-programs)\n\n2. Add server config to Claude Desktop:\n   - MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"inkdrop\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@inkdropapp/mcp-server\"],\n      \"env\": {\n        \"INKDROP_LOCAL_SERVER_URL\": \"http://localhost:19840\",\n        \"INKDROP_LOCAL_USERNAME\": \"your-local-server-username\",\n        \"INKDROP_LOCAL_PASSWORD\": \"your-local-server-password\"\n      }\n    }\n  }\n}\n```\n\n## Components\n\n### Tools\n\n1. **`read-note`**: Retrieve the complete contents of the note by its ID from the database.\n   - Required inputs:\n     - `noteId`: The ID of the note to retrieve. It can be found as `_id` in the note docs. It always starts with `note:`.\n2. **`search-notes`**: List all notes that contain a given keyword.\n   - Required inputs:\n     - `keyword`: Keyword to search for.\n   - Note: Results include truncated note bodies (200 characters). Use `read-note` to get full content.\n   - Supports advanced search qualifiers like `book:`, `tag:`, `status:`, `title:`, etc.\n3. **`list-notes`**: List all notes with specified conditions.\n   - Required inputs:\n     - `bookId`: The notebook ID. It always starts with 'book:'.\n   - Optional inputs:\n     - `tagIds`: An array of tag IDs to filter. Each starts with 'tag:'.\n     - `keyword`: Keyword to filter notes.\n     - `sort`: Sort field (`updatedAt`, `createdAt`, or `title`). Default: `updatedAt`.\n     - `descending`: Reverse the order of output. Default: `true`.\n   - Note: Results include truncated note bodies (200 characters). Use `read-note` to get full content.\n4. **`create-note`**: Create a new note in the database.\n   - Required inputs:\n     - `bookId`: The notebook ID. Must start with 'book:' or be 'trash'.\n     - `title`: The note title.\n     - `body`: The content of the note in Markdown.\n   - Optional inputs:\n     - `status`: The note status (`none`, `active`, `onHold`, `completed`, `dropped`).\n     - `tags`: An array of tag IDs to assign to the note. Each must start with 'tag:'.\n5. **`update-note`**: Update an existing note in the database.\n   - Required inputs:\n     - `_id`: The note ID. Must start with 'note:'.\n     - `_rev`: The revision ID (CouchDB MVCC-token).\n     - `bookId`: The notebook ID. Must start with 'book:' or be 'trash'.\n     - `title`: The note title.\n     - `body`: The content of the note in Markdown.\n   - Optional inputs:\n     - `status`: The note status (`none`, `active`, `onHold`, `completed`, `dropped`).\n     - `tags`: An array of tag IDs to assign to the note. Each must start with 'tag:'.\n6. **`list-notebooks`**: Retrieve a list of all notebooks.\n7. **`read-book`**: Retrieve a single notebook by its ID.\n   - Required inputs:\n     - `bookId`: The notebook ID. Must start with 'book:'.\n8. **`list-tags`**: Retrieve a list of all tags.\n9. **`read-tag`**: Retrieve a single tag by its ID.\n   - Required inputs:\n     - `tagId`: The tag ID. Must start with 'tag:'.\n10. **`create-tag`**: Create a new tag in the database.\n    - Required inputs:\n      - `name`: The name of the tag.\n    - Optional inputs:\n      - `color`: The color type of the tag (`default`, `red`, `orange`, `yellow`, `olive`, `green`, `teal`, `blue`, `violet`, `purple`, `pink`, `brown`, `grey`, `black`). Default: `default`.\n11. **`update-tag`**: Update an existing tag in the database.\n    - Required inputs:\n      - `_id`: The tag ID. Must start with 'tag:'.\n      - `_rev`: The revision ID (CouchDB MVCC-token).\n      - `name`: The name of the tag.\n    - Optional inputs:\n      - `color`: The color type of the tag. Default: `default`.\n\n## Debugging\n\nSince MCP servers run over stdio, debugging can be challenging. For the best debugging\nexperience, we strongly recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector).\n\nYou can launch the MCP Inspector via [`npm`](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm) with this command:\n\n```bash\nnpx @modelcontextprotocol/inspector \"./dist/index.js\"\n```\n\nBe sure that environment variables are properly configured.\n\nUpon launching, the Inspector will display a URL that you can access in your browser to begin debugging.\n\nYou can also watch the server logs with this command:\n\n```bash\ntail -n 20 -f ~/Library/Logs/Claude/mcp-server-inkdrop.log\n```\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "inkdropapp",
        "inkdrop",
        "notes",
        "inkdropapp mcp",
        "processing inkdropapp",
        "inkdrop access"
      ],
      "category": "document-processing"
    },
    "inkeep--mcp-server-python": {
      "owner": "inkeep",
      "name": "mcp-server-python",
      "url": "https://github.com/inkeep/mcp-server-python",
      "imageUrl": "/freedevtools/mcp/pfp/inkeep.webp",
      "description": "Integrates documentation with a powerful API for efficient management and access. Facilitates the development of intelligent applications that seamlessly interact with documentation.",
      "stars": 22,
      "forks": 9,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-21T10:25:02Z",
      "readme_content": "# mcp-server-python\nInkeep MCP Server powered by your docs and product content.\n\n### Dependencies\n\n- An account on [Inkeep](https://inkeep.com) to manage and provide the RAG\n- [`uv`](https://github.com/astral-sh/uv) Python project manager\n\n### Local Setup\n\n```\ngit clone https://github.com/inkeep/mcp-server-python.git\ncd mcp-server-python\nuv venv\nuv pip install -r pyproject.toml\n```\n\nNote the full path of the project, referred to as `<YOUR_INKEEP_MCP_SERVER_ABSOLUTE_PATH>` in a later step.\n\n## Get an API key\n\n1. Log in to the [Inkeep Dashboard](https://portal.inkeep.com)\n2. Navigate to the **Projects** section and select your project\n3. Open the **Integrations** tab\n4. Click **Create Integration** and choose **API** from the options\n5. Enter a Name for your new API integration.\n6. Click on **Create**\n7. A generated **API key** will appear that you can use to authenticate API requests.\n\nWe'll refer to this API key as the `<YOUR_INKEEP_API_KEY>` in later steps.\n\n### Add to your MCP client\n\nFollow the steps in [this](https://modelcontextprotocol.io/quickstart/user) guide to setup Claude Dekstop.\n\nIn your `claude_desktop_config.json` file, add the following entry to `mcpServers`.\n\n```json claude_desktop_config.json\n{\n    \"mcpServers\": {\n        \"inkeep-mcp-server\": {\n            \"command\": \"uv\",\n            \"args\": [\n                \"--directory\",\n                \"<YOUR_INKEEP_MCP_SERVER_ABSOLUTE_PATH>\",\n                \"run\",\n                \"-m\",\n                \"inkeep_mcp_server\"\n            ],\n            \"env\": {\n                \"INKEEP_API_BASE_URL\": \"https://api.inkeep.com/v1\",\n                \"INKEEP_API_KEY\": \"<YOUR_INKEEP_API_KEY>\",\n                \"INKEEP_API_MODEL\": \"inkeep-rag\",\n                \"INKEEP_MCP_TOOL_NAME\": \"search-product-content\",\n                \"INKEEP_MCP_TOOL_DESCRIPTION\": \"Retrieves product documentation about Inkeep. The query should be framed as a conversational question about Inkeep.\"\n            }\n        },\n    }\n}\n```\n\nYou may need to put the full path to the `uv` executable in the command field. You can get this by running `which uv` on MacOS/Linux or `where uv` on Windows.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "documentation",
        "document",
        "python",
        "documentation powerful",
        "document processing",
        "interact documentation"
      ],
      "category": "document-processing"
    },
    "intsig-textin--textin-mcp": {
      "owner": "intsig-textin",
      "name": "textin-mcp",
      "url": "https://github.com/intsig-textin/textin-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/intsig-textin.webp",
      "description": "Extract text from images, PDFs, and Word documents while performing OCR and document conversion tasks. Convert documents to Markdown format, and retrieve key information from files intelligently.",
      "stars": 23,
      "forks": 4,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-08-25T07:37:52Z",
      "readme_content": "# TextIn OCR MCP\n<p align=\"center\">\n<img align=\"center\" src=\"https://ccidownload.blob.core.chinacloudapi.cn/download/2025/LLMS/logo.png\" width=\"800\" alt=\"TextIn\">\n</p>\n\nEnglish | [中文](./README_CHS.md)\n\n## TextIn OCR MCP Server\n\nTextIn MCP Server is a tool for extracting text and performing OCR on documents, including document text recognition, ID recognition, and invoice recognition. It also supports converting documents into Markdown format.\n\n<!-- <a href=\"https://glama.ai/mcp/servers/@intsig-textin/textin-mcp\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@intsig-textin/textin-mcp/badge\" alt=\"Textin Server MCP server\" />\n</a> -->\n\n### Tools\n- `recognition_text`\n  - Text recognition from images, Word documents, and PDF files.\n  - Inputs:\n    - `path` (string, required): `file path` or `a URL (HTTP/HTTPS) pointing to a document`\n  - Return: Text of the document.\n  - Supports conversion for:\n    - PDF\n    - Image (Jpeg, Jpg, Png, Bmp)\n\n- `doc_to_markdown`\n  - Convert images, PDFs, and Word documents to Markdown.\n  - Inputs:\n    - `path` (string, required): `file path` or `a URL (HTTP/HTTPS) pointing to a document`\n  - Return: Markdown of the document.\n  - Supports conversion for:\n    - PDF\n    - Microsoft Office Documents (Word, Excel)\n    - Image (Jpeg, Jpg, Png, Bmp)\n\n- `general_information_extration`\n  - Automatically identify and extract information from documents, or identify and extract user-specified information.\n  - Inputs:\n    - `path` (string, required): `file path` or `a URL (HTTP/HTTPS) pointing to a document`\n    - `key` (string[], optional): The non-tabular text information that the user wants to identify, input format is an array of strings.\n    - `table_header` (string[], optional): The table information that the user wants to identify, input format is an array of strings.\n  - Return: The key information JSON.\n  - Supports conversion for:\n    - PDF\n    - Microsoft Office Documents (Word, Excel)\n    - Image (Jpeg, Jpg, Png, Bmp)\n\nWhen the input is a URL, it does not support handling access to protected resources.\n\n## Setup\n\n### APP_ID and APP_SECRET\n\nClick [here](https://www.textin.com/user/login?from=github_mcp) to register for a TextIn account.\n\nGet Textin APP_ID and APP_SECRET by following the instructions [here](https://www.textin.com/doc/guide/account/%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96app%20id?status=first).\n\n### NPX\n\n```json\n{\n  \"mcpServers\": {\n    \"textin-ocr\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@intsig/server-textin\"\n      ],\n      \"env\": {\n        \"APP_ID\": \"<YOUR_APP_ID>\",\n        \"APP_SECRET\": \"<YOUR_APP_SECRET>\",\n        \"MCP_SERVER_REQUEST_TIMEOUT\": \"600000\"\n      },\n      \"timeout\": 600\n    }\n  }\n}\n```\n\n## License\n\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ocr",
        "textin",
        "markdown",
        "document processing",
        "ocr document",
        "document conversion"
      ],
      "category": "document-processing"
    },
    "isaacphi--mcp-gdrive": {
      "owner": "isaacphi",
      "name": "mcp-gdrive",
      "url": "https://github.com/isaacphi/mcp-gdrive",
      "imageUrl": "/freedevtools/mcp/pfp/isaacphi.webp",
      "description": "Integrates with Google Drive for listing, reading, and searching files, and facilitates reading and writing to Google Sheets. Provides access to Google Drive content and spreadsheet data for various applications.",
      "stars": 209,
      "forks": 73,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T22:32:01Z",
      "readme_content": "# Google Drive server\n\nThis MCP server integrates with Google Drive to allow listing, reading, and searching files, as well as the ability to read and write to Google Sheets.\n\nThis project includes code originally developed by Anthropic, PBC, licensed under the MIT License from [this repo](https://github.com/modelcontextprotocol/servers/tree/main/src/gdrive).\n\n## Components\n\n### Tools\n\n- **gdrive_search**\n\n  - **Description**: Search for files in Google Drive.\n  - **Input**:\n    - `query` (string): Search query.\n    - `pageToken` (string, optional): Token for the next page of results.\n    - `pageSize` (number, optional): Number of results per page (max 100).\n  - **Output**: Returns file names and MIME types of matching files.\n\n- **gdrive_read_file**\n\n  - **Description**: Read contents of a file from Google Drive.\n  - **Input**:\n    - `fileId` (string): ID of the file to read.\n  - **Output**: Returns the contents of the specified file.\n\n- **gsheets_read**\n\n  - **Description**: Read data from a Google Spreadsheet with flexible options for ranges and formatting.\n  - **Input**:\n    - `spreadsheetId` (string): The ID of the spreadsheet to read.\n    - `ranges` (array of strings, optional): Optional array of A1 notation ranges (e.g., `['Sheet1!A1:B10']`). If not provided, reads the entire sheet.\n    - `sheetId` (number, optional): Specific sheet ID to read. If not provided with ranges, reads the first sheet.\n  - **Output**: Returns the specified data from the spreadsheet.\n\n- **gsheets_update_cell**\n  - **Description**: Update a cell value in a Google Spreadsheet.\n  - **Input**:\n    - `fileId` (string): ID of the spreadsheet.\n    - `range` (string): Cell range in A1 notation (e.g., `'Sheet1!A1'`).\n    - `value` (string): New cell value.\n  - **Output**: Confirms the updated value in the specified cell.\n\n### Resources\n\nThe server provides access to Google Drive files:\n\n- **Files** (`gdrive:///<file_id>`)\n  - Supports all file types\n  - Google Workspace files are automatically exported:\n    - Docs → Markdown\n    - Sheets → CSV\n    - Presentations → Plain text\n    - Drawings → PNG\n  - Other files are provided in their native format\n\n## Getting started\n\n1. [Create a new Google Cloud project](https://console.cloud.google.com/projectcreate)\n2. [Enable the Google Drive API](https://console.cloud.google.com/workspace-api/products)\n3. [Configure an OAuth consent screen](https://console.cloud.google.com/apis/credentials/consent) (\"internal\" is fine for testing)\n4. Add OAuth scopes `https://www.googleapis.com/auth/drive.readonly`, `https://www.googleapis.com/auth/spreadsheets`\n5. In order to allow interaction with sheets and docs you will also need to enable the [Google Sheets API](https://console.cloud.google.com/apis/api/sheets.googleapis.com/) and [Google Docs API](https://console.cloud.google.com/marketplace/product/google/docs.googleapis.com) in your workspaces Enabled API and Services section.\n6. [Create an OAuth Client ID](https://console.cloud.google.com/apis/credentials/oauthclient) for application type \"Desktop App\"\n7. Download the JSON file of your client's OAuth keys\n8. Rename the key file to `gcp-oauth.keys.json` and place into the path you specify with `GDRIVE_CREDS_DIR` (i.e. `/Users/username/.config/mcp-gdrive`)\n9. Note your OAuth Client ID and Client Secret. They must be provided as environment variables along with your configuration directory.\n10. You will also need to setup a .env file within the project with the following fields. You can find the Client ID and Client Secret in the Credentials section of the Google Cloud Console.\n\n```\nGDRIVE_CREDS_DIR=/path/to/config/directory\nCLIENT_ID=<CLIENT_ID>\nCLIENT_SECRET=<CLIENT_SECRET>\n```\n\nMake sure to build the server with either `npm run build` or `npm run watch`.\n\n### Authentication\n\nNext you will need to run `node ./dist/index.js` to trigger the authentication step\n\nYou will be prompted to authenticate with your browser. You must authenticate with an account in the same organization as your Google Cloud project.\n\nYour OAuth token is saved in the directory specified by the `GDRIVE_CREDS_DIR` environment variable.\n\n![Authentication Prompt](https://i.imgur.com/TbyV6Yq.png)\n\n### Usage with Desktop App\n\nTo integrate this server with the desktop app, add the following to your app's server configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"gdrive\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@isaacphi/mcp-gdrive\"],\n      \"env\": {\n        \"CLIENT_ID\": \"<CLIENT_ID>\",\n        \"CLIENT_SECRET\": \"<CLIENT_SECRET>\",\n        \"GDRIVE_CREDS_DIR\": \"/path/to/config/directory\"\n      }\n    }\n  }\n}\n```\n\n## License\n\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "gdrive",
        "document",
        "mcp",
        "mcp gdrive",
        "gdrive integrates",
        "google drive"
      ],
      "category": "document-processing"
    },
    "islem-zaraa--mcp-powerpoint": {
      "owner": "islem-zaraa",
      "name": "mcp-powerpoint",
      "url": "https://github.com/islem-zaraa/mcp-powerpoint",
      "imageUrl": "/freedevtools/mcp/pfp/islem-zaraa.webp",
      "description": "Create and manipulate PowerPoint presentations programmatically, enabling the generation of slides, exporting to PDF, and retrieving metadata seamlessly.",
      "stars": 4,
      "forks": 1,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-04-14T18:18:49Z",
      "readme_content": "# MCP PowerPoint Plugin\n\nA Model Context Protocol (MCP) plugin for PowerPoint operations, allowing AI assistants to create and manipulate PowerPoint presentations programmatically.\n\n## Features\n\n- Create new PowerPoint presentations\n- Add slides to presentations\n- Get slides information from a presentation\n- Export presentations to PDF\n- Read presentation metadata and structure\n\n## Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/islem-zaraa/mcp-powerpoint.git\n\n# Navigate to the project directory\ncd mcp-powerpoint\n\n# Install dependencies\nnpm install\n\n# Link for local development\nnpm link\n```\n\n## Usage as CLI\n\nThis plugin can be used directly as a command-line tool:\n\n```bash\n# Create a new presentation\nmcp-powerpoint create --outputPath=\"presentation.pptx\" --title=\"My Presentation\"\n\n# Add a slide to an existing presentation\nmcp-powerpoint add-slide --file=\"presentation.pptx\" --title=\"New Slide\" --content=\"This is the content of the slide\"\n\n# Get slides from a presentation\nmcp-powerpoint get-slides --file=\"presentation.pptx\"\n\n# Export presentation to PDF\nmcp-powerpoint export-pdf --file=\"presentation.pptx\" --outputPath=\"presentation.pdf\"\n\n# Read presentation metadata\nmcp-powerpoint read --file=\"presentation.pptx\"\n```\n\n## Usage as MCP Plugin\n\nThis plugin can be integrated into an MCP-compatible AI assistant system:\n\n```javascript\nconst mcpPowerPointPlugin = require('mcp-powerpoint/src/mcp-plugin');\n\n// Register the plugin with your MCP system\nmcpSystem.registerPlugin(mcpPowerPointPlugin);\n\n// Now the AI can use the PowerPoint functions through the MCP protocol\n// Example function calls:\n// - mcp_powerpoint_create_presentation\n// - mcp_powerpoint_add_slide\n// - mcp_powerpoint_get_slides\n// - mcp_powerpoint_export_to_pdf\n// - mcp_powerpoint_read_presentation\n```\n\n## Function Descriptions\n\n### mcp_powerpoint_create_presentation\n\nCreates a new PowerPoint presentation.\n\n**Parameters:**\n- `outputPath`: Path where to save the PowerPoint file (must end with .pptx)\n- `title`: (Optional) Title of the presentation\n\n### mcp_powerpoint_add_slide\n\nAdds a slide to an existing PowerPoint presentation.\n\n**Parameters:**\n- `file`: Path to the PowerPoint file\n- `title`: (Optional) Title of the slide\n- `content`: (Optional) Content of the slide\n\n### mcp_powerpoint_get_slides\n\nGets slides from a PowerPoint presentation.\n\n**Parameters:**\n- `file`: Path to the PowerPoint file\n\n### mcp_powerpoint_export_to_pdf\n\nExports a PowerPoint presentation to PDF.\n\n**Parameters:**\n- `file`: Path to the PowerPoint file\n- `outputPath`: Path where to save the PDF file (must end with .pdf)\n\n### mcp_powerpoint_read_presentation\n\nReads metadata and structure from a PowerPoint presentation.\n\n**Parameters:**\n- `file`: Path to the PowerPoint file\n\n## Limitations\n\n- The plugin currently provides basic PowerPoint functionality\n- Editing existing slides has limitations due to the complexity of the PPTX format\n- The PDF export is a simulated feature in this version\n\n## License\n\nMIT\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request. ### Topics\n- mcp\n- model-context-protocol\n- mcp-server\n- powerpoint\n- presentation\n- slides\n- office\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "powerpoint",
        "slides",
        "presentations",
        "mcp powerpoint",
        "powerpoint presentations",
        "powerpoint create"
      ],
      "category": "document-processing"
    },
    "jbchouinard--mcp-document-reader": {
      "owner": "jbchouinard",
      "name": "mcp-document-reader",
      "url": "https://github.com/jbchouinard/mcp-document-reader",
      "imageUrl": "/freedevtools/mcp/pfp/jbchouinard.webp",
      "description": "Interact with PDF and EPUB documents, enabling reading and processing tasks within an IDE. Supports seamless handling of document content directly within the development environment.",
      "stars": 7,
      "forks": 4,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-16T17:07:43Z",
      "readme_content": "# mcp-document-reader\n\nA rudimentary [MCP server](https://modelcontextprotocol.io/introduction) for interacting with PDF and EPUB documents.\n\nI use this with [Windsurf IDE by Codeium](https://codeium.com/windsurf), which\nonly supports MCP tools, not resources.\n\n## Installation\n\n### Requirements\n\n- [Python 3.11+](https://www.python.org/downloads/)\n- [Poetry](https://python-poetry.org/docs/)\n\n```bash\n# Clone the repository\ngit clone https://github.com/jbchouinard/mcp-document-reader.git\ncd mcp-document-reader\npoetry install\n```\n\n## Configure MCP Server\n\nRun with poetry:\n\n```json\n{\n  \"mcpServers\": {\n    \"documents\": {\n      \"command\": \"poetry\",\n      \"args\": [\"-C\", \"path/to/mcp-document-reader\", \"run\", \"mcp-document-reader\"]\n    }\n  }\n}\n```\n\nAlternatively, build and install with pip, then run the script directly:\n\n```bash\npoetry build\npipx install dist/*.whl\nwhich mcp-document-reader\n```\n\nThen use the following config, with the path output by which:\n\n```json\n{\n  \"mcpServers\": {\n    \"documents\": {\n      \"command\": \"/path/to/mcp-document-reader\",\n      \"args\": []\n    }\n  }\n}\n```\n\n## Development\n\n### Setup\n\n```bash\n# Install dependencies\npoetry install\n```\n\n### Testing\n\n```bash\npoetry run pytest\n```\n\n### Linting\n\n```bash\npoetry run ruff check --fix .\npoetry run ruff format .\n```\n\n## License\n\n[MIT](LICENSE)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "reader",
        "document",
        "epub",
        "document reader",
        "epub documents",
        "document processing"
      ],
      "category": "document-processing"
    },
    "jdot274--PptxGenJS": {
      "owner": "jdot274",
      "name": "PptxGenJS",
      "url": "https://github.com/jdot274/PptxGenJS",
      "imageUrl": "/freedevtools/mcp/pfp/jdot274.webp",
      "description": "Create PowerPoint presentations using JavaScript with ease, enabling developers to generate slides programmatically.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-02-27T08:36:14Z",
      "readme_content": "<h1 align=\"center\">PptxGenJS</h1>\n<h5 align=\"center\">\n  Create JavaScript PowerPoint Presentations\n</h5>\n<p align=\"center\">\n  <a href=\"https://github.com/gitbrent/PptxGenJS/\">\n    <img alt=\"PptxGenJS Sample Slides\" title=\"PptxGenJS Sample Slides\" src=\"https://raw.githubusercontent.com/gitbrent/PptxGenJS/gh-pages/img/readme_banner.png\"/>\n  </a>\n</p>\n<br/>\n\n[![Known Vulnerabilities](https://snyk.io/test/npm/pptxgenjs/badge.svg)](https://snyk.io/test/npm/pptxgenjs) [![npm downloads](https://img.shields.io/npm/dm/pptxgenjs.svg)](https://www.npmjs.com/package/pptxgenjs) [![jsdelivr downloads](https://data.jsdelivr.com/v1/package/gh/gitbrent/pptxgenjs/badge)](https://www.jsdelivr.com/package/gh/gitbrent/pptxgenjs) [![typescripts definitions](https://img.shields.io/npm/types/pptxgenjs)](https://img.shields.io/npm/types/pptxgenjs)\n\n# Table of Contents\n\n- [Table of Contents](#table-of-contents)\n- [Introduction](#introduction)\n- [Features](#features)\n\t- [Works Everywhere](#works-everywhere)\n\t- [Full Featured](#full-featured)\n\t- [Simple and Powerful](#simple-and-powerful)\n\t- [Export Your Way](#export-your-way)\n\t- [HTML to PowerPoint](#html-to-powerpoint)\n- [Live Demos](#live-demos)\n- [Installation](#installation)\n\t- [Npm](#npm)\n\t- [Yarn](#yarn)\n\t- [CDN](#cdn)\n\t- [Download](#download)\n\t- [Additional Builds](#additional-builds)\n- [Documentation](#documentation)\n\t- [Quick Start Guide](#quick-start-guide)\n\t\t- [Angular/React, ES6, TypeScript](#angularreact-es6-typescript)\n\t\t- [Script/Web Browser](#scriptweb-browser)\n\t- [Library API](#library-api)\n\t- [HTML-to-PowerPoint Feature](#html-to-powerpoint-feature)\n- [Library Ports](#library-ports)\n- [Issues / Suggestions](#issues--suggestions)\n- [Need Help?](#need-help)\n- [Contributors](#contributors)\n- [Sponsor Us](#sponsor-us)\n- [License](#license)\n\n# Introduction\n\nThis library creates Open Office XML (OOXML) Presentations which are compatible with Microsoft PowerPoint, Apple Keynote, and other applications.\n\n# Features\n\n## Works Everywhere\n\n- Every modern desktop and mobile browser is supported\n- Integrates with Node, Angular, React, and Electron\n- Compatible with PowerPoint, Keynote, and more\n\n## Full Featured\n\n- All major object types are available (charts, shapes, tables, etc.)\n- Master Slides for academic/corporate branding\n- SVG images, animated gifs, YouTube videos, RTL text, and Asian fonts\n\n## Simple and Powerful\n\n- The absolute easiest PowerPoint library to use\n- Learn as you code will full typescript definitions included\n- Tons of demo code comes included (over 75 slides of features)\n\n## Export Your Way\n\n- Exports files direct to client browsers with proper MIME-type\n- Other export formats available: base64, blob, stream, etc.\n- Presentation compression options and more\n\n## HTML to PowerPoint\n\n- Includes powerful [HTML-to-PowerPoint](#html-to-powerpoint-feature) feature to transform HTML tables into presentations with a single line of code\n\n# Live Demos\n\nVisit the demos page to create a simple presentation to see how easy it is to use pptxgenjs, or check out the complete demo which showcases every available feature.\n\n- [PptxGenJS Demos](https://gitbrent.github.io/PptxGenJS/demos/)\n\n# Installation\n\n## Npm\n\n[PptxGenJS NPM Home](https://www.npmjs.com/package/pptxgenjs)\n\n```bash\nnpm install pptxgenjs --save\n```\n\n## Yarn\n\n```bash\nyarn add pptxgenjs\n```\n\n## CDN\n\n[jsDelivr Home](https://www.jsdelivr.com/package/gh/gitbrent/pptxgenjs)\n\nBundle: Modern Browsers and IE11\n\n```html\n<script src=\"https://cdn.jsdelivr.net/gh/gitbrent/pptxgenjs@3.12.0/dist/pptxgen.bundle.js\"></script>\n```\n\nMin files: Modern Browsers\n\n```html\n<script src=\"https://cdn.jsdelivr.net/gh/gitbrent/pptxgenjs@3.12.0/libs/jszip.min.js\"></script>\n<script src=\"https://cdn.jsdelivr.net/gh/gitbrent/pptxgenjs@3.12.0/dist/pptxgen.min.js\"></script>\n```\n\n## Download\n\n[GitHub Latest Release](https://github.com/gitbrent/PptxGenJS/releases/latest)\n\nBundle: Modern Browsers\n\n- Use the bundle for IE11 support\n\n```html\n<script src=\"PptxGenJS/dist/pptxgen.bundle.js\"></script>\n```\n\nMin files: Modern Browsers\n\n```html\n<script src=\"PptxGenJS/libs/jszip.min.js\"></script>\n<script src=\"PptxGenJS/dist/pptxgen.min.js\"></script>\n```\n\n## Additional Builds\n\n- CommonJS: `dist/pptxgen.cjs.js`\n- ES Module: `dist/pptxgen.es.js`\n\n---\n\n# Documentation\n\n## Quick Start Guide\n\nPptxGenJS PowerPoint presentations are created via JavaScript by following 4 basic steps:\n\n### Angular/React, ES6, TypeScript\n\n```typescript\nimport pptxgen from \"pptxgenjs\";\n\n// 1. Create a new Presentation\nlet pres = new pptxgen();\n\n// 2. Add a Slide\nlet slide = pres.addSlide();\n\n// 3. Add one or more objects (Tables, Shapes, Images, Text and Media) to the Slide\nlet textboxText = \"Hello World from PptxGenJS!\";\nlet textboxOpts = { x: 1, y: 1, color: \"363636\" };\nslide.addText(textboxText, textboxOpts);\n\n// 4. Save the Presentation\npres.writeFile();\n```\n\n### Script/Web Browser\n\n```javascript\n// 1. Create a new Presentation\nlet pres = new PptxGenJS();\n\n// 2. Add a Slide\nlet slide = pres.addSlide();\n\n// 3. Add one or more objects (Tables, Shapes, Images, Text and Media) to the Slide\nlet textboxText = \"Hello World from PptxGenJS!\";\nlet textboxOpts = { x: 1, y: 1, color: \"363636\" };\nslide.addText(textboxText, textboxOpts);\n\n// 4. Save the Presentation\npres.writeFile();\n```\n\nThat's really all there is to it!\n\n---\n\n## Library API\n\nFull documentation and code examples are available\n\n- [Creating a Presentation](https://gitbrent.github.io/PptxGenJS/docs/usage-pres-create/)\n- [Presentation Options](https://gitbrent.github.io/PptxGenJS/docs/usage-pres-options/)\n- [Adding a Slide](https://gitbrent.github.io/PptxGenJS/docs/usage-add-slide/)\n- [Slide Options](https://gitbrent.github.io/PptxGenJS/docs/usage-slide-options/)\n- [Saving a Presentation](https://gitbrent.github.io/PptxGenJS/docs/usage-saving/)\n- [Master Slides](https://gitbrent.github.io/PptxGenJS/docs/masters/)\n- [Adding Charts](https://gitbrent.github.io/PptxGenJS/docs/api-charts/)\n- [Adding Images](https://gitbrent.github.io/PptxGenJS/docs/api-images/)\n- [Adding Media](https://gitbrent.github.io/PptxGenJS/docs/api-media/)\n- [Adding Shapes](https://gitbrent.github.io/PptxGenJS/docs/api-shapes/)\n- [Adding Tables](https://gitbrent.github.io/PptxGenJS/docs/api-tables/)\n- [Adding Text](https://gitbrent.github.io/PptxGenJS/docs/api-text/)\n- [Speaker Notes](https://gitbrent.github.io/PptxGenJS/docs/speaker-notes/)\n- [Using Scheme Colors](https://gitbrent.github.io/PptxGenJS/docs/shapes-and-schemes/)\n- [Integration with Other Libraries](https://gitbrent.github.io/PptxGenJS/docs/integration/)\n\n---\n\n## HTML-to-PowerPoint Feature\n\nEasily convert HTML tables to PowerPoint presentations in a single call.\n\n```javascript\nlet pptx = new PptxGenJS();\npptx.tableToSlides(\"tableElementId\");\npptx.writeFile({ fileName: \"html2pptx-demo.pptx\" });\n```\n\nLearn more:\n\n- [HTML-to-PowerPoint Docs/Demo](https://gitbrent.github.io/PptxGenJS/html2pptx/)\n\n---\n\n# Library Ports\n\nReact: [react-pptx](https://github.com/wyozi/react-pptx) - thanks to [Joonas](https://github.com/wyozi)!\n\n---\n\n# Issues / Suggestions\n\nPlease file issues or suggestions on the [issues page on github](https://github.com/gitbrent/PptxGenJS/issues/new), or even better, [submit a pull request](https://github.com/gitbrent/PptxGenJS/pulls). Feedback is always welcome!\n\nWhen reporting issues, please include a code snippet or a link demonstrating the problem.\nHere is a small [jsFiddle](https://jsfiddle.net/gitbrent/L1uctxm0/) that is already configured and uses the latest PptxGenJS code.\n\n---\n\n# Need Help?\n\nSometimes implementing a new library can be a difficult task and the slightest mistake will keep something from working. We've all been there!\n\nIf you are having issues getting a presentation to generate, check out the code in the `demos` directory. There\nare demos for both client browsers, node and react that contain working examples of every available library feature.\n\n- Use a pre-configured jsFiddle to test with: [PptxGenJS Fiddle](https://jsfiddle.net/gitbrent/L1uctxm0/)\n- [View questions tagged `PptxGenJS` on StackOverflow](https://stackoverflow.com/questions/tagged/pptxgenjs?sort=votes&pageSize=50). If you can't find your question, [ask it yourself](https://stackoverflow.com/questions/ask?tags=PptxGenJS) - be sure to tag it `PptxGenJS`.\n\n---\n\n# Contributors\n\nThank you to everyone for the issues, contributions and suggestions! ❤️\n\nSpecial Thanks:\n\n- [Dzmitry Dulko](https://github.com/DzmitryDulko) - Getting the project published on NPM\n- [Michal Kacerovský](https://github.com/kajda90) - New Master Slide Layouts and Chart expertise\n- [Connor Bowman](https://github.com/conbow) - Adding Placeholders\n- [Reima Frgos](https://github.com/ReimaFrgos) - Multiple chart and general functionality patches\n- [Matt King](https://github.com/kyrrigle) - Chart expertise\n- [Mike Wilcox](https://github.com/clubajax) - Chart expertise\n- [Joonas](https://github.com/wyozi) - React port\n\nPowerPoint shape definitions and some XML code via [Officegen Project](https://github.com/Ziv-Barber/officegen)\n\n---\n\n# Sponsor Us\n\nIf you find this library useful, please consider sponsoring us through a [donation](https://gitbrent.github.io/PptxGenJS/sponsor/)\n\n---\n\n# License\n\nCopyright &copy; 2015-present [Brent Ely](https://github.com/gitbrent/PptxGenJS)\n\n[MIT](https://github.com/gitbrent/PptxGenJS/blob/master/LICENSE)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "pptxgenjs",
        "powerpoint",
        "slides",
        "generate slides",
        "create powerpoint",
        "powerpoint presentations"
      ],
      "category": "document-processing"
    },
    "jenstangen1--pptx-xlsx-mcp": {
      "owner": "jenstangen1",
      "name": "pptx-xlsx-mcp",
      "url": "https://github.com/jenstangen1/pptx-xlsx-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/jenstangen1.webp",
      "description": "Interact with Microsoft Office applications like PowerPoint and Excel to create, modify, and analyze presentations and spreadsheets using natural language commands. Automate complex tasks and data manipulations efficiently within the Office environment.",
      "stars": 25,
      "forks": 3,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-09-30T16:54:39Z",
      "readme_content": "# Microsoft Office MCP Servers\n\nThis repository contains Model Context Protocol (MCP) servers for interacting with Microsoft Office applications through AI assistance. Currently supported applications:\n- PowerPoint: Create and manipulate presentations\n- Excel: Interact with workbooks and spreadsheets\n\nBoth servers use `pywin32` for COM automation, allowing direct interaction with running Office applications.\n\n## Prerequisites\n\n- Windows operating system\n- Microsoft Office installed (PowerPoint and/or Excel)\n- Python 3.7+\n- `pywin32` package\n\n## Installation\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/jenstangen1/mcp-pptx.git\ncd mcp-pptx\n```\n\n2. Install dependencies using `uv`:\n```bash\nuv pip install pywin32\n```\n\n3. Run the `pywin32` post-install script with administrator privileges:\n```bash\npython C:\\path\\to\\your\\env\\Scripts\\pywin32_postinstall.py -install\n```\n\n## Setting up with Claude\n\nTo integrate these MCP servers with Claude, add the following configuration to your Claude Desktop app settings:\n\n```json\n{\n    \"mcpServers\": {\n        \"powerpoint_mcp_win32\": {\n            \"command\": \"uv\",\n            \"args\": [\n                \"run\",\n                \"mcp_powerpoint_server_win32.py\"\n            ],\n            \"cwd\": \"C:\\\\path\\\\to\\\\your\\\\workspace\"\n        },\n        \"excel_mcp_win32\": {\n            \"command\": \"uv\",\n            \"args\": [\n                \"run\",\n                \"mcp_excel_server_win32.py\"\n            ],\n            \"cwd\": \"C:\\\\path\\\\to\\\\your\\\\workspace\"\n        }\n    }\n}\n```\n\nNote: Replace `C:\\\\path\\\\to\\\\your\\\\workspace` with your actual workspace path.\n\n# PowerPoint MCP Server\n\nThe PowerPoint server provides a comprehensive API for AI models to interact with PowerPoint presentations, supporting advanced formatting, financial charts, and data integration.\n\n## Features\n\n### Presentation Management\n- Create and modify PowerPoint presentations\n- Add, delete, and modify slides\n- Save and load presentations from workspace\n- Template management system\n\n### Element Operations\n- Fine-grained control over slide elements (text, shapes, images, charts)\n- Advanced shape creation and styling\n- Element positioning and grouping\n- Connector lines between shapes\n\n### Financial Integration\n- Create financial charts (line, bar, column, pie, waterfall, etc.)\n- Generate comparison tables\n- Support for various financial metrics:\n  - Revenue\n  - EBITDA\n  - Profit\n  - Assets\n  - Equity\n  - Growth rates\n  - Margins\n- Currently uses dummy data, with plans to integrate Proff API for Norwegian company data\n- Adaptable to other financial data providers through API customization\n\n### Styling and Formatting\n- Rich text formatting\n- Shape styling (fills, gradients, outlines)\n- Chart customization\n- Background colors and effects\n\nNote: You may need to modify the directory path to match your installation location.\n\n## Available MCP Tools\n\n### Presentation Management\n- `list_presentations`: List all PowerPoint files in the workspace\n- `upload_presentation`: Upload a new presentation to the workspace\n- `save_presentation`: Save the current presentation\n\n### Slide Operations\n- `add_slide`: Add a new slide to the presentation\n- `delete_slide`: Delete a slide from the presentation\n- `get_slide_count`: Get the total number of slides in the presentation\n- `analyze_slide`: Analyze the content of a slide\n- `set_background_color`: Set the background color of a slide\n\n### Element Operations\n- `add_text`: Add text to a slide\n- `add_shape`: Add a shape to a slide\n- `edit_element`: Edit an element's properties\n- `style_element`: Apply styling to an element\n- `connect_shapes`: Connect two shapes with a connector\n- `find_element`: Find elements on a slide based on criteria\n\n### Financial Tools\n- `get_company_financials`: Get financial data for a company (currently returns dummy data)\n- `create_financial_chart`: Create a financial chart on a slide\n- `create_comparison_table`: Create a comparison table for companies\n\n**Note:** The financial tools currently use dummy data. Future versions plan to integrate with the Proff API for automatic fetching of Norwegian company data. Users can modify the code to connect with local or preferred financial data providers.\n\n### Template Operations\n- `list_templates`: List all available templates\n- `apply_template`: Apply a template to a presentation\n- `create_slide_from_template`: Create a new slide from a template\n- `save_as_template`: Save a slide as a template\n\n### Debug Tools\n- `debug_element_mappings`: Debug tool to inspect element mappings for a slide\n\n## Usage\n\n### Interacting with Claude\n\nOnce you've configured the MCP servers in your Claude Desktop app, you can interact with PowerPoint and Excel through natural language commands. Here are some examples:\n\n#### PowerPoint Examples\n\n```\nYou: Create a new slide with a title \"Market Analysis\" and add a bar chart showing revenue growth.\n\nClaude: I'll help you create that slide with the title and chart. I'll:\n1. Add a new slide\n2. Add the title text\n3. Create a revenue chart\n\n[Claude will then use the MCP tools in sequence:\n- add_slide\n- add_text\n- create_financial_chart]\n\nYou: Make the title bigger and change its color to blue.\n\nClaude: I'll modify the title's formatting.\n[Claude will use:\n- find_element (to locate the title)\n- edit_element (to update the formatting)]\n\nYou: Add a comparison table below the chart comparing three companies.\n\nClaude: I'll add a comparison table below the existing chart.\n[Claude will use:\n- create_comparison_table]\n```\n\n#### Excel Examples\n\n```\nYou: Open the Q4 report and show me the revenue numbers from cells B2 to B5.\n\nClaude: I'll help you retrieve those revenue figures.\n[Claude will use:\n- list_open_workbooks (to find the workbook)\n- get_range_values (to read the specified cells)]\n\nYou: Calculate the sum of these numbers and put it in cell B6.\n\nClaude: I'll calculate the sum and write it to B6.\n[Claude will use:\n- get_range_values (to get the numbers)\n- set_cell_value (to write the sum)]\n\nYou: Create a new sheet called \"Summary\" and copy these values there.\n\nClaude: I'll create a new sheet and copy the data.\n[Claude will use:\n- add_worksheet\n- get_range_values (from source)\n- set_range_values (to destination)]\n```\n\n### How It Works\n\n1. **Natural Language Understanding**\n   - Claude interprets your requests and breaks them down into specific actions\n   - It understands context from previous interactions\n   - It can handle complex, multi-step operations\n\n2. **Tool Selection**\n   - Claude automatically selects the appropriate MCP tools for each task\n   - It can chain multiple tools together for complex operations\n   - It handles error cases and provides feedback\n\n3. **Context Management**\n   - Claude maintains context about:\n     - Currently open files\n     - Recent operations\n     - Selected elements\n     - User preferences\n\n4. **Error Handling**\n   - If an operation fails, Claude will:\n     - Explain what went wrong\n     - Suggest alternatives\n     - Help troubleshoot common issues\n\n### Best Practices\n\n1. **Be Specific**\n   - Mention slide numbers when relevant\n   - Specify exact cell ranges in Excel\n   - Describe desired formatting clearly\n\n2. **Complex Operations**\n   - Break down complex requests into steps\n   - Confirm intermediate results\n   - Ask for adjustments as needed\n\n3. **Troubleshooting**\n   - Ensure PowerPoint/Excel is running\n   - Check file permissions\n   - Verify COM automation is working\n   - Run pywin32_postinstall.py if needed\n\n### Example Workflows\n\n#### Creating a Financial Presentation\n\n```\nYou: Create a new presentation about Q4 financial results.\nClaude: I'll create a new presentation with a title slide.\n\nYou: Add revenue charts for the last 4 quarters.\nClaude: I'll create a new slide with a chart showing quarterly revenue.\n\nYou: Now add a comparison with our competitors.\nClaude: I'll add a comparison table with key metrics for you and competitors.\n```\n\n#### Analyzing Excel Data\n\n```\nYou: Show me all sheets in the Q4 analysis workbook.\nClaude: I'll list all worksheets in that workbook.\n\nYou: Find the highest revenue value in column B.\nClaude: I'll scan column B and find the maximum value.\n\nYou: Create a summary of the top 5 values.\nClaude: I'll create a new sheet with the top 5 revenue figures.\n```\n\n## Directory Structure\n\n```\npptx-mcp/\n├── mcp_powerpoint_server.py  # Main server implementation\n├── requirements.txt          # Python dependencies\n├── presentations/           # Workspace for presentations\n│   └── templates/          # Template storage\n└── README.md               # This file\n```\n\n## Dependencies\n\n- python-pptx: PowerPoint file manipulation\n- Pillow: Image processing\n- numpy: Numerical operations\n- MCP SDK: Model Context Protocol implementation\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n# Excel MCP Server\n\nThe Excel server provides tools for interacting with Excel workbooks, worksheets, and cell data through AI assistance.\n\n## Features\n\n### Workbook Management\n- Connect to running Excel instances\n- List open workbooks\n- Save workbooks with various formats (.xlsx, .xlsm, .xlsb, .xls)\n\n### Worksheet Operations\n- List worksheets in a workbook\n- Add new worksheets\n- Access worksheets by name or index\n\n### Cell and Range Operations\n- Read and write individual cell values\n- Get and set values for cell ranges\n- Handle various data types (text, numbers, dates, currency)\n- Automatic type conversion for dates and currency values\n\n## Available MCP Tools\n\n### Workbook Management\n- `list_open_workbooks`: List all currently open Excel workbooks\n- `save_workbook`: Save a workbook to disk with optional format selection\n\n### Worksheet Operations\n- `list_worksheets`: List all worksheets in a workbook\n- `add_worksheet`: Add a new worksheet to a workbook\n- `get_worksheet`: Get a worksheet by name or index\n\n### Cell and Range Operations\n- `get_cell_value`: Read a single cell's value\n- `set_cell_value`: Set a single cell's value\n- `get_range_values`: Read values from a range of cells\n- `set_range_values`: Set values for a range of cells\n\n\n## Notes\n\n- Both servers require Windows and their respective Microsoft Office applications installed\n- The servers interact with *running* instances of the applications\n- COM automation requires proper initialization; run the post-install script if you encounter COM-related errors\n- For better constant handling, consider using `makepy` to generate Office constants",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "powerpoint",
        "pptx",
        "spreadsheets",
        "pptx xlsx",
        "microsoft office",
        "powerpoint excel"
      ],
      "category": "document-processing"
    },
    "jettyio--mlcbakery": {
      "owner": "jettyio",
      "name": "mlcbakery",
      "url": "https://github.com/jettyio/mlcbakery",
      "imageUrl": "/freedevtools/mcp/pfp/jettyio.webp",
      "description": "Provides access to MLC Bakery functionalities through an MCP-compatible interface, enabling clients to search datasets, retrieve previews, and validate metadata efficiently. Facilitates interaction with MLC Bakery API tools for data exploration and management.",
      "stars": 5,
      "forks": 1,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-20T22:04:28Z",
      "readme_content": "# MLC Bakery\n\nA Python-based service for managing ML model provenance and lineage, built with FastAPI and SQLAlchemy. Support for Croissant metadata validation.\n\n## Features\n\n- Dataset management with collection support\n- Entity tracking\n- Activity logging\n- Provenance relationships tracking\n- RESTful API endpoints\n\n## Running with Docker\n\n1.  **Set up Environment Variables:**\n    Create a `.env` file in the project root by copying the example:\n    ```bash\n    cp env.example .env\n    ```\n\n2. **Start docker containers:**\n    The bakery relies on a postgres database and Typesense for search. The MCP server makes REST calls to the API server, which then calls the persistence layer.\n    ```\n    docker compose up -d\n    ```\n\n3.  **Run Database Migrations:**\n    Apply the latest database schema using Alembic. `uv run` executes commands within the project's managed environment.\n    ```bash\n    docker compose exec db psql -U postgres -c \"create DATABASE mlcbakery;\"\n    docker compose exec api alembic upgrade head\n    ```\n## Access the bakery\nBy default, the API will be available on localhost.\n-   Swagger UI: `http://bakery.localhost/docs`\n-   ReDoc: `http://bakery.localhost/redoc`\n-   Streamable MCP HTTP: `http://mcp.localhost/mcp` (you may need to add this to your `/etc/hosts` for local development)\n\n## Running the Server (Locally)\n\n### Prerequisites\n\n- Python 3.12+\n- [uv](https://github.com/astral-sh/uv) (Python package manager)\n\n### Development steps\n\n1.  **Clone the repository:**\n    ```bash\n    git clone git@github.com:jettyio/mlcbakery.git\n    cd mlcbakery\n    ```\n\n2.  **Install Dependencies:**\n    `uv` uses `pyproject.toml` to manage dependencies. It will automatically create a virtual environment if one doesn't exist.\n    ```bash\n    curl -LsSf https://astral.sh/uv/install.sh | sh\n    ```\n    ```\n    pip install poetry uvicorn\n    uv run poetry install --no-interaction --no-ansi --no-root --with mcp\n    ```\nStart the FastAPI application using uvicorn:\n```bash\n# Make sure your .env file is present for the DATABASE_URL\nuv run uvicorn mlcbakery.main:app --reload --host 0.0.0.0 --port 8000\n```\n\n### Authentication\nThe Bakery is setup to authenticate requests with two methods: JWT Tokens and a \"Master Admin Token\". Both are configured in the ENV variables (.env file). Both JWT tokens and the Master Admin Token should be provided as \"Bearer\" Authorization header values.\n\n- ADMIN_AUTH_TOKEN: A fixed value that is the token a user would need to provide to have admin permissions (unrestricted access to all resources).\n- JWT_VERIFICATION_STRATEGY: The URL of a trusted JWT token issuer, such as Clerk. We have a development instance of Clerk running that you can use. You can sign up for an account via flows.jetty.io (alpha), or contact dev@jetty.io for access to Jetty's Cloud.\n\n### Running Tests\n\nThe tests are configured to run against a PostgreSQL database defined by the `DATABASE_URL` environment variable. You can use the same database as your development environment or configure a separate test database in your `.env` file if preferred (adjust connection string as needed).\n\n```bash\n# Ensure DATABASE_URL is set in your environment or .env file\nuv run pytest\n```\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "bakery",
        "mlc",
        "mlcbakery",
        "mlc bakery",
        "mlcbakery provides",
        "bakery api"
      ],
      "category": "document-processing"
    },
    "jiawei0816--docs": {
      "owner": "jiawei0816",
      "name": "docs",
      "url": "https://github.com/jiawei0816/docs",
      "imageUrl": "/freedevtools/mcp/pfp/jiawei0816.webp",
      "description": "A starter kit designed for creating and managing project documentation with features like guide pages, navigation, and API references. It facilitates local previews and automatic deployment of documentation changes through a GitHub app integration.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "MDX",
      "updated_at": "2024-10-17T01:05:30Z",
      "readme_content": "# Mintlify Starter Kit\n\nClick on `Use this template` to copy the Mintlify starter kit. The starter kit contains examples including\n\n- Guide pages\n- Navigation\n- Customizations\n- API Reference pages\n- Use of popular components\n\n### Development\n\nInstall the [Mintlify CLI](https://www.npmjs.com/package/mintlify) to preview the documentation changes locally. To install, use the following command\n\n```\nnpm i -g mintlify\n```\n\nRun the following command at the root of your documentation (where mint.json is)\n\n```\nmintlify dev\n```\n\n### Publishing Changes\n\nInstall our Github App to auto propagate changes from your repo to your deployment. Changes will be deployed to production automatically after pushing to the default branch. Find the link to install on your dashboard. \n\n#### Troubleshooting\n\n- Mintlify dev isn't running - Run `mintlify install` it'll re-install dependencies.\n- Page loads as a 404 - Make sure you are running in a folder with `mint.json`\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "documentation",
        "document",
        "docs",
        "documentation features",
        "project documentation",
        "jiawei0816 docs"
      ],
      "category": "document-processing"
    },
    "jimpick--mcp-json-db-collection-server": {
      "owner": "jimpick",
      "name": "mcp-json-db-collection-server",
      "url": "https://github.com/jimpick/mcp-json-db-collection-server",
      "imageUrl": "/freedevtools/mcp/pfp/jimpick.webp",
      "description": "Manage multiple JSON document databases with capabilities for creating, reading, updating, and deleting documents. Sync databases to the cloud for easy access and enable collaboration on structured data.",
      "stars": 0,
      "forks": 4,
      "license": "Other",
      "language": "JavaScript",
      "updated_at": "2024-12-30T03:03:47Z",
      "readme_content": "# Model Context Protocol and Fireproof Demo: JSON Document Collection Server\n\n<h1>\n\n❤️\n\n</h1>\n\nThis is an example of how to use a [Fireproof](https://fireproof.storage/) database in a [Model Context Protocol](https://github.com/modelcontextprotocol) server (used for plugging code and data into A.I. systems such as [Claude Desktop](https://claude.ai/download)).\n\nThis server:\n\n  * allows the creation of multiple \"JSON Document Databases\" (implemented using Fireproof)\n  * implements basic CRUD operations (Create, Read, Update, Delete) within any database and the ability to query documents sorted by any field.\n  * allows sharing of any database with others using the Fireproof Cloud service and dashboard\n\nPrior art: This is based on https://github.com/fireproof-storage/mcp-database-server - it adds multiple databases plus the ability to sync to the cloud.\n\n## Running the Server\n\nFirst, build it:\n\n```\nnpm install\nnpm build\n```\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"json-db-collections\": {\n      \"command\": \"<base-dir>/mcp-json-db-collection-server/build/index.js\"\n    }\n  }\n}\n```\n\n# Sample Claude Desktop chat session\n\nHere is a sample session using Claude Desktop where I create 3 document databases and sync them to the cloud:\n\n## 1. Chat Session: Database of Elements\n\n**human** (Dec 29, 2024, 03:59 PM)\n\ncreate a json document database named elements\n\n**assistant** (Dec 29, 2024, 04:00 PM)\n\n I'll help you create a JSON document database named \"elements\".\n\n\n\nThe database has been created successfully. You can now use this database to store and manage JSON documents. Would you like to add any documents to it?\n\n**human** (Dec 29, 2024, 04:00 PM)\n\nadd noble gases from period table as individual docs\n\n**assistant** (Dec 29, 2024, 04:00 PM)\n\n I'll help you add the noble gases as individual documents to the elements database. I'll include key properties for each noble gas.\n\n\n\nI've added all seven noble gases (Helium, Neon, Argon, Krypton, Xenon, Radon, and Oganesson) to the database. For each element, I included:\n- Name and symbol\n- Atomic number and mass\n- Period, group, and block\n- Electron configuration\n- Melting and boiling points (in Kelvin)\n- Density (in g/cm³)\n\nNote that for Oganesson, some physical properties are marked as null since it's a synthetic element with very short half-life and its properties aren't well-determined experimentally.\n\nWould you like to query any specific information about these noble gases from the database?\n\n**human** (Dec 29, 2024, 04:01 PM)\n\nshow docs\n\n**assistant** (Dec 29, 2024, 04:01 PM)\n\n I'll query all the documents from the elements database, sorted by atomic number.\n\n\n\nHere are all the noble gases in the database, listed in order of atomic number (from highest to lowest):\n\n1. Oganesson (Og) - Element 118\n2. Radon (Rn) - Element 86\n3. Xenon (Xe) - Element 54\n4. Krypton (Kr) - Element 36\n5. Argon (Ar) - Element 18\n6. Neon (Ne) - Element 10\n7. Helium (He) - Element 2\n\nEach document contains detailed information about the element, including its atomic mass, density, melting and boiling points (where known), and electron configuration. Would you like to examine any specific properties or compare certain aspects of these elements?\n\n## 2. Chat Session: Database of Cookie Ingredients\n\n**human** (Dec 29, 2024, 04:01 PM)\n\ncreate json document db called cookie_ingredients\n\n**assistant** (Dec 29, 2024, 04:01 PM)\n\n I'll create a new JSON document database called \"cookie_ingredients\".\n\n\n\nThe database has been created successfully. Would you like to add any ingredients to it?\n\n**human** (Dec 29, 2024, 04:02 PM)\n\nadd ingredients from chocolate chip cookie recipe as individual docs\n\n**assistant** (Dec 29, 2024, 04:02 PM)\n\n I'll add common ingredients for chocolate chip cookies as individual documents with their typical measurements and properties.\n\n\n\nI've added all the essential ingredients for a classic chocolate chip cookie recipe. For each ingredient, I included:\n- Name and amount\n- Unit of measurement\n- Type (dry, wet, leavening, etc.)\n- Purpose in the recipe\n- Possible substitutes\n- Weight measurements\n- Important notes about usage\n\nWould you like to query any specific information about these ingredients from the database?\n\n**human** (Dec 29, 2024, 04:02 PM)\n\nshow ingredients as table\n\n**assistant** (Dec 29, 2024, 04:03 PM)\n\n I'll query the ingredients and format them as a markdown table.\n\n\n\n| Ingredient | Amount | Unit | Type | Purpose | Weight/Unit |\n|------------|--------|------|------|---------|------------|\n| All-Purpose Flour | 2¼ | cups | dry | structure | 120g/cup |\n| Unsalted Butter | 1 | cup | fat | texture and flavor | 227g/cup |\n| Granulated Sugar | ¾ | cup | sweetener | sweetness and texture | 200g/cup |\n| Brown Sugar | ¾ | cup | sweetener | moisture and flavor | 220g/cup |\n| Large Eggs | 2 | whole | binding | structure and richness | 50g each |\n| Vanilla Extract | 1 | teaspoon | flavoring | flavor enhancement | 5g/tsp |\n| Salt | 1 | teaspoon | seasoning | flavor enhancement | 6g/tsp |\n| Baking Soda | 1 | teaspoon | leavening | rise and spread | 4.8g/tsp |\n| Chocolate Chips | 2 | cups | mix-in | flavor and texture | 170g/cup |\n\nI've organized the ingredients by type and included their amounts, units, purposes, and weight measurements. Would you like to see any additional details about specific ingredients?\n\n## 3. Chat Session: Database of Horse Breeds\n\n**human** (Dec 29, 2024, 04:03 PM)\n\ncreate new json document db called horse_breeds\n\n**assistant** (Dec 29, 2024, 04:03 PM)\n\n I'll create a new JSON document database for horse breeds.\n\n\n\nThe database has been created successfully. Would you like to add some horse breeds to it?\n\n**human** (Dec 29, 2024, 04:03 PM)\n\nyes\n\n**assistant** (Dec 29, 2024, 04:04 PM)\n\n I'll add several popular horse breeds with their key characteristics, origins, and typical uses.\n\n\n\nI've added six distinctive horse breeds to the database:\n1. Arabian - known for endurance and refinement\n2. Thoroughbred - famous for racing and athleticism\n3. Clydesdale - a powerful draft horse\n4. Quarter Horse - America's versatile stock horse\n5. Friesian - elegant black horse from the Netherlands\n6. Appaloosa - known for spotted patterns and Native American heritage\n\nEach entry includes information about:\n- Origin and type\n- Height range (in hands - where 1 hand = 4 inches)\n- Common colors\n- Physical characteristics\n- Typical uses\n- Temperament\n- Notable traits\n\nWould you like to see the information presented in a specific way or learn more about any particular breed?\n\n## 4. Chat Session: Sync to Cloud\n\n**human** (Dec 29, 2024, 04:04 PM)\n\nlist json document dbs\n\n**assistant** (Dec 29, 2024, 04:04 PM)\n\n I'll list all the JSON document databases that have been created.\n\n\n\nWe have three JSON document databases:\n1. horse_breeds\n2. elements\n3. cookie_ingredients\n\nEach database contains documents related to its specific theme:\n- horse_breeds has information about different horse breeds\n- elements contains data about noble gases\n- cookie_ingredients has details about chocolate chip cookie ingredients\n\nWould you like to query any specific information from these databases?\n\n**human** (Dec 29, 2024, 04:04 PM)\n\nsync horse_breeds to cloud\n\n**assistant** (Dec 29, 2024, 04:04 PM)\n\n I'll help you connect the horse_breeds database to cloud sync service.\n\n\n\nThe horse_breeds database has been successfully connected to the cloud. You can access the dashboard using the URL provided above. This will allow you to view and manage your horse breeds data through the cloud interface. Would you like to sync any other databases to the cloud as well?\n\n**human** (Dec 29, 2024, 04:05 PM)\n\nshow url\n\n**assistant** (Dec 29, 2024, 04:05 PM)\n\n Here's the dashboard URL for the horse_breeds database:\n\nhttps://dashboard.fireproof.storage/fp/databases/connect?endpoint=fireproof%3A%2F%2Fcloud.fireproof.direct%2F&localName=horse_breeds&remoteName=019414e1-2db0-70aa-b9a4-2e2f78a7adce\n\nYou can use this URL to access and manage the horse breeds data through the cloud interface.\n\n**human** (Dec 29, 2024, 04:05 PM)\n\nsync elements db to cloud\n\n**assistant** (Dec 29, 2024, 04:05 PM)\n\n I'll connect the elements database to the cloud sync service.\n\n\n\nThe elements database has been successfully connected to the cloud. You can access the dashboard at:\n\nhttps://dashboard.fireproof.storage/fp/databases/connect?endpoint=fireproof%3A%2F%2Fcloud.fireproof.direct%2F&localName=elements&remoteName=019414e1-db52-75e7-b8d0-21ce605176a7\n\nWould you like to sync the cookie_ingredients database as well?\n\n**human** (Dec 29, 2024, 04:05 PM)\n\nyes\n\n**assistant** (Dec 29, 2024, 04:05 PM)\n\n I'll connect the cookie_ingredients database to the cloud sync service.\n\n\n\nHere's the dashboard URL for the cookie_ingredients database:\n\nhttps://dashboard.fireproof.storage/fp/databases/connect?endpoint=fireproof%3A%2F%2Fcloud.fireproof.direct%2F&localName=cookie_ingredients&remoteName=019414e2-1f47-72d7-bf8f-a721d29a24c7\n\nNow all three databases (horse_breeds, elements, and cookie_ingredients) are synchronized to the cloud and can be accessed through their respective dashboard URLs.\n\n## 5. Chat Session: Cleanup\n\n**human** (Dec 29, 2024, 04:06 PM)\n\ndelete all databases\n\n**assistant** (Dec 29, 2024, 04:06 PM)\n\n I'll help you delete all three databases.\n\n\n\nAll three databases have been successfully deleted:\n1. horse_breeds\n2. elements\n3. cookie_ingredients\n\nLet me verify that they're all gone.\n\n\n\nConfirmed - there are no remaining databases in the system. Would you like to create any new databases?\n\n**Converted to Markdown thanks to**: https://simonwillison.net/2024/Aug/8/convert-claude-json-to-markdown/\n\n# Future development ideas\n\n* prompts\n* resources\n* multiuser with permissions\n* indexing\n* generate static websites from Claude Desktop using Firebase npm libraries\n\n# Development\n\n```bash\npnpm install\npnpm build\npnpm run inspector\n# To reset, do: rm -rf ~/.fireproof /tmp/dist\n```\n\n`~/Library/Application\\ Support/Claude/claude_desktop_config.json`:\n```\n{\n  \"mcpServers\": {\n    \"json-db-collections\": {\n      \"command\": \"<base-dir>/mcp-json-db-collection-server/build/index.js\"\n    }\n  }\n}\n```\n\n# License\n\nMIT or Apache 2",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "databases",
        "documents",
        "db",
        "document databases",
        "databases cloud",
        "mcp json"
      ],
      "category": "document-processing"
    },
    "jinzcdev--markmap-mcp-server": {
      "owner": "jinzcdev",
      "name": "markmap-mcp-server",
      "url": "https://github.com/jinzcdev/markmap-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/jinzcdev.webp",
      "description": "Converts Markdown text into interactive mind maps, supporting export in various image formats including PNG, JPG, and SVG. Features include zooming, node expansion, automatic browser preview, and one-click Markdown copying.",
      "stars": 117,
      "forks": 18,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T23:14:25Z",
      "readme_content": "# Markmap MCP Server\n\n\n\n[![NPM Version](https://img.shields.io/npm/v/@jinzcdev/markmap-mcp-server.svg)](https://www.npmjs.com/package/@jinzcdev/markmap-mcp-server)\n[![GitHub License](https://img.shields.io/github/license/jinzcdev/markmap-mcp-server.svg)](LICENSE)\n[![Smithery Badge](https://smithery.ai/badge/@jinzcdev/markmap-mcp-server)](https://smithery.ai/server/@jinzcdev/markmap-mcp-server)\n[![中文文档](https://img.shields.io/badge/中文文档-点击查看-blue)](README_zh-CN.md)\n[![Stars](https://img.shields.io/github/stars/jinzcdev/markmap-mcp-server)](https://github.com/jinzcdev/markmap-mcp-server)\n\nMarkmap MCP Server is based on the [Model Context Protocol (MCP)](https://modelcontextprotocol.io/introduction) that allows one-click conversion of Markdown text to interactive mind maps, built on the open source project [markmap](https://github.com/markmap/markmap). The generated mind maps support rich interactive operations and can be exported in various image formats.\n\n> 🎉 **Explore More Mind Mapping Tools**\n>\n> Try [MarkXMind](https://github.com/jinzcdev/markxmind) - An online editor that creates complex mind maps using simple XMindMark syntax. It supports real-time preview, multi-format export (.xmind/.svg/.png), importing existing XMind files. [Try it now](https://markxmind.js.org/)!\n\n## Features\n\n- 🌠 **Markdown to Mind Map**: Convert Markdown text to interactive mind maps\n- 🖼️ **Multi-format Export**: Support for exporting as PNG, JPG, and SVG images\n- 🔄 **Interactive Operations**: Support for zooming, expanding/collapsing nodes, and other interactive features\n- 📋 **Markdown Copy**: One-click copy of the original Markdown content\n- 🌐 **Automatic Browser Preview**: Option to automatically open generated mind maps in the browser\n\n## Prerequisites\n\n1. Node.js (v20 or above)\n\n## Installation\n\n### Installing via Smithery\n\nTo install Markmap MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@jinzcdev/markmap-mcp-server):\n\n```bash\nnpx -y @smithery/cli install @jinzcdev/markmap-mcp-server --client claude\n```\n\n### Manual Installation\n\n```bash\n# Install from npm\nnpm install @jinzcdev/markmap-mcp-server -g\n\n# Basic run\nnpx -y @jinzcdev/markmap-mcp-server\n\n# Specify output directory\nnpx -y @jinzcdev/markmap-mcp-server --output /path/to/output/directory\n```\n\nAlternatively, you can clone the repository and run locally:\n\n```bash\n# Clone the repository\ngit clone https://github.com/jinzcdev/markmap-mcp-server.git\n\n# Navigate to the project directory\ncd markmap-mcp-server\n\n# Build project\nnpm install && npm run build\n\n# Run the server\nnode build/index.js\n```\n\n## Usage\n\nAdd the following configuration to your MCP client configuration file:\n\n```json\n{\n  \"mcpServers\": {\n    \"markmap\": {\n      \"type\": \"stdio\",\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@jinzcdev/markmap-mcp-server\"],\n      \"env\": {\n        \"MARKMAP_DIR\": \"/path/to/output/directory\"\n      }\n    }\n  }\n}\n```\n\n> [!TIP]\n>\n> The service supports the following environment variables:\n>\n> - `MARKMAP_DIR`: Specify the output directory for mind maps (optional, defaults to system temp directory)\n>\n> **Priority Note**:\n>\n> When both the `--output` command line argument and the `MARKMAP_DIR` environment variable are specified, the command line argument takes precedence.\n\n## Available Tools\n\n### markdown-to-mindmap\n\nConvert Markdown text into an interactive mind map.\n\n**Parameters:**\n\n- `markdown`: The Markdown content to convert (required string)\n- `open`: Whether to automatically open the generated mind map in the browser (optional boolean, default is false)\n\n**Return Value:**\n\n```json\n{\n  \"content\": [\n    {\n      \"type\": \"text\",\n      \"text\": \"JSON_DATA_OF_MINDMAP_FILEPATH\"\n    }\n  ]\n}\n```\n\n## License\n\nThis project is licensed under the [MIT](./LICENSE) License.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "markdown",
        "markmap",
        "mcp",
        "jinzcdev markmap",
        "markmap mcp",
        "converts markdown"
      ],
      "category": "document-processing"
    },
    "jjgordon89--document-qa": {
      "owner": "jjgordon89",
      "name": "document-qa",
      "url": "https://github.com/jjgordon89/document-qa",
      "imageUrl": "/freedevtools/mcp/pfp/jjgordon89.webp",
      "description": "A Streamlit app for answering questions about uploaded documents using GPT-3.5, enabling users to extract information quickly and efficiently. Ideal for enhancing productivity in document analysis.",
      "stars": 0,
      "forks": 0,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-03-07T03:57:02Z",
      "readme_content": "# 📄 Document question answering template\n\nA simple Streamlit app that answers questions about an uploaded document via OpenAI's GPT-3.5.\n\n[![Open in Streamlit](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://document-question-answering-template.streamlit.app/)\n\n### How to run it on your own machine\n\n1. Install the requirements\n\n   ```\n   $ pip install -r requirements.txt\n   ```\n\n2. Run the app\n\n   ```\n   $ streamlit run streamlit_app.py\n   ```\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "document",
        "documents",
        "streamlit",
        "document processing",
        "document analysis",
        "qa streamlit"
      ],
      "category": "document-processing"
    },
    "jkawamoto--mcp-youtube-transcript": {
      "owner": "jkawamoto",
      "name": "mcp-youtube-transcript",
      "url": "https://github.com/jkawamoto/mcp-youtube-transcript",
      "imageUrl": "/freedevtools/mcp/pfp/jkawamoto.webp",
      "description": "Retrieve transcripts from YouTube videos.",
      "stars": 85,
      "forks": 30,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-02T01:58:53Z",
      "readme_content": "# YouTube Transcript MCP Server\n[![Python Application](https://github.com/jkawamoto/mcp-youtube-transcript/actions/workflows/python-app.yaml/badge.svg)](https://github.com/jkawamoto/mcp-youtube-transcript/actions/workflows/python-app.yaml)\n[![GitHub License](https://img.shields.io/github/license/jkawamoto/mcp-youtube-transcript)](https://github.com/jkawamoto/mcp-youtube-transcript/blob/main/LICENSE)\n[![pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit)](https://github.com/pre-commit/pre-commit)\n[![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json)](https://github.com/astral-sh/ruff)\n[![smithery badge](https://smithery.ai/badge/@jkawamoto/mcp-youtube-transcript)](https://smithery.ai/server/@jkawamoto/mcp-youtube-transcript)\n[![Dockerhub](https://img.shields.io/badge/Docker-mcp%2Fyoutube--transcript-blue.svg)](https://hub.docker.com/mcp/server/youtube_transcript)\n\nThis MCP server retrieves transcripts for given YouTube video URLs.\n\n<a href=\"https://glama.ai/mcp/servers/of3kwtmlqp\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/of3kwtmlqp/badge\" alt=\"YouTube Transcript Server MCP server\" /></a>\n\n## Tools\nThis MCP server provides the following tools:\n\n### `get_transcript`\nFetches the transcript of a specified YouTube video.\n\n#### Parameters\n- **url** *(string)*: The full URL of the YouTube video. This field is required.\n- **lang** *(string, optional)*: The desired language for the transcript. Defaults to `en` if not specified.\n- **next_cursor** *(string, optional)*: Cursor to retrieve the next page of the transcript.\n\n### `get_timed_transcript`\nFetches the transcript of a specified YouTube video with timestamps..\n\n#### Parameters\n- **url** *(string)*: The full URL of the YouTube video. This field is required.\n- **lang** *(string, optional)*: The desired language for the transcript. Defaults to `en` if not specified.\n- **next_cursor** *(string, optional)*: Cursor to retrieve the next page of the transcript.\n\n### `get_video_info`\nFetches the metadata of a specified YouTube video.\n\n#### Parameters\n- **url** *(string)*: The full URL of the YouTube video. This field is required.\n\n## Installation\n> [!NOTE]\n> You'll need [`uv`](https://docs.astral.sh/uv) installed on your system to use `uvx` command.\n\n### For codename goose\nPlease refer to this tutorial for detailed installation instructions:\n[YouTube Transcript Extension](https://block.github.io/goose/docs/mcp/youtube-transcript-mcp).\n\n### For Claude Desktop\n\nDownload the latest MCP bundle `mcp-youtube-transcript.mcpb` from\nthe [Releases](https://github.com/jkawamoto/mcp-youtube-transcript/releases) page,\nthen open the downloaded `.mcpb `file or drag it into the Claude Desktop's Settings window.\n\nYou can also manually configure this server for Claude Desktop.\nEdit the `claude_desktop_config.json` file by adding the following entry under\n`mcpServers`:\n\n```json\n{\n  \"mcpServers\": {\n    \"youtube-transcript\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"--from\",\n        \"git+https://github.com/jkawamoto/mcp-youtube-transcript\",\n        \"mcp-youtube-transcript\"\n      ]\n    }\n  }\n}\n```\nAfter editing, restart the application.\nFor more information,\nsee: [For Claude Desktop Users - Model Context Protocol](https://modelcontextprotocol.io/quickstart/user).\n\n### For LM Studio\nTo configure this server for LM Studio, click the button below.\n\n[![Add MCP Server youtube-transcript to LM Studio](https://files.lmstudio.ai/deeplink/mcp-install-light.svg)](https://lmstudio.ai/install-mcp?name=youtube-transcript&config=eyJjb21tYW5kIjoidXZ4IiwiYXJncyI6WyItLWZyb20iLCJnaXQraHR0cHM6Ly9naXRodWIuY29tL2prYXdhbW90by9tY3AteW91dHViZS10cmFuc2NyaXB0IiwibWNwLXlvdXR1YmUtdHJhbnNjcmlwdCJdfQ%3D%3D)\n\n### Using Docker\n\nA Docker image for this server is available on [Docker Hub](https://hub.docker.com/mcp/server/youtube_transcript/).\nPlease refer to the Docker Hub page for detailed usage instructions and documentation.\n\n### Installing via Smithery\n> [!NOTE]\n> When using this method, you will be using servers hosted by Smithery.\n> Requests and responses will be routed through their servers.\n> Please refer to the [Smithery Privacy Notice](https://smithery.ai/privacy) for information\n> about their data handling practices.\n\nThe [Smithery CLI](https://github.com/smithery-ai/cli) enables the installation of MCP servers on various clients.\n\nFor instance, to install this server for Claude Desktop, execute the following command:\n\n```bash\nnpx -y @smithery/cli install @jkawamoto/mcp-youtube-transcript --client claude\n```\n\nTo view the list of clients supported by the Smithery CLI, use this command:\n\n```bash\nnpx -y @smithery/cli list clients\n```\n\nRefer to the [Smithery CLI documentation](https://github.com/smithery-ai/cli) for additional details.\n\n## Response Pagination\nWhen retrieving transcripts for longer videos, the content may exceed the token size limits of the LLM.\nTo avoid this issue, this server splits transcripts that exceed 50,000 characters.\nIf a transcript is split, the response will include a `next_cursor`.\nTo retrieve the next part, include this `next_cursor` value in your request.\n\nThe token size limits vary depending on the LLM and language you are using.\nIf you need to split responses into smaller chunks,\nyou can adjust this using the `--response-limit` command line argument.\nFor example, the configuration below splits responses to contain no more than 15,000 characters each:\n\n```json\n{\n  \"mcpServers\": {\n    \"youtube-transcript\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"--from\",\n        \"git+https://github.com/jkawamoto/mcp-youtube-transcript\",\n        \"mcp-youtube-transcript\",\n        \"--response-limit\",\n        \"15000\"\n      ]\n    }\n  }\n}\n```\n\n## Using Proxy Servers\nIn environments where access to YouTube is restricted, you can use proxy servers.\n\nWhen using [Webshare](https://www.webshare.io/), set the username and password for the Residential Proxy using either\nthe environment variables `WEBSHARE_PROXY_USERNAME` and `WEBSHARE_PROXY_PASSWORD`,\nor the command line arguments `--webshare-proxy-username` and `--webshare-proxy-password`.\n\nWhen using other proxy servers, set the proxy server URL using either the environment variables `HTTP_PROXY` or\n`HTTPS_PROXY`, or the command line arguments `--http-proxy` or `--https-proxy`.\n\nFor more details, please visit:\n[Working around IP bans - YouTube Transcript API](https://github.com/jdepoix/youtube-transcript-api?tab=readme-ov-file#working-around-ip-bans-requestblocked-or-ipblocked-exception).\n\n## License\n\nThis application is licensed under the MIT License. See the [LICENSE](LICENSE) file for more details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "transcripts",
        "transcript",
        "jkawamoto",
        "transcripts youtube",
        "youtube transcript",
        "retrieve transcripts"
      ],
      "category": "document-processing"
    },
    "jkf87--hwp-mcp": {
      "owner": "jkf87",
      "name": "hwp-mcp",
      "url": "https://github.com/jkf87/hwp-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/jkf87.webp",
      "description": "Control and manage HWP (Hangul Word Processor) documents by creating, editing, and automating tasks through AI models. It offers features like text editing, table manipulation, and batch processing of documents.",
      "stars": 159,
      "forks": 38,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-09-28T09:37:48Z",
      "readme_content": "# HWP-MCP (한글 Model Context Protocol)\n\n[![GitHub](https://img.shields.io/github/license/jkf87/hwp-mcp)](https://github.com/jkf87/hwp-mcp)\n\nHWP-MCP는 한글 워드 프로세서(HWP)를 Claude와 같은 AI 모델이 제어할 수 있도록 해주는 Model Context Protocol(MCP) 서버입니다. 이 프로젝트는 한글 문서를 자동으로 생성, 편집, 조작하는 기능을 AI에게 제공합니다.\n\n## 주요 기능\n\n- 문서 생성 및 관리: 새 문서 생성, 열기, 저장 기능\n- 텍스트 편집: 텍스트 삽입, 글꼴 설정, 단락 추가\n- 테이블 작업: 테이블 생성, 데이터 채우기, 셀 내용 설정\n- 완성된 문서 생성: 템플릿 기반 보고서 및 편지 자동 생성\n- 일괄 작업: 여러 작업을 한 번에 실행하는 배치 기능\n\n## 시스템 요구사항\n\n- Windows 운영체제\n- 한글(HWP) 프로그램 설치\n- Python 3.7 이상\n- 필수 Python 패키지 (requirements.txt 참조)\n\n## 설치 방법\n\n1. 저장소 클론:\n```bash\ngit clone https://github.com/jkf87/hwp-mcp.git\ncd hwp-mcp\n```\n\n2. 의존성 설치:\n```bash\npip install -r requirements.txt\n```\n\n3. (선택사항) MCP 패키지 설치:\n```bash\npip install mcp\n```\n\n## 사용 방법\n\n### Claude와 함께 사용하기\n\nClaude 데스크톱 설정 파일에 다음과 같이 HWP-MCP 서버를 등록하세요:\n\n```json\n{\n  \"mcpServers\": {\n    \"hwp\": {\n      \"command\": \"python\",\n      \"args\": [\"경로/hwp-mcp/hwp_mcp_stdio_server.py\"]\n    }\n  }\n}\n```\n\n### 주요 기능 예시\n\n#### 새 문서 생성\n```python\nhwp_create()\n```\n\n#### 텍스트 삽입\n```python\nhwp_insert_text(\"원하는 텍스트를 입력하세요.\")\n```\n\n#### 테이블 생성 및 데이터 입력\n```python\n# 테이블 생성\nhwp_insert_table(rows=5, cols=2)\n\n# 테이블에 데이터 채우기\nhwp_fill_table_with_data([\n    [\"월\", \"판매량\"], \n    [\"1월\", \"120\"], \n    [\"2월\", \"150\"], \n    [\"3월\", \"180\"], \n    [\"4월\", \"200\"]\n], has_header=True)\n\n# 표에 연속된 숫자 채우기\nhwp_fill_column_numbers(start=1, end=10, column=1, from_first_cell=True)\n```\n\n#### 문서 저장\n```python\nhwp_save(\"경로/문서명.hwp\")\n```\n\n#### 일괄 작업 예시\n```python\nhwp_batch_operations([\n    {\"operation\": \"hwp_create\"},\n    {\"operation\": \"hwp_insert_text\", \"params\": {\"text\": \"제목\"}},\n    {\"operation\": \"hwp_set_font\", \"params\": {\"size\": 20, \"bold\": True}},\n    {\"operation\": \"hwp_save\", \"params\": {\"path\": \"경로/문서명.hwp\"}}\n])\n```\n\n## 프로젝트 구조\n\n```\nhwp-mcp/\n├── hwp_mcp_stdio_server.py  # 메인 서버 스크립트\n├── requirements.txt         # 의존성 패키지 목록\n├── hwp-mcp-구조설명.md       # 프로젝트 구조 설명 문서\n├── src/\n│   ├── tools/\n│   │   ├── hwp_controller.py  # 한글 제어 핵심 컨트롤러\n│   │   └── hwp_table_tools.py # 테이블 관련 기능 전문 모듈\n│   ├── utils/                 # 유틸리티 함수\n│   └── __tests__/             # 테스트 모듈\n└── security_module/\n    └── FilePathCheckerModuleExample.dll  # 보안 모듈\n```\n\n## 트러블슈팅\n\n### 보안 모듈 관련 문제\n기본적으로 한글 프로그램은 외부에서 파일 접근 시 보안 경고를 표시합니다. 이를 우회하기 위해 `FilePathCheckerModuleExample.dll` 모듈을 사용합니다. 만약 보안 모듈 등록에 실패해도 기능은 작동하지만, 파일 열기/저장 시 보안 대화 상자가 표시될 수 있습니다.\n\n### 한글 연결 실패\n한글 프로그램이 실행 중이지 않을 경우 연결에 실패할 수 있습니다. 한글 프로그램이 설치되어 있고 정상 작동하는지 확인하세요.\n\n### 테이블 데이터 입력 문제\n테이블에 데이터를 입력할 때 커서 위치가 예상과 다르게 동작하는 경우가 있었으나, 현재 버전에서는 이 문제가 해결되었습니다. 테이블의 모든 셀에 정확하게 데이터가 입력됩니다.\n\n## 변경 로그\n\n### 2025-03-27\n- 표 생성 및 데이터 채우기 기능 개선\n  - 표 안에 표가 중첩되는 문제 해결\n  - 표 생성과 데이터 채우기 기능 분리\n  - 표 생성 전 현재 커서 위치 확인 로직 추가\n  - 기존 표에 데이터만 채우는 기능 개선\n- 프로젝트 관리 개선\n  - .gitignore 파일 추가 (임시 파일, 캐시 파일 등 제외)\n\n### 2025-03-25\n- 테이블 데이터 입력 기능 개선\n  - 첫 번째 셀부터 정확하게 데이터 입력 가능\n  - 셀 선택 및 커서 위치 설정 로직 개선\n  - 텍스트 입력 시 커서 위치 유지 기능 추가\n- 테이블 전용 도구 모듈(`hwp_table_tools.py`) 추가\n- `hwp_fill_column_numbers` 함수에 `from_first_cell` 옵션 추가\n\n## 라이선스\n\n이 프로젝트는 MIT 라이선스에 따라 배포됩니다. 자세한 내용은 [LICENSE](LICENSE) 파일을 참조하세요.\n\n## 기여 방법\n\n1. 이슈 제보 또는 기능 제안: GitHub 이슈를 사용하세요.\n2. 코드 기여: 변경사항을 포함한 Pull Request를 제출하세요.\n\n## 관련 프로젝트\n\n- [HWP SDK](https://www.hancom.com/product/sdk): 한글과컴퓨터의 공식 SDK\n- [Cursor MCP](https://docs.cursor.com/context/model-context-protocol#configuration-locations)\n- [Smithery](https://smithery.ai/server/@jkf87/hwp-mcp)\n\n## 연락처\n\n프로젝트 관련 문의는 GitHub 이슈, [코난쌤](https://www.youtube.com/@conanssam)를 통해 해주세요. \n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "hangul",
        "processing",
        "editing",
        "hwp hangul",
        "document processing",
        "word processor"
      ],
      "category": "document-processing"
    },
    "jlmelis--sanity-mcp-server": {
      "owner": "jlmelis",
      "name": "sanity-mcp-server",
      "url": "https://github.com/jlmelis/sanity-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/jlmelis.webp",
      "description": "Manage Sanity.io content by creating, editing, and listing documents within an LLM interface, facilitating smooth content workflow and integration with Claude Desktop.",
      "stars": 1,
      "forks": 2,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-06-30T03:48:47Z",
      "readme_content": "# Sanity MCP Server\n\nThis MCP server provides tools for interacting with Sanity.io content from Claude Desktop.\n\n## Installation\n\n1. Clone this repository\n2. Install dependencies:\n```bash\nnpm install\n```\n\n3. Create a `.env` file with your Sanity credentials:\n```\nSANITY_PROJECT_ID=your_project_id\nSANITY_DATASET=your_dataset\nSANITY_TOKEN=your_token\n```\n\n## Usage with Claude Desktop\n\n1. In Claude Desktop, go to Settings > MCP Servers\n2. Add a new server with these settings:\n```json\n{\n  \"command\": \"node\",\n  \"args\": [\"src/sanity-mcp-server.ts\"],\n  \"env\": {\n    \"SANITY_PROJECT_ID\": \"your_project_id\",\n    \"SANITY_DATASET\": \"your_dataset\", \n    \"SANITY_TOKEN\": \"your_token\"\n  }\n}\n```\n\n## Available Tools\n\n### Create Document\nCreates a new document in Sanity\n\n**Parameters:**\n- `type`: Document type\n- `content`: Document content\n\n**Example:**\n```json\n{\n  \"type\": \"post\",\n  \"content\": {\n    \"title\": \"My Post\",\n    \"body\": [\n      {\n        \"_type\": \"block\",\n        \"children\": [\n          {\n            \"_type\": \"span\",\n            \"text\": \"Hello world!\"\n          }\n        ]\n      }\n    ]\n  }\n}\n```\n\n### Edit Document\nEdits an existing document\n\n**Parameters:**\n- `id`: Document ID\n- `content`: Updated content\n\n### List Documents\nLists documents of a specific type\n\n**Parameters:**\n- `type`: Document type\n- `limit`: Maximum number of documents to return (default: 10)\n\n### Get Schema\nGets a schema template based on an existing document\n\n**Note:** For best results, manually create at least one document of each type before using this tool.\n\n**Parameters:**\n- `type`: Document type\n\n## Example Usage\n\n1. Create a new blog post:\n```json\n{\n  \"tool\": \"create-document\",\n  \"arguments\": {\n    \"type\": \"post\",\n    \"content\": {\n      \"title\": \"My First Post\",\n      \"slug\": \"my-first-post\",\n      \"body\": [\n        {\n          \"_type\": \"block\",\n          \"children\": [\n            {\n              \"_type\": \"span\",\n              \"text\": \"This is my first post!\"\n            }\n          ]\n        }\n      ]\n    }\n  }\n}\n```\n\n2. Edit an existing post:\n```json\n{\n  \"tool\": \"edit-document\",\n  \"arguments\": {\n    \"id\": \"post-id-123\",\n    \"content\": {\n      \"title\": \"Updated Title\"\n    }\n  }\n}\n```\n\n3. List recent posts:\n```json\n{\n  \"tool\": \"list-documents\",\n  \"arguments\": {\n    \"type\": \"post\",\n    \"limit\": 5\n  }\n}\n```\n\n4. Get schema for posts:\n```json\n{\n  \"tool\": \"get-schema\",\n  \"arguments\": {\n    \"type\": \"post\"\n  }\n}\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "jlmelis",
        "sanity",
        "document",
        "jlmelis sanity",
        "manage sanity",
        "processing jlmelis"
      ],
      "category": "document-processing"
    },
    "jmanhype--dart-mcp-server": {
      "owner": "jmanhype",
      "name": "dart-mcp-server",
      "url": "https://github.com/jmanhype/dart-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/jmanhype.webp",
      "description": "Manage tasks, documents, and workspaces seamlessly with capabilities for task creation, updates, priority settings, and team assignments, along with document handling features.",
      "stars": 5,
      "forks": 4,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-13T23:26:47Z",
      "readme_content": "# Dart MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@jmanhype/dart-mcp-server)](https://smithery.ai/server/@jmanhype/dart-mcp-server)\n\nA Model Context Protocol (MCP) server implementation for Dart, providing task management, document handling, and workspace organization capabilities through MCP tools.\n\n<a href=\"https://glama.ai/mcp/servers/2pdqgspm4q\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/2pdqgspm4q/badge\" alt=\"Dart Server MCP server\" />\n</a>\n\n## Prerequisites\n\n- Node.js 16.x or higher\n- Python 3.8 or higher\n- Dart Python SDK installed (`pip install dart-sdk`)\n- A valid Dart API token\n\n## Features\n\n- Task Management\n  - Create and update tasks\n  - Set task priorities and status\n  - Assign tasks to team members\n- Document Management\n  - Create and organize documents\n  - Support for markdown content\n  - Report generation\n- Space Management\n  - Create and manage workspaces\n  - Organize content with folders\n  - Control access permissions\n- Dartboard Integration\n  - Default status management\n  - Task organization\n  - Team collaboration\n\n## Installation\n\n### Installing via Smithery\n\nTo install Dart MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@jmanhype/dart-mcp-server):\n\n```bash\nnpx -y @smithery/cli install @jmanhype/dart-mcp-server --client claude\n```\n\n### Manual Installation\n1. Clone the repository:\n```bash\ngit clone https://github.com/jmanhype/dart-mcp-server.git\ncd dart-mcp-server\n```\n\n2. Install Node.js dependencies:\n```bash\nnpm install\n```\n\n3. Set up Python environment and install Dart SDK:\n```bash\n# Create and activate virtual environment\npython -m venv .venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n\n# Install Dart SDK\npip install dart-sdk\n```\n\n4. Set up environment variables:\n```bash\n# Copy example environment file\ncp .env.example .env\n\n# Edit .env with your configuration\n# Required: DART_TOKEN\n# Optional: PYTHONPATH (path to dart sdk)\n```\n\n## Usage\n\n1. Build the TypeScript code:\n```bash\nnpm run build\n```\n\n2. Start the MCP server:\n```bash\nnpm start\n```\n\n## Development\n\n```bash\n# Watch for TypeScript changes\nnpm run dev\n\n# Run tests\nnpm test\n```\n\n## Environment Variables\n\nCreate a `.env` file with the following variables:\n\n```env\n# Required: Your Dart API token\nDART_TOKEN=your_dart_token_here\n\n# Optional: Path to your Dart SDK installation\nPYTHONPATH=/path/to/dart/sdk\n\n# Optional: Python executable path (defaults to system Python)\nPYTHON_PATH=/path/to/python\n```\n\n## Available MCP Tools\n\n- `create_task`: Create new tasks with title, description, priority, etc.\n- `update_task`: Update existing tasks' status, title, description\n- `get_default_status`: Get default status DUIDs\n- `get_default_space`: Get default space DUID\n- `get_dartboards`: List available dartboards\n- `get_folders`: List folders in a space\n- `create_folder`: Create new folders\n- `create_doc`: Create new documents or reports\n- `create_space`: Create new workspaces\n- `delete_space`: Delete existing workspaces\n\n## Troubleshooting\n\nIf you encounter issues:\n\n1. Verify Python environment:\n   ```bash\n   python --version\n   pip list | grep dart\n   ```\n\n2. Check Dart SDK installation:\n   ```python\n   python -c \"import dart; print(dart.__version__)\"\n   ```\n\n3. Verify environment variables:\n   ```bash\n   echo $DART_TOKEN\n   echo $PYTHONPATH\n   ```\n\n## License\n\nMIT License \n\n# Dart Tools\n\nPyPI Supported Python Versions License \n\nDart is Project Management powered by AI.\n\n`dart-tools` is the Dart CLI and Python Library. It enables direct integration with Dart through a terminal CLI or through Python.\n\n* Installation\n* Using the CLI\n* Using the Python Library\n* Using the Python Library in AWS Lambda Functions\n* Using the MCP Server\n* Advanced Usage\n* Help and Resources\n* Contributing\n* License\n\n## Installation\n\nIn the terminal, install by running\n\n```bash\npip install dart-tools\n```\n\n## Using the CLI\n\nStart off by setting up authentication with\n\n```bash\ndart login\n```\n\nThen, you can create a new task with a command along the lines of\n\n```bash\ndart createtask \"Update the landing page\" -p0 --tag marketing\n```\n\nwhich will make a new task called 'Update the landing page' with priority 'Critical' (i.e. P0) and with the 'marketing' tag.\n\nYou can explore all of these options and many more with `dart --help` or the more specific help for subcommands, in this case `dart createtask --help`.\n\nAnother common workflow is to updating a preexisting task. To do this, run something like\n\n```bash\ndart updatetask [DUID] -s Done\n```\n\nThis command will mark the referenced task 'Done'. Here `[DUID]` is meant to be replaced (including the brackets) with the 'Dart ID' of an existing task. You can get a DUID from any existing task in a number of ways, such as by copying it from the end of a task's URL or by clicking the '...' button in a task page in Dart and then choosing 'Copy ID'.\n\n## Using the Python Library\n\nFirst, set up authentication. Run `dart login` in the terminal for an interactive process, or visit your Dart profile and then run `dart.login(token)` or save the token into the `DART_TOKEN` environment variable.\n\nThen, you can run something like\n\n```python\nimport os\nfrom dart import create_task, is_logged_in, update_task\n\n# Check that auth is set up and stop if not, can remove this once everything is set up\nis_logged_in(should_raise=True)\n\n# Create a new task called 'Update the landing page' with priority 'Critical' (i.e. p0) and with the 'marketing' tag\nnew_task = create_task(\n    \"Update the landing page\", priority_int=0, tag_titles=[\"marketing\"]\n)\n\n# Update the task to be 'Done'\nupdate_task(new_task.duid, status_title=\"Done\")\n```\n\n## Using the MCP Server\n\nThe Model Context Protocol (MCP) server implementation enables AI assistants (like Claude) to interact with Dart through standardized tools. This allows for seamless integration of AI capabilities with Dart's task management system.\n\n### Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/its-dart/dart-tools.git\ncd dart-tools/dart/mcp\n\n# Install dependencies\nnpm install\n\n# Set up Python environment\npython -m venv .venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\npip install dart-tools\n\n# Configure environment\ncp .env.example .env\n# Edit .env with your DART_TOKEN\n```\n\n### Available MCP Tools\n\nThe server provides these MCP tools:\n- Task Management (create/update tasks)\n- Document Management (create/organize docs)\n- Space Management (workspaces/folders)\n- Dartboard Integration\n\nFor detailed documentation, see [MCP Server README](dart/mcp/README.md).\n\n## Advanced Usage\n\nAlmost anything that can be done in Dart can be done with the Python library, but there are not convenient wrapper functions for everything. For most advanced usage, the best thing to do is to get in touch with us and we can help.\n\nHowever, if you want to explore on your own, the client is well-typed, so you can simply explore the code to see what is possible. All updates will go through the the `dart.transact` function.\n\nAs an example, you could run something akin to `update_task` with\n\n```python\nfrom dart import (\n    Dart,\n    Operation,\n    OperationKind,\n    OperationModelKind,\n    TaskUpdate,\n    TransactionKind,\n)\n\n# Initialize the inner client\ndart = Dart()\n\n# Prepare the update operation\ntask_update = TaskUpdate(\n    duid=\"[DUID]\",\n    size=5,\n)\ntask_update_op = Operation(\n    model=OperationModelKind.TASK,\n    kind=OperationKind.UPDATE,\n    data=task_update,\n)\n\n# Call the operation transactionally to perform the update\nresponse = dart.transact([task_update_op], TransactionKind.TASK_UPDATE)\n```\n\n## Help and Resources\n\n* Homepage\n* Web App\n* Help Center\n* Bugs and Features\n* Library Source\n* Chat on Discord\n* Email us at support@itsdart.com\n\n## Contributing\n\nContributions are welcome! Please open an issue or submit a pull request.\n\n## License\n\nThis project is licensed under the MIT License. ",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "dart",
        "tasks",
        "document",
        "dart mcp",
        "tasks documents",
        "jmanhype dart"
      ],
      "category": "document-processing"
    },
    "jmh108--MCP-server-readability-python": {
      "owner": "jmh108",
      "name": "MCP-server-readability-python",
      "url": "https://github.com/jmh108/MCP-server-readability-python",
      "imageUrl": "/freedevtools/mcp/pfp/jmh108.webp",
      "description": "Extracts and transforms webpage content into clean, LLM-optimized Markdown, removing ads and non-essential elements for improved readability and processing by language models.",
      "stars": 3,
      "forks": 3,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-29T05:37:20Z",
      "readme_content": "# MCP Server Readability Parser (Python / FastMCP)\n\n## Credits/Reference\nThis project is based on the original [server-moz-readability](https://github.com/emzimmer/server-moz-readability) implementation of [emzimmer](https://github.com/emzimmer). (For the original README documentation, please refer to the [original README.md](https://github.com/emzimmer/server-moz-readability/blob/main/readme.md).)\n\nThis Python implementation adapts the original concept to run as python based MCP using [FastMCP](https://github.com/jlowin/fastmcp)\n\n\n\n# Mozilla Readability Parser MCP Server\n\nA Python implementation of the [Model Context Protocol (MCP)](https://github.com/modelcontextprotocol) server that extracts and transforms webpage content into clean, LLM-optimized Markdown.\n\n## Table of Contents\n- [Features](#features)\n- [Why Not Just Fetch?](#why-not-just-fetch)\n- [Installation](#installation)\n- [Quick Start](#quick-start)\n- [Tool Reference](#tool-reference)\n- [Dependencies](#dependencies)\n- [License](#license)\n\n## Features\n- Removes ads, navigation, footers and other non-essential content\n- Converts clean HTML into well-formatted Markdown\n- Handles errors gracefully\n- Optimized for LLM processing\n- Lightweight and fast\n\n## Why Not Just Fetch?\nUnlike simple fetch requests, this server:\n- Extracts only relevant content using Readability algorithm\n- Eliminates noise like ads, popups, and navigation menus\n- Reduces token usage by removing unnecessary HTML/CSS\n- Provides consistent Markdown formatting for better LLM processing\n- Handles complex web pages with dynamic content\n\n## Installation\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/jmh108/MCP-server-readability-python.git\ncd MCP-server-readability-python\n```\n\n2. Create and activate a virtual environment:\n```bash\npython -m venv venv\nsource venv/bin/activate  # On Windows use: venv\\Scripts\\activate\n```\n\n3. Install dependencies:\n```bash\npip install -r requirements.txt\n```\n\n## Quick Start\n\n1. Start the server:\n```bash\nfastmcp run server.py\n```\n\n2. Example request:\n```bash\ncurl -X POST http://localhost:8000/tools/extract_content \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"url\": \"https://example.com/article\"}'\n```\n\n## Tool Reference\n\n### `extract_content`\nFetches and transforms webpage content into clean Markdown.\n\n**Arguments:**\n```json\n{\n  \"url\": {\n    \"type\": \"string\",\n    \"description\": \"The website URL to parse\",\n    \"required\": true\n  }\n}\n```\n\n**Returns:**\n```json\n{\n  \"content\": \"Markdown content...\"\n}\n```\n\n## MCP Server Configuration\n\nTo configure the MCP server, add the following to your MCP settings file:\n\n```json\n{\n  \"mcpServers\": {\n    \"readability\": {\n      \"command\": \"fastmcp\",\n      \"args\": [\"run\", \"server.py\"],\n      \"env\": {}\n    }\n  }\n}\n```\n\nThe server can then be started using the MCP protocol and accessed via the `parse` tool.\n\n## Dependencies\n- [readability-lxml](https://github.com/buriy/python-readability) - Content extraction\n- [html2text](https://github.com/Alir3z4/html2text) - HTML to Markdown conversion\n- [beautifulsoup4](https://www.crummy.com/software/BeautifulSoup/) - DOM parsing\n- [requests](https://docs.python-requests.org/) - HTTP requests\n\n## License\nMIT License - See [LICENSE](LICENSE) for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "markdown",
        "webpage",
        "python",
        "processing jmh108",
        "document processing",
        "optimized markdown"
      ],
      "category": "document-processing"
    },
    "jmh108--md-webcrawl-mcp": {
      "owner": "jmh108",
      "name": "md-webcrawl-mcp",
      "url": "https://github.com/jmh108/md-webcrawl-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/jmh108.webp",
      "description": "Extracts website content and saves it as markdown files while mapping website structures and links efficiently, enabling batch processing of multiple URLs.",
      "stars": 3,
      "forks": 5,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-07-19T18:57:32Z",
      "readme_content": "# MD MCP Webcrawler Project\n\nA Python-based MCP (https://modelcontextprotocol.io/introduction) web crawler for extracting and saving website content. \n\n## Features\n- Extract website content and save as markdown files\n- Map website structure and links\n- Batch processing of multiple URLs\n- Configurable output directory\n\n## Installation\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/yourusername/webcrawler.git\ncd webcrawler\n```\n\n2. Install dependencies:\n```bash\npip install -r requirements.txt\n```\n\n3. Optional: Configure environment variables:\n```bash\nexport OUTPUT_PATH=./output  # Set your preferred output directory\n```\n\n## Output\nCrawled content is saved in markdown format in the specified output directory.\n\n## Configuration\nThe server can be configured through environment variables:\n\n- `OUTPUT_PATH`: Default output directory for saved files\n- `MAX_CONCURRENT_REQUESTS`: Maximum parallel requests (default: 5)\n- `REQUEST_TIMEOUT`: Request timeout in seconds (default: 30)\n\n## Claude Set-Up\nInstall with FastMCP \n``` fastmcp install server.py ```\n\nor user custom settings to run with fastmcp directly\n\n````\n\"Crawl Server\": {\n      \"command\": \"fastmcp\",\n      \"args\": [\n        \"run\",\n        \"/Users/mm22/Dev_Projekte/servers-main/src/Webcrawler/server.py\"\n      ],\n      \"env\": {\n        \"OUTPUT_PATH\": \"/Users/user/Webcrawl\"\n      }\n```` \n\n\n\n## Development\n\n### Live Development\n```bash\nfastmcp dev server.py --with-editable .\n```\n### Debug \nIt helps to use https://modelcontextprotocol.io/docs/tools/inspector for debugging\n\n## Examples\n\n### Example 1: Extract and Save Content\n```bash\nmcp call extract_content --url \"https://example.com\" --output_path \"example.md\"\n```\n\n### Example 2: Create Content Index\n```bash\nmcp call scan_linked_content --url \"https://example.com\" | \\\n  mcp call create_index --content_map - --output_path \"index.md\"\n```\n\n## Contributing\n1. Fork the repository\n2. Create a feature branch (`git checkout -b feature/AmazingFeature`)\n3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)\n4. Push to the branch (`git push origin feature/AmazingFeature`)\n5. Open a Pull Request\n\n## License\n\nDistributed under the MIT License. See `LICENSE` for more information.\n\n## Requirements\n\n- Python 3.7+\n- FastMCP (uv pip install fastmcp)\n- Dependencies listed in requirements.txt\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "webcrawl",
        "markdown",
        "urls",
        "md webcrawl",
        "webcrawl mcp",
        "processing jmh108"
      ],
      "category": "document-processing"
    },
    "joaowinderfeldbussolotto--MCP-Websearch-Server": {
      "owner": "joaowinderfeldbussolotto",
      "name": "MCP-Websearch-Server",
      "url": "https://github.com/joaowinderfeldbussolotto/MCP-Websearch-Server",
      "imageUrl": "/freedevtools/mcp/pfp/joaowinderfeldbussolotto.webp",
      "description": "Fetches relevant documentation snippets from Langchain, Llama Index, and OpenAI to enhance search capabilities. Provides a simple tool to retrieve information based on user queries.",
      "stars": 0,
      "forks": 1,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-03-28T01:38:25Z",
      "readme_content": "## MPC Docs Server\n\nThis is a simple MCP (Model Context Protocol) server for retrieving information from the official documentation of Langchain, Llama Index, and OpenAI. It provides a tool that can be used by MCP-compatible applications to search and retrieve relevant documentation snippets.\n\n## Features\n\n-   **Documentation Retrieval:** Fetches content from the official documentation of Langchain, Llama Index, and OpenAI.\n-   **MCP Compatibility:** Implements an MCP server, allowing it to be easily integrated with other MCP-compatible applications.\n-   **Simple Tool:** Exposes a `get_docs` tool that accepts a query and library name, returning relevant documentation snippets.\n\n## How It Works\n\n```mermaid\ngraph LR\n    Client[MCP Client] -->|Calls tools| Server[MCP Server]\n    Server -->|Searches web for docs| Serper[Serper API]\n    Serper -->|Returns search results| Server\n    Server -->|Returns documentation| Client\n```\n\n## Getting Started\n\n### Installing uv Package Manager\n\n**On MacOS/Linux:**\n```bash\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n```\n\nMake sure to restart your terminal afterwards to ensure that the `uv` command gets picked up.\n\n### Project Setup\n\nCreate and initialize the project:\n```bash\n# Create a new directory for our project\nuv init mcp-server\ncd mcp-server\n\n# Create virtual environment and activate it\nuv venv\nsource .venv/bin/activate  # On Windows use: .venv\\Scripts\\activate\n\n# Install dependencies\nuv add \"mcp[cli]\" httpx python-dotenv bs4\n```\n\n\n### Environment Variables\n\nCreate a `.env` file in the root directory and add the following:\n\n```\nSERPER_API_KEY=YOUR_SERPER_API_KEY\n```\n\nYou'll need a SERPER API key to use the web search functionality. You can obtain one from [Serper.dev](https://serper.dev/). We are using the Serper API to search the web for relevant documentation.\n\n### Running the Server\n\nStart the MCP server:\n```bash\nuv run main.py\n```\n\nThe server will start and be ready to accept connections.\n\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "websearch",
        "search",
        "fetches",
        "mcp websearch",
        "websearch server",
        "index openai"
      ],
      "category": "document-processing"
    },
    "jonaolden--pbixray-mcp-server": {
      "owner": "jonaolden",
      "name": "pbixray-mcp-server",
      "url": "https://github.com/jonaolden/pbixray-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/jonaolden.webp",
      "description": "Load and analyze Power BI (.pbix) files, explore data models, and access metadata and query languages to enhance data analysis workflows.",
      "stars": 32,
      "forks": 8,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-30T10:52:12Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/jonaolden-pbixray-mcp-server-badge.png)](https://mseep.ai/app/jonaolden-pbixray-mcp-server)\n\n## Info! \nthose interested in this project might also be interested in\nthis follow-up project, [tabular-mcp](https://github.com/jonaolden/tabular-mcp), which allows running DAX queries against a local PowerBI model. \nsupport is highly appreciated !\n\n\n# PBIXRay MCP Server\n\nA [Model Context Protocol][mcp] (MCP) server for PBIXRay.\n\nThis MCP server exposes the capabilities of [PBIXRay](https://github.com/Hugoberry/pbixray) as tools and resources for LLM clients to interact with Power BI (.pbix) files.\n\n## Features\n\n- [x] Loading and analyzing PBIX files\n- [x] Data model exploration\n  - [x] Listing tables in the model\n  - [x] Retrieving model metadata\n  - [x] Checking model size\n  - [x] Getting model statistics\n  - [x] Getting comprehensive model summary\n- [x] Query language access\n  - [x] Viewing Power Query (M) code\n  - [x] Accessing M Parameters\n  - [x] Exploring DAX calculated tables\n  - [x] Viewing DAX measures\n  - [x] Examining DAX calculated columns\n- [x] Data structure analysis\n  - [x] Retrieving schema information\n  - [x] Analyzing table relationships\n  - [x] Accessing table contents with pagination\n\nThe list of tools is configurable, so you can choose which tools you want to make available to the MCP client.\nThis is useful if you don't use certain functionality or if you don't want to expose sensitive information.\n\n## Tools\n\n| Tool                  | Category  | Description                                                        |\n|-----------------------|-----------|--------------------------------------------------------------------|\n| `load_pbix_file`      | Core      | Load a Power BI (.pbix) file for analysis                          |\n| `get_tables`          | Model     | List all tables in the model                                       |\n| `get_metadata`        | Model     | Get metadata about the Power BI configuration                      |\n| `get_power_query`     | Query     | Display all M/Power Query code used for data transformation        |\n| `get_m_parameters`    | Query     | Display all M Parameters values                                    |\n| `get_model_size`      | Model     | Get the model size in bytes                                        |\n| `get_dax_tables`      | Query     | View DAX calculated tables                                         |\n| `get_dax_measures`    | Query     | Access DAX measures with filtering by table or measure name        |\n| `get_dax_columns`     | Query     | Access calculated column DAX expressions with filtering options    |\n| `get_schema`          | Structure | Get details about the data model schema and column types           |\n| `get_relationships`   | Structure | Get the details about the data model relationships                 |\n| `get_table_contents`  | Data      | Retrieve the contents of a specified table with pagination         |\n| `get_statistics`      | Model     | Get statistics about the model with optional filtering             |\n| `get_model_summary`   | Model     | Get a comprehensive summary of the current Power BI model          |\n\n## Usage\n\n## WSL (Recommended) \n\nAdd the server configuration to your client configuration file. For example, for Claude Desktop:\n\n```json\n{\n  \"mcpServers\": {\n    \"pbixray\": {\n      \"command\": \"wsl.exe\",\n      \"args\": [\n        \"bash\",\n        \"-c\",\n        \"source ~/dev/pbixray-mcp/venv/bin/activate && python ~/dev/pbixray-mcp/src/pbixray_server.py\"\n      ]\n    }\n  }\n}\n```\n\n### WSL Path conversion (Claude Project instructions for instance)\n\nWhen using the PBIXRay MCP Server in WSL with Claude Desktop on Windows, you need to be aware of path differences when loading PBIX files.\nWindows paths (like `C:\\Users\\name\\file.pbix`) cannot be directly accessed in WSL. Let your AI assistant know how to convert between pats by adding \n\"Note that mcp server is running in wsl. Windows paths (like C:\\Users\\name\\file.pbix) cannot be directly accessed in WSL. Instead, use WSL paths when referencing files:\nWindows: C:\\Users\\name\\Downloads\\file.pbix\"\nWSL: /mnt/c/Users/name/Downloads/file.pbix\" to project instructions or similar. \n\n### Command Line Options\n\nThe server supports several command line options:\n\n* `--disallow [tool_names]`: Disable specific tools for security reasons\n* `--max-rows N`: Set maximum number of rows returned (default: 100)\n* `--page-size N`: Set default page size for paginated results (default: 20)\n\nCommand-line options can be added as needed in config json:\n\n   ```json\n   {\n    \"mcpServers\": {\n      \"pbixray\": {\n        \"command\": \"wsl.exe\",\n        \"args\": [\n          \"bash\",\n          \"-c\",\n           \"source ~/dev/pbixray-mcp/venv/bin/activate && python ~/dev/pbixray-mcp/src/pbixray_server.py --max-rows 100 --page-size 50 --disallow get_power_query\"\n         ],\n         \"env\": {}\n       }\n     }\n   }\n   ```\n\n\n### Query Options\n\nTools support additional parameters for filtering and pagination:\n\n#### Filtering by Name\n\nTools like `get_dax_measures`, `get_dax_columns`, `get_schema` and others support filtering by specific names:\n\n```\n# Get measures from a specific table\nget_dax_measures(table_name=\"Sales\")\n\n# Get a specific measure\nget_dax_measures(table_name=\"Sales\", measure_name=\"Total Sales\")\n```\n\n#### Pagination for Large Tables\n\nThe `get_table_contents` tool supports pagination to handle large tables efficiently:\n\n```\n# Get first page of Customer table (default 20 rows per page)\nget_table_contents(table_name=\"Customer\")\n\n# Get second page with 50 rows per page\nget_table_contents(table_name=\"Customer\", page=2, page_size=50)\n```\n\n## Development and testing\n\nYou can install PBIXRay MCP Server:\n\n```bash\npip install pbixray-mcp-server\n```\n\n### Development Installation\n\nFor developers working on the project:\n\n1. Clone the repository:\n   ```bash\n   git clone https://github.com/username/pbixray-mcp.git\n   cd pbixray-mcp\n   ```\n\n2. Install in development mode:\n   ```bash\n   pip install -e .\n   ```\n\n3. If installing from source, create a virtual environment and install dependencies:\n   ```bash\n   python -m venv venv\n   source venv/bin/activate  # On Windows: venv\\Scripts\\activate\n   pip install mcp pbixray numpy\n   ```\n\n### Testing with Sample Files\n\nThe repository includes sample files and test scripts to help you get started:\n\n```bash\n# Test with sample AdventureWorks Sales.pbix file in demo/ folder\npython tests/test_with_sample.py\n\n# Try the interactive demo\npython examples/demo.py\n\n# For isolated tests of specific features\npython test_pagination.py\npython test_metadata_fix.py\n```\n\nThe test scripts will help you understand how to interact with the server using the sample PBIX files provided in the `demo/` directory.\n\n### Development Mode\n\nTo test the server during development, use the MCP Inspector:\n\n```bash\n# Activate your environment first\nsource venv/bin/activate\n\n# Run the MCP Inspector\nmcp dev src/pbixray_server.py\n```\n\nThis starts an interactive session where you can call tools and test responses.\n\n\n### Project Structure\n\n```\npbixray-mcp/\n├── README.md            - This file\n├── INSTALLATION.md      - Detailed installation instructions\n├── src/                 - Source code\n│   ├── __init__.py\n│   └── pbixray_server.py\n├── tests/               - Test scripts\n│   ├── __init__.py\n│   ├── conftest.py\n│   ├── test_server.py\n│   └── test_with_sample.py\n├── examples/            - Example scripts and configs\n│   ├── demo.py\n│   └── config/\n├── demo/                - Sample PBIX files\n│   ├── README.md\n│   └── AdventureWorks Sales.pbix\n└── docs/                - Additional documentation\n    └── ROADMAP.md\n```\n\n## Contributions\n\nContributions are much welcomed! \n\n## Credits\n\n* [Hugoberry](https://github.com/Hugoberry/pbixray) - Original PBIXRay library\n* [rusiaaman](https://github.com/rusiaaman/wcgw) - WCGW (This MCP was fully written by Claude using wcgw)\n\n## License (claude insists on adding these)\n\n[MIT License](LICENSE)\n\n[mcp]: https://modelcontextprotocol.io/\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "pbixray",
        "pbix",
        "workflows",
        "bi pbix",
        "pbixray mcp",
        "pbix files"
      ],
      "category": "document-processing"
    },
    "jspamd--docs": {
      "owner": "jspamd",
      "name": "docs",
      "url": "https://github.com/jspamd/docs",
      "imageUrl": "/freedevtools/mcp/pfp/jspamd.webp",
      "description": "Comprehensive documentation for DataEase, focusing on data management, system architecture, and user functionalities. Provides structured resources for installation and deployment, along with user manuals for various features.",
      "stars": 0,
      "forks": 0,
      "license": "GNU General Public License v3.0",
      "language": "",
      "updated_at": "2022-02-15T02:59:45Z",
      "readme_content": "本仓库保存了 [DataEase 项目]() 的 [官方文档](https://dataease.io/docs/)，该文档使用 [MkDocs]() 文档框架下的 [Material for MkDocs]() 主题进行构建。\n\n## 本地开发\n\n### 克隆本仓库\n```bash\ngit clone https://github.com/dataease/docs.git\n```\n\n### 安装依赖\n```bash\ncd docs\npip install -r requirements/requirements.txt\n```\n\n### 修改文档内容\n本文档的文档结构定义在 `mkdocs.yml` 文件中，文档的具体内容均在 `docs` 目录中。\n```yaml\n..........\nnav:\n    - 项目介绍: index.md\n    - 系统架构: system_arch.md\n    - 安装部署: \n        - 在线安装: installation/online_installation.md\n        - 离线安装: installation/offline_installation.md\n        - 在线升级: installation/online_upgrade.md\n        - 离线升级: installation/offline_upgrade.md\n    - 用户手册:\n        - 通用功能: user_manual/general.md\n        - 数据源: user_manual/datasource_configuration.md\n        - 数据集: user_manual/dataset_configuration.md\n        - 视图: user_manual/view_generation.md\n        - 仪表板: user_manual/dashboard_generation.md\n        - 系统管理:\n            - 用户管理: user_manual/system_management/user.md\n            - 模版管理: user_manual/system_management/module.md\n    - 使用教程:\n        - 使用 DataEase 制作销售仪表板: manual_demo/sales_dashboard.md\n    - 常见问题:\n        - 安装配置: faq/configuration_faq.md\n        - 系统管理: faq/system_management.md\n        - 数据集: faq/dataset_faq.md\n    - 开发文档: dev_manual.md\n    - 关于:\n        - 更新说明: about/changelog.md\n        - 联系我们: about/contact.md\n..........\n```\n\n文档内容使用 markdown 语法编写，若要添加新的文档，需要先在 `mkdocs.yml` 文件中的 `nav` 部分增加对应章节导航。\n\n### 本地调试文档\n```bash\nmkdocs serve\n```\n执行上述命令后，可通过 `http://127.0.0.1:8000` 地址查看生成的文档内容，当修改文档后，页面内容会自动更新。\n\n### 构建文档\n```bash\nmkdocs build\n```\n\n执行上述命令后，会在 `site` 目录下生成文档站点的静态文件，将目录中的内容复制到任意 HTTP 服务器上即可完成文档的部署。\n\n## 帮助完善文档\n\n### Fork 文档仓库\n点击仓库右上角的 `fork` 按钮，复制本仓库到自己的 github 账号。\n\n### 克隆 fork 后的仓库\n```bash\ngit clone https://github.com/your-github-account/docs.git\n```\n\n### 本地修改并调试\n\n### Push 修改内容到 GitHub 仓库\n\n### 提交 Pull Request 到本仓库\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "jspamd",
        "dataease",
        "documentation",
        "jspamd docs",
        "processing jspamd",
        "documentation dataease"
      ],
      "category": "document-processing"
    },
    "jxnl--apple-mcp": {
      "owner": "jxnl",
      "name": "apple-mcp",
      "url": "https://github.com/jxnl/apple-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/jxnl.webp",
      "description": "Integrates with Apple applications to manage messages, notes, and emails. Enables automation of tasks across the Apple ecosystem using simple commands for improved productivity.",
      "stars": 12,
      "forks": 3,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-23T20:09:10Z",
      "readme_content": "# Apple MCP tools\n\n[![smithery badge](https://smithery.ai/badge/@Dhravya/apple-mcp)](https://smithery.ai/server/@Dhravya/apple-mcp)\n\nThis is a collection of apple-native tools for the [MCP protocol](https://modelcontextprotocol.com/docs/mcp-protocol).\n\nHere's a step-by-step video about how to set this up, with a demo. - https://x.com/DhravyaShah/status/1892694077679763671\n\n<a href=\"https://glama.ai/mcp/servers/gq2qg6kxtu\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/gq2qg6kxtu/badge\" alt=\"Apple Server MCP server\" />\n</a>\n\n![image](https://github.com/user-attachments/assets/56a5ccfa-cb1a-4226-80c5-6cc794cefc34)\n\n\n<details>\n<summary>Here's the JSON to copy</summary>\n\n```\n{\n  \"mcpServers\": {\n    \"apple-mcp\": {\n      \"command\": \"bunx\",\n      \"args\": [\"--no-cache\", \"apple-mcp@latest\"]\n    }\n}\n\n```\n\n</details>\n\n#### Quick install\n\nTo install Apple MCP for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@Dhravya/apple-mcp):\n\n```bash\nnpx -y @smithery/cli@latest install @Dhravya/apple-mcp --client claude\n```\n\n... and for cursor, you can do:\n\n```bash\nnpx -y @smithery/cli@latest install @Dhravya/apple-mcp --client cursor\n```\n\n\n## Features\n\n- Messages:\n  - Send messages using the Apple Messages app\n  - Read out messages\n- Notes:\n  - List notes\n  - Search & read notes in Apple Notes app\n- Contacts:\n  - Search contacts for sending messages\n- Emails:\n  - Send emails with multiple recipients (to, cc, bcc) and file attachments\n  - Search emails with custom queries, mailbox selection, and result limits\n  - Schedule emails for future delivery\n  - List and manage scheduled emails\n  - Check unread email counts globally or per mailbox\n- Reminders:\n  - List all reminders and reminder lists\n  - Search for reminders by text\n  - Create new reminders with optional due dates and notes\n  - Open the Reminders app to view specific reminders\n- Calendar:\n  - Search calendar events with customizable date ranges\n  - List upcoming events\n  - Create new calendar events with details like title, location, and notes\n  - Open calendar events in the Calendar app\n- Web Search:\n  - Search the web using DuckDuckGo\n  - Retrieve and process content from search results\n- Maps:\n  - Search for locations and addresses\n  - Save locations to favorites\n  - Get directions between locations\n  - Drop pins on the map\n  - Create and list guides\n  - Add places to guides\n\n- TODO: Search and open photos in Apple Photos app\n- TODO: Search and open music in Apple Music app\n\n\nYou can also daisy-chain commands to create a workflow. Like:\n\"can you please read the note about people i met in the conference, find their contacts and emails, and send them a message saying thank you for the time.\"\n\n(it works!)\n\n\n#### Manual installation\n\nYou just need bun, install with `brew install oven-sh/bun/bun`\n\nNow, edit your `claude_desktop_config.json` with this:\n\n```claude_desktop_config.json\n{\n  \"mcpServers\": {\n    \"apple-mcp\": {\n      \"command\": \"bunx\",\n      \"args\": [\"@dhravya/apple-mcp@latest\"]\n    }\n  }\n}\n```\n\n### Usage\n\nNow, ask Claude to use the `apple-mcp` tool.\n\n```\nCan you send a message to John Doe?\n```\n\n```\nfind all the notes related to AI and send it to my girlfriend\n```\n\n```\ncreate a reminder to \"Buy groceries\" for tomorrow at 5pm\n```\n\n## Local Development\n\n```bash\ngit clone https://github.com/dhravya/apple-mcp.git\ncd apple-mcp\nbun install\nbun run index.ts\n```\n\nenjoy!\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "jxnl",
        "mcp",
        "document",
        "jxnl apple",
        "processing jxnl",
        "apple mcp"
      ],
      "category": "document-processing"
    },
    "kajirita2002--esa-mcp-server": {
      "owner": "kajirita2002",
      "name": "esa-mcp-server",
      "url": "https://github.com/kajirita2002/esa-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/kajirita2002.webp",
      "description": "Integrate Claude AI with the esa API to manage documents efficiently by performing operations such as searching, creating, and updating documents.",
      "stars": 8,
      "forks": 2,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-08-01T14:42:40Z",
      "readme_content": "# esa MCP Server\n\n<img width=\"775\" alt=\"スクリーンショット 2025-03-27 午後1 14 09\" src=\"https://github.com/user-attachments/assets/e5f8f308-ed7a-4774-b3a3-9cc284ea7422\" />\n\n\n*Read this in [Japanese](README.ja.md)*\n\n## Overview\n\nThis server is an interface that uses the [Model Context Protocol (MCP)](https://github.com/anthropics/anthropic-cookbook/tree/main/model_context_protocol) to enable Claude AI to interact with the [esa API](https://docs.esa.io/posts/102).\n\nWith this MCP server, Claude AI can perform operations such as searching, creating, and updating esa documents.\n\n<a href=\"https://glama.ai/mcp/servers/@kajirita2002/esa-mcp-server\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@kajirita2002/esa-mcp-server/badge\" alt=\"esa Server MCP server\" />\n</a>\n\n## About the Repository\n\nThis repository provides a standalone implementation of the esa MCP server. It integrates Claude AI with esa to streamline document management.\n\n## Setup\n\n### Prerequisites\n\n- Node.js 18 or higher\n- esa API access token\n- esa team name\n\n### Installation\n\n```bash\n# Install globally\nnpm install -g @kajirita2002/esa-mcp-server\n\n# Or use directly with npx\nnpx @kajirita2002/esa-mcp-server\n```\n\n### Setting Environment Variables\n\n```bash\n# Set environment variables\nexport ESA_ACCESS_TOKEN=\"your_esa_access_token\"\nexport ESA_TEAM=\"your_team_name\"\n```\n\n### MCP Configuration Example\n\nIf you're using this MCP server, add the following configuration to your `mcp_config.json` file:\n\n```json\n\"esa\": {\n  \"command\": \"npx\",\n  \"args\": [\"-y\", \"@kajirita2002/esa-mcp-server\"],\n  \"env\": {\n    \"ESA_ACCESS_TOKEN\": \"your_esa_access_token\",\n    \"ESA_TEAM\": \"your_team_name\"\n  }\n}\n```\n\n### Starting the Server\n\n```bash\n# Start the server\nnpm start\n```\n\n## Available Tools\n\nThis MCP server provides the following tools:\n\n### Post Related\n\n1. `esa_list_posts`\n   - Get a list of posts in the team\n   - Input:\n     - `q` (string, optional): Search query\n     - `include` (string, optional): Related data to include in the response (e.g. 'comments,stargazers')\n     - `sort` (string, optional): Sort method (updated, created, number, stars, watches, comments, best_match)\n     - `order` (string, optional): Sort order (desc, asc)\n     - `per_page` (number, optional): Number of results per page (max: 100)\n     - `page` (number, optional): Page number to retrieve\n\n2. `esa_get_post`\n   - Get detailed information about a specific post\n   - Input:\n     - `post_number` (number, required): Post number to retrieve\n     - `include` (string, optional): Related data to include in the response (e.g. 'comments,stargazers')\n\n3. `esa_create_post`\n   - Create a new post\n   - Input:\n     - `name` (string, required): Post title\n     - `body_md` (string, optional): Post body (Markdown format)\n     - `tags` (array of string, optional): List of tags for the post\n     - `category` (string, optional): Post category\n     - `wip` (boolean, optional, default: true): Whether to mark as WIP (Work In Progress)\n     - `message` (string, optional): Change message\n     - `user` (string, optional): Poster's screen_name (only team owners can specify)\n     - `template_post_id` (number, optional): ID of the post to use as a template\n\n4. `esa_update_post`\n   - Update an existing post\n   - Input:\n     - `post_number` (number, required): Post number to update\n     - `name` (string, optional): New title for the post\n     - `body_md` (string, optional): New body for the post (Markdown format)\n     - `tags` (array of string, optional): New list of tags for the post\n     - `category` (string, optional): New category for the post\n     - `wip` (boolean, optional): Whether to mark as WIP (Work In Progress)\n     - `message` (string, optional): Change message\n     - `created_by` (string, optional): Poster's screen_name (only team owners can specify)\n     - `original_revision` (string, optional): Revision to base the update on\n\n### Comment Related\n\n1. `esa_list_comments`\n   - Get a list of comments for a post\n   - Input:\n     - `post_number` (number, required): Post number to get comments for\n     - `page` (number, optional): Page number to retrieve\n     - `per_page` (number, optional): Number of results per page (max: 100)\n\n2. `esa_get_comment`\n   - Get a specific comment\n   - Input:\n     - `comment_id` (number, required): ID of the comment to retrieve\n     - `include` (string, optional): Related data to include in the response (e.g. 'stargazers')\n\n3. `esa_create_comment`\n   - Post a comment to an article\n   - Input:\n     - `post_number` (number, required): Post number to comment on\n     - `body_md` (string, required): Comment body (Markdown format)\n     - `user` (string, optional): Poster's screen_name (only team owners can specify)\n\n### Member Related\n\n1. `esa_get_members`\n   - Get a list of team members\n   - Input:\n     - `page` (number, optional): Page number to retrieve\n     - `per_page` (number, optional): Number of results per page (max: 100)\n\n2. `esa_get_member`\n   - Get information about a specific team member\n   - Input:\n     - `screen_name_or_email` (string, required): Screen name or email of the member to retrieve\n\n## Usage Example\n\nHere's an example of Claude using this MCP server to create an esa post:\n\n```\n[Claude] Please create a new post in esa. The title should be \"Project X Progress Report\" and the body should include \"# This Week's Progress\\n\\n- Implementation of Feature A completed\\n- Testing of Feature B started\\n\\n## Next Week's Plan\\n\\n- Start implementation of Feature C\".\n\n[MCP Server] Using the esa_create_post tool to create a new post.\n\n[Result]\n{\n  \"number\": 123,\n  \"name\": \"Project X Progress Report\",\n  \"body_md\": \"# This Week's Progress\\n\\n- Implementation of Feature A completed\\n- Testing of Feature B started\\n\\n## Next Week's Plan\\n\\n- Start implementation of Feature C\",\n  \"wip\": false,\n  \"created_at\": \"2023-06-01T12:34:56+09:00\",\n  \"updated_at\": \"2023-06-01T12:34:56+09:00\",\n  \"url\": \"https://your-team.esa.io/posts/123\"\n}\n\n[Claude] The post has been created successfully. The post number is 123, and you can access it at the following URL:\nhttps://your-team.esa.io/posts/123\n```\n\n## Troubleshooting\n\n### Access Token Issues\n\n```\nError: Request failed with status code 401\n```\n\nIf you see this error, your esa access token may be invalid or expired. Generate a new access token from the esa settings screen and update your environment variable.\n\n### Permission Issues\n\n```\nError: Request failed with status code 403\n```\n\nIf you see this error, the current access token doesn't have the necessary permissions. Check the permissions for your access token in the esa settings screen and issue a new token if needed.\n\n## License\n\nProvided under the MIT License.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "esa",
        "documents",
        "document",
        "document processing",
        "esa api",
        "documents efficiently"
      ],
      "category": "document-processing"
    },
    "kakukontrol--iodraw-files": {
      "owner": "kakukontrol",
      "name": "iodraw-files",
      "url": "https://github.com/kakukontrol/iodraw-files",
      "imageUrl": "/freedevtools/mcp/pfp/null.webp",
      "description": "Provide access to various diagram and chart file formats used by iodraw, including flow charts, mind maps, Gantt charts, whiteboards, code charts, and online charts. Enable seamless integration and manipulation of these specialized file types within your applications. Enhance your workflows by leveraging structured visual data formats.",
      "stars": 0,
      "forks": 0,
      "license": "Unknown",
      "language": "Unknown",
      "updated_at": "",
      "readme_content": "",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "iodraw",
        "formats",
        "files",
        "iodraw files",
        "iodraw including",
        "kakukontrol iodraw"
      ],
      "category": "document-processing"
    },
    "kaliaboi--mcp-zotero": {
      "owner": "kaliaboi",
      "name": "mcp-zotero",
      "url": "https://github.com/kaliaboi/mcp-zotero",
      "imageUrl": "/freedevtools/mcp/pfp/kaliaboi.webp",
      "description": "Integrates with Zotero to enable interactions with a Zotero library, facilitating the management and retrieval of bibliographic data.",
      "stars": 135,
      "forks": 17,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-29T12:49:43Z",
      "readme_content": "# MCP Zotero\n\n![NPM Version](https://img.shields.io/npm/v/mcp-zotero) [![smithery badge](https://smithery.ai/badge/mcp-zotero)](https://smithery.ai/server/mcp-zotero)\n\nA Model Context Protocol server for Zotero integration that allows Claude to interact with your Zotero library.\n\n<a href=\"https://glama.ai/mcp/servers/mjvu0xzzzz\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/mjvu0xzzzz/badge\" alt=\"Zotero MCP server\" /></a>\n\n## Setup\n\n1. Get your Zotero credentials:\n\n   ```bash\n   # First, create an API key at https://www.zotero.org/settings/keys\n   # Then use it to get your user ID:\n   curl -H \"Zotero-API-Key: YOUR_API_KEY\" https://api.zotero.org/keys/current\n   ```\n\n   The response will look like:\n\n   ```json\n   {\n     \"userID\": 123456,\n     \"username\": \"your_username\",\n     \"access\": {\n       \"user\": {\n         \"library\": true,\n         \"files\": true,\n         \"notes\": true,\n         \"write\": true\n       }\n     }\n   }\n   ```\n\n   The `userID` value is what you need.\n\n2. Set environment variables:\n\n   ```bash\n   export ZOTERO_API_KEY=\"your-api-key\"\n   export ZOTERO_USER_ID=\"user-id-from-curl\"\n   ```\n\n3. Verify your credentials:\n\n   ```bash\n   # Test that your credentials work:\n   curl -H \"Zotero-API-Key: $ZOTERO_API_KEY\" \\\n        \"https://api.zotero.org/users/$ZOTERO_USER_ID/collections\"\n   ```\n\n   You should see your collections list in the response.\n\n4. Install and run:\n\n   ```bash\n   # Install globally (recommended)\n   npm install -g mcp-zotero\n   mcp-zotero\n\n   # Or run directly with npx\n   npx mcp-zotero\n   ```\n\n## Integration with Claude Desktop\n\nTo use this server with Claude Desktop, add the following to your Claude Desktop configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"zotero\": {\n      \"command\": \"mcp-zotero\",\n      \"env\": {\n        \"ZOTERO_API_KEY\": YOUR_API_KEY,\n        \"ZOTERO_USER_ID\": YOUR_USER_ID\n      }\n    }\n  }\n}\n```\n\n## Available Tools\n\n- `get_collections`: List all collections in your library\n- `get_collection_items`: Get items in a specific collection\n- `get_item_details`: Get detailed information about a paper\n- `search_library`: Search your entire library\n- `get_recent`: Get recently added papers\n\n## Troubleshooting\n\nIf you encounter any issues:\n\n1. Verify your environment variables are set:\n\n   ```bash\n   echo $ZOTERO_API_KEY\n   echo $ZOTERO_USER_ID\n   ```\n\n2. Check the installation:\n\n   ```bash\n   npm list -g mcp-zotero\n   ```\n\n3. Try reinstalling:\n   ```bash\n   npm uninstall -g mcp-zotero\n   npm install -g mcp-zotero\n   ```\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "zotero",
        "bibliographic",
        "document",
        "zotero library",
        "mcp zotero",
        "zotero enable"
      ],
      "category": "document-processing"
    },
    "kazuph--mcp-docs-rag": {
      "owner": "kazuph",
      "name": "mcp-docs-rag",
      "url": "https://github.com/kazuph/mcp-docs-rag",
      "imageUrl": "/freedevtools/mcp/pfp/kazuph.webp",
      "description": "Manage and query documents in a local directory using retrieval-augmented generation techniques, integrating context from text files and Git repositories. Supports listing documents and generating responses based on queries with context from the stored content.",
      "stars": 12,
      "forks": 8,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-10-01T08:28:45Z",
      "readme_content": "# mcp-docs-rag MCP Server\n\nRAG (Retrieval-Augmented Generation) for documents in a local directory\n\nThis is a TypeScript-based MCP server that implements a RAG system for documents stored in a local directory. It allows users to query documents using LLMs with context from locally stored repositories and text files.\n\n## Features\n\n### Resources\n- List and access documents via `docs://` URIs\n- Documents can be Git repositories or text files\n- Plain text mime type for content access\n\n### Tools\n- `list_documents` - List all available documents in the DOCS_PATH directory\n  - Returns a formatted list of all documents\n  - Shows total number of available documents\n- `rag_query` - Query documents using RAG\n  - Takes document_id and query as parameters\n  - Returns AI-generated responses with context from documents\n- `add_git_repository` - Clone a Git repository to the docs directory with optional sparse checkout\n  - Takes repository_url as parameter\n  - Optional document_name parameter to customize the name of the document (use simple descriptive names without '-docs' suffix)\n  - Optional subdirectory parameter for sparse checkout of specific directories\n  - Automatically pulls latest changes if repository already exists\n- `add_text_file` - Download a text file to the docs directory\n  - Takes file_url as parameter\n  - Uses wget to download file\n\n### Prompts\n- `guide_documents_usage` - Guide on how to use documents and RAG functionality\n  - Includes list of available documents\n  - Provides usage hints for RAG functionality\n\n## Development\n\nInstall dependencies:\n```bash\nnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n```bash\nnpm run watch\n```\n\n## Setup\n\nThis server requires a local directory for storing documents. By default, it uses `~/docs` but you can configure a different location with the `DOCS_PATH` environment variable.\n\n### Document Structure\n\nThe documents directory can contain:\n- Git repositories (cloned directories)\n- Plain text files (with .txt extension)\n\nEach document is indexed separately using llama-index.ts with Google's Gemini embeddings.\n\n### API Keys\n\nThis server uses Google's Gemini API for document indexing and querying. You need to set your Gemini API key as an environment variable:\n\n```bash\nexport GEMINI_API_KEY=your-api-key-here\n```\n\nYou can obtain a Gemini API key from the [Google AI Studio](https://makersuite.google.com/app/apikey) website. Add this key to your shell profile or include it in the environment configuration for Claude Desktop.\n\n## Installation\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\nOn Linux: `~/.config/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"docs-rag\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@kazuph/mcp-docs-rag\"],\n      \"env\": {\n        \"DOCS_PATH\": \"/Users/username/docs\",\n        \"GEMINI_API_KEY\": \"your-api-key-here\"\n      }\n    }\n  }\n}\n```\n\nMake sure to replace `/Users/username/docs` with the actual path to your documents directory.\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n\n## Usage\n\nOnce configured, you can use the server with Claude to:\n\n1. **Add documents**:\n   ```\n   Add a new document from GitHub: https://github.com/username/repository\n   ```\n   or with a custom document name:\n   ```\n   Add GitHub repository https://github.com/username/repository-name and name it 'framework'\n   ```\n   or with sparse checkout of a specific directory:\n   ```\n   Add only the 'src/components' directory from https://github.com/username/repository\n   ```\n   or combine custom name and sparse checkout:\n   ```\n   Add the 'examples/demo' directory from https://github.com/username/large-repo and name it 'demo-app'\n   ```\n   or add a text file:\n   ```\n   Add this text file: https://example.com/document.txt\n   ```\n\n2. **Query documents**:\n   ```\n   What does the documentation say about X in the Y repository?\n   ```\n\n3. **List available documents**:\n   ```\n   What documents do you have access to?\n   ```\n\nThe server will automatically handle indexing of documents for efficient retrieval.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "documents",
        "git",
        "repositories",
        "query documents",
        "documents generating",
        "document processing"
      ],
      "category": "document-processing"
    },
    "kazuph--mcp-screenshot": {
      "owner": "kazuph",
      "name": "mcp-screenshot",
      "url": "https://github.com/kazuph/mcp-screenshot",
      "imageUrl": "/freedevtools/mcp/pfp/kazuph.webp",
      "description": "Captures screenshots and performs OCR text recognition on macOS. Supports both Japanese and English text, offering multiple output formats.",
      "stars": 21,
      "forks": 6,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-10-03T22:32:03Z",
      "readme_content": "# MCP Screenshot\n\nAn MCP server that captures screenshots and performs OCR text recognition.\n\n<a href=\"https://glama.ai/mcp/servers/vcnmmaejv8\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/vcnmmaejv8/badge\" alt=\"mcp-screenshot MCP server\" /></a>\n\n## Features\n\n- Screenshot capture (left half, right half, full screen)\n- OCR text recognition (supports Japanese and English)\n- Multiple output formats (JSON, Markdown, vertical, horizontal)\n\n## OCR Engines\n\nThis server uses two OCR engines:\n\n1. [yomitoku](https://github.com/kazuph/yomitoku)\n   - Primary OCR engine\n   - High-accuracy Japanese text recognition\n   - Runs as an API server\n\n2. [Tesseract.js](https://github.com/naptha/tesseract.js)\n   - Fallback OCR engine\n   - Used when yomitoku is unavailable\n   - Supports both Japanese and English recognition\n\n## Installation\n\n```bash\nnpx -y @kazuph/mcp-screenshot\n```\n\n## Claude Desktop Configuration\n\nAdd the following configuration to your `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"screenshot\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@kazuph/mcp-screenshot\"],\n      \"env\": {\n        \"OCR_API_URL\": \"http://localhost:8000\"  // yomitoku API base URL\n      }\n    }\n  }\n}\n```\n\n## Environment Variables\n\n| Variable Name | Description | Default Value |\n|--------------|-------------|---------------|\n| OCR_API_URL | yomitoku API base URL | http://localhost:8000 |\n\n## Usage Example\n\nYou can use it by instructing Claude like this:\n\n```\nPlease take a screenshot of the left half of the screen and recognize the text in it.\n```\n\n## Tool Specification\n\n### capture\n\nTakes a screenshot and performs OCR.\n\nOptions:\n- `region`: Screenshot area ('left'/'right'/'full', default: 'left')\n- `format`: Output format ('json'/'markdown'/'vertical'/'horizontal', default: 'markdown')\n\n## License\n\nMIT\n\n## Author\n\nkazuph\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "kazuph",
        "macos",
        "ocr",
        "kazuph mcp",
        "processing kazuph",
        "recognition macos"
      ],
      "category": "document-processing"
    },
    "kibela--kibela-mcp-server": {
      "owner": "kibela",
      "name": "kibela-mcp-server",
      "url": "https://github.com/kibela/kibela-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/kibela.webp",
      "description": "Interact with Kibela's knowledge base to search, organize, and manage notes and folders while utilizing AI-assisted writing and content creation. Integrate seamlessly with MCP clients like Claude Desktop or VSCode for enhanced productivity.",
      "stars": 10,
      "forks": 1,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-08-14T14:05:58Z",
      "readme_content": "<div align=\"center\">\n  <h1>Kibela MCP Server</h1>\n\n  <p>Kibela MCP Server is a <a href=\"https://modelcontextprotocol.io/introduction\">Model Context Protocol (MCP)</a> server for Kibela.</p>\n\n![GitHub commit activity](https://img.shields.io/github/commit-activity/w/kibela/kibela-mcp-server)\n![GitHub Release Date](https://img.shields.io/github/release-date/kibela/kibela-mcp-server)\n![GitHub package.json dynamic](https://img.shields.io/github/package-json/license/kibela/kibela-mcp-server)\n![GitHub package.json dynamic](https://img.shields.io/github/package-json/version/kibela/kibela-mcp-server)\n\n</div>\n\n## Overview\n\nKibela MCP Server is currently available only as a local server using STDIO and can be used with any MCP client such as Claude Desktop or VSCode.\n\nOnly those GraphQL APIs that are publicly available and suitable for MCP are implemented as tools.\n\n## Use Cases\n\n- Ask about information in Kibela\n- Organize folders and articles in Kibela\n- Using AI to help you write with Kibela\n\n## Requirements\n\n1. [Docker](https://www.docker.com/) is installed\n2. Docker must be running\n3. Kibela [access tokens](https://my.kibe.la/settings/access_tokens) is issued\n4. An application that implements the [MCP client](https://mcp.so/clients) must be installed\n\n## Installation\n\n### Example: Claude Desktop\n\nWrite the following configuration to `claude_desktop_config.json`. Set the Kibela origin and access token as environment variables.\n\n```json\n{\n  \"mcpServers\": {\n    \"kibela\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"-e\",\n        \"KIBELA_ORIGIN\",\n        \"-e\",\n        \"KIBELA_ACCESS_TOKEN\",\n        \"ghcr.io/kibela/kibela-mcp-server\"\n      ],\n      \"env\": {\n        \"KIBELA_ORIGIN\": \"https://your-subdomain.kibe.la\",\n        \"KIBELA_ACCESS_TOKEN\": \"***\"\n      }\n    }\n  }\n}\n```\n\n### No Docker\n\nThen set the script as the execution command. At this time, make sure that the path to the script is absolute.\n\n```json\n{\n  \"mcpServers\": {\n    \"kibela\": {\n      \"command\": \"/path/to/kibela-mcp-server/bin/cli.mjs\",\n      \"env\": {\n        \"KIBELA_ORIGIN\": \"https://your-subdomain.kibe.la\",\n        \"KIBELA_ACCESS_TOKEN\": \"***\"\n      }\n    }\n  }\n}\n```\n\n## Available Tools\n\n### Note Operations\n\n- `search_kibela_note` - Search notes\n\n  - `query`: Search keyword (required)\n  - `resources`: Resource type filter (optional)\n  - `coediting`: Co-editing flag (optional)\n  - `updated`: Update date range (optional)\n  - `groupIds`: Group ID filter (optional)\n  - `folderIds`: Folder ID filter (optional)\n  - `likerIds`: Liker user ID filter (optional)\n  - `isArchived`: Archive flag (optional)\n  - `sortBy`: Sort order (optional)\n\n- `get_kibela_note_by_relay_id` - Get a note by Relay ID\n\n  - `id`: Note's Relay ID (required)\n\n- `get_kibela_note_from_path_or_url` - Get a note from path or URL\n\n  - `path`: Note's path or URL (required)\n\n- `get_kibela_notes` - Get notes in a folder\n\n  - `folderId`: Folder ID (required)\n  - `first`: Number of records from front (optional)\n  - `last`: Number of records from back (optional)\n\n- `create_kibela_note` - Create a new note\n\n  - `title`: Note title (required)\n  - `content`: Note content (required)\n  - `draft`: Draft flag (optional)\n  - `groupIds`: List of group IDs to belong to (required)\n  - `folders`: Folder information (optional)\n    - `groupId`: Group ID\n    - `folderName`: Folder name\n\n- `update_kibela_note_content` - Update note content\n  - `id`: Note ID (required)\n  - `newContent`: New content (required)\n  - `baseContent`: Original content (required)\n\n### Folder Operations\n\n- `search_kibela_folder` - Search folders\n\n  - `query`: Search keyword (required)\n\n- `get_kibela_folder_by_relay_id` - Get a folder by Relay ID\n\n  - `id`: Folder's Relay ID (required)\n  - `first`: Number of records from front (optional)\n\n- `get_kibela_folder_from_path_or_url` - Get a folder from path or URL\n\n  - `path`: Folder's path or URL (required)\n  - `first`: Number of records from front (optional)\n\n- `get_kibela_folders` - Get folder list\n\n  - `first`: Number of records from front (optional)\n  - `last`: Number of records from back (optional)\n\n- `create_kibela_folder` - Create a new folder\n\n  - `groupId`: Group ID (required)\n  - `fullName`: Full path name of the folder (required)\n\n- `move_kibela_note_to_another_folder` - Move a note to another folder\n\n  - `id`: Note ID (required)\n  - `fromFolder`: Source folder information (required)\n    - `groupId`: Group ID\n    - `folderName`: Folder name\n  - `toFolder`: Destination folder information (required)\n    - `groupId`: Group ID\n    - `folderName`: Folder name\n\n- `attach_kibela_note_to_folder` - Associate a note with a folder\n  - `id`: Note ID (required)\n  - `folder`: Folder information (required)\n    - `groupId`: Group ID\n    - `folderName`: Folder name\n\n### Comment Operations\n\n- `create_kibela_comment` - Create a comment on a note\n\n  - `content`: Comment content (required)\n  - `noteId`: Target note ID (required)\n\n- `create_kibela_comment_reply` - Create a reply to a comment\n  - `content`: Reply content (required)\n  - `commentId`: Target comment ID (required)\n\n### Other Operations\n\n- `get_kibela_groups` - Get group list\n\n  - `first`: Number of records from front (optional)\n  - `last`: Number of records from back (optional)\n\n- `get_kibela_feed_sections` - Get feed section list\n  - `kind`: Feed type (required)\n  - `groupId`: Group ID (required)\n\n## Available Prompts\n\n### Review Prompt\n\nTakes a URL as input and reviews the specified note.\n\nInput schema:\n\n```typescript\n{\n  url: string; // URL format\n}\n```\n\n### Search Prompt\n\nTakes a query as input and searches for relevant information.\n\nInput schema:\n\n```typescript\n{\n  query: string;\n}\n```\n\n### Related Note Prompt\n\nTakes a URL as input and explore the related note.\n\nInput schema:\n\n```typescript\n{\n  url: string; // URL format\n}\n```\n\n### Reflect Comment Prompt\n\nTakes a URL as input and reflect its comment to note.\n\nInput schema:\n\n```typescript\n{\n  url: string; // URL format\n}\n```\n\n## Customization\n\nYou can customize the tool description and prompt by preparing a JSON file in the following format.\n\nSee [`server.ts`](https://github.com/kibela/kibela-mcp-server/blob/main/src/lib/server.ts) for tool and prompt keys.\n\n```json\n{\n  \"tools\": {\n    \"search_kibela_note\": {\n      \"description\": \"New description\"\n    }\n  },\n  \"prompts\": {\n    \"review\": {\n      \"prompt\": \"New review prompt\"\n    }\n  }\n}\n```\n\nAnd then mount it to the container as follows:\n\n```json\n{\n  \"mcpServers\": {\n    \"kibela\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"-e\",\n        \"KIBELA_ORIGIN\",\n        \"-e\",\n        \"KIBELA_ACCESS_TOKEN\",\n        \"-v\",\n        \"/path/to/kibela-mcp-server-config.json:/usr/src/app/kibela-mcp-server-config.json\",\n        \"ghcr.io/kibela/kibela-mcp-server\"\n      ],\n      \"env\": {\n        \"KIBELA_ORIGIN\": \"https://your-subdomain.kibe.la\",\n        \"KIBELA_ACCESS_TOKEN\": \"***\"\n      }\n    }\n  }\n}\n```\n\n## Development\n\n```bash\ndocker compose run mcp pnpm install\n```\n\n```bash\ndocker compose up\n```\n\n### Testing with MCP Inspector\n\n```bash\nnpx @modelcontextprotocol/inspector \\\n  -e KIBELA_ORIGIN=https://your-subdomain.kibe.la \\\n  -e KIBELA_ACCESS_TOKEN=*** \\\n  docker compose exec mcp bin/cli.mjs\n```\n\n# License\n\nThis package is licensed under the terms of the [MIT](https://github.com/kibela/kibela-mcp-server/blob/main/LICENSE) license.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "kibela",
        "document",
        "mcp",
        "processing kibela",
        "kibela mcp",
        "interact kibela"
      ],
      "category": "document-processing"
    },
    "kimtaeyoon83--mcp-server-youtube-transcript": {
      "owner": "kimtaeyoon83",
      "name": "mcp-server-youtube-transcript",
      "url": "https://github.com/kimtaeyoon83/mcp-server-youtube-transcript",
      "imageUrl": "/freedevtools/mcp/pfp/kimtaeyoon83.webp",
      "description": "Retrieve transcripts and subtitles from YouTube videos, accessing video captions and detailed metadata through a simple interface.",
      "stars": 327,
      "forks": 58,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-10-04T02:40:02Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/kimtaeyoon83-mcp-server-youtube-transcript-badge.png)](https://mseep.ai/app/kimtaeyoon83-mcp-server-youtube-transcript)\n\n# YouTube Transcript Server\n\n[![smithery badge](https://smithery.ai/badge/@kimtaeyoon83/mcp-server-youtube-transcript)](https://smithery.ai/server/@kimtaeyoon83/mcp-server-youtube-transcript)\n\nA Model Context Protocol server that enables retrieval of transcripts from YouTube videos. This server provides direct access to video captions and subtitles through a simple interface.\n\n<a href=\"https://glama.ai/mcp/servers/z429kk3te7\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/z429kk3te7/badge\" alt=\"mcp-server-youtube-transcript MCP server\" /></a>\n\n### Installing via Smithery\n\nTo install YouTube Transcript Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@kimtaeyoon83/mcp-server-youtube-transcript):\n\n```bash\nnpx -y @smithery/cli install @kimtaeyoon83/mcp-server-youtube-transcript --client claude\n```\n\n## Components\n\n### Tools\n\n- **get_transcript**\n  - Extract transcripts from YouTube videos\n  - Inputs:\n    - `url` (string, required): YouTube video URL or video ID\n    - `lang` (string, optional, default: \"en\"): Language code for transcript (e.g., 'ko', 'en')\n\n## Key Features\n\n- Support for multiple video URL formats\n- Language-specific transcript retrieval\n- Detailed metadata in responses\n\n## Configuration\n\nTo use with Claude Desktop, add this server configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"youtube-transcript\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@kimtaeyoon83/mcp-server-youtube-transcript\"]\n    }\n  }\n}\n```\n\n## Install via tool\n\n[mcp-get](https://github.com/michaellatman/mcp-get) A command-line tool for installing and managing Model Context Protocol (MCP) servers.\n\n```shell \nnpx @michaellatman/mcp-get@latest install @kimtaeyoon83/mcp-server-youtube-transcript\n```\n\n## Awesome-mcp-servers \n[awesome-mcp-servers](https://github.com/punkpeye/awesome-mcp-servers) A curated list of awesome Model Context Protocol (MCP) servers.\n\n## Development\n\n### Prerequisites\n\n- Node.js 18 or higher\n- npm or yarn\n\n### Setup\n\nInstall dependencies:\n```bash\nnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n```bash\nnpm run watch\n```\n\n### Testing\n\n```bash\nnpm test\n```\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the MCP Inspector for development:\n\n```bash\nnpm run inspector\n```\n\n\n\n## Running evals\n\nThe evals package loads an mcp client that then runs the index.ts file, so there is no need to rebuild between tests. You can load environment variables by prefixing the npx command. Full documentation can be found [here](https://www.mcpevals.io/docs).\n\n```bash\nOPENAI_API_KEY=your-key  npx mcp-eval src/evals/evals.ts src/index.ts\n```\n## Error Handling\n\nThe server implements robust error handling for common scenarios:\n- Invalid video URLs or IDs\n- Unavailable transcripts\n- Language availability issues\n- Network errors\n\n## Usage Examples\n\n1. Get transcript by video URL:\n```typescript\nawait server.callTool(\"get_transcript\", {\n  url: \"https://www.youtube.com/watch?v=VIDEO_ID\",\n  lang: \"en\"\n});\n```\n\n2. Get transcript by video ID:\n```typescript\nawait server.callTool(\"get_transcript\", {\n  url: \"VIDEO_ID\",\n  lang: \"ko\"\n});\n```\n\n3. How to Extract YouTube Subtitles in Claude Desktop App\n```\nchat: https://youtu.be/ODaHJzOyVCQ?si=aXkJgso96Deri0aB Extract subtitles\n```\n\n## Security Considerations\n\nThe server:\n- Validates all input parameters\n- Handles YouTube API errors gracefully\n- Implements timeouts for transcript retrieval\n- Provides detailed error messages for troubleshooting\n\n## License\n\nThis MCP server is licensed under the MIT License. See the LICENSE file for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "transcript",
        "youtube",
        "transcripts",
        "youtube transcript",
        "server youtube",
        "processing kimtaeyoon83"
      ],
      "category": "document-processing"
    },
    "kmexnx--excel-to-pdf-mcp": {
      "owner": "kmexnx",
      "name": "excel-to-pdf-mcp",
      "url": "https://github.com/kmexnx/excel-to-pdf-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/kmexnx.webp",
      "description": "Convert Excel and Apple Numbers files to PDF format, enabling seamless file handling and sharing. Integrate with AI assistants through the Model Context Protocol for direct file conversion during conversations.",
      "stars": 2,
      "forks": 4,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-08-08T14:32:09Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/kmexnx-excel-to-pdf-mcp-badge.png)](https://mseep.ai/app/kmexnx-excel-to-pdf-mcp)\n\n# Excel to PDF MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@kmexnx/excel-to-pdf-mcp)](https://smithery.ai/server/@kmexnx/excel-to-pdf-mcp)\n\nAn MCP (Model Context Protocol) server that can convert Excel (.xls/.xlsx) and Apple Numbers (.numbers) files to PDF format. This tool integrates with AI assistants like Claude to enable file conversion directly through the conversation.\n\n<a href=\"https://glama.ai/mcp/servers/@kmexnx/excel-to-pdf-mcp\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@kmexnx/excel-to-pdf-mcp/badge\" alt=\"Excel to PDF Converter MCP server\" />\n</a>\n\n## Features\n\n- Convert Excel files (.xls, .xlsx) to PDF\n- Convert Apple Numbers files (.numbers) to PDF\n- Integrates with AI assistants via the Model Context Protocol\n- Secure file handling that respects project boundaries\n- Easy installation via npm\n\n## Requirements\n\n- Node.js 16 or higher\n- LibreOffice (for the conversion process)\n\n## Installation\n\n### Installing via Smithery\n\nTo install Excel to PDF Converter for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@kmexnx/excel-to-pdf-mcp):\n\n```bash\nnpx -y @smithery/cli install @kmexnx/excel-to-pdf-mcp --client claude\n```\n\n### Install LibreOffice\n\nLibreOffice is required for the conversion process. Install it according to your operating system:\n\n#### On macOS:\n```bash\nbrew install libreoffice\n```\n\n#### On Ubuntu/Debian:\n```bash\napt-get install libreoffice\n```\n\n#### On Windows:\nDownload and install from [LibreOffice official website](https://www.libreoffice.org/download/download/).\n\n### Install the MCP server\n\n```bash\nnpm install -g excel-to-pdf-mcp\n```\n\n## Using with Claude Desktop\n\nTo use this MCP server with Claude desktop:\n\n1. Configure your MCP settings in Claude desktop by adding this server to your `mcp_settings.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"excel-to-pdf-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\"excel-to-pdf-mcp\"],\n      \"name\": \"Excel to PDF Converter\"\n    }\n  }\n}\n```\n\n2. Make sure your Excel or Numbers files are within your project directory.\n\n3. Once configured, Claude will be able to convert your spreadsheet files to PDF using this tool.\n\n## Example Conversation\n\nHere's an example of how a conversation with Claude might look when using this MCP server:\n\n**User**: \"I need to convert my quarterly_report.xlsx to PDF so I can share it with stakeholders.\"\n\n**Claude**: \"I can help you convert your Excel file to PDF. Let me use the Excel to PDF converter tool.\"\n\nClaude would then use the tool behind the scenes:\n\n```\nTool: convert_excel_to_pdf\nArguments: {\n  \"input_path\": \"quarterly_report.xlsx\",\n  \"output_format\": \"pdf\"\n}\n```\n\n**Claude**: \"I've converted your Excel file to PDF. You can find it at: quarterly_report-1628347658-a7b2c9.pdf in your project directory.\"\n\n## Available Tools\n\nThis MCP server provides the following tools:\n\n### 1. convert_excel_to_pdf\n\nConverts Excel files (.xls/.xlsx) to PDF format.\n\n**Arguments:**\n- `input_path`: Relative path to the Excel file (required)\n- `output_format`: Output format, currently only PDF is supported (default: \"pdf\")\n\n### 2. convert_numbers_to_pdf\n\nConverts Apple Numbers files (.numbers) to PDF format.\n\n**Arguments:**\n- `input_path`: Relative path to the Numbers file (required)\n- `output_format`: Output format, currently only PDF is supported (default: \"pdf\")\n\n## Development\n\nIf you want to run from source or contribute:\n\n1. Clone the repository\n2. Install dependencies: `npm install`\n3. Build the project: `npm run build`\n4. Run the server: `npm start`\n\n## License\n\nMIT",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "kmexnx",
        "pdf",
        "excel",
        "kmexnx excel",
        "processing kmexnx",
        "excel apple"
      ],
      "category": "document-processing"
    },
    "krimoi45--chroma-rag-project": {
      "owner": "krimoi45",
      "name": "chroma-rag-project",
      "url": "https://github.com/krimoi45/chroma-rag-project",
      "imageUrl": "/freedevtools/mcp/pfp/krimoi45.webp",
      "description": "Implement a Retrieval-Augmented Generation system using ChromaDB to facilitate semantic similarity search and document retrieval through embedding generation. Enables users to create and query document collections for effective RAG workflows in Python.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-04-15T00:37:27Z",
      "readme_content": "# Projet RAG avec ChromaDB\n\n## Description\nCe projet démontre l'utilisation de ChromaDB pour la mise en place d'un système de Retrieval-Augmented Generation (RAG) en Python.\n\n## Prérequis\n- Python 3.8+\n- pip\n\n## Installation\n1. Clonez le dépôt\n```bash\ngit clone https://github.com/krimoi45/chroma-rag-project.git\ncd chroma-rag-project\n```\n\n2. Créez un environnement virtuel\n```bash\npython -m venv venv\nsource venv/bin/activate  # Sur Windows, utilisez `venv\\Scripts\\activate`\n```\n\n3. Installez les dépendances\n```bash\npip install -r requirements.txt\n```\n\n## Utilisation\nLancez le script principal :\n```bash\npython main.py\n```\n\n## Fonctionnalités\n- Création d'une collection de documents avec ChromaDB\n- Génération d'embeddings avec Sentence Transformers\n- Recherche de similarité sémantique\n- Exemple de système RAG basique\n\n## Technologies\n- ChromaDB\n- Sentence Transformers\n- NumPy\n- Python\n\n## Licence\nProjet open-source\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "retrieval",
        "chromadb",
        "chroma",
        "document retrieval",
        "chroma rag",
        "implement retrieval"
      ],
      "category": "document-processing"
    },
    "kujenga--zotero-mcp": {
      "owner": "kujenga",
      "name": "zotero-mcp",
      "url": "https://github.com/kujenga/zotero-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/kujenga.webp",
      "description": "Access and manage your Zotero library through a Model Context Protocol server, enabling interactions with AI assistants. It provides a focused set of functionalities to streamline library management and integration.",
      "stars": 115,
      "forks": 18,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-25T14:33:13Z",
      "readme_content": "# Model Context Protocol server for Zotero\n\n[![GitHub branch status](https://img.shields.io/github/check-runs/kujenga/zotero-mcp/main)](https://github.com/kujenga/zotero-mcp/actions)\n[![PyPI - Version](https://img.shields.io/pypi/v/zotero-mcp)](https://pypi.org/project/zotero-mcp/)\n\nThis project is a python server that implements the [Model Context Protocol (MCP)](https://modelcontextprotocol.io/introduction) for [Zotero](https://www.zotero.org/), giving you access to your Zotero library within AI assistants. It is intended to implement a small but maximally useful set of interactions with Zotero for use with [MCP clients](https://modelcontextprotocol.io/clients).\n\n<a href=\"https://glama.ai/mcp/servers/jknz38ntu4\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/jknz38ntu4/badge\" alt=\"Zotero Server MCP server\" />\n</a>\n\n## Features\n\nThis MCP server provides the following tools:\n\n- `zotero_search_items`: Search for items in your Zotero library using a text query\n- `zotero_item_metadata`: Get detailed metadata information about a specific Zotero item\n- `zotero_item_fulltext`: Get the full text of a specific Zotero item (i.e. PDF contents)\n\nThese can be discovered and accessed through any MCP client or through the [MCP Inspector](https://modelcontextprotocol.io/docs/tools/inspector).\n\nEach tool returns formatted text containing relevant information from your Zotero items, and AI assistants such as Claude can use them sequentially, searching for items then retrieving their metadata or text content.\n\n## Installation\n\nThis server can either run against either a [local API offered by the Zotero desktop application](https://groups.google.com/g/zotero-dev/c/ElvHhIFAXrY/m/fA7SKKwsAgAJ)) or through the [Zotero Web API](https://www.zotero.org/support/dev/web_api/v3/start). The local API can be a bit more responsive, but requires that the Zotero app be running on the same computer with the API enabled. To enable the local API, do the following steps:\n\n1. Open Zotero and open \"Zotero Settings\"\n1. Under the \"Advanced\" tab, check the box that says \"Allow other applications on this computer to communicate with Zotero\".\n\n> [!IMPORTANT]\n> For access to the `/fulltext` endpoint on the local API which allows retrieving the full content of items in your library, you'll need to install a [Zotero Beta Build](https://www.zotero.org/support/beta_builds) (as of 2025-03-30). Once 7.1 is released this will no longer be the case. See https://github.com/zotero/zotero/pull/5004 for more information. If you do not want to do this, use the Web API instead.\n\nTo use the Zotero Web API, you'll need to create an API key and find your Library ID (usually your User ID) in your Zotero account settings here: <https://www.zotero.org/settings/keys>\n\nThese are the available configuration options:\n\n- `ZOTERO_LOCAL=true`: Use the local Zotero API (default: false, see note below)\n- `ZOTERO_API_KEY`: Your Zotero API key (not required for the local API)\n- `ZOTERO_LIBRARY_ID`: Your Zotero library ID (your user ID for user libraries, not required for the local API)\n- `ZOTERO_LIBRARY_TYPE`: The type of library (user or group, default: user)\n\n### [`uvx`](https://docs.astral.sh/uv/getting-started/installation/) with Local Zotero API\n\nTo use this with Claude Desktop and a direct python install with [`uvx`](https://docs.astral.sh/uv/getting-started/installation/), add the following to the `mcpServers` configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"zotero\": {\n      \"command\": \"uvx\",\n      \"args\": [\"--upgrade\", \"zotero-mcp\"],\n      \"env\": {\n        \"ZOTERO_LOCAL\": \"true\",\n        \"ZOTERO_API_KEY\": \"\",\n        \"ZOTERO_LIBRARY_ID\": \"\"\n      }\n    }\n  }\n}\n```\n\nThe `--upgrade` flag is optional and will pull the latest version when new ones are available. If you don't have `uvx` installed you can use `pipx run` instead, or clone this repository locally and use the instructions in [Development](#development) below.\n\n### Docker with Zotero Web API\n\nIf you want to run this MCP server in a Docker container, you can use the following configuration, inserting your API key and library ID:\n\n```json\n{\n  \"mcpServers\": {\n    \"zotero\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"-i\",\n        \"-e\", \"ZOTERO_API_KEY=PLACEHOLDER\",\n        \"-e\", \"ZOTERO_LIBRARY_ID=PLACEHOLDER\",\n        \"ghcr.io/kujenga/zotero-mcp:main\"\n      ],\n    }\n  }\n}\n```\n\nTo update to a newer version, run `docker pull ghcr.io/kujenga/zotero-mcp:main`. It is also possible to use the docker-based installation to talk to the local Zotero API, but you'll need to modify the above command to ensure that there is network connectivity to the Zotero application's local API interface.\n\n## Development\n\nInformation on making changes and contributing to the project.\n\n1. Clone this repository\n1. Install dependencies with [uv](https://docs.astral.sh/uv/) by running: `uv sync`\n1. Create a `.env` file in the project root with the environment variables above\n\nStart the [MCP Inspector](https://modelcontextprotocol.io/docs/tools/inspector) for local development:\n\n```bash\nnpx @modelcontextprotocol/inspector uv run zotero-mcp\n```\n\nTo test the local repository against Claude Desktop, run `echo $PWD/.venv/bin/zotero-mcp` in your shell within this directory, then set the following within your Claude Desktop configuration\n```json\n{\n  \"mcpServers\": {\n    \"zotero\": {\n      \"command\": \"/path/to/zotero-mcp/.venv/bin/zotero-mcp\"\n      \"env\": {\n        // Whatever configuration is desired.\n      }\n    }\n  }\n}\n```\n\n### Running Tests\n\nTo run the test suite:\n\n```bash\nuv run pytest\n```\n\n### Docker Development\n\nBuild the container image with this command:\n\n```sh\ndocker build . -t zotero-mcp:local\n```\n\nTo test the container with the MCP inspector, run the following command:\n\n```sh\nnpx @modelcontextprotocol/inspector \\\n    -e ZOTERO_API_KEY=$ZOTERO_API_KEY \\\n    -e ZOTERO_LIBRARY_ID=$ZOTERO_LIBRARY_ID \\\n    docker run --rm -i \\\n        --env ZOTERO_API_KEY \\\n        --env ZOTERO_LIBRARY_ID \\\n        zotero-mcp:local\n```\n\n## Relevant Documentation\n\n- https://modelcontextprotocol.io/tutorials/building-mcp-with-llms\n- https://github.com/modelcontextprotocol/python-sdk\n- https://pyzotero.readthedocs.io/en/latest/\n- https://www.zotero.org/support/dev/web_api/v3/start\n- https://modelcontextprotocol.io/llms-full.txt can be utilized by LLMs\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "zotero",
        "library",
        "protocol",
        "zotero library",
        "manage zotero",
        "zotero mcp"
      ],
      "category": "document-processing"
    },
    "kumzhijr--Covenant-ai": {
      "owner": "kumzhijr",
      "name": "Covenant-ai",
      "url": "https://github.com/kumzhijr/Covenant-ai",
      "imageUrl": "/freedevtools/mcp/pfp/kumzhijr.webp",
      "description": "Advanced contract analysis and management platform that processes PDF contracts, assesses risks, identifies opportunities, and provides user management and interactive visualization features.",
      "stars": 1,
      "forks": 0,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-08-14T20:50:48Z",
      "readme_content": "# Covenant AI Platform\n\n![Covenant AI Architecture Diagram](https://via.placeholder.com/800x400.png?text=AI+Contract+Analysis+Architecture)\n\nA full-stack contract analysis platform leveraging AI for legal document processing, risk assessment, and opportunity identification.\n\n## Key Features\n- **AI-Powered Analysis** - Multi-stage processing of PDF contracts\n- **Risk Assessment** - Severity-graded risk detection\n- **Opportunity Identification** - Impact-rated opportunity discovery\n- **User Management** - OAuth authentication with role-based access\n- **Payment Integration** - Stripe subscription management\n- **Real-time Dashboard** - Interactive results visualization\n\n## Technology Stack\n\n### Frontend\n| Component        | Technology           |\n|------------------|----------------------|\n| Framework        | Next.js 14 (App Router) |\n| State Management | React Query + Zustand |\n| UI Library       | Shadcn UI            |\n| Charts           | Recharts             |\n| Tables           | TanStack Table       |\n\n### Backend\n| Component        | Technology           |\n|------------------|----------------------|\n| Runtime          | Node.js 20           |\n| Framework        | Express              |\n| Database         | MongoDB Atlas        |\n| Cache            | Redis                |\n| Auth             | Passport.js + JWT    |\n| Payments         | Stripe API           |\n\n## Installation\n\n### Prerequisites\n- Node.js 20+\n- MongoDB 7+\n- Redis 7+\n- Stripe Account\n- Google OAuth Credentials\n\n```bash\n# Clone repository\ngit clone https://github.com/your-org/covenant-ai.git\ncd covenant-ai\n```\n\n### Client Setup\n```bash\ncd client\nnpm install\n\n# Environment variables (create .env)\nNEXT_PUBLIC_API_URL=http://localhost:5000\nNEXT_PUBLIC_STRIPE_PUBLISHABLE_KEY=your_stripe_key\n```\n\n### Server Setup\n```bash\ncd server\nnpm install\n\n# Environment variables (create .env)\nMONGO_URI=mongodb://localhost:27017/covenantai\nREDIS_URL=redis://localhost:6379\nSTRIPE_SECRET_KEY=your_stripe_secret\nGOOGLE_CLIENT_ID=your_google_id\nGOOGLE_CLIENT_SECRET=your_google_secret\nJWT_SECRET=your_jwt_secret\n```\n\n## Database Structure\n\n### Contract Analysis Schema\n```mermaid\nerDiagram\n    CONTRACT_ANALYSIS {\n        ObjectId _id\n        ObjectId userId\n        string contractText\n        IRisk[] risks\n        IOpportunity[] opportunities\n        string summary\n        string[] recommendations\n        number overallScore\n        date createdAt\n        string aiModel\n        string contractType\n    }\n    \n    RISK {\n        string risk\n        string explanation\n        string severity\n    }\n    \n    OPPORTUNITY {\n        string opportunity\n        string explanation\n        string impact\n    }\n```\n\n## AI Processing Workflow\n\n```mermaid\nsequenceDiagram\n    participant User\n    participant Frontend\n    participant Backend\n    participant AI\n    participant Redis\n    participant MongoDB\n    \n    User->>Frontend: Upload PDF Contract\n    Frontend->>Backend: POST /api/analyze\n    Backend->>Redis: Store raw PDF (temp)\n    Backend->>AI: Extract text/type\n    AI-->>Backend: Metadata\n    Backend->>AI: Analyze risks\n    AI-->>Backend: Risk report\n    Backend->>AI: Detect opportunities\n    AI-->>Backend: Opportunity report\n    Backend->>MongoDB: Persist analysis\n    Backend-->>Frontend: Analysis results\n    Frontend-->>User: Display dashboard\n```\n\n## Running the Application\n\n```bash\n# Start both services (from root directory)\nconcurrently \"cd client && npm run dev\" \"cd server && npm run start\"\n\n# Access interfaces\nFrontend: http://localhost:3000\nBackend: http://localhost:5000\nAPI Docs: http://localhost:5000/api-docs\n```\n\n## Configuration Guide\n\n### Required Services\n1. **MongoDB** - Document storage\n2. **Redis** - PDF text caching\n3. **Stripe** - Payment processing\n4. **Google OAuth** - User authentication\n\n### Environment Variables\n`.env.example` for client:\n```ini\nNEXT_PUBLIC_API_URL=\"http://localhost:5000\"\nNEXT_PUBLIC_STRIPE_PUBLISHABLE_KEY=\"pk_test_...\"\nNEXT_PUBLIC_GOOGLE_CLIENT_ID=\"...\"\n```\n\n`.env.example` for server:\n```ini\nMONGO_URI=\"mongodb://localhost:27017/covenantai\"\nREDIS_URL=\"redis://localhost:6379\"\nSTRIPE_SECRET_KEY=\"sk_test_...\"\nJWT_SECRET=\"your_jwt_secret_here\"\n```\n\n## Development Scripts\n\n```bash\n# Client\nnpm run dev        # Start development server\nnpm run build      # Create production build\nnpm run lint       # Run ESLint\n\n# Server \nnpm run start      # Start production server\nnpm run dev        # Start with nodemon\nnpm run test       # Run integration tests\n```\n\n## License\nMIT License - See [LICENSE](LICENSE) for details\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "document",
        "contracts",
        "contract",
        "pdf contracts",
        "advanced contract",
        "contract analysis"
      ],
      "category": "document-processing"
    },
    "landicefu--divide-and-conquer-mcp-server": {
      "owner": "landicefu",
      "name": "divide-and-conquer-mcp-server",
      "url": "https://github.com/landicefu/divide-and-conquer-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/landicefu.webp",
      "description": "Breaks down complex tasks into manageable pieces using a structured JSON format, tracks progress, and maintains context across multiple conversations.",
      "stars": 6,
      "forks": 6,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-07-28T04:35:30Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/landicefu-divide-and-conquer-mcp-server-badge.png)](https://mseep.ai/app/landicefu-divide-and-conquer-mcp-server)\n\n# Divide and Conquer MCP Server\n[![smithery badge](https://smithery.ai/badge/@landicefu/divide-and-conquer-mcp-server)](https://smithery.ai/server/@landicefu/divide-and-conquer-mcp-server)\n\nA Model Context Protocol (MCP) server that enables AI agents to break down complex tasks into manageable pieces using a structured JSON format.\n\n## Table of Contents\n\n- [Purpose](#purpose)\n- [Key Features](#key-features)\n- [Quick Start](#quick-start)\n- [Installation](#installation)\n- [Tools](#tools)\n- [Usage Examples](#usage-examples)\n- [Use Cases](#use-cases)\n- [Configuration Storage](#configuration-storage)\n- [Contributing](#contributing)\n- [License](#license)\n\n## Purpose\n\nThe Divide and Conquer MCP Server is an evolution of the Temp Notes MCP Server, designed specifically for complex tasks that need to be broken down into manageable pieces. Instead of using a simple text file, this server uses a structured JSON format to store task information, checklists, and context, making it easier to track progress and maintain context across multiple conversations.\n\n## Key Features\n\n- **Structured JSON Format**: Instead of plain text, uses a JSON structure to store task information\n- **Task Tracking**: Includes checklist functionality with completion status tracking\n- **Context Preservation**: Dedicated fields for task context and detailed descriptions\n- **Progress Monitoring**: Easy visualization of completed vs. remaining tasks\n- **Task Ordering**: Maintains the order of tasks for sequential execution\n- **Task Insertion**: Ability to insert new tasks at specific positions in the checklist\n- **Metadata**: Track additional information like tags, priority, and estimated completion time\n- **Notes and Resources**: Store additional notes and resources related to the task\n\n## Quick Start\n\n1. Add the server to your MCP configuration:\n   ```json\n   {\n     \"mcpServers\": {\n       \"divide-and-conquer\": {\n         \"command\": \"npx\",\n         \"args\": [\"-y\", \"@landicefu/divide-and-conquer-mcp-server\"],\n         \"disabled\": false\n       }\n     }\n   }\n   ```\n\n2. Start using it in your conversations:\n   ```javascript\n   // Initialize a new task\n   await use_mcp_tool({\n     server_name: \"divide-and-conquer\",\n     tool_name: \"initialize_task\",\n     arguments: {\n       task_description: \"Refactor the authentication system\",\n       context_for_all_tasks: \"The current system uses session-based authentication.\"\n     }\n   });\n   \n   // Add checklist items\n   await use_mcp_tool({\n     server_name: \"divide-and-conquer\",\n     tool_name: \"add_checklist_item\",\n     arguments: {\n       task: \"Analyze current authentication flow\",\n       detailed_description: \"Review the existing authentication code.\",\n       context_and_plan: \"Look at src/auth/* files. The current implementation uses express-session with MongoDB store.\"\n     }\n   });\n   ```\n\n## Installation\n\n### Installing via Smithery\n\nTo install Divide and Conquer Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@landicefu/divide-and-conquer-mcp-server):\n\n```bash\nnpx -y @smithery/cli install @landicefu/divide-and-conquer-mcp-server --client claude\n```\n\n### Option 1: Using npx (Recommended)\n\nAdd the server to your MCP configuration:\n```json\n{\n  \"mcpServers\": {\n    \"divide-and-conquer\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@landicefu/divide-and-conquer-mcp-server\"],\n      \"disabled\": false\n    }\n  }\n}\n```\n\n### Option 2: Install from source\n\n1. Clone the repository:\n   ```bash\n   git clone https://github.com/landicefu/divide-and-conquer-mcp-server.git\n   cd divide-and-conquer-mcp-server\n   ```\n\n2. Install dependencies:\n   ```bash\n   npm install\n   ```\n\n3. Build the server:\n   ```bash\n   npm run build\n   ```\n\n4. Add the server to your MCP configuration:\n   ```json\n   {\n     \"mcpServers\": {\n       \"divide-and-conquer\": {\n         \"command\": \"node\",\n         \"args\": [\"/path/to/divide-and-conquer-mcp-server/build/index.js\"],\n         \"disabled\": false\n       }\n     }\n   }\n   ```\n\n## Tools\n\nThe Divide and Conquer MCP Server provides the following tools:\n\n### `initialize_task`\n\nCreates a new task with the specified description and optional initial checklist items.\n\n### `update_task_description`\n\nUpdates the main task description.\n\n### `update_context`\n\nUpdates the context information for all tasks.\n\n### `add_checklist_item`\n\nAdds a new item to the checklist.\n\n### `update_checklist_item`\n\nUpdates an existing checklist item.\n\n### `mark_task_done`\n\nMarks a checklist item as done.\n\n### `mark_task_undone`\n\nMarks a checklist item as not done.\n\n### `remove_checklist_item`\n\nRemoves a checklist item.\n\n### `reorder_checklist_item`\n\nMoves a checklist item to a new position.\n\n### `add_note`\n\nAdds a note to the task.\n\n### `add_resource`\n\nAdds a resource to the task.\n\n### `update_metadata`\n\nUpdates the task metadata.\n\n### `clear_task`\n\nClears the current task data.\n\n### `get_checklist_summary`\n\nReturns a summary of the checklist with completion status. Context information is intentionally excluded from the summary to save context window space.\n\n### `get_current_task_details`\n\nRetrieves details of the current task (first uncompleted task) with full context, along with all other tasks with limited fields. For the current task, all fields including context_and_plan are included. For other tasks, only task, detailed_description, and done status are included (context_and_plan is excluded). This is the recommended tool to use when working with tasks.\n\n## Usage Examples\n\n### Initializing a Complex Task\n\n```javascript\nawait use_mcp_tool({\n  server_name: \"divide-and-conquer\",\n  tool_name: \"initialize_task\",\n  arguments: {\n    task_description: \"Refactor the authentication system to use JWT tokens and improve security\",\n    context_for_all_tasks: \"The current system uses session-based authentication with cookies. We need to migrate to JWT for better scalability and security.\",\n    initial_checklist: [\n      {\n        task: \"Analyze current authentication flow\",\n        detailed_description: \"Review the existing authentication code to understand the current flow.\",\n        context_and_plan: \"Look at src/auth/* files. The current implementation uses express-session with MongoDB store. Pay special attention to session expiration handling.\"\n      },\n      {\n        task: \"Design JWT implementation\",\n        detailed_description: \"Create a design document outlining how JWT will be implemented.\",\n        context_and_plan: \"Consider token structure, storage, and refresh mechanisms. Research best practices for JWT implementation in Node.js applications. Reference the security requirements document in docs/security.md.\"\n      }\n    ],\n    metadata: {\n      tags: [\"security\", \"refactoring\", \"authentication\"],\n      priority: \"high\",\n      estimated_completion_time: \"2 weeks\"\n    }\n  }\n});\n```\n\n### Getting a Checklist Summary\n\n```javascript\nconst summary = await use_mcp_tool({\n  server_name: \"divide-and-conquer\",\n  tool_name: \"get_checklist_summary\",\n  arguments: {\n    include_descriptions: true\n  }\n});\n\n// Result contains a formatted summary of the checklist with completion status (context is excluded to save space)\n```\n\n### Getting Current Task Details\n\n```javascript\nconst taskDetails = await use_mcp_tool({\n  server_name: \"divide-and-conquer\",\n  tool_name: \"get_current_task_details\",\n  arguments: {}\n});\n\n// Result contains:\n// - ultimate_goal: The final goal of the entire task (task_description)\n// - tasks: Array of all tasks, where the current task (first uncompleted) has all fields including context_and_plan,\n//   while other tasks have limited fields (task, detailed_description, done) without context_and_plan\n// - current_task_index: Index of the current task (first uncompleted)\n// - Additional task metadata, notes, resources, etc.\n```\n\n## Use Cases\n\n### 1. Complex Software Development Tasks\n\nWhen working on complex software development tasks, AI agents often face context window limitations that make it difficult to complete all steps in a single conversation. The Divide and Conquer MCP Server allows agents to:\n\n- Break down large tasks into smaller, manageable pieces\n- Track progress across multiple conversations\n- Maintain important context that would otherwise be lost\n- Organize tasks in a logical sequence\n- Document decisions and resources\n\n### 2. Project Planning and Management\n\nFor project planning and management tasks, the server enables:\n\n- Creating structured project plans with tasks and subtasks\n- Tracking progress and completion status\n- Maintaining context and requirements\n- Documenting decisions and resources\n- Collaborating across multiple conversations\n\n### 3. Research and Analysis\n\nWhen conducting research and analysis, agents can:\n\n- Break down research questions into specific areas to investigate\n- Track progress and findings\n- Maintain context and background information\n- Document sources and resources\n- Organize findings in a structured way\n\n## JSON Structure\n\nThe server uses the following JSON structure to store task information:\n\n```json\n{\n  \"task_description\": \"A medium-level detailed description about the whole task. The final goal we want to achieve.\",\n  \n  \"checklist\": [\n    {\n      \"done\": false,\n      \"task\": \"A short yet comprehensive name for the task\",\n      \"detailed_description\": \"A longer description about what we want to achieve with this task\",\n      \"context_and_plan\": \"Related information, files the agent should read, and more details from other tasks, as well as a detailed plan for this task. This is typically the longest string.\"\n    }\n  ],\n  \n  \"context_for_all_tasks\": \"Information that all tasks in the checklist should include.\",\n  \n  \"metadata\": {\n    \"created_at\": \"ISO timestamp\",\n    \"updated_at\": \"ISO timestamp\",\n    \"progress\": {\n      \"completed\": 0,\n      \"total\": 1,\n      \"percentage\": 0\n    },\n    \"tags\": [\"tag1\", \"tag2\"],\n    \"priority\": \"high|medium|low\",\n    \"estimated_completion_time\": \"ISO timestamp or duration\"\n  },\n  \n  \"notes\": [\n    {\n      \"timestamp\": \"ISO timestamp\",\n      \"content\": \"Additional notes or observations about the overall task\"\n    }\n  ],\n  \n  \"resources\": [\n    {\n      \"name\": \"Resource name\",\n      \"url\": \"URL or file path\",\n      \"description\": \"Description of the resource\"\n    }\n  ]\n}\n```\n\n## Configuration Storage\n\nBy default, the Divide and Conquer MCP Server stores task data in the following location:\n\n- On macOS/Linux: `~/.mcp_config/divide_and_conquer.json` (which expands to `/Users/username/.mcp_config/divide_and_conquer.json`)\n- On Windows: `C:\\Users\\username\\.mcp_config\\divide_and_conquer.json`\n\nThis file is created automatically when you first initialize a task. If the file doesn't exist when you try to read task data, the server will return an empty task structure and create the file when you write to it next time.\n\nThe server handles the following scenarios:\n\n- If the file doesn't exist when reading: Returns an empty task structure\n- If the directory doesn't exist: Creates the directory structure automatically when writing\n- If the file is corrupted or inaccessible: Returns appropriate error messages\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "processing",
        "mcp",
        "tasks",
        "document processing",
        "mcp server",
        "conquer mcp"
      ],
      "category": "document-processing"
    },
    "langchain-ai--mcpdoc": {
      "owner": "langchain-ai",
      "name": "mcpdoc",
      "url": "https://github.com/langchain-ai/mcpdoc",
      "imageUrl": "/freedevtools/mcp/pfp/langchain-ai.webp",
      "description": "Provides a user-defined list of llms.txt files and fetches documents from URLs within those files for auditing tool calls and enhancing context retrieval for LLM interactions. Connects with various IDEs and applications to improve the development experience while ensuring transparency and control.",
      "stars": 770,
      "forks": 85,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-04T03:33:49Z",
      "readme_content": "# MCP LLMS-TXT Documentation Server\n\n## Overview\n\n[llms.txt](https://llmstxt.org/) is a website index for LLMs, providing background information, guidance, and links to detailed markdown files. IDEs like Cursor and Windsurf or apps like Claude Code/Desktop can use `llms.txt` to retrieve context for tasks. However, these apps use different built-in tools to read and process files like `llms.txt`. The retrieval process can be opaque, and there is not always a way to audit the tool calls or the context returned.\n\n[MCP](https://github.com/modelcontextprotocol) offers a way for developers to have *full control* over tools used by these applications. Here, we create [an open source MCP server](https://github.com/modelcontextprotocol) to provide MCP host applications (e.g., Cursor, Windsurf, Claude Code/Desktop) with (1) a user-defined list of `llms.txt` files and (2) a simple  `fetch_docs` tool read URLs within any of the provided `llms.txt` files. This allows the user to audit each tool call as well as the context returned. \n\n<img src=\"https://github.com/user-attachments/assets/736f8f55-833d-4200-b833-5fca01a09e1b\" width=\"60%\">\n\n## llms-txt\n\nYou can find llms.txt files for langgraph and langchain here:\n\n| Library          | llms.txt                                                                                                   |\n|------------------|------------------------------------------------------------------------------------------------------------|\n| LangGraph Python | [https://langchain-ai.github.io/langgraph/llms.txt](https://langchain-ai.github.io/langgraph/llms.txt)     |\n| LangGraph JS     | [https://langchain-ai.github.io/langgraphjs/llms.txt](https://langchain-ai.github.io/langgraphjs/llms.txt) |\n| LangChain Python | [https://python.langchain.com/llms.txt](https://python.langchain.com/llms.txt)                             |\n| LangChain JS     | [https://js.langchain.com/llms.txt](https://js.langchain.com/llms.txt)                                     |\n\n## Quickstart\n\n#### Install uv\n* Please see [official uv docs](https://docs.astral.sh/uv/getting-started/installation/#installation-methods) for other ways to install `uv`.\n\n```bash\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n```\n\n#### Choose an `llms.txt` file to use. \n* For example, [here's](https://langchain-ai.github.io/langgraph/llms.txt) the LangGraph `llms.txt` file.\n\n> **Note: Security and Domain Access Control**\n> \n> For security reasons, mcpdoc implements strict domain access controls:\n> \n> 1. **Remote llms.txt files**: When you specify a remote llms.txt URL (e.g., `https://langchain-ai.github.io/langgraph/llms.txt`), mcpdoc automatically adds only that specific domain (`langchain-ai.github.io`) to the allowed domains list. This means the tool can only fetch documentation from URLs on that domain.\n> \n> 2. **Local llms.txt files**: When using a local file, NO domains are automatically added to the allowed list. You MUST explicitly specify which domains to allow using the `--allowed-domains` parameter.\n> \n> 3. **Adding additional domains**: To allow fetching from domains beyond those automatically included:\n>    - Use `--allowed-domains domain1.com domain2.com` to add specific domains\n>    - Use `--allowed-domains '*'` to allow all domains (use with caution)\n> \n> This security measure prevents unauthorized access to domains not explicitly approved by the user, ensuring that documentation can only be retrieved from trusted sources.\n\n#### (Optional) Test the MCP server locally with your `llms.txt` file(s) of choice:\n```bash\nuvx --from mcpdoc mcpdoc \\\n    --urls \"LangGraph:https://langchain-ai.github.io/langgraph/llms.txt\" \"LangChain:https://python.langchain.com/llms.txt\" \\\n    --transport sse \\\n    --port 8082 \\\n    --host localhost\n```\n\n* This should run at: http://localhost:8082\n\n![Screenshot 2025-03-18 at 3 29 30 PM](https://github.com/user-attachments/assets/24a3d483-cd7a-4c7e-a4f7-893df70e888f)\n\n* Run [MCP inspector](https://modelcontextprotocol.io/docs/tools/inspector) and connect to the running server:\n```bash\nnpx @modelcontextprotocol/inspector\n```\n\n![Screenshot 2025-03-18 at 3 30 30 PM](https://github.com/user-attachments/assets/14645d57-1b52-4a5e-abfe-8e7756772704)\n\n* Here, you can test the `tool` calls. \n\n#### Connect to Cursor \n\n* Open `Cursor Settings` and `MCP` tab.\n* This will open the `~/.cursor/mcp.json` file.\n\n![Screenshot 2025-03-19 at 11 01 31 AM](https://github.com/user-attachments/assets/3d1c8eb3-4d40-487f-8bad-3f9e660f770a)\n\n* Paste the following into the file (we use the `langgraph-docs-mcp` name and link to the LangGraph `llms.txt`).\n\n```\n{\n  \"mcpServers\": {\n    \"langgraph-docs-mcp\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"--from\",\n        \"mcpdoc\",\n        \"mcpdoc\",\n        \"--urls\",\n        \"LangGraph:https://langchain-ai.github.io/langgraph/llms.txt LangChain:https://python.langchain.com/llms.txt\",\n        \"--transport\",\n        \"stdio\"\n      ]\n    }\n  }\n}\n```\n\n* Confirm that the server is running in your `Cursor Settings/MCP` tab.\n* Best practice is to then update Cursor Global (User) rules.\n* Open Cursor `Settings/Rules` and update `User Rules` with the following (or similar):\n\n```\nfor ANY question about LangGraph, use the langgraph-docs-mcp server to help answer -- \n+ call list_doc_sources tool to get the available llms.txt file\n+ call fetch_docs tool to read it\n+ reflect on the urls in llms.txt \n+ reflect on the input question \n+ call fetch_docs on any urls relevant to the question\n+ use this to answer the question\n```\n\n* `CMD+L` (on Mac) to open chat.\n* Ensure `agent` is selected. \n\n![Screenshot 2025-03-18 at 1 56 54 PM](https://github.com/user-attachments/assets/0dd747d0-7ec0-43d2-b6ef-cdcf5a2a30bf)\n\nThen, try an example prompt, such as:\n```\nwhat are types of memory in LangGraph?\n```\n\n![Screenshot 2025-03-18 at 1 58 38 PM](https://github.com/user-attachments/assets/180966b5-ab03-4b78-8b5d-bab43f5954ed)\n\n### Connect to Windsurf\n\n* Open Cascade with `CMD+L` (on Mac).\n* Click `Configure MCP` to open the config file, `~/.codeium/windsurf/mcp_config.json`.\n* Update with `langgraph-docs-mcp` as noted above.\n\n![Screenshot 2025-03-19 at 11 02 52 AM](https://github.com/user-attachments/assets/d45b427c-1c1e-4602-820a-7161a310af24)\n\n* Update `Windsurf Rules/Global rules` with the following (or similar):\n\n```\nfor ANY question about LangGraph, use the langgraph-docs-mcp server to help answer -- \n+ call list_doc_sources tool to get the available llms.txt file\n+ call fetch_docs tool to read it\n+ reflect on the urls in llms.txt \n+ reflect on the input question \n+ call fetch_docs on any urls relevant to the question\n```\n\n![Screenshot 2025-03-18 at 2 02 12 PM](https://github.com/user-attachments/assets/5a29bd6a-ad9a-4c4a-a4d5-262c914c5276)\n\nThen, try the example prompt:\n* It will perform your tool calls.\n\n![Screenshot 2025-03-18 at 2 03 07 PM](https://github.com/user-attachments/assets/0e24e1b2-dc94-4153-b4fa-495fd768125b)\n\n### Connect to Claude Desktop\n\n* Open `Settings/Developer` to update `~/Library/Application\\ Support/Claude/claude_desktop_config.json`.\n* Update with `langgraph-docs-mcp` as noted above.\n* Restart Claude Desktop app.\n\n> [!Note]\n> If you run into issues with Python version incompatibility when trying to add MCPDoc tools to Claude Desktop, you can explicitly specify the filepath to `python` executable in the `uvx` command.\n>\n> <details>\n> <summary>Example configuration</summary>\n>\n> ```\n> {\n>   \"mcpServers\": {\n>     \"langgraph-docs-mcp\": {\n>       \"command\": \"uvx\",\n>       \"args\": [\n>         \"--python\",\n>         \"/path/to/python\",\n>         \"--from\",\n>         \"mcpdoc\",\n>         \"mcpdoc\",\n>         \"--urls\",\n>         \"LangGraph:https://langchain-ai.github.io/langgraph/llms.txt\",\n>         \"--transport\",\n>         \"stdio\"\n>       ]\n>     }\n>   }\n> }\n> ```\n> </details>\n\n> [!Note]\n> Currently (3/21/25) it appears that Claude Desktop does not support `rules` for global rules, so appending the following to your prompt.\n\n```\n<rules>\nfor ANY question about LangGraph, use the langgraph-docs-mcp server to help answer -- \n+ call list_doc_sources tool to get the available llms.txt file\n+ call fetch_docs tool to read it\n+ reflect on the urls in llms.txt \n+ reflect on the input question \n+ call fetch_docs on any urls relevant to the question\n</rules>\n```\n\n![Screenshot 2025-03-18 at 2 05 54 PM](https://github.com/user-attachments/assets/228d96b6-8fb3-4385-8399-3e42fa08b128)\n\n* You will see your tools visible in the bottom right of your chat input.\n\n![Screenshot 2025-03-18 at 2 05 39 PM](https://github.com/user-attachments/assets/71f3c507-91b2-4fa7-9bd1-ac9cbed73cfb)\n\nThen, try the example prompt:\n\n* It will ask to approve tool calls as it processes your request.\n\n![Screenshot 2025-03-18 at 2 06 54 PM](https://github.com/user-attachments/assets/59b3a010-94fa-4a4d-b650-5cd449afeec0)\n\n### Connect to Claude Code\n\n* In a terminal after installing [Claude Code](https://docs.anthropic.com/en/docs/agents-and-tools/claude-code/overview), run this command to add the MCP server to your project:\n```\nclaude mcp add-json langgraph-docs '{\"type\":\"stdio\",\"command\":\"uvx\" ,\"args\":[\"--from\", \"mcpdoc\", \"mcpdoc\", \"--urls\", \"langgraph:https://langchain-ai.github.io/langgraph/llms.txt\", \"LangChain:https://python.langchain.com/llms.txt\"]}' -s local\n```\n* You will see `~/.claude.json` updated.\n* Test by launching Claude Code and running to view your tools:\n```\n$ Claude\n$ /mcp \n```\n\n![Screenshot 2025-03-18 at 2 13 49 PM](https://github.com/user-attachments/assets/eb876a0e-27b4-480e-8c37-0f683f878616)\n\n> [!Note]\n> Currently (3/21/25) it appears that Claude Code does not support `rules` for global rules, so appending the following to your prompt.\n\n```\n<rules>\nfor ANY question about LangGraph, use the langgraph-docs-mcp server to help answer -- \n+ call list_doc_sources tool to get the available llms.txt file\n+ call fetch_docs tool to read it\n+ reflect on the urls in llms.txt \n+ reflect on the input question \n+ call fetch_docs on any urls relevant to the question\n</rules>\n```\n\nThen, try the example prompt:\n\n* It will ask to approve tool calls.\n\n![Screenshot 2025-03-18 at 2 14 37 PM](https://github.com/user-attachments/assets/5b9a2938-ea69-4443-8d3b-09061faccad0)\n\n## Command-line Interface\n\nThe `mcpdoc` command provides a simple CLI for launching the documentation server. \n\nYou can specify documentation sources in three ways, and these can be combined:\n\n1. Using a YAML config file:\n\n* This will load the LangGraph Python documentation from the `sample_config.yaml` file in this repo.\n\n```bash\nmcpdoc --yaml sample_config.yaml\n```\n\n2. Using a JSON config file:\n\n* This will load the LangGraph Python documentation from the `sample_config.json` file in this repo.\n\n```bash\nmcpdoc --json sample_config.json\n```\n\n3. Directly specifying llms.txt URLs with optional names:\n\n* URLs can be specified either as plain URLs or with optional names using the format `name:url`.\n* You can specify multiple URLs by using the `--urls` parameter multiple times.\n* This is how we loaded `llms.txt` for the MCP server above.\n\n```bash\nmcpdoc --urls LangGraph:https://langchain-ai.github.io/langgraph/llms.txt --urls LangChain:https://python.langchain.com/llms.txt\n```\n\nYou can also combine these methods to merge documentation sources:\n\n```bash\nmcpdoc --yaml sample_config.yaml --json sample_config.json --urls LangGraph:https://langchain-ai.github.io/langgraph/llms.txt --urls LangChain:https://python.langchain.com/llms.txt\n```\n\n## Additional Options\n\n- `--follow-redirects`: Follow HTTP redirects (defaults to False)\n- `--timeout SECONDS`: HTTP request timeout in seconds (defaults to 10.0)\n\nExample with additional options:\n\n```bash\nmcpdoc --yaml sample_config.yaml --follow-redirects --timeout 15\n```\n\nThis will load the LangGraph Python documentation with a 15-second timeout and follow any HTTP redirects if necessary.\n\n## Configuration Format\n\nBoth YAML and JSON configuration files should contain a list of documentation sources. \n\nEach source must include an `llms_txt` URL and can optionally include a `name`:\n\n### YAML Configuration Example (sample_config.yaml)\n\n```yaml\n# Sample configuration for mcp-mcpdoc server\n# Each entry must have a llms_txt URL and optionally a name\n- name: LangGraph Python\n  llms_txt: https://langchain-ai.github.io/langgraph/llms.txt\n```\n\n### JSON Configuration Example (sample_config.json)\n\n```json\n[\n  {\n    \"name\": \"LangGraph Python\",\n    \"llms_txt\": \"https://langchain-ai.github.io/langgraph/llms.txt\"\n  }\n]\n```\n\n## Programmatic Usage\n\n```python\nfrom mcpdoc.main import create_server\n\n# Create a server with documentation sources\nserver = create_server(\n    [\n        {\n            \"name\": \"LangGraph Python\",\n            \"llms_txt\": \"https://langchain-ai.github.io/langgraph/llms.txt\",\n        },\n        # You can add multiple documentation sources\n        # {\n        #     \"name\": \"Another Documentation\",\n        #     \"llms_txt\": \"https://example.com/llms.txt\",\n        # },\n    ],\n    follow_redirects=True,\n    timeout=15.0,\n)\n\n# Run the server\nserver.run(transport=\"stdio\")\n```\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcpdoc",
        "documents",
        "document",
        "llms txt",
        "mcpdoc provides",
        "ai mcpdoc"
      ],
      "category": "document-processing"
    },
    "lishenxydlgzs--simple-files-vectorstore": {
      "owner": "lishenxydlgzs",
      "name": "simple-files-vectorstore",
      "url": "https://github.com/lishenxydlgzs/simple-files-vectorstore",
      "imageUrl": "/freedevtools/mcp/pfp/lishenxydlgzs.webp",
      "description": "Creates a vector store from local directories and files, enabling semantic search across document contents. Monitors specified directories for file changes and generates vector embeddings to facilitate search functionality.",
      "stars": 33,
      "forks": 7,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-26T02:44:28Z",
      "readme_content": "# @lishenxydlgzs/simple-files-vectorstore\n\nA Model Context Protocol (MCP) server that provides semantic search capabilities across files. This server watches specified directories and creates vector embeddings of file contents, enabling semantic search across your documents.\n\n## Installation & Usage\nAdd to your MCP settings file:\n```json\n{\n  \"mcpServers\": {\n    \"files-vectorstore\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@lishenxydlgzs/simple-files-vectorstore\"\n      ],\n      \"env\": {\n        \"WATCH_DIRECTORIES\": \"/path/to/your/directories\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\nMCP settings file locations:\n- VSCode Cline Extension: `~/Library/Application Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json`\n- Claude Desktop App: `~/Library/Application Support/Claude/claude_desktop_config.json`\n\n## Configuration\n\nThe server requires configuration through environment variables:\n\n### Required Environment Variables\n\nYou must specify directories to watch using ONE of the following methods:\n\n- `WATCH_DIRECTORIES`: Comma-separated list of directories to watch\n- `WATCH_CONFIG_FILE`: Path to a JSON configuration file with a `watchList` array\n\nExample using WATCH_DIRECTORIES:\n```json\n{\n  \"mcpServers\": {\n    \"files-vectorstore\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@lishenxydlgzs/simple-files-vectorstore\"\n      ],\n      \"env\": {\n        \"WATCH_DIRECTORIES\": \"/path/to/dir1,/path/to/dir2\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\nExample using WATCH_CONFIG_FILE:\n```json\n{\n  \"mcpServers\": {\n    \"files-vectorstore\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@lishenxydlgzs/simple-files-vectorstore\"\n      ],\n      \"env\": {\n        \"WATCH_CONFIG_FILE\": \"/path/to/watch-config.json\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\nThe watch config file should have the following structure:\n```json\n{\n  \"watchList\": [\n    \"/path/to/dir1\",\n    \"/path/to/dir2\",\n    \"/path/to/specific/file.txt\"\n  ]\n}\n```\n\n### Optional Environment Variables\n\n- `CHUNK_SIZE`: Size of text chunks for processing (default: 1000)\n- `CHUNK_OVERLAP`: Overlap between chunks (default: 200)\n- `IGNORE_FILE`: Path to a .gitignore style file to exclude files/directories based on patterns\n\nExample with all optional parameters:\n\n```json\n  {\n    \"mcpServers\": {\n      \"files-vectorstore\": {\n        \"command\": \"npx\",\n        \"args\": [\n          \"-y\",\n          \"@lishenxydlgzs/simple-files-vectorstore\"\n        ],\n        \"env\": {\n          \"WATCH_DIRECTORIES\": \"/path/to/dir1,/path/to/dir2\",\n          \"CHUNK_SIZE\": \"2000\",\n          \"CHUNK_OVERLAP\": \"500\",\n          \"IGNORE_FILE\": \"/path/to/.gitignore\"\n        },\n        \"disabled\": false,\n        \"autoApprove\": []\n      }\n    }\n  }\n  ```\n## MCP Tools\n\nThis server provides the following MCP tools:\n\n### 1. search\n\nPerform semantic search across indexed files.\n\nParameters:\n- `query` (required): The search query string\n- `limit` (optional): Maximum number of results to return (default: 5, max: 20)\n\nExample response:\n```json\n[\n  {\n    \"content\": \"matched text content\",\n    \"source\": \"/path/to/file\",\n    \"fileType\": \"markdown\",\n    \"score\": 0.85\n  }\n]\n```\n\n### 2. get_stats\n\nGet statistics about indexed files.\n\nParameters: None\n\nExample response:\n```json\n{\n  \"totalDocuments\": 42,\n  \"watchedDirectories\": [\"/path/to/docs\"],\n  \"processingFiles\": []\n}\n```\n\n## Features\n\n- Real-time file watching and indexing\n- Semantic search using vector embeddings\n- Support for multiple file types\n- Configurable chunk size and overlap\n- Background processing of files\n- Automatic handling of file changes and deletions\n\n## Repository\n\n[GitHub Repository](https://github.com/lishenxydlgzs/simple-files-vectorstore)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "vectorstore",
        "files",
        "lishenxydlgzs",
        "files vectorstore",
        "vector store",
        "vectorstore creates"
      ],
      "category": "document-processing"
    },
    "liuyazui--base64_server": {
      "owner": "liuyazui",
      "name": "base64_server",
      "url": "https://github.com/liuyazui/base64_server",
      "imageUrl": "/freedevtools/mcp/pfp/liuyazui.webp",
      "description": "Provides efficient Base64 encoding and decoding services for both text and images, including support for Data URL formats. Features a simple API for easy integration and reusable prompt templates to simplify Base64 transformations in applications.",
      "stars": 3,
      "forks": 2,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-08-28T07:11:18Z",
      "readme_content": "# Base64编码解码MCP服务器\n\n[![smithery badge](https://smithery.ai/badge/@liuyazui/base64_server)](https://smithery.ai/server/@liuyazui/base64_server)\n[English Version](README_EN.md)\n\n一个简单高效的MCP服务器，专注于提供Base64编码和解码功能，支持文本和图片的Base64转换。\n\n<a href=\"https://glama.ai/mcp/servers/@liuyazui/base64_server\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@liuyazui/base64_server/badge\" alt=\"Base64 Server MCP server\" />\n</a>\n\n## 功能特点\n\n- 文本Base64编码和解码\n- 图片Base64编码和解码\n- 支持Data URL格式\n- 简单易用的API\n- 使用uv进行依赖管理\n\n## 安装\n\n### 使用uv安装\n\n```bash\n# 创建虚拟环境\nuv venv\n\n# 激活虚拟环境（Linux/macOS）\nsource .venv/bin/activate\n\n# 激活虚拟环境（Windows）\n.venv\\Scripts\\activate\n\n# 安装包（开发模式）\nuv pip install -e .\n\n# 安装带开发依赖的包\nuv pip install -e \".[dev]\"\n```\n\n### 安装Smithery\n\n使用Smithery为Claude桌面安装Base64编码解码MCP服务器，使用以下命令:\n\n```bash\nnpx -y @smithery/cli install @liuyazui/base64_server --client claude\n```\n\n## 使用方法\n\n### 使用MCP Inspector测试\n\n```bash\n# 使用MCP Inspector测试服务器\nuv run mcp dev base64_server.py\n```\n\n### 与MCP client集成\n\n1. 添加服务器配置：\n\n   ```json\n   {\n     \"mcpServers\": {\n        \"base64-encoder\": {\n        \"command\": \"uv\",\n        \"args\": [\n          \"run\",\n          \"--with\",\n          \"mcp[cli]\",\n          \"mcp\",\n          \"run\",\n          \"[path to base64_server.py]\"\n        ]\n      }\n     }\n   }\n   ```\n\n## API参考\n\n### 工具(Tools)\n\n- **base64_encode_text(text: str) -> str**：将文本转换为Base64编码\n- **base64_decode_text(encoded: str) -> str**：将Base64编码解码为文本\n- **base64_encode_image(image_path: str) -> str**：将图片转换为Base64编码\n- **base64_decode_image(encoded: str, output_path: str, mime_type: str = \"image/png\") -> str**：将Base64编码解码为图片\n\n### 资源(Resources)\n\n- **encode://base64/text/{text}**：获取文本的Base64编码\n- **decode://base64/text/{encoded}**：获取Base64编码的解码结果\n- **encode://base64/image/{image_path}**：获取图片的Base64编码\n- **decode://base64/image/{encoded}**：获取Base64编码的解码图片\n\n### 提示模板(Prompts)\n\n- **base64_usage_guide()**: 提供Base64服务的基本使用指南\n- **encode_text_prompt(text: str)**: 文本编码提示模板\n- **encode_image_prompt(image_path: str)**: 图片编码提示模板\n- **error_handling_prompt(error_message: str)**: 错误处理提示模板\n\n使用示例:\n\n```python\n# 获取使用指南提示\nmessages = await client.get_prompt(\"base64_usage_guide\")\n\n# 获取文本编码提示\nmessages = await client.get_prompt(\"encode_text_prompt\", {\"text\": \"Hello World\"})\n```\n\n## 开发\n\n## 许可证\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "base64",
        "base64_server",
        "encoding",
        "liuyazui base64_server",
        "base64 encoding",
        "efficient base64"
      ],
      "category": "document-processing"
    },
    "llmian-space--devdocs-mcp": {
      "owner": "llmian-space",
      "name": "devdocs-mcp",
      "url": "https://github.com/llmian-space/devdocs-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/llmian-space.webp",
      "description": "Manage and integrate documentation resources with a flexible template system for URI-based access. Ensure robust error handling and type safety while enhancing workflows through property-based testing and structured resource management.",
      "stars": 9,
      "forks": 2,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-08-07T05:48:22Z",
      "readme_content": "# DevDocs MCP Implementation\n\nA Model Context Protocol (MCP) implementation for documentation management and integration.\n\n## Project Structure\n\n```\nsrc/\n├── resources/\n│   ├── templates/      # Resource template system\n│   └── managers/       # Resource management\n├── documentation/\n│   ├── processors/     # Documentation processing\n│   └── integrators/    # Integration handlers\n├── tasks/\n│   ├── issues/         # Issue tracking\n│   └── reviews/        # Review management\n└── tests/\n    ├── property/       # Property-based tests\n    └── integration/    # Integration tests\n```\n\n## Core Components\n\n### Resource Template System\n\nThe resource template system provides URI-based access to documentation resources with:\n- Type-safe parameter handling through Pydantic\n- Flexible URI template matching\n- Comprehensive error handling\n- State management for resource lifecycle\n\nExample usage:\n\n```python\nfrom src.resources.templates.base import ResourceTemplate\n\n# Create a template with parameter typing\ntemplate = ResourceTemplate(\n    uri_template='docs://api/{version}/endpoint',\n    parameter_types={'version': str}\n)\n\n# Extract and validate parameters\nparams = template.extract_parameters('docs://api/v1/endpoint')\ntemplate.validate_parameters(params)\n```\n\n### Testing Strategy\n\nThe project uses property-based testing with Hypothesis to ensure:\n- URI template validation\n- Parameter extraction correctness\n- Error handling robustness\n- Type safety enforcement\n\nRun tests:\n```bash\npytest tests/property/test_templates.py\n```\n\n## Implementation Progress\n\n### Completed\n- [x] Basic project structure\n- [x] Resource template system\n- [x] Property-based testing infrastructure\n- [x] URI validation and parameter extraction\n- [x] Error handling foundation\n\n### In Progress\n- [ ] Documentation processor integration\n- [ ] Caching layer implementation\n- [ ] Task management system\n- [ ] Performance optimization\n\n### Planned\n- [ ] Search implementation\n- [ ] Branch mapping system\n- [ ] State tracking\n- [ ] Monitoring system\n\n## Development Guidelines\n\n1. Follow TDD approach:\n   - Write property-based tests first\n   - Implement minimal passing code\n   - Refactor for clarity and efficiency\n\n2. Error Handling:\n   - Use structured error types\n   - Implement recovery strategies\n   - Maintain system stability\n\n3. Documentation:\n   - Keep README updated\n   - Document new features\n   - Include usage examples\n\n## Branch Management\n\nThe project uses a branch-based development approach for:\n- Feature tracking\n- Documentation integration\n- Task management\n- Progress monitoring\n\n## Contributing\n\n1. Create feature branch\n2. Add property tests\n3. Implement feature\n4. Update documentation\n5. Submit pull request\n\n## Next Steps\n\n1. Implement documentation processor integration\n2. Add caching layer with proper lifecycle management\n3. Develop task management system\n4. Create monitoring and performance metrics\n\n## Support Resources\n\n- MCP Concepts: `mcp-docs/docs/concepts/`\n- Python SDK: `python-sdk/src/mcp/`\n- Example Servers: `python-sdk/examples/servers/`\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "documentation",
        "document",
        "devdocs",
        "integrate documentation",
        "devdocs mcp",
        "documentation resources"
      ],
      "category": "document-processing"
    },
    "lpsDevelopers--LPS-MCP": {
      "owner": "lpsDevelopers",
      "name": "LPS-MCP",
      "url": "https://github.com/lpsDevelopers/LPS-MCP",
      "imageUrl": "/freedevtools/mcp/pfp/null.webp",
      "description": "Proporciona acceso seguro al sistema de archivos y capacidades de pensamiento secuencial para mejorar la interacción de Claude con su entorno. Permite desglosar problemas complejos en pasos estructurados y acceder a archivos de manera controlada.",
      "stars": 0,
      "forks": 0,
      "license": "Unknown",
      "language": "Unknown",
      "updated_at": "",
      "readme_content": "",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "lps",
        "lpsdevelopers",
        "document",
        "processing lpsdevelopers",
        "lpsdevelopers lps",
        "lps mcp"
      ],
      "category": "document-processing"
    },
    "lucamauri--MediaWiki-MCP-adapter": {
      "owner": "lucamauri",
      "name": "MediaWiki-MCP-adapter",
      "url": "https://github.com/lucamauri/MediaWiki-MCP-adapter",
      "imageUrl": "/freedevtools/mcp/pfp/lucamauri.webp",
      "description": "Interact programmatically with MediaWiki and WikiBase APIs to fetch and edit MediaWiki pages. Perform operations using the MCP framework to enhance application's capabilities with seamless API access.",
      "stars": 4,
      "forks": 1,
      "license": "GNU General Public License v3.0",
      "language": "TypeScript",
      "updated_at": "2025-07-06T21:21:06Z",
      "readme_content": "# MediaWikiAdapter\n\n[](https://smithery.ai/server/@lucamauri/mediawiki-mcp-adapter)\n\nA custom **Model Context Protocol (MCP)** adapter for interacting with MediaWiki and WikiBase APIs. This adapter allows you to fetch and edit MediaWiki pages programmatically using the MCP framework.\n\n## Features\n\n- Fetch the content of a MediaWiki page.\n- Edit a MediaWiki page with new content and an optional summary.\n- Configurable API base URLs for different MediaWiki and WikiBase instances.\n\n## Requirements\n\n- Node.js (v16 or later)\n- TypeScript (for development)\n- MediaWiki instance with API access enabled\n\n## Installation\n\n1. Clone the repository:\n```bash\n   git clone https://github.com/yourusername/mediawikiadapter.git\n   cd mediawikiadapter\n   ```\n\n2. Install dependencies:\n   ```bash\n   npm install\n   ```\n\n3. Build the project:\n   ```bash\n   npm run build\n   ```\n\n## Usage\n\n### Configure the Adapter\n\nYou can configure the adapter to use custom MediaWiki and WikiBase API endpoints:\n\n```javascript\nserver.configure({\n  mediaWikiAPIBase: \"https://my.mediawiki.instance/api.php\",\n  wikiBaseAPIBase: \"https://my.wikibase.instance/api.php\",\n});\n```\n\n### Start the MCP Server\n\nRun the MCP server using the following command:\n```bash\nnode build/index.js\n```\n\n### Resources\n\n#### getPageContent\n\nFetches the content of a MediaWiki page.\n\n- **Input Schema**:\n```json\n  {\n    \"title\": \"string\"\n  }\n```\n- **Output Schema**:\n  ```json\n  {\n    \"content\": \"string\"\n  }\n  ```\n\n#### Example Usage:\n```javascript\nconst response = await server.callResource(\"getPageContent\", {\n  title: \"Main Page\",\n});\nconsole.log(response.content);\n```\n---\n\n### Tools\n\n#### editPage\n\nEdits a MediaWiki page with new content.\n\n- **Input Schema**:\n```json\n  {\n    \"title\": \"string\",\n    \"content\": \"string\",\n    \"summary\": \"string (optional)\"\n  }\n```\n- **Output Schema**:\n```json\n  {\n    \"success\": \"boolean\"\n  }\n```\n\n#### Example Usage:\n```javascript\nconst response = await server.callTool(\"editPage\", {\n  title: \"Main Page\",\n  content: \"Updated content for the page.\",\n  summary: \"Updated via MediaWikiAdapter\",\n});\nconsole.log(response.success ? \"Edit successful\" : \"Edit failed\");\n```\n\n---\n\n## Development\n\n### Run in Development Mode\n\nTo run the project in development mode with TypeScript:\n```bash\nnpm run dev\n```\n\n### Linting\n\nRun the linter to check for code quality:\n```bash\nnpm run lint\n```\n\n### Testing\n\nCurrently, no tests are implemented. You can add tests to the `test` directory and run them using:\n```bash\nnpm test\n```\n\n---\n\n## Configuration\n\nThe adapter uses the following default API base URLs:\n\n- **MediaWiki API Base**: https://en.wikipedia.org/w/api.php\n- **WikiBase API Base**: https://www.wikidata.org/w/api.php\n\nYou can override these defaults using the `server.configure()` method.\n\n---\n\n## Contributing\n\nContributions are welcome! Please follow these steps:\n\n1. Fork the repository.\n2. Create a new branch for your feature or bug fix.\n3. Submit a pull request with a detailed description of your changes.\n\n---\n\n## License\n\nThis project is licensed under the **LGPL-3.0-or-later** license. See the [LICENSE](LICENSE) file for details.\n\n---\n\n## Author\n\nCreated by **Luca Mauri**.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mediawiki",
        "wikibase",
        "document",
        "mediawiki mcp",
        "programmatically mediawiki",
        "lucamauri mediawiki"
      ],
      "category": "document-processing"
    },
    "luebken--playlist-mcp": {
      "owner": "luebken",
      "name": "playlist-mcp",
      "url": "https://github.com/luebken/playlist-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/luebken.webp",
      "description": "Provides access to transcripts of YouTube playlists, enabling retrieval and querying of video transcripts for enhanced application functionalities. It can preload specific playlists or be customized by specifying a different playlist URL.",
      "stars": 1,
      "forks": 1,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-04-16T10:31:43Z",
      "readme_content": "# Playlist-MCP\n\nThis is an experimental MCP server, which makes the transcripts of a Youtube Playlist available.\n\nIt currently is preloaded with the KubeCon London 2025 transcripts. But you can change this by changing the URL.\n\n\n\n## Install\n\n```sh\n# Clone this repo\ngit clone git@github.com:luebken/playlist-mcp.git; cd playlist-mcp\n\n# Install python dependencies\nuv venv\nsource .venv/bin/activate\nuv pip install -e .\n\n# Fill the transcript cache and vector db.\nuv run server.py https://www.youtube.com/playlist?list=PLj6h78yzYM2MP0QhYFK8HOb8UqgbIkLMc\n```\n\n## Setup for Claude Desktop\n\n```sh\n# Configure for Claude > Settings > Developer > Edit Config\n# /Users/YOUR_USERNAME/Library/Application Support/Claude/claude_desktop_config.json\n{\n  \"mcpServers\": {\n      \"playlist-mcp\": {\n          \"command\": \"uv\",\n          \"args\": [\n              \"--directory\",\n              \"/PATH/TO/PARENT/playlist-mcp/\",\n              \"run\",\n              \"server.py\",\n              \"https://www.youtube.com/playlist?list=PLj6h78yzYM2MP0QhYFK8HOb8UqgbIkLMc\"\n          ]\n      }\n  }\n}\n```",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "playlists",
        "playlist",
        "luebken",
        "luebken playlist",
        "youtube playlists",
        "playlist mcp"
      ],
      "category": "document-processing"
    },
    "lvshiyu21--Yuque-MCP-Server": {
      "owner": "lvshiyu21",
      "name": "Yuque-MCP-Server",
      "url": "https://github.com/lvshiyu21/Yuque-MCP-Server",
      "imageUrl": "/freedevtools/mcp/pfp/lvshiyu21.webp",
      "description": "Integrates with the Yuque knowledge base platform for document management and user information retrieval, enabling operations such as creating, reading, updating, and deleting documents while utilizing AI capabilities for enhanced workflow and analytics.",
      "stars": 1,
      "forks": 1,
      "license": "No License",
      "language": "",
      "updated_at": "2025-09-16T10:23:09Z",
      "readme_content": "# 语雀 MCP 服务器\n\n[English Version](./README.en.md)\n\n一个用于与语雀 API 集成的 Model-Context-Protocol (MCP) 服务器。此实现受 [Figma-Context-MCP](https://github.com/GLips/Figma-Context-MCP) 的启发，并使用 [语雀开放 API](https://app.swaggerhub.com/apis-docs/Jeff-Tian/yuque-open_api/2.0.1)。\n\n## 概述\n\n该服务器提供了与语雀知识库平台交互的 MCP 工具，允许 AI 模型：\n\n- 获取用户和文档信息\n- 创建、读取、更新和删除文档\n- 搜索语雀中的内容\n- 获取知识库信息\n- 获取统计数据和分析信息\n\n## 安装\n\n### 前提条件\n\n- Node.js 18+ (推荐)\n- 拥有 API 令牌的语雀账号\n\n### 设置\n\n1. 克隆此仓库：\n   ```\n   git clone https://github.com/Henryhaoson/Yueque-MCP-Server.git\n   cd Yueque-MCP-Server\n   ```\n\n2. 安装依赖：\n   ```\n   npm install\n   ```\n\n3. 基于 `.env.example` 创建 `.env` 文件：\n   ```\n   cp .env.example .env\n   ```\n\n4. (可选) 在 `.env` 文件中添加你的语雀 API 令牌：\n   ```\n   YUQUE_API_TOKEN=your_yuque_api_token_here\n   ```\n   \n   你也可以选择在连接到服务器时通过查询参数提供令牌，而不是在 .env 文件中设置。\n\n## 使用方法\n\n### 运行服务器\n\n#### 开发模式\n\n```bash\n# HTTP 服务器模式\nnpm run dev\n\n# CLI stdio 模式\nnpm run dev:cli\n```\n\n#### 生产模式\n\n首先，构建项目：\n\n```bash\nnpm run build\n```\n\n然后在 HTTP 或 CLI 模式下运行：\n\n```bash\n# HTTP 服务器模式\nnpm run start\n\n# CLI stdio 模式\nnpm run start:cli\n```\n\n### 使用 Docker 部署\n\n本项目提供了 Docker 支持，使您可以轻松地容器化和部署服务器。\n\n#### 使用 Docker Compose（推荐）\n\n1. 构建并启动容器：\n   ```bash\n   docker-compose up -d\n   ```\n\n2. 查看日志：\n   ```bash\n   docker-compose logs -f\n   ```\n\n3. 停止服务：\n   ```bash\n   docker-compose down\n   ```\n\n您可以通过环境变量或在 `.env` 文件中设置配置项：\n```bash\n# .env 文件示例\nPORT=3000\nYUQUE_API_TOKEN=your_token_here\nYUQUE_API_BASE_URL=https://www.yuque.com/api/v2\n```\n\n#### 手动使用 Docker\n\n1. 构建 Docker 镜像：\n   ```bash\n   docker build -t yuque-mcp-server .\n   ```\n\n2. 运行容器：\n   ```bash\n   docker run -d -p 3000:3000 --name yuque-mcp-server yuque-mcp-server\n   ```\n\n3. 使用环境变量：\n   ```bash\n   docker run -d -p 3000:3000 \\\n     -e YUQUE_API_TOKEN=your_token_here \\\n     -e YUQUE_API_BASE_URL=https://www.yuque.com/api/v2 \\\n     --name yuque-mcp-server yuque-mcp-server\n   ```\n\n### MCP 工具\n\n语雀 MCP 服务器提供以下工具：\n\n#### 用户和文档管理\n- `get_current_user` - 获取当前认证用户的信息，包括用户ID、用户名、头像等语雀账号基本信息\n- `get_user_docs` - 获取当前用户的所有知识库文档列表，包括私人和协作文档\n- `get_user_repos` - 获取指定用户的知识库列表，知识库是语雀中组织文档的集合\n- `get_repo_docs` - 获取特定知识库中的所有文档列表，包括文档标题、更新时间等信息\n- `get_doc` - 获取语雀中特定文档的详细内容，包括正文、修改历史和权限信息\n- `create_doc` - 在指定知识库中创建新的语雀文档，支持多种格式内容（Markdown、HTML、Lake）\n- `update_doc` - 更新语雀中已存在的文档，可以修改标题、内容或权限设置\n- `delete_doc` - 从语雀知识库中删除指定文档，此操作不可撤销\n- `search` - 在语雀平台中搜索文档或知识库内容，支持范围和作者筛选\n\n#### 团队统计分析\n- `get_group_statistics` - 获取团队的汇总统计数据，包括成员人数、文档数量、阅读量和互动数据等\n- `get_group_member_statistics` - 获取团队成员的统计数据，包括各成员的编辑次数、阅读量、点赞量等\n- `get_group_book_statistics` - 获取团队知识库的统计数据，包括各知识库的文档数、字数、阅读量等\n- `get_group_doc_statistics` - 获取团队文档的统计数据，包括各文档的字数、阅读量、评论量等\n\n## 与 AI 模型的集成\n\n此 MCP 服务器可以与支持 Model-Context-Protocol 的 AI 模型一起使用，允许它们通过定义的工具与语雀交互。例如：\n\n1. 启动 MCP 服务器\n2. 从兼容的客户端连接到服务器\n3. AI 模型现在可以使用注册的工具与语雀数据交互\n\n### SSE 端点的查询参数\n\n当连接到 SSE 端点时，你可以通过查询参数（query parameters）覆盖环境配置，这些参数的优先级高于环境变量：\n\n- `accessToken`: 覆盖在 .env 文件中设置的语雀 API 令牌\n- `baseUrl`: 覆盖在 .env 文件中设置的语雀 API 基础 URL\n\n示例：\n```\nhttp://localhost:3000/sse?accessToken=your_token_here&baseUrl=https://custom.yuque.api/v2\n```\n\n这允许你在不修改 .env 文件的情况下动态配置服务，并且查询参数的优先级高于环境变量。这对于多用户环境或测试不同 API 端点特别有用。\n\n每个 SSE 连接都可以使用不同的配置，这使得同一个服务器实例可以同时为不同的用户或环境提供服务。\n\n## 开发\n\n### 项目结构\n\n```\nsrc/\n  ├── config.ts          # 服务器配置\n  ├── index.ts           # 主入口点\n  ├── cli.ts             # CLI 入口点 \n  ├── server.ts          # MCP 服务器实现\n  └── services/\n      └── yuque.ts       # 语雀 API 服务\n```\n\n### 添加新工具\n\n要添加新工具，请修改 `src/server.ts` 中的 `registerTools` 方法。\n\n## API 改进\n\n最近的更新增加了以下功能：\n\n1. **团队统计数据**：添加了获取团队、成员、知识库和文档统计数据的功能，便于分析和监控团队知识库的使用情况。\n\n2. **文档管理增强**：\n   - 支持多种文档格式（Markdown、HTML、Lake）\n   - 完善的文档公开性设置（私密、公开、企业内公开）\n   - 搜索功能支持更多参数和过滤条件\n\n3. **数据类型完善**：更新了接口定义，使其与语雀 OpenAPI 规范保持一致。\n\n## 许可证\n\nMIT License\n\nCopyright (c) 2025 Henryhaoson\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n\n## 致谢\n\n- [Figma-Context-MCP](https://github.com/GLips/Figma-Context-MCP) 提供 MCP 服务器实现参考\n- [语雀开放 API](https://app.swaggerhub.com/apis-docs/Jeff-Tian/yuque-open_api/2.0.1) 提供 API 文档\n- [Model Context Protocol](https://github.com/anthropics/model-context-protocol) 提供 MCP 规范\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "yuque",
        "documents",
        "document",
        "yuque knowledge",
        "document processing",
        "integrates yuque"
      ],
      "category": "document-processing"
    },
    "madarco--ragrabbit": {
      "owner": "madarco",
      "name": "ragrabbit",
      "url": "https://github.com/madarco/ragrabbit",
      "imageUrl": "/freedevtools/mcp/pfp/madarco.webp",
      "description": "Crawl websites to create AI-powered search capabilities that enhance content discoverability and interaction with AI language models.",
      "stars": 124,
      "forks": 17,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T22:28:14Z",
      "readme_content": "<h1 style=\"font-weight:normal\">\n  <a href=\"https://ragrabbit.com\">\n    \n  </a>\n  &nbsp;RagRabbit&nbsp;\n  <a href=\"https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Fmadarco%2Fragrabbit&env=OPENAI_API_KEY,AUTH_USERNAME,AUTH_PASSWORD,AUTH_SECRET&envDescription=Get%20an%20OpenAI%20Api%20Key%20and%20set%20AUTH_USERNAME%20and%20AUTH_PASSWORD%20to%20the%20desired%20credentials%20to%20secure%20the%20admin%20section.%20Also%20be%20sure%20to%20enable%20the%20Postgres%20database%20integration&envLink=https%3A%2F%2Fplatform.openai.com%2Fapi-keys&demo-title=RagRabbit%20-%20AI%20Site%20Search%20and%20LLM.txt&demo-description=Site%20AI%20Search%20and%20LLM.txt%20in%20Minutes%2C%20Open%20Source%20with%201%20Click%20Deploy%20on%20Vercel.&demo-url=https%3A%2F%2Fragrabbit.vercel.app%2F&demo-image=https%3A%2F%2Fragrabbit.vercel.app%2Fopengraph-image.png&stores=%5B%7B%22type%22%3A%22postgres%22%7D%5D&root-directory=apps/saas\"><img src=\"https://img.shields.io/badge/deploy%20on-vercel-black.svg\"></a>\n  <a href=\"https://github.com/madarco/ragrabbit/blob/master/license.md\"><img src=https://img.shields.io/github/license/madarco/ragrabbit.svg?colorB=ff0000></a>\n  <a href=\"https://www.npmjs.com/package/@ragrabbit/mcp\"><img src=\"https://img.shields.io/npm/d18m/%40ragrabbit%2Fmcp?label=npm\" /></a>\n  <img src=\"https://img.shields.io/github/stars/madarco/ragrabbit\" />\n</h1>\n\nSelf Hosted Site AI Search, LLMs.txt, MCP Server that crawls your content. 1-Click Deploy on Vercel.\n<br>\n\n<p align=\"center\">\n  \n\n</p>\n\n[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Fmadarco%2Fragrabbit&env=OPENAI_API_KEY,AUTH_USERNAME,AUTH_PASSWORD,AUTH_SECRET&envDescription=Get%20an%20OpenAI%20Api%20Key%20and%20set%20AUTH_USERNAME%20and%20AUTH_PASSWORD%20to%20the%20desired%20credentials%20to%20secure%20the%20admin%20section.%20Also%20be%20sure%20to%20enable%20the%20Postgres%20database%20integration&envLink=https%3A%2F%2Fplatform.openai.com%2Fapi-keys&demo-title=RagRabbit%20-%20AI%20Site%20Search%20and%20LLM.txt&demo-description=Site%20AI%20Search%20and%20LLM.txt%20in%20Minutes%2C%20Open%20Source%20with%201%20Click%20Deploy%20on%20Vercel.&demo-url=https%3A%2F%2Fragrabbit.vercel.app%2F&demo-image=https%3A%2F%2Fragrabbit.vercel.app%2Fopengraph-image.png&stores=%5B%7B%22type%22%3A%22postgres%22%7D%5D&root-directory=apps/saas)\n\n## How it works\n\n[RagRabbit](https://github.com/madarco/ragrabbit) is a [Next.js](https://nextjs.org/) [Turborepo](https://turbo.build/repo) app that uses [Llamaindex](https://github.com/run-llama/LlamaIndexTS) with [pgVector](https://github.com/pgvector/pgvector).\n\nFeatures\n\n- 💬 Chat Widget: Embeddable AI Chat agent and instant Search\n- 🕸️ Website Crawler: scrapes and index pages with pgVector and PostgreSQL\n- 📄 LLMs.txt Generation: fully customizable wiht ToC reorder\n- 🔌 [MCP Server](./packages//mcp-server/README.md): `npx @ragrabbit/mcp` to access your docs from Claude Desktop and Cursor IDE\n- 🛠️ Flexible: Authentication, Open Source, API Keys access\n- 🚀 Easy Deployment: One-click setup on Vercel\n\nIntegrations:\n\n- [Fumadocs](#fumadocs)\n\n### Demo\n\nView [RagRabbit Demo Page](https://ragrabbit.vercel.app/widget/demo)\n\n\n\n## Install\n\nTo install on Vercel:\n\n[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Fmadarco%2Fragrabbit&env=OPENAI_API_KEY,AUTH_USERNAME,AUTH_PASSWORD,AUTH_SECRET&envDescription=Get%20an%20OpenAI%20Api%20Key%20and%20set%20AUTH_USERNAME%20and%20AUTH_PASSWORD%20to%20the%20desired%20credentials%20to%20secure%20the%20admin%20section.%20Also%20be%20sure%20to%20enable%20the%20Postgres%20database%20integration&envLink=https%3A%2F%2Fplatform.openai.com%2Fapi-keys&demo-title=RagRabbit%20-%20AI%20Site%20Search%20and%20LLM.txt&demo-description=Site%20AI%20Search%20and%20LLM.txt%20in%20Minutes%2C%20Open%20Source%20with%201%20Click%20Deploy%20on%20Vercel.&demo-url=https%3A%2F%2Fragrabbit.vercel.app%2F&demo-image=https%3A%2F%2Fragrabbit.vercel.app%2Fopengraph-image.png&stores=%5B%7B%22type%22%3A%22postgres%22%7D%5D&root-directory=apps/saas)\n\nRequirements:\n\n- Node.js 20.x\n- PostgreSQL w/ pgVector\n- OpenAI API Key\n- (Optional) Trigger.dev API Key\n\n### Configuration\n\nSet the following environment variables:\n\n- OPENAI_API_KEY\n\nFor username/password login:\n\n- ADMIN_USER\n- ADMIN_PASSWORD\n\nFor email login:\n\n- RESEND_AUTH=true\n- To restrict access to those emails: RESEND_ALLOWED_EMAILS=\"test@test.com,foo@bar.com\"\n- To not send emails but logs the login link instead (in Vercel logs): SIMULATE_EMAILS=true\n\nSee [.env.example](./apps/saas/.env.example) for the complete list.\n\n## How to use\n\nUse the Indexing section to add a new url/website to index, either a single url or a website to crawl recursively:\n\n\n\n\nThen start the Job Runner (keep the tab open until it finish)\n\n\n\nIn the LLM.txt section you can preview the generated LLM.txt file:\n\n\n\nYou can then embed the widget in your site with the following snippet:\n\n### Chat Button\n\nEmbed a button at the bottom of your page:\n\n```\n<script src=\"https://<your deployed app>/widget.js\"></script>\n```\n\n\n\n### Chat Widget\n\nInsert a search input anwhere in your page:\n\n\n\n```\n<script src=\"https://ragrabbit.com/widget.js?type=search\"></script>\n<ragrabbit-search></ragrabbit-search>\n```\n\n### To use with React.js\n\n```typescript\n\"use client\";\n\nimport Script from \"next/script\";\n\nexport function RagRabbitSearch() {\n  return (\n    <>\n      <Script src=\"/widget.js?type=search\" strategy=\"lazyOnload\" />\n      <style>{`\n        ragrabbit-search .ragrabbit-search-input {\n            padding: 6px 12px;\n        }\n      `}</style>\n      <div className=\"ml-auto min-w-[300px] flex-1 sm:flex-initial\">\n        {/* @ts-ignore - Custom element will be mounted by external script */}\n        <ragrabbit-search></ragrabbit-search>\n      </div>\n    </>\n  );\n}\n```\n\n### MPC Server\n\nThe MCP Server allows any supported AI Clients to retrieve pages from your documentation using semantic search.\n\n### Claude Desktop\n\nAdd a custom mcp server with the name of your product, so that Claude AI can use it when looking for info about it.\n\nin `claude_desktop_config.json` (Claude -> Settings -> Developer -> Edit Config)\n\n```\n{\n  \"mcpServers\": {\n    \"<name_of_your_documentation_no_spaces>\": {\n      \"command\": \"npx\",\n      \"args\": [\"@ragrabbit/mcp\", \"http://<RagRabbit install>/\", \"<name of your documentation>\"]\n    }\n  }\n}\n```\n\n### In Cursor IDE\n\nGo to Cursor -> Settings -> Cursor Settings -> MCP\n\nAnd add a new MCP of type `command` with the command:\n\n```\nnpx @ragrabbit/mcp\", \"http://<RagRabbit install>/\", \"<name of your documentation>\"\n```\n\nArguments:\n\n- `ragrabbit-url`: (Required) The base URL of your RagRabbit instance, eg https://my-ragrabbit.vercel.com/\n- `name`: (Required) Custom name for the documentation search service (defaults to \"RagRabbit\") so that AI will know to use it when looking for info\n\n## Configuration Options\n\n### Chat button\n\nYou can configure the chat button by adding the following parameters to the widget.js script tag:\n\n#### buttonText\n\n```\n<script src=\"https://ragrabbit.com/widget.js?buttonText=Ask%20AI\"></script>\n```\n\n### Search widget\n\nYou can configure the search widget by adding the following parameters and use the mountSearch call:\n\n#### searchPlaceholder\n\n```\n<div id=\"search-container\"></div>\n<script>\n  window.mountSearch(\"search-container\", { searchPlaceholder: \"Search documentation...\" });\n</script>\n```\n\n## Integrations\n\n### Fumadocs\n\nCreate a component to replace the Search Dialog:\n\n```bash\npnpm add @ragrabbit/search-react\n```\n\n```typescript\n\"use client\";\nimport type { SharedProps } from \"fumadocs-ui/components/dialog/search\";\nimport { RagRabbitModal } from \"@ragrabbit/search-react\";\n\nexport default function SearchDialog({ open, onOpenChange }: SharedProps) {\n  return <RagRabbitModal\n    domain=\"http://localhost:3000/\"\n    open={open}\n    onOpenChange={onOpenChange}\n    />;\n}\n```\n\nThen set it in the `layout.tsx`:\n\n```tsx\n<RootProvider\n  search={{\n    SearchDialog,\n  }}\n>\n  ...\n</RootProvider>\n```\n\nOptionally add the Floating Chat button:\n\n```typescript\n\"use client\";\nimport { RagRabbitChatButton } from \"@ragrabbit/search-react\";\n\nexport default function ChatButton() {\n  return <RagRabbitChatButton domain=\"http://localhost:3000/\" />;\n}\n```\n\nAnd add it to the `layout.tsx`:\n\n```tsx\n<body className=\"flex flex-col min-h-screen\">\n  <ChatButton />\n  ...\n```\n\n## Development\n\n```bash\n# Start the db (Docker needed)\npnpm dev:utils # Starts postgresql with pgvector, Storybook and Drizzle ORM Studio\n\n# Start the app\ncd apps/saas\npnpm dev\n```\n\n### Directory structure:\n\nRagRabbit is a monorepo with Turborepo a Next.js app and a modular design with separate packages.\n\n```\napps/\n├── docs -> the documentation site\n├── saas -> the main application\n└── web -> the web site\npackages/\n├── db -> the database with Drizzle ORM\n├── auth -> the authentication with Auth.js\n├── core -> shared utils\n├── design -> the design system\n├── rag -> the LLM and RAG package with LlamaIndexTS\n├── jobs -> job runner with Trigger.dev\n└── storybook -> a Next.js Storybook app\n.cursorrules -> Fine tuned Cursor rules with all the locations to work with the monorepo\n```\n\n# Author\n\n[Marco D'Alia](https://www.madarco.net) - [@madarco](https://x.com/madarco) - [Linkedin](https://www.linkedin.com/in/marcodalia/)\n\n# License\n\nMIT",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "search",
        "ai",
        "crawl",
        "search capabilities",
        "crawl websites",
        "powered search"
      ],
      "category": "document-processing"
    },
    "mahawi1992--mcp-documentation-server": {
      "owner": "mahawi1992",
      "name": "mcp-documentation-server",
      "url": "https://github.com/mahawi1992/mcp-documentation-server",
      "imageUrl": "/freedevtools/mcp/pfp/mahawi1992.webp",
      "description": "AI-assisted management of documentation and code improvement, supporting various frameworks with smart search capabilities. Integrates with Claude Desktop for an enhanced coding experience and improves suggestions over time.",
      "stars": 10,
      "forks": 2,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-08-15T09:27:08Z",
      "readme_content": "# MCP Documentation Server\n\nA smart documentation server that provides AI-assisted code improvement and documentation management through Claude Desktop integration.\n\n## Features\n\n- **AI Documentation Guide**: Maintains and updates documentation knowledge base\n- **AI Code Assistant**: Analyzes and improves code quality\n- **Framework Support**: \n  - React.js\n  - Next.js (with App Router)\n  - Python\n  - Vue.js\n  - Angular\n  - Node.js\n- **Brave Search Integration**: Smart documentation search and retrieval\n- **Learning System**: Improves suggestions over time\n\n## Quick Start\n\n1. Install the package:\n```bash\nnpm install -g mcp-documentation-server\n```\n\n2. Configure Claude Desktop (config.json):\n```json\n{\n  \"mcpServers\": {\n    \"documentation\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"mcp-documentation-server\"],\n      \"env\": {\n        \"BRAVE_API_KEY\": \"<YOUR_BRAVE_API_KEY>\"\n      }\n    }\n  }\n}\n```\n\n3. Start using with Claude:\n```\nClaude, search documentation for Next.js App Router\n```\n\nFor detailed setup instructions, see [Claude Desktop Setup Guide](docs/CLAUDE_DESKTOP_SETUP.md)\n\n## Development Setup\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/mahawi1992/mcp-documentation-server.git\ncd mcp-documentation-server\n```\n\n2. Install dependencies:\n```bash\nnpm install\n```\n\n3. Create a .env file:\n```env\nPORT=3000\nUPDATE_INTERVAL=3600000\nCACHE_DURATION=86400000\nBRAVE_API_KEY=your_brave_api_key\n```\n\n4. Start the development server:\n```bash\nnpm run dev\n```\n\n## Documentation\n\n- [Usage Guide](docs/USAGE.md)\n- [Claude Desktop Setup](docs/CLAUDE_DESKTOP_SETUP.md)\n- [API Documentation](docs/API.md)\n- [Contributing Guide](CONTRIBUTING.md)\n\n## Using with Claude Desktop\n\n### Basic Commands\n\n```\nClaude, search documentation for React hooks\n```\n\n```\nClaude, analyze this Python code and suggest improvements...\n```\n\n```\nClaude, find best practices for Next.js App Router\n```\n\n### Advanced Usage\n\n```\nClaude, search for documentation about async/await in Python 3.9\n```\n\n```\nClaude, analyze this code for security issues and suggest fixes...\n```\n\nFor more examples, see the [Usage Guide](docs/USAGE.md)\n\n## Contributing\n\n1. Fork the repository\n2. Create your feature branch:\n   ```bash\n   git checkout -b feature/amazing-feature\n   ```\n3. Commit your changes:\n   ```bash\n   git commit -m 'Add amazing feature'\n   ```\n4. Push to the branch:\n   ```bash\n   git push origin feature/amazing-feature\n   ```\n5. Open a Pull Request\n\n## Testing\n\nRun the test suite:\n\n```bash\nnpm test\n```\n\nRun specific tests:\n\n```bash\nnpm test -- tests/integration/BraveSearchIntegration.test.ts\n```\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "documentation",
        "document",
        "search",
        "documentation server",
        "document processing",
        "documentation code"
      ],
      "category": "document-processing"
    },
    "mamertofabian--elevenlabs-mcp-server": {
      "owner": "mamertofabian",
      "name": "elevenlabs-mcp-server",
      "url": "https://github.com/mamertofabian/elevenlabs-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/mamertofabian.webp",
      "description": "Integrates with ElevenLabs text-to-speech API to generate audio from text input, manage voice generation tasks, and store history using an SQLite database. Includes a sample SvelteKit client for performing text-to-speech conversions and managing script parts.",
      "stars": 112,
      "forks": 23,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-03T22:32:03Z",
      "readme_content": "# ElevenLabs MCP Server\n[![smithery badge](https://smithery.ai/badge/elevenlabs-mcp-server)](https://smithery.ai/server/elevenlabs-mcp-server)\n\nA Model Context Protocol (MCP) server that integrates with ElevenLabs text-to-speech API, featuring both a server component and a sample web-based MCP Client (SvelteKit) for managing voice generation tasks.\n\n<a href=\"https://glama.ai/mcp/servers/leukzvus7o\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/leukzvus7o/badge\" alt=\"ElevenLabs Server MCP server\" /></a>\n\n## Features\n\n- Generate audio from text using ElevenLabs API\n- Support for multiple voices and script parts\n- SQLite database for persistent history storage\n- Sample SvelteKit MCP Client for:\n  - Simple text-to-speech conversion\n  - Multi-part script management\n  - Voice history tracking and playback\n  - Audio file downloads\n\n## Installation\n\n### Installing via Smithery\n\nTo install ElevenLabs MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/elevenlabs-mcp-server):\n\n```bash\nnpx -y @smithery/cli install elevenlabs-mcp-server --client claude\n```\n\n### Using uvx (recommended)\n\nWhen using [`uvx`](https://docs.astral.sh/uv/guides/tools/), no specific installation is needed.\n\nAdd the following configuration to your MCP settings file (e.g., `cline_mcp_settings.json` for Claude Desktop):\n\n```json\n{\n  \"mcpServers\": {\n    \"elevenlabs\": {\n      \"command\": \"uvx\",\n      \"args\": [\"elevenlabs-mcp-server\"],\n      \"env\": {\n        \"ELEVENLABS_API_KEY\": \"your-api-key\",\n        \"ELEVENLABS_VOICE_ID\": \"your-voice-id\",\n        \"ELEVENLABS_MODEL_ID\": \"eleven_flash_v2\",\n        \"ELEVENLABS_STABILITY\": \"0.5\",\n        \"ELEVENLABS_SIMILARITY_BOOST\": \"0.75\",\n        \"ELEVENLABS_STYLE\": \"0.1\",\n        \"ELEVENLABS_OUTPUT_DIR\": \"output\"\n      }\n    }\n  }\n}\n```\n\n### Development Installation\n\n1. Clone this repository\n2. Install dependencies:\n   ```bash\n   uv venv\n   ```\n3. Copy `.env.example` to `.env` and fill in your ElevenLabs credentials\n\n```json\n{\n  \"mcpServers\": {\n    \"elevenlabs\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"path/to/elevenlabs-mcp-server\",\n        \"run\",\n        \"elevenlabs-mcp-server\"\n      ],\n      \"env\": {\n        \"ELEVENLABS_API_KEY\": \"your-api-key\",\n        \"ELEVENLABS_VOICE_ID\": \"your-voice-id\",\n        \"ELEVENLABS_MODEL_ID\": \"eleven_flash_v2\",\n        \"ELEVENLABS_STABILITY\": \"0.5\",\n        \"ELEVENLABS_SIMILARITY_BOOST\": \"0.75\",\n        \"ELEVENLABS_STYLE\": \"0.1\",\n        \"ELEVENLABS_OUTPUT_DIR\": \"output\"\n      }\n    }\n  }\n}\n```\n\n## Using the Sample SvelteKit MCP Client\n\n1. Navigate to the web UI directory:\n   ```bash\n   cd clients/web-ui\n   ```\n2. Install dependencies:\n   ```bash\n   pnpm install\n   ```\n3. Copy `.env.example` to `.env` and configure as needed\n4. Run the web UI:\n   ```bash\n   pnpm dev\n   ```\n5. Open http://localhost:5174 in your browser\n\n### Available Tools\n\n- `generate_audio_simple`: Generate audio from plain text using default voice settings\n- `generate_audio_script`: Generate audio from a structured script with multiple voices and actors\n- `delete_job`: Delete a job by its ID\n- `get_audio_file`: Get the audio file by its ID\n- `list_voices`: List all available voices\n- `get_voiceover_history`: Get voiceover job history. Optionally specify a job ID for a specific job.\n\n### Available Resources\n\n- `voiceover://history/{job_id}`: Get the audio file by its ID\n- `voiceover://voices`: List all available voices\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mamertofabian",
        "mcp",
        "elevenlabs",
        "mamertofabian elevenlabs",
        "processing mamertofabian",
        "elevenlabs mcp"
      ],
      "category": "document-processing"
    },
    "maoxiaoke--mcp-media-processor": {
      "owner": "maoxiaoke",
      "name": "mcp-media-processor",
      "url": "https://github.com/maoxiaoke/mcp-media-processor",
      "imageUrl": "/freedevtools/mcp/pfp/maoxiaoke.webp",
      "description": "A Node.js server for executing various media processing tasks, including video and image manipulation. It supports operations like video conversion, image effects, and media compression.",
      "stars": 24,
      "forks": 5,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-09-16T09:41:08Z",
      "readme_content": "# MCP Media Processing Server\n\n[![smithery badge](https://smithery.ai/badge/@maoxiaoke/mcp-media-processor)](https://smithery.ai/server/@maoxiaoke/mcp-media-processor)\n\nA Node.js server implementing Model Context Protocol (MCP) for media processing operations, providing powerful video and image manipulation capabilities.\n\n## Features\n\n* Video processing and conversion\n* Image processing and manipulation\n* Media compression\n* Video trimming and editing\n* Image effects and watermarking\n\n## Prerequisites\n\nBefore using this server, make sure you have the following dependencies installed on your system:\n\n* **FFmpeg**: Required for video processing operations\n  * macOS: `brew install ffmpeg`\n  * Ubuntu/Debian: `sudo apt-get install ffmpeg`\n  * Windows: Download from [FFmpeg official website](https://ffmpeg.org/download.html)\n\n* **ImageMagick**: Required for image processing operations\n  * macOS: `brew install imagemagick`\n  * Ubuntu/Debian: `sudo apt-get install imagemagick`\n  * Windows: Download from [ImageMagick official website](https://imagemagick.org/script/download.php)\n\n## How to use\n\nAdd this to your `claude_desktop_config.json`:\n\n### NPX\n\n```json\n{\n  \"mcpServers\": {\n    \"mediaProcessor\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"mcp-media-processor@latest\"\n      ]\n    }\n  }\n}\n```\n\n## API\n\n### Tools\n\n#### Video Operations\n\n* **execute-ffmpeg**\n  * Execute any FFmpeg command with custom options\n  * Inputs:\n    * `inputPath` (string): Absolute path to input video file\n    * `options` (string[]): Array of FFmpeg command options\n    * `outputPath` (string, optional): Absolute path for output file\n    * `outputFilename` (string, optional): Output filename\n\n* **convert-video**\n  * Convert video to different format\n  * Inputs:\n    * `inputPath` (string): Absolute path to input video file\n    * `outputFormat` (string): Desired output format (e.g., mp4, mkv, avi)\n    * `outputPath` (string, optional): Custom output path\n    * `outputFilename` (string, optional): Custom output filename\n\n* **compress-video**\n  * Compress video file\n  * Inputs:\n    * `inputPath` (string): Absolute path to input video file\n    * `quality` (number, optional): Compression quality (1-51, lower is better quality)\n    * `outputPath` (string, optional): Custom output path\n    * `outputFilename` (string, optional): Custom output filename\n\n* **trim-video**\n  * Trim video to specified duration\n  * Inputs:\n    * `inputPath` (string): Absolute path to input video file\n    * `startTime` (string): Start time in format HH:MM:SS\n    * `duration` (string): Duration in format HH:MM:SS\n    * `outputPath` (string, optional): Custom output path\n    * `outputFilename` (string, optional): Custom output filename\n\n#### Image Operations\n\n* **compress-image**\n  * Compress PNG image using ImageMagick\n  * Inputs:\n    * `inputPath` (string): Absolute path to input PNG image\n    * `quality` (number, optional): Compression quality (1-100)\n    * `outputPath` (string, optional): Custom output path\n    * `outputFilename` (string, optional): Custom output filename\n\n* **convert-image**\n  * Convert image to different format\n  * Inputs:\n    * `inputPath` (string): Absolute path to input image file\n    * `outputFormat` (string): Desired output format (e.g., jpg, png, webp, gif)\n    * `outputPath` (string, optional): Custom output path\n    * `outputFilename` (string, optional): Custom output filename\n\n* **resize-image**\n  * Resize image to specified dimensions\n  * Inputs:\n    * `inputPath` (string): Absolute path to input image file\n    * `width` (number, optional): Target width in pixels\n    * `height` (number, optional): Target height in pixels\n    * `maintainAspectRatio` (boolean, optional): Whether to maintain aspect ratio\n    * `outputPath` (string, optional): Custom output path\n    * `outputFilename` (string, optional): Custom output filename\n\n* **rotate-image**\n  * Rotate image by specified degrees\n  * Inputs:\n    * `inputPath` (string): Absolute path to input image file\n    * `degrees` (number): Rotation angle in degrees\n    * `outputPath` (string, optional): Custom output path\n    * `outputFilename` (string, optional): Custom output filename\n\n* **add-watermark**\n  * Add watermark to image\n  * Inputs:\n    * `inputPath` (string): Absolute path to input image file\n    * `watermarkPath` (string): Absolute path to watermark image file\n    * `position` (string, optional): Position of watermark (default: \"southeast\")\n    * `opacity` (number, optional): Watermark opacity (0-100)\n    * `outputPath` (string, optional): Custom output path\n    * `outputFilename` (string, optional): Custom output filename\n\n* **apply-effect**\n  * Apply visual effect to image\n  * Inputs:\n    * `inputPath` (string): Absolute path to input image file\n    * `effect` (string): Effect to apply (blur, sharpen, edge, emboss, grayscale, sepia, negate)\n    * `intensity` (number, optional): Effect intensity (0-100)\n    * `outputPath` (string, optional): Custom output path\n    * `outputFilename` (string, optional): Custom output filename\n\n\n## License\n\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "processing",
        "processor",
        "node",
        "media processing",
        "media processor",
        "mcp media"
      ],
      "category": "document-processing"
    },
    "mario-andreschak--mcp-msoffice-interop-word": {
      "owner": "mario-andreschak",
      "name": "mcp-msoffice-interop-word",
      "url": "https://github.com/mario-andreschak/mcp-msoffice-interop-word",
      "imageUrl": "/freedevtools/mcp/pfp/mario-andreschak.webp",
      "description": "Interact programmatically with Microsoft Word documents, automating common Word processing tasks using a simple MCP interface. Facilitates document manipulation capabilities via COM Interop on Windows.",
      "stars": 12,
      "forks": 4,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T22:32:25Z",
      "readme_content": "# MCP Office Interop Word Server\n\nThis project implements a [Model Context Protocol (MCP)](https://modelcontextprotocol.io/) server that allows interaction with Microsoft Word documents using COM Interop on Windows.\n\nIt provides MCP tools to perform common Word processing tasks programmatically.\n\n## Features\n\n*   Wraps common Microsoft Word operations via COM Interop (`winax`).\n*   Exposes functionality as MCP tools.\n*   Supports both `stdio` and `sse` transports for MCP communication.\n*   Built with TypeScript and uses the `@modelcontextprotocol/sdk`.\n\n## Prerequisites\n\n*   Node.js (v18 or later recommended)\n*   npm\n*   Microsoft Word installed on a Windows machine.\n\n## Installation\n\n1.  Clone the repository or download the source code.\n2.  Navigate to the project directory in your terminal.\n3.  Install dependencies:\n    ```bash\n    npm install\n    ```\n\n## Building\n\nTo compile the TypeScript code to JavaScript:\n\n```bash\nnpm run build\n```\n\nThis will output the compiled files to the `dist` directory.\n\n## Running the Server\n\nThe server can run using two different MCP transports: `stdio` or `sse`.\n\n### stdio Transport\n\nThis is the default mode. It's suitable for local clients that communicate via standard input/output.\n\n```bash\nnpm start\n```\n\nor\n\n```bash\nnode dist/index.js\n```\n\nConnect your MCP client (e.g., MCP Inspector) using the stdio method, pointing to the `node dist/index.js` command.\n\n### SSE (Server-Sent Events) Transport\n\nThis mode uses HTTP and Server-Sent Events, suitable for web-based or remote clients.\n\n**PowerShell:**\n\n```powershell\n$env:MCP_TRANSPORT=\"sse\"; npm start\n```\n\n**Bash / Cmd:**\n\n```bash\nMCP_TRANSPORT=sse npm start\n```\n\nThe server will start an HTTP server, typically on port 3001 (or the port specified by the `PORT` environment variable).\n\n*   **SSE Endpoint:** `http://localhost:3001/sse`\n*   **Message Endpoint (for client POSTs):** `http://localhost:3001/messages`\n\nConnect your MCP client using the SSE method, providing the SSE endpoint URL.\n\n## Available Tools\n\nThe server exposes the following tools (tool names are prefixed with `word_`):\n\n**Document Operations:**\n\n*   `word_createDocument`: Creates a new, blank Word document.\n*   `word_openDocument`: Opens an existing document.\n    *   `filePath` (string): Absolute path to the document.\n*   `word_saveActiveDocument`: Saves the currently active document.\n*   `word_saveActiveDocumentAs`: Saves the active document to a new path/format.\n    *   `filePath` (string): Absolute path to save to.\n    *   `fileFormat` (number, optional): Numeric `WdSaveFormat` value (e.g., 16 for docx, 17 for pdf).\n*   `word_closeActiveDocument`: Closes the active document.\n    *   `saveChanges` (number, optional): `WdSaveOptions` value (0=No, -1=Yes, -2=Prompt). Default: 0.\n\n**Text Manipulation:**\n\n*   `word_insertText`: Inserts text at the selection.\n    *   `text` (string): Text to insert.\n*   `word_deleteText`: Deletes text relative to the selection.\n    *   `count` (number, optional): Number of units to delete (default: 1). Positive=forward, negative=backward.\n    *   `unit` (number, optional): `WdUnits` value (1=Char, 2=Word, etc.). Default: 1.\n*   `word_findAndReplace`: Finds and replaces text.\n    *   `findText` (string): Text to find.\n    *   `replaceText` (string): Replacement text.\n    *   `matchCase` (boolean, optional): Default: false.\n    *   `matchWholeWord` (boolean, optional): Default: false.\n    *   `replaceAll` (boolean, optional): Default: true.\n*   `word_toggleBold`: Toggles bold formatting for the selection.\n*   `word_toggleItalic`: Toggles italic formatting for the selection.\n*   `word_toggleUnderline`: Toggles underline formatting for the selection.\n    *   `underlineStyle` (number, optional): `WdUnderline` value (default: 1=Single).\n\n**Paragraph Formatting:**\n\n*   `word_setParagraphAlignment`: Sets paragraph alignment.\n    *   `alignment` (number): `WdParagraphAlignment` value (0=Left, 1=Center, 2=Right, 3=Justify).\n*   `word_setParagraphLeftIndent`: Sets left indent.\n    *   `indentPoints` (number): Indent value in points.\n*   `word_setParagraphRightIndent`: Sets right indent.\n    *   `indentPoints` (number): Indent value in points.\n*   `word_setParagraphFirstLineIndent`: Sets first line/hanging indent.\n    *   `indentPoints` (number): Indent value in points (positive=indent, negative=hanging).\n*   `word_setParagraphSpaceBefore`: Sets space before paragraphs.\n    *   `spacePoints` (number): Space value in points.\n*   `word_setParagraphSpaceAfter`: Sets space after paragraphs.\n    *   `spacePoints` (number): Space value in points.\n*   `word_setParagraphLineSpacing`: Sets line spacing.\n    *   `lineSpacingRule` (number): `WdLineSpacing` value (0=Single, 1=1.5, 2=Double, 3=AtLeast, 4=Exactly, 5=Multiple).\n    *   `lineSpacingValue` (number, optional): Value needed for rules 3, 4, 5.\n\n**Table Operations:**\n\n*   `word_addTable`: Adds a table at the selection.\n    *   `numRows` (number): Number of rows.\n    *   `numCols` (number): Number of columns.\n*   `word_setTableCellText`: Sets text in a table cell.\n    *   `tableIndex` (number): 1-based table index.\n    *   `rowIndex` (number): 1-based row index.\n    *   `colIndex` (number): 1-based column index.\n    *   `text` (string): Text to set.\n*   `word_insertTableRow`: Inserts a row into a table.\n    *   `tableIndex` (number): 1-based table index.\n    *   `beforeRowIndex` (number, optional): Insert before this 1-based row index (or at end if omitted).\n*   `word_insertTableColumn`: Inserts a column into a table.\n    *   `tableIndex` (number): 1-based table index.\n    *   `beforeColIndex` (number, optional): Insert before this 1-based column index (or at right end if omitted).\n*   `word_applyTableAutoFormat`: Applies a style to a table.\n    *   `tableIndex` (number): 1-based table index.\n    *   `formatName` (string | number): Style name or `WdTableFormat` value.\n\n**Image Operations:**\n\n*   `word_insertPicture`: Inserts an inline picture.\n    *   `filePath` (string): Absolute path to the image file.\n    *   `linkToFile` (boolean, optional): Default: false.\n    *   `saveWithDocument` (boolean, optional): Default: true.\n*   `word_setInlinePictureSize`: Resizes an inline picture.\n    *   `shapeIndex` (number): 1-based index of the inline shape.\n    *   `heightPoints` (number): Height in points (-1 or 0 to auto-size).\n    *   `widthPoints` (number): Width in points (-1 or 0 to auto-size).\n    *   `lockAspectRatio` (boolean, optional): Default: true.\n\n**Header/Footer Operations:**\n\n*   `word_setHeaderFooterText`: Sets text in a header or footer.\n    *   `text` (string): Text content.\n    *   `isHeader` (boolean): True for header, false for footer.\n    *   `sectionIndex` (number, optional): 1-based section index (default: 1).\n    *   `headerFooterType` (number, optional): `WdHeaderFooterIndex` value (1=Primary, 2=FirstPage, 3=EvenPages). Default: 1.\n\n**Page Setup Operations:**\n\n*   `word_setPageMargins`: Sets page margins.\n    *   `topPoints` (number): Top margin in points.\n    *   `bottomPoints` (number): Bottom margin in points.\n    *   `leftPoints` (number): Left margin in points.\n    *   `rightPoints` (number): Right margin in points.\n*   `word_setPageOrientation`: Sets page orientation.\n    *   `orientation` (number): `WdOrientation` value (0=Portrait, 1=Landscape).\n*   `word_setPaperSize`: Sets paper size.\n    *   `paperSize` (number): `WdPaperSize` value (e.g., 1=Letter, 8=A4).\n\n## Notes\n\n*   This server requires Microsoft Word to be installed and accessible via COM Interop on the machine where the server runs.\n*   Error handling for COM operations is basic. Robust production use might require more detailed error checking and recovery.\n*   Word object model constants (like `WdSaveFormat`, `WdUnits`, etc.) are represented by their numeric values in the tool arguments. You may need to refer to the Word VBA documentation for specific values.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "msoffice",
        "automating",
        "microsoft",
        "msoffice interop",
        "microsoft word",
        "mcp msoffice"
      ],
      "category": "document-processing"
    },
    "mawazawa--agentic-pdf-app": {
      "owner": "mawazawa",
      "name": "agentic-pdf-app",
      "url": "https://github.com/mawazawa/agentic-pdf-app",
      "imageUrl": "/freedevtools/mcp/pfp/mawazawa.webp",
      "description": "Automatically fills California court PDF forms by extracting and mapping data from donor documents through AI analysis. Features a minimalist interface and a modular microservices architecture for easy deployment using Docker.",
      "stars": 1,
      "forks": 1,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-09-14T15:08:46Z",
      "readme_content": "# Agentic PDF Form Filler\n\nA visually stunning, minimalist system for automatically filling California court PDF forms using information extracted from donor documents.\n\n![Form Filling Process](https://mermaid.ink/img/pako:eNqtlMFO4zAQhl_F8rmVnMY-oC8A2nKACBBcuFRO4hFWc9ysYwtWqO_Ouly2Igu7XKLYmvnnn8-eiX3o2J7s1V0N4BuEe7DdnuxQKV-5mK-9cY2N0GGFyZVvQQsdrHRYIriP5F7rYzpH0XtdWUJk2wDnYGsNj7CmK6KzDhv2ELpBkDk1ELSxIURg-4YYexvNw5x8oO-4zy32hfUlX5cA2jYWIe5hXb40XPbkgFWu3fE7Hm0bSKj2rHJrPO8u3yEj-XLsMXxMBzJq_tPOH03-Ug7jzfH4qcef7qGLnYscZYezE96yK7VLPQW9UNlUJCBUB46gEkVBOEkpT3NaFIrndVmQvPg0aw_dNk1QLssTxT5FSk3JnZQiz1mqxKzKZZnTLFF5qkaVJ7OVDiPAIIx-MwNbnN6OsZGJj_jBuqiHxN4b-YcZHGJDr1t6XxvQp-dvTNZj7_DaIvjXBpuU-IXCWRN3FrwwdYWFc25pJKFsqU3_IOTC4YuIbYeXcTxJVt8wzlPGZSlTIUZMkpxTpZSk-UxykSsy40wzmRUinaU0S_MaTD9-hO25DPr0aBKGDHxpzCQUkLHoR_5mEo5CaPfvjdDnhA3Qv4h5sQ0gxFhM9h8ufVSJ?type=png)\n\n## Features\n\n- **Intelligent Document Extraction**: Uses Perplexity Sonar API or OpenAI API to extract data from various document types\n- **Smart Field Mapping**: Automatically maps extracted data to form fields\n- **Beautiful UI**: Clean, minimalist interface for easy form processing\n- **Docker-Based**: Simple deployment with Docker for both development and production\n- **Modular Design**: Microservices architecture for maintainability and scalability\n\n## Quick Start\n\n### Prerequisites\n\n- Docker and Docker Compose installed\n- API keys for Perplexity and/or OpenAI\n\n### Setup\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/yourusername/agentic-pdf.git\ncd agentic-pdf\n```\n\n2. Create an `.env` file in the root directory:\n```\nPERPLEXITY_API_KEY=your_perplexity_api_key\nOPENAI_API_KEY=your_openai_api_key\n```\n\n3. Start the application in development mode:\n```bash\ndocker-compose up --build\n```\n\nThe services will be available at:\n- UI: http://localhost:8080\n- Orchestration Service API: http://localhost:3002\n- Other microservices: ports 3000-3005\n\n### Usage\n\n1. Open http://localhost:8080 in your browser\n2. Enter the URL of the California court form to fill (or use the default)\n3. Upload supporting documents (ID cards, previous forms, etc.)\n4. Wait for the system to process and fill the form\n5. Download the completed form\n\n## Architecture\n\nThis project follows a modern microservices architecture:\n\n- **UI Layer** (Next.js): Provides a clean, responsive interface\n- **MCP Servers** (Node.js/TypeScript): Implements Model Context Protocol servers for various services:\n  - Puppeteer Server: Downloads PDFs from URLs\n  - AI Analysis Server: Extracts form fields using AI vision\n  - Document Extraction Server: Analyzes donor documents\n  - Field Mapping Service: Maps donor data to form fields\n  - Form Filling Server: Fills the PDF with mapped data\n- **Orchestration Layer**: Coordinates the workflow between services\n\n## Development\n\n### Project Structure\n\n```\nagentic-pdf/\n├── docker-compose.yml         # Main docker-compose configuration\n├── docker-compose.override.yml # Development overrides\n├── docker-compose.prod.yml    # Production configuration\n├── nginx.conf                 # Nginx config for production\n├── src/\n│   └── mcp-servers/           # Backend services (TypeScript)\n│       ├── src/\n│       │   ├── config/        # Configuration\n│       │   ├── orchestration/ # Workflow orchestrators\n│       │   ├── servers/       # MCP server implementations\n│       │   └── services/      # Service implementations\n│       └── Dockerfile         # Multi-stage Dockerfile\n└── ui/                        # Frontend (Next.js)\n    ├── src/\n    │   ├── components/        # React components\n    │   ├── pages/             # Next.js pages\n    │   └── styles/            # CSS styles\n    └── Dockerfile             # Multi-stage Dockerfile\n```\n\n### Local Development\n\nFor local development with automatic reloading:\n\n```bash\ndocker-compose up\n```\n\n### Production Deployment\n\nFor a production deployment:\n\n```bash\ndocker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d\n```\n\n## Design Principles\n\nThis project adheres to several key design principles:\n\n1. **Minimalism**: Clean interface and streamlined user experience\n2. **Separation of Concerns**: Each component has a single, well-defined responsibility\n3. **Visual Harmony**: Consistent use of typography, color, and space\n4. **Progressive Disclosure**: Complexity is revealed only when needed\n5. **Error Prevention**: Validation and clear user guidance\n\n## License\n\nMIT",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "microservices",
        "documents",
        "document",
        "documents ai",
        "document processing",
        "pdf app"
      ],
      "category": "document-processing"
    },
    "mgsrevolver--seo-inspector-mcp": {
      "owner": "mgsrevolver",
      "name": "seo-inspector-mcp",
      "url": "https://github.com/mgsrevolver/seo-inspector-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/mgsrevolver.webp",
      "description": "Analyzes HTML files and web pages to identify SEO issues and validate structured data schemas. Provides actionable recommendations for improving SEO quality directly through integrated tools without the need for a browser extension.",
      "stars": 4,
      "forks": 5,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-09-14T17:34:26Z",
      "readme_content": "// README.md - Instructions for setup and use\n\n# SEO Inspector & Schema Validator MCP\n\nA Model Context Protocol (MCP) server for Cursor that analyzes web pages for SEO issues and validates structured data schemas.\n\n## Features\n\n- Analyze HTML files in a codebase for SEO issues\n- Validate JSON-LD structured data\n- Get recommendations to improve SEO\n- No browser extension required - works directly with your codebase\n\n## Installation\n\n1. Clone this repository:\n\n   ```\n   git clone https://github.com/yourusername/seo-inspector-mcp.git\n   cd seo-inspector-mcp\n   ```\n\n2. Install dependencies:\n\n   ```\n   npm install\n   ```\n\n3. Configure Cursor to use this MCP server:\n   - Go to Settings > Features > MCP in Cursor\n   - Add a new MCP server with:\n     - Name: SEO Inspector\n     - Type: sse\n     - URL: http://localhost:8767/sse\n\n## Usage\n\n1. Start the MCP server:\n\n   ```\n   ./run-mcp.sh\n   ```\n\n2. In Cursor, you can now use the SEO Inspector tools:\n   - `seo.analyze-codebase` - Analyze HTML files in a directory\n   - `seo.analyze-html` - Analyze a specific HTML string\n\n## Prioritized SEO Components\n\nThe tool checks for these key SEO elements (in order of importance):\n\n### Critical\n\n- Page Title\n- Meta Description\n- H1 Heading\n- Canonical URL\n\n### Important\n\n- Heading Structure (H2-H6)\n- Image Alt Text\n- Structured Data (JSON-LD)\n- Robots Directives\n\n### Recommended\n\n- Open Graph Tags\n- Twitter Cards\n- Internal Linking\n- URL Structure\n- Mobile Friendliness\n\n## Schema Validation\n\nThe tool validates the following schema types:\n\n- Organization\n- LocalBusiness\n- Product\n- Article\n- WebPage\n- FAQPage\n- Event\n- Recipe\n- Review\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "seo",
        "mgsrevolver",
        "html",
        "mgsrevolver seo",
        "seo inspector",
        "analyzes html"
      ],
      "category": "document-processing"
    },
    "michalnaka--mcp-substack": {
      "owner": "michalnaka",
      "name": "mcp-substack",
      "url": "https://github.com/michalnaka/mcp-substack",
      "imageUrl": "/freedevtools/mcp/pfp/michalnaka.webp",
      "description": "Download and summarize public Substack posts by extracting titles, authors, subtitles, and content directly within workflows.",
      "stars": 10,
      "forks": 7,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-09-09T22:20:27Z",
      "readme_content": "# MCP Substack Server\n\nA Model Context Protocol (MCP) server for downloading and parsing Substack posts. Works with Claude.ai desktop app.\n\n## Installation\n\n1. Install dependencies:\n```bash\nnpm install\n```\n\n2. Configure Claude desktop app:\n   \nAdd to `~/Library/Application Support/Claude/claude_desktop_config.json`:\n```json\n{\n  \"mcpServers\": {\n    \"mcp-substack\": {\n      \"command\": \"/opt/homebrew/bin/node\",\n      \"args\": [\"/path/to/mcp-substack/lib/index.mjs\"],\n      \"methods\": {\n        \"download_substack\": {\n          \"description\": \"Download and parse content from a Substack post\"\n        }\n      }\n    }\n  }\n}\n```\n\n3. Start the server:\n```bash\nnpm start\n```\n\n## Usage\n\nIn Claude desktop app, use:\n```\nCould you download and summarize this Substack post: [URL]\n```\n\n## Features\n\n- Downloads and parses Substack posts\n- Extracts title, author, subtitle, and content\n- Works with public Substack posts\n- Integrates with Claude.ai desktop app\n\n## Requirements\n\n- Node.js v18+\n- Claude desktop app\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "substack",
        "subtitles",
        "extracting",
        "substack posts",
        "mcp substack",
        "substack download"
      ],
      "category": "document-processing"
    },
    "mimi520879--docs": {
      "owner": "mimi520879",
      "name": "docs",
      "url": "https://github.com/mimi520879/docs",
      "imageUrl": "/freedevtools/mcp/pfp/mimi520879.webp",
      "description": "A starter kit for creating and customizing documentation with built-in examples and components. It automates the deployment process from a GitHub repository, making it easier to manage API reference and guide pages.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "MDX",
      "updated_at": "2025-02-08T06:30:38Z",
      "readme_content": "# Mintlify Starter Kit\n\nClick on `Use this template` to copy the Mintlify starter kit. The starter kit contains examples including\n\n- Guide pages\n- Navigation\n- Customizations\n- API Reference pages\n- Use of popular components\n\n### Development\n\nInstall the [Mintlify CLI](https://www.npmjs.com/package/mintlify) to preview the documentation changes locally. To install, use the following command\n\n```\nnpm i -g mintlify\n```\n\nRun the following command at the root of your documentation (where docs.json is)\n\n```\nmintlify dev\n```\n\n### Publishing Changes\n\nInstall our Github App to auto propagate changes from your repo to your deployment. Changes will be deployed to production automatically after pushing to the default branch. Find the link to install on your dashboard. \n\n#### Troubleshooting\n\n- Mintlify dev isn't running - Run `mintlify install` it'll re-install dependencies.\n- Page loads as a 404 - Make sure you are running in a folder with `docs.json`\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "documentation",
        "document",
        "docs",
        "documentation built",
        "customizing documentation",
        "document processing"
      ],
      "category": "document-processing"
    },
    "modelcontextprotocol--servers": {
      "owner": "modelcontextprotocol",
      "name": "servers",
      "url": "https://github.com/modelcontextprotocol/servers",
      "imageUrl": "/freedevtools/mcp/pfp/modelcontextprotocol.webp",
      "description": "Integrates with Google Drive to provide functionality for listing, reading, and searching files. It supports various file formats and exports Google Workspace files to applicable formats for easier access.",
      "stars": 69473,
      "forks": 8234,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-04T09:56:52Z",
      "readme_content": "# Model Context Protocol servers\n\nThis repository is a collection of *reference implementations* for the [Model Context Protocol](https://modelcontextprotocol.io/) (MCP), as well as references to community-built servers and additional resources.\n\nThe servers in this repository showcase the versatility and extensibility of MCP, demonstrating how it can be used to give Large Language Models (LLMs) secure, controlled access to tools and data sources.\nTypically, each MCP server is implemented with an MCP SDK:\n\n- [C# MCP SDK](https://github.com/modelcontextprotocol/csharp-sdk)\n- [Go MCP SDK](https://github.com/modelcontextprotocol/go-sdk)\n- [Java MCP SDK](https://github.com/modelcontextprotocol/java-sdk)\n- [Kotlin MCP SDK](https://github.com/modelcontextprotocol/kotlin-sdk)\n- [PHP MCP SDK](https://github.com/modelcontextprotocol/php-sdk)\n- [Python MCP SDK](https://github.com/modelcontextprotocol/python-sdk)\n- [Ruby MCP SDK](https://github.com/modelcontextprotocol/ruby-sdk)\n- [Rust MCP SDK](https://github.com/modelcontextprotocol/rust-sdk)\n- [Swift MCP SDK](https://github.com/modelcontextprotocol/swift-sdk)\n- [TypeScript MCP SDK](https://github.com/modelcontextprotocol/typescript-sdk)\n\n> [!NOTE]\n> Lists in this README are maintained in alphabetical order to minimize merge conflicts when adding new items.\n\n## 🌟 Reference Servers\n\nThese servers aim to demonstrate MCP features and the official SDKs.\n\n- **[Everything](src/everything)** - Reference / test server with prompts, resources, and tools.\n- **[Fetch](src/fetch)** - Web content fetching and conversion for efficient LLM usage.\n- **[Filesystem](src/filesystem)** - Secure file operations with configurable access controls.\n- **[Git](src/git)** - Tools to read, search, and manipulate Git repositories.\n- **[Memory](src/memory)** - Knowledge graph-based persistent memory system.\n- **[Sequential Thinking](src/sequentialthinking)** - Dynamic and reflective problem-solving through thought sequences.\n- **[Time](src/time)** - Time and timezone conversion capabilities.\n\n### Archived\n\nThe following reference servers are now archived and can be found at [servers-archived](https://github.com/modelcontextprotocol/servers-archived).\n\n- **[AWS KB Retrieval](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/aws-kb-retrieval-server)** - Retrieval from AWS Knowledge Base using Bedrock Agent Runtime.\n- **[Brave Search](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/brave-search)** - Web and local search using Brave's Search API.  Has been replaced by the [official server](https://github.com/brave/brave-search-mcp-server).\n- **[EverArt](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/everart)** - AI image generation using various models.\n- **[GitHub](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/github)** - Repository management, file operations, and GitHub API integration.\n- **[GitLab](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/gitlab)** - GitLab API, enabling project management.\n- **[Google Drive](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/gdrive)** - File access and search capabilities for Google Drive.\n- **[Google Maps](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/google-maps)** - Location services, directions, and place details.\n- **[PostgreSQL](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/postgres)** - Read-only database access with schema inspection.\n- **[Puppeteer](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/puppeteer)** - Browser automation and web scraping.\n- **[Redis](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/redis)** - Interact with Redis key-value stores.\n- **[Sentry](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/sentry)** - Retrieving and analyzing issues from Sentry.io.\n- **[Slack](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/slack)** - Channel management and messaging capabilities. Now maintained by [Zencoder](https://github.com/zencoderai/slack-mcp-server)\n- **[SQLite](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/sqlite)** - Database interaction and business intelligence capabilities.\n\n## 🤝 Third-Party Servers\n\n### 🎖️ Official Integrations\n\nOfficial integrations are maintained by companies building production ready MCP servers for their platforms.\n\n- <img height=\"12\" width=\"12\" src=\"https://www.21st.dev/favicon.ico\" alt=\"21st.dev Logo\" /> **[21st.dev Magic](https://github.com/21st-dev/magic-mcp)** - Create crafted UI components inspired by the best 21st.dev design engineers.\n- <img height=\"12\" width=\"12\" src=\"https://framerusercontent.com/images/LpSK1tSZweomrAHOMAj9Gea96lA.svg\" alt=\"Paragon Logo\" /> **[ActionKit by Paragon](https://github.com/useparagon/paragon-mcp)** - Connect to 130+ SaaS integrations (e.g. Slack, Salesforce, Gmail) with Paragon’s [ActionKit](https://www.useparagon.com/actionkit) API.\n- <img height=\"12\" width=\"12\" src=\"https://invoxx-public-bucket.s3.eu-central-1.amazonaws.com/frontend-resources/adfin-logo-small.svg\" alt=\"Adfin Logo\" /> **[Adfin](https://github.com/Adfin-Engineering/mcp-server-adfin)** - The only platform you need to get paid - all payments in one place, invoicing and accounting reconciliations with [Adfin](https://www.adfin.com/).\n- <img height=\"12\" width=\"12\" src=\"https://github.com/AgentOps-AI/agentops/blob/main/docs/favicon.png\" alt=\"AgentOps Logo\" /> **[AgentOps](https://github.com/AgentOps-AI/agentops-mcp)** - Provide observability and tracing for debugging AI agents with [AgentOps](https://www.agentops.ai/) API.\n- <img height=\"12\" width=\"12\" src=\"https://www.agentql.com/favicon/favicon.png\" alt=\"AgentQL Logo\" /> **[AgentQL](https://github.com/tinyfish-io/agentql-mcp)** - Enable AI agents to get structured data from unstructured web with [AgentQL](https://www.agentql.com/).\n- <img height=\"12\" width=\"12\" src=\"https://agentrpc.com/favicon.ico\" alt=\"AgentRPC Logo\" /> **[AgentRPC](https://github.com/agentrpc/agentrpc)** - Connect to any function, any language, across network boundaries using [AgentRPC](https://www.agentrpc.com/).\n- **[Agentset](https://github.com/agentset-ai/mcp-server)** - RAG for your knowledge base connected to [Agentset](https://agentset.ai).\n- <img height=\"12\" width=\"12\" src=\"https://aiven.io/favicon.ico\" alt=\"Aiven Logo\" /> **[Aiven](https://github.com/Aiven-Open/mcp-aiven)** - Navigate your [Aiven projects](https://go.aiven.io/mcp-server) and interact with the PostgreSQL®, Apache Kafka®, ClickHouse® and OpenSearch® services\n- <img height=\"12\" width=\"12\" src=\"https://www.alation.com/resource-center/download/7p3vnbbznfiw/34FMtBTex5ppvs2hNYa9Fc/c877c37e88e5339878658697c46d2d58/Alation-Logo-Bug-Primary.svg\" alt=\"Alation Logo\" /> **[Alation](https://github.com/Alation/alation-ai-agent-sdk)** - Unlock the power of the enterprise Data Catalog by harnessing tools provided by the Alation MCP server.\n- <img height=\"12\" width=\"12\" src=\"https://i.postimg.cc/5NYw9qjS/alby-icon-head-yellow-500x500.png\" alt=\"Alby Logo\" /> **[Alby Bitcoin Payments](https://github.com/getAlby/mcp)** - Connect any bitcoin lightning wallet to your agent to send and receive instant payments globally with your agent.\n- **[Algolia](https://github.com/algolia/mcp)** - Use AI agents to provision, configure, and query your [Algolia](https://algolia.com) search indices.\n- <img height=\"12\" width=\"12\" src=\"https://img.alicdn.com/imgextra/i4/O1CN01epkXwH1WLAXkZfV6N_!!6000000002771-2-tps-200-200.png\" alt=\"Alibaba Cloud AnalyticDB for MySQL Logo\" /> **[Alibaba Cloud AnalyticDB for MySQL](https://github.com/aliyun/alibabacloud-adb-mysql-mcp-server)** - Connect to an [AnalyticDB for MySQL](https://www.alibabacloud.com/en/product/analyticdb-for-mysql) cluster for getting database or table metadata, querying and analyzing data. It will be supported to add the OpenAPI for cluster operation in the future.\n- <img height=\"12\" width=\"12\" src=\"https://github.com/aliyun/alibabacloud-adbpg-mcp-server/blob/master/images/AnalyticDB.png\" alt=\"Alibaba Cloud AnalyticDB for PostgreSQL Logo\" /> **[Alibaba Cloud AnalyticDB for PostgreSQL](https://github.com/aliyun/alibabacloud-adbpg-mcp-server)** - An MCP server to connect to [AnalyticDB for PostgreSQL](https://github.com/aliyun/alibabacloud-adbpg-mcp-server) instances, query and analyze data.\n- <img height=\"12\" width=\"12\" src=\"https://img.alicdn.com/imgextra/i3/O1CN0101UWWF1UYn3rAe3HU_!!6000000002530-2-tps-32-32.png\" alt=\"DataWorks Logo\" /> **[Alibaba Cloud DataWorks](https://github.com/aliyun/alibabacloud-dataworks-mcp-server)** - A Model Context Protocol (MCP) server that provides tools for AI, allowing it to interact with the [DataWorks](https://www.alibabacloud.com/help/en/dataworks/) Open API through a standardized interface. This implementation is based on the Alibaba Cloud Open API and enables AI agents to perform cloud resources operations seamlessly.\n- <img height=\"12\" width=\"12\" src=\"https://opensearch-shanghai.oss-cn-shanghai.aliyuncs.com/ouhuang/aliyun-icon.png\" alt=\"Alibaba Cloud OpenSearch Logo\" /> **[Alibaba Cloud OpenSearch](https://github.com/aliyun/alibabacloud-opensearch-mcp-server)** - This MCP server equips AI Agents with tools to interact with [OpenSearch](https://help.aliyun.com/zh/open-search/?spm=5176.7946605.J_5253785160.6.28098651AaYZXC) through a standardized and extensible interface.\n- <img height=\"12\" width=\"12\" src=\"https://github.com/aliyun/alibaba-cloud-ops-mcp-server/blob/master/image/alibaba-cloud.png\" alt=\"Alibaba Cloud OPS Logo\" /> **[Alibaba Cloud OPS](https://github.com/aliyun/alibaba-cloud-ops-mcp-server)** - Manage the lifecycle of your Alibaba Cloud resources with [CloudOps Orchestration Service](https://www.alibabacloud.com/en/product/oos) and Alibaba Cloud OpenAPI.\n- <img height=\"12\" width=\"12\" src=\"https://github.com/aliyun/alibabacloud-rds-openapi-mcp-server/blob/main/assets/alibabacloudrds.png\" alt=\"Alibaba Cloud RDS MySQL Logo\" /> **[Alibaba Cloud RDS](https://github.com/aliyun/alibabacloud-rds-openapi-mcp-server)** - An MCP server designed to interact with the Alibaba Cloud RDS OpenAPI, enabling programmatic management of RDS resources via an LLM.\n- <img height=\"12\" width=\"12\" src=\"https://www.alipayplus.com/favicon.ico\" alt=\"AlipayPlus Logo\" /> **[AlipayPlus](https://github.com/alipay/global-alipayplus-mcp)** - Connect your AI Agents to AlipayPlus Checkout Payment.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.allvoicelab.com/resources/workbench/dist/icon-dark.ico\" alt=\"AllVoiceLab Logo\" /> **[AllVoiceLab](https://www.allvoicelab.com/mcp)** - An AI voice toolkit with TTS, voice cloning, and video translation, now available as an MCP server for smarter agent integration.\n- <img height=\"12\" width=\"12\" src=\"https://files.alpaca.markets/webassets/favicon-32x32.png\" alt=\"Alpaca Logo\" /> **[Alpaca](https://github.com/alpacahq/alpaca-mcp-server)** – Alpaca's MCP server lets you trade stocks and options, analyze market data, and build strategies through [Alpaca's Trading API](https://alpaca.markets/)\n- <img height=\"12\" width=\"12\" src=\"https://www.alphavantage.co/logo.png/\" alt=\"AlphaVantage Logo\" /> **[AlphaVantage](https://mcp.alphavantage.co/)** - Connect to 100+ APIs for financial market data, including stock prices, fundamentals, and more from [AlphaVantage](https://www.alphavantage.co)\n- <img height=\"12\" width=\"12\" src=\"https://alttester.com/app/themes/alttester-sage-theme/public/images/logo-alttester.038ec8.png\" alt=\"AltTester Logo\" /> **[AltTester®](https://alttester.com/docs/desktop/latest/pages/ai-extension.html)** - Use AltTester® capabilities to connect and test your Unity or Unreal game. Write game test automation faster and smarter, using [AltTester](https://alttester.com) and the AltTester® MCP server. \n- <img height=\"12\" width=\"12\" src=\"https://www.antom.com/favicon.ico\" alt=\"Antom Logo\" /> **[Antom](https://github.com/alipay/global-antom-mcp)** - Connect your AI Agents to Antom Checkout Payment.\n- <img height=\"12\" width=\"12\" src=\"https://developers.anytype.io/img/favicon.ico\" alt=\"Anytype Logo\" /> **[Anytype](https://github.com/anyproto/anytype-mcp)** - An MCP server enabling AI assistants to interact with [Anytype](https://anytype.io) - a local and collaborative wiki - to organize objects, lists, and more through natural language.\n- <img height=\"12\" width=\"12\" src=\"https://doris.apache.org/images/favicon.ico\" alt=\"Apache Doris Logo\" /> **[Apache Doris](https://github.com/apache/doris-mcp-server)** - MCP Server For [Apache Doris](https://doris.apache.org/), an MPP-based real-time data warehouse.\n- <img height=\"12\" width=\"12\" src=\"https://iotdb.apache.org/img/logo.svg\" alt=\"Apache IoTDB Logo\" /> **[Apache IoTDB](https://github.com/apache/iotdb-mcp-server)** - MCP Server for [Apache IoTDB](https://github.com/apache/iotdb) database and its tools\n- **[Apache Pinot](https://github.com/startreedata/mcp-pinot)** – MCP server for running real - time analytics queries on Apache Pinot, an open-source OLAP database built for high-throughput, low-latency powering real-time applications.\n- <img height=\"12\" width=\"12\" src=\"https://apify.com/favicon.ico\" alt=\"Apify Logo\" /> **[Apify](https://github.com/apify/apify-mcp-server)** - Use 6,000+ pre-built cloud tools to extract data from websites, e-commerce, social media, search engines, maps, and more\n- <img height=\"12\" width=\"12\" src=\"https://2052727.fs1.hubspotusercontent-na1.net/hubfs/2052727/cropped-cropped-apimaticio-favicon-1-32x32.png\" alt=\"APIMatic Logo\" /> **[APIMatic MCP](https://github.com/apimatic/apimatic-validator-mcp)** - APIMatic MCP Server is used to validate OpenAPI specifications using [APIMatic](https://www.apimatic.io/). The server processes OpenAPI files and returns validation summaries by leveraging APIMatic's API.\n- <img height=\"12\" width=\"12\" src=\"https://apollo-server-landing-page.cdn.apollographql.com/_latest/assets/favicon.png\" alt=\"Apollo Graph Logo\" /> **[Apollo MCP Server](https://github.com/apollographql/apollo-mcp-server/)** - Connect your GraphQL APIs to AI agents\n- <img height=\"12\" width=\"12\" src=\"https://developer.aqara.com/favicon.ico\" alt=\"Aqara Logo\" /> **[Aqara MCP Server](https://github.com/aqara/aqara-mcp-server/)** - Control  [Aqara](https://www.aqara.com/) smart home devices, query status, execute scenes, and much more using natural language.\n- <img height=\"12\" width=\"12\" src=\"https://media.licdn.com/dms/image/v2/C4D0BAQEeD7Dxbpadkw/company-logo_200_200/company-logo_200_200/0/1644692667545/archbee_logo?e=2147483647&v=beta&t=lTi9GRIoqzG6jN3kJC26uZWh0q3uiQelsH6mGoq_Wfw\" alt=\"Archbee Logo\" /> **[Archbee](https://www.npmjs.com/package/@archbee/mcp)** - Write and publish documentation that becomes the trusted source for instant answers with AI. Stop cobbling tools and use [Archbee](https://www.archbee.com/) — the first complete documentation platform.\n- <img height=\"12\" width=\"12\" src=\"https://phoenix.arize.com/wp-content/uploads/2023/04/cropped-Favicon-32x32.png\" alt=\"Arize-Phoenix Logo\" /> **[Arize Phoenix](https://github.com/Arize-ai/phoenix/tree/main/js/packages/phoenix-mcp)** - Inspect traces, manage prompts, curate datasets, and run experiments using [Arize Phoenix](https://github.com/Arize-ai/phoenix), an open-source AI and LLM observability tool.\n- <img height=\"12\" width=\"12\" src=\"https://731523176-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FaVUBXRZbpAgtjYf5HsvO%2Fuploads%2FaRRrVVocXCTr6GkepfCx%2Flogo_color.svg?alt=media&token=3ba24089-0ab2-421f-a9d9-41f2f94f954a\" alt=\"Armor Logo\" /> **[Armor Crypto MCP](https://github.com/armorwallet/armor-crypto-mcp)** - MCP to interface with multiple blockchains, staking, DeFi, swap, bridging, wallet management, DCA, Limit Orders, Coin Lookup, Tracking and more.\n- <img height=\"12\" width=\"12\" src=\"https://console.asgardeo.io/app/libs/themes/wso2is/assets/images/branding/favicon.ico\" alt=\"Asgardeo Logo\" /> **[Asgardeo](https://github.com/asgardeo/asgardeo-mcp-server)** - MCP server to interact with your [Asgardeo](https://wso2.com/asgardeo) organization through LLM tools.\n- <img height=\"12\" width=\"12\" src=\"https://www.datastax.com/favicon-32x32.png\" alt=\"DataStax logo\" /> **[Astra DB](https://github.com/datastax/astra-db-mcp)** - Comprehensive tools for managing collections and documents in a [DataStax Astra DB](https://www.datastax.com/products/datastax-astra) NoSQL database with a full range of operations such as create, update, delete, find, and associated bulk actions.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/66598898fd13d51606c3215d/66ccbfef13bd8bc19d587578_favicon-32x32.png\" alt=\"Atla Logo\" /> **[Atla](https://github.com/atla-ai/atla-mcp-server)** - Enable AI agents to interact with the [Atla API](https://docs.atla-ai.com/) for state-of-the-art LLMJ evaluation.\n- <img height=\"12\" width=\"12\" src=\"https://assets.atlan.com/assets/atlan-a-logo-blue-background.png\" alt=\"Atlan Logo\" /> **[Atlan](https://github.com/atlanhq/agent-toolkit/tree/main/modelcontextprotocol)** - The Atlan Model Context Protocol server allows you to interact with the [Atlan](https://www.atlan.com/) services through multiple tools.\n- <img height=\"12\" width=\"12\" src=\"https://www.atlassian.com/favicon.ico\" alt=\"Atlassian Logo\" /> **[Atlassian](https://www.atlassian.com/platform/remote-mcp-server)** - Securely interact with Jira work items and Confluence pages, and search across both.\n- <img height=\"12\" width=\"12\" src=\"https://res.oafimg.cn/-/737b3b3ffed9b19e/logo.png\" alt=\"AtomGit Logo\" /> **[AtomGit](https://atomgit.com/atomgit-open-source-ecosystem/atomgit-mcp-server)** - Official AtomGit server for integration with repository management, PRs, issues, branches, labels, and more.\n- <img height=\"12\" width=\"12\" src=\"https://resources.audiense.com/hubfs/favicon-1.png\" alt=\"Audiense Logo\" /> **[Audiense Insights](https://github.com/AudienseCo/mcp-audiense-insights)** - Marketing insights and audience analysis from [Audiense](https://www.audiense.com/products/audiense-insights) reports, covering demographic, cultural, influencer, and content engagement analysis.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.auth0.com/website/website/favicons/auth0-favicon.svg\" alt=\"Auth0 Logo\" /> **[Auth0](https://github.com/auth0/auth0-mcp-server)** - MCP server for interacting with your Auth0 tenant, supporting creating and modifying actions, applications, forms, logs, resource servers, and more.\n- <img height=\"12\" width=\"12\" src=\"https://firstorder.ai/favicon_auth.ico\" alt=\"Authenticator App Logo\" /> **[Authenticator App · 2FA](https://github.com/firstorderai/authenticator_mcp)** - A secure MCP (Model Context Protocol) server that enables AI agents to interact with the Authenticator App.\n- <img height=\"12\" width=\"12\" src=\"https://a0.awsstatic.com/libra-css/images/site/fav/favicon.ico\" alt=\"AWS Logo\" /> **[AWS](https://github.com/awslabs/mcp)** -  Specialized MCP servers that bring AWS best practices directly to your development workflow.\n- <img height=\"12\" width=\"12\" src=\"https://axiom.co/favicon.ico\" alt=\"Axiom Logo\" /> **[Axiom](https://github.com/axiomhq/mcp-server-axiom)** - Query and analyze your Axiom logs, traces, and all other event data in natural language\n- <img height=\"12\" width=\"12\" src=\"https://cdn-dynmedia-1.microsoft.com/is/content/microsoftcorp/acom_social_icon_azure\" alt=\"Microsoft Azure Logo\" /> **[Azure](https://github.com/microsoft/mcp/tree/main/servers/Azure.Mcp.Server)** - The Azure MCP Server gives MCP Clients access to key Azure services and tools like Azure Storage, Cosmos DB, the Azure CLI, and more.\n- <img height=\"12\" width=\"12\" src=\"https://cdn-dynmedia-1.microsoft.com/is/content/microsoftcorp/1062064-Products-1.2-24x24\" alt=\"Microsoft Azure DevOps Logo\" /> **[Azure DevOps](https://github.com/microsoft/azure-devops-mcp)** - Interact with Azure DevOps services like repositories, work items, builds, releases, test plans, and code search.\n- <img height=\"12\" width=\"12\" src=\"https://application.backdocket.com/favicon.ico\" alt=\"Backdocket Logo\" /> **[Backdocket](https://ai.backdocket.com)** - Search, Retrieve, and Update your **[Backdocket](https://backdocket.com)** data. This currently includes Claims, Matters, Contacts, Tasks and Advanced Searches. To easily use the Remote Mcp Server utilize the following url: **[https://ai.backdocket.com/mcp]([https://backdocket.com](https://ai.backdocket.com/mcp))**\n- <img height=\"12\" width=\"12\" src=\"https://mapopen-website-wiki.cdn.bcebos.com/LOGO/lbsyunlogo_icon.ico\" alt=\"Baidu Map Logo\" /> **[Baidu Map](https://github.com/baidu-maps/mcp)** - [Baidu Map MCP Server](https://lbsyun.baidu.com/faq/api?title=mcpserver/base) provides tools for AI agents to interact with Baidu Maps APIs, enabling location-based services and geospatial data analysis.\n- <img height=\"12\" width=\"12\" src=\"https://www.bankless.com/favicon.ico\" alt=\"Bankless Logo\" /> **[Bankless Onchain](https://github.com/bankless/onchain-mcp)** - Query Onchain data, like ERC20 tokens, transaction history, smart contract state.\n- <img height=\"12\" width=\"12\" src=\"https://baserow.io/img/logo_baserow_square_large.png\" alt=\"Baserow Logo\" /> **[Baserow](https://gitlab.com/baserow/baserow/-/tree/develop/backend/src/baserow/api/mcp)** - Query data from Baserow self-hosted or SaaS databases using MCP integration.\n- <img height=\"12\" width=\"12\" src=\"https://bicscan.io/favicon.png\" alt=\"BICScan Logo\" /> **[BICScan](https://github.com/ahnlabio/bicscan-mcp)** - Risk score / asset holdings of EVM blockchain address (EOA, CA, ENS) and even domain names.\n- <img height=\"12\" width=\"12\" src=\"https://web-cdn.bitrise.io/favicon.ico\" alt=\"Bitrise Logo\" /> **[Bitrise](https://github.com/bitrise-io/bitrise-mcp)** - Chat with your builds, CI, and [more](https://bitrise.io/blog/post/chat-with-your-builds-ci-and-more-introducing-the-bitrise-mcp-server).\n- <img height=\"12\" width=\"12\" src=\"https://boikot.xyz/assets/favicon.svg\" alt=\"boikot Logo\" /> **[Boikot](https://github.com/boikot-xyz/boikot)** - Learn about the ethical and unethical actions of major companies with [boikot.xyz](https://boikot.xyz/).\n- <img height=\"12\" width=\"12\" src=\"https://boldsign.com/favicon.ico\" alt=\"BoldSign Logo\" /> **[BoldSign](https://github.com/boldsign/boldsign-mcp)** - Search, request, and manage e-signature contracts effortlessly with [BoldSign](https://boldsign.com/).\n- <img height=\"12\" width=\"12\" src=\"https://boost.space/favicon.ico\" alt=\"Boost.space Logo\" /> **[Boost.space](https://github.com/boostspace/boostspace-mcp-server)** - An MCP server integrating with [Boost.space](https://boost.space) for centralized, automated business data from 2000+ sources.\n- <img height=\"12\" width=\"12\" src=\"https://www.box.com/favicon.ico\" alt=\"Box Logo\" /> **[Box](https://github.com/box-community/mcp-server-box)** - Interact with the Intelligent Content Management platform through Box AI.\n- <img height=\"12\" width=\"12\" src=\"https://www.brightdata.com/favicon.ico\" alt=\"BrightData Logo\" /> **[BrightData](https://github.com/luminati-io/brightdata-mcp)** - Discover, extract, and interact with the web - one interface powering automated access across the public internet.\n- <img height=\"12\" width=\"12\" src=\"https://browserbase.com/favicon.ico\" alt=\"Browserbase Logo\" /> **[Browserbase](https://github.com/browserbase/mcp-server-browserbase)** - Automate browser interactions in the cloud (e.g. web navigation, data extraction, form filling, and more)\n- <img height=\"12\" width=\"12\" src=\"https://browserstack.wpenginepowered.com/wp-content/themes/browserstack/img/favicons/favicon.ico\" alt=\"BrowserStack Logo\" /> **[BrowserStack](https://github.com/browserstack/mcp-server)** - Access BrowserStack's [Test Platform](https://www.browserstack.com/test-platform) to debug, write and fix tests, do accessibility testing and more.\n- <img height=\"12\" width=\"12\" src=\"https://www.google.com/s2/favicons?domain=buildkite.com&sz=24\" alt=\"Buildkite Logo\" /> **[Buildkite](https://github.com/buildkite/buildkite-mcp-server)** - Exposing Buildkite data (pipelines, builds, jobs, tests) to AI tooling and editors.\n- <img height=\"12\" width=\"12\" src=\"https://bldbl.dev/favico.png\" alt=\"Buildable Logo\" />**[Buildable](https://github.com/chunkydotdev/bldbl-mcp)** (TypeScript) - Official MCP server for Buildable AI-powered development platform. Enables AI assistants to manage tasks, track progress, get project context, and collaborate with humans on software projects.\n- <img height=\"12\" width=\"12\" src=\"https://builtwith.com/favicon.ico\" alt=\"BuiltWith Logo\" /> **[BuiltWith](https://github.com/builtwith/mcp)** - Identify the technology stack behind any website.\n- <img height=\"12\" width=\"12\" src=\"https://portswigger.net/favicon.ico\" alt=\"PortSwigger Logo\" /> **[Burp Suite](https://github.com/PortSwigger/mcp-server)** - MCP Server extension allowing AI clients to connect to [Burp Suite](https://portswigger.net)\n- <img src=\"https://app.cal.com/favicon.ico\" alt=\"Cal.com\" width=\"12\" height=\"12\"> **[Cal.com](https://www.npmjs.com/package/@calcom/cal-mcp?activeTab=readme)** - Connect to the Cal.com API to schedule and manage bookings and appointments.\n- <img height=\"12\" width=\"12\" src=\"https://campertunity.com/assets/icon/favicon.ico\" alt=\"Campertunity Logo\" /> **[Campertunity](https://github.com/campertunity/mcp-server)** - Search campgrounds around the world on campertunity, check availability, and provide booking links.\n- <img height=\"12\" width=\"12\" src=\"https://static.canva.com/static/images/favicon.ico\" alt=\"Canva logo\" /> **[Canva](https://www.canva.dev/docs/apps/mcp-server/)** — Provide AI - powered development assistance for [Canva](https://canva.com) apps and integrations.\n- <img height=\"12\" width=\"12\" src=\"https://carbonvoice.app/favicon.ico\" alt=\"Carbon Voice Logo\" /> **[Carbon Voice](https://github.com/PhononX/cv-mcp-server)** - MCP Server that connects AI Agents to [Carbon Voice](https://getcarbon.app). Create, manage, and interact with voice messages, conversations, direct messages, folders, voice memos, AI actions and more in [Carbon Voice](https://getcarbon.app).\n-  **[Cartesia](https://github.com/cartesia-ai/cartesia-mcp)** - Connect to the [Cartesia](https://cartesia.ai/) voice platform to perform text-to-speech, voice cloning etc.\n- <img height=\"12\" width=\"12\" src=\"https://www.cashfree.com/favicon.ico\" alt=\"Cashfree logo\" /> **[Cashfree](https://github.com/cashfree/cashfree-mcp)** - [Cashfree Payments](https://www.cashfree.com/) official MCP server.\n- **[CB Insights](https://github.com/cbinsights/cbi-mcp-server)** - Use the [CB Insights](https://www.cbinsights.com) MCP Server to connect to [ChatCBI](https://www.cbinsights.com/chatcbi/)\n- <img height=\"12\" width=\"12\" src=\"https://cleanupcrew.ai/favicon-light.png\" alt=\"Cleanup Crew logo\" /> **[Cleanup Crew](https://cleanupcrew.ai/install)** - Real-time human support service for non-technical founders using AI coding tools. When AI hits a wall, request instant human help directly from your IDE.\n- <img height=\"12\" width=\"12\" src=\"https://www.chargebee.com/static/resources/brand/favicon.png\" alt=\"Chargebee Logo\" /> **[Chargebee](https://github.com/chargebee/agentkit/tree/main/modelcontextprotocol)** - MCP Server that connects AI agents to [Chargebee platform](https://www.chargebee.com).\n- <img height=\"12\" width=\"12\" src=\"https://cheqd.io/wp-content/uploads/2023/03/logo_cheqd_favicon.png\" alt=\"Cheqd Logo\" /> **[Cheqd](https://github.com/cheqd/mcp-toolkit)** - Enable AI Agents to be trusted, verified, prevent fraud, protect your reputation, and more through [cheqd's](https://cheqd.io) Trust Registries and Credentials.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.chiki.studio/brand/logo.png\" alt=\"Chiki StudIO Logo\" /> **[Chiki StudIO](https://chiki.studio/galimybes/mcp/)** - Create your own configurable MCP servers purely via configuration (no code), with instructions, prompts, and tools support.\n- <img height=\"12\" width=\"12\" src=\"https://trychroma.com/_next/static/media/chroma-logo.ae2d6e4b.svg\" alt=\"Chroma Logo\" /> **[Chroma](https://github.com/chroma-core/chroma-mcp)** - Embeddings, vector search, document storage, and full-text search with the open-source AI application database\n- <img height=\"12\" width=\"12\" src=\"https://www.chronulus.com/favicon/chronulus-logo-blue-on-alpha-square-128x128.ico\" alt=\"Chronulus AI Logo\" /> **[Chronulus AI](https://github.com/ChronulusAI/chronulus-mcp)** - Predict anything with Chronulus AI forecasting and prediction agents.\n- <img height=\"12\" width=\"12\" src=\"https://circleci.com/favicon.ico\" alt=\"CircleCI Logo\" /> **[CircleCI](https://github.com/CircleCI-Public/mcp-server-circleci)** - Enable AI Agents to fix build failures from CircleCI.\n- <img height=\"12\" width=\"12\" src=\"https://assets.zilliz.com/Zilliz_Logo_Mark_White_20230223_041013_86057436cc.png\" alt=\"Claude Context Logo\" /> **[Claude Context](https://github.com/zilliztech/claude-context)** - Bring your codebase as context to Claude Code\n- <img height=\"12\" width=\"12\" src=\"https://clickhouse.com/favicon.ico\" alt=\"ClickHouse Logo\" /> **[ClickHouse](https://github.com/ClickHouse/mcp-clickhouse)** - Query your [ClickHouse](https://clickhouse.com/) database server.\n- <img height=\"12\" width=\"12\" src=\"https://brand.clicksend.com/_ipx/s_794x608/img/clicksend_icon_only.svg\" alt=\"ClickSend Logo\" /> **[ClickSend](https://github.com/ClickSend/clicksend-mcp-server/)** - This is the official ClickSend MCP Server developed by ClickSend team.\n- <img height=\"12\" width=\"12\" src=\"https://7463-tcb-advanced-a656fc-1257967285.tcb.qcloud.la/mcp/cloudbase-logo.svg\" alt=\"CloudBase Logo\" /> **[CloudBase](https://github.com/TencentCloudBase/CloudBase-AI-ToolKit)** - One-stop backend services for WeChat Mini-Programs and full-stack apps with serverless cloud functions and databases by [Tencent CloudBase](https://tcb.cloud.tencent.com/)\n- <img height=\"12\" width=\"12\" src=\"https://www.cloudbet.com/favicon.ico\" alt=\"Cloudbet Logo\" /> **[Cloudbet](https://github.com/cloudbet/sports-mcp-server)** - Structured sports and esports data via Cloudbet API: fixtures, live odds, stake limits, and markets.\n- <img height=\"12\" width=\"12\" src=\"https://www.cloudbees.com/favicon.ico\" alt=\"CloudBees Logo\" /> **[CloudBees](https://docs.cloudbees.com/docs/cloudbees-mcp/latest/)** - Enable AI access to your [CloudBees Unify](https://www.cloudbees.com/unify) environment.\n- <img src=\"http://www.google.com/s2/favicons?domain=www.cloudera.com\" alt=\"Cloudera Iceberg\" width=\"12\" height=\"12\"> **[Cloudera Iceberg](https://github.com/cloudera/iceberg-mcp-server)** - enabling AI on the [Open Data Lakehouse](https://www.cloudera.com/products/open-data-lakehouse.html).\n- <img height=\"12\" width=\"12\" src=\"https://cdn.simpleicons.org/cloudflare\" /> **[Cloudflare](https://github.com/cloudflare/mcp-server-cloudflare)** - Deploy, configure & interrogate your resources on the Cloudflare developer platform (e.g. Workers/KV/R2/D1)\n- <img src=\"https://cdn.prod.website-files.com/64d41aab8183c7c3324ddb29/67c0f1e272e51cf3c511c17c_Gyph.svg\" alt=\"Cloudinary\" width=\"12\" height=\"12\"> **[Cloudinary](https://github.com/cloudinary/mcp-servers)** - Exposes Cloudinary's media upload, transformation, AI analysis, management, optimization and delivery as tools usable by AI agents\n- <img height=\"12\" width=\"12\" src=\"https://raw.githubusercontent.com/Cloudsway-AI/smartsearch/refs/heads/main/plugin_cloudsway.ico\" alt=\"Cloudsway Logo\" /> **[Cloudsway SmartSearch](https://github.com/Cloudsway-AI/smartsearch)** - Web search MCP server powered by Cloudsway, supporting keyword search, language, and safety options. Returns structured JSON results.\n-  **[Codacy](https://github.com/codacy/codacy-mcp-server/)** - Interact with [Codacy](https://www.codacy.com) API to query code quality issues, vulnerabilities, and coverage insights about your code.\n-  **[CodeLogic](https://github.com/CodeLogicIncEngineering/codelogic-mcp-server)** - Interact with [CodeLogic](https://codelogic.com), a Software Intelligence platform that graphs complex code and data architecture dependencies, to boost AI accuracy and insight.\n- <img height=\"12\" width=\"12\" src=\"https://www.coingecko.com/favicon.ico\" alt=\"CoinGecko Logo\" /> **[CoinGecko](https://github.com/coingecko/coingecko-typescript/tree/main/packages/mcp-server)** - Official [CoinGecko API](https://www.coingecko.com/en/api) MCP Server for Crypto Price & Market Data, across 200+ Blockchain Networks and 8M+ Tokens.\n- <img height=\"12\" width=\"12\" src=\"https://www.comet.com/favicon.ico\" alt=\"Comet Logo\" /> **[Comet Opik](https://github.com/comet-ml/opik-mcp)** - Query and analyze your [Opik](https://github.com/comet-ml/opik) logs, traces, prompts and all other telemetry data from your LLMs in natural language.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/6572bd8c27ee5db3eb91f4b3/6572bd8d27ee5db3eb91f55e_favicon-dashflow-webflow-template.svg\" alt=\"OSS Conductor Logo\" /> <img height=\"12\" width=\"12\" src=\"https://orkes.io/icons/icon-48x48.png\" alt=\"Orkes Conductor Logo\" />**[Conductor](https://github.com/conductor-oss/conductor-mcp)** - Interact with Conductor (OSS and Orkes) REST APIs.\n- <img height=\"12\" width=\"12\" src=\"https://platform.composio.dev/favicon.ico\" alt=\"Composio Logo\" /> **[Composio](https://docs.composio.dev/docs/mcp-overview#-getting-started)** – Use [Composio](https://composio.dev) to connect 100+ tools. Zero setup. Auth built-in. Made for agents, works for humans.\n- <img height=\"12\" width=\"12\" src=\"https://www.confluent.io/favicon.ico\" alt=\"Confluent Logo\" /> **[Confluent](https://github.com/confluentinc/mcp-confluent)** - Interact with Confluent Kafka and Confluent Cloud REST APIs.\n- <img src=\"https://contrastsecurity.com/favicon.ico\" alt=\"Contrast Security\" width=\"12\" height=\"12\"> **[Contrast Security](https://github.com/Contrast-Security-OSS/mcp-contrast)** - Brings Contrast's vulnerability and SCA data into your coding agent to quickly remediate vulnerabilities.\n- <img height=\"12\" width=\"12\" src=\"https://www.convex.dev/favicon.ico\" alt=\"Convex Logo\" /> **[Convex](https://stack.convex.dev/convex-mcp-server)** - Introspect and query your apps deployed to Convex.\n- <img height=\"12\" width=\"12\" src=\"https://www.cortex.io/favicon.ico\" alt=\"Cortex Logo\" /> **[Cortex](https://github.com/cortexapps/cortex-mcp)** - Official MCP server for [Cortex](https://www.cortex.io).\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/605755?s=200&v=4\" alt=\"Couchbase Logo\" /> **[Couchbase](https://github.com/Couchbase-Ecosystem/mcp-server-couchbase)** - Interact with the data stored in Couchbase clusters.\n- <img height=\"12\" width=\"12\" src=\"https://github.com/user-attachments/assets/b256f9fa-2020-4b37-9644-c77229ef182b\" alt=\"CRIC 克而瑞 LOGO\"> **[CRIC Wuye AI](https://github.com/wuye-ai/mcp-server-wuye-ai)** - Interact with capabilities of the CRIC Wuye AI platform, an intelligent assistant specifically for the property management industry.\n- <img height=\"12\" width=\"12\" src=\"https://www.crowdstrike.com/etc.clientlibs/crowdstrike/clientlibs/crowdstrike-common/resources/favicon.ico\" alt=\"CrowdStrike Logo\" /> **[CrowdStrike Falcon](https://github.com/CrowdStrike/falcon-mcp)** - Connects AI agents with the CrowdStrike Falcon platform for intelligent security analysis, providing programmatic access to detections, incidents, behaviors, threat intelligence, hosts, vulnerabilities, and identity protection capabilities.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/58433296\" alt=\"CTERA Edge Filer\" /> **[CTERA Edge Filer](https://github.com/ctera/mcp-ctera-edge)** - CTERA Edge Filer delivers intelligent edge caching and multiprotocol file access, enabling fast, secure access to files across core and remote sites.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/58433296\" alt=\"CTERA Portal\" /> **[CTERA Portal](https://github.com/ctera/mcp-ctera-core)** - CTERA Portal is a multi-tenant, multi-cloud platform that delivers a global namespace and unified management across petabytes of distributed content.\n- <img height=\"12\" width=\"12\" src=\"https://app.cycode.com/img/favicon.ico\" alt=\"Cycode Logo\" /> **[Cycode](https://github.com/cycodehq/cycode-cli#mcp-command-experiment)** - Boost security in your dev lifecycle via SAST, SCA, Secrets & IaC scanning with [Cycode](https://cycode.com/).\n- <img height=\"12\" width=\"12\" src=\"http://app.itsdart.com/static/img/favicon.png\" alt=\"Dart Logo\" /> **[Dart](https://github.com/its-dart/dart-mcp-server)** - Interact with task, doc, and project data in [Dart](https://itsdart.com), an AI-native project management tool\n- <img height=\"12\" width=\"12\" src=\"https://cdn.bfldr.com/9AYANS2F/at/k8bgnnxhb4bggjk88r4x9snf/databricks-symbol-color.svg?auto=webp&format=png&width=12&height=13\" alt=\"Databricks Logo\" /> **[Databricks](https://docs.databricks.com/aws/en/generative-ai/mcp/)** - Connect to data, AI tools & agents, and the rest of the Databricks platform using turnkey managed MCP servers. Or, host your own custom MCP servers within the Databricks security and data governance boundary.\n- <img height=\"12\" width=\"12\" src=\"https://datahub.com/wp-content/uploads/2025/04/cropped-Artboard-1-32x32.png\" alt=\"DataHub Logo\" /> **[DataHub](https://github.com/acryldata/mcp-server-datahub)** - Search your data assets, traverse data lineage, write SQL queries, and more using [DataHub](https://datahub.com/) metadata.\n- <img height=\"12\" width=\"12\" src=\"https://www.daytona.io/brand/social-daytona-icon.png\" alt=\"Daytona Logo\" /> **[Daytona](https://github.com/daytonaio/daytona/tree/main/apps/cli/mcp)** - Fast and secure execution of your AI generated code with [Daytona](https://daytona.io) sandboxes\n- <img height=\"12\" width=\"12\" src=\"https://debugg.ai/favicon.svg\" alt=\"Debugg AI Logo\" /> **[Debugg.AI](https://github.com/debugg-ai/debugg-ai-mcp)** - Zero-Config, Fully AI-Managed End-to-End Testing for any code gen platform via [Debugg.AI](https://debugg.ai) remote browsing test agents.\n- <img height=\"12\" width=\"12\" src=\"https://www.deepl.com/img/logo/deepl-logo-blue.svg\" alt=\"DeepL Logo\" /> **[DeepL](https://github.com/DeepLcom/deepl-mcp-server)** - Translate or rewrite text with [DeepL](https://deepl.com)'s very own AI models using [the DeepL API](https://developers.deepl.com/docs)\n- <img height=\"12\" width=\"12\" src=\"https://defang.io/_next/static/media/defang-icon-dark-colour.25f95b77.svg\" alt=\"Defang Logo\" /> **[Defang](https://github.com/DefangLabs/defang/blob/main/src/pkg/mcp/README.md)** - Deploy your project to the cloud seamlessly with the [Defang](https://www.defang.io) platform without leaving your integrated development environment\n- <img height=\"12\" width=\"12\" src=\"https://detailer.ginylil.com/favicon.ico\" alt=\"Detailer Logo\" /> **[Detailer](https://detailer.ginylil.com/)** – Instantly generate rich, AI-powered documentation for your GitHub repositories. Designed for AI agents to gain deep project context before taking action.\n- <img height=\"12\" width=\"12\" src=\"https://devcycle.com/_next/image?url=%2Fassets%2Fbrand%2FColor-logo-mark.png&w=384&q=75\" alt=\"DevCycle Logo\" /> **[DevCycle](https://docs.devcycle.com/cli-mcp/mcp-getting-started)** - Create and monitor feature flags using natural language in your AI coding assistant.\n- <img height=\"12\" width=\"12\" src=\"https://www.devhub.com/img/upload/favicon-196x196-dh.png\" alt=\"DevHub Logo\" /> **[DevHub](https://github.com/devhub/devhub-cms-mcp)** - Manage and utilize website content within the [DevHub](https://www.devhub.com) CMS platform\n- <img height=\"12\" width=\"12\" src=\"https://devrev.ai/favicon.ico\" alt=\"DevRev Logo\" /> **[DevRev](https://github.com/devrev/mcp-server)** - An MCP server to integrate with DevRev APIs to search through your DevRev Knowledge Graph where objects can be imported from diff. Sources listed [here](https://devrev.ai/docs/import#available-sources).\n- <img height=\"12\" width=\"12\" src=\"https://dexpaprika.com/favicon.ico\" alt=\"DexPaprika Logo\" /> **[DexPaprika (CoinPaprika)](https://github.com/coinpaprika/dexpaprika-mcp)** - Access real-time DEX data, liquidity pools, token information, and trading analytics across multiple blockchain networks with [DexPaprika](https://dexpaprika.com) by CoinPaprika.\n- <img height=\"12\" width=\"12\" src=\"https://github.com/dolthub/dolt/raw/main/images/Dolt-Logo@3x.svg\" alt=\"Dolt Logo\" /> **[Dolt](https://github.com/dolthub/dolt-mcp)** - The official MCP server for version-controlled [Dolt](https://doltdb.com/) databases.\n- <img height=\"12\" width=\"12\" src=\"https://eu.getdot.ai/favicon.ico\" alt=\"GetDot.ai Logo\" /> **[Dot (GetDot.ai)](https://docs.getdot.ai/dot/integrations/mcp)** - Fetch, analyze or visualize data from your favorite database or data warehouse (Snowflake, BigQuery, Redshift, Databricks, Clickhouse, ...) with [Dot](https://getdot.ai), your AI Data Analyst. This remote MCP server is a one-click integration for user that have setup Dot.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/65421071?s=200&v=4\" alt=\"Drata Logo\" /> **[Drata](https://drata.com/mcp)** - Get hands-on with our experimental MCP server—bringing real-time compliance intelligence into your AI workflows.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/204530939?s=200&v=4\" alt=\"Dumpling AI Logo\" /> **[Dumpling AI](https://github.com/Dumpling-AI/mcp-server-dumplingai)** - Access data, web scraping, and document conversion APIs by [Dumpling AI](https://www.dumplingai.com/)\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/58178984\" alt=\"Dynatrace Logo\" /> **[Dynatrace](https://github.com/dynatrace-oss/dynatrace-mcp)** - Manage and interact with the [Dynatrace Platform ](https://www.dynatrace.com/platform) for real-time observability and monitoring.\n- <img height=\"12\" width=\"12\" src=\"https://e2b.dev/favicon.ico\" alt=\"E2B Logo\" /> **[E2B](https://github.com/e2b-dev/mcp-server)** - Run code in secure sandboxes hosted by [E2B](https://e2b.dev)\n- <img height=\"12\" width=\"12\" src=\"https://www.edgee.cloud/favicon.ico\" alt=\"Edgee Logo\" /> **[Edgee](https://github.com/edgee-cloud/mcp-server-edgee)** - Deploy and manage [Edgee](https://www.edgee.cloud) components and projects\n- <img height=\"12\" width=\"12\" src=\"https://static.edubase.net/media/brand/favicon/favicon-32x32.png\" alt=\"EduBase Logo\" /> **[EduBase](https://github.com/EduBase/MCP)** - Interact with [EduBase](https://www.edubase.net), a comprehensive e-learning platform with advanced quizzing, exam management, and content organization capabilities\n- <img height=\"12\" width=\"12\" src=\"https://www.elastic.co/favicon.ico\" alt=\"Elasticsearch Logo\" /> **[Elasticsearch](https://github.com/elastic/mcp-server-elasticsearch)** - Query your data in [Elasticsearch](https://www.elastic.co/elasticsearch)\n- <img height=\"12\" width=\"12\" src=\"https://github.com/EmberAGI/arbitrum-vibekit/blob/main/img/Ember%20Black.png?raw=true\" alt=\"Ember AI Logo\" /> **[Ember AI](https://docs.emberai.xyz/)** - A unified MCP server that enables AI agents to execute cross-chain DeFi strategies.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/656eaf5c6da3527caf362363/656ecc07555afac40df4c40e_Facicon.png\" alt=\"Endor Labs Logo\" /> **[Endor Labs](https://docs.endorlabs.com/deployment/ide/mcp/)** - Find and fix security risks in you code. Integrate [Endor Labs](https://endorlabs.com) to scan and secure your code from vulnerabilities and secret leaks.\n- <img height=\"12\" width=\"12\" src=\"https://esignatures.com/favicon.ico\" alt=\"eSignatures Logo\" /> **[eSignatures](https://github.com/esignaturescom/mcp-server-esignatures)** - Contract and template management for drafting, reviewing, and sending binding contracts.\n- <img height=\"12\" width=\"12\" src=\"https://rainmaker.espressif.com/favicon.ico\" alt=\"ESP RainMaker Logo\" /> **[ESP RainMaker](https://github.com/espressif/esp-rainmaker-mcp)** - Official Espressif MCP Server to Control and Manage ESP RainMaker Devices.\n- <img height=\"12\" width=\"12\" src=\"https://exa.ai/images/favicon-32x32.png\" alt=\"Exa Logo\" /> **[Exa](https://github.com/exa-labs/exa-mcp-server)** - Search Engine made for AIs by [Exa](https://exa.ai)\n- <img height=\"12\" width=\"12\" src=\"https://www.explorium.ai/wp-content/uploads/2025/04/Favicon-Purple-512x512-1-150x150.png\" alt=\"Explorium Logo\" /> **[Explorium](https://github.com/explorium-ai/mcp-explorium)** - B2B data and infrastructure for AI SDR & GTM Agents [Explorium](https://www.explorium.ai)\n- **[FalkorDB](https://github.com/FalkorDB/FalkorDB-MCPServer)** - FalkorDB graph database server get schema and read/write-cypher [FalkorDB](https://www.falkordb.com)\n- <img height=\"12\" width=\"12\" src=\"https://fetchserp.com/icon.png\" alt=\"fetchSERP Logo\" /> **[fetchSERP](https://github.com/fetchSERP/fetchserp-mcp-server-node)** - All-in-One SEO & Web Intelligence Toolkit API [fetchSERP](https://www.fetchserp.com/)\n- <img height=\"12\" width=\"12\" src=\"https://fewsats.com/favicon.svg\" alt=\"Fewsats Logo\" /> **[Fewsats](https://github.com/Fewsats/fewsats-mcp)** - Enable AI Agents to purchase anything in a secure way using [Fewsats](https://fewsats.com)\n- <img height=\"12\" width=\"12\" src=\"https://fibery.io/favicon.svg\" alt=\"Fibery Logo\" /> **[Fibery](https://github.com/Fibery-inc/fibery-mcp-server)** - Perform queries and entity operations in your [Fibery](https://fibery.io) workspace.\n- <img height=\"12\" width=\"12\" src=\"https://financialdatasets.ai/favicon.ico\" alt=\"Financial Datasets Logo\" /> **[Financial Datasets](https://github.com/financial-datasets/mcp-server)** - Stock market API made for AI agents\n- <img height=\"12\" width=\"12\" src=\"https://www.gstatic.com/devrel-devsite/prod/v7aeef7f1393bb1d75a4489145c511cdd5aeaa8e13ad0a83ec1b5b03612e66330/firebase/images/favicon.png\" alt=\"Firebase Logo\" /> **[Firebase](https://github.com/firebase/firebase-tools/blob/master/src/mcp)** - Firebase's experimental [MCP Server](https://firebase.google.com/docs/cli/mcp-server) to power your AI Tools\n- <img height=\"12\" width=\"12\" src=\"https://firecrawl.dev/favicon.ico\" alt=\"Firecrawl Logo\" /> **[Firecrawl](https://github.com/firecrawl/firecrawl-mcp-server)** - Extract web data with [Firecrawl](https://firecrawl.dev)\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/100200663?s=200&v=4\" alt=\"Firefly Logo\" /> **[Firefly](https://github.com/gofireflyio/firefly-mcp)** - Integrates, discovers, manages, and codifies cloud resources with [Firefly](https://firefly.ai).\n- <img height=\"12\" width=\"12\" src=\"https://fireproof.storage/favicon.ico\" alt=\"Fireproof Logo\" /> **[Fireproof](https://github.com/fireproof-storage/mcp-database-server)** - Immutable ledger database with live synchronization\n- <img height=\"12\" width=\"12\" src=\"https://fixparser.dev/favicon.ico\" alt=\"FIXParser Logo\" /> **[FIXParser](https://gitlab.com/logotype/fixparser/-/tree/main/packages/fixparser-plugin-mcp)** - A modern FIX Protocol engine for AI-powered trading agents\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/52471808\" alt=\"Fluid Attacks Logo\" /> **[Fluid Attacks](https://github.com/fluidattacks/mcp)** - Interact with the [Fluid Attacks](https://fluidattacks.com/) API, enabling vulnerability management, organization insights, and GraphQL query execution.\n- <img height=\"12\" width=\"12\" src=\"https://forevervm.com/icon.png\" alt=\"ForeverVM Logo\" /> **[ForeverVM](https://github.com/jamsocket/forevervm/tree/main/javascript/mcp-server)** - Run Python in a code sandbox.\n- <img height=\"12\" width=\"12\" src=\"https://flutterwave.com/favicon.ico\" alt=\"Flutterwave Logo\" /> **[Flutterwave](https://github.com/bajoski34/mcp-flutterwave/tree/main)** - Interact with Flutterwave payment solutions API, to manage transactions, payment links and more.\n- <img height=\"12\" width=\"12\" src=\"https://app.gibsonai.com/favicon.ico\" alt=\"GibsonAI Logo\" /> **[GibsonAI](https://github.com/GibsonAI/mcp)** - AI-Powered Cloud databases: Build, migrate, and deploy database instances with AI\n- <img height=\"12\" width=\"12\" src=\"https://gcore.com/assets/favicon/favicon-16x16.png\" alt=\"Gcore Logo\" /> **[Gcore](https://github.com/G-Core/gcore-mcp-server)** - Interact with Gcore platform services via LLM assistants, providing unified access to CDN, GPU Cloud & AI Inference, Video Streaming, WAAP, and cloud resources including instances and networks.\n- <img height=\"12\" width=\"12\" src=\"https://gitea.com/assets/img/favicon.svg\" alt=\"Gitea Logo\" /> **[Gitea](https://gitea.com/gitea/gitea-mcp)** - Interact with Gitea instances with MCP.\n- <img height=\"12\" width=\"12\" src=\"https://gitee.com/favicon.ico\" alt=\"Gitee Logo\" /> **[Gitee](https://github.com/oschina/mcp-gitee)** - Gitee API integration, repository, issue, and pull request management, and more.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/5ee25cbe47310017adf964da/6323888a9b9f4e22a7bc766b_GG%20Favicon.svg\" alt=\"GitGuardian Logo\" /> **[GitGuardian](https://github.com/GitGuardian/gg-mcp)** - GitGuardian official MCP server - Scan projects using GitGuardian's industry-leading API, which features over 500 secret detectors to prevent credential leaks before they reach public repositories. Resolve security incidents directly with rich contextual data for rapid, automated remediation.\n- <img height=\"12\" width=\"12\" src=\"https://gitlab.com/favicon.ico\" alt=\"GitLab Logo\" /> **[GitLab](https://docs.gitlab.com/user/gitlab_duo/model_context_protocol/mcp_server/)** - GitLab's official MCP server enabling AI tools to securely access GitLab project data, manage issues, and perform repository operations via OAuth 2.0.\n- <img height=\"12\" width=\"12\" src=\"https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png\" alt=\"GitHub Logo\" /> **[GitHub](https://github.com/github/github-mcp-server)** - GitHub's official MCP Server.\n- <img height=\"12\" width=\"12\" src=\"https://www.gitkraken.com/wp-content/uploads/2021/03/android-chrome-144x144-1.png\" alt=\"GitKraken Logo\" /> **[GitKraken](https://github.com/gitkraken/gk-cli?tab=readme-ov-file#mcp-server)** - A CLI for interacting with GitKraken APIs. Includes an MCP server via `gk mcp` that not only wraps GitKraken APIs, but also Jira, GitHub, GitLab, and more.\n- <img height=\"12\" width=\"12\" src=\"https://app.glean.com/images/favicon3-196x196.png\" alt=\"Glean Logo\" /> **[Glean](https://github.com/gleanwork/mcp-server)** - Enterprise search and chat using Glean's API.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.jsdelivr.net/gh/jsdelivr/globalping-media@refs/heads/master/icons/android-chrome-192x192.png\" alt=\"Globalping Logo\" /> **[Globalping](https://github.com/jsdelivr/globalping-mcp-server)** - Access a network of thousands of probes to run network commands like ping, traceroute, mtr, http and DNS resolve.\n- <img height=\"12\" width=\"12\" src=\"https://gnucleus.ai/favicon.ico\" alt=\"gNucleus Logo\" /> **[gNucleus Text-To-CAD](https://github.com/gNucleus/text-to-cad-mcp)** - Generate CAD parts and assemblies from text using gNucleus AI models.\n- <img height=\"12\" width=\"12\" src=\"https://www.gstatic.com/cgc/favicon.ico\" alt=\"Google Cloud Logo\" /> **[Google Cloud Run](https://github.com/GoogleCloudPlatform/cloud-run-mcp)** - Deploy code to Google Cloud Run\n- <img height=\"12\" width=\"12\" src=\"https://api.gologin.com/favicon.ico\" alt=\"GoLogin Logo\" /> **[GoLogin MCP server](https://github.com/gologinapp/gologin-mcp)** - Manage your GoLogin browser profiles and automation directly through AI conversations!\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/3717923?s=200&v=4\" alt=\"Google Maps Platform Logo\" /> **[Google Maps Platform Code Assist](https://github.com/googlemaps/platform-ai/tree/main/packages/code-assist)** - Ground agents on fresh, official documentation and code samples for optimal geo-related guidance and code..\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/6605a2979ff17b2cd1939cd4/6605a460de47e7596ed84f06_icon256.png\" alt=\"gotoHuman Logo\" /> **[gotoHuman](https://github.com/gotohuman/gotohuman-mcp-server)** - Human-in-the-loop platform - Allow AI agents and automations to send requests for approval to your [gotoHuman](https://www.gotohuman.com) inbox.\n- <img height=\"12\" width=\"12\" src=\"https://grafana.com/favicon.ico\" alt=\"Grafana Logo\" /> **[Grafana](https://github.com/grafana/mcp-grafana)** - Search dashboards, investigate incidents and query datasources in your Grafana instance\n- <img height=\"12\" width=\"12\" src=\"https://grafbase.com/favicon.ico\" alt=\"Grafbase Logo\" /> **[Grafbase](https://github.com/grafbase/grafbase/tree/main/crates/mcp)** - Turn your GraphQL API into an efficient MCP server with schema intelligence in a single command.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/5f5e90c17e7c9eb95c7acb17/61d3457a519242f2c75c725c_favicon.png\" alt=\"Grain Logo\" /> **[Grain](https://grain.com/release-note/06-18-2025)** - Access your Grain meetings notes & transcripts directly in claude and generate reports with native Claude Prompts.\n- <img height=\"12\" width=\"12\" src=\"https://framerusercontent.com/images/KCOWBYLKunDff1Dr452y6EfjiU.png\" alt=\"Graphlit Logo\" /> **[Graphlit](https://github.com/graphlit/graphlit-mcp-server)** - Ingest anything from Slack to Gmail to podcast feeds, in addition to web crawling, into a searchable [Graphlit](https://www.graphlit.com) project.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/64a5291e7847ac04fe1531ad/64a529af2f1fc7debc26f2a6_favicon-32x32.avif\" alt=\"Gremlin favicon\" /> **[Gremlin](https://github.com/gremlin/mcp)** - The official [Gremlin](https://www.gremlin.com) MCP server. Analyze your reliability posture, review recent tests and chaos engineering experiments, and create detailed reports.\n- <img height=\"12\" width=\"12\" src=\"https://greptime.com/favicon.ico\" alt=\"Greptime Logo\" /> **[GreptimeDB](https://github.com/GreptimeTeam/greptimedb-mcp-server)** - Provides AI assistants with a secure and structured way to explore and analyze data in [GreptimeDB](https://github.com/GreptimeTeam/greptimedb).\n- <img height=\"12\" width=\"12\" src=\"https://growi.org/assets/images/favicon.ico\" alt=\"GROWI Logo\" /> **[GROWI](https://github.com/growilabs/growi-mcp-server)** - Official MCP Server to integrate with GROWI APIs.\n- <img height=\"12\" width=\"12\" src=\"https://gyazo.com/favicon.ico\" alt=\"Gyazo Logo\" /> **[Gyazo](https://github.com/nota/gyazo-mcp-server)** - Search, fetch, upload, and interact with Gyazo images, including metadata and OCR data.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/6374050260446c42f94dc90f/63d828be3e13d32ee6973f35_favicon-32x32.png\" alt=\"Harper Logo\" /> **[Harper](https://github.com/HarperDB/mcp-server)** - An MCP server providing an interface for MCP clients to access data within [Harper](https://www.harpersystems.dev/).\n- <img height=\"12\" width=\"12\" src=\"https://www.herokucdn.com/favicons/favicon.ico\" alt=\"Heroku Logo\" /> **[Heroku](https://github.com/heroku/heroku-mcp-server)** - Interact with the Heroku Platform through LLM-driven tools for managing apps, add-ons, dynos, databases, and more.\n- <img height=\"12\" width=\"12\" src=\"https://heyoncall.com/favicon.ico\" alt=\"HeyOnCall Logo\" /> **[HeyOnCall](https://heyoncall.com/blog/mcp-server-for-paging-a-human)** - Page a human, sending critical or non-critical alerts to the free [HeyOnCall](https://heyoncall.com/) iOS or Android apps.\n- <img height=\"12\" width=\"12\" src=\"https://www.hiveflow.ai/favicon.ico\" alt=\"Hiveflow Logo\" /> **[Hiveflow](https://github.com/hiveflowai/hiveflow-mcp-server)** - Create, manage, and execute agentic AI workflows directly from your assistant.\n- <img height=\"12\" width=\"12\" src=\"https://hiveintelligence.xyz/favicon.ico\" alt=\"Hive Intelligence Logo\" /> **[Hive Intelligence](https://github.com/hive-intel/hive-crypto-mcp)** - Ultimate cryptocurrency MCP for AI assistants with unified access to crypto, DeFi, and Web3 analytics\n- <img height=\"12\" width=\"12\" src=\"https://img.alicdn.com/imgextra/i3/O1CN01d9qrry1i6lTNa2BRa_!!6000000004364-2-tps-218-200.png\" alt=\"Hologres Logo\" /> **[Hologres](https://github.com/aliyun/alibabacloud-hologres-mcp-server)** - Connect to a [Hologres](https://www.alibabacloud.com/en/product/hologres) instance, get table metadata, query and analyze data.\n- <img height=\"12\" width=\"12\" src=\"https://brew.sh/assets/img/favicon.ico\" alt=\"Homebrew Logo\" /> **[Homebrew](https://docs.brew.sh/MCP-Server)** Allows [Homebrew](https://brew.sh) users to run Homebrew commands locally.\n- <img height=\"12\" width=\"12\" src=\"https://www.honeycomb.io/favicon.ico\" alt=\"Honeycomb Logo\" /> **[Honeycomb](https://github.com/honeycombio/honeycomb-mcp)** Allows [Honeycomb](https://www.honeycomb.io/) Enterprise customers to query and analyze their data, alerts, dashboards, and more; and cross-reference production behavior with the codebase.\n- <img height=\"12\" width=\"12\" src=\"https://static.hsinfrastatic.net/StyleGuideUI/static-3.438/img/sprocket/favicon-32x32.png\" alt=\"HubSpot Logo\" /> **[HubSpot](https://developer.hubspot.com/mcp)** - Connect, manage, and interact with [HubSpot](https://www.hubspot.com/) CRM data\n- <img height=\"12\" width=\"12\" src=\"https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo.svg\" alt=\"HuggingFace Logo\" /> **[Hugging Face](https://huggingface.co/settings/mcp)** - Connect to the Hugging Face Hub APIs programmatically: semantic search for spaces and papers, exploration of datasets and models, and access to all compatible MCP Gradio tool spaces!\n- <img height=\"12\" width=\"12\" src=\"https://hunter.io/favicon.ico\" alt=\"Hunter Logo\" /> **[Hunter](https://github.com/hunter-io/hunter-mcp)** - Interact with the [Hunter API](https://hunter.io) to get B2B data using natural language.\n- <img height=\"12\" width=\"12\" src=\"https://app.hyperbolic.xyz/hyperbolic-logo.svg\" alt=\"Hyperbolic Labs Logo\" /> **[Hyperbolic](https://github.com/HyperbolicLabs/hyperbolic-mcp)** - Interact with Hyperbolic's GPU cloud, enabling agents and LLMs to view and rent available GPUs, SSH into them, and run GPU-powered workloads for you.\n- <img height=\"12\" width=\"12\" src=\"https://hyperbrowser-assets-bucket.s3.us-east-1.amazonaws.com/Hyperbrowser-logo.png\" alt=\"Hyperbrowsers23 Logo\" /> **[Hyperbrowser](https://github.com/hyperbrowserai/mcp)** - [Hyperbrowser](https://www.hyperbrowser.ai/) is the next-generation platform empowering AI agents and enabling effortless, scalable browser automation.\n- **[IBM wxflows](https://github.com/IBM/wxflows/tree/main/examples/mcp/javascript)** - Tool platform by IBM to build, test and deploy tools for any data source\n- <img height=\"12\" width=\"12\" src=\"https://www.getinboxzero.com/icon.png\" alt=\"Inbox Zero Logo\" /> **[Inbox Zero](https://github.com/elie222/inbox-zero/tree/main/apps/mcp-server)** - AI personal assistant for email [Inbox Zero](https://www.getinboxzero.com)\n- <img height=\"12\" width=\"12\" src=\"https://www.inflectra.com/Favicon.ico\" alt=\"Inflectra Logo\" /> **[Inflectra Spira](https://github.com/Inflectra/mcp-server-spira)** - Connect to your instance of the SpiraTest, SpiraTeam or SpiraPlan application lifecycle management platform by [Inflectra](https://www.inflectra.com)\n-  **[Inkeep](https://github.com/inkeep/mcp-server-python)** - RAG Search over your content powered by [Inkeep](https://inkeep.com)\n- <img height=\"12\" width=\"12\" src=\"https://integration.app/favicon.ico\" alt=\"Integration App Icon\" /> **[Integration App](https://github.com/integration-app/mcp-server)** - Interact with any other SaaS applications on behalf of your customers.\n- <img height=\"12\" width=\"12\" src=\"https://www.ip2location.io/favicon.ico\" alt=\"IP2Location.io Icon\" /> **[IP2Location.io](https://github.com/ip2location/mcp-ip2location-io)** - Interact with IP2Location.io API to retrieve the geolocation information for an IP address.\n- <img height=\"12\" width=\"12\" src=\"https://static.iplocate.io/custom/logo-square-rounded.png\" alt=\"IPLocate Icon\" /> **[IPLocate](https://github.com/iplocate/mcp-server-iplocate)** - Look up IP address geolocation, network information, detect proxies and VPNs, and find abuse contact details using [IPLocate.io](https://www.iplocate.io)\n- <img height=\"12\" width=\"12\" src=\"https://jellyfish.co/favicon.ico\" alt=\"Jellyfish Logo\" /> **[Jellyfish](https://github.com/Jellyfish-AI/jellyfish-mcp)** – Give your AI agent context about your team's software engineering allocations and workflow via the [Jellyfish](https://jellyfish.co) platform\n- <img height=\"12\" width=\"12\" src=\"https://cdn.simpleicons.org/jetbrains\" /> **[JetBrains](https://www.jetbrains.com/help/idea/mcp-server.html)** – Work on your code with JetBrains IDEs: IntelliJ IDEA, PhpStorm, etc.\n- <img height=\"12\" width=\"12\" src=\"https://speedmedia.jfrog.com/08612fe1-9391-4cf3-ac1a-6dd49c36b276/media.jfrog.com/wp-content/uploads/2019/04/20131046/Jfrog16-1.png\" alt=\"JFrog Logo\" /> **[JFrog](https://github.com/jfrog/mcp-jfrog)** - Model Context Protocol (MCP) Server for the [JFrog](https://jfrog.com/) Platform API, enabling repository management, build tracking, release lifecycle management, and more.\n- <img height=\"12\" width=\"12\" src=\"https://jenkins.io/images/logos/jenkins/jenkins.svg\" alt=\"Jenkins Logo\" /> **[Jenkins](https://plugins.jenkins.io/mcp-server/)** - Official Jenkins MCP Server plugin enabling AI assistants to manage builds, check job statuses, retrieve logs, and integrate with CI/CD pipelines through standardized MCP interface.\n- <img height=\"12\" width=\"12\" src=\"https://kagi.com/favicon.ico\" alt=\"Kagi Logo\" /> **[Kagi Search](https://github.com/kagisearch/kagimcp)** - Search the web using Kagi's search API\n- <img height=\"12\" width=\"12\" src=\"https://connection.keboola.com/favicon.ico\" alt=\"Keboola Logo\" /> **[Keboola](https://github.com/keboola/keboola-mcp-server)** - Build robust data workflows, integrations, and analytics on a single intuitive platform.\n- <img height=\"12\" width=\"12\" src=\"https://mcp.onkernel.com/favicon.svg\" alt=\"Kernel Logo\" /> **[Kernel](https://github.com/onkernel/kernel-mcp-server)** – Access Kernel's cloud‑based browsers via MCP.\n- <img height=\"12\" width=\"12\" src=\"https://keywordseverywhere.com/favicon.ico\" alt=\"Keywords Everywhere Logo\" /> **[Keywords Everywhere](https://api.keywordseverywhere.com/docs/#/mcp_integration)** – Access SEO data through the official Keywords Everywhere API MCP server.\n- <img height=\"12\" width=\"12\" src=\"https://keywordspeopleuse.com/favicon.ico\" alt=\"KeywordsPeopleUse Logo\" /> **[KeywordsPeopleUse.com](https://github.com/data-skunks/kpu-mcp)** - Find questions people ask online with [KeywordsPeopleUse](https://keywordspeopleuse.com).\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/4815054\" alt=\"Kintone Logo\" /> **[Kintone](https://github.com/kintone/mcp-server)** - The official local MCP server for [Kintone](https://kintone.com).\n- <img height=\"12\" width=\"12\" src=\"https://kirokuforms.com/favicon.svg\" alt=\"KirokuForms Logo\" /> **[KirokuForms](https://www.kirokuforms.com/ai/mcp)** - [KirokuForms](https://www.kirokuforms.com) is an AI-powered form platform combining professional form building with Human-in-the-Loop (HITL) capabilities. Create custom forms, collect submissions, and integrate human oversight into AI workflows through [MCP integration](https://kirokuforms.com/ai/mcp).\n- <img height=\"12\" width=\"12\" src=\"https://raw.githubusercontent.com/klavis-ai/klavis/main/static/klavis-ai.png\" alt=\"Klavis Logo\" /> **[Klavis ReportGen](https://github.com/Klavis-AI/klavis/tree/main/mcp_servers/report_generation)** - Create professional reports from a simple user query.\n- <img height=\"12\" width=\"12\" src=\"https://www.klaviyo.com/media/Favicon-16by16.png\" alt=\"Klaviyo Logo\" /> **[Klaviyo](https://developers.klaviyo.com/en/docs/klaviyo_mcp_server)** - Interact with your [Klaviyo](https://www.klaviyo.com/) marketing data.\n- <img height=\"12\" width=\"12\" src=\"https://platform.kluster.ai/logo-light.svg\" alt=\"kluster.ai Logo\" /> **[kluster.ai](https://docs.kluster.ai/get-started/mcp/overview/)** - kluster.ai provides MCP servers that bring AI services directly into your development workflow, including guardrails like hallucination detection.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/6347ea26001f0287c592ff91/649953ef7a9ffe1f3e492b5a_Knit%20Logo.svg\" alt=\"Knit Logo\" /> **[Knit MCP Server](https://developers.getknit.dev/docs/knit-mcp-server-getting-started)** - Production-ready remote MCP servers that enable you to connect with 10000+ tools across CRM, HRIS, Payroll, Accounting, ERP, Calendar, Expense Management, and Chat categories.\n- <img height=\"12\" width=\"12\" src=\"https://knock.app/favicon/favicon-dark.svg\" alt=\"Knock Logo\" /> **[Knock MCP Server](https://github.com/knocklabs/agent-toolkit#model-context-protocol-mcp)** - Send product and customer messaging across email, in-app, push, SMS, Slack, MS Teams.\n- <img height=\"12\" width=\"12\" src=\"https://kumo-sdk-public.s3.us-west-2.amazonaws.com/rfm-colabs/kumo_ai_logo.jpeg\" alt=\"Kumo Logo\" /> **[Kumo](https://github.com/kumo-ai/kumo-rfm-mcp)** - MCP Server to interact with KumoRFM, a foundation model for generating predictions from your relational data.\n- <img height=\"12\" width=\"12\" src=\"https://www.kurrent.io/favicon.ico\" alt=\"Kurrent Logo\" /> **[KurrentDB](https://github.com/kurrent-io/mcp-server)** - This is a simple MCP server to help you explore data and prototype projections faster on top of KurrentDB.\n- <img height=\"12\" width=\"12\" src=\"https://kuzudb.com/favicon.ico\" alt=\"Kuzu Logo\" /> **[Kuzu](https://github.com/kuzudb/kuzu-mcp-server)** - This server enables LLMs to inspect database schemas and execute queries on the provided Kuzu graph database. See [blog](https://blog.kuzudb.com/post/2025-03-23-kuzu-mcp-server/)) for a debugging use case.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/187484914\" alt=\"KWDB Logo\" /> **[KWDB](https://github.com/KWDB/kwdb-mcp-server)** - Reading, writing, querying, modifying data, and performing DDL operations with data in your KWDB Database.\n- <img height=\"12\" width=\"12\" src=\"https://labelstud.io/favicon-16x16.png\" alt=\"Label Studio Logo\" /> **[Label Studio](https://github.com/HumanSignal/label-studio-mcp-server)** - Open Source data labeling platform.\n- <img src=\"https://avatars.githubusercontent.com/u/188884511?s=48&v=4\" alt=\"Lambda Capture\" width=\"12\" height=\"12\"> **[Lambda Capture](https://github.com/lambda-capture/mcp-server)** - Macroeconomic Forecasts & Semantic Context from Federal Reserve, Bank of England, ECB.\n- <img src=\"https://www.lambdatest.com/resources/images/header/professional-service.svg\" alt=\"LambdaTest MCP server\" width=\"12\" height=\"12\"> **[LambdaTest](https://www.lambdatest.com/mcp)** - LambdaTest MCP Servers ranging from Accessibility, SmartUI, Automation, and HyperExecute allows you to connect AI assistants with your testing workflow, streamlining setup, analyzing failures, and generating fixes to speed up testing and improve efficiency.\n- <img height=\"12\" width=\"12\" src=\"https://langfuse.com/favicon.ico\" alt=\"Langfuse Logo\" /> **[Langfuse Prompt Management](https://github.com/langfuse/mcp-server-langfuse)** - Open-source tool for collaborative editing, versioning, evaluating, and releasing prompts.\n- <img height=\"12\" width=\"12\" src=\"https://laratranslate.com/favicon.ico\" alt=\"Lara Translate Logo\" /> **[Lara Translate](https://github.com/translated/lara-mcp)** - MCP Server for Lara Translate API, enabling powerful translation capabilities with support for language detection and context-aware translations.\n- <img height=\"12\" width=\"12\" src=\"https://last9.io/favicon.png\" alt=\"Last9 Logo\" /> **[Last9](https://github.com/last9/last9-mcp-server)** - Seamlessly bring real-time production context—logs, metrics, and traces—into your local environment to auto-fix code faster.\n- <img height=\"12\" width=\"12\" src=\"https://www.launchdarkly.com/favicon.ico\" alt=\"LaunchDarkly Logo\" /> **[LaunchDarkly](https://github.com/launchdarkly/mcp-server)** - LaunchDarkly is a continuous delivery platform that provides feature flags as a service and allows developers to iterate quickly and safely.\n- <img height=\"12\" width=\"12\" src=\"https://www.line.me/favicon-32x32.png\" alt=\"LINE Logo\" /> **[LINE](https://github.com/line/line-bot-mcp-server)** - Integrates the LINE Messaging API to connect an AI Agent to the LINE Official Account.\n- <img height=\"12\" width=\"12\" src=\"https://linear.app/favicon.ico\" alt=\"Linear Logo\" /> **[Linear](https://linear.app/docs/mcp)** - Search, create, and update Linear issues, projects, and comments.\n- <img height=\"12\" width=\"12\" src=\"https://lingo.dev/favicon.ico\" alt=\"Lingo.dev Logo\" /> **[Lingo.dev](https://github.com/lingodotdev/lingo.dev/blob/main/mcp.md)** - Make your AI agent speak every language on the planet, using [Lingo.dev](https://lingo.dev) Localization Engine.\n- <img height=\"12\" width=\"12\" src=\"https://ligo.ertiqah.com/favicon.avif\" alt=\"LiGo Logo\" /> **[LinkedIn MCP Runner](https://github.com/ertiqah/linkedin-mcp-runner)** - Write, edit, and schedule LinkedIn posts right from ChatGPT and Claude with [LiGo](https://ligo.ertiqah.com/).\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/175112039?s=200&v=4\" alt=\"Linkup Logo\" /> **[Linkup](https://github.com/LinkupPlatform/js-mcp-server)** - (JS version) MCP server that provides web search capabilities through Linkup's advanced search API. This server enables AI assistants and development tools to perform intelligent web searches with natural language queries.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/175112039?s=200&v=4\" alt=\"Linkup Logo\" /> **[Linkup](https://github.com/LinkupPlatform/python-mcp-server)** - (Python version) MCP server that provides web search capabilities through Linkup's advanced search API. This server enables AI assistants and development tools to perform intelligent web searches with natural language queries.\n- <img src=\"https://avatars.githubusercontent.com/u/149083471\" alt=\"Lippia.io\" width=\"12\" height=\"12\"> **[Lippia](https://github.com/Lippia-io/Lippia-MCP-Server/blob/main/getting-started.md)** - MCP Server to accelerate Test Automation using Lippia Framework.\n- <img src=\"https://gornschool.com/gorn.png\" alt=\"Lisply\" width=\"12\" height=\"12\"> **[Lisply](https://github.com/gornskew/lisply-mcp)** - Flexible frontend for compliant Lisp-speaking backends.\n- <img height=\"12\" width=\"12\" src=\"https://litmus.io/favicon.ico\" alt=\"Litmus.io Logo\" /> **[Litmus.io](https://github.com/litmusautomation/litmus-mcp-server)** - Official MCP server for configuring [Litmus](https://litmus.io) Edge for Industrial Data Collection, Edge Analytics & Industrial AI.\n- <img height=\"12\" width=\"12\" src=\"https://liveblocks.io/favicon.ico\" alt=\"Liveblocks Logo\" /> **[Liveblocks](https://github.com/liveblocks/liveblocks-mcp-server)** - Ready‑made features for AI & human collaboration—use this to develop your [Liveblocks](https://liveblocks.io) app quicker.\n- <img height=\"12\" width=\"12\" src=\"https://logfire.pydantic.dev/favicon.ico\" alt=\"Logfire Logo\" /> **[Logfire](https://github.com/pydantic/logfire-mcp)** - Provides access to OpenTelemetry traces and metrics through Logfire.\n- <img height=\"12\" width=\"12\" src=\"https://make.magicmealkits.com/favicon.ico\" alt=\"Magic Meal Kits Logo\" /> **[Magic Meal Kits](https://github.com/pureugong/mmk-mcp)** - Unleash Make's Full Potential by [Magic Meal Kits](https://make.magicmealkits.com/)\n- <img height=\"12\" width=\"12\" src=\"https://www.mailgun.com/favicon.ico\" alt=\"Mailgun Logo\" /> **[Mailgun](https://github.com/mailgun/mailgun-mcp-server)** - Interact with Mailgun API.\n- <img height=\"12\" width=\"12\" src=\"https://www.mailjet.com/favicon.ico\" alt=\"Mailjet Logo\" /> **[Mailjet](https://github.com/mailgun/mailjet-mcp-server)** - Official MCP server which allows AI agents to interact with contact, campaign, segmentation, statistics, workflow (and more) APIs from [Sinch Mailjet](https://www.mailjet.com).\n- <img height=\"12\" width=\"12\" src=\"https://www.make.com/favicon.ico\" alt=\"Make Logo\" /> **[Make](https://github.com/integromat/make-mcp-server)** - Turn your [Make](https://www.make.com/) scenarios into callable tools for AI assistants.\n- <img height=\"12\" width=\"12\" src=\"https://static-assets.mapbox.com/branding/favicon/v1/favicon.ico\" alt=\"Mapbox Logo\" /> **[Mapbox](https://github.com/mapbox/mcp-server)** - Unlock geospatial intelligence through Mapbox APIs like geocoding, POI search, directions, isochrones and more.\n- <img height=\"12\" width=\"12\" src=\"https://www.mariadb.com/favicon.ico\" alt=\"MariaDB Logo\" /> **[MariaDB](https://github.com/mariadb/mcp)** - A standard interface for managing and querying MariaDB databases, supporting both standard SQL operations and advanced vector/embedding-based search.\n- <img height=\"14\" width=\"14\" src=\"https://raw.githubusercontent.com/rust-mcp-stack/mcp-discovery/refs/heads/main/docs/_media/mcp-discovery-logo.png\" alt=\"mcp-discovery logo\" /> **[MCP Discovery](https://github.com/rust-mcp-stack/mcp-discovery)** - A lightweight CLI tool built in Rust for discovering MCP server capabilities.\n- <img height=\"12\" width=\"12\" src=\"https://googleapis.github.io/genai-toolbox/favicons/favicon.ico\" alt=\"MCP Toolbox for Databases Logo\" /> **[MCP Toolbox for Databases](https://github.com/googleapis/genai-toolbox)** - Open source MCP server specializing in easy, fast, and secure tools for Databases. Supports  AlloyDB, BigQuery, Bigtable, Cloud SQL, Dgraph, Looker, MySQL, Neo4j, Postgres, Spanner, and more.\n- <img height=\"12\" width=\"12\" src=\"https://www.meilisearch.com/favicon.ico\" alt=\"Meilisearch Logo\" /> **[Meilisearch](https://github.com/meilisearch/meilisearch-mcp)** - Interact & query with Meilisearch (Full-text & semantic search API)\n- <img height=\"12\" width=\"12\" src=\"https://memgraph.com/favicon.png\" alt=\"Memgraph Logo\" /> **[Memgraph](https://github.com/memgraph/ai-toolkit/tree/main/integrations/mcp-memgraph)** - Query your data in [Memgraph](https://memgraph.com/) graph database.\n- <img height=\"12\" width=\"12\" src=\"https://www.mercadolibre.com.ar/favicon.ico\" alt=\"MercadoLibre Logo\" /> **[Mercado Libre](https://mcp.mercadolibre.com/)** - Mercado Libre's official MCP server.\n- <img height=\"12\" width=\"12\" src=\"https://www.mercadopago.com/favicon.ico\" alt=\"MercadoPago Logo\" /> **[Mercado Pago](https://mcp.mercadopago.com/)** - Mercado Pago's official MCP server.\n- <img height=\"12\" width=\"12\" src=\"https://metoro.io/static/images/logos/MetoroLogo.png\" alt=\"Metoro Logo\" /> **[Metoro](https://github.com/metoro-io/metoro-mcp-server)** - Query and interact with kubernetes environments monitored by Metoro\n- <img height=\"12\" width=\"12\" src=\"https://claritystatic.azureedge.net/images/logo.ico\" alt=\"Microsoft Clarity Logo\"/> **[Microsoft Clarity](https://github.com/microsoft/clarity-mcp-server)** - Official MCP Server to get your behavioral analytics data and insights from [Clarity](https://clarity.microsoft.com)\n- <img height=\"12\" width=\"12\" src=\"https://conn-afd-prod-endpoint-bmc9bqahasf3grgk.b01.azurefd.net/releases/v1.0.1735/1.0.1735.4099/commondataserviceforapps/icon.png\" alt=\"Microsoft Dataverse Logo\" /> **[Microsoft Dataverse](https://go.microsoft.com/fwlink/?linkid=2320176)** - Chat over your business data using NL - Discover tables, run queries, retrieve data, insert or update records, and execute custom prompts grounded in business knowledge and context.\n- <img height=\"12\" width=\"12\" src=\"https://learn.microsoft.com/favicon.ico\" alt=\"Microsoft Learn Logo\" /> **[Microsoft Learn Docs](https://github.com/microsoftdocs/mcp)** - An MCP server that provides structured access to Microsoft's official documentation. Retrieves accurate, authoritative, and context-aware technical content for code generation, question answering, and workflow grounding.\n- <img height=\"12\" width=\"12\" src=\"https://statics.teams.microsoft.com/hashedassets/favicon/prod/favicon-9f45b466.ico\" alt=\"Microsoft Teams Logo\" /> **[Microsoft Teams](https://devblogs.microsoft.com/microsoft365dev/announcing-the-updated-teams-ai-library-and-mcp-support/)** - Official Microsoft Teams AI Library with MCP support enabling advanced agent orchestration, multi-agent collaboration, and seamless integration with Teams messaging and collaboration features.\n- <img height=\"12\" width=\"12\" src=\"https://milvus.io/favicon-32x32.png\" /> **[Milvus](https://github.com/zilliztech/mcp-server-milvus)** - Search, Query and interact with data in your Milvus Vector Database.\n- <img src=\"https://www.mimilabs.ai/logos/mimilabsSquare.svg\" alt=\"mimilabs\" width=\"12\" height=\"12\"> **[mimilabs](https://www.mimilabs.ai/mcp)** - A US healthcare data discovery guide for 50+ gov sources and thousands of publicly available US healthcare datasets regarding gov-funded programs, policies, drug pricings, clinical trials, etc.\n- <img src=\"https://avatars.githubusercontent.com/u/94089762?s=48&v=4\" alt=\"Mobb\" width=\"12\" height=\"12\"> **[Mobb](https://github.com/mobb-dev/bugsy?tab=readme-ov-file#model-context-protocol-mcp-server)** - The [Mobb Vibe Shield](https://vibe.mobb.ai/) MCP server identifies and remediates vulnerabilities in both human and AI-written code, ensuring your applications remain secure without slowing development.\n- <img height=\"12\" width=\"12\" src=\"https://console.gomomento.com/favicon.ico\" /> **[Momento](https://github.com/momentohq/mcp-momento)** - Momento Cache lets you quickly improve your performance, reduce costs, and handle load at any scale.\n- <img height=\"12\" width=\"12\" src=\"https://www.monday.com/favicon.ico\" alt=\"Monday.com Logo\" /> **[Monday.com](https://github.com/mondaycom/mcp)** - Interact with Monday.com boards, items, accounts and work forms.\n- <img height=\"12\" width=\"12\" src=\"https://www.mongodb.com/favicon.ico\" /> **[MongoDB](https://github.com/mongodb-js/mongodb-mcp-server)** - Both MongoDB Community Server and MongoDB Atlas are supported.\n- <img height=\"12\" width=\"12\" src=\"https://moorcheh.ai/Moorcheh-mcp.ico\" alt=\"Moorcheh Logo\" /> **[Moorcheh](https://github.com/moorcheh-ai/moorcheh-mcp)** - Embed, store, and search your documents, and build secure chatbots and RAG systems with Moorcheh's information-theoretic semantic search engine\n- <img height=\"12\" width=\"12\" src=\"https://www.motherduck.com/favicon.ico\" alt=\"MotherDuck Logo\" /> **[MotherDuck](https://github.com/motherduckdb/mcp-server-motherduck)** - Query and analyze data with MotherDuck and local DuckDB\n- <img height=\"12\" width=\"12\" src=\"https://docs.mulesoft.com/_/img/favicon.ico\" alt=\"Mulesoft Logo\" /> **[Mulesoft](https://www.npmjs.com/package/@mulesoft/mcp-server)** - Build, deploy, and manage MuleSoft applications with natural language, directly inside any compatible IDE.\n- <img height=\"12\" width=\"12\" src=\"https://www.multiplayer.app/favicon-32x32.png\" alt=\"Multiplayer Logo\" /> **[Multiplayer](https://www.multiplayer.app/docs/ai/mcp-server)** - Analyze your full stack session recordings easily. Record a bug with Multiplayer, analyze and fix it with LLM\n-  **[Nango](https://docs.nango.dev/guides/use-cases/mcp-server)** - Integrate your AI agent with 500+ APIs: Auth, custom tools, and observability. Open-source.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/38020270\" alt=\"NanoVMs Logo\" /> **[NanoVMs](https://github.com/nanovms/ops-mcp)** - Easily Build and Deploy unikernels to any cloud.\n- <img height=\"12\" width=\"12\" src=\"https://needle-ai.com/images/needle-logo-orange-2-rounded.png\" alt=\"Needle AI Logo\" /> **[Needle](https://github.com/needle-ai/needle-mcp)** - Production-ready RAG out of the box to search and retrieve data from your own documents.\n- <img height=\"12\" width=\"12\" src=\"https://neo4j.com/favicon.ico\" alt=\"Neo4j Logo\" /> **[Neo4j](https://github.com/neo4j-contrib/mcp-neo4j/)** - Neo4j graph database server (schema + read/write-cypher) and separate graph database backed memory\n- <img height=\"12\" width=\"12\" src=\"https://knowall.ai/favicon.ico\" alt=\"Neo4j Agent Memory Logo\" /> **[Neo4j Agent Memory](https://github.com/knowall-ai/mcp-neo4j-agent-memory)** - Memory management for AI agents using Neo4j knowledge graphs\n- <img height=\"12\" width=\"12\" src=\"https://neo4j.com/favicon.ico\" alt=\"Neo4j Logo\" /> **[Neo4j GDS](https://github.com/neo4j-contrib/gds-agent)** - Neo4j graph data science server with comprehensive graph algorithms that enables complex graph reasoning and Q&A.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/183852044?s=48&v=4\" alt=\"Neon Logo\" /> **[Neon](https://github.com/neondatabase/mcp-server-neon)** - Interact with the Neon serverless Postgres platform\n- <img height=\"12\" width=\"12\" src=\"https://app.usenerve.com/favicon.ico\" alt=\"Nerve Logo\" /> **[Nerve](https://github.com/nerve-hq/nerve-mcp-server)** - Search and Act on all your company data across all your SaaS apps via [Nerve](https://www.usenerve.com/)\n- <img height=\"12\" width=\"12\" src=\"https://www.netdata.cloud/favicon-32x32.png\" alt=\"Netdata Logo\" /> **[Netdata](https://github.com/netdata/netdata/blob/master/src/web/mcp/README.md)** - Discovery, exploration, reporting and root cause analysis using all observability data, including metrics, logs, systems, containers, processes, and network connections\n- <img height=\"12\" width=\"12\" src=\"https://www.netlify.com/favicon/icon.svg\" alt=\"Netlify Logo\" /> **[Netlify](https://docs.netlify.com/welcome/build-with-ai/netlify-mcp-server/)** - Create, build, deploy, and manage your websites with Netlify web platform.\n- <img height=\"12\" width=\"12\" src=\"https://www.thenile.dev/favicon.ico\" alt=\"Nile Logo\" /> **[Nile](https://github.com/niledatabase/nile-mcp-server)** - An MCP server that talks to Nile - Postgres re-engineered for B2B apps. Manage and query databases, tenants, users, auth using LLMs\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/208441832?s=400&v=4\" alt=\"Nodit Logo\" /> **[Nodit](https://github.com/noditlabs/nodit-mcp-server)** - Official Nodit MCP Server enabling access to multi-chain RPC Nodes and Data APIs for blockchain data.\n- <img height=\"12\" width=\"12\" src=\"https://app.norman.finance/favicons/favicon-32x32.png\" alt=\"Norman Logo\" /> **[Norman Finance](https://github.com/norman-finance/norman-mcp-server)** - MCP server for managing accounting and taxes with Norman Finance.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/4792552?s=200&v=4\" alt=\"Notion Logo\" /> **[Notion](https://github.com/makenotion/notion-mcp-server#readme)** - This project implements an MCP server for the Notion API.\n-  **[Nutrient](https://github.com/PSPDFKit/nutrient-dws-mcp-server)** - Create, Edit, Sign, Extract Documents using Natural Language\n- <img height=\"12\" width=\"12\" src=\"https://nx.dev/favicon/favicon.svg\" alt=\"Nx Logo\" /> **[Nx](https://github.com/nrwl/nx-console/blob/master/apps/nx-mcp)** - Makes [Nx's understanding](https://nx.dev/features/enhance-AI) of your codebase accessible to LLMs, providing insights into the codebase architecture, project relationships and runnable tasks thus allowing AI to make precise code suggestions.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/82347605?s=48&v=4\" alt=\"OceanBase Logo\" /> **[OceanBase](https://github.com/oceanbase/mcp-oceanbase)** - MCP Server for OceanBase database and its tools\n- <img height=\"12\" width=\"12\" src=\"https://docs.octagonagents.com/logo.svg\" alt=\"Octagon Logo\" /> **[Octagon](https://github.com/OctagonAI/octagon-mcp-server)** - Deliver real-time investment research with extensive private and public market data.\n- <img height=\"12\" width=\"12\" src=\"https://octoeverywhere.com/img/logo.png\" alt=\"OctoEverywhere Logo\" /> **[OctoEverywhere](https://github.com/OctoEverywhere/mcp)** - A 3D Printing MCP server that allows for querying for live state, webcam snapshots, and 3D printer control.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/211697972\" alt=\"Offorte Logo\" /> **[Offorte](https://github.com/offorte/offorte-mcp-server#readme)** - Offorte Proposal Software official MCP server enables creation and sending of business proposals.\n-  **[OlaMaps](https://pypi.org/project/ola-maps-mcp-server)** - Official Ola Maps MCP Server for services like geocode, directions, place details and many more.\n- <img height=\"12\" width=\"12\" src=\"https://www.olostep.com/favicon.ico\" alt=\"Olostep\" /> **[Olostep](https://github.com/olostep/olostep-mcp-server)** - Search, scrape and crawl content from web. Real-time results in clean markdown.\n- <img height=\"12\" width=\"12\" src=\"https://static.onlyoffice.com/images/favicon.ico\" alt=\"ONLYOFFICE DocSpace\" /> **[ONLYOFFICE DocSpace](https://github.com/ONLYOFFICE/docspace-mcp)** - Interact with [ONLYOFFICE DocSpace](https://www.onlyoffice.com/docspace.aspx) API to create rooms, manage files and folders.\n- **[OMOP MCP](https://github.com/OHNLP/omop_mcp)** - Map clinical terminology to OMOP concepts using LLMs for healthcare data standardization.\n- <img height=\"12\" width=\"12\" src=\"https://op.gg/favicon.ico\" alt=\"OP.GG Logo\" /> **[OP.GG](https://github.com/opgginc/opgg-mcp)** - Access real-time gaming data across popular titles like League of Legends, TFT, and Valorant, offering champion analytics, esports schedules, meta compositions, and character statistics.\n- <img height=\"12\" width=\"12\" src=\"https://www.openfort.io/img/icon.svg\" alt=\"Openfort\" /> **[Openfort](https://github.com/openfort-xyz/mcp)** - Connect your AI to Openfort's smart wallet, auth, and project infrastructure.\n- <img height=\"12\" width=\"12\" src=\"https://open-metadata.org/favicon.ico\" alt=\"OpenMetadata\" /> **[OpenMetadata](https://open-metadata.org/mcp)** - The first Enterprise-grade MCP server for metadata\n- <img height=\"12\" width=\"12\" src=\"https://opensearch.org/wp-content/uploads/2025/01/opensearch_mark_default.svg\" alt=\"OpenSearch Logo\" /> **[OpenSearch](https://github.com/opensearch-project/opensearch-mcp-server-py)** -  MCP server that enables AI agents to perform search and analytics use cases on data stored in [OpenSearch](https://opensearch.org/).\n- <img height=\"12\" width=\"12\" src=\"https://app.opslevel.com/favicon.ico\" alt=\"OpsLevel\" /> **[OpsLevel](https://github.com/opslevel/opslevel-mcp)** - Official MCP Server for [OpsLevel](https://www.opslevel.com).\n- <img height=\"12\" width=\"12\" src=\"https://optuna.org/assets/img/favicon.ico\" alt=\"Optuna Logo\" /> **[Optuna](https://github.com/optuna/optuna-mcp)** - Official MCP server enabling seamless orchestration of hyperparameter search and other optimization tasks with [Optuna](https://optuna.org/).\n- <img height=\"12\" width=\"12\" src=\"https://raw.githubusercontent.com/oracle/mcp/refs/heads/main/oracle.svg\" alt=\"Oracle Logo\" /> **[Oracle](https://docs.oracle.com/en/database/oracle/sql-developer-command-line/25.2/sqcug/starting-and-managing-sqlcl-mcp-server.html#GUID-5F916B5D-8670-42BD-9F8B-D3D2424EC47E)** - Official [Oracle Database: SQLcl ](https://www.oracle.com/database/sqldeveloper/technologies/sqlcl/download/) MCP server enabling all access to any Oracle Database via native MCP support directly in SQLcl.\n- <img height=\"12\" width=\"12\" src=\"https://orshot.com/brand/favicon.svg\" alt=\"Orshot Logo\" /> **[Orshot](https://github.com/rishimohan/orshot-mcp-server)** - Official [Orshot](https://orshot.com) MCP server to dynamically generate images from custom design templates.\n- <img height=\"12\" width=\"12\" src=\"https://oxylabs.io/favicon.ico\" alt=\"Oxylabs Logo\" /> **[Oxylabs](https://github.com/oxylabs/oxylabs-mcp)** - Scrape websites with Oxylabs Web API, supporting dynamic rendering and parsing for structured data extraction.\n- <img height=\"12\" width=\"12\" src=\"https://developer.paddle.com/favicon.svg\" alt=\"Paddle Logo\" /> **[Paddle](https://github.com/PaddleHQ/paddle-mcp-server)** - Interact with the Paddle API. Manage product catalog, billing and subscriptions, and reports.\n- **[PaddleOCR](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/mcp_server.html)** - An MCP server that brings enterprise-grade OCR and document parsing capabilities to AI applications.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.brandfolder.io/YX9ETPCP/at/266537g8kh6mmvt24jvsjb/P-GreenRGB.svg\" alt=\"PagerDuty Logo\" /> **[PagerDuty](https://github.com/PagerDuty/pagerduty-mcp-server)** - Interact with your PagerDuty account, allowing you to manage incidents, services, schedules, and more directly from your MCP-enabled client.\n- **[Pagos](https://github.com/pagos-ai/pagos-mcp)** - Interact with the Pagos API. Query Credit Card BIN Data with more to come.\n- <img height=\"12\" width=\"12\" src=\"https://paiml.com/favicon.ico\" alt=\"PAIML Logo\" /> **[PAIML MCP Agent Toolkit](https://github.com/paiml/paiml-mcp-agent-toolkit)** - Professional project scaffolding toolkit with zero-configuration AI context generation, template generation for Rust/Deno/Python projects, and hybrid neuro-symbolic code analysis.\n- <img height=\"12\" width=\"12\" src=\"https://app.paperinvest.io/favicon.svg\" alt=\"Paper Logo\" /> **[Paper](https://github.com/paperinvest/mcp-server)** - Realistic paper trading platform with market simulation, 22 broker emulations, and professional tools for risk-free trading practice. First trading platform with MCP integration.\n- **[Patronus AI](https://github.com/patronus-ai/patronus-mcp-server)** - Test, evaluate, and optimize AI agents and RAG apps\n- <img height=\"12\" width=\"12\" src=\"https://mcp.paubox.com/paubox.png\" alt=\"Paubox Logo\" />**[Paubox](https://mcp.paubox.com)** - Official MCP server which allows AI agents to interact with Paubox Email API. HITRUST certified.\n- <img height=\"12\" width=\"12\" src=\"https://www.paypalobjects.com/webstatic/icon/favicon.ico\" alt=\"PayPal Logo\" /> **[PayPal](https://mcp.paypal.com)** - PayPal's official MCP server.\n- <img height=\"12\" width=\"12\" src=\"https://ww2-secure.pearl.com/static/pearl/pearl-logo.svg\" alt=\"Pearl Logo\" /> **[Pearl](https://github.com/Pearl-com/pearl_mcp_server)** - Official MCP Server to interact with Pearl API. Connect your AI Agents with 12,000+ certified experts instantly.\n- <img height=\"12\" width=\"12\" src=\"https://www.perplexity.ai/favicon.ico\" alt=\"Perplexity Logo\" /> **[Perplexity](https://github.com/ppl-ai/modelcontextprotocol)** - An MCP server that connects to Perplexity's Sonar API, enabling real-time web-wide research in conversational AI.\n- <img height=\"12\" width=\"12\" src=\"https://www.foxit.com/favicon.ico\" alt=\"Foxit Logo\" /> **[PDFActionInspector](https://github.com/foxitsoftware/PDFActionInspector/tree/develop)** - A Model Context Protocol server for extracting and analyzing JavaScript Actions from PDF files. Provides comprehensive security analysis to detect malicious PDF behaviors, hidden scripts, and potential security threats through AI-assisted risk assessment.\n- <img height=\"12\" width=\"12\" src=\"https://www.pga.com/favicon.ico\" alt=\"PGA Logo\" /> **[PGA (Golf)](https://mcp.pga.com)** - PGA's official MCP Server for all things golf-related. Find a coach, play golf, improve your game, and more.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/54333248\" /> **[Pinecone](https://github.com/pinecone-io/pinecone-mcp)** - [Pinecone](https://docs.pinecone.io/guides/operations/mcp-server)'s developer MCP Server assist developers in searching documentation and managing data within their development environment.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/54333248\" /> **[Pinecone Assistant](https://github.com/pinecone-io/assistant-mcp)** - Retrieves context from your [Pinecone Assistant](https://docs.pinecone.io/guides/assistant/mcp-server) knowledge base.\n- <img height=\"12\" width=\"12\" src=\"https://pipedream.com/favicon.ico\" alt=\"Pipedream Logo\" /> **[Pipedream](https://github.com/PipedreamHQ/pipedream/tree/master/modelcontextprotocol)** - Connect with 2,500 APIs with 8,000+ prebuilt tools.\n- <img height=\"12\" width=\"12\" src=\"https://playcanvas.com/static-assets/images/icons/favicon.png\" alt=\"PlayCanvas Logo\" /> **[PlayCanvas](https://github.com/playcanvas/editor-mcp-server)** - Create interactive 3D web apps with the PlayCanvas Editor.\n- <img height=\"12\" width=\"12\" src=\"https://playwright.dev/img/playwright-logo.ico\" alt=\"Playwright Logo\" /> **[Playwright](https://github.com/microsoft/playwright-mcp)** — Browser automation MCP server using Playwright to run tests, navigate pages, capture screenshots, scrape content, and automate web interactions reliably.\n- <img height=\"12\" width=\"12\" src=\"https://www.plugged.in/favicon.ico\" alt=\"Plugged.in Logo\" /> **[Plugged.in](https://github.com/VeriTeknik/pluggedin-mcp)** - A comprehensive proxy that combines multiple MCP servers into a single MCP. It provides discovery and management of tools, prompts, resources, and templates across servers, plus a playground for debugging when building MCP servers.\n- <img height=\"12\" width=\"12\" src=\"https://github.com/port-labs/port-mcp-server/blob/main/assets/port_symbol_white.svg\" alt=\"Port Logo\" /> **[Port IO](https://github.com/port-labs/port-mcp-server)** - Access and manage your software catalog to improve service quality and compliance.\n- **[PostHog](https://github.com/posthog/mcp)** - Interact with PostHog analytics, feature flags, error tracking and more with the official PostHog MCP server.\n- **[Postman API](https://github.com/postmanlabs/postman-api-mcp)** - Manage your Postman resources using the [Postman API](https://www.postman.com/postman/postman-public-workspace/collection/i2uqzpp/postman-api).\n- <img height=\"12\" width=\"12\" src=\"https://powerdrill.ai/_next/static/media/powerdrill.0fa27d00.webp\" alt=\"Powerdrill Logo\" /> **[Powerdrill](https://github.com/powerdrillai/powerdrill-mcp)** - An MCP server that provides tools to interact with Powerdrill datasets, enabling smart AI data analysis and insights.\n- <img height=\"12\" width=\"12\" src=\"https://www.prisma.io/images/favicon-32x32.png\" alt=\"Prisma Logo\" /> **[Prisma](https://www.prisma.io/docs/postgres/mcp-server)** - Create and manage Prisma Postgres databases\n- <img height=\"12\" width=\"12\" src=\"https://probe.dev/favicon.ico\" alt=\"Probe.dev Logo\" /> **[Probe.dev](https://docs.probe.dev/guides/mcp-integration)** - Comprehensive media analysis and validation powered by [Probe.dev](https://probe.dev). Hosted MCP server with FFprobe, MediaInfo, and Probe Report analysis capabilities.\n- <img height=\"12\" width=\"12\" src=\"https://framerusercontent.com/images/FGzpihs4MxmSJhyGZ6n7f2Xj0.png\" alt=\"Prode.ai Logo\" /> **[ProdE](https://github.com/CuriousBox-AI/ProdE-mcp)** - Your 24/7 production engineer that preserves context across multiple codebases.\n- <img height=\"12\" width=\"12\" src=\"https://programintegrity.org/wp-content/uploads/2024/07/PIA-Favicon.svg\" alt=\"Program Integrity Alliance (PIA) Logo\" /> **[Program Integrity Alliance (PIA)](https://github.com/Program-Integrity-Alliance/pia-mcp-local)** - Local and Hosted MCP servers providing AI-friendly access to U.S. Government Open Datasets. Also available on [Docker MCP Catalog](https://hub.docker.com/mcp/explore?search=PIA). See [our website](https://programintegrity.org) for more details.\n- <img height=\"12\" width=\"12\" src=\"https://github.com/newtype-01/prompthouse-mcp/raw/main/prompthouse-logo-12x12.png\" alt=\"PromptHouse Logo\" /> **[PromptHouse](https://github.com/newtype-01/prompthouse-mcp)** - Personal prompt library with MCP integration for AI clients.\n- <img height=\"12\" width=\"12\" src=\"https://docs.speedscale.com/img/favicon.ico\" alt=\"proxymock Logo\" /> **[proxymock](https://docs.speedscale.com/proxymock/reference/mcp/)** - An MCP server that automatically generates tests and mocks by recording a live app.\n- <img src=\"https://www.pubnub.com/favicon/favicon-32x32.png\" alt=\"PubNub\" width=\"12\" height=\"12\"> **[PubNub](https://github.com/pubnub/pubnub-mcp-server)** - Retrieves context for developing with PubNub SDKs and calling APIs.\n- <img height=\"12\" width=\"12\" src=\"https://www.pulumi.com/images/favicon.ico\" alt=\"Pulumi Logo\" /> **[Pulumi](https://github.com/pulumi/mcp-server)** - Deploy and manage cloud infrastructure using [Pulumi](https://pulumi.com).\n- <img height=\"12\" width=\"12\" src=\"https://pure.md/favicon.png\" alt=\"Pure.md Logo\" /> **[Pure.md](https://github.com/puremd/puremd-mcp)** - Reliably access web content in markdown format with [pure.md](https://pure.md) (bot detection avoidance, proxy rotation, and headless JS rendering built in).\n- <img height=\"12\" width=\"12\" src=\"https://put.io/images/favicon.ico\" alt=\"Put.io Logo\" /> **[Put.io](https://github.com/putdotio/putio-mcp-server)** - Interact with your Put.io account to download torrents.\n- <img height=\"12\" width=\"12\" src=\"https://qdrant.tech/img/brand-resources-logos/logomark.svg\" /> **[Qdrant](https://github.com/qdrant/mcp-server-qdrant/)** - Implement semantic memory layer on top of the Qdrant vector search engine\n- <img src=\"https://api.qoretechnologies.com/api/public/apps/Qorus/qorus-logo.svg\" alt=\"Qorus\" width=\"12\" height=\"12\"> **[Qorus](https://qoretechnologies.com/manual/qorus/current/qorus/sysarch.html#mcp_server)** - Connect to any application, system, or technology and automate your business processes without coding and with AI\n- <img src=\"https://avatars.githubusercontent.com/u/18053493?s=200&v=4\" alt=\"Qonto\" width=\"12\" height=\"12\"> **[Qonto](https://github.com/qonto/qonto-mcp-server)** - Access and interact your Qonto account through LLMs using MCP.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/3912814\" alt=\"QuantConnect Logo\" /> **[QuantConnect](https://github.com/QuantConnect/mcp-server)** - Interact with your [QuantConnect](https://www.quantconnect.com/) account to update projects, write strategies, run backtest, and deploying strategies to production live-trading.\n- **[Quickchat AI](https://github.com/incentivai/quickchat-ai-mcp)** - Launch your conversational [Quickchat AI](https://quickchat.ai) agent as an MCP to give AI apps real-time access to its Knowledge Base and conversational capabilities\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/165178062\" alt=\"Ragie Logo\" /> **[Ragie](https://github.com/ragieai/ragie-mcp-server/)** - Retrieve context from your [Ragie](https://www.ragie.ai) (RAG) knowledge base connected to integrations like Google Drive, Notion, JIRA and more.\n- <img height=\"12\" width=\"12\" src=\"https://www.ramp.com/favicon.ico\" /> **[Ramp](https://github.com/ramp-public/ramp-mcp)** - Interact with [Ramp](https://ramp.com)'s Developer API to run analysis on your spend and gain insights leveraging LLMs\n- **[Raygun](https://github.com/MindscapeHQ/mcp-server-raygun)** - Interact with your crash reporting and real using monitoring data on your Raygun account\n- <img height=\"12\" width=\"12\" src=\"https://framerusercontent.com/images/CU1m0xFonUl76ZeaW0IdkQ0M.png\" alt=\"Razorpay Logo\" /> **[Razorpay](https://github.com/razorpay/razorpay-mcp-server)** - Razorpay's official MCP server\n- <img height=\"12\" width=\"12\" src=\"https://www.recraft.ai/favicons/icon.svg\" alt=\"Recraft Logo\" /> **[Recraft](https://github.com/recraft-ai/mcp-recraft-server)** - Generate raster and vector (SVG) images using [Recraft](https://recraft.ai). Also you can edit, upscale images, create your own styles, and vectorize raster images\n- <img height=\"12\" width=\"12\" src=\"https://www.redhat.com/favicon.ico\" alt=\"Red Hat Logo\" /> **[Red Hat Insights](https://github.com/RedHatInsights/insights-mcp)** - Interact with [Red Hat Insights](https://www.redhat.com/en/technologies/management/insights) - build images, manage vulnerabilities, or view targeted recommendations.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/1529926\" alt=\"Redis Logo\" /> **[Redis](https://github.com/redis/mcp-redis/)** - The Redis official MCP Server offers an interface to manage and search data in Redis.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/1529926\" alt=\"Redis Logo\" /> **[Redis Cloud API](https://github.com/redis/mcp-redis-cloud/)** - The Redis Cloud API MCP Server allows you to manage your Redis Cloud resources using natural language.\n- <img src=\"https://avatars.githubusercontent.com/u/149024635\" alt=\"Reexpress\" width=\"12\" height=\"12\"> **[Reexpress](https://github.com/ReexpressAI/reexpress_mcp_server)** - Enable Similarity-Distance-Magnitude statistical verification for your search, software, and data science workflows\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/68a872edf3df6064de547670/68b7f089c45a6083ce25acb1_reflag-favicon-32.png\" alt=\"Reflag\" /> **[Reflag](https://github.com/reflagcom/javascript/tree/main/packages/cli#model-context-protocol)** - Create and manage feature flags using [Reflag](https://reflag.com)\n- <img height=\"12\" width=\"12\" src=\"https://www.reltio.com/wp-content/uploads/2024/03/cropped-cropped-Reltio_Light_Mode_Dark_Mode_Favicon-270x270.png\" alt=\"Reltio Logo\" /> **[Reltio](https://github.com/reltio-ai/reltio-mcp-server)** - A lightweight, plugin-based MCP server designed to perform advanced entity matching with language models in Reltio environments.\n- <img height=\"12\" width=\"12\" src=\"https://www.rember.com/favicon.ico\" alt=\"Rember Logo\" /> **[Rember](https://github.com/rember/rember-mcp)** - Create spaced repetition flashcards in [Rember](https://rember.com) to remember anything you learn in your chats\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/114033652\" alt=\"Render Logo\" /> **[Render](https://render.com/docs/mcp-server)** - The official Render MCP server: spin up new services, run queries against your databases, and debug rapidly with direct access to service metrics and logs.\n- <img height=\"12\" width=\"12\" src=\"https://reportportal.io/favicon.ico\" alt=\"ReportPortal Logo\" /> **[ReportPortal](https://github.com/reportportal/reportportal-mcp-server)** - explore and analyze automated test results from [ReportPortal](https://reportportal.io) using your favourite LLM.\n- <img height=\"12\" width=\"12\" src=\"http://nonica.io/Nonica-logo.ico\" alt=\"Nonica Logo\" /> **[Revit](https://github.com/NonicaTeam/AI-Connector-for-Revit)** - Connect and interact with your Revit models live.\n- <img height=\"12\" width=\"12\" src=\"https://ui.rilldata.com/favicon.png\" alt=\"Rill Data Logo\" /> **[Rill Data](https://docs.rilldata.com/explore/mcp)** - Interact with Rill Data to query and analyze your data.\n- <img height=\"12\" width=\"12\" src=\"https://riza.io/favicon.ico\" alt=\"Riza logo\" /> **[Riza](https://github.com/riza-io/riza-mcp)** - Arbitrary code execution and tool-use platform for LLMs by [Riza](https://riza.io)\n- <img height=\"12\" width=\"12\" src=\"https://cdn.foundation.roblox.com/current/RobloxStudio.ico\" alt=\"Roblox Studio\" /> **[Roblox Studio](https://github.com/Roblox/studio-rust-mcp-server)** - Roblox Studio MCP Server, create and manipulate scenes, scripts in Roblox Studio\n- <img src=\"https://hyper3d.ai/favicon.ico\" alt=\"Rodin\" width=\"12\" height=\"12\"> **[Rodin](https://github.com/DeemosTech/rodin-api-mcp)** - Generate 3D Models with [Hyper3D Rodin](https://hyper3d.ai)\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/66b7de6a233c04f4dac200a6/66bed52680d689629483c18b_faviconV2%20(2).png\" alt=\"Root Signals Logo\" /> **[Root Signals](https://github.com/root-signals/root-signals-mcp)** - Improve and quality control your outputs with evaluations using LLM-as-Judge\n- **[Routine](https://github.com/routineco/mcp-server)** - MCP server to interact with [Routine](https://routine.co/): calendars, tasks, notes, etc.\n- <img height=\"12\" width=\"12\" src=\"https://platform.composio.dev/favicon.ico\" alt=\"Composio Logo\"> **[Rube](https://github.com/ComposioHQ/Rube)** - Rube is a Model Context Protocol (MCP) server that connects your AI tools to 500+ apps like Gmail, Slack, GitHub, and Notion. Simply install it in your AI client, authenticate once with your apps, and start asking your AI to perform real actions like \"Send an email\" or \"Create a task.\"\n- <img height=\"12\" width=\"12\" src=\"https://raw.githubusercontent.com/safedep/.github/refs/heads/main/assets/logo/1.png\" alt=\"SafeDep Logo\" /> **[SafeDep](https://github.com/safedep/vet/blob/main/docs/mcp.md)** - SafeDep `vet-mcp` helps in  vetting open source packages for security risks—such as vulnerabilities and malicious code—before they're used in your project, especially with AI-generated code suggestions.\n- <img height=\"12\" width=\"12\" src=\"https://waf-ce.chaitin.cn/favicon.ico\" alt=\"SafeLine Logo\" /> **[SafeLine](https://github.com/chaitin/SafeLine/tree/main/mcp_server)** - [SafeLine](https://safepoint.cloud/landing/safeline) is a self-hosted WAF(Web Application Firewall) to protect your web apps from attacks and exploits.\n- <img height=\"12\" width=\"12\" src=\"https://scrapi.tech/favicon.ico\" alt=\"ScrAPI Logo\" /> **[ScrAPI](https://github.com/DevEnterpriseSoftware/scrapi-mcp)** - Web scraping using [ScrAPI](https://scrapi.tech). Extract website content that is difficult to access because of bot detection, captchas or even geolocation restrictions.\n- <img height=\"12\" width=\"12\" src=\"https://upnorthmedia.co/favicon.ico\" alt=\"Up North Media Logo\" /> **[ScreenshotMCP](https://github.com/upnorthmedia/ScreenshotMCP/)** - A Model Context Protocol MCP server for capturing website screenshots with full page, element, and device size features.\n- <img height=\"12\" width=\"12\" src=\"https://screenshotone.com/favicon.ico\" alt=\"ScreenshotOne Logo\" /> **[ScreenshotOne](https://github.com/screenshotone/mcp/)** - Render website screenshots with [ScreenshotOne](https://screenshotone.com/)\n- <img height=\"12\" width=\"12\" src=\"https://pics.fatwang2.com/56912e614b35093426c515860f9f2234.svg\" alt=\"Search1API Logo\" /> **[Search1API](https://github.com/fatwang2/search1api-mcp)** - One API for Search, Crawling, and Sitemaps\n- <img height=\"12\" width=\"12\" src=\"https://www.searchunify.com/favicon.ico\" alt=\"SearchUnify Logo\" /> **[SearchUnify](https://github.com/searchunify/su-mcp/)** - SearchUnify MCP Server (su-mcp) enables seamless integration of SearchUnify with Claude Desktop\n- <img height=\"12\" width=\"12\" src=\"https://secureframe.com/favicon.ico\" alt=\"Secureframe Logo\" /> **[Secureframe](https://github.com/secureframe/secureframe-mcp-server)** - Query security controls, monitor compliance tests, and access audit data across SOC 2, ISO 27001, CMMC, FedRAMP, and other frameworks from [Secureframe](https://secureframe.com).\n- <img height=\"12\" width=\"12\" src=\"https://semgrep.dev/favicon.ico\" alt=\"Semgrep Logo\" /> **[Semgrep](https://github.com/semgrep/mcp)** - Enable AI agents to secure code with [Semgrep](https://semgrep.dev/).\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/187640573?s=48&v=4\" alt=\"Sequa Logo\" /> **[Sequa.AI](https://github.com/sequa-ai/sequa-mcp)** - Stop stitching context for Copilot and Cursor. With [Sequa MCP](https://github.com/sequa-ai/sequa-mcp), your AI tools know all your codebases and docs out of the box.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/6372338e5477e047032b37a5/64f85e6388a2a5c8c9525b4d_favLogo.png\" alt=\"Shortcut Logo\" /> **[Shortcut](https://github.com/useshortcut/mcp-server-shortcut)** - Access and implement all of your projects and tasks (Stories) from [Shortcut](https://shortcut.com/).\n- <img height=\"12\" width=\"12\" src=\"https://www.singlestore.com/favicon-32x32.png?v=277b9cbbe31e8bc416504cf3b902d430\"/> **[SingleStore](https://github.com/singlestore-labs/mcp-server-singlestore)** - Interact with the SingleStore database platform\n- <img height=\"12\" width=\"12\" src=\"https://smartbear.com/smartbear/assets/img/favicon.png\" alt=\"SmartBear Logo\" /> **[SmartBear](https://github.com/SmartBear/smartbear-mcp)** - Provides access to multiple capabilities across SmartBear's API Hub, Test Hub, and Insight Hub, all through [dedicated tools and resources](https://developer.smartbear.com/smartbear-mcp/docs/mcp-server).\n- <img src=\"https://smooth-operator.online/logo48.png\" alt=\"Smooth Operator\" width=\"12\" height=\"12\"> **[Smooth Operator](https://smooth-operator.online/agent-tools-api-docs/toolserverdocs)** - Tools to automate Windows via AI Vision, Mouse, Keyboard, Automation Trees, Webbrowser\n- <img height=\"12\" width=\"12\" src=\"https://app.snyk.io/bundle/favicon-faj49uD9.png\" alt=\"Snyk Logo\" /> **[Snyk](https://github.com/snyk/snyk-ls/blob/main/mcp_extension/README.md)** - Enhance security posture by embedding [Snyk](https://snyk.io/) vulnerability scanning directly into agentic workflows.\n- <img height=\"12\" width=\"12\" src=\"https://www.sonarsource.com/favicon.ico\" alt=\"SonarQube Logo\" /> **[SonarQube](https://github.com/SonarSource/sonarqube-mcp-server)** - Enables seamless integration with [SonarQube](https://www.sonarsource.com/) Server or Cloud and allows for code snippet analysis within the agent context.\n- <img src=\"https://sophtron.com/favicon.ico\" alt=\"Sophtron\" width=\"12\" height=\"12\"> **[Sophtron](https://github.com/sophtron/Sophtron-Integration/tree/main/modelcontextprotocol)** - Connect to your bank, credit card, utilities accounts to retrieve account balances and transactions with [Sophtron Bank Integration](https://sophtron.com).\n- <img height=\"12\" width=\"12\" src=\"https://www.stackhawk.com/wp-content/uploads/2025/03/icon-512x512-2-150x150.png\" alt=\"StackHawk Logo\" /> **[StackHawk](https://github.com/stackhawk/stackhawk-mcp)** - Use [StackHawk](https://www.stackhawk.com/) to test for and FIX security problems in your code or vibe coded app.\n- <img height=\"12\" width=\"12\" src=\"https://www.starrocks.io/favicon.ico\" alt=\"StarRocks Logo\" /> **[StarRocks](https://github.com/StarRocks/mcp-server-starrocks)** - Interact with [StarRocks](https://www.starrocks.io/)\n- <img height=\"12\" width=\"12\" src=\"https://downloads.steadybit.com/logomark.svg\" alt=\"Steadybit Logo\" /> **[Steadybit](https://github.com/steadybit/mcp)** - Interact with [Steadybit](https://www.steadybit.com/)\n- <img height=\"12\" width=\"12\" src=\"https://steuerboard.net/favicon.ico\" alt=\"Steuerboard Logo\" /> **[Steuerboard](https://github.com/steuerboard/steuerboard-mcp-typescript)** - Interact with the accounting data in your business using our official MCP server\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/22632046?s=200&v=4\" alt=\"Storybook Logo\" /> **[Storybook](https://github.com/storybookjs/addon-mcp)** - Interact with [Storybook](https://storybook.js.org/) to automate UI component testing and documentation\n- <img height=\"12\" width=\"12\" src=\"https://stripe.com/favicon.ico\" alt=\"Stripe Logo\" /> **[Stripe](https://github.com/stripe/agent-toolkit)** - Interact with Stripe API\n- <img height=\"12\" width=\"12\" src=\"https://sunra.ai/favicon.ico\" alt=\"Sunra AI Logo\" /> **[Sunra AI](https://github.com/sunra-ai/sunra-clients/tree/main/mcp-server)** - Search for and run AI models on [Sunra.ai](https://sunra.ai). Discover models, create video, image, and 3D model content, track their status, and manage the generated media.\n- <img height=\"12\" width=\"12\" src=\"https://supabase.com/favicon/favicon.ico\" alt=\"Supabase Logo\" /> **[Supabase](https://github.com/supabase-community/supabase-mcp)** - Interact with Supabase: Create tables, query data, deploy edge functions, and more.\n- <img height=\"12\" width=\"12\" src=\"https://supadata.ai/favicon.ico\" alt=\"Supadata Logo\" /> **[Supadata](https://github.com/supadata-ai/mcp)** - Official MCP server for [Supadata](https://supadata.ai) - YouTube, TikTok, X and Web data for makers.\n- <img height=\"12\" width=\"12\" src=\"https://d12w4pyrrczi5e.cloudfront.net/archive/50eb154ab859c63a8f1c850f9fe094e25d35e929/images/favicon.ico\" alt=\"Tako Logo\" /> **[Tako](https://github.com/TakoData/tako-mcp)** - Use natural language to search [Tako](https://trytako.com) for real-time financial, sports, weather, and public data with visualization\n- <img height=\"12\" width=\"12\" src=\"https://tavily.com/favicon.ico\" alt=\"Tavily Logo\" /> **[Tavily](https://github.com/tavily-ai/tavily-mcp)** - Search engine for AI agents (search + extract) powered by [Tavily](https://tavily.com/)\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/10522416?s=200&v=4\" alt=\"Telnyx Logo\" /> **[Telnyx](https://github.com/team-telnyx/telnyx-mcp-server)** - Official MCP server for building AI-powered communication apps. Create voice assistants, send SMS campaigns, manage phone numbers, and integrate real-time messaging with enterprise-grade reliability. Includes remote [streamable-http](https://api.telnyx.com/v2/mcp) and [sse](https://api.telnyx.com/mcp/sse) servers.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/1615979?s=200&v=4\" alt=\"Teradata Logo\" /> **[Teradata](https://github.com/Teradata/teradata-mcp-server)** - This MCP Server support tools and prompts for multi task data analytics on a [Teradata](https://teradata.com) platform.\n- <img height=\"12\" width=\"12\" src=\"https://raw.githubusercontent.com/hashicorp/terraform-mcp-server/main/public/images/Terraform-LogoMark_onDark.svg\" alt=\"Terraform Logo\" /> **[Terraform](https://github.com/hashicorp/terraform-mcp-server)** - Seamlessly integrate with Terraform ecosystem, enabling advanced automation and interaction capabilities for Infrastructure as Code (IaC) development powered by [Terraform](https://www.hashicorp.com/en/products/terraform)\n- <img height=\"12\" width=\"12\" src=\"https://www.textin.com/favicon.png\" alt=\"TextIn Logo\" /> **[TextIn](https://github.com/intsig-textin/textin-mcp)** - An MCP server for the [TextIn](https://www.textin.com/?from=github_mcp) API, is a tool for extracting text and performing OCR on documents, it also supports converting documents into Markdown\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/106156665?s=200\" alt=\"Thena Logo\" /> **[Thena](https://mcp.thena.ai)** - Thena's MCP server for enabling users and AI agents to interact with Thena's services and manage customers across different channels such as Slack, Email, Web, Discord etc.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/24291394?v=4\" alt=\"ThingsBoard\" /> **[ThingsBoard](https://github.com/thingsboard/thingsboard-mcp)** - The ThingsBoard MCP Server provides a natural language interface for LLMs and AI agents to interact with your ThingsBoard IoT platform.\n- <img height=\"12\" width=\"12\" src=\"https://www.lg.com/favicon.ico\" alt=\"ThinQ Logo\" /> **[ThinQ Connect](https://github.com/thinq-connect/thinqconnect-mcp)** - Interact with LG ThinQ smart home devices and appliances through the ThinQ Connect MCP server.\n- <img height=\"12\" width=\"12\" src=\"https://thirdweb.com/favicon.ico\" alt=\"Thirdweb Logo\" /> **[Thirdweb](https://github.com/thirdweb-dev/ai/tree/main/python/thirdweb-mcp)** - Read/write to over 2k blockchains, enabling data querying, contract analysis/deployment, and transaction execution, powered by [Thirdweb](https://thirdweb.com/)\n- <img height=\"12\" width=\"12\" src=\"https://www.thoughtspot.com/favicon-16x16.png\" alt=\"ThoughtSpot Logo\" /> **[ThoughtSpot](https://github.com/thoughtspot/mcp-server)** - AI is the new BI. A dedicated data analyst for everyone on your team. Bring [ThoughtSpot](https://thoughtspot.com) powers into Claude or any MCP host.\n- <img height=\"12\" width=\"12\" src=\"https://tianji.msgbyte.com/img/dark-brand.svg\" alt=\"Tianji Logo\" /> **[Tianji](https://github.com/msgbyte/tianji/tree/master/apps/mcp-server)** - Interact with Tianji platform whatever selfhosted or cloud platform, powered by [Tianji](https://tianji.msgbyte.com/).\n- <img height=\"12\" width=\"12\" src=\"https://www.pingcap.com/favicon.ico\" alt=\"TiDB Logo\" /> **[TiDB](https://github.com/pingcap/pytidb)** - MCP Server to interact with TiDB database platform.\n- <img height=\"12\" width=\"12\" src=\"https://www.tinybird.co/favicon.ico\" alt=\"Tinybird Logo\" /> **[Tinybird](https://github.com/tinybirdco/mcp-tinybird)** - Interact with Tinybird serverless ClickHouse platform\n- <img height=\"12\" width=\"12\" src=\"https://b2729162.smushcdn.com/2729162/wp-content/uploads/2023/10/cropped-Favicon-1-192x192.png?lossy=1&strip=1&webp=1\" alt=\"Tldv Logo\" /> **[Tldv](https://gitlab.com/tldv/tldv-mcp-server)** - Connect your AI agents to Google-Meet, Zoom & Microsoft Teams through [tl;dv](https://tldv.io)\n- <img height=\"12\" width=\"12\" src=\"https://www.todoist.com/static/favicon-32x32.png\" alt=\"Todoist Logo\" /> **[Todoist](https://github.com/doist/todoist-ai)** - Search, add, and update [Todoist](https://todoist.com) tasks, projects, sections, comments, and more.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.tokenmetrics.com/logo.svg\" alt=\"Token Metrics Logo\" /> **[Token Metrics](https://github.com/token-metrics/mcp)** - [Token Metrics](https://www.tokenmetrics.com/) integration for fetching real-time crypto market data, trading signals, price predictions, and advanced analytics.\n- <img height=\"12\" width=\"12\" src=\"https://di8m9w6rqrh5d.cloudfront.net/2G3TRwfv1w3GTLfmT7Dmco1VddoFTI5P/1920_6b7e7ec2-d897-4cd7-94f3-46a8301212c3.png\" alt=\"TomTom Logo\" /> **[TomTom-MCP](https://github.com/tomtom-international/tomtom-mcp)** - The [TomTom](https://www.tomtom.com/) MCP Server simplifies geospatial development by providing seamless access to TomTom's location services, including search, routing, traffic and static maps data.\n- <img height=\"12\" width=\"12\" src=\"https://images.thetradeagent.ai/trade_agent/logo.svg\" alt=\"Trade Agent Logo\" /> **[Trade Agent](https://github.com/Trade-Agent/trade-agent-mcp)** - Execute stock and crypto trades on your brokerage via [Trade Agent](https://thetradeagent.ai)\n-  **[Twelve Data](https://github.com/twelvedata/mcp)** — Integrate your AI agents with real-time and historical financial market data through our official [Twelve Data](https://twelvedata.com) MCP server.\n- <img height=\"12\" width=\"12\" src=\"https://www.twilio.com/content/dam/twilio-com/core-assets/social/favicon-16x16.png\" alt=\"Twilio Logo\" /> **[Twilio](https://github.com/twilio-labs/mcp)** - Interact with [Twilio](https://www.twilio.com/en-us) APIs to send SMS messages, manage phone numbers, configure your account, and more.\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/91520705?s=48&v=4\" alt=\"Tencent RTC Logo\" /> **[Tencent RTC](https://github.com/Tencent-RTC/mcp)** - The MCP Server enables AI IDEs to more effectively understand and use [Tencent's Real-Time Communication](https://trtc.io/) SDKs and APIs, which significantly streamlines the process for developers to build audio/video call applications.\n- <img height=\"12\" width=\"12\" src=\"https://uberall.com/media/favicon.svg\" alt=\"Uberall Logo\" /> **[Uberall](https://github.com/uberall/uberall-mcp-server)** – Manage multi - location presence, including listings, reviews, and social posting, via [uberall](https://uberall.com).\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/91906527\" alt=\"Unblocked Logo\" /> **[Unblocked](https://docs.getunblocked.com/unblocked-mcp)** Help your AI-powered IDEs generate faster, more accurate code by giving them access to context from Slack, Confluence, Google Docs, JIRA, and more with [Unblocked](https://getunblocked.com).\n- <img height=\"12\" width=\"12\" src=\"https://unifai.network/favicon.ico\" alt=\"UnifAI Logo\" /> **[UnifAI](https://github.com/unifai-network/unifai-mcp-server)** - Dynamically search and call tools using [UnifAI Network](https://unifai.network)\n- <img height=\"12\" width=\"12\" src=\"https://framerusercontent.com/images/plcQevjrOYnyriuGw90NfQBPoQ.jpg\" alt=\"Unstructured Logo\" /> **[Unstructured](https://github.com/Unstructured-IO/UNS-MCP)** - Set up and interact with your unstructured data processing workflows in [Unstructured Platform](https://unstructured.io)\n- <img height=\"12\" width=\"12\" src=\"https://upstash.com/icons/favicon-32x32.png\" alt=\"Upstash Logo\" /> **[Upstash](https://github.com/upstash/mcp-server)** - Manage Redis databases and run Redis commands on [Upstash](https://upstash.com/) with natural language.\n-  **[Vantage](https://github.com/vantage-sh/vantage-mcp-server)** - Interact with your organization's cloud cost spend.\n- <img height=\"12\" width=\"12\" src=\"https://mcp.variflight.com/favicon.ico\" alt=\"VariFlight Logo\" /> **[VariFlight](https://github.com/variflight/variflight-mcp)** - VariFlight's official MCP server provides tools to query flight information, weather data, comfort metrics, the lowest available fares, and other civil aviation-related data.\n- <img height=\"12\" width=\"12\" src=\"https://docs.octagonagents.com/logo.svg\" alt=\"Octagon Logo\" /> **[VCAgents](https://github.com/OctagonAI/octagon-vc-agents)** - Interact with investor agents—think Wilson or Thiel—continuously updated with market intel.\n- **[Vectorize](https://github.com/vectorize-io/vectorize-mcp-server/)** - [Vectorize](https://vectorize.io) MCP server for advanced retrieval, Private Deep Research, Anything-to-Markdown file extraction and text chunking.\n- <img height=\"12\" width=\"12\" src=\"https://static.verbwire.com/favicon-16x16.png\" alt=\"Verbwire Logo\" /> **[Verbwire](https://github.com/verbwire/verbwire-mcp-server)** - Deploy smart contracts, mint NFTs, manage IPFS storage, and more through the Verbwire API\n- <img height=\"12\" width=\"12\" src=\"http://vercel.com/favicon.ico\" alt=\"Vercel Logo\" /> **[Vercel](https://vercel.com/docs/mcp/vercel-mcp)** - Access logs, search docs, and manage projects and deployments.\n- <img height=\"12\" width=\"12\" src=\"https://verodat.io/assets/favicon-16x16.png\" alt=\"Verodat Logo\" /> **[Verodat](https://github.com/Verodat/verodat-mcp-server)** - Interact with Verodat AI Ready Data platform\n- <img height=\"12\" width=\"12\" src=\"https://www.veyrax.com/favicon.ico\" alt=\"VeyraX Logo\" /> **[VeyraX](https://github.com/VeyraX/veyrax-mcp)** - Single tool to control all 100+ API integrations, and UI components\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/174736222?s=200&v=4\" alt=\"VictoriaMetrics Logo\" /> **[VictoriaMetrics](https://github.com/VictoriaMetrics-Community/mcp-victoriametrics)** - Comprehensive integration with [VictoriaMetrics APIs](https://docs.victoriametrics.com/victoriametrics/url-examples/) and [documentation](https://docs.victoriametrics.com/) for monitoring, observability, and debugging tasks related to your VictoriaMetrics instances.\n- <img height=\"12\" width=\"12\" src=\"https://framerusercontent.com/images/ijlYG00LOcMD6zR1XLMxHbAwZkM.png\" alt=\"VideoDB Director\" /> **[VideoDB Director](https://github.com/video-db/agent-toolkit/tree/main/modelcontextprotocol)** - Create AI-powered video workflows including automatic editing, content moderation, voice cloning, highlight generation, and searchable video moments—all accessible via simple APIs and intuitive chat-based interfaces.\n- <img height=\"12\" width=\"12\" src=\"https://landing.ai/wp-content/uploads/2024/04/cropped-favicon-192x192.png\" alt=\"LandingAI VisionAgent\" /> **[VisionAgent MCP](https://github.com/landing-ai/vision-agent-mcp)** - A simple MCP server that enables your LLM to better reason over images, video and documents.\n- <img height=\"12\" width=\"12\" src=\"https://raw.githubusercontent.com/mckinsey/vizro/main/vizro-core/docs/assets/images/favicon.png\" alt=\"Vizro Logo\" /> **[Vizro](https://github.com/mckinsey/vizro/tree/main/vizro-mcp)** - Tools and templates to create validated and maintainable data charts and dashboards\n- <img height=\"12\" width=\"12\" src=\"https://wavespeed.ai/logo.webp\" alt=\"WaveSpeed Logo\" /> **[WaveSpeed](https://github.com/WaveSpeedAI/mcp-server)** - WaveSpeed MCP server providing AI agents with image and video generation capabilities.\n- <img height=\"12\" width=\"12\" src=\"https://waystation.ai/images/logo.svg\" alt=\"WayStation Logo\" /> **[WayStation](https://github.com/waystation-ai/mcp)** - Universal MCP server to connect to popular productivity tools such as Notion, Monday, AirTable, and many more\n- <img height=\"12\" width=\"12\" src=\"https://static.whatsapp.net/rsrc.php/v3/yz/r/ujTY9i_Jhs1.png\" alt=\"WhatsApp Business Logo\" /> **[WhatsApp Business](https://medium.com/@wassenger/introducing-whatsapp-mcp-ai-connector-3d393b52d1b0)** - WhatsApp Business MCP connector enabling AI agents to send messages, manage conversations, access templates, and integrate with WhatsApp Business API for automated customer communication.\n- <img height=\"12\" width=\"12\" src=\"https://www.webflow.com/favicon.ico\" alt=\"Webflow Logo\"> **[Webflow](https://github.com/webflow/mcp-server)** - Interact with Webflow sites, pages, and collections\n- <img height=\"12\" width=\"12\" src=\"https://webscraping.ai/favicon.ico\" alt=\"WebScraping.AI Logo\" /> **[WebScraping.AI](https://github.com/webscraping-ai/webscraping-ai-mcp-server)** - Interact with **[WebScraping.AI](https://WebScraping.AI)** for web data extraction and scraping\n- <img height=\"12\" width=\"12\" src=\"https://winston-app-production-public.s3.us-east-1.amazonaws.com/winston-ai-favicon-light.svg\" alt=\"Winston.AI Logo\" /> **[Winston AI](https://github.com/gowinston-ai/winston-ai-mcp-server)** - AI detector MCP server with industry leading accuracy rates in detecting use of AI in text and images. The [Winston AI](https://gowinston.ai) MCP server also offers a robust plagiarism checker to help maintain integrity.\n- <img height=\"12\" width=\"12\" src=\"https://www.xero.com/favicon.ico\" alt=\"Xero Logo\" /> **[Xero](https://github.com/XeroAPI/xero-mcp-server)** - Interact with the accounting data in your business using our official MCP server\n- <img height=\"12\" width=\"12\" src=\"https://storage.yandexcloud.net/ydb-www-prod-site-assets/favicon-202305/favicon.ico\" alt=\"YDB Logo\" /> **[YDB](https://github.com/ydb-platform/ydb-mcp)** - Query [YDB](https://ydb.tech/) databases\n- <img height=\"12\" width=\"12\" src=\"https://fe-resource.yeelight.com/logo-black.jpeg\" alt=\"Yeelight Logo\" /> **[Yeelight MCP Server](https://github.com/Yeelight/yeelight-iot-mcp)** - The official [Yeelight MCP Server](https://github.com/Yeelight/yeelight-iot-mcp) enables users to control and query their [Yeelight](https://en.yeelight.com/) smart devices using natural language, offering a seamless and efficient human-AI interaction experience.\n- <img height=\"12\" width=\"12\" src=\"https://cdn.prod.website-files.com/632cd328ed2b485519c3f689/6334977a5d1a542102d4b9b5_favicon-32x32.png\" alt=\"YepCode Logo\" /> **[YepCode](https://github.com/yepcode/mcp-server-js)** - Run code in a secure, scalable sandbox environment with full support for dependencies, secrets, logs, and access to APIs or databases. Powered by [YepCode](https://yepcode.io)\n- <img height=\"12\" width=\"12\" src=\"https://www.yugabyte.com/favicon-16x16.png\" alt=\"YugabyteDB Logo\" /> **[YugabyteDB](https://github.com/yugabyte/yugabytedb-mcp-server)** -  MCP Server to interact with your [YugabyteDB](https://www.yugabyte.com/) database\n- <img height=\"12\" width=\"12\" src=\"https://avatars.githubusercontent.com/u/14069894\" alt=\"Yunxin Logo\" /> **[Yunxin](https://github.com/netease-im/yunxin-mcp-server)** - An MCP server that connects to Yunxin's IM/RTC/DATA Open-API\n- <img height=\"12\" width=\"12\" src=\"https://cdn.zapier.com/zapier/images/favicon.ico\" alt=\"Zapier Logo\" /> **[Zapier](https://zapier.com/mcp)** - Connect your AI Agents to 8,000 apps instantly.\n- <img height=\"12\" width=\"12\" src=\"https://www.zenable.app/zenable_light.svg\" alt=\"Zenable Logo\" /> **[Zenable](https://docs.zenable.io/integrations/mcp/getting-started)** - Clean up sloppy AI code and prevent vulnerabilities\n- **[ZenML](https://github.com/zenml-io/mcp-zenml)** - Interact with your MLOps and LLMOps pipelines through your [ZenML](https://www.zenml.io) MCP server\n- <img height=\"12\" width=\"12\" src=\"https://www.zine.ai/images/zine-logo.png\" alt=\"Zine Logo\" /> **[Zine](https://www.zine.ai)** - Your memory, everywhere AI goes. Think iPhoto for your knowledge - upload and curate. Like ChatGPT but portable - context that travels with you.\n- <img height=\"12\" width=\"12\" src=\"https://zizai.work/images/logo.jpg\" alt=\"ZIZAI Logo\" /> **[ZIZAI Recruitment](https://github.com/zaiwork/mcp)** - Interact with the next-generation intelligent recruitment platform for employees and employers, powered by [ZIZAI Recruitment](https://zizai.work).\n\n### 🌎 Community Servers\n\nA growing set of community-developed and maintained servers demonstrates various applications of MCP across different domains.\n\n> [!NOTE]\n> Community servers are **untested** and should be used at **your own risk**. They are not affiliated with or endorsed by Anthropic.\n\n- **[1mcpserver](https://github.com/particlefuture/1mcpserver)** - MCP of MCPs. Automatically discover, configure, and add MCP servers on your local machine.\n- **[1Panel](https://github.com/1Panel-dev/mcp-1panel)** - MCP server implementation that provides 1Panel interaction.\n- **[A2A](https://github.com/GongRzhe/A2A-MCP-Server)** - An MCP server that bridges the Model Context Protocol (MCP) with the Agent-to-Agent (A2A) protocol, enabling MCP-compatible AI assistants (like Claude) to seamlessly interact with A2A agents.\n- **[Ableton Live](https://github.com/Simon-Kansara/ableton-live-mcp-server)** - an MCP server to control Ableton Live.\n- **[Ableton Live](https://github.com/ahujasid/ableton-mcp)** (by ahujasid) - Ableton integration allowing prompt enabled music creation.\n- **[Actor Critic Thinking](https://github.com/aquarius-wing/actor-critic-thinking-mcp)** - Actor-critic thinking for performance evaluation\n- **[Adobe Commerce](https://github.com/rafaelstz/adobe-commerce-dev-mcp)** — MCP to interact with Adobe Commerce GraphQL API, including orders, products, customers, etc.\n- **[ADR Analysis](https://github.com/tosin2013/mcp-adr-analysis-server)** - AI-powered Architectural Decision Records (ADR) analysis server that provides architectural insights, technology stack detection, security checks, and TDD workflow enhancement for software development projects.\n- **[AgentBay](https://github.com/Michael98671/agentbay)** - An MCP server for providing serverless cloud infrastructure for AI agents.\n- **[AgentMode](https://www.agentmode.app)** - Connect to dozens of databases, data warehouses, Github & more, from a single MCP server.  Run the Docker image locally, in the cloud, or on-premise.\n- **[AI Agent Marketplace Index](https://github.com/AI-Agent-Hub/ai-agent-marketplace-index-mcp)** - MCP server to search more than 5000+ AI agents and tools of various categories from [AI Agent Marketplace Index](http://www.deepnlp.org/store/ai-agent) and monitor traffic of AI Agents.\n- **[AI Tasks](https://github.com/jbrinkman/valkey-ai-tasks)** - Let the AI manage complex plans with integrated task management and tracking tools. Supports STDIO, SSE and Streamable HTTP transports.\n- **[ai-Bible](https://github.com/AdbC99/ai-bible)** - Search the bible reliably and repeatably [ai-Bible Labs](https://ai-bible.com)\n- **[Airbnb](https://github.com/openbnb-org/mcp-server-airbnb)** - Provides tools to search Airbnb and get listing details.\n- **[Airflow](https://github.com/yangkyeongmo/mcp-server-apache-airflow)** - An MCP Server that connects to [Apache Airflow](https://airflow.apache.org/) using official python client.\n- **[Airtable](https://github.com/domdomegg/airtable-mcp-server)** - Read and write access to [Airtable](https://airtable.com/) databases, with schema inspection.\n- **[Airtable](https://github.com/felores/airtable-mcp)** - Airtable Model Context Protocol Server.\n- **[Algorand](https://github.com/GoPlausible/algorand-mcp)** - A comprehensive MCP server for tooling interactions (40+) and resource accessibility (60+) plus many useful prompts for interacting with the Algorand blockchain.\n- **[Amadeus](https://github.com/donghyun-chae/mcp-amadeus)** (by donghyun-chae) - An MCP server to access, explore, and interact with Amadeus Flight Offers Search API for retrieving detailed flight options, including airline, times, duration, and pricing data.\n- **[Amazon Ads](https://github.com/MarketplaceAdPros/amazon-ads-mcp-server)** - MCP Server that provides interaction capabilities with Amazon Advertising through [MarketplaceAdPros](https://marketplaceadpros.com)/\n- **[AniList](https://github.com/yuna0x0/anilist-mcp)** (by yuna0x0) - An MCP server to interact with AniList API, allowing you to search for anime and manga, retrieve user data, and manage your watchlist.\n- **[Anki](https://github.com/scorzeth/anki-mcp-server)** - An MCP server for interacting with your [Anki](https://apps.ankiweb.net) decks and cards.\n- **[Anki](https://github.com/nietus/anki-mcp)** - MCP server to run locally with Anki and Ankiconnect. Supports creating, updating, searching and filtering cards and decks. Include mass update and other advanced tools.\n- **[AntV Chart](https://github.com/antvis/mcp-server-chart)** - A Model Context Protocol server for generating 15+ visual charts using [AntV](https://github.com/antvis).\n- **[Any Chat Completions](https://github.com/pyroprompts/any-chat-completions-mcp)** - Interact with any OpenAI SDK Compatible Chat Completions API like OpenAI, Perplexity, Groq, xAI and many more.\n- **[Apache Gravitino(incubating)](https://github.com/datastrato/mcp-server-gravitino)** - Allow LLMs to explore metadata of structured data and unstructured data with Gravitino, and perform data governance tasks including tagging/classification.\n- **[API Lab MCP](https://github.com/atototo/api-lab-mcp)** - Transform Claude into your AI-powered API testing laboratory. Test, debug, and document APIs through natural conversation with authentication support, response validation, and performance metrics.\n- **[APIWeaver](https://github.com/GongRzhe/APIWeaver)** - An MCP server that dynamically creates MCP  servers from web API configurations. This allows you to easily integrate any REST API, GraphQL endpoint, or web service into an MCP-compatible tool that can be used by AI assistants like Claude.\n- **[Apollo IO MCP Server](https://github.com/AgentX-ai/apollo-io-mcp-server)** - apollo.io mcp server. Get/enrich contact data for people and organizations agentically.\n- **[Apple Books](https://github.com/vgnshiyer/apple-books-mcp)** - Interact with your library on Apple Books, manage your book collection, summarize highlights, notes, and much more.\n- **[Apple Calendar](https://github.com/Omar-v2/mcp-ical)** - An MCP server that allows you to interact with your macOS Calendar through natural language, including features such as event creation, modification, schedule listing, finding free time slots etc.\n- **[Apple Docs](https://github.com/kimsungwhee/apple-docs-mcp)** - A powerful Model Context Protocol (MCP) server that provides seamless access to Apple Developer Documentation through natural language queries. Search, explore, and get detailed information about Apple frameworks, APIs, sample code, and more directly in your AI-powered development environment.\n- **[Apple Script](https://github.com/peakmojo/applescript-mcp)** - MCP server that lets LLM run AppleScript code to to fully control anything on Mac, no setup needed.\n- **[APT MCP](https://github.com/GdMacmillan/apt-mcp-server)** - MCP server which runs debian package manager (apt) commands for you using ai agents.\n- **[Aranet4](https://github.com/diegobit/aranet4-mcp-server)** - MCP Server to manage your Aranet4 CO2 sensor. Fetch data and store in a local SQLite. Ask questions about historical data.\n- **[ArangoDB](https://github.com/ravenwits/mcp-server-arangodb)** - MCP Server that provides database interaction capabilities through [ArangoDB](https://arangodb.com/).\n- **[ArangoDB Graph](https://github.com/PCfVW/mcp-arangodb-async)** - Async-first Python architecture, wrapping the official [python-arango driver](https://github.com/arangodb/python-arango) with graph management capabilities, content conversion utilities (JSON, Markdown, YAML and Table), backup/restore functionality, and graph analytics capabilities; the 33 MCP tools use strict [Pydantic](https://github.com/pydantic/pydantic) validation.\n- **[Arduino](https://github.com/vishalmysore/choturobo)** - MCP Server that enables AI-powered robotics using Claude AI and Arduino (ESP32) for real-world automation and interaction with robots.\n- **[arXiv API](https://github.com/prashalruchiranga/arxiv-mcp-server)** - An MCP server that enables interacting with the arXiv API using natural language.\n- **[arxiv-latex-mcp](https://github.com/takashiishida/arxiv-latex-mcp)** - MCP server that fetches and processes arXiv LaTeX sources for precise interpretation of mathematical expressions in papers.\n- **[Atlassian](https://github.com/sooperset/mcp-atlassian)** - Interact with Atlassian Cloud products (Confluence and Jira) including searching/reading Confluence spaces/pages, accessing Jira issues, and project metadata.\n- **[Atlassian Server (by phuc-nt)](https://github.com/phuc-nt/mcp-atlassian-server)** - An MCP server that connects AI agents (Cline, Claude Desktop, Cursor, etc.) to Atlassian Jira & Confluence, enabling data queries and actions through the Model Context Protocol.\n- **[Attestable MCP](https://github.com/co-browser/attestable-mcp-server)** - An MCP server running inside a trusted execution environment (TEE) via Gramine, showcasing remote attestation using [RA-TLS](https://gramine.readthedocs.io/en/stable/attestation.html). This allows an MCP client to verify the server before connecting.\n- **[Audius](https://github.com/glassBead-tc/audius-mcp-atris)** - Audius + AI = Atris. Interact with fans, stream music, tip your favorite artists, and more on Audius: all through Claude.\n- **[AutoML](https://github.com/emircansoftware/MCP_Server_DataScience)** – An MCP server for data analysis workflows including reading, preprocessing, feature engineering, model selection, visualization, and hyperparameter tuning.\n- **[AX-Platform](https://github.com/AX-MCP/PaxAI?tab=readme-ov-file#mcp-setup-guides)** - AI Agent collaboration platform. Collaborate on tasks, share context, and coordinate workflows.\n- **[AWS](https://github.com/rishikavikondala/mcp-server-aws)** - Perform operations on your AWS resources using an LLM.\n- **[AWS Athena](https://github.com/lishenxydlgzs/aws-athena-mcp)** - An MCP server for AWS Athena to run SQL queries on Glue Catalog.\n- **[AWS Cognito](https://github.com/gitCarrot/mcp-server-aws-cognito)** - An MCP server that connects to AWS Cognito for authentication and user management.\n- **[AWS Cost Explorer](https://github.com/aarora79/aws-cost-explorer-mcp-server)** - Optimize your AWS spend (including Amazon Bedrock spend) with this MCP server by examining spend across regions, services, instance types and foundation models ([demo video](https://www.youtube.com/watch?v=WuVOmYLRFmI&feature=youtu.be)).\n- **[AWS Resources Operations](https://github.com/baryhuang/mcp-server-aws-resources-python)** - Run generated python code to securely query or modify any AWS resources supported by boto3.\n- **[AWS S3](https://github.com/aws-samples/sample-mcp-server-s3)** - A sample MCP server for AWS S3 that flexibly fetches objects from S3 such as PDF documents.\n- **[AWS SES](https://github.com/aws-samples/sample-for-amazon-ses-mcp)** Sample MCP Server for Amazon SES (SESv2). See [AWS blog post](https://aws.amazon.com/blogs/messaging - and-targeting/use-ai-agents-and-the-model-context-protocol-with-amazon-ses/) for more details.\n- **[Azure ADX](https://github.com/pab1it0/adx-mcp-server)** - Query and analyze Azure Data Explorer databases.\n- **[Azure DevOps](https://github.com/Vortiago/mcp-azure-devops)** - An MCP server that provides a bridge to Azure DevOps services, enabling AI assistants to query and manage work items.\n- **[Azure MCP Hub](https://github.com/Azure-Samples/mcp)** - A curated list of all MCP servers and related resources for Azure developers by **[Arun Sekhar](https://github.com/achandmsft)**\n- **[Azure OpenAI DALL-E 3 MCP Server](https://github.com/jacwu/mcp-server-aoai-dalle3)** - An MCP server for Azure OpenAI DALL-E 3 service to generate image from text.\n- **[Azure Wiki Search](https://github.com/coder-linping/azure-wiki-search-server)** - An MCP that enables AI to query the wiki hosted on Azure Devops Wiki.\n- **[Baidu AI Search](https://github.com/baidubce/app-builder/tree/master/python/mcp_server/ai_search)** - Web search with Baidu Cloud's AI Search\n- **[BambooHR MCP](https://github.com/encoreshao/bamboohr-mcp)** - An MCP server that interfaces with the BambooHR APIs, providing access to employee data, time tracking, and HR management features.\n- **[Base Free USDC Transfer](https://github.com/magnetai/mcp-free-usdc-transfer)** - Send USDC on [Base](https://base.org) for free using Claude AI! Built with [Coinbase CDP](https://docs.cdp.coinbase.com/mpc-wallet/docs/welcome).\n- **[Basic Memory](https://github.com/basicmachines-co/basic-memory)** - Local-first knowledge management system that builds a semantic graph from Markdown files, enabling persistent memory across conversations with LLMs.\n- **[BGG MCP](https://github.com/kkjdaniel/bgg-mcp)** (by kkjdaniel) - MCP to enable interaction with the BoardGameGeek API via AI tooling.\n- **[Bible](https://github.com/trevato/bible-mcp)** - Add biblical context to your generative AI applications.\n- **[BigQuery](https://github.com/LucasHild/mcp-server-bigquery)** (by LucasHild) - This server enables LLMs to inspect database schemas and execute queries on BigQuery.\n- **[BigQuery](https://github.com/ergut/mcp-bigquery-server)** (by ergut) - Server implementation for Google BigQuery integration that enables direct BigQuery database access and querying capabilities\n- **[Bilibili](https://github.com/wangshunnn/bilibili-mcp-server)** - This MCP server provides tools to fetch Bilibili user profiles, video metadata, search videos, and more.\n- **[Binance](https://github.com/ethancod1ng/binance-mcp-server)** - Cryptocurrency trading and market data access through Binance API integration.\n- **[Binance](https://github.com/AnalyticAce/BinanceMCPServer)** (by dosseh shalom) - Unofficial tools and server implementation for Binance's Model Context Protocol (MCP). Designed to support developers building crypto trading AI Agents.\n- **[Bing Web Search API](https://github.com/leehanchung/bing-search-mcp)** (by hanchunglee) - Server implementation for Microsoft Bing Web Search API.\n- **[BioMCP](https://github.com/genomoncology/biomcp)** (by imaurer) - Biomedical research assistant server providing access to PubMed, ClinicalTrials.gov, and MyVariant.info.\n- **[bioRxiv](https://github.com/JackKuo666/bioRxiv-MCP-Server)** - 🔍 Enable AI assistants to search and access bioRxiv papers through a simple MCP interface.\n- **[Bitable MCP](https://github.com/lloydzhou/bitable-mcp)** (by lloydzhou) - MCP server provides access to Lark Bitable through the Model Context Protocol. It allows users to interact with Bitable tables using predefined tools.\n- **[Blender](https://github.com/ahujasid/blender-mcp)** (by ahujasid) - Blender integration allowing prompt enabled 3D scene creation, modeling and manipulation.\n- **[Blender MCP](https://github.com/pranav-deshmukh/blender-mcp)** - MCP server to create professional like 3d scenes on blender using natural language.\n- **[Blockbench MCP Plugin](https://github.com/jasonjgardner/blockbench-mcp-plugin)** (by jasonjgardner) - Blockbench plugin to connect AI agents to Blockbench's JavaScript API. Allows for creating and editing 3D models or pixel art textures with AI in Blockbench.\n- **[Blockchain MCP](https://github.com/tatumio/blockchain-mcp)** - MCP Server for Blockchain Data from **[Tatum](http://tatum.io/mcp)** that instantly unlocks blockchain access for your AI agents. This official Tatum MCP server connects to any LLM in seconds.\n- **[Bluesky](https://github.com/semioz/bluesky-mcp)** (by semioz) - An MCP server for Bluesky, a decentralized social network. It enables automated interactions with the AT Protocol, supporting features like posting, liking, reposting, timeline management, and profile operations.\n- **[Bluetooth MCP Server](https://github.com/Hypijump31/bluetooth-mcp-server)** - Control Bluetooth devices and manage connections through natural language commands, including device discovery, pairing, and audio controls.\n- **[BNBChain MCP](https://github.com/bnb-chain/bnbchain-mcp)** - An MCP server for interacting with BSC, opBNB, and the Greenfield blockchain.\n- **[Braintree](https://github.com/QuentinCody/braintree-mcp-server)** - Unofficial PayPal Braintree payment gateway MCP Server for AI agents to process payments, manage customers, and handle transactions securely.\n- **[Brazilian Law](https://github.com/pdmtt/brlaw_mcp_server/)** (by pdmtt) - Agent-driven research on Brazilian law using official sources.\n- **[BreakoutRoom](https://github.com/agree-able/room-mcp)** - Agents accomplishing goals together in p2p rooms\n- **[Browser MCP](https://github.com/bytedance/UI-TARS-desktop/tree/main/packages/agent-infra/mcp-servers/browser)** (by UI-TARS) - A fast, lightweight MCP server that empowers LLMs with browser automation via Puppeteer’s structured accessibility data, featuring optional vision mode for complex visual understanding and flexible, cross-platform configuration.\n- **[browser-use](https://github.com/co-browser/browser-use-mcp-server)** (by co-browser) - browser-use MCP server with dockerized playwright + chromium + vnc. supports stdio & resumable http.\n- **[BrowserLoop](https://github.com/mattiasw/browserloop)** - An MCP server for taking screenshots of web pages using Playwright. Supports high-quality capture with configurable formats, viewport sizes, cookie-based authentication, and both full page and element-specific screenshots.\n- **[Bsc-mcp](https://github.com/TermiX-official/bsc-mcp)** The first MCP server that serves as the bridge between AI and BNB Chain, enabling AI agents to execute complex on-chain operations through seamless integration with the BNB Chain, including transfer, swap, launch, security check on any token and even more.\n- **[BugBug MCP Server](https://github.com/simplypixi/bugbug-mcp-server)** - Unofficial MCP server for BugBug API.\n- **[BVG MCP Server - (Unofficial) ](https://github.com/svkaizoku/mcp-bvg)** - Unofficial MCP server for Berliner Verkehrsbetriebe Api.\n- **[Bybit](https://github.com/ethancod1ng/bybit-mcp-server)** - A Model Context Protocol (MCP) server for integrating AI assistants with Bybit cryptocurrency exchange APIs, enabling automated trading, market data access, and account management.\n- **[CAD-MCP](https://github.com/daobataotie/CAD-MCP#)** (by daobataotie) - Drawing CAD(Line,Circle,Text,Annotation...) through MCP server, supporting mainstream CAD software.\n- **[Calculator](https://github.com/githejie/mcp-server-calculator)** - This server enables LLMs to use calculator for precise numerical calculations.\n- **[CalDAV MCP](https://github.com/dominik1001/caldav-mcp)** - A CalDAV MCP server to expose calendar operations as tools for AI assistants.\n- **[Calendly-mcp-server](https://github.com/meAmitPatil/calendly-mcp-server)** - Open source calendly mcp server.\n- **[Catalysis Hub](https://github.com/QuentinCody/catalysishub-mcp-server)** - Unofficial MCP server for searching and retrieving scientific data from the Catalysis Hub database, providing access to computational catalysis research and surface reaction data.\n- **[CCTV VMS MCP](https://github.com/jyjune/mcp_vms)** - A Model Context Protocol (MCP) server designed to connect to a CCTV recording program (VMS) to retrieve recorded and live video streams. It also provides tools to control the VMS software, such as showing live or playback dialogs for specific channels at specified times.\n- **[CFBD API](https://github.com/lenwood/cfbd-mcp-server)** - An MCP server for the [College Football Data API](https://collegefootballdata.com/).\n- **[ChatMCP](https://github.com/AI-QL/chat-mcp)** – An Open Source Cross-platform GUI Desktop application compatible with Linux, macOS, and Windows, enabling seamless interaction with MCP servers across dynamically selectable LLMs, by **[AIQL](https://github.com/AI-QL)**\n- **[ChatSum](https://github.com/mcpso/mcp-server-chatsum)** - Query and Summarize chat messages with LLM. by [mcpso](https://mcp.so)\n- **[Chess.com](https://github.com/pab1it0/chess-mcp)** - Access Chess.com player data, game records, and other public information through standardized MCP interfaces, allowing AI assistants to search and analyze chess information.\n- **[ChessPal Chess Engine (stockfish)](https://github.com/wilson-urdaneta/chesspal-mcp-engine)** - A Stockfish-powered chess engine exposed as an MCP server. Calculates best moves and supports both HTTP/SSE and stdio transports.\n- **[Chroma](https://github.com/privetin/chroma)** - Vector database server for semantic document search and metadata filtering, built on Chroma\n- **[Chrome history](https://github.com/vincent-pli/chrome-history-mcp)** - Talk with AI about your browser history, get fun ^_^\n- **[CIViC](https://github.com/QuentinCody/civic-mcp-server)** - MCP server for the Clinical Interpretation of Variants in Cancer (CIViC) database, providing access to clinical variant interpretations and genomic evidence for cancer research.\n- **[Claude Thread Continuity](https://github.com/peless/claude-thread-continuity)** - Persistent memory system enabling Claude Desktop conversations to resume with full context across sessions. Maintains conversation history, project states, and user preferences for seamless multi-session workflows.\n- **[ClaudePost](https://github.com/ZilongXue/claude-post)** - ClaudePost enables seamless email management for Gmail, offering secure features like email search, reading, and sending.\n- **[CLDGeminiPDF Analyzer](https://github.com/tfll37/CLDGeminiPDF-Analyzer)** - MCP server tool enabling sharing large PDF files to Google LLMs via API for further/additional analysis and response retrieval to Claude Desktop.\n- **[ClearML MCP](https://github.com/prassanna-ravishankar/clearml-mcp)** - Get comprehensive ML experiment context and analysis directly from [ClearML](https://clear.ml) in your AI conversations.\n- **[ClickUp](https://github.com/TaazKareem/clickup-mcp-server)** - MCP server for ClickUp task management, supporting task creation, updates, bulk operations, and markdown descriptions.\n- **[Cloudinary](https://github.com/felores/cloudinary-mcp-server)** - Cloudinary Model Context Protocol Server to upload media to Cloudinary and get back the media link and details.\n- **[CockroachDB](https://github.com/amineelkouhen/mcp-cockroachdb)** - MCP server enabling AI agents and LLMs to manage, monitor, and query **[CockroachDB](https://www.cockroachlabs.com/)** using natural language.\n- **[CockroachDB MCP Server](https://github.com/viragtripathi/cockroachdb-mcp-server)** – Full - featured MCP implementation built with FastAPI and CockroachDB. Supports schema bootstrapping, JSONB storage, LLM-ready CLI, and optional `/debug` endpoints.\n- **[code-assistant](https://github.com/stippi/code-assistant)** - A coding assistant MCP server that allows to explore a code-base and make changes to code. Should be used with trusted repos only (insufficient protection against prompt injections).\n- **[code-context-provider-mcp](https://github.com/AB498/code-context-provider-mcp)** - MCP server that provides code context and analysis for AI assistants. Extracts directory structure and code symbols using WebAssembly Tree-sitter parsers without Native Dependencies.\n- **[code-executor](https://github.com/bazinga012/mcp_code_executor)** - An MCP server that allows LLMs to execute Python code within a specified Conda environment.\n- **[code-sandbox-mcp](https://github.com/Automata-Labs-team/code-sandbox-mcp)** - An MCP server to create secure code sandbox environment for executing code within Docker containers.\n- **[cognee-mcp](https://github.com/topoteretes/cognee/tree/main/cognee-mcp)** - GraphRAG memory server with customizable ingestion, data processing and search\n- **[coin_api_mcp](https://github.com/longmans/coin_api_mcp)** - Provides access to [coinmarketcap](https://coinmarketcap.com/) cryptocurrency data.\n- **[CoinMarketCap](https://github.com/shinzo-labs/coinmarketcap-mcp)** - Implements the complete [CoinMarketCap](https://coinmarketcap.com/) API for accessing cryptocurrency market data, exchange information, and other blockchain-related metrics.\n- **[commands](https://github.com/g0t4/mcp-server-commands)** - Run commands and scripts. Just like in a terminal.\n- **[Companies House MCP](https://github.com/stefanoamorelli/companies-house-mcp)** (by Stefano Amorelli) - MCP server to connect with the UK Companies House API.\n- **[computer-control-mcp](https://github.com/AB498/computer-control-mcp)** - MCP server that provides computer control capabilities, like mouse, keyboard, OCR, etc. using PyAutoGUI, RapidOCR, ONNXRuntime Without External Dependencies.\n- **[Computer-Use - Remote MacOS Use](https://github.com/baryhuang/mcp-remote-macos-use)** - Open-source out-of-the-box alternative to OpenAI Operator, providing a full desktop experience and optimized for using remote macOS machines as autonomous AI agents.\n- **[Congress.gov API](https://github.com/AshwinSundar/congress_gov_mcp)** - An MCP server to interact with real-time data from the Congress.gov API, which is the official API for the United States Congress.\n- **[consul-mcp](https://github.com/kocierik/consul-mcp-server)** - A consul MCP server for service management, health check and Key-Value Store\n- **[consult7](https://github.com/szeider/consult7)** - Analyze large codebases and document collections using high-context models via OpenRouter, OpenAI, or Google AI -- very useful, e.g., with Claude Code\n- **[Contentful-mcp](https://github.com/ivo-toby/contentful-mcp)** - Read, update, delete, publish content in your [Contentful](https://contentful.com) space(s) from this MCP Server.\n- **[Context Crystallizer](https://github.com/hubertciebiada/context-crystallizer)** - AI Context Engineering tool that transforms large repositories into crystallized, AI-consumable knowledge through systematic analysis and optimization.\n- **[MCP Context Provider](https://github.com/doobidoo/MCP-Context-Provider)** - Static server that provides AI models with persistent tool-specific context and rules, preventing context loss between chat sessions and enabling consistent behavior across interactions.\n- **[context-portal](https://github.com/GreatScottyMac/context-portal)** - Context Portal (ConPort) is a memory bank database system that effectively builds a project-specific knowledge graph, capturing entities like decisions, progress, and architecture, along with their relationships. This serves as a powerful backend for Retrieval Augmented Generation (RAG), enabling AI assistants to access precise, up-to-date project information.\n- **[cplusplus-mcp](https://github.com/kandrwmrtn/cplusplus_mcp)** - Semantic C++ code analysis using libclang. Enables Claude to understand C++ codebases through AST parsing rather than text search - find classes, navigate inheritance, trace function calls, and explore code relationships.\n- **[CreateveAI Nexus](https://github.com/spgoodman/createveai-nexus-server)** - Open-Source Bridge Between AI Agents and Enterprise Systems, with simple custom API plug-in capabilities (including close compatibility with ComfyUI nodes), support for Copilot Studio's MCP agent integations, and support for Azure deployment in secure environments with secrets stored in Azure Key Vault, as well as straightforward on-premises deployment.\n- **[CRASH](https://github.com/nikkoxgonzales/crash-mcp)** - MCP server for structured, iterative reasoning and thinking with flexible validation, confidence tracking, revision mechanisms, and branching support.\n- **[Creatify](https://github.com/TSavo/creatify-mcp)** - MCP Server that exposes Creatify AI API capabilities for AI video generation, including avatar videos, URL-to-video conversion, text-to-speech, and AI-powered editing tools.\n- **[Cronlytic](https://github.com/Cronlytic/cronlytic-mcp-server)** - Create CRUD operations for serverless cron jobs through [Cronlytic](https://cronlytic.com) MCP Server\n- **[crypto-feargreed-mcp](https://github.com/kukapay/crypto-feargreed-mcp)**  -  Providing real-time and historical Crypto Fear & Greed Index data.\n- **[crypto-indicators-mcp](https://github.com/kukapay/crypto-indicators-mcp)**  -  An MCP server providing a range of cryptocurrency technical analysis indicators and strategies.\n- **[crypto-sentiment-mcp](https://github.com/kukapay/crypto-sentiment-mcp)**  -  An MCP server that delivers cryptocurrency sentiment analysis to AI agents.\n- **[cryptopanic-mcp-server](https://github.com/kukapay/cryptopanic-mcp-server)** - Providing latest cryptocurrency news to AI agents, powered by CryptoPanic.\n- **[CSV Editor](https://github.com/santoshray02/csv-editor)** - Comprehensive CSV processing with 40+ operations for data manipulation, analysis, and validation. Features auto-save, undo/redo, and handles GB+ files. Built with FastMCP & Pandas.\n- **[Cursor MCP Installer](https://github.com/matthewdcage/cursor-mcp-installer)** - A tool to easily install and configure other MCP servers within Cursor IDE, with support for npm packages, local directories, and Git repositories.\n- **[CVE Intelligence Server](https://github.com/gnlds/mcp-cve-intelligence-server-lite)** – Provides vulnerability intelligence via multi - source CVE data, essential exploit discovery, and EPSS risk scoring through the MCP. Useful for security research, automation, and agent workflows.\n- **[D365FO](https://github.com/mafzaal/d365fo-client)** - A comprehensive MCP server for Microsoft Dynamics 365 Finance & Operations (D365 F&O) that provides easy access to OData endpoints, metadata operations, label management, and AI assistant integration.\n- **[Dagster](https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-dg-cli)** - An MCP server to easily build data pipelines using [Dagster](https://dagster.io/).\n- **[Dappier](https://github.com/DappierAI/dappier-mcp)** - Connect LLMs to real-time, rights-cleared, proprietary data from trusted sources. Access specialized models for Real-Time Web Search, News, Sports, Financial Data, Crypto, and premium publisher content. Explore data models at [marketplace.dappier.com](https://marketplace.dappier.com/marketplace).\n- **[Data Exploration](https://github.com/reading-plus-ai/mcp-server-data-exploration)** - MCP server for autonomous data exploration on .csv-based datasets, providing intelligent insights with minimal effort. NOTE: Will execute arbitrary Python code on your machine, please use with caution!\n- **[Databricks](https://github.com/JordiNeil/mcp-databricks-server)** - Allows LLMs to run SQL queries, list and get details of jobs executions in a Databricks account.\n- **[Databricks Genie](https://github.com/yashshingvi/databricks-genie-MCP)** - A server that connects to the Databricks Genie, allowing LLMs to ask natural language questions, run SQL queries, and interact with Databricks conversational agents.\n- **[Databricks Smart SQL](https://github.com/RafaelCartenet/mcp-databricks-server)** - Leveraging Databricks Unity Catalog metadata, perform smart efficient SQL queries to solve Ad-hoc queries and explore data.\n- **[DataCite](https://github.com/QuentinCody/datacite-mcp-server)** - Unofficial MCP server for DataCite, providing access to research data and publication metadata through DataCite's REST API and GraphQL interface for scholarly research discovery.\n- **[Datadog](https://github.com/GeLi2001/datadog-mcp-server)** - Datadog MCP Server for application tracing, monitoring, dashboard, incidents queries built on official datadog api.\n- **[Dataset Viewer](https://github.com/privetin/dataset-viewer)** - Browse and analyze Hugging Face datasets with features like search, filtering, statistics, and data export\n- **[DataWorks](https://github.com/aliyun/alibabacloud-dataworks-mcp-server)** - A Model Context Protocol (MCP) server that provides tools for AI, allowing it to interact with the [DataWorks](https://www.alibabacloud.com/help/en/dataworks/) Open API through a standardized interface. This implementation is based on the Alibaba Cloud Open API and enables AI agents to perform cloud resources operations seamlessly.\n- **[Data4library](https://github.com/isnow890/data4library-mcp)** (by isnow890) - MCP server for Korea's Library Information Naru API, providing comprehensive access to public library data, book searches, loan status, reading statistics, and GPS-based nearby library discovery across South Korea.\n\n- **[DaVinci Resolve](https://github.com/samuelgursky/davinci-resolve-mcp)** - MCP server integration for DaVinci Resolve providing powerful tools for video editing, color grading, media management, and project control.\n- **[DBHub](https://github.com/bytebase/dbhub/)** - Universal database MCP server connecting to MySQL, MariaDB, PostgreSQL, and SQL Server.\n- **[Deebo](https://github.com/snagasuri/deebo-prototype)** – Agentic debugging MCP server that helps AI coding agents delegate and fix hard bugs through isolated multi-agent hypothesis testing.\n- **[Deep Research](https://github.com/reading-plus-ai/mcp-server-deep-research)** - Lightweight MCP server offering Grok/OpenAI/Gemini/Perplexity-style automated deep research exploration and structured reporting.\n- **[DeepSeek MCP Server](https://github.com/DMontgomery40/deepseek-mcp-server)** - Model Context Protocol server integrating DeepSeek's advanced language models, in addition to [other useful API endpoints](https://github.com/DMontgomery40/deepseek-mcp-server?tab=readme-ov-file#features)\n- **[deepseek-thinker-mcp](https://github.com/ruixingshi/deepseek-thinker-mcp)** - A MCP (Model Context Protocol) provider Deepseek reasoning content to MCP-enabled AI Clients, like Claude Desktop. Supports access to Deepseek's thought processes from the Deepseek API service or from a local Ollama server.\n- **[Deepseek_R1](https://github.com/66julienmartin/MCP-server-Deepseek_R1)** - A Model Context Protocol (MCP) server implementation connecting Claude Desktop with DeepSeek's language models (R1/V3)\n- **[Depyler](https://github.com/paiml/depyler/blob/main/docs/mcp-integration.md)** - Energy-efficient Python-to-Rust transpiler with progressive verification, enabling AI assistants to convert Python code to safe, performant Rust while reducing energy consumption by 75-85%.\n- **[deploy-mcp](https://github.com/alexpota/deploy-mcp)** - Universal deployment tracker for AI assistants with live status badges and deployment monitoring.\n- **[Descope](https://github.com/descope-sample-apps/descope-mcp-server)** - An MCP server to integrate with [Descope](https://descope.com) to search audit logs, manage users, and more.\n- **[DesktopCommander](https://github.com/wonderwhy-er/DesktopCommanderMCP)** - Let AI edit and manage files on your computer, run terminal commands, and connect to remote servers via SSH - all powered by one of the most popular local MCP servers.\n- **[Devcontainer](https://github.com/AI-QL/mcp-devcontainers)** - An MCP server for devcontainer to generate and configure development containers directly from devcontainer configuration files.\n- **[DevDb](https://github.com/damms005/devdb-vscode?tab=readme-ov-file#mcp-configuration)** - An MCP server that runs right inside the IDE, for connecting to MySQL, Postgres, SQLite, and MSSQL databases.\n- **[DevOps AI Toolkit](https://github.com/vfarcic/dot-ai)** - AI-powered development productivity platform that enhances software development workflows through intelligent automation and AI-driven assistance.\n- **[DevOps-MCP](https://github.com/wangkanai/devops-mcp)** - Dynamic Azure DevOps MCP server with directory-based authentication switching, supporting work items, repositories, builds, pipelines, and multi-project management with local configuration files.\n- **[DGIdb](https://github.com/QuentinCody/dgidb-mcp-server)** - MCP server for the Drug Gene Interaction Database (DGIdb), providing access to drug-gene interaction data, druggable genome information, and pharmacogenomics research.\n- **[Dicom](https://github.com/ChristianHinge/dicom-mcp)** - An MCP server to query and retrieve medical images and for parsing and reading dicom-encapsulated documents (pdf etc.).\n- **[Dify](https://github.com/YanxingLiu/dify-mcp-server)** - A simple implementation of an MCP server for dify workflows.\n- **[Discogs](https://github.com/cswkim/discogs-mcp-server)** - An MCP server that connects to the Discogs API for interacting with your music collection.\n- **[Discord](https://github.com/v-3/discordmcp)** - An MCP server to connect to Discord guilds through a bot and read and write messages in channels\n- **[Discord](https://github.com/SaseQ/discord-mcp)** - An MCP server, which connects to Discord through a bot, and provides comprehensive integration with Discord.\n- **[Discord](https://github.com/Klavis-AI/klavis/tree/main/mcp_servers/discord)** - For Discord API integration by Klavis AI\n- **[Discourse](https://github.com/AshDevFr/discourse-mcp-server)** - An MCP server to search Discourse posts on a Discourse forum.\n- **[DocBase](https://help.docbase.io/posts/3925317)** - Official MCP server for DocBase API integration, enabling post management, user collaboration, group administration, and more.\n- **[Docker](https://github.com/ckreiling/mcp-server-docker)** - Integrate with Docker to manage containers, images, volumes, and networks.\n- **[Docker](https://github.com/0xshariq/docker-mcp-server)** - Docker MCP Server provides advanced, unified Docker management via CLI and MCP workflows, supporting containers, images, volumes, networks, and orchestration.\n- **[Docs](https://github.com/da1z/docsmcp)** - Enable documentation access for the AI agent, supporting llms.txt and other remote or local files.\n- **[documcp](https://github.com/tosin2013/documcp)** - An MCP server for intelligent document processing and management, supporting multiple formats and document operations.\n- **[Docy](https://github.com/oborchers/mcp-server-docy)** - Docy gives your AI direct access to the technical documentation it needs, right when it needs it. No more outdated information, broken links, or rate limits - just accurate, real-time documentation access for more precise coding assistance.\n- **[Dodo Payments](https://github.com/dodopayments/dodopayments-node/tree/main/packages/mcp-server)** - Enables AI agents to securely perform payment operations via a lightweight, serverless-compatible interface to the [Dodo Payments](https://dodopayments.com) API.\n- **[Domain Tools](https://github.com/deshabhishek007/domain-tools-mcp-server)** - A Model Context Protocol (MCP) server for comprehensive domain analysis: WHOIS, DNS records, and DNS health checks.\n- **[DPLP](https://github.com/szeider/mcp-dblp)**  - Searches the [DBLP](https://dblp.org) computer science bibliography database.\n- **[Druid MCP Server](https://github.com/iunera/druid-mcp-server)** - STDIO/SEE MCP Server for Apache Druid by [iunera](https://www.iunera.com) that provides extensive tools, resources, and prompts for managing and analyzing Druid clusters.\n- **[Drupal](https://github.com/Omedia/mcp-server-drupal)** - Server for interacting with [Drupal](https://www.drupal.org/project/mcp) using STDIO transport layer.\n- **[dune-analytics-mcp](https://github.com/kukapay/dune-analytics-mcp)** -  A mcp server that bridges Dune Analytics data to AI agents.\n- **[DynamoDB-Toolbox](https://www.dynamodbtoolbox.com/docs/databases/actions/mcp-toolkit)** - Leverages your Schemas and Access Patterns to interact with your [DynamoDB](https://aws.amazon.com/dynamodb) Database using natural language.\n- **[eBook-mcp](https://github.com/onebirdrocks/ebook-mcp)** - A lightweight MCP server that allows LLMs to read and interact with your personal PDF and EPUB ebooks. Ideal for building AI reading assistants or chat-based ebook interfaces.\n- **[ECharts MCP Server](https://github.com/hustcc/mcp-echarts)** - Generate visual charts using ECharts with AI MCP dynamically, used for chart generation and data analysis.\n- **[EDA MCP Server](https://github.com/NellyW8/mcp-EDA)** - A comprehensive Model Context Protocol server for Electronic Design Automation tools, enabling AI assistants to synthesize Verilog with Yosys, simulate designs with Icarus Verilog, run complete ASIC flows with OpenLane, and view results with GTKWave and KLayout.\n- **[EdgeOne Pages MCP](https://github.com/TencentEdgeOne/edgeone-pages-mcp)** - An MCP service for deploying HTML content to EdgeOne Pages and obtaining a publicly accessible URL.\n- **[Edwin](https://github.com/edwin-finance/edwin/tree/main/examples/mcp-server)** - MCP server for edwin SDK - enabling AI agents to interact with DeFi protocols across EVM, Solana and other blockchains.\n- **[eechat](https://github.com/Lucassssss/eechat)** - An open-source, cross-platform desktop application that seamlessly connects with MCP servers, across Linux, macOS, and Windows.\n- **[Elasticsearch](https://github.com/cr7258/elasticsearch-mcp-server)** - MCP server implementation that provides Elasticsearch interaction.\n- **[ElevenLabs](https://github.com/mamertofabian/elevenlabs-mcp-server)** - A server that integrates with ElevenLabs text-to-speech API capable of generating full voiceovers with multiple voices.\n- **[Email](https://github.com/Shy2593666979/mcp-server-email)** - This server enables users to send emails through various email providers, including Gmail, Outlook, Yahoo, Sina, Sohu, 126, 163, and QQ Mail. It also supports attaching files from specified directories, making it easy to upload attachments along with the email content.\n- **[Email SMTP](https://github.com/egyptianego17/email-mcp-server)** - A simple MCP server that lets your AI agent send emails and attach files through SMTP.\n- **[Enhance Prompt](https://github.com/FelixFoster/mcp-enhance-prompt)** - An MCP service for enhance you prompt.\n- **[Entrez](https://github.com/QuentinCody/entrez-mcp-server)** - Unofficial MCP server for NCBI Entrez databases, providing access to PubMed articles, gene information, protein data, and other biomedical research resources through NCBI's E-utilities API.\n- **[Ergo Blockchain MCP](https://github.com/marctheshark3/ergo-mcp)** -An MCP server to integrate Ergo Blockchain Node and Explorer APIs for checking address balances, analyzing transactions, viewing transaction history, performing forensic analysis of addresses, searching for tokens, and monitoring network status.\n- **[ESP MCP Server](https://github.com/horw/esp-mcp)** - An MCP server that integrates ESP IDF commands like building and flashing code for ESP Microcontrollers using an LLM.\n- **[Eunomia](https://github.com/whataboutyou-ai/eunomia-MCP-server)** - Extension of the Eunomia framework that connects Eunomia instruments with MCP servers\n- **[Everything Search](https://github.com/mamertofabian/mcp-everything-search)** - Fast file searching capabilities across Windows (using [Everything SDK](https://www.voidtools.com/support/everything/sdk/)), macOS (using mdfind command), and Linux (using locate/plocate command).\n- **[EVM MCP Server](https://github.com/mcpdotdirect/evm-mcp-server)** - Comprehensive blockchain services for 30+ EVM networks, supporting native tokens, ERC20, NFTs, smart contracts, transactions, and ENS resolution.\n- **[Excel](https://github.com/haris-musa/excel-mcp-server)** - Excel manipulation including data reading/writing, worksheet management, formatting, charts, and pivot table.\n- **[Excel to JSON MCP by WTSolutions](https://github.com/he-yang/excel-to-json-mcp)** - MCP Server providing a standardized interface for converting (1) Excel or CSV data into JSON format ;(2) Excel(.xlsx) file into Structured JSON.\n- **[Extended Memory](https://github.com/ssmirnovpro/extended-memory-mcp)** - Persistent memory across Claude conversations with multi-project support, automatic importance scoring, and tag-based organization. Production-ready with 400+ tests.\n- **[F1](https://github.com/AbhiJ2706/f1-mcp/tree/main)** - Access to Formula 1 data including race results, driver information, lap times, telemetry, and circuit details.\n- **[Fabric MCP](https://github.com/aci-labs/ms-fabric-mcp)** - Microsoft Fabric MCP server to accelerate working in your Fabric Tenant with the help of your favorite LLM models.\n- **[Fabric Real-Time Intelligence MCP](https://github.com/Microsoft/fabric-rti-mcp)** - Official Microsoft Fabric RTI server to accelerate working with Eventhouse, Azure Data Explorer(Kusto), Eventstreams and other RTI items using your favorite LLM models.\n- **[fabric-mcp-server](https://github.com/adapoet/fabric-mcp-server)** - The fabric-mcp-server is an MCP server that integrates [Fabric](https://github.com/danielmiessler/fabric) patterns with [Cline](https://cline.bot/), exposing them as tools for AI-driven task execution and enhancing Cline's capabilities.\n- **[Fal MCP Server](https://github.com/raveenb/fal-mcp-server)** - Generate AI images, videos, and music using Fal.ai models (FLUX, Stable Diffusion, MusicGen) directly in Claude\n- **[Facebook Ads](https://github.com/gomarble-ai/facebook-ads-mcp-server)** - MCP server acting as an interface to the Facebook Ads, enabling programmatic access to Facebook Ads data and management features.\n- **[Facebook Ads 10xeR](https://github.com/fortytwode/10xer)** - Advanced Facebook Ads MCP server with enhanced creative insights, multi-dimensional breakdowns, and comprehensive ad performance analytics.\n- **[Facebook Ads Library](https://github.com/trypeggy/facebook-ads-library-mcp)** - Get any answer from the Facebook Ads Library, conduct deep research including messaging, creative testing and comparisons in seconds.\n- **[Fantasy PL](https://github.com/rishijatia/fantasy-pl-mcp)** - Give your coding agent direct access to up-to date Fantasy Premier League data\n- **[Fastmail MCP](https://github.com/MadLlama25/fastmail-mcp)** - Access Fastmail via JMAP: list/search emails, send and move mail, handle attachments/threads, plus contacts and calendar tools.\n- **[fastn.ai – Unified API MCP Server](https://github.com/fastnai/mcp-fastn)** - A remote, dynamic MCP server with a unified API that connects to 1,000+ tools, actions, and workflows, featuring built-in authentication and monitoring.\n- **[FDIC BankFind MCP Server - (Unofficial)](https://github.com/clafollett/fdic-bank-find-mcp-server)** - The is a MCPserver that brings the power of FDIC BankFind APIs straight to your AI tools and workflows. Structured U.S. banking data, delivered with maximum vibes. 😎📊\n- **[FPE Demo MCP](https://github.com/Horizon-Digital-Engineering/fpe-demo-mcp)** - FF3 Format Preserving Encryption with authentication patterns for secure data protection in LLM workflows.\n- **[Federal Reserve Economic Data (FRED)](https://github.com/stefanoamorelli/fred-mcp-server)** (by Stefano Amorelli) - Community developed MCP server to interact with the Federal Reserve Economic Data.\n- **[Fetch](https://github.com/zcaceres/fetch-mcp)** - A server that flexibly fetches HTML, JSON, Markdown, or plaintext.\n- **[Feyod](https://github.com/jeroenvdmeer/feyod-mcp)** - A server that answers questions about football matches, and specialised in the football club Feyenoord.\n- **[Fast Filesystem](https://github.com/efforthye/fast-filesystem-mcp)** - Advanced filesystem operations with large file handling capabilities and Claude-optimized features. Provides fast file reading/writing, sequential reading for large files, directory operations, file search, and streaming writes with backup & recovery.\n- **[FHIR](https://github.com/wso2/fhir-mcp-server)** - A Model Context Protocol server that provides seamless, standardized access to Fast Healthcare Interoperability Resources (FHIR) data from any compatible FHIR server. Designed for easy integration with AI tools, developer workflows, and healthcare applications, it enables natural language and programmatic search, retrieval, and analysis of clinical data.\n- **[Fibaro HC3](https://github.com/coding-sailor/mcp-server-hc3)** - MCP server for Fibaro Home Center 3 smart home systems.\n- **[Figma](https://github.com/GLips/Figma-Context-MCP)** - Give your coding agent direct access to Figma file data, helping it one-shot design implementation.\n- **[Figma](https://github.com/paulvandermeijs/figma-mcp)** - A blazingly fast MCP server to read and export your Figma design files.\n- **[Figma to Flutter](https://github.com/mhmzdev/figma-flutter-mcp)** - Write down clean and better Flutter code from Figma design tokens and enrich nodes data in Flutter terminology.\n- **[Files](https://github.com/flesler/mcp-files)** - Enables agents to quickly find and edit code in a codebase with surgical precision. Find symbols, edit them everywhere.\n- **[FileSystem Server](https://github.com/Oncorporation/filesystem_server)** - Local MCP server for Visual Studio 2022 that provides code-workspace functionality by giving AI agents selective access to project folders and files\n- **[finmap.org](https://github.com/finmap-org/mcp-server)** MCP server provides comprehensive historical data from the US, UK, Russian and Turkish stock exchanges. Access sectors, tickers, company profiles, market cap, volume, value, and trade counts, as well as treemap and histogram visualizations.\n- **[Firebase](https://github.com/gannonh/firebase-mcp)** - Server to interact with Firebase services including Firebase Authentication, Firestore, and Firebase Storage.\n- **[Fish Audio](https://github.com/da-okazaki/mcp-fish-audio-server)** - Text-to-Speech integration with Fish Audio's API, supporting multiple voices, streaming, and real-time playback\n- **[FitBit MCP Server](https://github.com/NitayRabi/fitbit-mcp)** - An MCP server that connects to FitBit API using a token obtained from OAuth flow.\n- **[FlightRadar24](https://github.com/sunsetcoder/flightradar24-mcp-server)** - A Claude Desktop MCP server that helps you track flights in real-time using Flightradar24 data.\n- **[Fluent-MCP](https://github.com/modesty/fluent-mcp)** - MCP server for Fluent (ServiceNow SDK) providing access to ServiceNow SDK CLI, API specifications, code snippets, and more.\n- **[Flyworks Avatar](https://github.com/Flyworks-AI/flyworks-mcp)** - Fast and free zeroshot lipsync MCP server.\n- **[fmp-mcp-server](https://github.com/vipbat/fmp-mcp-server)** - Enable your agent for M&A analysis and investment banking workflows. Access company profiles, financial statements, ratios, and perform sector analysis with the [Financial Modeling Prep APIs]\n- **[FoundationModels](https://github.com/phimage/mcp-foundation-models)** - An MCP server that integrates Apple's [FoundationModels](https://developer.apple.com/documentation/foundationmodels) for text generation.\n- **[Foursquare](https://github.com/foursquare/foursquare-places-mcp)** - Enable your agent to recommend places around the world with the [Foursquare Places API](https://location.foursquare.com/products/places-api/)\n- **[FrankfurterMCP](https://github.com/anirbanbasu/frankfurtermcp)** - MCP server acting as an interface to the [Frankfurter API](https://frankfurter.dev/) for currency exchange data.\n- **[freqtrade-mcp](https://github.com/kukapay/freqtrade-mcp)** - An MCP server that integrates with the Freqtrade cryptocurrency trading bot.\n- **[Geolocation](https://github.com/jackyang25/geolocation-mcp-server)** - WalkScore API integration for walkability, transit, and bike scores.\n- **[GDB](https://github.com/pansila/mcp_server_gdb)** - A GDB/MI protocol server based on the MCP protocol, providing remote application debugging capabilities with AI assistants.\n- **[ggRMCP](https://github.com/aalobaidi/ggRMCP)** - A Go gateway that converts gRPC services into MCP-compatible tools, allowing AI models like Claude to directly call your gRPC services.\n- **[Gemini Bridge](https://github.com/eLyiN/gemini-bridge)** - Lightweight MCP server that enables Claude to interact with Google's Gemini AI through the official CLI, offering zero API costs and stateless architecture.\n- **[Ghost](https://github.com/MFYDev/ghost-mcp)** - A Model Context Protocol (MCP) server for interacting with Ghost CMS through LLM interfaces like Claude.\n- **[Git](https://github.com/geropl/git-mcp-go)** - Allows LLM to interact with a local git repository, incl. optional push support.\n- **[Git Mob](https://github.com/Mubashwer/git-mob-mcp-server)** - MCP server that interfaces with the [git-mob](https://github.com/Mubashwer/git-mob) CLI app for managing co-authors in git commits during pair/mob programming.\n- **[Github](https://github.com/0xshariq/github-mcp-server)** - A Model Context Protocol (MCP) server that provides 29 Git operations + 11 workflow combinations for AI assistants and developers. This server exposes comprehensive Git repository management through a standardized interface, enabling AI models and developers to safely manage complex version control workflows.\n- **[GitHub Actions](https://github.com/ko1ynnky/github-actions-mcp-server)** - A Model Context Protocol (MCP) server for interacting with GitHub Actions.\n- **[GitHub Enterprise MCP](https://github.com/ddukbg/github-enterprise-mcp)** - A Model Context Protocol (MCP) server for interacting with GitHub Enterprise.\n- **[GitHub GraphQL](https://github.com/QuentinCody/github-graphql-mcp-server)** - Unofficial GitHub MCP server that provides access to GitHub's GraphQL API, enabling more powerful and flexible queries for repository data, issues, pull requests, and other GitHub resources.\n- **[GitHub Projects](https://github.com/redducklabs/github-projects-mcp)** — Manage GitHub Projects with full GraphQL API access including items, fields, and milestones.\n- **[GitHub Repos Manager MCP Server](https://github.com/kurdin/github-repos-manager-mcp)** - Token-based GitHub automation management. No Docker, Flexible configuration, 80+ tools with direct API integration.\n- **[GitMCP](https://github.com/idosal/git-mcp)** - gitmcp.io is a generic remote MCP server to connect to ANY GitHub repository or project documentation effortlessly\n- **[Glean](https://github.com/longyi1207/glean-mcp-server)** - A server that uses Glean API to search and chat.\n- **[Gmail](https://github.com/GongRzhe/Gmail-MCP-Server)** - A Model Context Protocol (MCP) server for Gmail integration in Claude Desktop with auto authentication support.\n- **[Gmail](https://github.com/Ayush-k-Shukla/gmail-mcp-server)** - A Simple MCP server for Gmail with support for all basic operations with oauth2.0.\n- **[Gmail Headless](https://github.com/baryhuang/mcp-headless-gmail)** - Remote hostable MCP server that can get and send Gmail messages without local credential or file system setup.\n- **[Gmail MCP](https://github.com/gangradeamitesh/mcp-google-email)** - A Gmail service implementation using MCP (Model Context Protocol) that provides functionality for sending, receiving, and managing emails through Gmail's API.\n- **[Gnuradio](https://github.com/yoelbassin/gnuradioMCP)** - An MCP server for GNU Radio that enables LLMs to autonomously create and modify RF .grc flowcharts.\n- **[Goal Story](https://github.com/hichana/goalstory-mcp)** - a Goal Tracker and Visualization Tool for personal and professional development.\n- **[GOAT](https://github.com/goat-sdk/goat/tree/main/typescript/examples/by-framework/model-context-protocol)** - Run more than +200 onchain actions on any blockchain including Ethereum, Solana and Base.\n- **[Godot](https://github.com/Coding-Solo/godot-mcp)** - An MCP server providing comprehensive Godot engine integration for project editing, debugging, and scene management.\n- **[Golang Filesystem Server](https://github.com/mark3labs/mcp-filesystem-server)** - Secure file operations with configurable access controls built with Go!\n- **[Goodnews](https://github.com/VectorInstitute/mcp-goodnews)** - A simple MCP server that delivers curated positive and uplifting news stories.\n- **[Gopher MCP](https://github.com/cameronrye/gopher-mcp)** - Modern, cross-platform MCP server that enables AI assistants to browse and interact with both Gopher protocol and Gemini protocol resources safely and efficiently.\n- **[Google Ads](https://github.com/gomarble-ai/google-ads-mcp-server)** - MCP server acting as an interface to the Google Ads, enabling programmatic access to Facebook Ads data and management features.\n- **[Google Analytics](https://github.com/surendranb/google-analytics-mcp)** - Google Analytics MCP Server to bring data across 200+ dimensions & metrics for LLMs to analyse.\n- **[Google Calendar](https://github.com/v-3/google-calendar)** - Integration with Google Calendar to check schedules, find time, and add/delete events\n- **[Google Calendar](https://github.com/nspady/google-calendar-mcp)** - Google Calendar MCP Server for managing Google calendar events. Also supports searching for events by attributes like title and location.\n- **[Google Custom Search](https://github.com/adenot/mcp-google-search)** - Provides Google Search results via the Google Custom Search API\n- **[Google Maps](https://github.com/Mastan1301/google_maps_mcp)** - Provides location results using Google Places API.\n- **[Google Sheets](https://github.com/xing5/mcp-google-sheets)** - Access and editing data to your Google Sheets.\n- **[Google Sheets](https://github.com/rohans2/mcp-google-sheets)** - An MCP Server written in TypeScript to access and edit data in your Google Sheets.\n- **[Google Tasks](https://github.com/zcaceres/gtasks-mcp)** - Google Tasks API Model Context Protocol Server.\n- **[Google Vertex AI Search](https://github.com/ubie-oss/mcp-vertexai-search)** - Provides Google Vertex AI Search results by grounding a Gemini model with your own private data\n- **[Google Workspace](https://github.com/taylorwilsdon/google_workspace_mcp)** - Comprehensive Google Workspace MCP with full support for Calendar, Drive, Gmail, and Docs using Streamable HTTP or SSE transport.\n- **[Google-Scholar](https://github.com/JackKuo666/Google-Scholar-MCP-Server)** - Enable AI assistants to search and access Google Scholar papers through a simple MCP interface.\n- **[Google-Scholar](https://github.com/mochow13/google-scholar-mcp)** - An MCP server for Google Scholar written in TypeScript with Streamable HTTP transport, along with a `client` implementations that integrates with the server and interacts with `gemini-2.5-flash`.\n- **[gx-mcp-server](https://github.com/davidf9999/gx-mcp-server)** - Expose Great Expectations data validation and quality checks as MCP tools for AI agents.\n- **[Gralio SaaS Database](https://github.com/tymonTe/gralio-mcp)** - Find and compare SaaS products, including data from G2 reviews, Trustpilot, Crunchbase, Linkedin, pricing, features and more, using [Gralio MCP](https://gralio.ai/mcp) server\n- **[GraphQL](https://github.com/drestrepom/mcp_graphql)** - Comprehensive GraphQL API integration that automatically exposes each GraphQL query as a separate tool.\n- **[GraphQL Schema](https://github.com/hannesj/mcp-graphql-schema)** - Allow LLMs to explore large GraphQL schemas without bloating the context.\n- **[HackMD](https://github.com/yuna0x0/hackmd-mcp)** (by yuna0x0) - An MCP server for HackMD, a collaborative markdown editor. It allows users to create, read, and update documents in HackMD using the Model Context Protocol.\n- **[HAProxy](https://github.com/tuannvm/haproxy-mcp-server)** - A Model Context Protocol (MCP) server for HAProxy implemented in Go, leveraging HAProxy Runtime API.\n- **[Hashing MCP Server](https://github.com/kanad13/MCP-Server-for-Hashing)** - MCP Server with cryptographic hashing functions e.g. SHA256, MD5, etc.\n- **[HDW LinkedIn](https://github.com/horizondatawave/hdw-mcp-server)** - Access to profile data and management of user account with [HorizonDataWave.ai](https://horizondatawave.ai/).\n- **[HeatPump](https://github.com/jiweiqi/heatpump-mcp-server)** — Residential heat - pump sizing & cost-estimation tools by **HeatPumpHQ**.\n- **[Helm Chart CLI](https://github.com/jeff-nasseri/helm-chart-cli-mcp)** - Helm MCP provides a bridge between AI assistants and the Helm package manager for Kubernetes. It allows AI assistants to interact with Helm through natural language requests, executing commands like installing charts, managing repositories, and more.\n- **[Heurist Mesh Agent](https://github.com/heurist-network/heurist-mesh-mcp-server)** - Access specialized web3 AI agents for blockchain analysis, smart contract security, token metrics, and blockchain interactions through the [Heurist Mesh network](https://github.com/heurist-network/heurist-agent-framework/tree/main/mesh).\n- **[HLedger MCP](https://github.com/iiAtlas/hledger-mcp)** - Double entry plain text accounting, right in your LLM! This MCP enables comprehensive read, and (optional) write access to your local [HLedger](https://hledger.org/) accounting journals.\n- **[Holaspirit](https://github.com/syucream/holaspirit-mcp-server)** - Interact with [Holaspirit](https://www.holaspirit.com/).\n- **[Home Assistant](https://github.com/tevonsb/homeassistant-mcp)** - Interact with [Home Assistant](https://www.home-assistant.io/) including viewing and controlling lights, switches, sensors, and all other Home Assistant entities.\n- **[Home Assistant](https://github.com/voska/hass-mcp)** - Docker-ready MCP server for Home Assistant with entity management, domain summaries, automation support, and guided conversations. Includes pre-built container images for easy installation.\n- **[HubSpot](https://github.com/buryhuang/mcp-hubspot)** - HubSpot CRM integration for managing contacts and companies. Create and retrieve CRM data directly through Claude chat.\n- **[HuggingFace Spaces](https://github.com/evalstate/mcp-hfspace)** - Server for using HuggingFace Spaces, supporting Open Source Image, Audio, Text Models and more. Claude Desktop mode for easy integration.\n- **[Human-In-the-Loop](https://github.com/GongRzhe/Human-In-the-Loop-MCP-Server)** - A powerful MCP Server that enables AI assistants like Claude to interact with humans through intuitive GUI dialogs. This server bridges the gap between automated AI processes and human decision-making by providing real-time user input tools, choices, confirmations, and feedback mechanisms.\n- **[Human-use](https://github.com/RapidataAI/human-use)** - Instant human feedback through an MCP, have your AI interact with humans around the world. Powered by [Rapidata](https://www.rapidata.ai/)\n- **[Hyperledger Fabric Agent Suite](https://github.com/padmarajkore/hlf-fabric-agent)** - Modular toolkit for managing Fabric test networks and chaincode lifecycle via MCP tools.\n- **[Hyperliquid](https://github.com/mektigboy/server-hyperliquid)** - An MCP server implementation that integrates the Hyperliquid SDK for exchange data.\n- **[Hypertool](https://github.com/toolprint/hypertool-mcp)** – MCP that let's you create hot - swappable, \"persona toolsets\" from multiple MCP servers to reduce tool overload and improve tool execution.\n- **[hyprmcp](https://github.com/stefanoamorelli/hyprmcp)** (by Stefano Amorelli) - Lightweight MCP server for `hyprland`.\n- **[iFlytek SparkAgent Platform](https://github.com/iflytek/ifly-spark-agent-mcp)** - This is a simple example of using MCP Server to invoke the task chain of the  iFlytek SparkAgent Platform.\n- **[iFlytek Workflow](https://github.com/iflytek/ifly-workflow-mcp-server)** - Connect to iFlytek Workflow via the MCP server and run your own Agent.\n- **[IIIF](https://github.com/code4history/IIIF_MCP)** - Comprehensive IIIF (International Image Interoperability Framework) protocol support for searching, navigating, and manipulating digital collections from museums, libraries, and archives worldwide.\n- **[Image Generation](https://github.com/GongRzhe/Image-Generation-MCP-Server)** - This MCP server provides image generation capabilities using the Replicate Flux model.\n- **[ImageSorcery MCP](https://github.com/sunriseapps/imagesorcery-mcp)** - ComputerVision-based 🪄 sorcery of image recognition and editing tools for AI assistants.\n- **[IMAP MCP](https://github.com/dominik1001/imap-mcp)** - 📧 An IMAP Model Context Protocol (MCP) server to expose IMAP operations as tools for AI assistants.\n- **[iMCP](https://github.com/loopwork-ai/iMCP)** - A macOS app that provides an MCP server for your iMessage, Reminders, and other Apple services.\n- **[InfluxDB](https://github.com/idoru/influxdb-mcp-server)** - Run queries against InfluxDB OSS API v2.\n- **[Intelligent Image Generator](https://github.com/shinpr/mcp-image)** - Turn casual prompts into professional-quality images with AI enhancement\n- **[Inner Monologue MCP](https://github.com/abhinav-mangla/inner-monologue-mcp)** - A cognitive reasoning tool that enables LLMs to engage in private, structured self-reflection and multi-step reasoning before generating responses, improving response quality and problem-solving capabilities.\n- **[Inoyu](https://github.com/sergehuber/inoyu-mcp-unomi-server)** - Interact with an Apache Unomi CDP customer data platform to retrieve and update customer profiles\n- **[Instagram DM](https://github.com/trypeggy/instagram_dm_mcp)** - Send DMs on Instagram via your LLM\n- **[interactive-mcp](https://github.com/ttommyth/interactive-mcp)** - Enables interactive LLM workflows by adding local user prompts and chat capabilities directly into the MCP loop.\n- **[Intercom](https://github.com/raoulbia-ai/mcp-server-for-intercom)** - An MCP-compliant server for retrieving customer support tickets from Intercom. This tool enables AI assistants like Claude Desktop and Cline to access and analyze your Intercom support tickets.\n- **[iOS Simulator](https://github.com/InditexTech/mcp-server-simulator-ios-idb)** - A Model Context Protocol (MCP) server that enables LLMs to interact with iOS simulators (iPhone, iPad, etc.) through natural language commands.\n- **[ipybox](https://github.com/gradion-ai/ipybox)** - Python code execution sandbox based on IPython and Docker. Stateful code execution, file transfer between host and container, configurable network access. See [ipybox MCP server](https://gradion-ai.github.io/ipybox/mcp-server/) for details.\n- **[it-tools-mcp](https://github.com/wrenchpilot/it-tools-mcp)** - A Model Context Protocol server that recreates [CorentinTh it-tools](https://github.com/CorentinTh/it-tools) utilities for AI agents, enabling access to a wide range of developer tools (encoding, decoding, conversions, and more) via MCP.\n- **[itemit MCP](https://github.com/umin-ai/itemit-mcp)** - itemit is Asset Tracking MCP that manage the inventory, monitoring and location tracking that powers over +300 organizations.\n- **[iTerm MCP](https://github.com/ferrislucas/iterm-mcp)** - Integration with iTerm2 terminal emulator for macOS, enabling LLMs to execute and monitor terminal commands.\n- **[iTerm MCP Server](https://github.com/rishabkoul/iTerm-MCP-Server)** - A Model Context Protocol (MCP) server implementation for iTerm2 terminal integration. Able to manage multiple iTerm Sessions.\n- **[Java Decompiler](https://github.com/idachev/mcp-javadc)** - Decompile Java bytecode into readable source code from .class files, package names, or JAR archives using CFR decompiler\n- **[JavaFX](https://github.com/quarkiverse/quarkus-mcp-servers/tree/main/jfx)** - Make drawings using a JavaFX canvas\n- **[JDBC](https://github.com/quarkiverse/quarkus-mcp-servers/tree/main/jdbc)** - Connect to any JDBC-compatible database and query, insert, update, delete, and more. Supports MySQL, PostgreSQL, Oracle, SQL Server, SQLite and [more](https://github.com/quarkiverse/quarkus-mcp-servers/tree/main/jdbc#supported-jdbc-variants).\n- **[Jenkins](https://github.com/jasonkylelol/jenkins-mcp-server)** - This MCP server allow you to create Jenkins tasks.\n- **[JMeter](https://github.com/QAInsights/jmeter-mcp-server)** - Run load testing using Apache JMeter via MCP-compliant tools.\n- **[Job Searcher](https://github.com/0xDAEF0F/job-searchoor)** - A FastMCP server that provides tools for retrieving and filtering job listings based on time period, keywords, and remote work preferences.\n- **[jobswithgpt](https://github.com/jobswithgpt/mcp)** - Job search MCP using jobswithgpt which indexes 500K+ public job listings and refreshed continously.\n- **[joinly](https://github.com/joinly-ai/joinly)** - MCP server to interact with browser-based meeting platforms (Zoom, Teams, Google Meet). Enables AI agents to send bots to online meetings, gather live transcripts, speak text, and send messages in the meeting chat.\n- **[JSON](https://github.com/GongRzhe/JSON-MCP-Server)** - JSON handling and processing server with advanced query capabilities using JSONPath syntax and support for array, string, numeric, and date operations.\n- **[JSON](https://github.com/kehvinbehvin/json-mcp-filter)** - JSON schema generation and filtering server with TypeScript type creation optimised for retrieving relevant context JSON data using quicktype-core and support for shape-based data extraction, nested object filtering, and array processing operations.\n- **[JSON to Excel by WTSolutions](https://github.com/he-yang/json-to-excel-mcp)** - Converting JSON into CSV format string from (1) JSON data, (2) URLs pointing to publiclly available .json files.\n- **[JSON2Video MCP](https://github.com/omergocmen/json2video-mcp-server)** - A Model Context Protocol (MCP) server implementation for programmatically generating videos using the json2video API. This server exposes powerful video generation and status-checking tools for use with LLMs, agents, or any MCP-compatible client.\n- **[jupiter-mcp](https://github.com/kukapay/jupiter-mcp)** - An MCP server for executing token swaps on the Solana blockchain using Jupiter's new Ultra API.\n- **[Jupyter MCP Server](https://github.com/datalayer/jupyter-mcp-server)** – Real-time interaction with Jupyter Notebooks, allowing AI to edit, document and execute code for data analysis, visualization etc. Compatible with any Jupyter deployment (local, JupyterHub, ...).\n- **[Jupyter Notebook](https://github.com/jjsantos01/jupyter-notebook-mcp)** - connects Jupyter Notebook to Claude AI, allowing Claude to directly interact with and control Jupyter Notebooks. This integration enables AI-assisted code execution, data analysis, visualization, and more.\n- **[k8s-multicluster-mcp](https://github.com/razvanmacovei/k8s-multicluster-mcp)** - An MCP server for interact with multiple Kubernetes clusters simultaneously using multiple kubeconfig files.\n- **[Kafka](https://github.com/tuannvm/kafka-mcp-server)** - A Model Context Protocol (MCP) server for Apache Kafka implemented in Go, leveraging [franz-go](https://github.com/twmb/franz-go).\n- **[Kafka Schema Registry MCP](https://github.com/aywengo/kafka-schema-reg-mcp)** \\ - A comprehensive MCP server for Kafka Schema Registry with 48 tools, multi-registry support, authentication, and production safety features. Enables AI-powered schema management with enterprise-grade capabilities including schema contexts, migration tools, and comprehensive export capabilities.\n- **[kafka-mcp](https://github.com/shivamxtech/kafka-mcp)** - An MCP Server for Kafka clusters to interact with kafka environment via tools on messages, topics, offsets, partitions for consumer and producers along with seamless integration with MCP clients.\n- **[Keycloak](https://github.com/idoyudha/mcp-keycloak)** - The Keycloak MCP Server designed for agentic applications to manage and search data in Keycloak efficiently.\n- **[Keycloak MCP](https://github.com/ChristophEnglisch/keycloak-model-context-protocol)** - This MCP server enables natural language interaction with Keycloak for user and realm management including creating, deleting, and listing users and realms.\n- **[Keycloak MCP Server](https://github.com/sshaaf/keycloak-mcp-server)** - designed to work with Keycloak for identity and access management, with about 40+ tools covering, Users, Realms, Clients, Roles, Groups, IDPs, Authentication. Native builds available.\n- **[Kibana MCP](https://github.com/TocharianOU/mcp-server-kibana.git)** (by TocharianOU) - A community-maintained MCP server implementation that allows any MCP-compatible client to access and manage Kibana instances through natural language or programmatic requests.\n- **[Kibela](https://github.com/kiwamizamurai/mcp-kibela-server)** (by kiwamizamurai) - Interact with Kibela API.\n- **[KiCad MCP](https://github.com/lamaalrajih/kicad-mcp)** - MCP server for KiCad on Mac, Windows, and Linux.\n- **[kill-process-mcp](https://github.com/misiektoja/kill-process-mcp)** - List and terminate OS processes via natural language queries\n- **[Kindred Offers & Discounts MCP](https://github.com/kindred-app/mcp-server-kindred-offers)** (by kindred.co) - This MCP server allows you to get live deals and offers/coupons from e-commerce merchant sites all over the world.\n- **[kintone](https://github.com/macrat/mcp-server-kintone)** - Manage records and apps in [kintone](https://kintone.com) through LLM tools.\n- **[Kokoro TTS](https://github.com/mberg/kokoro-tts-mcp)** - Use Kokoro text to speech to convert text to MP3s with optional autoupload to S3.\n- **[Kong Konnect](https://github.com/Kong/mcp-konnect)** - A Model Context Protocol (MCP) server for interacting with Kong Konnect APIs, allowing AI assistants to query and analyze Kong Gateway configurations, traffic, and analytics.\n- **[Korea Stock Analyzer](https://github.com/Mrbaeksang/korea-stock-analyzer-mcp)** - Analyze Korean stocks (KOSPI/KOSDAQ) with 6 legendary investment strategies including Buffett, Lynch, Graham, Greenblatt, Fisher, and Templeton.\n- **[Kubernetes](https://github.com/Flux159/mcp-server-kubernetes)** - Connect to Kubernetes cluster and manage pods, deployments, and services.\n- **[Kubernetes and OpenShift](https://github.com/manusa/kubernetes-mcp-server)** - A powerful Kubernetes MCP server with additional support for OpenShift. Besides providing CRUD operations for any Kubernetes resource, this server provides specialized tools to interact with your cluster.\n- **[KubeSphere](https://github.com/kubesphere/ks-mcp-server)** - The KubeSphere MCP Server is a Model Context Protocol(MCP) server that provides integration with KubeSphere APIs, enabling to get resources from KubeSphere. Divided into four tools modules: Workspace Management, Cluster Management, User and Roles, Extensions Center.\n- **[Kukapay MCP Servers](https://github.com/kukapay/kukapay-mcp-servers)** - A comprehensive suite of Model Context Protocol (MCP) servers dedicated to cryptocurrency, blockchain, and Web3 data aggregation, analysis, and services from Kukapay.\n- **[kwrds.ai](https://github.com/mkotsollaris/kwrds_ai_mcp)** - Keyword research, people also ask, SERP and other SEO tools for [kwrds.ai](https://www.kwrds.ai/)\n- **[KYC-mcp-server](https://github.com/vishnurudra-ai/KYC-mcp-server)** - Know Your Computer (KYC) - MCP Server compatible with Claude Desktop. Comprehensive system diagnostics for Windows, Mac OS and Linux operating system with AI-powered recommendations.\n- **[Langflow-DOC-QA-SERVER](https://github.com/GongRzhe/Langflow-DOC-QA-SERVER)** - A Model Context Protocol server for document Q&A powered by Langflow. It demonstrates core MCP concepts by providing a simple interface to query documents through a Langflow backend.\n- **[Language Server](https://github.com/isaacphi/mcp-language-server)** - MCP Language Server helps MCP enabled clients navigate codebases more easily by giving them access to semantic tools like get definition, references, rename, and diagnostics.\n- **[Lark(Feishu)](https://github.com/kone-net/mcp_server_lark)** - A Model Context Protocol(MCP) server for Lark(Feishu) sheet, message, doc and etc.\n- **[Lazy Toggl MCP](https://github.com/movstox/lazy-toggl-mcp)** - Simple unofficial MCP server to track time via Toggl API\n- **[lean-lsp-mcp](https://github.com/oOo0oOo/lean-lsp-mcp)** - Interact with the [Lean theorem prover](https://lean-lang.org/) via the Language Server Protocol.\n- **[librenms-mcp](https://github.com/mhajder/librenms-mcp)** - MCP server for [LibreNMS](https://www.librenms.org/) management\n- **[libvirt-mcp](https://github.com/MatiasVara/libvirt-mcp)** - Allows LLM to interact with libvirt thus enabling to create, destroy or list the Virtual Machines in a system.\n- **[Lightdash](https://github.com/syucream/lightdash-mcp-server)** - Interact with [Lightdash](https://www.lightdash.com/), a BI tool.\n- **[LINE](https://github.com/amornpan/py-mcp-line)** (by amornpan) - Implementation for LINE Bot integration that enables Language Models to read and analyze LINE conversations through a standardized interface. Features asynchronous operation, comprehensive logging, webhook event handling, and support for various message types.\n- **[Linear](https://github.com/tacticlaunch/mcp-linear)** - Interact with Linear project management system.\n- **[Linear](https://github.com/jerhadf/linear-mcp-server)** - Allows LLM to interact with Linear's API for project management, including searching, creating, and updating issues.\n- **[Linear (Go)](https://github.com/geropl/linear-mcp-go)** - Allows LLM to interact with Linear's API via a single static binary.\n- **[Linear MCP](https://github.com/anoncam/linear-mcp)** - Full blown implementation of the Linear SDK to support comprehensive Linear management of projects, initiatives, issues, users, teams and states.\n- **[Linked API MCP](https://github.com/Linked-API/linkedapi-mcp)** - MCP server that lets AI assistants control LinkedIn accounts and retrieve real-time data.\n- **[Listmonk MCP Server](https://github.com/rhnvrm/listmonk-mcp)** (by rhnvrm) - Full API coverage of [Listmonk](https://github.com/knadh/listmonk) email marketing FOSS.\n- **[LlamaCloud](https://github.com/run-llama/mcp-server-llamacloud)** (by marcusschiesser) - Integrate the data stored in a managed index on [LlamaCloud](https://cloud.llamaindex.ai/)\n- **[lldb-mcp](https://github.com/stass/lldb-mcp)** - A Model Context Protocol server for LLDB that provides LLM-driven debugging.\n- **[llm-context](https://github.com/cyberchitta/llm-context.py)** - Provides a repo-packing MCP tool with configurable profiles that specify file inclusion/exclusion patterns and optional prompts.\n- **[Local History](https://github.com/xxczaki/local-history-mcp)** – MCP server for accessing VS Code/Cursor's Local History.\n- **[Locust](https://github.com/QAInsights/locust-mcp-server)** - Allows running and analyzing Locust tests using MCP compatible clients.\n- **[Loki](https://github.com/scottlepp/loki-mcp)** - Golang based MCP Server to query logs from [Grafana Loki](https://github.com/grafana/loki).\n- **[Loki MCP Server](https://github.com/mo-silent/loki-mcp-server)** - Python based MCP Server for querying and analyzing logs from Grafana Loki with advanced filtering and authentication support.\n- **[LottieFiles](https://github.com/junmer/mcp-server-lottiefiles)** - Searching and retrieving Lottie animations from [LottieFiles](https://lottiefiles.com/)\n- **[lsp-mcp](https://github.com/Tritlo/lsp-mcp)** - Interact with Language Servers usint the Language Server Protocol to provide additional context information via hover, code actions and completions.\n- **[Lspace](https://github.com/Lspace-io/lspace-server)** - Turn scattered ChatGPT/Claude/Cursor conversations into persistent, searchable knowledge.\n- **[lucene-mcp-server](https://github.com/VivekKumarNeu/MCP-Lucene-Server)** - spring boot server using Lucene for fast document search and management.\n- **[lucid-mcp-server](https://github.com/smartzan63/lucid-mcp-server)** – An MCP server for Lucidchart and Lucidspark: connect, search, and obtain text representations of your Lucid documents and diagrams via LLM - driven AI Vision analysis. [npm](https://www.npmjs.com/package/lucid-mcp-server)\n- **[LunarCrush Remote MCP](https://github.com/lunarcrush/mcp-server)** - Get the latest social metrics and posts for both current live social context as well as historical metrics in LLM and token optimized outputs. Ideal for automated trading / financial advisory.\n- **[mac-messages-mcp](https://github.com/carterlasalle/mac_messages_mcp)** - An MCP server that securely interfaces with your iMessage database via the Model Context Protocol (MCP), allowing LLMs to query and analyze iMessage conversations. It includes robust phone number validation, attachment processing, contact management, group chat handling, and full support for sending and receiving messages.\n- **[Maestro MCP](https://github.com/maestro-org/maestro-mcp)** - An MCP server for interacting with Bitcoin via the Maestro RPC API.\n- **[Magg: The MCP Aggregator](https://github.com/sitbon/magg)** - A meta-MCP server that acts as a universal hub, allowing LLMs to autonomously discover, install, and orchestrate multiple MCP servers - essentially giving AI assistants the power to extend their own capabilities on-demand. Includes `mbro`, a powerful CLI MCP server browser with scripting capability.\n- **[Mailchimp MCP](https://github.com/AgentX-ai/mailchimp-mcp)** - Allows AI agents to interact with the Mailchimp API (read-only)\n- **[MalwareBazaar_MCP](https://github.com/mytechnotalent/MalwareBazaar_MCP)** (by Kevin Thomas) - An AI-driven MCP server that autonomously interfaces with MalwareBazaar, delivering real-time threat intel and sample metadata for authorized cybersecurity research workflows.\n- **[Mandoline](https://github.com/mandoline-ai/mandoline-mcp-server)** - Enable AI assistants to reflect on, critique, and continuously improve their own performance using Mandoline's evaluation framework.\n- **[Matrix](https://github.com/mjknowles/matrix-mcp-server)** - Interact with a Matrix homeserver.\n- **[man-mcp-server](https://github.com/guyru/man-mcp-server)** - MCP to search and access man pages on the local machine.\n- **[MariaDB](https://github.com/abel9851/mcp-server-mariadb)** - MariaDB database integration with configurable access controls in Python.\n- **[Markdown2doc](https://github.com/Klavis-AI/klavis/tree/main/mcp_servers/pandoc)** - Convert between various file formats using Pandoc\n- **[Markdownify](https://github.com/zcaceres/mcp-markdownify-server)** - MCP to convert almost anything to Markdown (PPTX, HTML, PDF, Youtube Transcripts and more)\n- **[market-fiyati](https://github.com/mtcnbzks/market-fiyati-mcp-server)** - The MCP server for marketfiyati.org.tr, offering grocery price search and comparison across Turkish markets.)\n- **[Markitdown](https://github.com/Klavis-AI/klavis/tree/main/mcp_servers/markitdown)** - Convert files to Markdown\n- **[Masquerade](https://github.com/postralai/masquerade)** - Redact sensitive information from your PDF documents before sending them to Claude. Masquerade serves as a privacy firewall for LLMs.\n- **[MasterGo](https://github.com/mastergo-design/mastergo-magic-mcp)** - The server designed to connect MasterGo design tools with AI models. It enables AI models to directly retrieve DSL data from MasterGo design files.\n- **[Matlab-MCP-Tools](https://github.com/neuromechanist/matlab-mcp-tools)** - An MCP to write and execute MATLAB scripts, maintain workspace context between MCP calls, visualize plots, and perform section-by-section analysis of MATLAB code with full access to MATLAB's computational capabilities.\n- **[Maton](https://github.com/maton-ai/agent-toolkit/tree/main/modelcontextprotocol)** - Connect to your SaaS tools like HubSpot, Salesforce, and more.\n- **[Maven Tools MCP](https://github.com/arvindand/maven-tools-mcp)** - Maven Central dependency intelligence for JVM build tools. Supports all build tools (Maven, Gradle, SBT, Mill) with Context7 integration for documentation support.\n- **[MCP-Airflow-API](https://github.com/call518/MCP-Airflow-API)** - Model Context Protocol (MCP) server for Apache Airflow API integration. Provides comprehensive tools for managing Airflow clusters including service operations, configuration management, status monitoring, and request tracking.\n- **[mcpcap](https://github.com/mcpcap/mcpcap)** - A modular Python MCP (Model Context Protocol) Server for analyzing PCAP files.\n- **[MCP Compass](https://github.com/liuyoshio/mcp-compass)** - Suggest the right MCP server for your needs\n- **[MCP Create](https://github.com/tesla0225/mcp-create)** - A dynamic MCP server management service that creates, runs, and manages Model Context Protocol servers on-the-fly.\n- **[MCP Documentation Server](https://github.com/andrea9293/mcp-documentation-server)** - Server that provides local-first document management and semantic search via embeddings or Gemini AI (recommended). Optimized for performance with disk persistence, an in-memory index, and caching.\n- **[MCP Installer](https://github.com/anaisbetts/mcp-installer)** - This server is a server that installs other MCP servers for you.\n- **[MCP ProjectManage OpenProject](https://github.com/boma086/mcp-projectmanage-openproject)** - This server provides the MCP service for project weekly reports, with project management information supplied by OpenProject.\n- **[MCP Proxy Server](https://github.com/TBXark/mcp-proxy)** - An MCP proxy server that aggregates and serves multiple MCP resource servers through a single HTTP server.\n- **[MCP Server Creator](https://github.com/GongRzhe/MCP-Server-Creator)** - A powerful Model Context Protocol (MCP) server that creates other MCP servers! This meta-server provides tools for dynamically generating FastMCP server configurations and Python code.\n- **[MCP Server Generator](https://github.com/SerhatUzbas/mcp-server-generator)** - An MCP server that creates and manages  MCP servers! Helps both non-technical users and developers build custom JavaScript MCP servers with AI guidance, automatic dependency management, and Claude Desktop integration.\n- **[MCP STDIO to Streamable HTTP Adapter](https://github.com/pyroprompts/mcp-stdio-to-streamable-http-adapter)** - Connect to Streamable HTTP MCP Servers even if the MCP Client only supports STDIO.\n- **[MCP-Ambari-API](https://github.com/call518/MCP-Ambari-API)** - Model Context Protocol (MCP) server for Apache Ambari API integration. This project provides tools for managing Hadoop clusters, including service operations, configuration management, status monitoring, and request tracking.\n- **[MCP-OpenStack-Ops](https://github.com/call518/MCP-OpenStack-Ops)** - Professional OpenStack operations automation via MCP server. Specialized tools for cluster monitoring, instance management, volume control & network analysis. FastMCP + OpenStack SDK + Bearer auth. Claude Desktop ready. Perfect for DevOps & cloud automation.\n- **[MCP-PostgreSQL-Ops](https://github.com/call518/MCP-PostgreSQL-Ops)** - Model Context Protocol (MCP) server for Apache Ambari API integration. This project provides tools for managing Hadoop clusters, including service operations, configuration management, status monitoring, and request tracking.\n- **[mcp-containerd](https://github.com/jokemanfire/mcp-containerd)** - The containerd MCP implemented by Rust supports the operation of the CRI interface.\n- **[MCP-Database-Server](https://github.com/executeautomation/mcp-database-server)** - Fastest way to interact with your Database such as SQL Server, SQLite and PostgreSQL\n- **[mcp-grep](https://github.com/erniebrodeur/mcp-grep)** - Python-based MCP server that brings grep functionality to LLMs. Supports common grep features including pattern searching, case-insensitive matching, context lines, and recursive directory searches.\n- **[mcp-k8s-go](https://github.com/strowk/mcp-k8s-go)** - Golang-based Kubernetes server for MCP to browse pods and their logs, events, namespaces and more. Built to be extensible.\n- **[mcp-local-rag](https://github.com/nkapila6/mcp-local-rag)** - \"primitive\" RAG-like web search model context protocol (MCP) server that runs locally using Google's MediaPipe Text Embedder and DuckDuckGo Search.\n- **[mcp-mcp](https://github.com/wojtyniak/mcp-mcp)** - Meta-MCP Server that acts as a tool discovery service for MCP clients.\n- **[mcp-meme-sticky](https://github.com/nkapila6/mcp-meme-sticky)** - Make memes or stickers using MCP server for WhatsApp or Telegram.\n- **[mcp-memory-service](https://github.com/doobidoo/mcp-memory-service)** - Universal MCP memory service providing semantic memory search, persistent storage, and autonomous memory consolidation for AI assistants across 13+ AI applications.\n- **[MCP-NixOS](https://github.com/utensils/mcp-nixos)** - A Model Context Protocol server that provides AI assistants with accurate, real-time information about NixOS packages, system options, Home Manager settings, and nix-darwin macOS configurations.\n- **[mcp-open-library](https://github.com/8enSmith/mcp-open-library)** - A Model Context Protocol (MCP) server for the Open Library API that enables AI assistants to search for book and author information.\n- **[mcp-proxy](https://github.com/sparfenyuk/mcp-proxy)** - Connect to MCP servers that run on SSE transport, or expose stdio servers as an SSE server.\n- **[mcp-read-website-fast](https://github.com/just-every/mcp-read-website-fast)** - Fast, token-efficient web content extraction that converts websites to clean Markdown. Features Mozilla Readability, smart caching, polite crawling with robots.txt support, and concurrent fetching with minimal dependencies.\n- **[mcp-salesforce](https://github.com/lciesielski/mcp-salesforce-example)** - MCP server with basic demonstration of interactions with your Salesforce instance\n- **[mcp-sanctions](https://github.com/madupay/mcp-sanctions)** - Screen individuals and organizations against global sanctions lists (OFAC, SDN, UN, etc). Query by prompt or document upload.\n- **[mcp-screenshot-website-fast](https://github.com/just-every/mcp-screenshot-website-fast)** - High-quality screenshot capture optimized for Claude Vision API. Automatically tiles full pages into 1072x1072 chunks (1.15 megapixels) with configurable viewports and wait strategies for dynamic content.\n- **[mcp-server-leetcode](https://github.com/doggybee/mcp-server-leetcode)** - Practice and retrieve problems from LeetCode. Automate problem retrieval, solutions, and insights for coding practice and competitions.\n- **[Mcp-Swagger-Server](https://github.com/zaizaizhao/mcp-swagger-server)** (by zaizaizhao) - This MCP server transforms OpenAPI specifications into MCP tools, enabling AI assistants to interact with REST APIs through standardized protocol\n- **[MCP Dynamic Tool Groups](https://github.com/ECF/MCPToolGroups)** - Example MCP servers that use [annotated](https://github.com/spring-ai-community/mcp-annotations) Java interfaces/classes as 'tool groups'.  Using standard MCP annotations, service implementations can then, at runtime, be used to generate tool specifications, and then dynamically added or removed from MCP servers.   The functionality is demonstrated in a sample tool group, but can be similarly used for any API or service.\n- **[mcp-vision](https://github.com/groundlight/mcp-vision)** - An MCP server exposing HuggingFace computer vision models such as zero-shot object detection as tools, enhancing the vision capabilities of large language or vision-language models.\n- **[mcp-weather](https://github.com/TimLukaHorstmann/mcp-weather)** - Accurate weather forecasts via the AccuWeather API (free tier available).\n- **[KnowAir Weather MCP](https://github.com/shuowang-ai/Weather-MCP)** - A comprehensive Model Context Protocol (MCP) server providing real-time weather data, air quality monitoring, forecasts, and astronomical information powered by Caiyun Weather API.\n- **[mcp-youtube-extract](https://github.com/sinjab/mcp_youtube_extract)** - A Model Context Protocol server for YouTube operations, extracting video information and transcripts with intelligent fallback logic. Features comprehensive logging, error handling, and support for both auto-generated and manual transcripts.\n- **[mcp_weather](https://github.com/isdaniel/mcp_weather_server)** - Get weather information from https://api.open-meteo.com API.\n- **[MCPfinder](https://github.com/mcpfinder/server)** - The AI Agent's \"App Store\": Discover, install, and monetize AI capabilities — all within the MCP ecosystem.\n- **[MCPIgnore Filesytem](https://github.com/CyberhavenInc/filesystem-mcpignore)** - A Data Security First filesystem MCP server that implements .mcpignore to prevent MCP clients from accessing sensitive data.\n- **[MCPJungle](https://github.com/mcpjungle/MCPJungle)** - Self-hosted MCP Registry and Gateway for enterprise AI Agents\n- **[Md2doc](https://github.com/Yorick-Ryu/md2doc-mcp)** - Convert Markdown text to DOCX format using an external conversion service\n- **[MeasureSpace MCP](https://github.com/MeasureSpace/measure-space-mcp-server)** - A free [Model Context Protocol (MCP) Server](https://smithery.ai/server/@MeasureSpace/measure-space-mcp-server) that provides global weather, climate, air quality forecast and geocoding services by [measurespace.io](https://measurespace.io).\n- **[MediaWiki](https://github.com/ProfessionalWiki/MediaWiki-MCP-Server)** - A Model Context Protocol (MCP) Server that interacts with any MediaWiki wiki\n- **[MediaWiki MCP adapter](https://github.com/lucamauri/MediaWiki-MCP-adapter)** - A custom Model Context Protocol adapter for MediaWiki and WikiBase APIs\n- **[medRxiv](https://github.com/JackKuo666/medRxiv-MCP-Server)** - Enable AI assistants to search and access medRxiv papers through a simple MCP interface.\n- **[mem0-mcp](https://github.com/mem0ai/mem0-mcp)** - A Model Context Protocol server for Mem0, which helps with managing coding preferences.\n- **[Membase](https://github.com/unibaseio/membase-mcp)** - Save and query your agent memory in distributed way by Membase.\n- **[Meme MCP](https://github.com/lidorshimoni/meme-mcp)** - Generate memes via AI using the Imgflip API through the Model Context Protocol.\n- **[memento-mcp](https://github.com/gannonh/memento-mcp)** - Knowledge graph memory system built on Neo4j with semantic search, temporal awareness.\n- **[Meta Ads Remote MCP](https://github.com/pipeboard-co/meta-ads-mcp)** - Remote MCP server to interact with Meta Ads API - access, analyze, and manage Facebook, Instagram, and other Meta platforms advertising campaigns.\n- **[MetaTrader MCP](https://github.com/ariadng/metatrader-mcp-server)** - Enable AI LLMs to execute trades using MetaTrader 5 platform.\n- **[Metricool MCP](https://github.com/metricool/mcp-metricool)** - A Model Context Protocol server that integrates with Metricool's social media analytics platform to retrieve performance metrics and schedule content across networks like Instagram, Facebook, Twitter, LinkedIn, TikTok and YouTube.\n- **[Microsoft 365](https://github.com/merill/lokka)** - (by Merill) A Model Context Protocol (MCP) server for Microsoft 365. Includes support for all services including Teams, SharePoint, Exchange, OneDrive, Entra, Intune and more. See [Lokka](https://lokka.dev/) for more details.\n- **[Microsoft 365](https://github.com/softeria/ms-365-mcp-server)** - MCP server that connects to Microsoft Office and the whole Microsoft 365 suite using Graph API (including Outlook/mail, files, Excel, calendar)\n- **[Microsoft 365](https://github.com/pnp/cli-microsoft365-mcp-server)** - Single MCP server that allows to manage many different areas of Microsoft 365, for example: Entra ID, OneDrive, OneNote, Outlook, Planner, Power Apps, Power Automate, Power Platform, SharePoint Embedded, SharePoint Online, Teams, Viva Engage, and many more.\n- **[Microsoft 365 Files (SharePoint/OneDrive)](https://github.com/godwin3737/mcp-server-microsoft365-filesearch)** (by godwin3737) - MCP server with tools to search and get file content from Microsoft 365 including Onedrive and SharePoint. Works with Documents (pdf/docx), Presentations, Spreadsheets and Images.\n- **[Microsoft Teams](https://github.com/InditexTech/mcp-teams-server)** - MCP server that integrates Microsoft Teams messaging (read, post, mention, list members and threads)\n- **[Mifos X](https://github.com/openMF/mcp-mifosx)** - An MCP server for the Mifos X Open Source Banking useful for managing clients, loans, savings, shares, financial transactions and generating financial reports.\n- **[Mikrotik](https://github.com/jeff-nasseri/mikrotik-mcp)** - Mikrotik MCP server which cover networking operations (IP, DHCP, Firewall, etc)\n- **[Mindmap](https://github.com/YuChenSSR/mindmap-mcp-server)** (by YuChenSSR) - A server that generates mindmaps from input containing markdown code.\n- **[Minima](https://github.com/dmayboroda/minima)** - MCP server for RAG on local files\n- **[Modao Proto MCP](https://github.com/modao-dev/modao-proto-mcp)** - AI-powered HTML prototype generation server that converts natural language descriptions into complete HTML code with modern design and responsive layouts. Supports design description expansion and seamless integration with Modao workspace.\n- **[Mobile MCP](https://github.com/mobile-next/mobile-mcp)** (by Mobile Next) - MCP server for Mobile(iOS/Android) automation, app scraping and development using physical devices or simulators/emulators.\n- **[Monday.com (unofficial)](https://github.com/sakce/mcp-server-monday)** - MCP Server to interact with Monday.com boards and items.\n- **[MongoDB](https://github.com/kiliczsh/mcp-mongo-server)** - A Model Context Protocol Server for MongoDB.\n- **[MongoDB & Mongoose](https://github.com/nabid-pf/mongo-mongoose-mcp)** - MongoDB MCP Server with Mongoose Schema and Validation.\n- **[MongoDB Lens](https://github.com/furey/mongodb-lens)** - Full Featured MCP Server for MongoDB Databases.\n- **[Monzo](https://github.com/BfdCampos/monzo-mcp-bfdcampos)** - Access and manage your Monzo bank accounts through natural language, including balance checking, pot management, transaction listing, and transaction annotation across multiple account types (personal, joint, flex).\n- **[Morningstar](https://github.com/Morningstar/morningstar-mcp-server)** - MCP Server to interact with Morningstar Research, Editorial and Datapoints\n- **[MSSQL](https://github.com/aekanun2020/mcp-server/)** - MSSQL database integration with configurable access controls and schema inspection\n- **[MSSQL](https://github.com/JexinSam/mssql_mcp_server)** (by jexin) - MCP Server for MSSQL database in Python\n- **[MSSQL-MCP](https://github.com/daobataotie/mssql-mcp)** (by daobataotie) - MSSQL MCP that refer to the official website's SQLite MCP for modifications to adapt to MSSQL\n- **[MSSQL-MCP-Node](https://github.com/mihai-dulgheru/mssql-mcp-node)** (by mihai - dulgheru) – Node.js MCP server for Microsoft SQL Server featuring auto-detected single / multi-database configs, execute-SQL and schema tools, robust Zod validation, and optional Express endpoints for local testing\n- **[MSSQL-Python](https://github.com/amornpan/py-mcp-mssql)** (by amornpan) - A read-only Python implementation for MSSQL database access with enhanced security features, configurable access controls, and schema inspection capabilities. Focuses on safe database interaction through Python ecosystem.\n- **[Multi-Model Advisor](https://github.com/YuChenSSR/multi-ai-advisor-mcp)** - A Model Context Protocol (MCP) server that orchestrates queries across multiple Ollama models, synthesizing their insights to deliver a comprehensive and multifaceted AI perspective on any given query.\n- **[Multicluster-MCP-Sever](https://github.com/yanmxa/multicluster-mcp-server)** - The gateway for GenAI systems to interact with multiple Kubernetes clusters.\n- **[MySQL](https://github.com/benborla/mcp-server-mysql)** (by benborla) - MySQL database integration in NodeJS with configurable access controls and schema inspection\n- **[MySQL](https://github.com/designcomputer/mysql_mcp_server)** (by DesignComputer) - MySQL database integration in Python with configurable access controls and schema inspection\n- **[MySQL-Server](https://github.com/tonycai/mcp-mysql-server)** (by TonyCai) - MySQL Database Integration using Python script with configurable access controls and schema inspection, usng stdio mode to suitable local deployment, you can run it in docker container.\n- **[n8n](https://github.com/leonardsellem/n8n-mcp-server)** - This MCP server provides tools and resources for AI assistants to manage n8n workflows and executions, including listing, creating, updating, and deleting workflows, as well as monitoring their execution status.\n- **[Nacos MCP Router](https://github.com/nacos-group/nacos-mcp-router)** - This MCP(Model Context Protocol) Server provides tools to search, install, proxy other MCP servers.\n- **[NASA](https://github.com/ProgramComputer/NASA-MCP-server)** (by ProgramComputer) - Access to a unified gateway of NASA's data sources including but not limited to APOD, NEO, EPIC, GIBS.\n- **[NASA Image MCP Server](https://github.com/adithya1012/NASA-MCP-Server/blob/main/README.md)** - MCP server providing access to NASA's visual data APIs including Mars Rover photos, Earth satellite imagery (EPIC/GIBS), and Astronomy picture of the day. Features built-in image analysis tools with automatic format detection, compression, and base64 conversion for LLM integration.\n- **[Nasdaq Data Link](https://github.com/stefanoamorelli/nasdaq-data-link-mcp)** (by stefanoamorelli) - An MCP server to access, explore, and interact with Nasdaq Data Link's extensive and valuable financial and economic datasets.\n- **[National Parks](https://github.com/KyrieTangSheng/mcp-server-nationalparks)** - The server provides latest information of park details, alerts, visitor centers, campgrounds, hiking trails, and events for U.S. National Parks.\n- **[NAVER](https://github.com/pfldy2850/py-mcp-naver)** (by pfldy2850) - This MCP server provides tools to interact with various Naver services, such as searching blogs, news, books, and more.\n- **[Naver](https://github.com/isnow890/naver-search-mcp)** (by isnow890) - MCP server for Naver Search API integration, supporting blog, news, shopping search and DataLab analytics features.\n- **[NBA](https://github.com/Taidgh-Robinson/nba-mcp-server)** - This MCP server provides tools to fetch recent and historical NBA games including basic and advanced statistics.\n- **[NCI GDC](https://github.com/QuentinCody/nci-gdc-mcp-server)** - Unofficial MCP server for the National Cancer Institute's Genomic Data Commons (GDC), providing access to harmonized cancer genomic and clinical data for oncology research.\n- **[Neo4j](https://github.com/da-okazaki/mcp-neo4j-server)** - A community built server that interacts with Neo4j Graph Database.\n- **[Neovim](https://github.com/bigcodegen/mcp-neovim-server)** - An MCP Server for your Neovim session.\n- **[Netbird](https://github.com/aantti/mcp-netbird)** - List and analyze Netbird network peers, groups, policies, and more.\n- **[NetMind ParsePro](https://github.com/protagolabs/Netmind-Parse-PDF-MCP)** - The PDF Parser AI service, built and customized by the [NetMind](https://www.netmind.ai/) team.\n- **[Nikto MCP](https://github.com/weldpua2008/nikto-mcp)** (by weldpua2008) - A secure MCP server that enables AI agents to interact with Nikto web server scanner](- use with npx or docker).\n- **[NocoDB](https://github.com/edwinbernadus/nocodb-mcp-server)** - Read and write access to NocoDB database.\n- **[Node Code Sandbox](https://github.com/alfonsograziano/node-code-sandbox-mcp)** – A Node.js MCP server that spins up isolated Docker - based sandboxes for executing JavaScript snippets with on-the-fly npm dependency installation\n- **[nomad-mcp](https://github.com/kocierik/mcp-nomad)** - A server that provides a set of tools for managing Nomad clusters through the MCP.\n- **[Notion](https://github.com/suekou/mcp-notion-server)** (by suekou) - Interact with Notion API.\n- **[Notion](https://github.com/v-3/notion-server)** (by v-3) - Notion MCP integration. Search, Read, Update, and Create pages through Claude chat.\n- **[NPM Plus](https://github.com/shacharsol/js-package-manager-mcp)** - AI-powered JavaScript package management with security scanning, bundle analysis, and intelligent dependency management for MCP-compatible editors.\n- **[NS Travel Information](https://github.com/r-huijts/ns-mcp-server)** - Access Dutch Railways (NS) real-time train travel information and disruptions through the official NS API.\n- **[ntfy-mcp](https://github.com/teddyzxcv/ntfy-mcp)** (by teddyzxcv) - The MCP server that keeps you informed by sending the notification on phone using ntfy\n- **[ntfy-me-mcp](https://github.com/gitmotion/ntfy-me-mcp)** (by gitmotion) - An ntfy MCP server for sending/fetching ntfy notifications to your self-hosted ntfy server from AI Agents 📤 (supports secure token auth & more - use with npx or docker!)\n- **[oatpp-mcp](https://github.com/oatpp/oatpp-mcp)** - C++ MCP integration for Oat++. Use [Oat++](https://oatpp.io) to build MCP servers.\n- **[Obsidian Markdown Notes](https://github.com/calclavia/mcp-obsidian)** - Read and search through your Obsidian vault or any directory containing Markdown notes\n- **[obsidian-mcp](https://github.com/StevenStavrakis/obsidian-mcp)** - (by Steven Stavrakis) An MCP server for Obsidian.md with tools for searching, reading, writing, and organizing notes.\n- **[OceanBase](https://github.com/yuanoOo/oceanbase_mcp_server)** - (by yuanoOo) A Model Context Protocol (MCP) server that enables secure interaction with OceanBase databases.\n- **[Octocode](https://github.com/bgauryy/octocode-mcp)** - (by Guy Bary) AI-powered developer assistant that enables advanced code research, analysis and discovery across GitHub and NPM realms in realtime\n- **[Odoo](https://github.com/ivnvxd/mcp-server-odoo)** - Connect AI assistants to Odoo ERP systems for business data access and workflow automation.\n- **[Office-PowerPoint-MCP-Server](https://github.com/GongRzhe/Office-PowerPoint-MCP-Server)** - A Model Context Protocol (MCP) server for creating, reading, and manipulating Microsoft PowerPoint documents.\n- **[Office-Visio-MCP-Server](https://github.com/GongRzhe/Office-Visio-MCP-Server)** - A Model Context Protocol (MCP) server for creating, reading, and manipulating Microsoft Visio documents.\n- **[Office-Word-MCP-Server](https://github.com/GongRzhe/Office-Word-MCP-Server)** - A Model Context Protocol (MCP) server for creating, reading, and manipulating Microsoft Word documents.\n- **[Okta](https://github.com/kapilduraphe/okta-mcp-server)** - Interact with Okta API.\n- **[OKX-MCP-Server](https://github.com/memetus/okx-mcp-playground)** - An MCP server provides various blockchain data and market price data via the OKX API. The server enables Claude to perform operations like retrieve assets prices, transaction data, account history data and trade instruction data.\n- **[OneNote](https://github.com/rajvirtual/MCP-Servers/tree/master/onenote)** - (by Rajesh Vijay) An MCP server that connects to Microsoft OneNote using the Microsoft Graph API. Reading notebooks, sections, and pages from OneNote,Creating new notebooks, sections, and pages in OneNote.\n- **[Onyx MCP Sandbox](https://github.com/avd1729/Onyx)** – (by Aravind) A secure MCP server that executes code in isolated Docker sandboxes. Supports Python, Java, C, C++, JavaScript, and Rust. Provides the `run_code` tool, enforces CPU/memory limits, includes comprehensive tests, and detailed setup instructions.\n- **[Open Strategy Partners Marketing Tools](https://github.com/open-strategy-partners/osp_marketing_tools)** - Content editing codes, value map, and positioning tools for product marketing.\n- **[OpenAI WebSearch MCP](https://github.com/ConechoAI/openai-websearch-mcp)** - This is a Python-based MCP server that provides OpenAI `web_search` built-in tool.\n- **[OpenAlex.org MCP](https://github.com/drAbreu/alex-mcp)** - Professional MCP server providing ML-powered author disambiguation and comprehensive researcher profiles using the OpenAlex database.\n- **[OpenAPI](https://github.com/snaggle-ai/openapi-mcp-server)** - Interact with [OpenAPI](https://www.openapis.org/) APIs.\n- **[OpenAPI AnyApi](https://github.com/baryhuang/mcp-server-any-openapi)** - Interact with large [OpenAPI](https://www.openapis.org/) docs using built-in semantic search for endpoints. Allows for customizing the MCP server prefix.\n- **[OpenAPI Schema](https://github.com/hannesj/mcp-openapi-schema)** - Allow LLMs to explore large [OpenAPI](https://www.openapis.org/) schemas without bloating the context.\n- **[OpenAPI Schema Explorer](https://github.com/kadykov/mcp-openapi-schema-explorer)** - Token-efficient access to local or remote OpenAPI/Swagger specs via MCP Resources.\n- **[OpenCTI](https://github.com/Spathodea-Network/opencti-mcp)** - Interact with OpenCTI platform to retrieve threat intelligence data including reports, indicators, malware and threat actors.\n- **[OpenCV](https://github.com/GongRzhe/opencv-mcp-server)** - An MCP server providing OpenCV computer vision capabilities. This allows AI assistants and language models to access powerful computer vision tools.\n- **[OpenDota](https://github.com/asusevski/opendota-mcp-server)** - Interact with OpenDota API to retrieve Dota 2 match data, player statistics, and more.\n- **[OpenLink Generic Java Database Connectivity](https://github.com/OpenLinkSoftware/mcp-jdbc-server)** - Generic Database Management System (DBMS) access via Open Database Connectivity (ODBC) Connectors (Drivers)\n- **[OpenLink Generic Open Database Connectivity](https://github.com/OpenLinkSoftware/mcp-odbc-server)** - Generic Database Management System (DBMS) access via Open Database Connectivity (ODBC) Connectors (Drivers)\n- **[OpenLink Generic Python Open Database Connectivity](https://github.com/OpenLinkSoftware/mcp-pyodbc-server)** - Generic Database Management System (DBMS) access via Open Database Connectivity (ODBC) Connectors (Drivers) for PyODBC\n- **[OpenLink Generic SQLAlchemy Object-Relational Database Connectivity for PyODBC](https://github.com/OpenLinkSoftware/mcp-sqlalchemy-server)** - Generic Database Management System (DBMS) access via SQLAlchemy (PyODBC) Connectors (Drivers)\n- **[OpenMetadata](https://github.com/yangkyeongmo/mcp-server-openmetadata)** - MCP Server for OpenMetadata, an open-source metadata management platform.\n- **[OpenNeuro](https://github.com/QuentinCody/open-neuro-mcp-server)** - Unofficial MCP server for OpenNeuro, providing access to open neuroimaging datasets, study metadata, and brain imaging data for neuroscience research and analysis.\n- **[OpenReview](https://github.com/anyakors/openreview-mcp-server)** - An MCP server for [OpenReview](https://openreview.net/) to fetch, read and save manuscripts from AI/ML conferences.\n- **[OpenRPC](https://github.com/shanejonas/openrpc-mpc-server)** - Interact with and discover JSON-RPC APIs via [OpenRPC](https://open-rpc.org).\n- **[OpenStack](https://github.com/wangsqly0407/openstack-mcp-server)** - MCP server implementation that provides OpenStack interaction.\n- **[Open Targets](https://github.com/QuentinCody/open-targets-mcp-server)** - Unofficial MCP server for the Open Targets Platform, providing access to target-disease associations, drug discovery data, and therapeutic hypothesis generation for biomedical research.\n- **[OpenWeather](https://github.com/mschneider82/mcp-openweather)** - Interact with the free openweathermap API to get the current and forecast weather for a location.\n- **[OpenZIM MCP](https://github.com/cameronrye/openzim-mcp)** - Modern, secure, and high-performance MCP server that enables AI models to access and search ZIM format knowledge bases offline, including Wikipedia and educational content archives.\n- **[Operative WebEvalAgent](https://github.com/Operative-Sh/web-eval-agent)** (by [Operative.sh](https://www.operative.sh)) - An MCP server to test, debug, and fix web applications autonomously.\n- **[OPNSense MCP](https://github.com/vespo92/OPNSenseMCP)** - MCP Server for OPNSense Firewall Management and API access\n- **[OpenAI GPT Image](https://github.com/SureScaleAI/openai-gpt-image-mcp)** - OpenAI GPT image generation/editing MCP server.\n- **[Optimade MCP](https://github.com/dianfengxiaobo/optimade-mcp-server)** - An MCP server conducts real-time material science data queries with the Optimade database (for example, elemental composition, crystal structure).\n- **[Oracle](https://github.com/marcelo-ochoa/servers)** (by marcelo-ochoa) - Oracle Database integration in NodeJS with configurable access controls, query explain, stats and schema inspection\n- **[Oracle Cloud Infrastructure (OCI)](https://github.com/karthiksuku/oci-mcp)** (by karthiksukumar) - Python MCP server for OCI infrastructure (Compute, Autonomous Database, Object Storage). Read-heavy by default with safe instance actions (start/stop/reset). Includes Claude Desktop config and `.env` compartment scoping.\n- **[Oura MCP server](https://github.com/tomekkorbak/oura-mcp-server)** - MCP server for Oura API to retrieve one's sleep data\n- **[Oura Ring](https://github.com/rajvirtual/oura-mcp-server)** (by Rajesh Vijay) - MCP Server to access and analyze your Oura Ring data. It provides a structured way to fetch and understand your health metrics.\n- **[Outline](https://github.com/Vortiago/mcp-outline)** - MCP Server to interact with [Outline](https://www.getoutline.com) knowledge base to search, read, create, and manage documents and their content, access collections, add comments, and manage document backlinks.\n- **[Outlook Mail + Calendar + OneDrive](https://github.com/Norcim133/OutlookMCPServer) - Virtual assistant with Outlook Mail, Calendar, and early OneDrive support (requires Azure admin).\n- **[Pacman](https://github.com/oborchers/mcp-server-pacman)** - An MCP server that provides package index querying capabilities. This server is able to search and retrieve information from package repositories like PyPI, npm, crates.io, Docker Hub, and Terraform Registry.\n- **[pancakeswap-poolspy-mcp](https://github.com/kukapay/pancakeswap-poolspy-mcp)** - An MCP server that tracks newly created liquidity pools on Pancake Swap.\n- **[Pandoc](https://github.com/vivekVells/mcp-pandoc)** - MCP server for seamless document format conversion using Pandoc, supporting Markdown, HTML, PDF, DOCX (.docx), csv and more.\n- **[Paradex MCP](https://github.com/sv/mcp-paradex-py)** - MCP native server for interacting with Paradex platform, including fully features trading.\n- **[Parliament MCP]([https://github.com/sv/mcp-paradex-py](https://github.com/i-dot-ai/parliament-mcp))** - MCP server for querying UK parliamentary data.\n- **[PDF reader MCP](https://github.com/gpetraroli/mcp_pdf_reader)** - MCP server to read and search text in a local PDF file.\n- **[PDF Tools MCP](https://github.com/Sohaib-2/pdf-mcp-server)** - Comprehensive PDF manipulation toolkit (merge, split, encrypt, optimize and much more)\n- **[PDMT](https://github.com/paiml/pdmt)** - Pragmatic Deterministic MCP Templating - High-performance deterministic templating library with comprehensive todo validation, quality enforcement, and 0.0 temperature generation for reproducible outputs.\n- **[Peacock for VS Code](https://github.com/johnpapa/peacock-mcp)** - MCP Server for the Peacock extension for VS Code, coloring your world, one Code editor at a time. The main goal of the project is to show how an MCP server can be used to interact with APIs.\n- **[persistproc](https://github.com/irskep/persistproc)** - MCP server + command line tool that allows agents to see & control long-running processes like web servers.\n- **[Pexels](https://github.com/garylab/pexels-mcp-server)** - A MCP server providing access to Pexels Free Image API, enabling seamless search, retrieval, and download of high-quality royalty-free images.\n- **[Pharos](https://github.com/QuentinCody/pharos-mcp-server)** - Unofficial MCP server for the Pharos database by the National Center for Advancing Translational Sciences (NCATS), providing access to target, drug, and disease information for drug discovery research.\n- **[Phone MCP](https://github.com/hao-cyber/phone-mcp)** - 📱 A powerful plugin that lets you control your Android phone. Enables AI agents to perform complex tasks like automatically playing music based on weather or making calls and sending texts.\n- **[PIF](https://github.com/hungryrobot1/MCP-PIF)** - A Personal Intelligence Framework (PIF), providing tools for file operations, structured reasoning, and journal-based documentation to support continuity and evolving human-AI collaboration across sessions.\n- **[Pinecone](https://github.com/sirmews/mcp-pinecone)** - MCP server for searching and uploading records to Pinecone. Allows for simple RAG features, leveraging Pinecone's Inference API.\n- **[Pinner MCP](https://github.com/safedep/pinner-mcp)** - An MCP server for pinning GitHub Actions and container base images to their immutable SHA hashes to prevent supply chain attacks.\n- **[Pixelle MCP](https://github.com/AIDC-AI/Pixelle-MCP)** - An omnimodal AIGC framework that seamlessly converts ComfyUI workflows into MCP tools with zero code, enabling full-modal support for Text, Image, Sound, and Video generation with Chainlit-based web interface.\n- **[Placid.app](https://github.com/felores/placid-mcp-server)** - Generate image and video creatives using Placid.app templates\n- **[Plane](https://github.com/kelvin6365/plane-mcp-server)** - This MCP Server will help you to manage projects and issues through Plane's API\n- **[Playwright](https://github.com/executeautomation/mcp-playwright)** - This MCP Server will help you run browser automation and webscraping using Playwright\n- **[Podbean](https://github.com/amurshak/podbeanMCP)** - MCP server for managing your podcasts, episodes, and analytics through the Podbean API. Allows for updating, adding, deleting podcasts, querying show description, notes, analytics, and more.\n- **[Polarsteps](https://github.com/remuzel/polarsteps-mcp)** - An MCP server to help you review your previous Trips and plan new ones!\n- **[PostgreSQL](https://github.com/ahmedmustahid/postgres-mcp-server)** - A PostgreSQL MCP server offering dual HTTP/Stdio transports for database schema inspection and read-only query execution with session management and Podman(or Docker) support.\n- **[Postman](https://github.com/shannonlal/mcp-postman)** - MCP server for running Postman Collections locally via Newman. Allows for simple execution of Postman Server and returns the results of whether the collection passed all the tests.\n- **[Powerdrill](https://github.com/powerdrillai/powerdrill-mcp)** - Interact with Powerdrill datasets, authenticated with [Powerdrill](https://powerdrill.ai) User ID and Project API Key.\n- **[Prefect](https://github.com/allen-munsch/mcp-prefect)** - MCP Server for workflow orchestration and ELT/ETL with Prefect Server, and Prefect Cloud [https://www.prefect.io/] using the `prefect` python client.\n- **[Productboard](https://github.com/kenjihikmatullah/productboard-mcp)** - Integrate the Productboard API into agentic workflows via MCP.\n- **[Prometheus](https://github.com/pab1it0/prometheus-mcp-server)** - Query and analyze Prometheus - open-source monitoring system.\n- **[Prometheus (TypeScript)](https://github.com/yanmxa/prometheus-mcp-server)** - Enable AI assistants to query Prometheus using natural language with TypeScript implementation.\n- **[Prometheus (Golang)](https://github.com/tjhop/prometheus-mcp-server/)** - A Prometheus MCP server with full API support for comprehensive management and deep interaction with Prometheus beyond basic query support. Written in go, it is a single binary install that is capable of STDIO, SSE, and HTTP transports for complex deployments. \n- **[PubChem](https://github.com/sssjiang/pubchem_mcp_server)** - extract drug information from pubchem API.\n- **[PubMed](https://github.com/JackKuo666/PubMed-MCP-Server)** - Enable AI assistants to search, access, and analyze PubMed articles through a simple MCP interface.\n- **[Pulumi](https://github.com/dogukanakkaya/pulumi-mcp-server)** - MCP Server to Interact with Pulumi API, creates and lists Stacks\n- **[Puppeteer vision](https://github.com/djannot/puppeteer-vision-mcp)** - Use Puppeteer to browse a webpage and return a high quality Markdown. Use AI vision capabilities to handle cookies, captchas, and other interactive elements automatically.\n- **[Pushover](https://github.com/ashiknesin/pushover-mcp)** - Send instant notifications to your devices using [Pushover.net](https://pushover.net/)\n- **[py-mcp-qdrant-rag](https://github.com/amornpan/py-mcp-qdrant-rag)** (by amornpan) - A Model Context Protocol server implementation that provides RAG capabilities through Qdrant vector database integration, enabling AI agents to perform semantic search and document retrieval with local or cloud-based embedding generation support across Mac, Linux, and Windows platforms.\n- **[pydantic/pydantic-ai/mcp-run-python](https://github.com/pydantic/pydantic-ai/tree/main/mcp-run-python)** - Run Python code in a secure sandbox via MCP tool calls, powered by Deno and Pyodide\n- **[Python CLI MCP](https://github.com/ofek/pycli-mcp)** - Interact with local Python command line applications.\n- **[QGIS](https://github.com/jjsantos01/qgis_mcp)** - connects QGIS to Claude AI through the MCP. This integration enables prompt-assisted project creation, layer loading, code execution, and more.\n- **[Qiniu MCP Server](https://github.com/qiniu/qiniu-mcp-server)** - The Model Context Protocol (MCP) Server built on Qiniu Cloud products supports users in accessing Qiniu Cloud Storage, intelligent multimedia services, and more through this MCP Server within the context of AI large model clients.\n- **[QuantConnect](https://github.com/taylorwilsdon/quantconnect-mcp)** - QuantConnect Algorithmic Trading Platform Orchestration MCP - Agentic LLM Driven Trading Strategy Design, Research & Implementation.\n- **[Quarkus](https://github.com/quarkiverse/quarkus-mcp-servers)** - MCP servers for the Quarkus Java framework.\n- **[QuickChart](https://github.com/GongRzhe/Quickchart-MCP-Server)** - A Model Context Protocol server for generating charts using QuickChart.io\n- **[Qwen_Max](https://github.com/66julienmartin/MCP-server-Qwen_Max)** - A Model Context Protocol (MCP) server implementation for the Qwen models.\n- **[RabbitMQ](https://github.com/kenliao94/mcp-server-rabbitmq)** - The MCP server that interacts with RabbitMQ to publish and consume messages.\n- **[RAE](https://github.com/rae-api-com/rae-mcp)** - MPC Server to connect your preferred model with rae-api.com, Roya Academy of Spanish Dictionary\n- **[RAG Local](https://github.com/renl/mcp-rag-local)** - This MCP server for storing and retrieving text passages locally based on their semantic meaning.\n- **[RAG Web Browser](https://github.com/apify/mcp-server-rag-web-browser)** An MCP server for Apify's open-source RAG Web Browser [Actor](https://apify.com/apify/rag-web-browser) to perform web searches, scrape URLs, and return content in Markdown.\n- **[Raindrop.io](https://github.com/hiromitsusasaki/raindrop-io-mcp-server)** - An integration that allows LLMs to interact with Raindrop.io bookmarks using the Model Context Protocol (MCP).\n- **[Random Number](https://github.com/zazencodes/random-number-mcp)** - Provides LLMs with essential random generation abilities, built entirely on Python's standard library.\n- **[RCSB PDB](https://github.com/QuentinCody/rcsb-pdb-mcp-server)** - Unofficial MCP server for the Research Collaboratory for Structural Bioinformatics Protein Data Bank (RCSB PDB), providing access to 3D protein structures, experimental data, and structural bioinformatics information.\n- **[Reaper](https://github.com/dschuler36/reaper-mcp-server)** - Interact with your [Reaper](https://www.reaper.fm/) (Digital Audio Workstation) projects.\n- **[Redbee](https://github.com/Tamsi/redbee-mcp)** - Redbee MCP server that provides support for interacting with Redbee API.\n- **[Redfish](https://github.com/nokia/mcp-redfish)** - Redfish MCP server that provides support for interacting with [DMTF Redfish API](https://www.dmtf.org/standards/redfish).\n- **[Redis](https://github.com/GongRzhe/REDIS-MCP-Server)** - Redis database operations and caching microservice server with support for key-value operations, expiration management, and pattern-based key listing.\n- **[Redis](https://github.com/prajwalnayak7/mcp-server-redis)** MCP server to interact with Redis Server, AWS Memory DB, etc for caching or other use-cases where in-memory and key-value based storage is appropriate\n- **[RedNote MCP](https://github.com/ifuryst/rednote-mcp)** - MCP server for accessing RedNote(XiaoHongShu, xhs) content\n- **[Reed Jobs](https://github.com/kld3v/reed_jobs_mcp)** - Search and retrieve job listings from Reed.co.uk.\n- **[Rememberizer AI](https://github.com/skydeckai/mcp-server-rememberizer)** - An MCP server designed for interacting with the Rememberizer data source, facilitating enhanced knowledge retrieval.\n- **[Replicate](https://github.com/deepfates/mcp-replicate)** - Search, run and manage machine learning models on Replicate through a simple tool-based interface. Browse models, create predictions, track their status, and handle generated images.\n- **[Resend](https://github.com/Klavis-AI/klavis/tree/main/mcp_servers/resend)** - Send email using Resend services\n- **[Revit MCP](https://github.com/revit-mcp)** - A service implementing the MCP protocol for Autodesk Revit.\n- **[Rijksmuseum](https://github.com/r-huijts/rijksmuseum-mcp)** - Interface with the Rijksmuseum API to search artworks, retrieve artwork details, access image tiles, and explore user collections.\n- **[Riot Games](https://github.com/jifrozen0110/mcp-riot)** - MCP server for League of Legends – fetch player info, ranks, champion stats, and match history via Riot API.\n- **[Rohlik](https://github.com/tomaspavlin/rohlik-mcp)** - Shop groceries across the Rohlik Group platforms (Rohlik.cz, Knuspr.de, Gurkerl.at, Kifli.hu, Sezamo.ro)\n- **[Rquest](https://github.com/xxxbrian/mcp-rquest)** - An MCP server providing realistic browser-like HTTP request capabilities with accurate TLS/JA3/JA4 fingerprints for bypassing anti-bot measures.\n- **[Rust MCP Filesystem](https://github.com/rust-mcp-stack/rust-mcp-filesystem)** - Fast, asynchronous MCP server for efficient handling of various filesystem operations built with the power of Rust.\n- **[SafetySearch](https://github.com/surabhya/SafetySearch)** - Real-time FDA food safety data: recalls, adverse events, analysis.\n- **[Salesforce MCP](https://github.com/smn2gnt/MCP-Salesforce)** - Interact with Salesforce Data and Metadata\n- **[Salesforce MCP (AiondaDotCom)](https://github.com/AiondaDotCom/mcp-salesforce)** - Universal Salesforce integration with OAuth authentication, smart learning system, comprehensive backup capabilities, and full CRUD operations for any Salesforce org including custom objects and fields.\n- **[Salesforce MCP Server](https://github.com/tsmztech/mcp-server-salesforce)** - Comprehensive Salesforce integration with tools for querying records, executing Apex, managing fields/objects, and handling debug logs\n- **[Scanova MCP Server](https://github.com/trycon/scanova-mcp)** - MCP server for creating and managing QR codes using the [Scanova](https://scanova.io) API. Provides tools for generating, managing, and downloading QR codes.\n- **[SchemaCrawler](https://github.com/schemacrawler/SchemaCrawler-MCP-Server-Usage)** - Connect to any relational database, and be able to get valid SQL, and ask questions like what does a certain column prefix mean.\n- **[SchemaFlow](https://github.com/CryptoRadi/schemaflow-mcp-server)** - Real-time PostgreSQL & Supabase database schema access for AI-IDEs via Model Context Protocol. Provides live database context through secure SSE connections with three powerful tools: get_schema, analyze_database, and check_schema_alignment. [SchemaFlow](https://schemaflow.dev)\n- **[Scholarly](https://github.com/adityak74/mcp-scholarly)** - An MCP server to search for scholarly and academic articles.\n- **[scrapling-fetch](https://github.com/cyberchitta/scrapling-fetch-mcp)** - Access text content from bot-protected websites. Fetches HTML/markdown from sites with anti-automation measures using Scrapling.\n- **[Screeny](https://github.com/rohanrav/screeny)** - Privacy-first macOS MCP server that provides visual context for AI agents through window screenshots\n- **[ScriptFlow](https://github.com/yanmxa/scriptflow-mcp)** - Transform complex, repetitive AI interactions into persistent, executable scripts with comprehensive script management (add, edit, remove, list, search, execute) and multi-language support (Bash, Python, Node.js, TypeScript).\n- **[SearXNG](https://github.com/ihor-sokoliuk/mcp-searxng)** - A Model Context Protocol Server for [SearXNG](https://docs.searxng.org)\n- **[SearXNG](https://github.com/erhwenkuo/mcp-searxng)** - An MCP server provide web searching via [SearXNG](https://docs.searxng.org) & retrieve url as makrdown.\n- **[SearXNG Public](https://github.com/pwilkin/mcp-searxng-public)** - A Model Context Protocol Server for retrieving data from public [SearXNG](https://docs.searxng.org) instances, with fallback support\n- **[SEC EDGAR](https://github.com/stefanoamorelli/sec-edgar-mcp)** - (by Stefano Amorelli) A community Model Context Protocol Server to access financial filings and data through the U.S. Securities and Exchange Commission ([SEC](https://www.sec.gov/)) `Electronic Data Gathering, Analysis, and Retrieval` ([EDGAR](https://www.sec.gov/submit-filings/about-edgar)) database\n- **[SEO MCP](https://github.com/cnych/seo-mcp)** - A free SEO tool MCP (Model Control Protocol) service based on Ahrefs data. Includes features such as backlinks, keyword ideas, and more. by [claudemcp](https://www.claudemcp.com/servers/seo-mcp).\n- **[Serper](https://github.com/garylab/serper-mcp-server)** - An MCP server that performs Google searches using [Serper](https://serper.dev).\n- **[ServiceNow](https://github.com/osomai/servicenow-mcp)** - An MCP server to interact with a ServiceNow instance\n- **[ShaderToy](https://github.com/wilsonchenghy/ShaderToy-MCP)** - This MCP server lets LLMs to interact with the ShaderToy API, allowing LLMs to learn from compute shaders examples and enabling them to create complex GLSL shaders that they are previously not capable of.\n- **[ShareSeer](https://github.com/shareseer/shareseer-mcp-server)** - MCP to Access SEC filings, financials & insider trading data in real time using [ShareSeer](https://shareseer.com)\n- **[Shell](https://github.com/sonirico/mcp-shell)** - Give hands to AI. MCP server to run shell commands securely, auditably, and on demand\n- **[Shodan MCP](https://github.com/Hexix23/shodan-mcp)** - MCP server to interact with [Shodan](https://www.shodan.io/)\n- **[Shopify](https://github.com/GeLi2001/shopify-mcp)** - MCP to interact with Shopify API including order, product, customers and so on.\n- **[Shopify Storefront](https://github.com/QuentinCody/shopify-storefront-mcp-server)** - Unofficial MCP server that allows AI agents to discover Shopify storefronts and interact with them to fetch products, collections, and other store data through the Storefront API.\n- **[Simple Loki MCP](https://github.com/ghrud92/simple-loki-mcp)** - A simple MCP server to query Loki logs using logcli.\n- **[Siri Shortcuts](https://github.com/dvcrn/mcp-server-siri-shortcuts)** - MCP to interact with Siri Shortcuts on macOS. Exposes all Shortcuts as MCP tools.\n- **[Skyvern](https://github.com/Skyvern-AI/skyvern/tree/main/integrations/mcp)** - MCP to let Claude / Windsurf / Cursor / your LLM control the browser\n- **[Slack](https://github.com/korotovsky/slack-mcp-server)** - The most powerful MCP server for Slack Workspaces. This integration supports both Stdio and SSE transports, proxy settings and does not require any permissions or bots being created or approved by Workspace admins 😏.\n- **[Slack](https://github.com/zencoderai/slack-mcp-server)** - Slack MCP server which supports both stdio and Streamable HTTP transports. Extended from the original Anthropic's implementation which is now [archived](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/slack)\n- **[Slidespeak](https://github.com/SlideSpeak/slidespeak-mcp)** - Create PowerPoint presentations using the [Slidespeak](https://slidespeak.com/) API.\n- **[Smartlead](https://github.com/jean-technologies/smartlead-mcp-server-local)** - MCP to connect to Smartlead. Additional, tooling, functionality, and connection to workflow automation platforms also available.\n- **[Snowflake](https://github.com/Snowflake-Labs/mcp)** - Open-source MCP server for Snowflake from official Snowflake-Labs supports prompting Cortex Agents, querying structured & unstructured data, object management, SQL execution, semantic view querying, and more. RBAC, fine-grained CRUD controls, and all authentication methods supported.\n- **[Snowflake](https://github.com/isaacwasserman/mcp-snowflake-server)** - This MCP server enables LLMs to interact with Snowflake databases, allowing for secure and controlled data operations.\n- **[Snowflake Cortex MCP Server](https://github.com/thisisbhanuj/Snowflake-Cortex-MCP-Server)** -This Snowflake MCP server provides tooling for Snowflake Cortex AI features, bringing these capabilities to the MCP ecosystem. When connected to an MCP Client (e.g. Claude for Desktop, fast-agent, Agentic Orchestration Framework), users can leverage these Cortex AI features.\n- **[SoccerDataAPI](https://github.com/yeonupark/mcp-soccer-data)** - This MCP server provides real-time football match data based on the SoccerDataAPI.\n- **[Solana Agent Kit](https://github.com/sendaifun/solana-agent-kit/tree/main/examples/agent-kit-mcp-server)** - This MCP server enables LLMs to interact with the Solana blockchain with help of Solana Agent Kit by SendAI, allowing for 40+ protocol actions and growing\n- **[Solr MCP](https://github.com/mjochum64/mcp-solr-search)** - This MCP server offers a basic functionality to perform a search on Solr servers.\n- **[Solver](https://github.com/szeider/mcp-solver)** - Solves constraint satisfaction and optimization problems .\n- **[Solvitor](https://github.com/Adeptus-Innovatio/solvitor-mcp)** – Solvitor MCP server provides tools to access reverse engineering tools that help developers extract IDL files from closed - source Solana smart contracts and decompile them.\n- **[Sourcerer](https://github.com/st3v3nmw/sourcerer-mcp)** - MCP for semantic code search & navigation that reduces token waste.\n- **[Specbridge](https://github.com/TBosak/specbridge)** - Easily turn your OpenAPI specs into MCP Tools.\n- **[Splunk](https://github.com/jkosik/mcp-server-splunk)** - Golang MCP server for Splunk (lists saved searches, alerts, indexes, macros...). Supports SSE and STDIO.\n- **[Spotify](https://github.com/varunneal/spotify-mcp)** - This MCP allows an LLM to play and use Spotify.\n- **[Spring Initializr](https://github.com/hpalma/springinitializr-mcp)** - This MCP allows an LLM to create Spring Boot projects with custom configurations. Instead of manually visiting start.spring.io, you can now ask your AI assistant to generate projects with specific dependencies, Java versions, and project structures.\n- **[Squad AI](https://github.com/the-basilisk-ai/squad-mcp)** – Product‑discovery and strategy platform integration. Create, query and update opportunities, solutions, outcomes, requirements and feedback from any MCP‑aware LLM.\n- **[SSH](https://github.com/AiondaDotCom/mcp-ssh)** - Agent for managing and controlling SSH connections.\n- **[SSH](https://github.com/classfang/ssh-mcp-server)** - An MCP server that can execute SSH commands remotely, upload files, download files, and so on.\n- **[SSH MCP Server](https://github.com/sinjab/mcp_ssh)** - A production-ready Model Context Protocol server for SSH automation with background execution, file transfers, and comprehensive timeout protection. Features structured output, progress tracking, and enterprise-grade testing (87% coverage).\n- **[sslmon](https://github.com/firesh/sslmon-mcp)** - Domain/HTTPS/SSL domain registration information and SSL certificate monitoring capabilities. Query domain registration and expiration information, and SSL certificate information and validity status for any domain.\n- **[Standard Korean Dictionary](https://github.com/privetin/stdict)** - Search the dictionary using API\n- **[Star Wars](https://github.com/johnpapa/mcp-starwars)** -MCP Server for the SWAPI Star Wars API. The main goal of the project is to show how an MCP server can be used to interact with APIs.\n- **[Starknet MCP Server](https://github.com/mcpdotdirect/starknet-mcp-server)** - A comprehensive MCP server for interacting with the Starknet blockchain, providing tools for querying blockchain data, resolving StarknetIDs, and performing token transfers.\n- **[Starwind UI](https://github.com/Boston343/starwind-ui-mcp/)** - This MCP provides relevant commands, documentation, and other information to allow LLMs to take full advantage of Starwind UI's open source Astro components.\n- **[Stellar](https://github.com/syronlabs/stellar-mcp/)** - This MCP server enables LLMs to interact with the Stellar blockchain to create accounts, check address balances, analyze transactions, view transaction history, mint new assets, interact with smart contracts and much more.\n- **[Stitch AI](https://github.com/StitchAI/stitch-ai-mcp/)** - Knowledge management system for AI agents with memory space creation and retrieval capabilities.\n- **[Stockfish](https://github.com/sonirico/mcp-stockfish)** - MCP server connecting AI systems to Stockfish chess engine\n- **[Storybook](https://github.com/stefanoamorelli/storybook-mcp-server)** (by Stefano Amorelli) - Interact with Storybook component libraries, enabling component discovery, story management, prop inspection, and visual testing across different viewports.\n- **[Strava](https://github.com/r-huijts/strava-mcp)** - Connect to the Strava API to access activity data, athlete profiles, segments, and routes, enabling fitness tracking and analysis with Claude.\n- **[Strava API](https://github.com/tomekkorbak/strava-mcp-server)** - MCP server for Strava API to retrieve one's activities\n- **[Stripe](https://github.com/atharvagupta2003/mcp-stripe)** - This MCP allows integration with Stripe for handling payments, customers, and refunds.\n- **[Substack/Medium](https://github.com/jonathan-politzki/mcp-writer-substack)** - Connect Claude to your Substack/Medium writing, enabling semantic search and analysis of your published content.\n- **[System Health](https://github.com/thanhtung0201/mcp-remote-system-health)** - The MCP (Multi-Channel Protocol) System Health Monitoring is a robust, real-time monitoring solution designed to provide comprehensive health metrics and alerts for remote Linux servers.\n- **[SystemSage](https://github.com/Tarusharma1/SystemSage)** - A powerful, cross-platform system management and monitoring tool for Windows, Linux, and macOS.\n- **[Talk To Figma](https://github.com/sonnylazuardi/cursor-talk-to-figma-mcp)** - This MCP server enables LLMs to interact with Figma, allowing them to read and modify designs programmatically.\n- **[Talk To Figma via Claude](https://github.com/gaganmanku96/talk-with-figma-claude)** - TMCP server that provides seamless Figma integration specifically for Claude Desktop, enabling design creation, modification, and real-time collaboration through natural language commands.\n- **[TAM MCP Server](https://github.com/gvaibhav/TAM-MCP-Server)** - Market research and business intelligence with TAM/SAM calculations and integration across 8 economic data sources: Alpha Vantage, BLS, Census Bureau, FRED, IMF, Nasdaq Data Link, OECD, and World Bank.\n- **[Tasks](https://github.com/flesler/mcp-tasks)** - An efficient task manager. Designed to minimize tool confusion and maximize LLM budget efficiency while providing powerful search, filtering, and organization capabilities across multiple file formats (Markdown, JSON, YAML)\n- **[Tavily search](https://github.com/RamXX/mcp-tavily)** - An MCP server for Tavily's search & news API, with explicit site inclusions/exclusions\n- **[TcpSocketMCP](https://github.com/SpaceyKasey/TcpSocketMCP/)** - A Model Context Protocol (MCP) server that provides raw TCP socket access, enabling AI models to interact directly with network services using raw TCP Sockets. Supports multiple concurrent connections, buffering of response data and triggering automatic responses.\n- **[TeamRetro](https://github.com/adepanges/teamretro-mcp-server)** - This MCP server allows LLMs to interact with TeamRetro, allowing LLMs to manage user, team, team member, retrospective, health check, action, agreement and fetch the reports.\n- **[Telegram](https://github.com/chigwell/telegram-mcp)** - An MCP server that provides paginated chat reading, message retrieval, and message sending capabilities for Telegram through Telethon integration.\n- **[Telegram-Client](https://github.com/chaindead/telegram-mcp)** - A Telegram API bridge that manages user data, dialogs, messages, drafts, read status, and more for seamless interactions.\n- **[Telegram-mcp-server](https://github.com/DLHellMe/telegram-mcp-server)** - Access Telegram channels and groups directly in Claude. Features dual-mode operation with API access (100x faster) or web scraping, unlimited post retrieval, and search functionality.\n- **[Template MCP Server](https://github.com/mcpdotdirect/template-mcp-server)** - A CLI tool to create a new Model Context Protocol server project with TypeScript support, dual transport options, and an extensible structure\n- **[Tempo](https://github.com/scottlepp/tempo-mcp-server)** - An MCP server to query traces/spans from [Grafana Tempo](https://github.com/grafana/tempo).\n- **[Teradata](https://github.com/arturborycki/mcp-teradata)** - his MCP server enables LLMs to interact with Teradata databases. This MCP Server support tools and prompts for multi task data analytics\n- **[Terminal-Control](https://github.com/GongRzhe/terminal-controller-mcp)** - An MCP server that enables secure terminal command execution, directory navigation, and file system operations through a standardized interface.\n- **[Terraform-Cloud](https://github.com/severity1/terraform-cloud-mcp)** - An MCP server that integrates AI assistants with the Terraform Cloud API, allowing you to manage your infrastructure through natural conversation.\n- **[Tideways](https://github.com/abuhamza/tideways-mcp-server)** - A Model Context Protocol server that enables AI assistants to query Tideways performance monitoring data and provide conversational performance insights for PHP applications.\n- **[TFT-Match-Analyzer](https://github.com/GeLi2001/tft-mcp-server)** - MCP server for teamfight tactics match history & match details fetching, providing user the detailed context for every match.\n- **[Thales CDSP CAKM MCP Server](https://github.com/sanyambassi/thales-cdsp-cakm-mcp-server)** - An MCP server for the Thales CipherTrust Data Security Platform (CDSP) Cloud Key Management (CAKM) connector. This MCP server supports Ms SQL and Oracle databases.\n- **[Thales CDSP CRDP MCP Server](https://github.com/sanyambassi/thales-cdsp-crdp-mcp-server)** - A Model Context Protocol (MCP) server that allows interacting with the CipherTrust RestFul Data Protection (CRDP) data protection service.\n- **[Thales CipherTrust Manager MCP Server](https://github.com/sanyambassi/ciphertrust-manager-mcp-server)** - MCP server for Thales CipherTrust Manager integration, enabling secure key management and cryptographic operations.\n- **[thegraph-mcp](https://github.com/kukapay/thegraph-mcp)** - An MCP server that powers AI agents with indexed blockchain data from The Graph.\n- **[TheHive MCP Server](https://github.com/redwaysecurity/the-hive-mcp-server)** - An MCP server for [TheHive](https://strangebee.com/thehive/) Security Incident Response Platform.\n- **[Things3 MCP](https://github.com/urbanogardun/things3-mcp)** - Things3 task management integration for macOS with comprehensive TODO, project, and tag management.\n- **[Think MCP](https://github.com/Rai220/think-mcp)** - Enhances any agent's reasoning capabilities by integrating the think-tools, as described in [Anthropic's article](https://www.anthropic.com/engineering/claude-think-tool).\n- **[Think Node MCP](https://github.com/abhinav-mangla/think-tool-mcp)** - Enhances any agent's reasoning capabilities by integrating the think-tools, as described in [Anthropic's article](https://www.anthropic.com/engineering/claude-think-tool). (Works with Node)\n- **[Ticketmaster](https://github.com/delorenj/mcp-server-ticketmaster)** - Search for events, venues, and attractions through the Ticketmaster Discovery API\n- **[Ticketmaster MCP Server](https://github.com/mochow13/ticketmaster-mcp-server)** - A Model Context Protocol (MCP) server implemented in Streamable HTTP transport that allows AI models to interact with the Ticketmaster Discovery API, enabling searching events, venues, and attractions.\n- **[TickTick](https://github.com/alexarevalo9/ticktick-mcp-server)** - A Model Context Protocol (MCP) server designed to integrate with the TickTick task management platform, enabling intelligent context-aware task operations and automation.\n- **[TigerGraph](https://github.com/custom-discoveries/TigerGraph_MCP)** - A community built MCP server that interacts with TigerGraph Graph Database.\n- **[tip.md](https://github.com/tipdotmd#-mcp-server-for-ai-assistants)** - An MCP server that enables AI assistants to interact with tip.md's crypto tipping functionality, allowing agents or supporters to tip registered developers directly from AI chat interfaces.\n- **[TMD Earthquake](https://github.com/amornpan/tmd-earthquake-server-1.0)** - 🌍 Real-time earthquake monitoring from Thai Meteorological Department. Features magnitude filtering, location-based search (Thai/English), today's events tracking, dangerous earthquake alerts, and comprehensive statistics. Covers regional and global seismic activities.\n- **[TMDB](https://github.com/Laksh-star/mcp-server-tmdb)** - This MCP server integrates with The Movie Database (TMDB) API to provide movie information, search capabilities, and recommendations.\n- **[Todoist](https://github.com/abhiz123/todoist-mcp-server)** - Interact with Todoist to manage your tasks.\n- **[Todos](https://github.com/tomelliot/todos-mcp)** - A practical todo list manager to use with your favourite chatbot.\n- **[token-minter-mcp](https://github.com/kukapay/token-minter-mcp)** - An MCP server providing tools for AI agents to mint ERC-20 tokens across multiple blockchains.\n- **[token-revoke-mcp](https://github.com/kukapay/token-revoke-mcp)** - An MCP server for checking and revoking ERC-20 token allowances across multiple blockchains.\n- **[Ton Blockchain MCP](https://github.com/devonmojito/ton-blockchain-mcp)** - An MCP server for interacting with Ton Blockchain.\n- **[TouchDesigner](https://github.com/8beeeaaat/touchdesigner-mcp)** - An MCP server for TouchDesigner, enabling interaction with TouchDesigner projects, nodes, and parameters.\n- **[Transcribe](https://github.com/transcribe-app/mcp-transcribe)** - An MCP server provides fast and reliable transcriptions for audio/video files and voice memos. It allows LLMs to interact with the text content of audio/video file.\n- **[Travel Planner](https://github.com/GongRzhe/TRAVEL-PLANNER-MCP-Server)** - Travel planning and itinerary management server integrating with Google Maps API for location search, place details, and route calculations.\n- **[Trello MCP Server](https://github.com/lioarce01/trello-mcp-server)** - An MCP server that interact with user Trello boards, modifying them with prompting.\n- **[Trino](https://github.com/tuannvm/mcp-trino)** - A high-performance Model Context Protocol (MCP) server for Trino implemented in Go.\n- **[Tripadvisor](https://github.com/pab1it0/tripadvisor-mcp)** - An MCP server that enables LLMs to interact with Tripadvisor API, supporting location data, reviews, and photos through standardized MCP interfaces\n- **[Triplyfy MCP](https://github.com/helpful-AIs/triplyfy-mcp)** - An MCP server that lets LLMs plan and manage itineraries with interactive maps in Triplyfy; manage itineraries, places and notes, and search/save flights.\n- **[TrueNAS Core MCP](https://github.com/vespo92/TrueNasCoreMCP)** - An MCP server for interacting with TrueNAS Core.\n- **[TuriX Computer Automation MCP](https://github.com/TurixAI/TuriX-CUA/tree/mac_mcp)** - MCP server for helping automation control your computer complete your pre-setting task.\n- **[Tyk API Management](https://github.com/TykTechnologies/tyk-dashboard-mcp)** - Chat with all of your organization's managed APIs and perform other API lifecycle operations, managing tokens, users, analytics, and more.\n- **[Typesense](https://github.com/suhail-ak-s/mcp-typesense-server)** - A Model Context Protocol (MCP) server implementation that provides AI models with access to Typesense search capabilities. This server enables LLMs to discover, search, and analyze data stored in Typesense collections.\n- **[UniFi Dream Machine](https://github.com/sabler/mcp-unifi)** An MCP server that gets your network telemetry from the UniFi Site Manager and your local UniFi router.\n- **[UniProt](https://github.com/QuentinCody/uniprot-mcp-server)** - Unofficial MCP server for UniProt, providing access to protein sequence data, functional annotations, taxonomic information, and cross-references for proteomics and bioinformatics research.\n- **[uniswap-poolspy-mcp](https://github.com/kukapay/uniswap-poolspy-mcp)** - An MCP server that tracks newly created liquidity pools on Uniswap across nine blockchain networks.\n- **[uniswap-trader-mcp](https://github.com/kukapay/uniswap-trader-mcp)** -An MCP server for AI agents to automate token swaps on Uniswap DEX across multiple blockchains.\n- **[Unity Catalog](https://github.com/ognis1205/mcp-server-unitycatalog)** - An MCP server that enables LLMs to interact with Unity Catalog AI, supporting CRUD operations on Unity Catalog Functions and executing them as MCP tools.\n- **[Unity Integration (Advanced)](https://github.com/quazaai/UnityMCPIntegration)** - Advanced Unity3d Game Engine MCP which supports ,Execution of Any Editor Related Code Directly Inside of Unity, Fetch Logs, Get Editor State and Allow File Access of the Project making it much more useful in Script Editing or asset creation.\n- **[Unity3d Game Engine](https://github.com/CoderGamester/mcp-unity)** - An MCP server that enables LLMs to interact with Unity3d Game Engine, supporting access to a variety of the Unit's Editor engine tools (e.g. Console Logs, Test Runner logs, Editor functions, hierarchy state, etc) and executing them as MCP tools or gather them as resources.\n- **[Universal MCP Servers](https://github.com/universal-mcp)** - A collection of MCP servers created using the [AgentR Universal MCP SDK](https://github.com/universal-mcp/universal-mcp).\n- **[Unleash Integration (Feature Toggle)](https://github.com/cuongtl1992/unleash-mcp)** - A Model Context Protocol (MCP) server implementation that integrates with Unleash Feature Toggle system. Provide a bridge between LLM applications and Unleash feature flag system\n- **[Upbit MCP Server](https://github.com/solangii/upbit-mcp-server)** – An MCP server that enables real - time access to cryptocurrency prices, market summaries, and asset listings from the Upbit exchange.\n- **[use_aws_mcp](https://github.com/runjivu/use_aws_mcp)** - amazon-q-cli's use_aws tool extracted into independent mcp, for general aws api usage.\n- **[User Feedback](https://github.com/mrexodia/user-feedback-mcp)** - Simple MCP Server to enable a human-in-the-loop workflow in tools like Cline and Cursor.\n- **[USPTO](https://github.com/riemannzeta/patent_mcp_server)** - MCP server for accessing United States Patent & Trademark Office data through its Open Data Protocol (ODP) API.\n- **[Vectara](https://github.com/vectara/vectara-mcp)** - Query Vectara's trusted RAG-as-a-service platform.\n- **[Vega-Lite](https://github.com/isaacwasserman/mcp-vegalite-server)** - Generate visualizations from fetched data using the VegaLite format and renderer.\n- **[Vertica](https://github.com/nolleh/mcp-vertica)** - Vertica database integration in Python with configurable access controls and schema inspection\n- **[Vibe Check](https://github.com/PV-Bhat/vibe-check-mcp-server)** - An MCP server leveraging an external oversight layer to \"vibe check\" agents, and also self-improve accuracy & user alignment over time. Prevents scope creep, code bloat, misalignment, misinterpretation, tunnel vision, and overcomplication.\n- **[Video Editor](https://github.com/burningion/video-editing-mcp)** - A Model Context Protocol Server to add, edit, and search videos with [Video Jungle](https://www.video-jungle.com/).\n- **[Video Still Capture](https://github.com/13rac1/videocapture-mcp)** - 📷 Capture video stills from an OpenCV-compatible webcam or other video source.\n- **[Virtual location (Google Street View,etc.)](https://github.com/mfukushim/map-traveler-mcp)** - Integrates Google Map, Google Street View, PixAI, Stability.ai, ComfyUI API and Bluesky to provide a virtual location simulation in LLM (written in Effect.ts)\n- **[VMware Fusion](https://github.com/yeahdongcn/vmware-fusion-mcp-server)** - Manage VMware Fusion virtual machines via the Fusion REST API.\n- **[VoiceMode](https://github.com/mbailey/voicemode)** - Enable voice conversations with Claude using any OpenAI-compatible STT/TTS service [getvoicemode.com](https://getvoicemode.com/)\n- **[Voice Status Report](https://github.com/tomekkorbak/voice-status-report-mcp-server)** - An MCP server that provides voice status updates using OpenAI's text-to-speech API, to be used with Cursor or Claude Code.\n- **[VolcEngine TOS](https://github.com/dinghuazhou/sample-mcp-server-tos)** - A sample MCP server for VolcEngine TOS that flexibly get objects from TOS.\n- **[Voyp](https://github.com/paulotaylor/voyp-mcp)** - VOYP MCP server for making calls using Artificial Intelligence.\n- **[vulnicheck](https://github.com/andrasfe/vulnicheck)** - Real-time Python package vulnerability scanner that checks dependencies against OSV and NVD databases, providing comprehensive security analysis with CVE details, lock file support, and actionable upgrade recommendations.\n- **[Wanaku MCP Router](https://github.com/wanaku-ai/wanaku/)** - The Wanaku MCP Router is a SSE-based MCP server that provides an extensible routing engine that allows integrating your enterprise systems with AI agents.\n- **[weather-mcp-server](https://github.com/devilcoder01/weather-mcp-server)** - Get real-time weather data for any location using weatherapi.\n- **[Web Search MCP](https://github.com/mrkrsl/web-search-mcp)** - A server that provides full web search, summaries and page extration for use with Local LLMs.\n- **[Webex](https://github.com/Kashyap-AI-ML-Solutions/webex-messaging-mcp-server)** - A Model Context Protocol (MCP) server that provides AI assistants with comprehensive access to Cisco Webex messaging capabilities.\n- **[Webflow](https://github.com/kapilduraphe/webflow-mcp-server)** - Interact with the Webflow APIs\n- **[webhook-mcp](https://github.com/noobnooc/webhook-mcp)** (by Nooc) - A Model Context Protocol (MCP) server that sends webhook notifications when called.\n- **[whale-tracker-mcp](https://github.com/kukapay/whale-tracker-mcp)**  -  A mcp server for tracking cryptocurrency whale transactions.\n- **[WhatsApp MCP Server](https://github.com/lharries/whatsapp-mcp)** - MCP server for your personal WhatsApp handling individuals, groups, searching and sending.\n- **[Whois MCP](https://github.com/bharathvaj-ganesan/whois-mcp)** - MCP server that performs whois lookup against domain, IP, ASN and TLD.\n- **[Wikidata MCP](https://github.com/zzaebok/mcp-wikidata)** - Wikidata MCP server that interact with Wikidata, by searching identifiers, extracting metadata, and executing sparql query.\n- **[Wikidata SPARQL](https://github.com/QuentinCody/wikidata-sparql-mcp-server)** - Unofficial REMOTE MCP server for Wikidata's SPARQL endpoint, providing access to structured knowledge data, entity relationships, and semantic queries for research and data analysis.\n- **[Wikifunctions](https://github.com/Fredibau/wikifunctions-mcp-fredibau)** - Allowing AI models to discover and execute functions from the WikiFunctions library.\n- **[Wikipedia MCP](https://github.com/Rudra-ravi/wikipedia-mcp)** - Access and search Wikipedia articles via MCP for AI-powered information retrieval.\n- **[WildFly MCP](https://github.com/wildfly-extras/wildfly-mcp)** - WildFly MCP server that enables LLM to interact with running WildFly servers (retrieve metrics, logs, invoke operations, ...).\n- **[Windows CLI](https://github.com/SimonB97/win-cli-mcp-server)** - MCP server for secure command-line interactions on Windows systems, enabling controlled access to PowerShell, CMD, and Git Bash shells.\n- **[Windsor](https://github.com/windsor-ai/windsor_mcp)** - Windsor MCP (Model Context Protocol) enables your LLM to query, explore, and analyze your full-stack business data integrated into Windsor.ai with zero SQL writing or custom scripting.\n- **[Wordle MCP](https://github.com/cr2007/mcp-wordle-python)** - MCP Server that gets the Wordle Solution for a particular date.\n- **[WordPress MCP](https://github.com/Automattic/wordpress-mcp)** - Make your WordPress site into a simple MCP server, exposing functionality to LLMs and AI agents.\n- **[Workflowy](https://github.com/danield137/mcp-workflowy)** - A server that interacts with [workflowy](https://workflowy.com/).\n- **[World Bank data API](https://github.com/anshumax/world_bank_mcp_server)** - A server that fetches data indicators available with the World Bank as part of their data API\n- **[Wren Engine](https://github.com/Canner/wren-engine)** - The Semantic Engine for Model Context Protocol(MCP) Clients and AI Agents\n- **[X (Twitter)](https://github.com/EnesCinr/twitter-mcp)** (by EnesCinr) - Interact with twitter API. Post tweets and search for tweets by query.\n- **[X (Twitter)](https://github.com/vidhupv/x-mcp)** (by vidhupv) - Create, manage and publish X/Twitter posts directly through Claude chat.\n- **[Xcode](https://github.com/r-huijts/xcode-mcp-server)** - MCP server that brings AI to your Xcode projects, enabling intelligent code assistance, file operations, project management, and automated development tasks.\n- **[Xcode-mcp-server](https://github.com/drewster99/xcode-mcp-server)** (by drewster99) - Best Xcode integration - ClaudeCode and Cursor can build your project *with* Xcode and see the same errors you do. Fast easy setup.\n- **[xcodebuild](https://github.com/ShenghaiWang/xcodebuild)**  - 🍎 Build iOS Xcode workspace/project and feed back errors to llm.\n- **[Xero-mcp-server](https://github.com/john-zhang-dev/xero-mcp)** - Enabling clients to interact with Xero system for streamlined accounting, invoicing, and business operations.\n- **[XiYan](https://github.com/XGenerationLab/xiyan_mcp_server)** - 🗄️ An MCP server that supports fetching data from a database using natural language queries, powered by XiyanSQL as the text-to-SQL LLM.\n- **[XMind](https://github.com/apeyroux/mcp-xmind)** - Read and search through your XMind directory containing XMind files.\n- **[Yahoo Finance](https://github.com/AgentX-ai/yahoo-finance-server)** - 📈 Lets your AI interact with Yahoo Finance to get comprehensive stock market data, news, financials, and more. Proxy supported.\n- **[yfinance](https://github.com/Adity-star/mcp-yfinance-server)** -💹The MCP YFinance Stock Server provides real-time and historical stock data in a standard format, powering dashboards, AI agents,and research tools with seamless financial insights.\n- **[YNAB](https://github.com/ChuckBryan/ynabmcpserver)** - A Model Context Protocol (MCP) server for integrating with YNAB (You Need A Budget), allowing AI assistants to securely access and analyze your financial data.\n- **[YouTrack](https://github.com/tonyzorin/youtrack-mcp)** - A Model Context Protocol (MCP) server implementation for JetBrains YouTrack, allowing AI assistants to interact with YouTrack issue tracking system.\n- **[YouTube](https://github.com/Klavis-AI/klavis/tree/main/mcp_servers/youtube)** - Extract Youtube video information (with proxies support).\n- **[YouTube](https://github.com/ZubeidHendricks/youtube-mcp-server)** - Comprehensive YouTube API integration for video management, Shorts creation, and analytics.\n- **[YouTube DLP](https://github.com/AgentX-ai/youtube-dlp-server)** - Retrieve video information, subtitles, and top comments with proxies.\n- **[YouTube MCP](https://github.com/aardeshir/youtube-mcp)** - Create playlists from song lists with OAuth2. Search videos, manage playlists, let AI curate your YouTube collections.\n- **[Youtube Uploader MCP](https://github.com/anwerj/youtube-uploader-mcp)** - AI‑powered YouTube uploader—no CLI, no YouTube Studio.\n- **[YouTube Video Summarizer](https://github.com/nabid-pf/youtube-video-summarizer-mcp)** - Summarize lengthy youtube videos.\n- **[yutu](https://github.com/eat-pray-ai/yutu)** - A fully functional MCP server and CLI for YouTube to automate YouTube operation.\n- **[ZapCap](https://github.com/bogdan01m/zapcap-mcp-server)** - MCP server for ZapCap API providing video caption and B-roll generation via natural language\n- **[Zettelkasten](https://github.com/joshylchen/zettelkasten)**- Comprehensive AI-powered knowledge management system implementing the Zettelkasten method. Features atomic note creation, full-text search, AI-powered CEQRC workflows (Capture→Explain→Question→Refine→Connect), intelligent link discovery, and multi-interface access (CLI, API, Web UI, MCP). Perfect for researchers, students, and knowledge workers.\n- **[ZincBind](https://github.com/QuentinCody/zincbind-mcp-server)** - Unofficial MCP server for ZincBind, providing access to a comprehensive database of zinc binding sites in proteins, structural coordination data, and metalloproteomics research information.\n- **[Zoom](https://github.com/Prathamesh0901/zoom-mcp-server/tree/main)** - Create, update, read and delete your zoom meetings.\n## 📚 Frameworks\n\nThese are high-level frameworks that make it easier to build MCP servers or clients.\n\n### For servers\n\n* **[Anubis MCP](https://github.com/zoedsoupe/anubis-mcp)** (Elixir) - A high-performance and high-level Model Context Protocol (MCP) implementation in Elixir. Think like \"Live View\" for MCP.\n* **[ModelFetch](https://github.com/phuctm97/modelfetch/)** (TypeScript) - Runtime-agnostic SDK to create and deploy MCP servers anywhere TypeScript/JavaScript runs\n* **[EasyMCP](https://github.com/zcaceres/easy-mcp/)** (TypeScript)\n* **[FastAPI to MCP auto generator](https://github.com/tadata-org/fastapi_mcp)** – A zero-configuration tool for automatically exposing FastAPI endpoints as MCP tools by **[Tadata](https://tadata.com/)**\n* **[FastMCP](https://github.com/punkpeye/fastmcp)** (TypeScript)\n* **[Foobara MCP Connector](https://github.com/foobara/mcp-connector)** - Easily expose Foobara commands written in Ruby as tools via MCP\n* **[Foxy Contexts](https://github.com/strowk/foxy-contexts)** – A library to build MCP servers in Golang by **[strowk](https://github.com/strowk)**\n* **[Higress MCP Server Hosting](https://github.com/alibaba/higress/tree/main/plugins/wasm-go/mcp-servers)** - A solution for hosting MCP Servers by extending the API Gateway (based on Envoy) with wasm plugins.\n* **[MCP Declarative Java SDK](https://github.com/codeboyzhou/mcp-declarative-java-sdk)** Annotation-driven MCP servers development with Java, no Spring Framework Required, minimize dependencies as much as possible.\n* **[MCP-Framework](https://mcp-framework.com)** Build MCP servers with elegance and speed in TypeScript. Comes with a CLI to create your project with `mcp create app`. Get started with your first server in under 5 minutes by **[Alex Andru](https://github.com/QuantGeekDev)**\n* **[MCP Plexus](https://github.com/Super-I-Tech/mcp_plexus)**: A secure, **multi-tenant** and Multi-user MCP python server framework built to integrate easily with external services via OAuth 2.1, offering scalable and robust solutions for managing complex AI applications.\n* **[mcp_sse (Elixir)](https://github.com/kEND/mcp_sse)** An SSE implementation in Elixir for rapidly creating MCP servers.\n* **[mxcp](https://github.com/raw-labs/mxcp)** (Python) - Open-source framework for building enterprise-grade MCP servers using just YAML, SQL, and Python, with built-in auth, monitoring, ETL and policy enforcement.\n* **[Next.js MCP Server Template](https://github.com/vercel-labs/mcp-for-next.js)** (Typescript) - A starter Next.js project that uses the MCP Adapter to allow MCP clients to connect and access resources.\n* **[PayMCP](https://github.com/blustAI/paymcp)** (Python & TypeScript) - Lightweight payments layer for MCP servers: turn tools into paid endpoints with a two-line decorator. [PyPI](https://pypi.org/project/paymcp/) · [npm](https://www.npmjs.com/package/paymcp) · [TS repo](https://github.com/blustAI/paymcp-ts)\n* **[Perl SDK](https://github.com/mojolicious/mojo-mcp)** - An SDK for building MCP servers and clients with the Perl programming language.\n* **[Quarkus MCP Server SDK](https://github.com/quarkiverse/quarkus-mcp-server)** (Java)\n- **[R mcptools](https://github.com/posit-dev/mcptools)** - An R SDK for creating R-based MCP servers and retrieving functionality from third-party MCP servers as R functions.\n* **[SAP ABAP MCP Server SDK](https://github.com/abap-ai/mcp)** - Build SAP ABAP based MCP servers. ABAP 7.52 based with 7.02 downport; runs on R/3 & S/4HANA on-premises, currently not cloud-ready.\n* **[Spring AI MCP Server](https://docs.spring.io/spring-ai/reference/api/mcp/mcp-server-boot-starter-docs.html)** - Provides auto-configuration for setting up an MCP server in Spring Boot applications.\n* **[Template MCP Server](https://github.com/mcpdotdirect/template-mcp-server)** - A CLI tool to create a new Model Context Protocol server project with TypeScript support, dual transport options, and an extensible structure\n* **[AgentR Universal MCP SDK](https://github.com/universal-mcp/universal-mcp)** - A python SDK to build MCP Servers with inbuilt credential management by **[Agentr](https://agentr.dev/home)**\n* **[Vercel MCP Adapter](https://github.com/vercel/mcp-adapter)** (TypeScript) - A simple package to start serving an MCP server on most major JS meta-frameworks including Next, Nuxt, Svelte, and more.\n* **[PHP MCP Server](https://github.com/php-mcp/server)** (PHP) - Core PHP implementation for the Model Context Protocol (MCP) server\n\n### For clients\n\n* **[codemirror-mcp](https://github.com/marimo-team/codemirror-mcp)** - CodeMirror extension that implements the Model Context Protocol (MCP) for resource mentions and prompt commands\n* **[llm-analysis-assistant](https://github.com/xuzexin-hz/llm-analysis-assistant)** <img height=\"12\" width=\"12\" src=\"https://raw.githubusercontent.com/xuzexin-hz/llm-analysis-assistant/refs/heads/main/src/llm_analysis_assistant/pages/html/imgs/favicon.ico\" alt=\"Langfuse Logo\" /> - A very streamlined mcp client that supports calling and monitoring stdio/sse/streamableHttp, and can also view request responses through the /logs page. It also supports monitoring and simulation of ollama/openai interface.\n* **[MCP-Agent](https://github.com/lastmile-ai/mcp-agent)** - A simple, composable framework to build agents using Model Context Protocol by **[LastMile AI](https://www.lastmileai.dev)**\n* **[Spring AI MCP Client](https://docs.spring.io/spring-ai/reference/api/mcp/mcp-client-boot-starter-docs.html)** - Provides auto-configuration for MCP client functionality in Spring Boot applications.\n* **[MCP CLI Client](https://github.com/vincent-pli/mcp-cli-host)** - A CLI host application that enables Large Language Models (LLMs) to interact with external tools through the Model Context Protocol (MCP).\n* **[OpenMCP Client](https://github.com/LSTM-Kirigaya/openmcp-client/)** - An all-in-one vscode/trae/cursor plugin for MCP server debugging. [Document](https://kirigaya.cn/openmcp/) & [OpenMCP SDK](https://kirigaya.cn/openmcp/sdk-tutorial/).\n* **[PHP MCP Client](https://github.com/php-mcp/client)** - Core PHP implementation for the Model Context Protocol (MCP) Client\n\n\n## 📚 Resources\n\nAdditional resources on MCP.\n\n- **[A2A-MCP Java Bridge](https://github.com/vishalmysore/a2ajava)** - A2AJava brings powerful A2A-MCP integration directly into your Java applications. It enables developers to annotate standard Java methods and instantly expose them as MCP Server, A2A-discoverable actions — with no boilerplate or service registration overhead.\n- **[AiMCP](https://www.aimcp.info)** - A collection of MCP clients&servers to find the right mcp tools by **[Hekmon](https://github.com/hekmon8)**\n- **[Awesome Crypto MCP Servers by badkk](https://github.com/badkk/awesome-crypto-mcp-servers)** - A curated list of MCP servers by **[Luke Fan](https://github.com/badkk)**\n- **[Awesome MCP Servers by appcypher](https://github.com/appcypher/awesome-mcp-servers)** - A curated list of MCP servers by **[Stephen Akinyemi](https://github.com/appcypher)**\n- **[Awesome MCP Servers by punkpeye](https://github.com/punkpeye/awesome-mcp-servers)** (**[website](https://glama.ai/mcp/servers)**) - A curated list of MCP servers by **[Frank Fiegel](https://github.com/punkpeye)**\n- **[Awesome MCP Servers by wong2](https://github.com/wong2/awesome-mcp-servers)** (**[website](https://mcpservers.org)**) - A curated list of MCP servers by **[wong2](https://github.com/wong2)**\n- **[Awesome Remote MCP Servers by JAW9C](https://github.com/jaw9c/awesome-remote-mcp-servers)** - A curated list of **remote** MCP servers, including their authentication support by **[JAW9C](https://github.com/jaw9c)**\n- **[Discord Server](https://glama.ai/mcp/discord)** – A community discord server dedicated to MCP by **[Frank Fiegel](https://github.com/punkpeye)**\n- **[Discord Server (ModelContextProtocol)](https://discord.gg/jHEGxQu2a5)** – Connect with developers, share insights, and collaborate on projects in an active Discord community dedicated to the Model Context Protocol by **[Alex Andru](https://github.com/QuantGeekDev)**\n- <img height=\"12\" width=\"12\" src=\"https://raw.githubusercontent.com/klavis-ai/klavis/main/static/klavis-ai.png\" alt=\"Klavis Logo\" /> **[Klavis AI](https://www.klavis.ai)** - Open Source MCP Infra. Hosted MCP servers and MCP clients on Slack and Discord.\n- **[MCP Badges](https://github.com/mcpx-dev/mcp-badges)** – Quickly highlight your MCP project with clear, eye-catching badges, by **[Ironben](https://github.com/nanbingxyz)**\n- **[MCPRepository.com](https://mcprepository.com/)** - A repository that indexes and organizes all MCP servers for easy discovery.\n- **[mcp-cli](https://github.com/wong2/mcp-cli)** - A CLI inspector for the Model Context Protocol by **[wong2](https://github.com/wong2)**\n- **[mcp-dockmaster](https://mcp-dockmaster.com)** - An Open-Sourced UI to install and manage MCP servers for Windows, Linux and macOS.\n- **[mcp-get](https://mcp-get.com)** - Command line tool for installing and managing MCP servers by **[Michael Latman](https://github.com/michaellatman)**\n- **[mcp-guardian](https://github.com/eqtylab/mcp-guardian)** - GUI application + tools for proxying / managing control of MCP servers by **[EQTY Lab](https://eqtylab.io)**\n- **[MCP Linker](https://github.com/milisp/mcp-linker)** - A cross-platform Tauri GUI tool for one-click setup and management of MCP servers, supporting Claude Desktop, Cursor, Windsurf, VS Code, Cline, and Neovim.\n- **[mcp-manager](https://github.com/zueai/mcp-manager)** - Simple Web UI to install and manage MCP servers for Claude Desktop by **[Zue](https://github.com/zueai)**\n- **[MCP Marketplace Web Plugin](https://github.com/AI-Agent-Hub/mcp-marketplace)** MCP Marketplace is a small Web UX plugin to integrate with AI applications, Support various MCP Server API Endpoint (e.g pulsemcp.com/deepnlp.org and more). Allowing user to browse, paginate and select various MCP servers by different categories. [Pypi](https://pypi.org/project/mcp-marketplace) | [Maintainer](https://github.com/AI-Agent-Hub) | [Website](http://www.deepnlp.org/store/ai-agent/mcp-server)\n- **[mcp.natoma.ai](https://mcp.natoma.ai)** – A Hosted MCP Platform to discover, install, manage and deploy MCP servers by **[Natoma Labs](https://www.natoma.ai)**\n- **[mcp.run](https://mcp.run)** - A hosted registry and control plane to install & run secure + portable MCP Servers.\n- **[MCPHub](https://www.mcphub.com)** - Website to list high quality MCP servers and reviews by real users. Also provide online chatbot for popular LLM models with MCP server support.\n- **[MCP Router](https://mcp-router.net)** – Free Windows and macOS app that simplifies MCP management while providing seamless app authentication and powerful log visualization by **[MCP Router](https://github.com/mcp-router/mcp-router)**\n- **[MCP Servers Hub](https://github.com/apappascs/mcp-servers-hub)** (**[website](https://mcp-servers-hub-website.pages.dev/)**) - A curated list of MCP servers by **[apappascs](https://github.com/apappascs)**\n- **[MCPServers.com](https://mcpservers.com)** - A growing directory of high-quality MCP servers with clear setup guides for a variety of MCP clients. Built by the team behind the **[Highlight MCP client](https://highlightai.com/)**\n- **[MCP Servers Rating and User Reviews](http://www.deepnlp.org/store/ai-agent/mcp-server)** - Website to rate MCP servers, write authentic user reviews, and [search engine for agent & mcp](http://www.deepnlp.org/search/agent)\n- **[MCP Sky](https://bsky.app/profile/brianell.in/feed/mcp)** - Bluesky feed for MCP related news and discussion by **[@brianell.in](https://bsky.app/profile/brianell.in)**\n- **[MCP X Community](https://x.com/i/communities/1861891349609603310)** – A X community for MCP by **[Xiaoyi](https://x.com/chxy)**\n- **[MCPHub](https://github.com/Jeamee/MCPHub-Desktop)** – An Open Source macOS & Windows GUI Desktop app for discovering, installing and managing MCP servers by **[Jeamee](https://github.com/jeamee)**\n- **[mcpm](https://github.com/pathintegral-institute/mcpm.sh)** ([website](https://mcpm.sh)) - MCP Manager (MCPM) is a Homebrew-like service for managing Model Context Protocol (MCP) servers across clients by **[Pathintegral](https://github.com/pathintegral-institute)**\n- **[MCPVerse](https://mcpverse.dev)** - A portal for creating & hosting authenticated MCP servers and connecting to them securely.\n- **[MCP Servers Search](https://github.com/atonomus/mcp-servers-search)** - An MCP server that provides tools for querying and discovering available MCP servers from this list.\n- **[Search MCP Server](https://github.com/krzysztofkucmierz/search-mcp-server)** - Recommends the most relevant MCP servers based on the client's query by searching this README file.\n- **[MCPWatch](https://github.com/kapilduraphe/mcp-watch)** - A comprehensive security scanner for Model Context Protocol (MCP) servers that detects vulnerabilities and security issues in your MCP server implementations.\n- <img height=\"12\" width=\"12\" src=\"https://mkinf.io/favicon-lilac.png\" alt=\"mkinf Logo\" /> **[mkinf](https://mkinf.io)** - An Open Source registry of hosted MCP Servers to accelerate AI agent workflows.\n- **[Open-Sourced MCP Servers Directory](https://github.com/chatmcp/mcp-directory)** - A curated list of MCP servers by **[mcpso](https://mcp.so)**\n- <img height=\"12\" width=\"12\" src=\"https://opentools.com/favicon.ico\" alt=\"OpenTools Logo\" /> **[OpenTools](https://opentools.com)** - An open registry for finding, installing, and building with MCP servers by **[opentoolsteam](https://github.com/opentoolsteam)**\n- **[PulseMCP](https://www.pulsemcp.com)** ([API](https://www.pulsemcp.com/api)) - Community hub & weekly newsletter for discovering MCP servers, clients, articles, and news by **[Tadas Antanavicius](https://github.com/tadasant)**, **[Mike Coughlin](https://github.com/macoughl)**, and **[Ravina Patel](https://github.com/ravinahp)**\n- **[r/mcp](https://www.reddit.com/r/mcp)** – A Reddit community dedicated to MCP by **[Frank Fiegel](https://github.com/punkpeye)**\n- **[r/modelcontextprotocol](https://www.reddit.com/r/modelcontextprotocol)** – A Model Context Protocol community Reddit page - discuss ideas, get answers to your questions, network with like-minded people, and showcase your projects! by **[Alex Andru](https://github.com/QuantGeekDev)**\n- **[MCP.ing](https://mcp.ing/)** - A list of MCP services for discovering MCP servers in the community and providing a convenient search function for MCP services by **[iiiusky](https://github.com/iiiusky)**\n- **[MCP Hunt](https://mcp-hunt.com)** - Realtime platform for discovering trending MCP servers with momentum tracking, upvoting, and community discussions - like Product Hunt meets Reddit for MCP\n- **[Smithery](https://smithery.ai/)** - A registry of MCP servers to find the right tools for your LLM agents by **[Henry Mao](https://github.com/calclavia)**\n- **[Toolbase](https://gettoolbase.ai)** - Desktop application that manages tools and MCP servers with just a few clicks - no coding required by **[gching](https://github.com/gching)**\n- **[ToolHive](https://github.com/StacklokLabs/toolhive)** - A lightweight utility designed to simplify the deployment and management of MCP servers, ensuring ease of use, consistency, and security through containerization by **[StacklokLabs](https://github.com/StacklokLabs)**\n- **[NetMind](https://www.netmind.ai/AIServices)** - Access powerful AI services via simple APIs or MCP servers to supercharge your productivity.\n\n## 🚀 Getting Started\n\n### Using MCP Servers in this Repository\nTypeScript-based servers in this repository can be used directly with `npx`.\n\nFor example, this will start the [Memory](src/memory) server:\n```sh\nnpx -y @modelcontextprotocol/server-memory\n```\n\nPython-based servers in this repository can be used directly with [`uvx`](https://docs.astral.sh/uv/concepts/tools/) or [`pip`](https://pypi.org/project/pip/). `uvx` is recommended for ease of use and setup.\n\nFor example, this will start the [Git](src/git) server:\n```sh\n# With uvx\nuvx mcp-server-git\n\n# With pip\npip install mcp-server-git\npython -m mcp_server_git\n```\n\nFollow [these](https://docs.astral.sh/uv/getting-started/installation/) instructions to install `uv` / `uvx` and [these](https://pip.pypa.io/en/stable/installation/) to install `pip`.\n\n### Using an MCP Client\nHowever, running a server on its own isn't very useful, and should instead be configured into an MCP client. For example, here's the Claude Desktop configuration to use the above server:\n\n```json\n{\n  \"mcpServers\": {\n    \"memory\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-memory\"]\n    }\n  }\n}\n```\n\nAdditional examples of using the Claude Desktop as an MCP client might look like:\n\n```json\n{\n  \"mcpServers\": {\n    \"filesystem\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-filesystem\", \"/path/to/allowed/files\"]\n    },\n    \"git\": {\n      \"command\": \"uvx\",\n      \"args\": [\"mcp-server-git\", \"--repository\", \"path/to/git/repo\"]\n    },\n    \"github\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-github\"],\n      \"env\": {\n        \"GITHUB_PERSONAL_ACCESS_TOKEN\": \"<YOUR_TOKEN>\"\n      }\n    },\n    \"postgres\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-postgres\", \"postgresql://localhost/mydb\"]\n    }\n  }\n}\n```\n\n## 🛠️ Creating Your Own Server\n\nInterested in creating your own MCP server? Visit the official documentation at [modelcontextprotocol.io](https://modelcontextprotocol.io/introduction) for comprehensive guides, best practices, and technical details on implementing MCP servers.\n\n## 🤝 Contributing\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md) for information about contributing to this repository.\n\n## 🔒 Security\n\nSee [SECURITY.md](SECURITY.md) for reporting security vulnerabilities.\n\n## 📜 License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## 💬 Community\n\n- [GitHub Discussions](https://github.com/orgs/modelcontextprotocol/discussions)\n\n## ⭐ Support\n\nIf you find MCP servers useful, please consider starring the repository and contributing new servers or improvements!\n\n---\n\nManaged by Anthropic, but built together with the community. The Model Context Protocol is open source and we encourage everyone to contribute their own servers and improvements!",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "modelcontextprotocol",
        "files",
        "document",
        "modelcontextprotocol servers",
        "google drive",
        "processing modelcontextprotocol"
      ],
      "category": "document-processing"
    },
    "nCrom--readme-updater-mcp": {
      "owner": "nCrom",
      "name": "readme-updater-mcp",
      "url": "https://github.com/nCrom/readme-updater-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/null.webp",
      "description": "Enhance your README.md files effortlessly by analyzing and resolving content conflicts with Ollama. Automatically update your documentation while ensuring consistency and clarity. Streamline your project documentation process with intelligent suggestions and conflict resolution.",
      "stars": 0,
      "forks": 0,
      "license": "Unknown",
      "language": "Unknown",
      "updated_at": "",
      "readme_content": "",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ncrom",
        "documentation",
        "document",
        "processing ncrom",
        "ncrom readme",
        "document processing"
      ],
      "category": "document-processing"
    },
    "narphorium--mcp-memex": {
      "owner": "narphorium",
      "name": "mcp-memex",
      "url": "https://github.com/narphorium/mcp-memex",
      "imageUrl": "/freedevtools/mcp/pfp/narphorium.webp",
      "description": "Analyze web content and enhance your knowledge base by extracting information from URLs, storing it as Markdown files for easy access. Integrates seamlessly with Obsidian to facilitate questioning and retrieval of insights from the curated content.",
      "stars": 9,
      "forks": 1,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-05-05T23:05:46Z",
      "readme_content": "# Memex for Model Context Protocol\n\nMemex is a tool for Model Context Protocol (MCP) that allows you to analyze web content and add it to your knowledge base.\n\nThe tool was inspired by the [Memex](docs/as_we_may_think.pdf) project by [Vannevar Bush](https://en.wikipedia.org/wiki/Vannevar_Bush).\n\n## Requirements\n\nYou will need API keys for the following services:\n\n- [Claude API](https://www.anthropic.com/en/claude)\n- [FireCrawl API](https://www.firecrawl.com/)\n- [Voyage API](https://voyageai.com/)\n\nThe knowledge base produced by this tool is stored as Markdown files so they can be viewed with any Markdown viewer but [Obsidian](https://obsidian.md/) is recommended.\n\n## Installation\n\n```bash\npip install mcp-memex\n```\n\nAdd the following to your `claude_desktop_config.json` and replace the placeholders with the actual paths and API keys:\n\n```json\n{\n  \"mcpServers\": {\n    \"memex\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"PATH_TO_LOCAL_MEMEX_REPO\",\n        \"run\",\n        \"mcp-memex\",\n        \"--index\",\n        \"PATH_TO_MEMEX_INDEX\",\n        \"--workspace\",\n        \"PATH_TO_OBSIDIAN_VAULT\"\n      ],\n      \"env\": {\n        \"ANTHROPIC_API_KEY\": \"YOUR-API-KEY\",\n        \"FIRECRAWL_API_KEY\": \"YOUR-API-KEY\",\n        \"VOYAGE_API_KEY\": \"YOUR-API-KEY\"\n      }\n    }\n  }\n}\n```\n\n## Usage\n\nStart by asking Claude a question with a list of URLs to reference.\n\n```\nWhat is the capital of France? \"https://en.wikipedia.org/wiki/France\"\n```\n\nOnce Claude has finished analyzing the content, you will see the results in your Obsidian vault. You can then ask questions about the content and Memex will use the knowledge base to answer your questions.\n\n```\nWhat is the capital of France?\n```\n\n## Development\n\nTo run the tool locally, you can use the following command:\n\n```bash\nnpx @modelcontextprotocol/inspector \\\n  uv \\\n  --directory PATH_TO_LOCAL_MEMEX_REPO \\\n  run \\\n  mcp-memex \\\n  --index PATH_TO_MEMEX_INDEX \\\n  --workspace PATH_TO_OBSIDIAN_VAULT\n```\n\nThen open the inspector and connect to the server.\n\nhttp://localhost:5173?timeout=30000",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "memex",
        "narphorium",
        "markdown",
        "mcp memex",
        "memex analyze",
        "narphorium mcp"
      ],
      "category": "document-processing"
    },
    "narumiruna--gitingest-mcp": {
      "owner": "narumiruna",
      "name": "gitingest-mcp",
      "url": "https://github.com/narumiruna/gitingest-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/narumiruna.webp",
      "description": "Analyze and ingest Git repositories to produce structured text digests of their codebases, providing summaries, file structures, and content. Customize file filtering and branch selection for tailored analysis.",
      "stars": 7,
      "forks": 5,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-03T13:27:11Z",
      "readme_content": "# Gitingest MCP Server\n\nA Model Context Protocol (MCP) server implementation that integrates with [gitingest](https://github.com/cyclotruc/gitingest) for turning any Git repository into a simple text digest of its codebase.\n\n<a href=\"https://glama.ai/mcp/servers/@narumiruna/gitingest-mcp\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@narumiruna/gitingest-mcp/badge\" alt=\"Gitingest Server MCP server\" />\n</a>\n\n## Features\n\n- Easy integration with AI assistants through the Model Context Protocol\n- Git repository analysis and ingestion capabilities\n- Support for filtering files by size, patterns, and branches\n- Returns comprehensive repository information including summaries, file structure, and content\n\n## Usage\n\n### Configuration Options\n\nAdd the following configuration to your AI assistant's settings to enable gitingest-mcp as an MCP server:\n\n#### PyPI Installation\n\n```json\n{\n  \"mcpServers\": {\n    \"gitingestmcp\": {\n      \"command\": \"uvx\",\n      \"args\": [\"gitingestmcp@latest\"]\n    }\n  }\n}\n```\n\n#### GitHub Installation\n\n```json\n{\n  \"mcpServers\": {\n    \"gitingestmcp\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"--from\",\n        \"git+https://github.com/narumiruna/gitingest-mcp\",\n        \"gitingestmcp\"\n      ]\n    }\n  }\n}\n```\n\n#### Local Installation\n\n```json\n{\n  \"mcpServers\": {\n    \"gitingestmcp\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"run\",\n        \"--directory\",\n        \"/home/<user>/workspace/gitingest-mcp\",\n        \"gitingestmcp\"\n      ]\n    }\n  }\n}\n```\n\n## API\n\nThe server provides the following tool:\n\n### `ingest_git`\n\nAnalyzes a Git repository and returns its content in a structured format.\n\n#### Parameters:\n\n- `source`: The URL of a Git repository or a local directory path\n- `max_file_size` (optional): Maximum allowed file size in bytes (default: 10MB)\n- `include_patterns` (optional): Pattern or set of patterns specifying files to include (e.g., \"\\*.md, src/\")\n- `exclude_patterns` (optional): Pattern or set of patterns specifying files to exclude\n- `branch` (optional): The branch to clone and analyze (default: \"main\")\n\n#### Returns:\n\nA string containing:\n\n1. Repository summary\n2. Tree-like structure of the files\n3. Content of the repository files\n\n## Resources\n\n- gitingest website: https://gitingest.com/\n- gitingest repository: https://github.com/cyclotruc/gitingest\n\n## License\n\nSee the [LICENSE](LICENSE) file for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "git",
        "gitingest",
        "repositories",
        "narumiruna gitingest",
        "ingest git",
        "processing narumiruna"
      ],
      "category": "document-processing"
    },
    "nathanonn--mcp-url-fetcher": {
      "owner": "nathanonn",
      "name": "mcp-url-fetcher",
      "url": "https://github.com/nathanonn/mcp-url-fetcher",
      "imageUrl": "/freedevtools/mcp/pfp/nathanonn.webp",
      "description": "Fetch and transform web content from any URL into formats like HTML, JSON, Markdown, or plain text. This MCP server supports various input types and intelligently detects source formats for seamless content conversion.",
      "stars": 4,
      "forks": 1,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-07-13T18:29:14Z",
      "readme_content": "# MCP URL Format Converter\n\nA Model Context Protocol (MCP) server that fetches content from any URL and converts it to your desired output format.\n\n## Overview\n\nMCP URL Format Converter provides tools for retrieving content from any web URL and transforming it into various formats (HTML, JSON, Markdown, or plain text), regardless of the original content type. It's designed to work with any MCP-compatible client, including Claude for Desktop, enabling LLMs to access, transform, and analyze web content in a consistent format.\n\n## Features\n\n- 🔄 **Format Conversion**: Transform any web content to HTML, JSON, Markdown, or plain text\n- 🌐 **Universal Input Support**: Handle websites, APIs, raw files, and more\n- 🔍 **Automatic Content Detection**: Intelligently identifies source format\n- 🧰 **Robust Library Support**: Uses industry-standard libraries:\n  - Cheerio for HTML parsing\n  - Marked for Markdown processing\n  - Fast-XML-Parser for XML handling\n  - CSVtoJSON for CSV conversion\n  - SanitizeHTML for security\n  - Turndown for HTML-to-Markdown conversion\n- 🔧 **Advanced Format Processing**:\n  - HTML parsing with metadata extraction\n  - JSON pretty-printing and structure preservation\n  - Markdown rendering with styling\n  - CSV-to-table conversion\n  - XML-to-JSON transformation\n- 📜 **History Tracking**: Maintains logs of recently fetched URLs\n- 🛡️ **Security Focus**: Content sanitization to prevent XSS attacks\n\n## Installation\n\n### Prerequisites\n\n- Node.js 16.x or higher\n- npm or yarn\n\n### Quick Start\n\n1. Clone the repository:\n\n   ```bash\n   git clone https://github.com/yourusername/mcp-url-converter.git\n   cd mcp-url-converter\n   ```\n\n2. Install dependencies:\n\n   ```bash\n   npm install\n   ```\n\n3. Build the project:\n\n   ```bash\n   npm run build\n   ```\n\n4. Run the server:\n   ```bash\n   npm start\n   ```\n\n## Integration with Claude for Desktop\n\n1. Open your Claude for Desktop configuration file:\n\n   - macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n\n2. Add the URL converter server to your configuration:\n\n   ```json\n   {\n     \"mcpServers\": {\n       \"url-converter\": {\n         \"command\": \"node\",\n         \"args\": [\"/absolute/path/to/mcp-url-converter/build/index.js\"]\n       }\n     }\n   }\n   ```\n\n3. Restart Claude for Desktop\n\n## Available Tools\n\n### `fetch`\n\nFetches content from any URL and automatically detects the best output format.\n\n**Parameters:**\n\n- `url` (string, required): The URL to fetch content from\n- `format` (string, optional): Format to convert to (`auto`, `html`, `json`, `markdown`, `text`). Default: `auto`\n\n**Example:**\n\n```\nCan you fetch https://example.com and choose the best format to display it?\n```\n\n### `fetch-json`\n\nFetches content from any URL and converts it to JSON format.\n\n**Parameters:**\n\n- `url` (string, required): The URL to fetch content from\n- `prettyPrint` (boolean, optional): Whether to pretty-print the JSON. Default: `true`\n\n**Example:**\n\n```\nCan you fetch https://example.com and convert it to JSON format?\n```\n\n### `fetch-html`\n\nFetches content from any URL and converts it to HTML format.\n\n**Parameters:**\n\n- `url` (string, required): The URL to fetch content from\n- `extractText` (boolean, optional): Whether to extract text content only. Default: `false`\n\n**Example:**\n\n```\nCan you fetch https://api.example.com/users and convert it to HTML?\n```\n\n### `fetch-markdown`\n\nFetches content from any URL and converts it to Markdown format.\n\n**Parameters:**\n\n- `url` (string, required): The URL to fetch content from\n\n**Example:**\n\n```\nCan you fetch https://example.com and convert it to Markdown?\n```\n\n### `fetch-text`\n\nFetches content from any URL and converts it to plain text format.\n\n**Parameters:**\n\n- `url` (string, required): The URL to fetch content from\n\n**Example:**\n\n```\nCan you fetch https://example.com and convert it to plain text?\n```\n\n### `web-search` and `deep-research`\n\nThese tools provide interfaces to Perplexity search capabilities (when supported by the MCP host).\n\n## Available Resources\n\n### `recent-urls://list`\n\nReturns a list of recently fetched URLs with timestamps and output formats.\n\n**Example:**\n\n```\nWhat URLs have I fetched recently?\n```\n\n## Security\n\nThis server implements several security measures:\n\n- HTML sanitization using `sanitize-html` to prevent XSS attacks\n- Content validation before processing\n- Error handling and safe defaults\n- Input parameter validation with Zod\n- Safe output encoding\n\n## Testing\n\nYou can test the server using the MCP Inspector:\n\n```bash\nnpm run test\n```\n\n## Troubleshooting\n\n### Common Issues\n\n1. **Connection errors**: Verify that the URL is accessible and correctly formatted\n2. **Conversion errors**: Some complex content may not convert cleanly between formats\n3. **Cross-origin issues**: Some websites may block requests from unknown sources\n\n### Debug Mode\n\nFor additional debugging information, set the `DEBUG` environment variable:\n\n```bash\nDEBUG=mcp:* npm start\n```\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## Acknowledgments\n\n- Built with the [Model Context Protocol](https://modelcontextprotocol.io/)\n- Uses modern, actively maintained libraries with security focus\n- Sanitization approach based on OWASP recommendations\n\n---\n\nLast updated: 29 March 2025\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcp",
        "formats",
        "html",
        "mcp url",
        "mcp server",
        "url formats"
      ],
      "category": "document-processing"
    },
    "nattyraz--youtube-mcp": {
      "owner": "nattyraz",
      "name": "youtube-mcp",
      "url": "https://github.com/nattyraz/youtube-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/nattyraz.webp",
      "description": "Extracts video metadata and captions from YouTube videos, converting them into customizable markdown formats. Supports multiple languages and offers search functionality within captions.",
      "stars": 2,
      "forks": 4,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-08-07T05:33:27Z",
      "readme_content": "# YouTube MCP Server\n\nA Model Context Protocol (MCP) server for interacting with YouTube videos. This server provides tools for extracting video metadata, captions, and converting them to markdown format with various templates.\n\n## Features\n\n- **Video Metadata**: Fetch comprehensive video information\n- **Caption Extraction**: Support for auto-generated and manual captions\n- **Multiple Languages**: Built-in support for English and French\n- **Template System**: Three built-in markdown templates:\n  - Basic: Simple transcript format\n  - Detailed: Full metadata with timestamps\n  - Search: Results highlighting with context\n- **Search Functionality**: Search within video captions\n- **Flexible Authentication**: Supports both API key and OAuth2 authentication\n\n## Prerequisites\n\n- Node.js (v16 or higher)\n- npm or yarn\n- A YouTube Data API key and/or OAuth2 credentials\n\n## Installation\n\n1. Clone the repository:\n```bash\ngit clone [repository-url]\ncd youtube-mcp\n```\n\n2. Install dependencies:\n```bash\nnpm install\n```\n\n3. Build the project:\n```bash\nnpm run build\n```\n\n## Configuration\n\nCreate a `.env` file in the root directory with your YouTube credentials:\n\n```env\nYOUTUBE_API_KEY=your_api_key\nYOUTUBE_CLIENT_ID=your_client_id\nYOUTUBE_CLIENT_SECRET=your_client_secret\nYOUTUBE_REFRESH_TOKEN=your_refresh_token  # Optional, for OAuth2\n```\n\n## MCP Configuration\n\nAdd the server to your MCP settings file (usually at `~/.config/Code/User/globalStorage/rooveterinaryinc.roo-cline/settings/cline_mcp_settings.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"youtube\": {\n      \"command\": \"node\",\n      \"args\": [\"path/to/youtube-mcp/build/index.js\"],\n      \"env\": {\n        \"YOUTUBE_API_KEY\": \"your_api_key\",\n        \"YOUTUBE_CLIENT_ID\": \"your_client_id\",\n        \"YOUTUBE_CLIENT_SECRET\": \"your_client_secret\"\n      },\n      \"disabled\": false,\n      \"alwaysAllow\": []\n    }\n  }\n}\n```\n\n## Usage\n\nThe server provides the following tools:\n\n### 1. Get Video Info\n```typescript\nuse_mcp_tool youtube get_video_info {\n  \"url\": \"https://www.youtube.com/watch?v=VIDEO_ID\"\n}\n```\n\n### 2. Get Captions\n```typescript\nuse_mcp_tool youtube get_captions {\n  \"url\": \"https://www.youtube.com/watch?v=VIDEO_ID\",\n  \"language\": \"en\"  // Optional, defaults to \"en\"\n}\n```\n\n### 3. Convert to Markdown\n```typescript\nuse_mcp_tool youtube convert_to_markdown {\n  \"url\": \"https://www.youtube.com/watch?v=VIDEO_ID\",\n  \"template_name\": \"detailed\",  // Optional, \"basic\", \"detailed\", or \"search\"\n  \"language\": \"en\",            // Optional\n  \"options\": {                 // Optional\n    \"include_chapters\": true,\n    \"search_term\": \"keyword\"   // Only for search template\n  }\n}\n```\n\n### 4. List Templates\n```typescript\nuse_mcp_tool youtube list_templates\n```\n\n## Dependencies\n\n```json\n{\n  \"dependencies\": {\n    \"@modelcontextprotocol/sdk\": \"latest\",\n    \"googleapis\": \"^146.0.0\",\n    \"google-auth-library\": \"^9.0.0\",\n    \"youtube-captions-scraper\": \"^2.0.0\",\n    \"express\": \"^4.18.2\",\n    \"open\": \"^9.1.0\"\n  },\n  \"devDependencies\": {\n    \"@types/node\": \"^20.0.0\",\n    \"typescript\": \"^5.0.0\",\n    \"tsx\": \"^4.0.0\"\n  }\n}\n```\n\n## OAuth2 Setup\n\nFor OAuth2 authentication (required for private video access):\n\n1. Create a project in the [Google Cloud Console](https://console.cloud.google.com)\n2. Enable the YouTube Data API v3\n3. Create OAuth2 credentials (Web application type)\n4. Run the authentication script:\n```bash\nnode src/get-api-key.js\n```\n5. Follow the browser prompts to authorize the application\n6. Copy the refresh token to your configuration\n\n## Customizing Templates\n\nYou can add custom templates by modifying the `DEFAULT_TEMPLATES` array in `src/index.ts`. Templates follow this structure:\n\n```typescript\ninterface MarkdownTemplate {\n  name: string;\n  description: string;\n  format: {\n    header?: string;\n    chapter_format?: string;\n    caption_block: string;\n    timestamp_format?: string;\n    search_result_format?: string;\n  }\n}\n```\n\n## License\n\nMIT\n\n## Contributing\n\n1. Fork the repository\n2. Create your feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add some amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "markdown",
        "nattyraz",
        "captions",
        "nattyraz youtube",
        "captions youtube",
        "youtube mcp"
      ],
      "category": "document-processing"
    },
    "ndchikin--reference-mcp": {
      "owner": "ndchikin",
      "name": "reference-mcp",
      "url": "https://github.com/ndchikin/reference-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/ndchikin.webp",
      "description": "Retrieve BibTeX-formatted citation data from CiteAs and Google Scholar to streamline citation management in research applications.",
      "stars": 9,
      "forks": 2,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-08-07T07:55:23Z",
      "readme_content": "# CiteAssist MCP server\n\n[![smithery badge](https://smithery.ai/badge/@ndchikin/reference-mcp)](https://smithery.ai/server/@ndchikin/reference-mcp)\n\nA Model Context Protocol server that provides BibTeX-formatted citation data from CiteAs and Google Scholar. Enhance your research workflow by integrating citation retrieval directly into your applications.\n\n## Components\n\n### Tools\n\n* `get_citeas_data` - Retrieve BibTeX-formatted citation for the specified resource from the CiteAs\n  * `resource` (string, required): DOI, URL, keyword\n* `get_scholar_data` - Retrieve BibTeX-formatted citations from the Google Scholar\n  * `query` (string, required): Search query\n  * `results` (integer, optional): Number of results (default: 2)\n\n## Quickstart\n\n### Install\n\n#### Claude Desktop\n\nOn MacOS: `~/Library/Application\\ Support/Claude/claude_desktop_config.json`\n\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\nDevelopment/Unpublished Servers Configuration:\n\n```json\n\"mcpServers\": {\n  \"reference-mcp\": {\n    \"command\": \"uv\",\n    \"args\": [\n      \"--directory\",\n      \"/path/to/project/dir\",\n      \"run\",\n      \"reference-mcp\"\n    ]\n  }\n}\n```\n\nPublished Servers Configuration:\n\n```json\n\"mcpServers\": {\n  \"reference-mcp\": {\n    \"command\": \"uvx\",\n    \"args\": [\n      \"reference-mcp\"\n    ]\n  }\n}\n```\n\n### Installing via Smithery\n\nTo install reference-mcp for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@ndchikin/reference-mcp):\n\n```bash\nnpx -y @smithery/cli install @ndchikin/reference-mcp --client claude\n```\n\n## Development\n\n### Building and Publishing\n\nTo prepare the package for distribution:\n\n1. Sync dependencies and update lockfile:\n```bash\nuv sync\n```\n\n2. Build package distributions:\n```bash\nuv build\n```\n\nThis will create source and wheel distributions in the `dist/` directory.\n\n3. Publish to PyPI:\n```bash\nuv publish\n```\n\nNote: You'll need to set PyPI credentials via environment variables or command flags:\n- Token: `--token` or `UV_PUBLISH_TOKEN`\n- Or username/password: `--username`/`UV_PUBLISH_USERNAME` and `--password`/`UV_PUBLISH_PASSWORD`\n\n### Debugging\n\nSince MCP servers run over stdio, debugging can be challenging. For the best debugging\nexperience, we strongly recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector).\n\nYou can launch the MCP Inspector via [`npm`](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm) with this command:\n\n```bash\nnpx @modelcontextprotocol/inspector uv --directory /path/to/project/dir run reference-mcp\n```\n\nUpon launching, the Inspector will display a URL that you can access in your browser to begin debugging.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "bibtex",
        "citation",
        "citeas",
        "citation management",
        "citation data",
        "streamline citation"
      ],
      "category": "document-processing"
    },
    "negokaz--excel-mcp-server": {
      "owner": "negokaz",
      "name": "excel-mcp-server",
      "url": "https://github.com/negokaz/excel-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/negokaz.webp",
      "description": "Read and write data in Microsoft Excel files, including text values and formulas. It supports creating new sheets and offers live editing and screen capture functionalities on Windows.",
      "stars": 539,
      "forks": 71,
      "license": "MIT License",
      "language": "Go",
      "updated_at": "2025-10-03T22:32:15Z",
      "readme_content": "# Excel MCP Server\n\n<img src=\"https://github.com/negokaz/excel-mcp-server/blob/main/docs/img/icon-800.png?raw=true\" width=\"128\">\n\n<a href=\"https://glama.ai/mcp/servers/@negokaz/excel-mcp-server\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@negokaz/excel-mcp-server/badge\" alt=\"Excel Server MCP server\" />\n</a>\n\n[![NPM Version](https://img.shields.io/npm/v/@negokaz/excel-mcp-server)](https://www.npmjs.com/package/@negokaz/excel-mcp-server)\n[![smithery badge](https://smithery.ai/badge/@negokaz/excel-mcp-server)](https://smithery.ai/server/@negokaz/excel-mcp-server)\n\nA Model Context Protocol (MCP) server that reads and writes MS Excel data.\n\n## Features\n\n- Read/Write text values\n- Read/Write formulas\n- Create new sheets\n\n**🪟Windows only:**\n- Live editing\n- Capture screen image from a sheet\n\nFor more details, see the [tools](#tools) section.\n\n## Requirements\n\n- Node.js 20.x or later\n\n## Supported file formats\n\n- xlsx (Excel book)\n- xlsm (Excel macro-enabled book)\n- xltx (Excel template)\n- xltm (Excel macro-enabled template)\n\n## Installation\n\n### Installing via NPM\n\nexcel-mcp-server is automatically installed by adding the following configuration to the MCP servers configuration.\n\nFor Windows:\n```json\n{\n    \"mcpServers\": {\n        \"excel\": {\n            \"command\": \"cmd\",\n            \"args\": [\"/c\", \"npx\", \"--yes\", \"@negokaz/excel-mcp-server\"],\n            \"env\": {\n                \"EXCEL_MCP_PAGING_CELLS_LIMIT\": \"4000\"\n            }\n        }\n    }\n}\n```\n\nFor other platforms:\n```json\n{\n    \"mcpServers\": {\n        \"excel\": {\n            \"command\": \"npx\",\n            \"args\": [\"--yes\", \"@negokaz/excel-mcp-server\"],\n            \"env\": {\n                \"EXCEL_MCP_PAGING_CELLS_LIMIT\": \"4000\"\n            }\n        }\n    }\n}\n```\n\n### Installing via Smithery\n\nTo install Excel MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@negokaz/excel-mcp-server):\n\n```bash\nnpx -y @smithery/cli install @negokaz/excel-mcp-server --client claude\n```\n\n<h2 id=\"tools\">Tools</h2>\n\n### `excel_describe_sheets`\n\nList all sheet information of specified Excel file.\n\n**Arguments:**\n- `fileAbsolutePath`\n    - Absolute path to the Excel file\n\n### `excel_read_sheet`\n\nRead values from Excel sheet with pagination.\n\n**Arguments:**\n- `fileAbsolutePath`\n    - Absolute path to the Excel file\n- `sheetName`\n    - Sheet name in the Excel file\n- `range`\n    - Range of cells to read in the Excel sheet (e.g., \"A1:C10\"). [default: first paging range]\n- `showFormula`\n    - Show formula instead of value [default: false]\n- `showStyle`\n    - Show style information for cells [default: false]\n\n### `excel_screen_capture`\n\n**[Windows only]** Take a screenshot of the Excel sheet with pagination.\n\n**Arguments:**\n- `fileAbsolutePath`\n    - Absolute path to the Excel file\n- `sheetName`\n    - Sheet name in the Excel file\n- `range`\n    - Range of cells to read in the Excel sheet (e.g., \"A1:C10\"). [default: first paging range]\n\n### `excel_write_to_sheet`\n\nWrite values to the Excel sheet.\n\n**Arguments:**\n- `fileAbsolutePath`\n    - Absolute path to the Excel file\n- `sheetName`\n    - Sheet name in the Excel file\n- `newSheet`\n    - Create a new sheet if true, otherwise write to the existing sheet\n- `range`\n    - Range of cells to read in the Excel sheet (e.g., \"A1:C10\").\n- `values`\n    - Values to write to the Excel sheet. If the value is a formula, it should start with \"=\"\n\n### `excel_create_table`\n\nCreate a table in the Excel sheet\n\n**Arguments:**\n- `fileAbsolutePath`\n    - Absolute path to the Excel file\n- `sheetName`\n    - Sheet name where the table is created\n- `range`\n    - Range to be a table (e.g., \"A1:C10\")\n- `tableName`\n    - Table name to be created\n\n### `excel_copy_sheet`\n\nCopy existing sheet to a new sheet\n\n**Arguments:**\n- `fileAbsolutePath`\n    - Absolute path to the Excel file\n- `srcSheetName`\n    - Source sheet name in the Excel file\n- `dstSheetName`\n    - Sheet name to be copied\n\n### `excel_format_range`\n\nFormat cells in the Excel sheet with style information\n\n**Arguments:**\n- `fileAbsolutePath`\n    - Absolute path to the Excel file\n- `sheetName`\n    - Sheet name in the Excel file\n- `range`\n    - Range of cells in the Excel sheet (e.g., \"A1:C3\")\n- `styles`\n    - 2D array of style objects for each cell. If a cell does not change style, use null. The number of items of the array must match the range size.\n    - Style object properties:\n        - `border`: Array of border styles (type, color, style)\n        - `font`: Font styling (bold, italic, underline, size, strike, color, vertAlign)\n        - `fill`: Fill/background styling (type, pattern, color, shading)\n        - `numFmt`: Custom number format string\n        - `decimalPlaces`: Number of decimal places (0-30)\n\n<h2 id=\"configuration\">Configuration</h2>\n\nYou can change the MCP Server behaviors by the following environment variables:\n\n### `EXCEL_MCP_PAGING_CELLS_LIMIT`\n\nThe maximum number of cells to read in a single paging operation.  \n[default: 4000]\n\n## License\n\nCopyright (c) 2025 Kazuki Negoro\n\nexcel-mcp-server is released under the [MIT License](LICENSE)",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "excel",
        "negokaz",
        "microsoft",
        "negokaz excel",
        "processing negokaz",
        "excel files"
      ],
      "category": "document-processing"
    },
    "nfshanq--mcp-invoice": {
      "owner": "nfshanq",
      "name": "mcp-invoice",
      "url": "https://github.com/nfshanq/mcp-invoice",
      "imageUrl": "/freedevtools/mcp/pfp/nfshanq.webp",
      "description": "Advanced OCR capabilities for invoice and receipt management, enabling data extraction from various formats and document merging for efficient handling.",
      "stars": 2,
      "forks": 1,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-05-06T06:07:14Z",
      "readme_content": "# MCP Invoice\n\n这是一个使用 Python 开发的 MCP (Model Context Protocol) 服务器项目，专注于发票和收据处理的工具集合。该项目利用 OCR 技术实现发票识别、数据提取和 PDF 处理功能，为 AI 助手提供发票处理能力。\n\n## 功能特点\n\n- 发票和收据 OCR 处理：\n  - 使用 macOS Vision framework 进行高精度文本识别\n  - 支持处理单个 PDF 或图片文件（JPEG、PNG）\n  - 支持批量处理目录下的所有发票和收据文件\n  - 支持中英文 OCR 识别，适用于各类发票格式\n  - 提供结构化数据提取，方便后续分析\n- PDF合并和管理功能：\n  - 支持将多个发票或收据 PDF 文件合并为一个\n  - 支持将多张发票图片（JPEG、PNG）合并为一个 PDF 文件\n  - 支持混合合并不同格式的发票和收据\n- 高效的内存处理方式，减少磁盘 I/O，提高处理速度\n\n## MCP 部署指南\n\n### 环境要求\n\n- macOS 系统（支持 Vision framework）\n- Python 3.10 或更高版本\n- uv 依赖管理工具\n\n### 从 GitHub 安装\n\n1. 确保已安装 uv：\n\n```bash\npip install uv\n```\n\n2. 从 GitHub 克隆项目并安装依赖：\n\n```bash\ngit clone https://github.com/[username]/mcp-invoice.git\ncd mcp-invoice\nuv venv\nsource .venv/bin/activate\nuv pip install -e .\n```\n\n### 安装 PDF 处理依赖\n\npdf2image 需要系统上安装 Poppler：\n\n```bash\nbrew install poppler\n```\n\n### 部署为 MCP 服务\n\n有两种方式部署 MCP 服务：\n\n#### 1. 直接运行服务器\n\n```bash\n# 标准模式\nmcp-invoice\n\n# 或启用调试模式（包含文本位置信息）\nMCP_INVOICE_DEBUG=true mcp-invoice\n```\n\n#### 2. 使用 invoice_server.py 脚本\n\n```bash\n# 标准模式\npython invoice_server.py\n\n# 或启用调试模式\nMCP_INVOICE_DEBUG=true python invoice_server.py\n```\n\n### 配置为系统服务\n\n可以将 MCP 服务配置为系统服务，使其在系统启动时自动运行：\n\n1. 创建 LaunchAgent plist 文件：\n\n```bash\nmkdir -p ~/Library/LaunchAgents\ncat > ~/Library/LaunchAgents/com.user.mcp-invoice.plist << EOF\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\">\n<plist version=\"1.0\">\n<dict>\n    <key>Label</key>\n    <string>com.user.mcp-invoice</string>\n    <key>ProgramArguments</key>\n    <array>\n        <string>$(which python)</string>\n        <string>$(pwd)/invoice_server.py</string>\n    </array>\n    <key>RunAtLoad</key>\n    <true/>\n    <key>KeepAlive</key>\n    <true/>\n    <key>StandardOutPath</key>\n    <string>$(pwd)/logs/mcp-invoice.log</string>\n    <key>StandardErrorPath</key>\n    <string>$(pwd)/logs/mcp-invoice-error.log</string>\n    <key>WorkingDirectory</key>\n    <string>$(pwd)</string>\n    <key>EnvironmentVariables</key>\n    <dict>\n        <key>PATH</key>\n        <string>/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin</string>\n    </dict>\n</dict>\n</plist>\nEOF\n\n# 创建日志目录\nmkdir -p logs\n\n# 加载服务\nlaunchctl load ~/Library/LaunchAgents/com.user.mcp-invoice.plist\n```\n\n2. 启动服务：\n\n```bash\nlaunchctl start com.user.mcp-invoice\n```\n\n3. 停止服务：\n\n```bash\nlaunchctl stop com.user.mcp-invoice\n```\n\n## AI 编辑器集成\n\n### 在 Cursor 中配置 MCP\n\n在 Cursor 编辑器中，可以通过以下配置添加 MCP Invoice 服务：\n\n1. 打开 Cursor 的 MCP 配置文件：\n   - macOS: `$HOME/Library/Application Support/Cursor/tools/tools.json`\n   - Linux: `$HOME/.config/Cursor/tools/tools.json`\n   - Windows: `%APPDATA%\\Cursor\\tools\\tools.json`\n\n2. 在 `tools.json` 文件中添加 MCP Invoice 服务配置：\n\n```json\n{\n  \"tools\": {\n    \"invoice\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/path/to/mcp-invoice\",\n        \"run\",\n        \"invoice_server.py\"\n      ],\n      \"env\": {\n        \"MCP_INVOICE_DEBUG\": \"false\"\n      },\n      \"alwaysAllow\": [\n        \"process_file\",\n        \"process_directory\",\n        \"merge_pdfs\"\n      ]\n    }\n  }\n}\n```\n\n3. 重启 Cursor 后，你可以在 AI 助手中直接请求使用功能，例如：\n   \"请使用 OCR 工具读取文件：/path/to/document.pdf\"\n   \"请合并这些 PDF 文件：/path/to/file1.pdf, /path/to/file2.pdf\"\n\n### 在 Cline 中配置 MCP\n\nCline 与 MCP 集成方法类似于 Cursor：\n\n1. 更新 Cline 配置文件来添加此 MCP 工具\n2. 重启 Cline 客户端\n3. 使用与 Cursor 相同的方式来请求处理发票文件\n\n### 在 Roocode 中配置 MCP\n\n在 Roocode 中集成 MCP Invoice 服务：\n\n1. 按照 Roocode 文档配置外部工具\n2. 指向已部署的 MCP Invoice 服务\n3. 在 Roocode 中使用自然语言请求处理发票文件\n\n## MCP 服务调试\n\n1. 启用详细日志：\n\n```bash\nMCP_INVOICE_DEBUG=true mcp-invoice\n```\n\n2. 检查服务是否正常运行：\n\n```bash\nps aux | grep mcp-invoice\n```\n\n3. 查看日志：\n\n```bash\ntail -f logs/mcp-invoice.log\n```\n\n## 使用方法\n\nMCP 服务器提供以下主要工具：\n\n1. `process_file`: 处理单个文件并提取文本\n   - 参数：`file_path` - 文件的绝对路径\n   - 返回：包含文件路径和提取文本的字典\n\n2. `process_directory`: 处理一个目录中的所有 PDF 和图片文件\n   - 参数：`directory_path` - 目录的绝对路径\n   - 返回：包含每个文件路径和提取文本的字典列表\n\n3. `merge_pdfs`: 合并多个PDF和/或图片文件为一个PDF\n   - 参数：`file_paths` - 要合并的文件路径列表\n   - 参数：`output_path` - 输出PDF的路径\n   - 返回：合并后PDF的路径\n\n## 开发和扩展\n\n本项目使用 uv 进行依赖管理，使用 hatch 进行构建。\n\n### 开发环境设置\n\n1. 创建虚拟环境：\n\n```bash\nuv venv\nsource .venv/bin/activate\n```\n\n2. 安装开发依赖：\n\n```bash\nuv pip install -e \".[dev]\"\n```\n\n## 故障排除\n\n1. **Vision framework 错误**\n   - 确保使用 macOS 系统\n   - 确保已安装 pyobjc-framework-vision 11.0 或更高版本\n\n2. **UTF-8 编码问题**\n   - 所有 OCR 结果均使用 UTF-8 编码处理，确保多语言文本正确显示\n\n3. **PDF 转换错误**\n   - 确保已安装 poppler\n   - 检查 PDF 文件是否有权限访问和可读\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ocr",
        "invoice",
        "nfshanq",
        "mcp invoice",
        "ocr capabilities",
        "document processing"
      ],
      "category": "document-processing"
    },
    "nloui--paperless-mcp": {
      "owner": "nloui",
      "name": "paperless-mcp",
      "url": "https://github.com/nloui/paperless-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/nloui.webp",
      "description": "Manage documents, tags, correspondents, and document types through the Paperless-NGX API. Enables efficient organization and retrieval of document-related information.",
      "stars": 88,
      "forks": 24,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T12:04:51Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/nloui-paperless-mcp-badge.png)](https://mseep.ai/app/nloui-paperless-mcp)\n\n# Paperless-NGX MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@nloui/paperless-mcp)](https://smithery.ai/server/@nloui/paperless-mcp)\n\nAn MCP (Model Context Protocol) server for interacting with a Paperless-NGX API server. This server provides tools for managing documents, tags, correspondents, and document types in your Paperless-NGX instance.\n\n## Quick Start\n\n### Installing via Smithery\n\nTo install Paperless NGX MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@nloui/paperless-mcp):\n\n```bash\nnpx -y @smithery/cli install @nloui/paperless-mcp --client claude\n```\n\n### Manual Installation\n1. Install the MCP server:\n```bash\nnpm install -g paperless-mcp\n```\n\n2. Add it to your Claude's MCP configuration:\n\nFor VSCode extension, edit `~/Library/Application Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json`:\n```json\n{\n  \"mcpServers\": {\n    \"paperless\": {\n      \"command\": \"npx\",\n      \"args\": [\"paperless-mcp\", \"http://your-paperless-instance:8000\", \"your-api-token\"]\n    }\n  }\n}\n```\n\nFor Claude desktop app, edit `~/Library/Application Support/Claude/claude_desktop_config.json`:\n```json\n{\n  \"mcpServers\": {\n    \"paperless\": {\n      \"command\": \"npx\",\n      \"args\": [\"paperless-mcp\", \"http://your-paperless-instance:8000\", \"your-api-token\"]\n    }\n  }\n}\n```\n\n3. Get your API token:\n   1. Log into your Paperless-NGX instance\n   2. Click your username in the top right\n   3. Select \"My Profile\"\n   4. Click the circular arrow button to generate a new token\n\n4. Replace the placeholders in your MCP config:\n   - `http://your-paperless-instance:8000` with your Paperless-NGX URL\n   - `your-api-token` with the token you just generated\n\nThat's it! Now you can ask Claude to help you manage your Paperless-NGX documents.\n\n## Example Usage\n\nHere are some things you can ask Claude to do:\n\n- \"Show me all documents tagged as 'Invoice'\"\n- \"Search for documents containing 'tax return'\"\n- \"Create a new tag called 'Receipts' with color #FF0000\"\n- \"Download document #123\"\n- \"List all correspondents\"\n- \"Create a new document type called 'Bank Statement'\"\n\n## Available Tools\n\n### Document Operations\n\n#### list_documents\nGet a paginated list of all documents.\n\nParameters:\n- page (optional): Page number\n- page_size (optional): Number of documents per page\n\n```typescript\nlist_documents({\n  page: 1,\n  page_size: 25\n})\n```\n\n#### get_document\nGet a specific document by ID.\n\nParameters:\n- id: Document ID\n\n```typescript\nget_document({\n  id: 123\n})\n```\n\n#### search_documents\nFull-text search across documents.\n\nParameters:\n- query: Search query string\n\n```typescript\nsearch_documents({\n  query: \"invoice 2024\"\n})\n```\n\n#### download_document\nDownload a document file by ID.\n\nParameters:\n- id: Document ID\n- original (optional): If true, downloads original file instead of archived version\n\n```typescript\ndownload_document({\n  id: 123,\n  original: false\n})\n```\n\n#### bulk_edit_documents\nPerform bulk operations on multiple documents.\n\nParameters:\n- documents: Array of document IDs\n- method: One of:\n  - set_correspondent: Set correspondent for documents\n  - set_document_type: Set document type for documents\n  - set_storage_path: Set storage path for documents\n  - add_tag: Add a tag to documents\n  - remove_tag: Remove a tag from documents\n  - modify_tags: Add and/or remove multiple tags\n  - delete: Delete documents\n  - reprocess: Reprocess documents\n  - set_permissions: Set document permissions\n  - merge: Merge multiple documents\n  - split: Split a document into multiple documents\n  - rotate: Rotate document pages\n  - delete_pages: Delete specific pages from a document\n- Additional parameters based on method:\n  - correspondent: ID for set_correspondent\n  - document_type: ID for set_document_type\n  - storage_path: ID for set_storage_path\n  - tag: ID for add_tag/remove_tag\n  - add_tags: Array of tag IDs for modify_tags\n  - remove_tags: Array of tag IDs for modify_tags\n  - permissions: Object for set_permissions with owner, permissions, merge flag\n  - metadata_document_id: ID for merge to specify metadata source\n  - delete_originals: Boolean for merge/split\n  - pages: String for split \"[1,2-3,4,5-7]\" or delete_pages \"[2,3,4]\"\n  - degrees: Number for rotate (90, 180, or 270)\n\nExamples:\n```typescript\n// Add a tag to multiple documents\nbulk_edit_documents({\n  documents: [1, 2, 3],\n  method: \"add_tag\",\n  tag: 5\n})\n\n// Set correspondent and document type\nbulk_edit_documents({\n  documents: [4, 5],\n  method: \"set_correspondent\",\n  correspondent: 2\n})\n\n// Merge documents\nbulk_edit_documents({\n  documents: [6, 7, 8],\n  method: \"merge\",\n  metadata_document_id: 6,\n  delete_originals: true\n})\n\n// Split document into parts\nbulk_edit_documents({\n  documents: [9],\n  method: \"split\",\n  pages: \"[1-2,3-4,5]\"\n})\n\n// Modify multiple tags at once\nbulk_edit_documents({\n  documents: [10, 11],\n  method: \"modify_tags\",\n  add_tags: [1, 2],\n  remove_tags: [3, 4]\n})\n```\n\n#### post_document\nUpload a new document to Paperless-NGX.\n\nParameters:\n- file: Base64 encoded file content\n- filename: Name of the file\n- title (optional): Title for the document\n- created (optional): DateTime when the document was created (e.g. \"2024-01-19\" or \"2024-01-19 06:15:00+02:00\")\n- correspondent (optional): ID of a correspondent\n- document_type (optional): ID of a document type\n- storage_path (optional): ID of a storage path\n- tags (optional): Array of tag IDs\n- archive_serial_number (optional): Archive serial number\n- custom_fields (optional): Array of custom field IDs\n\n```typescript\npost_document({\n  file: \"base64_encoded_content\",\n  filename: \"invoice.pdf\",\n  title: \"January Invoice\",\n  created: \"2024-01-19\",\n  correspondent: 1,\n  document_type: 2,\n  tags: [1, 3],\n  archive_serial_number: \"2024-001\"\n})\n```\n\n### Tag Operations\n\n#### list_tags\nGet all tags.\n\n```typescript\nlist_tags()\n```\n\n#### create_tag\nCreate a new tag.\n\nParameters:\n- name: Tag name\n- color (optional): Hex color code (e.g. \"#ff0000\")\n- match (optional): Text pattern to match\n- matching_algorithm (optional): One of \"any\", \"all\", \"exact\", \"regular expression\", \"fuzzy\"\n\n```typescript\ncreate_tag({\n  name: \"Invoice\",\n  color: \"#ff0000\",\n  match: \"invoice\",\n  matching_algorithm: \"fuzzy\"\n})\n```\n\n### Correspondent Operations\n\n#### list_correspondents\nGet all correspondents.\n\n```typescript\nlist_correspondents()\n```\n\n#### create_correspondent\nCreate a new correspondent.\n\nParameters:\n- name: Correspondent name\n- match (optional): Text pattern to match\n- matching_algorithm (optional): One of \"any\", \"all\", \"exact\", \"regular expression\", \"fuzzy\"\n\n```typescript\ncreate_correspondent({\n  name: \"ACME Corp\",\n  match: \"ACME\",\n  matching_algorithm: \"fuzzy\"\n})\n```\n\n### Document Type Operations\n\n#### list_document_types\nGet all document types.\n\n```typescript\nlist_document_types()\n```\n\n#### create_document_type\nCreate a new document type.\n\nParameters:\n- name: Document type name\n- match (optional): Text pattern to match\n- matching_algorithm (optional): One of \"any\", \"all\", \"exact\", \"regular expression\", \"fuzzy\"\n\n```typescript\ncreate_document_type({\n  name: \"Invoice\",\n  match: \"invoice total amount due\",\n  matching_algorithm: \"any\"\n})\n```\n\n## Error Handling\n\nThe server will show clear error messages if:\n- The Paperless-NGX URL or API token is incorrect\n- The Paperless-NGX server is unreachable\n- The requested operation fails\n- The provided parameters are invalid\n\n## Development\n\nWant to contribute or modify the server? Here's what you need to know:\n\n1. Clone the repository\n2. Install dependencies:\n```bash\nnpm install\n```\n\n3. Make your changes to server.js\n4. Test locally:\n```bash\nnode server.js http://localhost:8000 your-test-token\n```\n\nThe server is built with:\n- [litemcp](https://github.com/wong2/litemcp): A TypeScript framework for building MCP servers\n- [zod](https://github.com/colinhacks/zod): TypeScript-first schema validation\n\n## API Documentation\n\nThis MCP server implements endpoints from the Paperless-NGX REST API. For more details about the underlying API, see the [official documentation](https://docs.paperless-ngx.com/api/).\n\n## Running the MCP Server\n\nThe MCP server can be run in two modes:\n\n### 1. stdio (default)\n\nThis is the default mode. The server communicates over stdio, suitable for CLI and direct integrations.\n\n```\nnpm run start -- <baseUrl> <token>\n```\n\n### 2. HTTP (Streamable HTTP Transport)\n\nTo run the server as an HTTP service, use the `--http` flag. You can also specify the port with `--port` (default: 3000). This mode requires [Express](https://expressjs.com/) to be installed (it is included as a dependency).\n\n```\nnpm run start -- <baseUrl> <token> --http --port 3000\n```\n\n- The MCP API will be available at `POST /mcp` on the specified port.\n- Each request is handled statelessly, following the [StreamableHTTPServerTransport](https://github.com/modelcontextprotocol/typescript-sdk) pattern.\n- GET and DELETE requests to `/mcp` will return 405 Method Not Allowed.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "paperless",
        "document",
        "documents",
        "paperless ngx",
        "nloui paperless",
        "document processing"
      ],
      "category": "document-processing"
    },
    "oakenai--mcp-edit-file-lines": {
      "owner": "oakenai",
      "name": "mcp-edit-file-lines",
      "url": "https://github.com/oakenai/mcp-edit-file-lines",
      "imageUrl": "/freedevtools/mcp/pfp/oakenai.webp",
      "description": "Make precise line-based edits to text files using string or regex pattern matching, including the ability to replace entire lines, specific text matches, and handle multiple edits with a preview function for safety.",
      "stars": 29,
      "forks": 5,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-02T05:55:40Z",
      "readme_content": "# Edit File Lines MCP Server\n\nA TypeScript-based MCP server that provides tools for making precise line-based edits to text files within allowed directories.\n\n## Features\n\n### Main Editing Tool\n\n#### `edit_file_lines`\nMake line-based edits to a file using string or regex pattern matching. Each edit can:\n- Replace entire lines\n- Replace specific text matches while preserving line formatting\n- Use regex patterns for complex matches\n- Handle multiple lines and multiple edits\n- Preview changes with dry run mode\n\nExample file (`src/components/App.tsx`):\n```typescript\n// Basic component with props\nconst Button = ({ color = \"blue\", size = \"md\" }) => {\n  return <button className={`btn-${color} size-${size}`}>Click me</button>;\n};\n\n// Component with multiple props and nested structure\nexport const Card = ({\n  title,\n  subtitle = \"Default subtitle\",\n  theme = \"light\",\n  size = \"lg\",\n}) => {\n  const cardClass = `card-${theme} size-${size}`;\n  \n  return (\n    <div className={cardClass}>\n      <h2>{title}</h2>\n      <p>{subtitle}</p>\n    </div>\n  );\n};\n\n// Constants and configurations\nconst THEME = {\n  light: { bg: \"#ffffff\", text: \"#000000\" },\n  dark: { bg: \"#000000\", text: \"#ffffff\" },\n};\n\nconst CONFIG = {\n  apiUrl: \"https://api.example.com\",\n  timeout: 5000,\n  retries: 3,\n};\n```\n\n### Example Use Cases\n\n1. Simple String Replacement\n```json\n{\n  \"p\": \"src/components/App.tsx\",\n  \"e\": [{\n    \"startLine\": 2,\n    \"endLine\": 2,\n    \"content\": \"primary\",\n    \"strMatch\": \"blue\"\n  }],\n  \"dryRun\": true\n}\n```\n\nOutput:\n```diff\nIndex: src/components/App.tsx\n===================================================================\n--- src/components/App.tsx        original\n+++ src/components/App.tsx        modified\n@@ -1,6 +1,6 @@\n // Basic component with props\n-const Button = ({ color = \"blue\", size = \"md\" }) => {\n+const Button = ({ color = \"primary\", size = \"md\" }) => {\n   return Click me;\n };\n \n // Component with multiple props and nested structure\n ```\n\nState ID: fcbf740a\nUse this ID with approve_edit to apply the changes.\n\n\n2. Multi-line Content with Preserved Structure  \n```json\n{\n  \"p\": \"src/components/App.tsx\",\n  \"e\": [{\n    \"startLine\": 16,\n    \"endLine\": 19,\n    \"content\": \"    <div className={cardClass}>\\n      <h2 className=\\\"title\\\">{title}</h2>\\n      <p className=\\\"subtitle\\\">{subtitle}</p>\\n    </div>\",\n    \"regexMatch\": \"<div[^>]*>[\\\\s\\\\S]*?</div>\"\n  }],\n  \"dryRun\": true\n}\n```\n\nOutput:\n```diff\nIndex: src/components/App.tsx\n===================================================================\n--- src/components/App.tsx        original\n+++ src/components/App.tsx        modified\n@@ -13,10 +13,10 @@\n   const cardClass = `card-${theme} size-${size}`;\n   \n   return (\n     <div className={cardClass}>\n-      <h2>{title}</h2>\n-      <p>{subtitle}</p>\n+      <h2 className=\"title\">{title}</h2>\n+      <p className=\"subtitle\">{subtitle}</p>\n     </div>\n   );\n };\n```\nState ID: f2ce973f\nUse this ID with approve_edit to apply the changes.\n\n\n3. Complex JSX Structure Modification\n```json\n{\n  \"p\": \"src/components/App.tsx\",\n  \"e\": [{\n    \"startLine\": 7,\n    \"endLine\": 12,\n    \"content\": \"export const Card = ({\\n  title,\\n  subtitle = \\\"New default\\\",\\n  theme = \\\"modern\\\",\\n  size = \\\"responsive\\\"\\n}) => {\",\n    \"regexMatch\": \"export const Card[\\\\s\\\\S]*?\\\\) => \\\\{\"\n  }],\n  \"dryRun\": true\n}\n```\n\nOutput:\n```diff\nIndex: src/components/App.tsx\n===================================================================\n--- src/components/App.tsx        original\n+++ src/components/App.tsx        modified\n@@ -5,11 +5,11 @@\n // Component with multiple props and nested structure\n export const Card = ({\n   title,\n-  subtitle = \"Default subtitle\",\n-  theme = \"light\",\n-  size = \"lg\",\n+  subtitle = \"New default\",\n+  theme = \"modern\",\n+  size = \"responsive\"\n }) => {\n   const cardClass = `card-${theme} size-${size}`;\n   \n   return (\n```   \nState ID: f1f1d27b\nUse this ID with approve_edit to apply the changes.\n\n\n4. Configuration Update with Whitespace Preservation\n```json\n{\n  \"p\": \"src/components/App.tsx\",\n  \"e\": [{\n    \"startLine\": 29,\n    \"endLine\": 32,\n    \"content\": \"const CONFIG = {\\n  baseUrl: \\\"https://api.newexample.com\\\",\\n  timeout: 10000,\\n  maxRetries: 5\",\n    \"regexMatch\": \"const CONFIG[\\\\s\\\\S]*?retries: \\\\d+\"\n  }],\n  \"dryRun\": true\n}\n```\n\nOutput:\n```diff\nIndex: src/components/App.tsx\n===================================================================\n--- src/components/App.tsx        original\n+++ src/components/App.tsx        modified\n@@ -26,8 +26,8 @@\n   dark: { bg: \"#000000\", text: \"#ffffff\" },\n };\n \n const CONFIG = {\n-  apiUrl: \"https://api.example.com\",\n-  timeout: 5000,\n-  retries: 3,\n+  baseUrl: \"https://api.newexample.com\",\n+  timeout: 10000,\n+  maxRetries: 5\n };\n```\nState ID: 20e93c34\nUse this ID with approve_edit to apply the changes.\n\n5. Flexible Whitespace Matching\n```json\n{\n  \"p\": \"src/components/App.tsx\",\n  \"e\": [{\n    \"startLine\": 9,\n    \"endLine\": 9,\n    \"content\": \"description\",\n    \"strMatch\": \"subtitle   =   \\\"Default subtitle\\\"\"  // Extra spaces are handled\n  }],\n  \"dryRun\": true\n}\n```\n\nOutput:\n```diff\nIndex: src/components/App.tsx\n===================================================================\n--- src/components/App.tsx        original\n+++ src/components/App.tsx        modified\n@@ -5,9 +5,9 @@\n // Component with multiple props and nested structure\n export const Card = ({\n   title,\n-  subtitle = \"Default subtitle\",\n+  description\n   theme = \"light\",\n   size = \"lg\",\n }) => {\n   const cardClass = `card-${theme} size-${size}`;\n```\n\n### Additional Tools\n\n#### `approve_edit`\nApply changes from a previous dry run of `edit_file_lines`. This tool provides a two-step editing process for safety. Here is an example workflow:\n\n1. First, make a dry run edit:\n```json \n{\n  \"p\": \"src/components/App.tsx\",\n  \"e\": [{\n    \"startLine\": 2,\n    \"endLine\": 2,\n    \"content\": \"primary\",\n    \"strMatch\": \"blue\"\n  }],\n  \"dryRun\": true\n}\n```\n\nOutput:\n```diff\nIndex: src/components/App.tsx\n===================================================================\n--- src/components/App.tsx        original\n+++ src/components/App.tsx        modified\n@@ -1,6 +1,6 @@\n // Basic component with props\n-const Button = ({ color = \"blue\", size = \"md\" }) => {\n+const Button = ({ color = \"primary\", size = \"md\" }) => {\n   return <button className={`btn-${color} size-${size}`}>Click me</button>;\n };\n ```\n\nState ID: fcbf740a\nUse this ID with approve_edit to apply the changes.\n\n\n2. Then, approve the changes using the state ID:\n```json\n{\n  \"stateId\": \"fcbf740a\"\n}\n```\n\nOutput:\n```diff\nIndex: src/components/App.tsx\n===================================================================\n--- src/components/App.tsx        original\n+++ src/components/App.tsx        modified\n@@ -1,6 +1,6 @@\n // Basic component with props\n-const Button = ({ color = \"blue\", size = \"md\" }) => {\n+const Button = ({ color = \"primary\", size = \"md\" }) => {\n   return <button className={`btn-${color} size-${size}`}>Click me</button>;\n };\n```\n\n3. Verify the changes:\n```json\n{\n  \"path\": \"src/components/App.tsx\",\n  \"lineNumbers\": [2],\n  \"context\": 1\n}\n```\n\nOutput:\n```\nLine 2:\n  1: // Basic component with props\n> 2: const Button = ({ color = \"primary\", size = \"md\" }) => {\n  3:   return <button className={`btn-${color} size-${size}`}>Click me</button>;\n```\n\nNote that state IDs expire after a short time for security. Attempting to use an expired or invalid state ID will result in an error:\n```json\n{\n  \"stateId\": \"invalid123\"\n}\n```\n\nOutput:\n```\nError: Invalid or expired state ID\n```\n\n#### `get_file_lines`\nInspect specific lines in a file with optional context lines. This tool is useful for verifying line content before making edits.\n\n```json\n{\n  \"path\": \"src/components/App.tsx\",\n  \"lineNumbers\": [1, 2, 3],\n  \"context\": 1\n}\n```\n\nOutput:\n```\nLine 1:\n> 1: // Basic component with props\n  2: const Button = ({ color = \"blue\", size = \"md\" }) => {\n\nLine 2:\n  1: // Basic component with props\n> 2: const Button = ({ color = \"blue\", size = \"md\" }) => {\n  3:   return Click me;\n\nLine 3:\n  2: const Button = ({ color = \"blue\", size = \"md\" }) => {\n> 3:   return Click me;\n  4: };\n```\n\n#### `search_file`\nSearch a file for text patterns or regular expressions to find specific line numbers and their surrounding context. This tool is particularly useful for locating the exact lines you want to edit with `edit_file_lines`.\n\nFeatures:\n- Simple text search with optional case sensitivity\n- Regular expression support\n- Whole word matching\n- Configurable context lines\n- Returns line numbers, content, and surrounding context with line numbers\n\nArguments:\n```typescript\n{\n  path: string;          // Path to the file to search\n  pattern: string;       // Search pattern (text or regex)\n  type?: \"text\" | \"regex\"; // Type of search (default: \"text\")\n  caseSensitive?: boolean; // Case-sensitive search (default: false)\n  contextLines?: number;   // Number of context lines (default: 2, max: 10)\n  maxMatches?: number;     // Maximum matches to return (default: 100)\n  wholeWord?: boolean;     // Match whole words only (default: false)\n  multiline?: boolean;     // Enable multiline regex mode (default: false)\n}\n```\n\nExample use cases:\n\n1. Simple text search:\n```json\n{\n  \"path\": \"src/components/App.tsx\",\n  \"pattern\": \"const\",\n  \"contextLines\": 2\n}\n```\n\nOutput:\n```\nFound 6 matches in 0.9ms:\nFile size: 0.7KB\n\nMatch 1: Line 2, Column 1\n----------------------------------------\n     1 | // Basic component with props\n>    2 | const Button = ({ color = \"blue\", size = \"md\" }) => {\n     3 |   return <button className={`btn-${color} size-${size}`}>Click me</button>;\n     4 | };\n\nMatch 2: Line 7, Column 8\n----------------------------------------\n     5 | \n     6 | // Component with multiple props and nested structure\n>    7 | export const Card = ({\n     8 |   title,\n     9 |   subtitle = \"Default subtitle\",\n\nMatch 3: Line 13, Column 3\n----------------------------------------\n    11 |   size = \"lg\",\n    12 | }) => {\n>   13 |   const cardClass = `card-${theme} size-${size}`;\n    14 |   \n    15 |   return (\n\nMatch 4: Line 23, Column 4\n----------------------------------------\n    21 | };\n    22 | \n>   23 | // Constants and configurations\n    24 | const THEME = {\n    25 |   light: { bg: \"#ffffff\", text: \"#000000\" },\n\nMatch 5: Line 24, Column 1\n----------------------------------------\n    22 | \n    23 | // Constants and configurations\n>   24 | const THEME = {\n    25 |   light: { bg: \"#ffffff\", text: \"#000000\" },\n    26 |   dark: { bg: \"#000000\", text: \"#ffffff\" },\n\nMatch 6: Line 29, Column 1\n----------------------------------------\n    27 | };\n    28 | \n>   29 | const CONFIG = {\n    30 |   apiUrl: \"https://api.example.com\",\n    31 |   timeout: 5000,\n```\n\n2. Case-sensitive whole word search:\n```json\n{\n  \"path\": \"src/components/App.tsx\",\n  \"pattern\": \"props\",\n  \"caseSensitive\": true,\n  \"wholeWord\": true,\n  \"contextLines\": 1\n}\n```\n\nOutput:\n```\nFound 2 matches in 0.7ms:\nFile size: 0.7KB\n\nMatch 1: Line 1, Column 25\n----------------------------------------\n>    1 | // Basic component with props\n     2 | const Button = ({ color = \"blue\", size = \"md\" }) => {\n\nMatch 2: Line 6, Column 28\n----------------------------------------\n     5 | \n>    6 | // Component with multiple props and nested structure\n     7 | export const Card = ({\n```\n\n3. Finding JSX components:\n```json\n{\n  \"path\": \"src/components/App.tsx\",\n  \"pattern\": \"<[A-Z]\\\\w+\\\\s\",\n  \"type\": \"regex\",\n  \"contextLines\": 1\n}\n```\n\nOutput:\n```\nFound 2 matches in 0.6ms:\nFile size: 0.7KB\n\nMatch 1: Line 3, Column 10\n----------------------------------------\n     2 | const Button = ({ color = \"blue\", size = \"md\" }) => {\n>    3 |   return <button className={`btn-${color} size-${size}`}>Click me</button>;\n     4 | };\n\nMatch 2: Line 16, Column 5\n----------------------------------------\n    15 |   return (\n>   16 |     <div className={cardClass}>\n    17 |       <h2>{title}</h2>\n```\n\nCommon workflows:\n\n1. Find then edit:\n```typescript\n// First, search for the line\n{\n  \"path\": \"src/config.ts\",\n  \"pattern\": \"API_URL\",\n  \"wholeWord\": true\n}\n\n// Then use the returned line number in edit_file_lines\n{\n  \"p\": \"src/config.ts\",\n  \"e\": [{\n    \"startLine\": 23,  // Line number from search result\n    \"endLine\": 23,\n    \"content\": \"export const API_URL = 'https://new-api.example.com';\"\n  }]\n}\n```\n\n2. Find all usages:\n```typescript\n{\n  \"path\": \"src/components/App.tsx\",\n  \"pattern\": \"\\\\buseMemo\\\\b\",\n  \"type\": \"regex\",\n  \"contextLines\": 2,\n  \"maxMatches\": 50\n}\n```\n\n3. Find specific prop patterns:\n```typescript\n{\n  \"path\": \"src/components/App.tsx\",\n  \"pattern\": \"className=['\\\"]([^'\\\"]+)['\\\"]\",\n  \"type\": \"regex\",\n  \"contextLines\": 1\n}\n```\n\n### Important Notes\n\n1. Whitespace Handling\n   - The tool intelligently handles whitespace in both string and regex matches\n   - Original indentation is preserved in replacements\n   - Multiple spaces between tokens are normalized for matching\n\n2. Pattern Matching\n   - String matches (`strMatch`) are whitespace-normalized\n   - Regex patterns (`regexMatch`) support look-ahead and look-behind\n   - Cannot use both `strMatch` and `regexMatch` in the same edit\n   - Overlapping regex patterns are detected and prevented\n\n3. Best Practices\n   - Always use dry run first to verify changes\n   - Review the diff output before approving changes\n   - Keep edit operations focused and atomic\n   - Use appropriate pattern matching for your use case\n\n\n## Development\n\nInstall dependencies:\n```bash\nnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n```bash\nnpm run watch\n```\n\n### Testing\n\nRun the test suite:\n```bash\nnpm run test\n```\n\nAdditional testing utilities:\n\n#### Test Tools Script\nTest the MCP tools directly against sample files:\n```bash\nnpm run test:tools\n```\n\nThis script:\n- Resets test fixtures to a known state\n- Connects to the MCP server\n- Tests each tool in sequence:\n  - `get_file_lines`\n  - `edit_file_lines` (dry run)\n  - `approve_edit`\n- Shows the output of each operation\n- Verifies changes were applied correctly\n\n#### Reset Fixtures Script\nReset test fixtures to their original state:\n```bash\nnpm run reset:fixtures\n```\n\nUse this script to:\n- Reset test files to a known state before testing\n- Clean up after failed tests\n- Ensure consistent test environment\n- Create missing fixture directories\n\n## Usage\n\nThe server requires one or more allowed directories to be specified when starting:\n\n```bash\nnode build/index.js <allowed-directory> [additional-directories...]\n```\n\nAll file operations will be restricted to these directories for security.\n\n### Environment Variables\n\n- `MCP_EDIT_STATE_TTL`: Time-to-live in milliseconds for edit states (default: 60000). Edit states will expire after this duration and must be recreated.\n\n## Installation\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"edit-file-lines\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/path/to/edit-file-lines/build/index.js\",\n        \"<allowed-directory>\"\n      ],\n      \"env\": {\n        \"MCP_EDIT_STATE_TTL\": \"300000\"  // Optional: Set custom TTL (in milliseconds)\n      }\n    }\n  }\n}\n```\n\n### Error Handling\n\nThe tool provides clear error messages for common issues:\n\n1. Match Not Found\n```\nError: No string match found for \"oldValue\" on line 5\n```\n\n2. Invalid Regex\n```\nError: Invalid regex pattern \"([\": Unterminated group\n```\n\n3. Multiple Edits on Same Line\n```\nError: Line 5 is affected by multiple edits\n```\n\n### Security Considerations\n\n- All file operations are restricted to explicitly allowed directories\n- Symlinks are validated to prevent escaping allowed directories\n- Parent directory traversal is prevented\n- Path normalization is performed for consistent security checks\n- Invalid line numbers and character positions are rejected\n- Line ending normalization ensures consistent behavior across platforms\n- Edit states expire after 60 seconds for security\n- Edit approvals require exact match of file path and edits\n\n### Debugging\n\nUse the Test Tools script to test the MCP tools directly against sample files. The [MCP Inspector](https://github.com/modelcontextprotocol/inspector) might help, but it currently does not support handing input that are not string values.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "lines",
        "file",
        "regex",
        "edit file",
        "file lines",
        "edits text"
      ],
      "category": "document-processing"
    },
    "oborchers--mcp-server-docy": {
      "owner": "oborchers",
      "name": "mcp-server-docy",
      "url": "https://github.com/oborchers/mcp-server-docy",
      "imageUrl": "/freedevtools/mcp/pfp/oborchers.webp",
      "description": "Provides real-time access to technical documentation from various sources, enabling accurate coding assistance. Supports dynamic updates to documentation sources and employs caching to reduce latency while ensuring fresh content.",
      "stars": 12,
      "forks": 3,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-01T13:25:47Z",
      "readme_content": "# Docy: Documentation at Your AI's Fingertips\n\n**Supercharge your AI assistant with instant access to technical documentation.**\n\nDocy gives your AI direct access to the technical documentation it needs, right when it needs it. No more outdated information, broken links, or rate limits - just accurate, real-time documentation access for more precise coding assistance.\n\n## Why Choose Docy?\n\n- **Instant Documentation Access**: Direct access to docs from React, Python, crawl4ai, and any other tech stack you use\n- **Hot-Reload Support**: Add new documentation sources on-the-fly without restarting - just edit the .docy.urls file!\n- **Intelligent Caching**: Reduces latency and external requests while maintaining fresh content\n- **Self-Hosted Control**: Keep your documentation access within your security perimeter\n- **Seamless MCP Integration**: Works effortlessly with Claude, VS Code, and other MCP-enabled AI tools\n\n> **Note**: Claude may default to using its built-in WebFetchTool instead of Docy. To explicitly request Docy's functionality, use a callout like: \"Please use Docy to find...\"\n\n# Docy MCP Server\n\nA Model Context Protocol server that provides documentation access capabilities. This server enables LLMs to search and retrieve content from documentation websites by scraping them with crawl4ai. Built with FastMCP v2.\n\n## Using Docy\n\nHere are examples of how Docy can help with common documentation tasks:\n\n```\n# Verify implementation against documentation\nAre we implementing Crawl4Ai scrape results correctly? Let's check the documentation.\n\n# Explore API usage patterns\nWhat do the docs say about using mcp.tool? Show me examples from the documentation.\n\n# Compare implementation options\nHow should we structure our data according to the React documentation? What are the best practices?\n```\n\nWith Docy, Claude Code can directly access and analyze documentation from configured sources, making it more effective at providing accurate, documentation-based guidance.\n\nTo ensure Claude Code prioritizes Docy for documentation-related tasks, add the following guidelines to your project's `CLAUDE.md` file:\n\n```\n## Documentation Guidelines\n- When checking documentation, prefer using Docy over WebFetchTool\n- Use list_documentation_sources_tool to discover available documentation sources\n- Use fetch_documentation_page to retrieve full documentation pages\n- Use fetch_document_links to discover related documentation\n```\n\nAdding these instructions to your `CLAUDE.md` file helps Claude Code consistently use Docy instead of its built-in web fetch capabilities when working with documentation.\n\n\n### Available Tools\n\n- `list_documentation_sources_tool` - List all available documentation sources\n  - No parameters required\n\n- `fetch_documentation_page` - Fetch the content of a documentation page by URL as markdown\n  - `url` (string, required): The URL to fetch content from\n\n- `fetch_document_links` - Fetch all links from a documentation page\n  - `url` (string, required): The URL to fetch links from\n\n### Prompts\n\n- **documentation_sources**\n  - List all available documentation sources with their URLs and types\n  - No arguments required\n\n- **documentation_page**\n  - Fetch the full content of a documentation page at a specific URL as markdown\n  - Arguments:\n    - `url` (string, required): URL of the specific documentation page to get\n\n- **documentation_links**\n  - Fetch all links from a documentation page to discover related content\n  - Arguments:\n    - `url` (string, required): URL of the documentation page to get links from\n\n## Installation\n\n### Using uv (recommended)\n\nWhen using [`uv`](https://docs.astral.sh/uv/) no specific installation is needed. We will\nuse [`uvx`](https://docs.astral.sh/uv/guides/tools/) to directly run *mcp-server-docy*.\n\n### Using PIP\n\nAlternatively you can install `mcp-server-docy` via pip:\n\n```\npip install mcp-server-docy\n```\n\nAfter installation, you can run it as a script using:\n\n```\nDOCY_DOCUMENTATION_URLS=\"https://docs.crawl4ai.com/,https://react.dev/\" python -m mcp_server_docy\n```\n\n### Using Docker\n\nYou can also use the Docker image:\n\n```\ndocker pull oborchers/mcp-server-docy:latest\ndocker run -i --rm -e DOCY_DOCUMENTATION_URLS=\"https://docs.crawl4ai.com/,https://react.dev/\" oborchers/mcp-server-docy\n```\n\n### Global Server Setup\n\nFor teams or multi-project development, check out the `server/README.md` for instructions on running a persistent SSE server that can be shared across multiple projects. This setup allows you to maintain a single Docy instance with shared documentation URLs and cache.\n\n## Configuration\n\n### Configure for Claude.app\n\nAdd to your Claude settings:\n\n<details>\n<summary>Using uvx</summary>\n\n```json\n\"mcpServers\": {\n  \"docy\": {\n    \"command\": \"uvx\",\n    \"args\": [\"mcp-server-docy\"],\n    \"env\": {\n      \"DOCY_DOCUMENTATION_URLS\": \"https://docs.crawl4ai.com/,https://react.dev/\"\n    }\n  }\n}\n```\n</details>\n\n<details>\n<summary>Using docker</summary>\n\n```json\n\"mcpServers\": {\n  \"docy\": {\n    \"command\": \"docker\",\n    \"args\": [\"run\", \"-i\", \"--rm\", \"oborchers/mcp-server-docy:latest\"],\n    \"env\": {\n      \"DOCY_DOCUMENTATION_URLS\": \"https://docs.crawl4ai.com/,https://react.dev/\"\n    }\n  }\n}\n```\n</details>\n\n<details>\n<summary>Using pip installation</summary>\n\n```json\n\"mcpServers\": {\n  \"docy\": {\n    \"command\": \"python\",\n    \"args\": [\"-m\", \"mcp_server_docy\"],\n    \"env\": {\n      \"DOCY_DOCUMENTATION_URLS\": \"https://docs.crawl4ai.com/,https://react.dev/\"\n    }\n  }\n}\n```\n</details>\n\n### Configure for VS Code\n\nFor manual installation, add the following JSON block to your User Settings (JSON) file in VS Code. You can do this by pressing `Ctrl + Shift + P` and typing `Preferences: Open User Settings (JSON)`.\n\nOptionally, you can add it to a file called `.vscode/mcp.json` in your workspace. This will allow you to share the configuration with others.\n\n> Note that the `mcp` key is needed when using the `mcp.json` file.\n\n<details>\n<summary>Using uvx</summary>\n\n```json\n{\n  \"mcp\": {\n    \"servers\": {\n      \"docy\": {\n        \"command\": \"uvx\",\n        \"args\": [\"mcp-server-docy\"],\n        \"env\": {\n          \"DOCY_DOCUMENTATION_URLS\": \"https://docs.crawl4ai.com/,https://react.dev/\"\n        }\n      }\n    }\n  }\n}\n```\n</details>\n\n<details>\n<summary>Using Docker</summary>\n\n```json\n{\n  \"mcp\": {\n    \"servers\": {\n      \"docy\": {\n        \"command\": \"docker\",\n        \"args\": [\"run\", \"-i\", \"--rm\", \"oborchers/mcp-server-docy:latest\"],\n        \"env\": {\n          \"DOCY_DOCUMENTATION_URLS\": \"https://docs.crawl4ai.com/,https://react.dev/\"\n        }\n      }\n    }\n  }\n}\n```\n</details>\n\n### Configuration Options\n\nThe application can be configured using environment variables:\n\n- `DOCY_DOCUMENTATION_URLS` (string): Comma-separated list of URLs to documentation sites to include (e.g., \"https://docs.crawl4ai.com/,https://react.dev/\")\n- `DOCY_DOCUMENTATION_URLS_FILE` (string): Path to a file containing documentation URLs, one per line (default: \".docy.urls\")\n- `DOCY_CACHE_TTL` (integer): Cache time-to-live in seconds (default: 432000)\n- `DOCY_CACHE_DIRECTORY` (string): Path to the cache directory (default: \".docy.cache\")\n- `DOCY_USER_AGENT` (string): Custom User-Agent string for HTTP requests\n- `DOCY_DEBUG` (boolean): Enable debug logging (\"true\", \"1\", \"yes\", or \"y\")\n- `DOCY_SKIP_CRAWL4AI_SETUP` (boolean): Skip running the crawl4ai-setup command at startup (\"true\", \"1\", \"yes\", or \"y\")\n- `DOCY_TRANSPORT` (string): Transport protocol to use (options: \"sse\" or \"stdio\", default: \"stdio\")\n- `DOCY_HOST` (string): Host address to bind the server to (default: \"127.0.0.1\")\n- `DOCY_PORT` (integer): Port to run the server on (default: 8000)\n\nEnvironment variables can be set directly or via a `.env` file.\n\n### URL Configuration File\n\nAs an alternative to setting the `DOCY_DOCUMENTATION_URLS` environment variable, you can create a `.docy.urls` file in your project directory with one URL per line:\n\n```\nhttps://docs.crawl4ai.com/\nhttps://react.dev/\n# Lines starting with # are treated as comments\nhttps://docs.python.org/3/\n```\n\nThis approach is especially useful for:\n- Projects where you want to share documentation sources with your team\n- Repositories where storing URLs in version control is beneficial\n- Situations where you want to avoid long environment variable values\n\nThe server will first check for URLs in the `DOCY_DOCUMENTATION_URLS` environment variable, and if none are found, it will look for the `.docy.urls` file.\n\n#### Hot Reload for URL File\n\nWhen using the `.docy.urls` file for documentation sources, the server implements a hot-reload mechanism that reads the file on each request rather than caching the URLs. This means you can:\n\n1. Add, remove, or modify documentation URLs in the `.docy.urls` file while the server is running\n2. See those changes reflected immediately in subsequent calls to `list_documentation_sources_tool` or other documentation tools\n3. Avoid restarting the server when modifying your documentation sources\n\nThis is particularly useful during development or when you need to quickly add new documentation sources to a running server.\n\n### Documentation URL Best Practices\n\nThe URLs you configure should ideally point to documentation index or introduction pages that contain:\n\n- Tables of contents\n- Navigation structures\n- Collections of internal and external links\n\nThis allows the LLM to:\n1. Start at a high-level documentation page\n2. Discover relevant subpages via links\n3. Navigate to specific documentation as needed\n\nUsing documentation sites with well-structured subpages is highly recommended as it:\n- Minimizes context usage by allowing the LLM to focus on relevant sections\n- Improves navigation efficiency through documentation\n- Provides a natural way to explore and find information\n- Reduces the need to load entire documentation sets at once\n\nFor example, instead of loading an entire documentation site, the LLM can start at the index page, identify the relevant section, and then navigate to specific subpages as needed.\n\n### Caching Behavior\n\nThe MCP server automatically caches documentation content to improve performance:\n\n- At startup, the server pre-fetches and caches all configured documentation URLs from `DOCY_DOCUMENTATION_URLS`\n- The cache time-to-live (TTL) can be configured via the `DOCY_CACHE_TTL` environment variable\n- Each new site accessed is automatically loaded into cache to reduce traffic and improve response times\n- Cached content is stored in a persistent disk-based cache using the `diskcache` library\n- The cache location can be configured via the `DOCY_CACHE_DIRECTORY` environment variable (default: \".docy.cache\")\n- The cache persists between server restarts, providing better performance for frequently accessed documentation\n\n#### Exceptions to Caching\n\nWhile most content is cached for performance, there are specific exceptions:\n\n- **Documentation URL Lists**: When using the `.docy.urls` file, the list of documentation sources is never cached - instead, the file is re-read on each request to support hot-reloading of URLs\n- **Page Content**: The actual content of documentation pages is still cached according to the configured TTL\n\nThis hybrid approach offers both performance benefits for content access and flexibility for documentation source management.\n\n## Local Development\n- Run in development mode: `fastmcp dev src/mcp_server_docy/__main__.py --with-editable .`\n- Access API at: `http://127.0.0.1:6274`\n- Run with MCP inspector: `uv run --with fastmcp --with-editable /Users/oliverborchers/Desktop/Code.nosync/mcp-server-docy --with crawl4ai --with loguru --with diskcache --with pydantic-settings fastmcp run src/mcp_server_docy/__main__.py`\n\n## Debugging\n\nYou can use the MCP inspector to debug the server. For uvx installations:\n\n```\nDOCY_DOCUMENTATION_URLS=\"https://docs.crawl4ai.com/\" npx @modelcontextprotocol/inspector uvx mcp-server-docy\n```\n\nOr if you've installed the package in a specific directory or are developing on it:\n\n```\ncd path/to/docy\nDOCY_DOCUMENTATION_URLS=\"https://docs.crawl4ai.com/\" npx @modelcontextprotocol/inspector uv run mcp-server-docy\n```\n\n### Troubleshooting: \"Tool not found\" Error in Claude Code CLI\n\nIf you encounter errors like \"ERROR Tool not found for mcp__docy__fetch_documentation_page\" in Claude Code CLI, follow these steps:\n\n1. Create a `.docy.urls` file in your current directory with your documentation URLs:\n```\nhttps://docs.crawl4ai.com/\nhttps://react.dev/\n```\n\n2. Run the server using Docker with the SSE transport protocol and mount the URLs file:\n\n```bash\ndocker run -i --rm -p 8000:8000 \\\n  -e DOCY_TRANSPORT=sse \\\n  -e DOCY_HOST=0.0.0.0 \\\n  -e DOCY_PORT=8000 \\\n  -v \"$(pwd)/.docy.urls:/app/.docy.urls\" \\\n  oborchers/mcp-server-docy\n```\n\n3. Configure your Claude Code `.mcp.json` to use the SSE endpoint:\n\n```json\n{\n  \"mcp\": {\n    \"servers\": {\n      \"docy\": {\n        \"type\": \"sse\",\n        \"url\": \"http://localhost:8000/sse\"\n      }\n    }\n  }\n}\n```\n\nThis configuration:\n- Uses a mounted `.docy.urls` file instead of environment variables for documentation sources\n- Switches from the default stdio mode to SSE (Server-Sent Events) protocol\n- Makes the server accessible from outside the container\n- Exposes the server on port 8000 for HTTP access\n\nThe SSE transport is recommended when running the server as a standalone service that needs to be accessed over HTTP, which is particularly useful for Docker deployments.\n\n## Release Process\n\nThe project uses GitHub Actions for automated releases:\n\n1. Update the version in `pyproject.toml`\n2. Create a new tag with `git tag vX.Y.Z` (e.g., `git tag v0.1.0`)\n3. Push the tag with `git push --tags`\n\nThis will automatically:\n- Verify the version in `pyproject.toml` matches the tag\n- Run tests and lint checks\n- Build and publish to PyPI\n- Build and publish to Docker Hub as `oborchers/mcp-server-docy:latest` and `oborchers/mcp-server-docy:X.Y.Z`\n\n## Contributing\n\nWe encourage contributions to help expand and improve mcp-server-docy. Whether you want to add new features, enhance existing functionality, or improve documentation, your input is valuable.\n\nFor examples of other MCP servers and implementation patterns, see:\nhttps://github.com/modelcontextprotocol/servers\n\nPull requests are welcome! Feel free to contribute new ideas, bug fixes, or enhancements to make mcp-server-docy even more powerful and useful.\n\n## License\n\nmcp-server-docy is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "documentation",
        "document",
        "docy",
        "docy provides",
        "server docy",
        "document processing"
      ],
      "category": "document-processing"
    },
    "omer-ayhan--custom-context-mcp": {
      "owner": "omer-ayhan",
      "name": "custom-context-mcp",
      "url": "https://github.com/omer-ayhan/custom-context-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/omer-ayhan.webp",
      "description": "Transforms and structures text into JSON formats by extracting key information from AI-generated text. Facilitates seamless data integration into applications by converting unstructured text into structured JSON data.",
      "stars": 1,
      "forks": 0,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-04-07T20:42:45Z",
      "readme_content": "# Custom Context MCP Server\n\nThis Model Context Protocol (MCP) server provides tools for structuring and extracting data from text according to JSON templates.\n\n## Features\n\n### Text-to-JSON Transformation\n\n- Group and structure text based on JSON templates with placeholders\n- Extract information from AI-generated text into structured JSON formats\n- Support for any arbitrary JSON structure with nested placeholders\n- Intelligent extraction of key-value pairs from text\n- Process AI outputs into structured data for downstream applications\n\n## Getting Started\n\n### Installation\n\n```bash\nnpm install\n```\n\n### Running the server\n\n```bash\nnpm start\n```\n\nFor development with hot reloading:\n\n```bash\nnpm run dev:watch\n```\n\n## Usage\n\nThis MCP server provides two main tools:\n\n### 1. Group Text by JSON (`group-text-by-json`)\n\nThis tool takes a JSON template with placeholders and generates a prompt for an AI to group text according to the template's structure.\n\n```json\n{\n\t\"template\": \"{ \\\"type\\\": \\\"<type>\\\", \\\"text\\\": \\\"<text>\\\" }\"\n}\n```\n\nThe tool analyzes the template, extracts placeholder keys, and returns a prompt that guides the AI to extract information in a key-value format.\n\n### 2. Text to JSON (`text-to-json`)\n\nThis tool takes the grouped text output from the previous step and converts it into a structured JSON object based on the original template.\n\n```json\n{\n\t\"template\": \"{ \\\"type\\\": \\\"<type>\\\", \\\"text\\\": \\\"<text>\\\" }\",\n\t\"text\": \"type: pen\\ntext: This is a blue pen\"\n}\n```\n\nIt extracts key-value pairs from the text and structures them according to the template.\n\n## Example Workflow\n\n1. **Define a JSON template with placeholders:**\n\n   ```json\n   {\n   \t\"item\": {\n   \t\t\"name\": \"<name>\",\n   \t\t\"price\": \"<price>\",\n   \t\t\"description\": \"<description>\"\n   \t}\n   }\n   ```\n\n2. **Use `group-text-by-json` to create a prompt for AI:**\n\n   - The tool identifies placeholder keys: name, price, description\n   - Generates a prompt instructing the AI to group information by these keys\n\n3. **Send the prompt to an AI model and receive grouped text:**\n\n   ```\n   name: Blue Pen\n   price: $2.99\n   description: A smooth-writing ballpoint pen with blue ink\n   ```\n\n4. **Use `text-to-json` to convert the grouped text to JSON:**\n   - Result:\n   ```json\n   {\n   \t\"item\": {\n   \t\t\"name\": \"Blue Pen\",\n   \t\t\"price\": \"$2.99\",\n   \t\t\"description\": \"A smooth-writing ballpoint pen with blue ink\"\n   \t}\n   }\n   ```\n\n## Template Format\n\nTemplates can include placeholders anywhere within a valid JSON structure:\n\n- Use angle brackets to define placeholders: `<name>`, `<type>`, `<price>`, etc.\n- The template must be a valid JSON string\n- Placeholders can be at any level of nesting\n- Supports complex nested structures\n\nExample template with nested placeholders:\n\n```json\n{\n\t\"product\": {\n\t\t\"details\": {\n\t\t\t\"name\": \"<name>\",\n\t\t\t\"category\": \"<category>\"\n\t\t},\n\t\t\"pricing\": {\n\t\t\t\"amount\": \"<price>\",\n\t\t\t\"currency\": \"USD\"\n\t\t}\n\t},\n\t\"metadata\": {\n\t\t\"timestamp\": \"2023-09-01T12:00:00Z\"\n\t}\n}\n```\n\n## Implementation Details\n\nThe server works by:\n\n1. Analyzing JSON templates to extract placeholder keys\n2. Generating prompts that guide AI models to extract information by these keys\n3. Parsing AI-generated text to extract key-value pairs\n4. Reconstructing JSON objects based on the original template structure\n\n## Development\n\n### Prerequisites\n\n- Node.js v18 or higher\n- npm or yarn\n\n### Build and Run\n\n```bash\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n\n# Run the server\nnpm start\n\n# Development with hot reloading\nnpm run dev:watch\n```\n\n### Custom Hot Reloading\n\nThis project includes a custom hot reloading setup that combines:\n\n- **nodemon**: Watches for file changes in the src directory and rebuilds TypeScript files\n- **browser-sync**: Automatically refreshes the browser when build files change\n- **Concurrent execution**: Runs both services simultaneously with output synchronization\n\nThe setup is configured in:\n\n- `nodemon.json`: Controls TypeScript watching and rebuilding\n- `package.json`: Uses concurrently to run nodemon and browser-sync together\n\nTo use the custom hot reloading feature:\n\n```bash\nnpm run dev:watch\n```\n\nThis creates a development environment where:\n\n1. TypeScript files are automatically rebuilt when changed\n2. The MCP server restarts with the updated code\n3. Connected browsers refresh to show the latest changes\n\n### Using with MCP Inspector\n\nYou can use the MCP Inspector for debugging:\n\n```bash\nnpm run dev\n```\n\nThis runs the server with the MCP Inspector for visual debugging of requests and responses.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "json",
        "structured",
        "unstructured",
        "structured json",
        "text structured",
        "unstructured text"
      ],
      "category": "document-processing"
    },
    "onebirdrocks--ebook-mcp": {
      "owner": "onebirdrocks",
      "name": "ebook-mcp",
      "url": "https://github.com/onebirdrocks/ebook-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/onebirdrocks.webp",
      "description": "Transforms interactions with digital books by enabling natural language conversations and intuitive navigation. Supports library management and insights extraction from EPUB and PDF formats.",
      "stars": 111,
      "forks": 20,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-10-03T19:44:43Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/onebirdrocks-ebook-mcp-badge.png)](https://mseep.ai/app/onebirdrocks-ebook-mcp)\n\n# Ebook-MCP\n\n\n\n\n[English](https://github.com/onebirdrocks/ebook-mcp/blob/main/README.md) | [中文](https://github.com/onebirdrocks/ebook-mcp/blob/main/README-CN.md) | [日本語](https://github.com/onebirdrocks/ebook-mcp/blob/main/README-JP.md) | [한국어](https://github.com/onebirdrocks/ebook-mcp/blob/main/README-KR.md) | [Français](https://github.com/onebirdrocks/ebook-mcp/blob/main/README-FR.md) | [Deutsch](https://github.com/onebirdrocks/ebook-mcp/blob/main/README-DE.md) \n\nEbook-MCP is a powerful Model Context Protocol (MCP) server for processing electronic books. Built on the [Model Context Protocol](https://github.com/modelcontextprotocol), it provides a set of standardized APIs for seamless integration between LLM applications and e-book processing capabilities. Currently supports EPUB and PDF formats.\n\n\n## Use Cases & Value\n\nEbook-MCP transforms how you interact with your digital books by enabling natural language conversations with your reading materials. It seamlessly integrates with modern AI-powered IDEs like Cursor and Claude, allowing you to:\n\n- **Smart Library Management**: Simply ask \"Show me all EPUB files in my downloads folder\" or \"Find books about GenAI in my library\"\n- **Interactive Reading Experience**: Have natural conversations about your books:\n  - \"Give me a brief introduction to 'LLM Engineer Handbook'\"\n  - \"What's covered in Chapter 3?\"\n  - \"Summarize the key points about RAG from this book\"\n- **Active Learning Support**: Enhance your learning through AI-powered interactions:\n  - \"Create a quiz based on the RAG concepts from Chapter 5\"\n  - \"Explain the differences between the architectures discussed in this chapter\"\n  - \"Give me practical exercises based on the concepts in this section\"\n- **Content Navigation**: Easily navigate through your books with natural language queries:\n  - \"Find all sections discussing prompt engineering\"\n  - \"Show me the chapters about fine-tuning\"\n  - \"Take me to the part about vector databases\"\n\nBy bridging the gap between traditional e-books and AI capabilities, Ebook-MCP helps readers extract more value from their digital library through intuitive, conversation-based interactions.\n\nQuick demo - Run with DeepSeek (Please check all the examples with Claude/OpenAI under mcp-client-example folder) \n```\nQuery:Please check all the epub books in my download folder. user id is onebird.\n......\n\nQuery: Can you ask me a few questions to test my understanding of this book?\n\n\nAnswer: Sure! Here are 5 questions about Elon Musk by Walter Isaacson to test your understanding of the book. Please answer based on your knowledge — I’ll give feedback and add details after each response.\n\nQuestion 1:\nHow did Musk’s childhood and family background shape his personality and career later in life?\n(Hint: His relationship with his father, growing up in South Africa, etc.)\n\nQuestion 2:\nZip2 and X.com (later PayPal) were Musk’s early startups. What problems did they solve? How did Musk eventually exit from these companies?\n(Hint: Zip2’s business model, X.com’s merger with Confinity, etc.)\n\nQuestion 3:\nIn 2008, both SpaceX and Tesla were on the verge of bankruptcy. How did Musk save these two companies?\n(Hint: Falcon 1’s fourth launch, NASA contract, Tesla’s last-minute rescue, etc.)\n\nQuestion 4:\nWhat controversies surround Musk’s management style? What specific incidents in the book illustrate his “hardcore” or “extreme” work culture?\n(Hint: Fremont factory’s “production hell,” Twitter layoffs, etc.)\n\nQuestion 5:\nWhat is Musk’s attitude toward Artificial Intelligence (AI)? Why did he simultaneously support both OpenAI and Neuralink, which seem to have conflicting goals?\n(Hint: AI as an existential threat, brain-machine interface vision, etc.)\n\nPlease answer each question. I’ll provide feedback and additional details or correct any misunderstandings!\n(If a question isn’t clear, feel free to ask me.)\n\nQuery:\nQuestion 1: His father’s abusive attitude made him less empathetic towards others.\nQuestion 2: Zip2 solved the problem of electronic maps and online yellow pages. X.com solved online payments.\nQuestion 3: He secured a contract with NASA. Tesla solved its production problems by building a factory in China.\nQuestion 4: I don’t know. Please answer for me.\nQuestion 5: He believes open-source technology is necessary to ensure AI is safe and open.\n\nAnswer: Your answers have captured some key points from the book. Let me add details, correct some inaccuracies, and provide further background for Questions 4 and 5:\n\nQuestion 1 — Correction & Supplement\nInfluence of His Father:\nMusk's father, Errol, was indeed extremely harsh — for example, forcing young Elon to kneel and count grains of rice for hours. The book emphasizes that this emotional desensitization shaped Musk into an extremely goal-oriented person — indifferent to others’ suffering but obsessively committed to his goals.\n\nReverse Impact:\nIt’s not that Musk is incapable of empathy — it’s selective. For instance, he may treat employees coldly but personally study medical equipment for his son X’s health issues.\n\nQuestion 2 — Correction & Supplement\nZip2:\nEssentially an online Yellow Pages + map navigation service (helping newspapers go online). Musk wrote much of the early code himself and slept in the office. Eventually, Compaq acquired Zip2 for $307 million (Musk received $22 million).\n\nX.com:\nNot just online payments — it was Musk’s attempt to create a comprehensive financial platform (aiming to replace banks). Later merged with Confinity (the precursor of PayPal). Musk was ousted due to internal conflicts, but when eBay acquired PayPal, Musk earned $180 million.\n(Note: Musk later bought back the domain X.com — it’s now Twitter’s parent company name).\n\nQuestion 3 — Correction & Supplement\nSpaceX:\nIn 2008, Falcon 1 succeeded on its fourth launch (after three failures drained their funds). Right after that, SpaceX secured a $1.6 billion NASA contract for cargo resupply — a lifeline for the company.\n\nTesla:\nIn 2008, Tesla survived through a $50 million investment from Daimler and a loan from the U.S. Department of Energy.\nBuilding the Gigafactory in China (2019) came much later. In the early years, survival depended on the launch of Model S (2012) and Musk’s personal gamble — selling all his real estate to fund Tesla.\n\nQuestion 4 — Explanation: Controversy Around His Management Style\n“Hardcore” Culture:\n\nAt SpaceX/Tesla: Musk demanded employees work 80+ hours per week, even sleeping at the factory. (\"If you’re not here, your replacement is.\")\n\nAfter acquiring Twitter: He immediately laid off 75% of staff and asked the remaining employees to sign a \"hardcore commitment\" — agreeing to long hours and high-intensity output.\n\nExtreme Cases:\n\nAt the Fremont Factory: During the \"production hell\" of the Model 3, Musk slept on the production line and once yelled at employees calling them \"worse than dogs\" (he later apologized).\n\nFiring Executives: Musk once fired a senior Tesla executive on the spot because the font size in their PowerPoint presentation wasn’t big enough.\n\nQuestion 5 — Correction & Supplement\nAI Threat Theory:\nMusk believes that AI could destroy humanity (\"more dangerous than nuclear weapons\"). Therefore:\n\nOpenAI: He initially supported it to promote safe, open-source AI (but left later due to disputes over control).\n\nNeuralink: He aims to use brain-machine interfaces to merge humans with AI — to prevent humans from being left behind.\n\nContradictions:\nWhile warning about AI risks, Musk is simultaneously pushing for Full Self-Driving (FSD) technology at Tesla and has founded xAI to research Artificial General Intelligence (AGI).\n\nOverall Evaluation:\n✅ You have captured the key events accurately, but the details need to be strengthened (such as timelines and specific figures).\n🔍 Recommended areas for further study: Musk's multi-threaded management style (running five companies simultaneously) and his skill in media manipulation (governing through Twitter).\n```\n\n## Features\n\n### EPUB Support\n- Extract metadata (title, author, publication date, etc.)\n- Extract table of contents\n- Extract chapter content (with Markdown output)\n- Batch process EPUB files\n\n### PDF Support\n- Extract metadata (title, author, creation date, etc.)\n- Extract table of contents\n- Extract content by page number\n- Extract content by chapter title\n- Markdown output support\n- Batch process PDF files\n\n## Installation\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/yourusername/ebook-mcp.git\ncd ebook-mcp\n```\n\n2. Install dependencies using `uv`:\n```bash\nuv pip install -e .\n```\n\n## Usage\n\n### Starting the MCP Server in development mode\n\nRun the server in development mode:\n```bash\nuv run mcp dev src/ebook_mcp/main.py\n```\n\n\nYou can visit http://localhost:5173/ for testing & debugging purpose \nYou can also install the inspector for the test.\n```\nnpx @modelcontextprotocol/inspector uv --directory . run src/ebook_mcp/main.py\n```\n\n### Starting the MCP Server in Prod mode\n\nRun the server:\n```bash\nuv run src/ebook_mcp/main.py\n```\n\n\n#### Configure the MCP in Cursor\n\nAdd the following configuration in Cursor\n```bash\n\"ebook-mcp\":{\n            \"command\": \"uv\",\n            \"args\": [\n                \"--directory\",\n                \"/Users/onebird/github/ebook-mcp/src/ebook_mcp/\",\n                \"run\",\n                \"main.py\"\n            ]\n        }\n```\n\n\n\n\n### EPUB Processing Examples\n\n```python\n# Get all EPUB files in a directory\nepub_files = get_all_epub_files(\"/path/to/books\")\n\n# Get EPUB metadata\nmetadata = get_metadata(\"/path/to/book.epub\")\n\n# Get table of contents\ntoc = get_toc(\"/path/to/book.epub\")\n\n# Get specific chapter content (in Markdown format)\nchapter_content = get_chapter_markdown(\"/path/to/book.epub\", \"chapter_id\")\n```\n\n### PDF Processing Examples\n\n```python\n# Get all PDF files in a directory\npdf_files = get_all_pdf_files(\"/path/to/books\")\n\n# Get PDF metadata\nmetadata = get_pdf_metadata(\"/path/to/book.pdf\")\n\n# Get table of contents\ntoc = get_pdf_toc(\"/path/to/book.pdf\")\n\n# Get specific page content\npage_text = get_pdf_page_text(\"/path/to/book.pdf\", 1)\npage_markdown = get_pdf_page_markdown(\"/path/to/book.pdf\", 1)\n\n# Get specific chapter content\nchapter_content, page_numbers = get_pdf_chapter_content(\"/path/to/book.pdf\", \"Chapter 1\")\n```\n\n## API Reference\n\n### EPUB APIs\n\n#### `get_all_epub_files(path: str) -> List[str]`\nGet all EPUB files in the specified directory.\n\n#### `get_metadata(epub_path: str) -> Dict[str, Union[str, List[str]]]`\nGet metadata from an EPUB file.\n\n#### `get_toc(epub_path: str) -> List[Tuple[str, str]]`\nGet table of contents from an EPUB file.\n\n#### `get_chapter_markdown(epub_path: str, chapter_id: str) -> str`\nGet chapter content in Markdown format.\n\n### PDF APIs\n\n#### `get_all_pdf_files(path: str) -> List[str]`\nGet all PDF files in the specified directory.\n\n#### `get_pdf_metadata(pdf_path: str) -> Dict[str, Union[str, List[str]]]`\nGet metadata from a PDF file.\n\n#### `get_pdf_toc(pdf_path: str) -> List[Tuple[str, int]]`\nGet table of contents from a PDF file.\n\n#### `get_pdf_page_text(pdf_path: str, page_number: int) -> str`\nGet plain text content from a specific page.\n\n#### `get_pdf_page_markdown(pdf_path: str, page_number: int) -> str`\nGet Markdown formatted content from a specific page.\n\n#### `get_pdf_chapter_content(pdf_path: str, chapter_title: str) -> Tuple[str, List[int]]`\nGet chapter content and corresponding page numbers by chapter title.\n\n## Dependencies\n\nKey dependencies include:\n- ebooklib: EPUB file processing\n- PyPDF2: Basic PDF processing\n- PyMuPDF: Advanced PDF processing\n- beautifulsoup4: HTML parsing\n- html2text: HTML to Markdown conversion\n- pydantic: Data validation\n- fastmcp: MCP server framework\n\n## Important Notes\n\n1. PDF processing relies on the document's table of contents. Some features may not work if TOC is not available.\n2. For large PDF files, it's recommended to process by page ranges to avoid loading the entire file at once.\n3. EPUB chapter IDs must be obtained from the table of contents structure.\n\n## Architecture\n\n```\n           ┌────────────────────────────┐\n           │         Agent Layer        │\n           │  - Translation Strategy    │\n           │  - Style Consistency Check │\n           │  - LLM Call & Interaction │\n           └────────────▲─────────────┘\n                        │ Tool Calls\n           ┌────────────┴─────────────┐\n           │        MCP Tool Layer     │\n           │  - extract_chapter        │\n           │  - write_translated_chapter│\n           │  - generate_epub          │\n           └────────────▲─────────────┘\n                        │ System/IO Calls\n           ┌────────────┴─────────────┐\n           │     System Base Layer     │\n           │  - File Reading          │\n           │  - ebooklib Parsing      │\n           │  - File Path Storage/Check│\n           └────────────────────────────┘\n```\n\n\n\n## Contributing\n\nWe welcome Issues and Pull Requests!\n\nFor detailed information about recent changes, please see [CHANGELOG.md](CHANGELOG.md).",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ebook",
        "books",
        "library",
        "onebirdrocks ebook",
        "ebook mcp",
        "books enabling"
      ],
      "category": "document-processing"
    },
    "oneshot-engineering--mcp-webresearch": {
      "owner": "oneshot-engineering",
      "name": "mcp-webresearch",
      "url": "https://github.com/oneshot-engineering/mcp-webresearch",
      "imageUrl": "/freedevtools/mcp/pfp/oneshot-engineering.webp",
      "description": "Fetch real-time information from the web, extract content from webpages, and track research sessions with the ability to capture screenshots for better insights.",
      "stars": 1,
      "forks": 0,
      "license": "MIT License",
      "language": "",
      "updated_at": "2025-04-28T23:55:21Z",
      "readme_content": "# MCP Web Research Server\n\nA Model Context Protocol (MCP) server for web research. \n\nBring real-time info into Claude and easily research any topic.\n\n## Features\n\n- Google search integration\n- Webpage content extraction\n- Research session tracking (list of visited pages, search queries, etc.)\n- Screenshot capture\n\n## Prerequisites\n\n- [Node.js](https://nodejs.org/) >= 18 (includes `npm` and `npx`)\n- [Claude Desktop app](https://claude.ai/download)\n\n## Installation\n\nFirst, ensure you've downloaded and installed the [Claude Desktop app](https://claude.ai/download) and you have npm installed.\n\nNext, add this entry to your `claude_desktop_config.json` (on Mac, found at `~/Library/Application\\ Support/Claude/claude_desktop_config.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"webresearch\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@mzxrai/mcp-webresearch@latest\"]\n    }\n  }\n}\n```\n\nThis config allows Claude Desktop to automatically start the web research MCP server when needed.\n\n## Usage\n\nSimply start a chat with Claude and send a prompt that would benefit from web research. If you'd like a prebuilt prompt customized for deeper web research, you can use the `agentic-research` prompt that we provide through this package. Access that prompt in Claude Desktop by clicking the Paperclip icon in the chat input and then selecting `Choose an integration` → `webresearch` → `agentic-research`.\n\n<img src=\"https://i.ibb.co/N6Y3C0q/Screenshot-2024-12-05-at-11-01-27-PM.png\" alt=\"Example screenshot of web research\" width=\"400\"/>\n\n### Tools\n\n1. `search_google`\n   - Performs Google searches and extracts results\n   - Arguments: `{ query: string }`\n\n2. `visit_page`\n   - Visits a webpage and extracts its content\n   - Arguments: `{ url: string, takeScreenshot?: boolean }`\n\n3. `take_screenshot`\n   - Takes a screenshot of the current page\n   - No arguments required\n\n### Prompts\n\n#### `agentic-research`\nA guided research prompt that helps Claude conduct thorough web research. The prompt instructs Claude to:\n- Start with broad searches to understand the topic landscape\n- Prioritize high-quality, authoritative sources\n- Iteratively refine the research direction based on findings\n- Keep you informed and let you guide the research interactively\n- Always cite sources with URLs\n\n### Resources\n\nWe expose two things as MCP resources: (1) captured webpage screenshots, and (2) the research session.\n\n#### Screenshots\n\nWhen you take a screenshot, it's saved as an MCP resource. You can access captured screenshots in Claude Desktop via the Paperclip icon.\n\n#### Research Session\n\nThe server maintains a research session that includes:\n- Search queries\n- Visited pages\n- Extracted content\n- Screenshots\n- Timestamps\n\n### Suggestions\n\nFor the best results, if you choose not to use the `agentic-research` prompt when doing your research, it may be helpful to suggest high-quality sources for Claude to use when researching general topics. For example, you could prompt `news today from reuters or AP` instead of `news today`.\n\n## Problems\n\nThis is very much pre-alpha code. And it is also AIGC, so expect bugs.\n\nIf you run into issues, it may be helpful to check Claude Desktop's MCP logs:\n\n```bash\ntail -n 20 -f ~/Library/Logs/Claude/mcp*.log\n```\n\n## Development\n\n```bash\n# Install dependencies\npnpm install\n\n# Build the project\npnpm build\n\n# Watch for changes\npnpm watch\n\n# Run in development mode\npnpm dev\n```\n\n## Requirements\n\n- Node.js >= 18\n- Playwright (automatically installed as a dependency)\n\n## Verified Platforms\n\n- [x] macOS\n- [ ] Linux\n\n## License\n\nMIT\n\n## Author\n\n[mzxrai](https://github.com/mzxrai) ",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "webresearch",
        "screenshots",
        "webpages",
        "mcp webresearch",
        "capture screenshots",
        "oneshot engineering"
      ],
      "category": "document-processing"
    },
    "onigeya--siyuan-mcp-server": {
      "owner": "onigeya",
      "name": "siyuan-mcp-server",
      "url": "https://github.com/onigeya/siyuan-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/onigeya.webp",
      "description": "Integrate with the SiYuan Note system to access and manage notebooks, documents, and content blocks while supporting SQL queries and various file operations.",
      "stars": 42,
      "forks": 8,
      "license": "ISC License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T12:46:53Z",
      "readme_content": "# SiYuan Note MCP Server\n[![smithery badge](https://smithery.ai/badge/@onigeya/siyuan-mcp-server)](https://smithery.ai/server/@onigeya/siyuan-mcp-server)\n\n一个 MCP 服务器实现，提供与思源笔记系统的集成，使 AI 模型能够访问和操作笔记数据。\n\nAn MCP server implementation that provides integration with the SiYuan Note system, enabling AI models to access and manipulate note data.\n\n## 功能特性 | Features\n\n* 笔记本管理 | Notebook Management\n* 文档操作 | Document Operations\n* 内容块控制 | Block Control\n* 文件和资源管理 | File and Asset Management\n* SQL 查询支持 | SQL Query Support\n* 属性管理 | Attribute Management\n* 导出和转换 | Export and Conversion\n* 系统功能 | System Functions\n\n## 命令列表 | Command List\n\n所有命令都支持使用 `help` 查询获取详细说明。例如：\n\nAll commands support detailed documentation via the `help` command. For example:\n\n```json\n{\n  \"type\": \"help\",\n  \"params\": {\n    \"type\": \"block.insertBlock\"\n  }\n}\n```\n\n### 资源管理 | Asset Management\n\n* `assets.uploadAssets` - 上传资源文件 | Upload assets\n\n### 属性管理 | Attribute Management\n\n* `attr.setBlockAttrs` - 设置块属性 | Set block attributes\n* `attr.getBlockAttrs` - 获取块属性 | Get block attributes\n\n### 内容块操作 | Block Operations\n\n* `block.insertBlock` - 插入内容块 | Insert a block\n* `block.updateBlock` - 更新内容块 | Update block content\n* `block.deleteBlock` - 删除内容块 | Delete a block\n* `block.moveBlock` - 移动内容块 | Move a block\n* `block.getBlockKramdown` - 获取块的 Markdown 内容 | Get block Kramdown content\n\n### 格式转换 | Format Conversion\n\n* `convert.pandoc` - 使用 Pandoc 转换内容 | Convert content using Pandoc\n\n### 导出功能 | Export Functions\n\n* `export.exportNotebook` - 导出笔记本 | Export notebook\n* `export.exportDoc` - 导出文档 | Export document\n\n### 文件操作 | File Operations\n\n* `file.getFile` - 获取文件内容 | Get file content\n* `file.putFile` - 写入文件内容 | Put file content\n* `file.removeFile` - 删除文件 | Remove file\n* `file.readDir` - 读取目录内容 | List files in directory\n\n### 文档树操作 | File Tree Operations\n\n* `filetree.createDocWithMd` - 使用 Markdown 创建文档 | Create document with Markdown\n* `filetree.renameDoc` - 重命名文档 | Rename document\n* `filetree.removeDoc` - 删除文档 | Remove document\n* `filetree.moveDocs` - 移动文档 | Move documents\n* `filetree.getHPathByPath` - 获取文档可读路径 | Get document HPath by path\n* `filetree.getHPathByID` - 通过 ID 获取文档可读路径 | Get document HPath by ID\n\n### 网络代理 | Network Proxy\n\n* `network.forwardProxy` - 网络请求代理 | Forward proxy request\n\n### 笔记本管理 | Notebook Management\n\n* `notebook.lsNotebooks` - 列出所有笔记本 | List all notebooks\n* `notebook.openNotebook` - 打开笔记本 | Open notebook\n* `notebook.closeNotebook` - 关闭笔记本 | Close notebook\n* `notebook.renameNotebook` - 重命名笔记本 | Rename notebook\n* `notebook.createNotebook` - 创建笔记本 | Create notebook\n* `notebook.removeNotebook` - 删除笔记本 | Remove notebook\n* `notebook.getNotebookConf` - 获取笔记本配置 | Get notebook configuration\n* `notebook.setNotebookConf` - 设置笔记本配置 | Set notebook configuration\n\n### 通知提醒 | Notifications\n\n* `notification.pushMsg` - 发送消息通知 | Push message notification\n* `notification.pushErrMsg` - 发送错误通知 | Push error message notification\n\n### 查询功能 | Query Functions\n\n* `query.sql` - 执行 SQL 查询 | Execute SQL query\n* `query.block` - 通过 ID 查询块 | Query block by ID\n\n### 搜索功能 | Search Functions\n\n* `search.fullTextSearch` - 全文搜索 | Full text search\n\n### SQL 查询 | SQL Query\n\n* `sql.sql` - 执行 SQL 查询 | Execute SQL query\n\n### 系统功能 | System Functions\n\n* `system.getBootProgress` - 获取启动进度 | Get boot progress\n* `system.getVersion` - 获取系统版本 | Get system version\n* `system.getCurrentTime` - 获取当前时间 | Get current time\n\n### 模板功能 | Template Functions\n\n* `template.renderTemplate` - 渲染模板 | Render template\n* `template.renderSprig` - 渲染 Sprig 模板 | Render Sprig template\n\n## 使用说明 | Usage\n\n### 环境变量配置 | Environment Variables\n\n服务器需要配置以下环境变量：\nThe server requires the following environment variables:\n\n* `SIYUAN_TOKEN` - 思源笔记 API 令牌（必需）| SiYuan Note API token (required)\n  * 在思源笔记设置 - 关于 中查看 | Check in SiYuan Note Settings - About\n  * 用于 API 认证 | Used for API authentication\n\n### 在 Claude Desktop 中使用 | Using in Claude Desktop\n\n将以下配置添加到 `claude_desktop_config.json`：\nAdd the following configuration to `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"siyuan\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@onigeya/siyuan-mcp-server\"\n      ],\n      \"env\": {\n        \"SIYUAN_TOKEN\": \"your-siyuan-token\"\n      }\n    }\n  }\n}\n```\n\n### 本地运行 | Local Run\n\n1. 安装依赖 | Install dependencies:\n```bash\npnpm install\n```\n\n2. 设置环境变量 | Set environment variables:\n```bash\n# Windows\nset SIYUAN_TOKEN=your-siyuan-token\n\n# Linux/macOS\nexport SIYUAN_TOKEN=your-siyuan-token\n```\n\n3. 启动服务 | Start service:\n```bash\npnpm start\n```\n\n### Docker 运行 | Docker Run\n\n```bash\ndocker run --rm -i \\\n  -e SIYUAN_TOKEN=your-siyuan-token \\\n  mcp/siyuan\n```\n\n## 构建 | Build\n\n### 环境要求 | Requirements\n\n* Node.js >= 23.10.0\n* pnpm\n\n### 本地构建 | Local Build\n\n```bash\npnpm build\n```\n\n### Docker 构建 | Docker Build\n\n```bash\ndocker build -t mcp/siyuan .\n```\n\n## 许可证 | License\n\n本项目基于 ISC 许可证发布。这意味着你可以自由使用、修改和分发本软件，但需要遵守 ISC 许可证的条款和条件。详细信息请参见项目仓库中的 LICENSE 文件。\n\nThis project is released under the ISC License. This means you can freely use, modify, and distribute this software, subject to the terms and conditions of the ISC License. For detailed information, please refer to the LICENSE file in the project repository.\n\n## 相关资源 | Related Resources\n\n- [思源笔记 | SiYuan Note](https://github.com/siyuan-note/siyuan)\n- [Model Context Protocol](https://modelcontextprotocol.io/)\n- [思源笔记 API 文档 | SiYuan Note API Documentation](https://github.com/siyuan-note/siyuan/blob/master/API.md)",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "siyuan",
        "documents",
        "document",
        "siyuan note",
        "siyuan mcp",
        "integrate siyuan"
      ],
      "category": "document-processing"
    },
    "orellazri--coda-mcp": {
      "owner": "orellazri",
      "name": "coda-mcp",
      "url": "https://github.com/orellazri/coda-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/orellazri.webp",
      "description": "Enable seamless interaction with Coda documents, including listing, creating, reading, updating, and duplicating pages. Provides command access to manipulate document content directly within an AI framework.",
      "stars": 28,
      "forks": 17,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-23T07:11:35Z",
      "readme_content": "# Coda MCP Server\n\nThis project implements a Model Context Protocol (MCP) server that acts as a bridge to interact with the [Coda](https://coda.io/) API. It allows an MCP client (like an AI assistant) to perform actions on Coda pages, such as listing, creating, reading, updating, duplicating, and renaming.\n\n## Features\n\nThe server exposes the following tools to the MCP client:\n\n- **`coda_list_documents`**: Lists all documents available to the user.\n- **`coda_list_pages`**: Lists all pages within the configured Coda document with pagination support.\n- **`coda_create_page`**: Creates a new page in the document, optionally under a specified parent page (creating a subpage) and populating it with initial markdown content.\n- **`coda_get_page_content`**: Retrieves the content of a specified page (by ID or name) as markdown.\n- **`coda_replace_page_content`**: Replaces the content of a specified page with new markdown content.\n- **`coda_append_page_content`**: Appends new markdown content to the end of a specified page.\n- **`coda_duplicate_page`**: Creates a copy of an existing page with a new name.\n- **`coda_rename_page`**: Renames an existing page.\n- **`coda_peek_page`**: Peek into the beginning of a page and return a limited number of lines.\n- **`coda_resolve_link`**: Resolve metadata given a browser link to a Coda object.\n\n## Usage\n\nAdd the MCP server to Cursor/Claude Desktop/etc. like so:\n\n```json\n{\n  \"mcpServers\": {\n    \"coda\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"coda-mcp@latest\"],\n      \"env\": {\n        \"API_KEY\": \"...\"\n      }\n    }\n  }\n}\n```\n\nRequired environment variables:\n\n- `API_KEY`: Your Coda API key. You can generate one from your Coda account settings.\n\nThis MCP server is also available with Docker, like so:\n\n```json\n{\n  \"mcpServers\": {\n    \"coda\": {\n      \"command\": \"docker\",\n      \"args\": [\"run\", \"-i\", \"--rm\", \"-e\", \"API_KEY\", \"reaperberri/coda-mcp:latest\"],\n      \"env\": {\n        \"API_KEY\": \"...\"\n      }\n    }\n  }\n}\n```\n\n## Local Setup\n\n1.  **Prerequisites:**\n\n    - Node.js\n    - pnpm\n\n2.  **Clone the repository:**\n\n    ```bash\n    git clone <repository-url>\n    cd coda-mcp\n    ```\n\n3.  **Install dependencies:**\n\n    ```bash\n    pnpm install\n    ```\n\n4.  **Build the project:**\n    ```bash\n    pnpm build\n    ```\n    This compiles the TypeScript code to JavaScript in the `dist/` directory.\n\n## Running the Server\n\nThe MCP server communicates over standard input/output (stdio). To run it, set the environment variables and run the compiled JavaScript file - `dist/index.js`.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "coda",
        "document",
        "processing",
        "coda documents",
        "coda mcp",
        "orellazri coda"
      ],
      "category": "document-processing"
    },
    "pbteja1998--sourcesyncai-mcp": {
      "owner": "pbteja1998",
      "name": "sourcesyncai-mcp",
      "url": "https://github.com/pbteja1998/sourcesyncai-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/pbteja1998.webp",
      "description": "Integrates with a knowledge management platform to manage and organize documents, ingest content from various sources, and perform semantic and hybrid searches. Facilitates connections to external services for enhanced data retrieval and document management.",
      "stars": 3,
      "forks": 1,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-06-11T16:57:56Z",
      "readme_content": "# SourceSync.ai MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@pbteja1998/sourcesyncai-mcp)](https://smithery.ai/server/@pbteja1998/sourcesyncai-mcp)\n\nA Model Context Protocol (MCP) server implementation for the [SourceSync.ai](https://sourcesync.ai) API. This server allows AI models to interact with SourceSync.ai's knowledge management platform through a standardized interface.\n\n## Features\n\n- Manage namespaces for organizing knowledge\n- Ingest content from various sources (text, URLs, websites, external services)\n- Retrieve, update, and manage documents stored in your knowledge base\n- Perform semantic and hybrid searches against your knowledge base\n- Access document content directly from parsed text URLs\n- Manage connections to external services\n- Default configuration support for seamless AI integration\n\n## Installation\n\n### Running with npx\n\n```bash\n# Install and run with your API key and tenant ID\nenv SOURCESYNC_API_KEY=your_api_key npx -y sourcesyncai-mcp\n```\n\n### Installing via Smithery\n\nTo install sourcesyncai-mcp for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@pbteja1998/sourcesyncai-mcp):\n\n```bash\nnpx -y @smithery/cli install @pbteja1998/sourcesyncai-mcp --client claude\n```\n\n### Manual Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/yourusername/sourcesyncai-mcp.git\ncd sourcesyncai-mcp\n\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n\n# Run the server\nnode dist/index.js\n```\n\n### Running on Cursor\n\nTo configure SourceSync.ai MCP in Cursor:\n\n1. Open Cursor Settings\n1. Go to `Features > MCP Servers`\n1. Click `+ Add New MCP Server`\n1. Enter the following:\n   - Name: `sourcesyncai-mcp` (or your preferred name)\n   - Type: `command`\n   - Command: `env SOURCESYNCAI_API_KEY=your-api-key npx -y sourcesyncai-mcp`\n\nAfter adding, you can use SourceSync.ai tools with Cursor's AI features by describing your knowledge management needs.\n\n### Running on Windsurf\n\nAdd this to your `./codeium/windsurf/model_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"sourcesyncai-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"soucesyncai-mcp\"],\n      \"env\": {\n        \"SOURCESYNC_API_KEY\": \"your_api_key\",\n        \"SOURCESYNC_NAMESPACE_ID\": \"your_namespace_id\",\n        \"SOURCESYNC_TENANT_ID\": \"your_tenant_id\"\n      }\n    }\n  }\n}\n```\n\n### Running on Claude Desktop\n\nTo use this MCP server with Claude Desktop:\n\n1. Locate the Claude Desktop configuration file:\n\n   - **macOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - **Windows**: `%APPDATA%\\Claude\\claude_desktop_config.json`\n   - **Linux**: `~/.config/Claude/claude_desktop_config.json`\n\n2. Edit the configuration file to add the SourceSync.ai MCP server:\n\n```json\n{\n  \"mcpServers\": {\n    \"sourcesyncai-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"sourcesyncai-mcp\"],\n      \"env\": {\n        \"SOURCESYNC_API_KEY\": \"your_api_key\",\n        \"SOURCESYNC_NAMESPACE_ID\": \"your_namespace_id\",\n        \"SOURCESYNC_TENANT_ID\": \"your_tenant_id\"\n      }\n    }\n  }\n}\n```\n\n3. Save the configuration file and restart Claude Desktop\n\n## Configuration\n\n### Environment Variables\n\n#### Required\n\n- `SOURCESYNC_API_KEY`: Your SourceSync.ai API key (required)\n\n#### Optional\n\n- `SOURCESYNC_NAMESPACE_ID`: Default namespace ID to use for operations\n- `SOURCESYNC_TENANT_ID`: Your tenant ID (optional)\n\n### Configuration Examples\n\nBasic configuration with default values:\n\n```bash\nexport SOURCESYNC_API_KEY=your_api_key\nexport SOURCESYNC_TENANT_ID=your_tenant_id\nexport SOURCESYNC_NAMESPACE_ID=your_namespace_id\n```\n\n## Available Tools\n\n### Authentication\n\n- `validate_api_key`: Validate a SourceSync.ai API key\n\n```json\n{\n  \"name\": \"validate_api_key\",\n  \"arguments\": {}\n}\n```\n\n### Namespaces\n\n- `create_namespace`: Create a new namespace\n- `list_namespaces`: List all namespaces\n- `get_namespace`: Get details of a specific namespace\n- `update_namespace`: Update a namespace\n- `delete_namespace`: Delete a namespace\n\n```json\n{\n  \"name\": \"create_namespace\",\n  \"arguments\": {\n    \"name\": \"my-namespace\",\n    \"fileStorageConfig\": {\n      \"provider\": \"S3_COMPATIBLE\",\n      \"config\": {\n        \"endpoint\": \"s3.amazonaws.com\",\n        \"accessKey\": \"your_access_key\",\n        \"secretKey\": \"your_secret_key\",\n        \"bucket\": \"your_bucket\",\n        \"region\": \"us-east-1\"\n      }\n    },\n    \"vectorStorageConfig\": {\n      \"provider\": \"PINECONE\",\n      \"config\": {\n        \"apiKey\": \"your_pinecone_api_key\",\n        \"environment\": \"your_environment\",\n        \"index\": \"your_index\"\n      }\n    },\n    \"embeddingModelConfig\": {\n      \"provider\": \"OPENAI\",\n      \"config\": {\n        \"apiKey\": \"your_openai_api_key\",\n        \"model\": \"text-embedding-3-small\"\n      }\n    },\n    \"tenantId\": \"tenant_XXX\"\n  }\n}\n```\n\n```json\n{\n  \"name\": \"list_namespaces\",\n  \"arguments\": {\n    \"tenantId\": \"tenant_XXX\"\n  }\n}\n```\n\n```json\n{\n  \"name\": \"get_namespace\",\n  \"arguments\": {\n    \"namespaceId\": \"namespace_XXX\",\n    \"tenantId\": \"tenant_XXX\"\n  }\n}\n```\n\n```json\n{\n  \"name\": \"update_namespace\",\n  \"arguments\": {\n    \"namespaceId\": \"namespace_XXX\",\n    \"tenantId\": \"tenant_XXX\",\n    \"name\": \"updated-namespace-name\"\n  }\n}\n```\n\n```json\n{\n  \"name\": \"delete_namespace\",\n  \"arguments\": {\n    \"namespaceId\": \"namespace_XXX\",\n    \"tenantId\": \"tenant_XXX\"\n  }\n}\n```\n\n### Data Ingestion\n\n- `ingest_text`: Ingest text content\n- `ingest_urls`: Ingest content from URLs\n- `ingest_sitemap`: Ingest content from a sitemap\n- `ingest_website`: Ingest content from a website\n- `ingest_notion`: Ingest content from Notion\n- `ingest_google_drive`: Ingest content from Google Drive\n- `ingest_dropbox`: Ingest content from Dropbox\n- `ingest_onedrive`: Ingest content from OneDrive\n- `ingest_box`: Ingest content from Box\n- `get_ingest_job_run_status`: Get the status of an ingestion job run\n\n```json\n{\n  \"name\": \"ingest_text\",\n  \"arguments\": {\n    \"namespaceId\": \"your_namespace_id\",\n    \"ingestConfig\": {\n      \"source\": \"TEXT\",\n      \"config\": {\n        \"name\": \"example-document\",\n        \"text\": \"This is an example document for ingestion.\",\n        \"metadata\": {\n          \"category\": \"example\",\n          \"author\": \"AI Assistant\"\n        }\n      }\n    },\n    \"tenantId\": \"tenant_XXX\"\n  }\n}\n```\n\n```json\n{\n  \"name\": \"ingest_urls\",\n  \"arguments\": {\n    \"namespaceId\": \"your_namespace_id\",\n    \"ingestConfig\": {\n      \"source\": \"URLS\",\n      \"config\": {\n        \"urls\": [\"https://example.com/page1\", \"https://example.com/page2\"],\n        \"metadata\": {\n          \"source\": \"web\",\n          \"category\": \"documentation\"\n        }\n      }\n    },\n    \"tenantId\": \"tenant_XXX\"\n  }\n}\n```\n\n```json\n{\n  \"name\": \"ingest_sitemap\",\n  \"arguments\": {\n    \"namespaceId\": \"your_namespace_id\",\n    \"ingestConfig\": {\n      \"source\": \"SITEMAP\",\n      \"config\": {\n        \"url\": \"https://example.com/sitemap.xml\",\n        \"metadata\": {\n          \"source\": \"sitemap\",\n          \"website\": \"example.com\"\n        }\n      }\n    },\n    \"tenantId\": \"tenant_XXX\"\n  }\n}\n```\n\n```json\n{\n  \"name\": \"ingest_website\",\n  \"arguments\": {\n    \"namespaceId\": \"your_namespace_id\",\n    \"ingestConfig\": {\n      \"source\": \"WEBSITE\",\n      \"config\": {\n        \"url\": \"https://example.com\",\n        \"maxDepth\": 3,\n        \"maxPages\": 100,\n        \"metadata\": {\n          \"source\": \"website\",\n          \"domain\": \"example.com\"\n        }\n      }\n    },\n    \"tenantId\": \"tenant_XXX\"\n  }\n}\n```\n\n```json\n{\n  \"name\": \"ingest_notion\",\n  \"arguments\": {\n    \"namespaceId\": \"your_namespace_id\",\n    \"ingestConfig\": {\n      \"source\": \"NOTION\",\n      \"config\": {\n        \"connectionId\": \"your_notion_connection_id\",\n        \"metadata\": {\n          \"source\": \"notion\",\n          \"workspace\": \"My Workspace\"\n        }\n      }\n    },\n    \"tenantId\": \"your_tenant_id\"\n  }\n}\n```\n\n```json\n{\n  \"name\": \"ingest_google_drive\",\n  \"arguments\": {\n    \"namespaceId\": \"your_namespace_id\",\n    \"ingestConfig\": {\n      \"source\": \"GOOGLE_DRIVE\",\n      \"config\": {\n        \"connectionId\": \"connection_XXX\",\n        \"metadata\": {\n          \"source\": \"google_drive\",\n          \"owner\": \"user@example.com\"\n        }\n      }\n    },\n    \"tenantId\": \"tenant_XXX\"\n  }\n}\n```\n\n```json\n{\n  \"name\": \"ingest_dropbox\",\n  \"arguments\": {\n    \"namespaceId\": \"your_namespace_id\",\n    \"ingestConfig\": {\n      \"source\": \"DROPBOX\",\n      \"config\": {\n        \"connectionId\": \"connection_XXX\",\n        \"metadata\": {\n          \"source\": \"dropbox\",\n          \"account\": \"user@example.com\"\n        }\n      }\n    },\n    \"tenantId\": \"tenant_XXX\"\n  }\n}\n```\n\n```json\n{\n  \"name\": \"ingest_onedrive\",\n  \"arguments\": {\n    \"namespaceId\": \"your_namespace_id\",\n    \"ingestConfig\": {\n      \"source\": \"ONEDRIVE\",\n      \"config\": {\n        \"connectionId\": \"connection_XXX\",\n        \"metadata\": {\n          \"source\": \"onedrive\",\n          \"account\": \"user@example.com\"\n        }\n      }\n    },\n    \"tenantId\": \"tenant_XXX\"\n  }\n}\n```\n\n```json\n{\n  \"name\": \"ingest_box\",\n  \"arguments\": {\n    \"namespaceId\": \"your_namespace_id\",\n    \"ingestConfig\": {\n      \"source\": \"BOX\",\n      \"config\": {\n        \"connectionId\": \"connection_XXX\",\n        \"metadata\": {\n          \"source\": \"box\",\n          \"owner\": \"user@example.com\"\n        }\n      }\n    },\n    \"tenantId\": \"tenant_XXX\"\n  }\n}\n```\n\n```json\n{\n  \"name\": \"get_ingest_job_run_status\",\n  \"arguments\": {\n    \"namespaceId\": \"your_namespace_id\",\n    \"ingestJobRunId\": \"ingest_job_run_XXX\",\n    \"tenantId\": \"tenant_XXX\"\n  }\n}\n```\n\n### Documents\n\n- `getDocuments`: Retrieve documents with optional filters\n- `updateDocuments`: Update document metadata\n- `deleteDocuments`: Delete documents\n- `resyncDocuments`: Resync documents\n- `fetchUrlContent`: Fetch text content from document URLs\n\n```json\n{\n  \"name\": \"getDocuments\",\n  \"arguments\": {\n    \"namespaceId\": \"namespace_XXX\",\n    \"tenantId\": \"tenant_XXX\",\n    \"filterConfig\": {\n      \"documentTypes\": [\"PDF\"]\n    },\n    \"includeConfig\": {\n      \"parsedTextFileUrl\": true\n    }\n  }\n}\n```\n\n```json\n{\n  \"name\": \"updateDocuments\",\n  \"arguments\": {\n    \"namespaceId\": \"namespace_XXX\",\n    \"tenantId\": \"tenant_XXX\",\n    \"documentIds\": [\"doc_XXX\", \"doc_YYY\"],\n    \"filterConfig\": {\n      \"documentIds\": [\"doc_XXX\", \"doc_YYY\"]\n    },\n    \"data\": {\n      \"metadata\": {\n        \"status\": \"reviewed\",\n        \"category\": \"technical\"\n      }\n    }\n  }\n}\n```\n\n```json\n{\n  \"name\": \"deleteDocuments\",\n  \"arguments\": {\n    \"namespaceId\": \"namespace_XXX\",\n    \"tenantId\": \"tenant_XXX\",\n    \"documentIds\": [\"doc_XXX\", \"doc_YYY\"],\n    \"filterConfig\": {\n      \"documentIds\": [\"doc_XXX\", \"doc_YYY\"]\n    }\n  }\n}\n```\n\n```json\n{\n  \"name\": \"resyncDocuments\",\n  \"arguments\": {\n    \"namespaceId\": \"namespace_XXX\",\n    \"tenantId\": \"tenant_XXX\",\n    \"documentIds\": [\"doc_XXX\", \"doc_YYY\"],\n    \"filterConfig\": {\n      \"documentIds\": [\"doc_XXX\", \"doc_YYY\"]\n    }\n  }\n}\n```\n\n```json\n{\n  \"name\": \"fetchUrlContent\",\n  \"arguments\": {\n    \"url\": \"https://api.sourcesync.ai/v1/documents/doc_XXX/content?format=text\",\n    \"apiKey\": \"your_api_key\",\n    \"tenantId\": \"tenant_XXX\"\n  }\n}\n```\n\n### Search\n\n- `semantic_search`: Perform semantic search\n- `hybrid_search`: Perform hybrid search (semantic + keyword)\n\n```json\n{\n  \"name\": \"semantic_search\",\n  \"arguments\": {\n    \"namespaceId\": \"your_namespace_id\",\n    \"query\": \"example document\",\n    \"topK\": 5,\n    \"tenantId\": \"tenant_XXX\"\n  }\n}\n```\n\n```json\n{\n  \"name\": \"hybrid_search\",\n  \"arguments\": {\n    \"namespaceId\": \"your_namespace_id\",\n    \"query\": \"example document\",\n    \"topK\": 5,\n    \"tenantId\": \"tenant_XXX\",\n    \"hybridConfig\": {\n      \"semanticWeight\": 0.7,\n      \"keywordWeight\": 0.3\n    }\n  }\n}\n```\n\n### Connections\n\n- `create_connection`: Create a new connection to an external service\n- `list_connections`: List all connections\n- `get_connection`: Get details of a specific connection\n- `update_connection`: Update a connection\n- `revoke_connection`: Revoke a connection\n\n```json\n{\n  \"name\": \"create_connection\",\n  \"arguments\": {\n    \"tenantId\": \"tenant_XXX\",\n    \"namespaceId\": \"namespace_XXX\",\n    \"name\": \"My Connection\",\n    \"connector\": \"GOOGLE_DRIVE\",\n    \"clientRedirectUrl\": \"https://your-app.com/callback\"\n  }\n}\n```\n\n```json\n{\n  \"name\": \"list_connections\",\n  \"arguments\": {\n    \"tenantId\": \"tenant_XXX\",\n    \"namespaceId\": \"namespace_XXX\"\n  }\n}\n```\n\n```json\n{\n  \"name\": \"get_connection\",\n  \"arguments\": {\n    \"tenantId\": \"tenant_XXX\",\n    \"namespaceId\": \"namespace_XXX\",\n    \"connectionId\": \"connection_XXX\"\n  }\n}\n```\n\n```json\n{\n  \"name\": \"update_connection\",\n  \"arguments\": {\n    \"tenantId\": \"tenant_XXX\",\n    \"namespaceId\": \"namespace_XXX\",\n    \"connectionId\": \"connection_XXX\",\n    \"name\": \"Updated Connection Name\",\n    \"clientRedirectUrl\": \"https://your-app.com/updated-callback\"\n  }\n}\n```\n\n```json\n{\n  \"name\": \"revoke_connection\",\n  \"arguments\": {\n    \"tenantId\": \"tenant_XXX\",\n    \"namespaceId\": \"namespace_XXX\",\n    \"connectionId\": \"connection_XXX\"\n  }\n}\n```\n\n## Example Prompts\n\nHere are some example prompts you can use with Claude or Cursor after configuring the MCP server:\n\n- \"Search my SourceSync knowledge base for information about machine learning.\"\n- \"Ingest this article into my SourceSync knowledge base: [URL]\"\n- \"Create a new namespace in SourceSync for my project documentation.\"\n- \"List all the documents in my SourceSync namespace.\"\n- \"Get the text content of document [document_id] from my SourceSync namespace.\"\n\n## Troubleshooting\n\n### Connection Issues\n\nIf you encounter issues connecting the SourceSync.ai MCP server:\n\n1. **Verify Paths**: Ensure all paths in your configuration are absolute paths, not relative.\n2. **Check Permissions**: Ensure the server file has execution permissions (`chmod +x dist/index.js`).\n3. **Enable Developer Mode**: In Claude Desktop, enable Developer Mode and check the MCP Log File.\n4. **Test the Server**: Run the server directly from the command line:\n\n   ```bash\n   node /path/to/sourcesyncai-mcp/dist/index.js\n   ```\n\n5. **Restart AI Client**: After making changes, completely restart Claude Desktop or Cursor.\n6. **Check Environment Variables**: Ensure all required environment variables are correctly set.\n\n### Debug Logging\n\nFor detailed logging, add the DEBUG environment variable:\n\n```\n\n```\n\n## Development\n\n### Project Structure\n\n- `src/index.ts`: Main entry point and server setup\n- `src/schemas.ts`: Schema definitions for all tools\n- `src/sourcesync.ts`: Client for interacting with SourceSync.ai API\n- `src/sourcesync.types.ts`: TypeScript type definitions\n\n### Building and Testing\n\n```bash\n# Build the project\nnpm run build\n\n# Run tests\nnpm test\n```\n\n## License\n\nMIT\n\n## Links\n\n- [SourceSync.ai Documentation](https://sourcesync.ai)\n- [SourceSync.ai API Reference](https://sourcesync.ai/api-reference/authentication)\n- [Model Context Protocol](https://modelcontextprotocol.io/introduction)\n\nDocument content retrieval workflow:\n\n1. First, use `getDocuments` with `includeConfig.parsedTextFileUrl: true` to get documents with their content URLs\n2. Extract the URL from the document response\n3. Use `fetchUrlContent` to retrieve the actual content:\n\n```json\n{\n  \"name\": \"fetchUrlContent\",\n  \"arguments\": {\n    \"url\": \"https://example.com\"\n  }\n}\n```\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "documents",
        "document",
        "sourcesyncai",
        "document processing",
        "document management",
        "sourcesyncai mcp"
      ],
      "category": "document-processing"
    },
    "petercat-ai--whiskerrag_toolkit": {
      "owner": "petercat-ai",
      "name": "whiskerrag_toolkit",
      "url": "https://github.com/petercat-ai/whiskerrag_toolkit",
      "imageUrl": "/freedevtools/mcp/pfp/petercat-ai.webp",
      "description": "Provides retrieval-augmented generation capabilities for applications, allowing integration of various data sources with advanced processing methods. Features a toolkit with type definitions and methods for effective RAG implementation.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-02T06:44:45Z",
      "readme_content": "# WhiskerRAG\n\n[![MIT License](https://img.shields.io/badge/License-MIT-green.svg)](https://choosealicense.com/licenses/mit/)\n[![Python Version](https://img.shields.io/pypi/pyversions/whiskerrag)](https://pypi.org/project/whiskerrag/)\n[![PyPI version](https://badge.fury.io/py/whiskerrag.svg)](https://badge.fury.io/py/whiskerrag)\n[![codecov](https://codecov.io/gh/petercat-ai/whiskerrag_toolkit/branch/main/graph/badge.svg)](https://codecov.io/gh/petercat-ai/whiskerrag_toolkit)\n\nWhiskerRAG 是为 PeterCat 和 Whisker 项目开发的 RAG（Retrieval-Augmented Generation）工具包，提供完整的 RAG 相关类型定义和方法实现。\n\n## 特性\n\n- 针对通用 RAG 的领域建模类型, 包括任务（Task）、知识（Knowledge）、分段(Chunk)、租户(Tenant)、知识库空间(Space)。\n- Whisker rag 插件接口描述。\n- Github 仓库、S3 资源管理器。\n\n## 安装\n\n使用 pip 安装：\n\n```bash\npip install whiskerrag\n```\n\n## 快速开始\n\nwhiskerrag 包含三个子模块，分别是 whiskerrag_utils、whiskerrag_client、whiskerrag_types。它们分别有不同的用途：\n\n### whiskerrag_utils\n\n包含了构建 RAG 系统的常用方法：\n\n```python\nfrom whiskerrag_utils import loader,embedding,retriever\n```\n\n### whiskerrag_client\n\n将 RAG 系统服务通过 python sdk 的形式向外暴露。\n\n```python\nfrom whiskerrag_client import APIClient\n\napi_client = APIClient(\n    base_url=\"https://api.example.com\",\n    token=\"your_token_here\"\n)\n\nknowledge_chunks = await api_client.retrieval.retrieve_knowledge_content(\n    RetrievalByKnowledgeRequest(knowledge_id=\"your knowledge uuid here\")\n)\n\nspace_chunks = await api_client.retrieval.retrieve_space_content(\n    RetrievalBySpaceRequest(space_id=\"your space id here \")\n)\n\nchunk_list = await api_client.chunk.get_chunk_list(\n    page=1,\n    size=10,\n    filters={\"status\": \"active\"}\n)\n\ntask_list = await api_client.task.get_task_list(\n    page=1,\n    size=10\n)\n\ntask_detail = await api_client.task.get_task_detail(\"task_id_here\")\n```\n\n### whiskerrag_types\n\n一些辅助开发的类型提示，接口；\n\n```python\nfrom whiskerrag_types.interface import DBPluginInterface, TaskEngineInterface\nfrom whiskerrag_types.model import Knowledge, Task, Tenant, PageParams, PageResponse\n```\n\n## 开发者指南\n\n### 环境初始化\n\n1. 克隆项目\n\n```bash\ngit clone https://github.com/petercat-ai/whiskerrag_toolkit.git\ncd whiskerrag_toolkit\n```\n\n2. 创建并激活虚拟环境\n\n```bash\n# 查看poetry配置\npoetry config --list\n\n# 修改 poetry 配置\npoetry config virtualenvs.create true\npoetry config virtualenvs.in-project true\n\npoetry env use python3.10\n\n# 激活虚拟环境\nsource .venv/bin/activate\n```\n\n3. 安装依赖\n\n```bash\n# 安装项目依赖\npoetry install\n# 安装 pre-commit 工具\npre-commit install\n```\n\n4. 运行测试\n\n```bash\n# 运行所有测试\npoetry run pytest\n# 运行指定测试文件\npoetry run pytest tests/test_loader.py\n```\n\n4. poetry 常用命令\n\n```bash\n# 安装依赖\npoetry install\n\n# 添加新依赖\npoetry add package_name\n\n# 添加新 dev 依赖\npoetry add --dev package_name\n\n# 更新依赖\npoetry update\n\n# 查看环境信息\npoetry env info\n\n# 查看已安装的包\npoetry show\n```\n\n### 开发工作流\n\n1. 创建新分支\n2. 开发新功能，补充单元测试，确保代码质量。注意，请确保单元测试覆盖率不低于 80%。\n3. 提交代码，并创建 Pull Request。\n4. 等待代码审查，并根据反馈进行修改。\n5. 合并 Pull Request。\n\n## 项目结构\n\n```\nwhiskerRAG-toolkit/\n├── src/\n│   ├── whiskerrag_utils/\n│   └── whiskerrag_types/\n│   └── whiskerrag_client/\n└── pyproject.toml\n```\n\n## 贡献指南\n\n1. Fork 本仓库\n2. 创建特性分支 (`make branch name=feature/amazing-feature`)\n3. 提交更改 (`git commit -m 'Add some amazing feature'`)\n4. 推送到分支 (`git push origin feature/amazing-feature`)\n5. 开启 Pull Request\n\n## 许可证\n\n本项目采用 MIT 许可证 - 查看 [LICENSE](LICENSE) 文件了解详情\n\n## 联系方式\n\n项目维护者 - [@petercat-ai](https://github.com/petercat-ai)\n\n项目链接：[https://github.com/petercat-ai/whiskerrag_toolkit](https://github.com/your-username/whiskerrag_toolkit)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "whiskerrag_toolkit",
        "toolkit",
        "retrieval",
        "ai whiskerrag_toolkit",
        "whiskerrag_toolkit provides",
        "document processing"
      ],
      "category": "document-processing"
    },
    "privetin--chroma": {
      "owner": "privetin",
      "name": "chroma",
      "url": "https://github.com/privetin/chroma",
      "imageUrl": "/freedevtools/mcp/pfp/privetin.webp",
      "description": "Provides vector database capabilities for semantic search and document management, enabling storage and retrieval of documents along with their metadata.",
      "stars": 38,
      "forks": 14,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-05T23:55:58Z",
      "readme_content": "# Chroma MCP Server\n\nA Model Context Protocol (MCP) server implementation that provides vector database capabilities through Chroma. This server enables semantic document search, metadata filtering, and document management with persistent storage.\n\n## Requirements\n\n- Python 3.8+\n- Chroma 0.4.0+\n- MCP SDK 0.1.0+\n\n## Components\n\n### Resources\nThe server provides document storage and retrieval through Chroma's vector database:\n- Stores documents with content and metadata\n- Persists data in `src/chroma/data` directory\n- Supports semantic similarity search\n\n### Tools\n\nThe server implements CRUD operations and search functionality:\n\n#### Document Management\n- `create_document`: Create a new document\n  - Required: `document_id`, `content`\n  - Optional: `metadata` (key-value pairs)\n  - Returns: Success confirmation\n  - Error: Already exists, Invalid input\n\n- `read_document`: Retrieve a document by ID\n  - Required: `document_id`\n  - Returns: Document content and metadata\n  - Error: Not found\n\n- `update_document`: Update an existing document\n  - Required: `document_id`, `content`\n  - Optional: `metadata`\n  - Returns: Success confirmation\n  - Error: Not found, Invalid input\n\n- `delete_document`: Remove a document\n  - Required: `document_id`\n  - Returns: Success confirmation\n  - Error: Not found\n\n- `list_documents`: List all documents\n  - Optional: `limit`, `offset`\n  - Returns: List of documents with content and metadata\n\n#### Search Operations\n- `search_similar`: Find semantically similar documents\n  - Required: `query`\n  - Optional: `num_results`, `metadata_filter`, `content_filter`\n  - Returns: Ranked list of similar documents with distance scores\n  - Error: Invalid filter\n\n## Features\n\n- **Semantic Search**: Find documents based on meaning using Chroma's embeddings\n- **Metadata Filtering**: Filter search results by metadata fields\n- **Content Filtering**: Additional filtering based on document content\n- **Persistent Storage**: Data persists in local directory between server restarts\n- **Error Handling**: Comprehensive error handling with clear messages\n- **Retry Logic**: Automatic retries for transient failures\n\n## Installation\n\n1. Install dependencies:\n```bash\nuv venv\nuv sync --dev --all-extras\n```\n\n## Configuration\n\n### Claude Desktop\n\nAdd the server configuration to your Claude Desktop config:\n\nWindows: `C:\\Users\\<username>\\AppData\\Roaming\\Claude\\claude_desktop_config.json`\n\nMacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"chroma\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"C:/MCP/server/community/chroma\",\n        \"run\",\n        \"chroma\"\n      ]\n    }\n  }\n}\n```\n\n### Data Storage\n\nThe server stores data in:\n- Windows: `src/chroma/data`\n- MacOS/Linux: `src/chroma/data`\n\n## Usage\n\n1. Start the server:\n```bash\nuv run chroma\n```\n\n2. Use MCP tools to interact with the server:\n\n```python\n# Create a document\ncreate_document({\n    \"document_id\": \"ml_paper1\",\n    \"content\": \"Convolutional neural networks improve image recognition accuracy.\",\n    \"metadata\": {\n        \"year\": 2020,\n        \"field\": \"computer vision\",\n        \"complexity\": \"advanced\"\n    }\n})\n\n# Search similar documents\nsearch_similar({\n    \"query\": \"machine learning models\",\n    \"num_results\": 2,\n    \"metadata_filter\": {\n        \"year\": 2020,\n        \"field\": \"computer vision\"\n    }\n})\n```\n\n## Error Handling\n\nThe server provides clear error messages for common scenarios:\n- `Document already exists [id=X]`\n- `Document not found [id=X]`\n- `Invalid input: Missing document_id or content`\n- `Invalid filter`\n- `Operation failed: [details]`\n\n## Development\n\n### Testing\n\n1. Run the MCP Inspector for interactive testing:\n```bash\nnpx @modelcontextprotocol/inspector uv --directory C:/MCP/server/community/chroma run chroma\n```\n\n2. Use the inspector's web interface to:\n   - Test CRUD operations\n   - Verify search functionality\n   - Check error handling\n   - Monitor server logs\n\n### Building\n\n1. Update dependencies:\n```bash\nuv compile pyproject.toml\n```\n\n2. Build package:\n```bash\nuv build\n```\n\n## Contributing\n\nContributions are welcome! Please read our [Contributing Guidelines](CONTRIBUTING.md) for details on:\n- Code style\n- Testing requirements\n- Pull request process\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "documents",
        "document",
        "retrieval",
        "retrieval documents",
        "document processing",
        "documents metadata"
      ],
      "category": "document-processing"
    },
    "probelabs--docs-mcp": {
      "owner": "probelabs",
      "name": "docs-mcp",
      "url": "https://github.com/probelabs/docs-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/probelabs.webp",
      "description": "Enables AI assistants to search and interact with documentation or codebases by pointing to a Git repository or local folder, allowing for natural language queries about the contents.",
      "stars": 60,
      "forks": 16,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-21T01:52:20Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/buger-docs-mcp-badge.png)](https://mseep.ai/app/buger-docs-mcp)\n\n# Docs MCP Server\n[![smithery badge](https://smithery.ai/badge/@buger/docs-mcp)](https://smithery.ai/server/@buger/docs-mcp)\n\nThis project provides a flexible Model Context Protocol (MCP) server, powered by [Probe](https://probeai.dev/), designed to make documentation or codebases searchable by AI assistants.\n\n<a href=\"https://glama.ai/mcp/servers/@buger/docs-mcp\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@buger/docs-mcp/badge\" alt=\"Docs Server MCP server\" />\n</a>\n\nYou can chat with code or your docs, simply by pointing to git repo or a folder.\n```\nnpx -y @buger/docs-mcp@latest --gitUrl https://github.com/buger/probe\n```\n\n**Use Cases:**\n\n*   **Chat with any GitHub Repository:** Point the server to a public or private Git repository to enable natural language queries about its contents.\n*   **Search Your Documentation:** Integrate your project's documentation (from a local directory or Git) for easy searching.\n*   **Build Custom MCP Servers:** Use this project as a template to create your own official MCP servers tailored to specific documentation sets or even codebases.\n\nThe content source (documentation or code) can be **pre-built** into the package during the `npm run build` step, or configured **dynamically** at runtime using local directories or Git repositories. By default, when using a `gitUrl` without enabling auto-updates, the server downloads a `.tar.gz` archive for faster startup. Full Git cloning is used only when `autoUpdateInterval` is greater than 0.\n\n## Features\n\n- **Powered by Probe:** Leverages the [Probe](https://probeai.dev/) search engine for efficient and relevant results.\n- **Flexible Content Sources:** Include a specific local directory or clone a Git repository.\n- **Pre-build Content:** Optionally bundle documentation/code content directly into the package.\n- **Dynamic Configuration:** Configure content sources, Git settings, and MCP tool details via config file, CLI arguments, or environment variables.\n- **Automatic Git Updates:** Keep content fresh by automatically pulling changes from a Git repository at a configurable interval.\n- **Customizable MCP Tool:** Define the name and description of the search tool exposed to AI assistants.\n- **AI Integration:** Seamlessly integrates with AI assistants supporting the Model Context Protocol (MCP).\n\n## Usage\n\nThe primary way to use this server is via `npx`, which downloads and runs the package without needing a local installation. This makes it easy to integrate with AI assistants and MCP clients (like IDE extensions).\n\n### Installing via Smithery\n\nTo install Docs MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@buger/docs-mcp):\n\n```bash\nnpx -y @smithery/cli install @buger/docs-mcp --client claude\n```\n\n### Integrating with MCP Clients (e.g., IDEs)\n\nYou can configure your MCP client to launch this server using `npx`. Here are examples of how you might configure a client (syntax may vary based on the specific client):\n\n**Example 1: Dynamically Searching a Git Repository (Tyk Docs)**\n\nThis configuration tells the client to run the latest `@buger/docs-mcp` package using `npx`, pointing it dynamically to the Tyk documentation repository. The `-y` argument automatically confirms the `npx` installation prompt. The `--toolName` and `--toolDescription` arguments customize how the search tool appears to the AI assistant.\n\n```json\n{\n  \"mcpServers\": {\n    \"tyk-docs-search\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@buger/docs-mcp@latest\",\n        \"--gitUrl\",\n        \"https://github.com/TykTechnologies/tyk-docs\",\n        \"--toolName\",\n        \"search_tyk_docs\",\n        \"--toolDescription\",\n        \"Search Tyk API Management Documentation\"\n      ],\n      \"enabled\": true\n    }\n  }\n}\n```\n\nAlternatively, some clients might allow specifying the full command directly. You could achieve the same as Example 1 using:\n\n```bash\nnpx -y @buger/docs-mcp@latest --gitUrl https://github.com/TykTechnologies/tyk-docs --toolName search_tyk_docs --toolDescription \"Search Tyk API Management Documentation\"\n```\n\n**Example 2: Using a Pre-built, Branded MCP Server (e.g., Tyk Package)**\n\nIf a team publishes a pre-built package containing specific documentation (like `@tyk-technologies/docs-mcp`), the configuration becomes simpler as the content source and tool details are baked into that package. The `-y` argument is still recommended for `npx`.\n\n```json\n{\n  \"mcpServers\": {\n    \"tyk-official-docs\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@tyk-technologies/docs-mcp@latest\"\n      ],\n      \"enabled\": true\n    }\n  }\n}\n```\n\nThis approach is ideal for distributing standardized search experiences for official documentation or codebases. See the \"Creating Your Own Pre-built MCP Server\" section below.\n\nHere is example on how Tyk team have build own documentation MCP server https://github.com/TykTechnologies/docs-mcp. \n\n## Configuration\n\nCreate a `docs-mcp.config.json` file in the root directory to define the **default** content source and MCP tool details used during the build and at runtime (unless overridden by CLI arguments or environment variables).\n\n### Example 1: Using a Local Directory\n\n```json\n{\n  \"includeDir\": \"/Users/username/projects/my-project/docs\",\n  \"toolName\": \"search_my_project_docs\",\n  \"toolDescription\": \"Search the documentation for My Project.\",\n  \"ignorePatterns\": [\n    \"node_modules\",\n    \".git\",\n    \"build\",\n    \"*.log\"\n  ]\n}\n```\n\n### Example 2: Using a Git Repository\n\n```json\n{\n  \"gitUrl\": \"https://github.com/your-org/your-codebase.git\",\n  \"gitRef\": \"develop\",\n  \"autoUpdateInterval\": 15,\n  \"toolName\": \"search_codebase\",\n  \"toolDescription\": \"Search the main company codebase.\",\n  \"ignorePatterns\": [\n    \"*.test.js\",\n    \"dist/\",\n    \"__snapshots__\"\n  ]\n}\n```\n\n### Configuration Options\n\n- `includeDir`: **(Build/Runtime)** Absolute path to a local directory whose contents will be copied to the `data` directory during build, or used directly at runtime if `dataDir` is not specified. Use this OR `gitUrl`.\n- `gitUrl`: **(Build/Runtime)** URL of the Git repository. Use this OR `includeDir`.\n    - If `autoUpdateInterval` is 0 (default), the server attempts to download a `.tar.gz` archive directly (currently assumes GitHub URL structure: `https://github.com/{owner}/{repo}/archive/{ref}.tar.gz`). This is faster but doesn't support updates.\n    - If `autoUpdateInterval` > 0, the server performs a `git clone` and enables periodic updates.\n- `gitRef`: **(Build/Runtime)** The branch, tag, or commit hash to use from the `gitUrl` (default: `main`). Used for both tarball download and Git clone/pull.\n- `autoUpdateInterval`: **(Runtime)** Interval in minutes to automatically check for Git updates (default: 0, meaning disabled). Setting this to a value > 0 enables Git cloning and periodic `git pull` operations. Requires the `git` command to be available in the system path.\n- `dataDir`: **(Runtime)** Path to the directory containing the content to be searched at runtime. Overrides content sourced from `includeDir` or `gitUrl` defined in the config file or built into the package. Useful for pointing the server to live data without rebuilding.\n- `toolName`: **(Build/Runtime)** The name of the MCP tool exposed by the server (default: `search_docs`). Choose a descriptive name relevant to the content.\n- `toolDescription`: **(Build/Runtime)** The description of the MCP tool shown to AI assistants (default: \"Search documentation using the probe search engine.\").\n- `ignorePatterns`: **(Build/Runtime)** An array of glob patterns.\n- `enableBuildCleanup`: **(Build)** If `true` (default), removes common binary/media files (images, videos, archives, etc.) and files larger than 100KB from the `data` directory after the build step. Set to `false` to disable this cleanup.\n    - If using `includeDir` during build: Files matching these patterns are excluded when copying to `data`. `.gitignore` rules are also respected.\n    - If using `gitUrl` or `dataDir` at runtime: Files matching these patterns within the `data` directory are ignored by the search indexer.\n\n**Precedence:**\n\n1.  **Runtime Configuration (Highest):** CLI arguments (`--dataDir`, `--gitUrl`, etc.) and Environment Variables (`DATA_DIR`, `GIT_URL`, etc.) override all other settings. CLI arguments take precedence over Environment Variables.\n2.  **Build-time Configuration:** Settings in `docs-mcp.config.json` (`includeDir`, `gitUrl`, `toolName`, etc.) define defaults used during `npm run build` and also serve as runtime defaults if not overridden.\n3.  **Default Values (Lowest):** Internal defaults are used if no configuration is provided (e.g., `toolName: 'search_docs'`, `autoUpdateInterval: 5`).\n\nNote: If both `includeDir` and `gitUrl` are provided in the *same* configuration source (e.g., both in the config file, or both as CLI args), `gitUrl` takes precedence.\n\n## Creating Your Own Pre-built MCP Server\n\nYou can use this project as a template to create and publish your own npm package with documentation or code pre-built into it. This provides a zero-configuration experience for users (like Example 2 above).\n\n1.  **Fork/Clone this Repository:** Start with this project's code.\n2.  **Configure `docs-mcp.config.json`:** Define the `includeDir` or `gitUrl` pointing to your content source. Set the default `toolName` and `toolDescription`.\n3.  **Update `package.json`:** Change the `name` (e.g., `@my-org/my-docs-mcp`), `version`, `description`, etc.\n4.  **Build:** Run `npm run build`. This clones/copies your content into the `data` directory and makes the package ready.\n5.  **Publish:** Run `npm publish` (you'll need npm authentication configured).\n\nNow, users can run your specific documentation server easily: `npx @my-org/my-docs-mcp@latest`.\n\n*(The previous \"Running\", \"Dynamic Configuration at Runtime\", and \"Environment Variables\" sections have been removed as `npx` usage with arguments within client configurations is now the primary documented method.)*\n\n## Using with AI Assistants\n\nThis MCP server exposes a search tool to connected AI assistants via the Model Context Protocol. The tool's name and description are configurable (see Configuration section). It searches the content within the currently active `data` directory (determined by build settings, config file, CLI args, or environment variables).\n\n**Tool Parameters:**\n\n- `query`: A natural language query or keywords describing what to search for (e.g., \"how to configure the gateway\", \"database connection example\", \"user authentication\"). The server uses Probe's search capabilities to find relevant content. (Required)\n- `page`: The page number for results when dealing with many matches. Defaults to 1 if omitted. (Optional)\n\n**Example Tool Call (using `search_tyk_docs` from Usage Example 1):**\n\n```json\n{\n  \"tool_name\": \"search_tyk_docs\",\n  \"arguments\": {\n    \"query\": \"gateway rate limiting\",\n    \"page\": 1 // Requesting the first page\n  }\n}\n```\n\n**Example Tool Call (using the tool from the `@tyk/docs-mcp` package):**\n\nAssuming the pre-built package `@tyk/docs-mcp` defined its tool name as `search_tyk_official_docs`:\n\n```json\n{\n  \"tool_name\": \"search_tyk_official_docs\",\n  \"arguments\": {\n    \"query\": \"dashboard api access\",\n    \"page\": 2 // Requesting the second page\n  }\n}\n```\n\n*(The previous \"Publishing as an npm Package\" section has been replaced by the \"Creating Your Own Pre-built MCP Server\" section above.)*\n\n## License\n\nMIT",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "documentation",
        "git",
        "probelabs",
        "docs mcp",
        "documentation codebases",
        "probelabs docs"
      ],
      "category": "document-processing"
    },
    "protomated--legal-context": {
      "owner": "protomated",
      "name": "legal-context",
      "url": "https://github.com/protomated/legal-context",
      "imageUrl": "/freedevtools/mcp/pfp/null.webp",
      "description": "Connects a law firm's Clio document management system with Claude Desktop for efficient retrieval and analysis of legal documents while ensuring security and confidentiality. Enables local processing and vector search capabilities to enhance legal research.",
      "stars": 0,
      "forks": 0,
      "license": "Unknown",
      "language": "Unknown",
      "updated_at": "",
      "readme_content": "",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "documents",
        "document",
        "law",
        "legal documents",
        "document management",
        "document processing"
      ],
      "category": "document-processing"
    },
    "puchunjie--doc-tools-mcp": {
      "owner": "puchunjie",
      "name": "doc-tools-mcp",
      "url": "https://github.com/puchunjie/doc-tools-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/puchunjie.webp",
      "description": "Manipulate Word documents using natural language commands for tasks such as creation, editing, and management. The server supports advanced features like table creation, layout control, and metadata management, along with real-time document state monitoring.",
      "stars": 8,
      "forks": 3,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-19T22:50:01Z",
      "readme_content": "# Word Tools MCP Server\n\nA Model Context Protocol (MCP) server that provides AI-powered Word document manipulation capabilities. This server implements the MCP protocol to enable AI applications to create, edit, and manage Word documents through natural language interactions.\n\n[![smithery badge](https://smithery.ai/badge/@puchunjie/doc-tools)](https://smithery.ai/server/@puchunjie/doc-tools)\n\n<a href=\"https://glama.ai/mcp/servers/q9e176vq7l\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/q9e176vq7l/badge\" />\n</a>\n\n## Features\n\n- Full MCP protocol implementation\n- Word document creation and management\n- Rich text content manipulation\n- Table creation and formatting\n- Document layout control\n- Document metadata management\n- Real-time document state monitoring\n\n## Prerequisites\n\n- Node.js 14 or higher\n- Microsoft Word (optional, for advanced features)\n\n## Installation\n\n```bash\nnpx @puchunjie/doc-tools-mcp\n```\n\nOr install globally:\n\n```bash\nnpm install -g @puchunjie/doc-tools-mcp\n```\n\nFor use as a dependency in your project:\n\n```bash\nnpm install @puchunjie/doc-tools-mcp\n```\n\n## Usage\n\n1. Start the MCP server:\n\n```bash\nnpx @puchunjie/doc-tools-mcp\n```\n\n2. The server will start on port 8765 by default\n\n3. Configure your AI application (e.g., Cursor, VSCode) to use the MCP server:\n   ```\n   http://localhost:8765\n   ```\n\n## MCP Tools\n\nThe server provides the following MCP functions:\n\n- `create_document` - Create a new Word document\n  - Parameters: filePath (required), title, author\n\n- `open_document` - Open an existing Word document\n  - Parameters: filePath (required)\n\n- `add_paragraph` - Add a paragraph to the document\n  - Parameters: filePath (required), text (required), style, alignment\n\n- `add_table` - Add a table to the document\n  - Parameters: filePath (required), rows (required), cols (required), headers, data\n\n- `search_and_replace` - Find and replace text in the document\n  - Parameters: filePath (required), searchText (required), replaceText (required), matchCase\n\n- `set_page_margins` - Set document page margins\n  - Parameters: filePath (required), top, right, bottom, left\n\n- `get_document_info` - Get document metadata\n  - Parameters: filePath (required)\n\n## Integration with AI Applications\n\n### Cursor\n\n1. Open the Cursor configuration file `~/.cursor/mcp.json`\n2. Add the following configuration:\n```json\n{\n  \"mcpServers\": {\n    \"doc-tools-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"@puchunjie/doc-tools-mcp\"\n      ]\n    }\n  }\n}\n\n```\n\nOr for local development version:\n```json\n{\n  \"mcpServers\": {\n    \"doc-tools-mcp\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/path/to/your/doc-tools-mcp/dist/mcp-server.js\"\n      ]\n    }\n  }\n}\n```\n\nAfter configuration, you can use natural language to manipulate Word documents:\n```\n\"Create a new document named report.docx\"\n\"Add a heading 'Monthly Report' to report.docx\"\n\"Insert a 4x3 table with sales data\"\n```\n\n### VSCode and Other MCP-Compatible Tools\n\nSimilar integration steps apply to other tools that support the MCP protocol. Consult your tool's documentation for specific MCP server configuration steps.\n\n## Development\n\nTo extend or modify this MCP server:\n\n1. Clone the repository:\n```bash\ngit clone <repository-url>\ncd doc-tools-mcp\n```\n\n2. Install dependencies:\n```bash\nnpm install\n```\n\n3. Start in development mode:\n```bash\nnpm run start\n```\n\n4. Build for production:\n```bash\nnpm run build\n```\n\n### Adding New MCP Functions\n\n1. Add new methods in `src/services/DocumentService.ts`\n2. Register new functions in `src/mcp-server.ts`\n3. Update type definitions as needed\n\n## Configuration\n\n- Default port: 8765 (configurable)\n- Supported file types: .docx\n- All file paths should be absolute or relative to the current working directory\n\n## License\n\nMIT\n\n## Support\n\nIf you encounter any issues or have suggestions for improvements, please submit an issue on our GitHub repository. \n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "document",
        "puchunjie",
        "documents",
        "doc tools",
        "document processing",
        "tools mcp"
      ],
      "category": "document-processing"
    },
    "puremd--puremd-mcp": {
      "owner": "puremd",
      "name": "puremd-mcp",
      "url": "https://github.com/puremd/puremd-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/puremd.webp",
      "description": "Access web content in markdown format by prefixing URLs with `pure.md/`, facilitating seamless retrieval of web pages while avoiding bot detection. It converts various formats like HTML and PDFs into markdown and globally caches responses for efficiency.",
      "stars": 41,
      "forks": 3,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-09-23T01:32:32Z",
      "readme_content": "# pure.md MCP server\n\n[![smithery badge](https://smithery.ai/badge/@puremd/puremd-mcp)](https://smithery.ai/server/@puremd/puremd-mcp)\n\nWelcome to the Model Context Protocol (MCP) server for [pure.md](https://pure.md).\n\n![pure.md - Markdown delivery network for LLMs](https://pure.md/assets/og.png)\n\n[pure.md](https://pure.md) lets your scripts, APIs, apps, agents, etc reliably access web content in markdown format -- simply prefix any URL with `pure.md/`.\nIt avoids bot detection and renders JavaScript for SPAs, and can convert HTML, PDFs, images, and more into pure markdown. Like a CDN for markdown content, it globally caches responses for future requests to the same resource, relieving stress on origin web servers.\n\n**Without puremd-mcp, local agents may fail to fetch web content.** puremd-mcp teaches MCP clients like Cursor, Windsurf, and Claude Desktop how to adopt the functionality of pure.md, giving them web unblocking and searching capabilities.\n\npuremd-mcp comes with two tools:\n\n- `unblock-url` - Extract markdown from web pages without getting blocked\n- `search-web` - Search the web for a query and concatenate results into markdown\n\nThe [Model Context Protocol](https://modelcontextprotocol.io/introduction), developed by Anthropic, is an open standard that enables AI systems to seamlessly interact with an ecosystem of tooling. With it, MCP clients like Cursor, Windsurf, and Claude Desktop can learn how to use a variety of APIs and other functionality.\n\n## Authentication\n\nGenerating an API key is an optional step that unlocks higher rate limits. If you'd like to use the pure.md MCP server anonymously, simply set your `PUREMD_API_KEY` value to empty string (`\"\"`).\n\n1. Sign up for a new account at [pure.md](https://pure.md) &mdash; it's free to sign up!\n2. In the dashboard, generate a new API token\n3. Copy the token, and use it for the `PUREMD_API_KEY` value in your MCP client's configuration file (see below)\n\n## Client configuration\n\n### Cursor\n\nAdd the following to your `~/.cursor/mcp.json` file:\n\n```json\n{\n  \"mcpServers\": {\n    \"pure.md\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"puremd-mcp\"],\n      \"env\": {\n        \"PUREMD_API_KEY\": \"<TOKEN>\"\n      }\n    }\n  }\n}\n```\n\n### Windsurf\n\nAdd the following to your `./codeium/windsurf/model_config.json` file:\n\n```json\n{\n  \"mcpServers\": {\n    \"pure.md\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"puremd-mcp\"],\n      \"env\": {\n        \"PUREMD_API_KEY\": \"<TOKEN>\"\n      }\n    }\n  }\n}\n```\n\n### Claude Desktop\n\nAdd the following to your `~/Library/Application\\ Support/Claude/claude_desktop_config.json` file:\n\n```json\n{\n  \"mcpServers\": {\n    \"pure.md\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"puremd-mcp\"],\n      \"env\": {\n        \"PUREMD_API_KEY\": \"<TOKEN>\"\n      }\n    }\n  }\n}\n```\n\n### Installing via Smithery\n\nTo install puremd-mcp for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@puremd/puremd-mcp):\n\n```bash\nnpx -y @smithery/cli install @puremd/puremd-mcp --client claude\n```\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "puremd",
        "markdown",
        "formats",
        "processing puremd",
        "puremd puremd",
        "puremd mcp"
      ],
      "category": "document-processing"
    },
    "qing-turnaround--markitdown_mcp_server": {
      "owner": "qing-turnaround",
      "name": "markitdown_mcp_server",
      "url": "https://github.com/qing-turnaround/markitdown_mcp_server",
      "imageUrl": "/freedevtools/mcp/pfp/qing-turnaround.webp",
      "description": "Convert various file formats to Markdown using the MarkItDown utility. Process PDFs, Office documents, images, audio files, HTML, and more into a Markdown format for streamlined content handling.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "",
      "updated_at": "2025-04-24T07:56:26Z",
      "readme_content": "# MarkItDown MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@KorigamiK/markitdown_mcp_server)](https://smithery.ai/server/@KorigamiK/markitdown_mcp_server)\n\nA Model Context Protocol (MCP) server that converts various file formats to Markdown using the MarkItDown utility.\n\n<a href=\"https://glama.ai/mcp/servers/sbc6bljjg5\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/sbc6bljjg5/badge\" alt=\"MarkItDown Server MCP server\" /></a>\n\n## Supported Formats\n\n- PDF\n- PowerPoint\n- Word\n- Excel\n- Images (EXIF metadata and OCR)\n- Audio (EXIF metadata and speech transcription)\n- HTML\n- Text-based formats (CSV, JSON, XML)\n- ZIP files (iterates over contents)\n\n## Installation\n\n### Installing via Smithery\n\nTo install MarkItDown MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@KorigamiK/markitdown_mcp_server):\n\n```bash\nnpx -y @smithery/cli install @KorigamiK/markitdown_mcp_server --client claude\n```\n\n### Manual Installation\n\n1. Clone this repository\n2. Install dependencies:\n```bash\nuv install\n```\n\n## Usage\n\n### As MCP Server\n\nThe server can be integrated with any MCP client. Here are some examples:\n\n#### Zed Editor\n\nAdd the following to your `settings.json`:\n\n```json\n\"context_servers\": {\n  \"markitdown_mcp\": {\n    \"settings\": {},\n    \"command\": {\n      \"path\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/path/to/markitdown_mcp_server\",\n        \"run\",\n        \"markitdown\"\n      ]\n    }\n  }\n}\n```\n\n### Commands\n\nThe server responds to the following MCP commands:\n\n- `/md <file>` - Convert the specified file to Markdown\n\nExample:\n```bash\n/md document.pdf\n```\n\n## Supported MCP Clients\n\nWorks with any MCP-compliant client listed at [modelcontextprotocol.io/clients](https://modelcontextprotocol.io/clients), including:\n\n- Zed Editor\n- Any other MCP-compatible editors and tools\n\n## License\n\nMIT License. See [LICENSE](LICENSE) for details.\n\n## Acknowledgements\n\nhttps://github.com/microsoft/markitdown#readme\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "markitdown",
        "markdown",
        "markitdown_mcp_server",
        "formats markdown",
        "markitdown utility",
        "markdown format"
      ],
      "category": "document-processing"
    },
    "qiniu--qiniu-mcp-server": {
      "owner": "qiniu",
      "name": "qiniu-mcp-server",
      "url": "https://github.com/qiniu/qiniu-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/qiniu.webp",
      "description": "Connect to Qiniu Cloud Storage for accessing, managing, and processing multimedia files within AI large model clients. Perform operations such as listing buckets, uploading files, reading file contents, and utilizing intelligent multimedia features.",
      "stars": 28,
      "forks": 13,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-25T15:54:39Z",
      "readme_content": "# Qiniu MCP Server\n\n## 概述\n\n基于七牛云产品构建的 Model Context Protocol (MCP) Server，支持用户在 AI 大模型客户端的上下文中通过该 MCP\nServer 来访问七牛云存储、智能多媒体服务等。\n\n关于访问七牛云存储详细情况请参考 [基于 MCP 使用大模型访问七牛云存储](https://developer.qiniu.com/kodo/12914/mcp-aimodel-kodo)。\n\n能力集：\n- 存储\n  - 获取 Bucket 列表\n  - 获取 Bucket 中的文件列表\n  - 上传本地文件，以及给出文件内容进行上传\n  - 读取文件内容\n  - 获取文件下载链接\n- 智能多媒体\n  - 图片缩放\n  - 图片切圆角\n- CDN\n  - 根据链接刷新文件\n  - 根据链接预取文件\n\n## 环境要求\n\n- Python 3.12 或更高版本\n- uv 包管理器\n\n如果还没有安装 uv，可以使用以下命令安装：\n```bash\n# Mac，推荐使用 brew 安装\nbrew install uv\n\n\n# Linux & Mac\n# 1. 安装\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n# 2. 安装完成后，请确保将软件包安装路径（包含 uv 和 uvx 可执行文件的目录）添加到系统的 PATH 环境变量中。\n# 假设安装包路径为 /Users/xxx/.local/bin（见安装执行输出）\n### 临时生效（当前会话），在当前终端中执行以下命令：\nexport PATH=\"/Users/xxx/.local/bin:$PATH\"\n### 永久生效（推荐），在当前终端中执行以下命令：\necho 'export PATH=\"/Users/xxx/.local/bin:$PATH\"' >> ~/.bash_profile\nsource ~/.bash_profile\n\n\n# Windows\npowershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n```\n\n具体安装方式参考 [uv 安装](https://docs.astral.sh/uv/getting-started/installation/#pypi)\n\n## 在 Cline 中使用：\n\n步骤：\n\n1. 在 vscode 下载 Cline 插件（下载后 Cline 插件后在侧边栏会增加 Cline 的图标）\n2. 配置大模型\n3. 配置 qiniu MCP\n    1. 点击 Cline 图标进入 Cline 插件，选择 MCP Server 模块\n    2. 选择 installed，点击 Advanced MCP Settings 配置 MCP Server，参考下面配置信息\n   ```\n   {\n     \"mcpServers\": {\n       \"qiniu\": {\n         \"command\": \"uvx\",\n         \"args\": [\n           \"qiniu-mcp-server\"\n         ],\n         \"env\": {\n           \"QINIU_ACCESS_KEY\": \"YOUR_ACCESS_KEY\",\n           \"QINIU_SECRET_KEY\": \"YOUR_SECRET_KEY\",\n           \"QINIU_REGION_NAME\": \"YOUR_REGION_NAME\",\n           \"QINIU_ENDPOINT_URL\": \"YOUR_ENDPOINT_URL\",\n           \"QINIU_BUCKETS\": \"YOUR_BUCKET_A,YOUR_BUCKET_B\"\n        },\n         \"disabled\": false\n       }\n     }\n   }\n   ```\n    3. 点击 qiniu MCP Server 的链接开关进行连接\n4. 在 Cline 中创建一个聊天窗口，此时我们可以和 AI 进行交互来使用 qiniu-mcp-server ，下面给出几个示例：\n    - 列举 qiniu 的资源信息\n    - 列举 qiniu 中所有的 Bucket\n    - 列举 qiniu 中 xxx Bucket 的文件\n    - 读取 qiniu xxx Bucket 中 yyy 的文件内容\n    - 对 qiniu xxx Bucket 中 yyy 的图片切个宽200像素的圆角\n    - 刷新下 qiniu 的这个 CDN 链接：https://developer.qiniu.com/test.txt\n\n注：\ncursor 中创建 MCP Server 可直接使用上述配置。\nclaude 中使用时可能会遇到：Error: spawn uvx ENOENT 错误，解决方案：command 中 参数填写 uvx 的绝对路径，eg: /usr/local/bin/uvx\n\n## 开发\n1. 克隆仓库：\n\n```bash\n# 克隆项目并进入目录\ngit clone git@github.com:qiniu/qiniu-mcp-server.git\ncd qiniu-mcp-server\n```\n\n2. 创建并激活虚拟环境：\n\n```bash\nuv venv\nsource .venv/bin/activate  # Linux/macOS\n# 或\n.venv\\Scripts\\activate  # Windows\n```\n\n3. 安装依赖：\n\n```bash\nuv pip install -e .\n```\n\n4. 配置\n\n复制环境变量模板：\n```bash\ncp .env.example .env\n```\n\n编辑 `.env` 文件，配置以下参数：\n```bash\n# S3/Kodo 认证信息\nQINIU_ACCESS_KEY=your_access_key\nQINIU_SECRET_KEY=your_secret_key\n\n# 区域信息\nQINIU_REGION_NAME=your_region\nQINIU_ENDPOINT_URL=endpoint_url # eg:https://s3.your_region.qiniucs.com\n\n# 配置 bucket，多个 bucket 使用逗号隔开，建议最多配置 20 个 bucket\nQINIU_BUCKETS=bucket1,bucket2,bucket3\n```\n\n扩展功能，首先在 core 目录下新增一个业务包目录（eg: 存储 -> storage），在此业务包目录下完成功能拓展。\n在业务包目录下的 `__init__.py` 文件中定义 load 函数用于注册业务工具或者资源，最后在 `core` 目录下的 `__init__.py`\n中调用此 load 函数完成工具或资源的注册。\n\n```shell\ncore\n├── __init__.py # 各个业务工具或者资源加载\n└── storage # 存储业务目录\n    ├── __init__.py # 加载存储工具或者资源\n    ├── resource.py # 存储资源扩展\n    ├── storage.py # 存储工具类\n    └── tools.py # 存储工具扩展\n```\n\n## 测试\n\n### 使用 Model Control Protocol Inspector 测试\n\n强烈推荐使用 [Model Control Protocol Inspector](https://github.com/modelcontextprotocol/inspector) 进行测试。\n\n```shell\n# node 版本为：v22.4.0\nnpx @modelcontextprotocol/inspector uv --directory . run qiniu-mcp-server\n```\n\n### 本地启动 MCP Server 示例\n\n1. 使用标准输入输出（stdio）模式启动（默认）：\n\n```bash\nuv --directory . run qiniu-mcp-server\n```\n\n2. 使用 SSE 模式启动（用于 Web 应用）：\n\n```bash\nuv --directory . run qiniu-mcp-server --transport sse --port 8000\n```\n\n\n\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "qiniu",
        "cloud",
        "uploading",
        "qiniu cloud",
        "processing qiniu",
        "qiniu mcp"
      ],
      "category": "document-processing"
    },
    "qpd-v--mcp-ragdocs": {
      "owner": "qpd-v",
      "name": "mcp-ragdocs",
      "url": "https://github.com/qpd-v/mcp-ragdocs",
      "imageUrl": "/freedevtools/mcp/pfp/qpd-v.webp",
      "description": "Fetches and stores documentation in a vector database for semantic search and retrieval, enhancing LLM capabilities with relevant documentation context. Supports adding documentation from URLs or local files and querying with natural language.",
      "stars": 124,
      "forks": 63,
      "license": "Apache License 2.0",
      "language": "JavaScript",
      "updated_at": "2025-10-03T17:26:40Z",
      "readme_content": "# MCP-Ragdocs\n\nA Model Context Protocol (MCP) server that enables semantic search and retrieval of documentation using a vector database (Qdrant). This server allows you to add documentation from URLs or local files and then search through them using natural language queries.\n\n## Quick Install Guide\n\n1. Install the package globally:\n   ```bash\n   npm install -g @qpd-v/mcp-server-ragdocs\n   ```\n\n2. Start Qdrant (using Docker):\n   ```bash\n   docker run -p 6333:6333 -p 6334:6334 qdrant/qdrant\n   ```\n\n3. Ensure Ollama is running with the default embedding model:\n   ```bash\n   ollama pull nomic-embed-text\n   ```\n\n4. Add to your configuration file:\n   - For Cline: `%AppData%\\Roaming\\Code\\User\\globalStorage\\saoudrizwan.claude-dev\\settings\\cline_mcp_settings.json`\n   - For Roo-Code: `%AppData%\\Roaming\\Code\\User\\globalStorage\\rooveterinaryinc.roo-cline\\settings\\cline_mcp_settings.json`\n   - For Claude Desktop: `%AppData%\\Claude\\claude_desktop_config.json`\n\n   ```json\n   {\n     \"mcpServers\": {\n       \"ragdocs\": {\n         \"command\": \"node\",\n         \"args\": [\"C:/Users/YOUR_USERNAME/AppData/Roaming/npm/node_modules/@qpd-v/mcp-server-ragdocs/build/index.js\"],\n         \"env\": {\n           \"QDRANT_URL\": \"http://127.0.0.1:6333\",\n           \"EMBEDDING_PROVIDER\": \"ollama\",\n           \"OLLAMA_URL\": \"http://localhost:11434\"\n         }\n       }\n     }\n   }\n   ```\n\n5. Verify installation:\n   ```bash\n   # Check Qdrant is running\n   curl http://localhost:6333/collections\n   \n   # Check Ollama has the model\n   ollama list | grep nomic-embed-text\n   ```\n\n## Version\n\nCurrent version: 0.1.6\n\n## Features\n\n- Add documentation from URLs or local files\n- Store documentation in a vector database for semantic search\n- Search through documentation using natural language\n- List all documentation sources\n\n## Installation\n\nInstall globally using npm:\n\n```bash\nnpm install -g @qpd-v/mcp-server-ragdocs\n```\n\nThis will install the server in your global npm directory, which you'll need for the configuration steps below.\n\n## Requirements\n\n- Node.js 16 or higher\n- Qdrant (either local or cloud)\n- One of the following for embeddings:\n  - Ollama running locally (default, free)\n  - OpenAI API key (optional, paid)\n\n## Qdrant Setup Options\n\n### Option 1: Local Qdrant\n\n1. Using Docker (recommended):\n```bash\ndocker run -p 6333:6333 -p 6334:6334 qdrant/qdrant\n```\n\n2. Or download from [Qdrant's website](https://qdrant.tech/documentation/quick-start/)\n\n### Option 2: Qdrant Cloud\n\n1. Create an account at [Qdrant Cloud](https://cloud.qdrant.io/)\n2. Create a new cluster\n3. Get your cluster URL and API key from the dashboard\n4. Use these in your configuration (see Configuration section below)\n\n## Configuration\n\nThe server can be used with both Cline/Roo and Claude Desktop. Configuration differs slightly between them:\n\n### Cline Configuration\n\nAdd to your Cline settings file (`%AppData%\\Roaming\\Code\\User\\globalStorage\\saoudrizwan.claude-dev\\settings\\cline_mcp_settings.json`)\nAND/OR\nAdd to your Roo-Code settings file (`%AppData%\\Roaming\\Code\\User\\globalStorage\\rooveterinaryinc.roo-cline\\settings\\cline_mcp_settings.json`):\n\n1. Using npm global install (recommended):\n```json\n{\n\t\t\"mcpServers\": {\n\t\t\t\t\"ragdocs\": {\n\t\t\t\t\t\t\"command\": \"node\",\n      \"args\": [\"C:/Users/YOUR_USERNAME/AppData/Roaming/npm/node_modules/@qpd-v/mcp-server-ragdocs/build/index.js\"],\n      \"env\": {\n        \"QDRANT_URL\": \"http://127.0.0.1:6333\",\n        \"EMBEDDING_PROVIDER\": \"ollama\",\n        \"OLLAMA_URL\": \"http://localhost:11434\"\n      }\n    }\n  }\n}\n```\n\nFor OpenAI instead of Ollama:\n```json\n{\n\t\t\"mcpServers\": {\n\t\t\t\t\"ragdocs\": {\n\t\t\t\t\t\t\"command\": \"node\",\n      \"args\": [\"C:/Users/YOUR_USERNAME/AppData/Roaming/npm/node_modules/@qpd-v/mcp-server-ragdocs/build/index.js\"],\n      \"env\": {\n        \"QDRANT_URL\": \"http://127.0.0.1:6333\",\n        \"EMBEDDING_PROVIDER\": \"openai\",\n        \"OPENAI_API_KEY\": \"your-openai-api-key\"\n      }\n    }\n  }\n}\n```\n\n2. Using local development setup:\n```json\n{\n\t\t\"mcpServers\": {\n\t\t\t\t\"ragdocs\": {\n\t\t\t\t\t\t\"command\": \"node\",\n\t\t\t\t\t\t\"args\": [\"PATH_TO_PROJECT/mcp-ragdocs/build/index.js\"],\n\t\t\t\t\t\t\"env\": {\n\t\t\t\t\t\t\t\t\"QDRANT_URL\": \"http://127.0.0.1:6333\",\n\t\t\t\t\t\t\t\t\"EMBEDDING_PROVIDER\": \"ollama\",\n\t\t\t\t\t\t\t\t\"OLLAMA_URL\": \"http://localhost:11434\"\n\t\t\t\t\t\t}\n\t\t\t\t}\n\t\t}\n}\n```\n\n### Claude Desktop Configuration\n\nAdd to your Claude Desktop config file:\n- Windows: `%AppData%\\Claude\\claude_desktop_config.json`\n- macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n\n1. Windows Setup with Ollama (using full paths):\n```json\n{\n  \"mcpServers\": {\n    \"ragdocs\": {\n      \"command\": \"C:\\\\Program Files\\\\nodejs\\\\node.exe\",\n      \"args\": [\n        \"C:\\\\Users\\\\YOUR_USERNAME\\\\AppData\\\\Roaming\\\\npm\\\\node_modules\\\\@qpd-v/mcp-server-ragdocs\\\\build\\\\index.js\"\n      ],\n      \"env\": {\n\t\t\t\t\t\t\t\t\"QDRANT_URL\": \"http://127.0.0.1:6333\",\n\t\t\t\t\t\t\t\t\"EMBEDDING_PROVIDER\": \"ollama\",\n\t\t\t\t\t\t\t\t\"OLLAMA_URL\": \"http://localhost:11434\"\n\t\t\t\t\t\t}\n\t\t\t\t}\n\t\t}\n}\n```\n\nWindows Setup with OpenAI:\n```json\n{\n\t\t\"mcpServers\": {\n\t\t\t\t\"ragdocs\": {\n\t\t\t\t\t\t\"command\": \"C:\\\\Program Files\\\\nodejs\\\\node.exe\",\n\t\t\t\t\t\t\"args\": [\n\t\t\t\t\t\t\t\t\"C:\\\\Users\\\\YOUR_USERNAME\\\\AppData\\\\Roaming\\\\npm\\\\node_modules\\\\@qpd-v/mcp-server-ragdocs\\\\build\\\\index.js\"\n\t\t\t\t\t\t],\n\t\t\t\t\t\t\"env\": {\n\t\t\t\t\t\t\t\t\"QDRANT_URL\": \"http://127.0.0.1:6333\",\n\t\t\t\t\t\t\t\t\"EMBEDDING_PROVIDER\": \"openai\",\n\t\t\t\t\t\t\t\t\"OPENAI_API_KEY\": \"your-openai-api-key\"\n\t\t\t\t\t\t}\n\t\t\t\t}\n\t\t}\n}\n```\n\n2. macOS Setup with Ollama:\n```json\n{\n\t\t\"mcpServers\": {\n\t\t\t\t\"ragdocs\": {\n\t\t\t\t\t\t\"command\": \"/usr/local/bin/node\",\n\t\t\t\t\t\t\"args\": [\n\t\t\t\t\t\t\t\t\"/usr/local/lib/node_modules/@qpd-v/mcp-server-ragdocs/build/index.js\"\n\t\t\t\t\t\t],\n\t\t\t\t\t\t\"env\": {\n\t\t\t\t\t\t\t\t\"QDRANT_URL\": \"http://127.0.0.1:6333\",\n\t\t\t\t\t\t\t\t\"EMBEDDING_PROVIDER\": \"ollama\",\n\t\t\t\t\t\t\t\t\"OLLAMA_URL\": \"http://localhost:11434\"\n\t\t\t\t\t\t}\n\t\t\t\t}\n\t\t}\n}\n```\n\n### Qdrant Cloud Configuration\n\nFor either Cline or Claude Desktop, when using Qdrant Cloud, modify the env section:\n\nWith Ollama:\n```json\n{\n\t\t\"env\": {\n\t\t\t\t\"QDRANT_URL\": \"https://your-cluster-url.qdrant.tech\",\n\t\t\t\t\"QDRANT_API_KEY\": \"your-qdrant-api-key\",\n\t\t\t\t\"EMBEDDING_PROVIDER\": \"ollama\",\n\t\t\t\t\"OLLAMA_URL\": \"http://localhost:11434\"\n\t\t}\n}\n```\n\nWith OpenAI:\n```json\n{\n\t\t\"env\": {\n\t\t\t\t\"QDRANT_URL\": \"https://your-cluster-url.qdrant.tech\",\n\t\t\t\t\"QDRANT_API_KEY\": \"your-qdrant-api-key\",\n\t\t\t\t\"EMBEDDING_PROVIDER\": \"openai\",\n\t\t\t\t\"OPENAI_API_KEY\": \"your-openai-api-key\"\n\t\t}\n}\n```\n\n### Environment Variables\n\n#### Qdrant Configuration\n- `QDRANT_URL` (required): URL of your Qdrant instance\n  - For local: http://localhost:6333\n  - For cloud: https://your-cluster-url.qdrant.tech\n- `QDRANT_API_KEY` (required for cloud): Your Qdrant Cloud API key\n\n#### Embeddings Configuration\n- `EMBEDDING_PROVIDER` (optional): Choose between 'ollama' (default) or 'openai'\n- `EMBEDDING_MODEL` (optional):\n  - For Ollama: defaults to 'nomic-embed-text'\n  - For OpenAI: defaults to 'text-embedding-3-small'\n- `OLLAMA_URL` (optional): URL of your Ollama instance (defaults to http://localhost:11434)\n- `OPENAI_API_KEY` (required if using OpenAI): Your OpenAI API key\n\n## Available Tools\n\n1. `add_documentation`\n   - Add documentation from a URL to the RAG database\n   - Parameters:\n     - `url`: URL of the documentation to fetch\n\n2. `search_documentation`\n   - Search through stored documentation\n   - Parameters:\n     - `query`: Search query\n     - `limit` (optional): Maximum number of results to return (default: 5)\n\n3. `list_sources`\n   - List all documentation sources currently stored\n   - No parameters required\n\n## Example Usage\n\nIn Claude Desktop or any other MCP-compatible client:\n\n1. Add documentation:\n```\nAdd this documentation: https://docs.example.com/api\n```\n\n2. Search documentation:\n```\nSearch the documentation for information about authentication\n```\n\n3. List sources:\n```\nWhat documentation sources are available?\n```\n\n## Development\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/qpd-v/mcp-server-ragdocs.git\ncd mcp-server-ragdocs\n```\n\n2. Install dependencies:\n```bash\nnpm install\n```\n\n3. Build the project:\n```bash\nnpm run build\n```\n\n4. Run locally:\n```bash\nnpm start\n```\n\n## License\n\nMIT\n\n## Troubleshooting\n\n### Common Issues\n\n1. **Qdrant Connection Error**\n   ```\n   Error: Failed to connect to Qdrant at http://localhost:6333\n   ```\n   - Check if Docker is running\n   - Verify Qdrant container is running: `docker ps | grep qdrant`\n   - Try restarting the container\n\n2. **Ollama Model Missing**\n   ```\n   Error: Model nomic-embed-text not found\n   ```\n   - Run: `ollama pull nomic-embed-text`\n   - Verify model is installed: `ollama list`\n\n3. **Configuration Path Issues**\n   - Windows: Replace `YOUR_USERNAME` with your actual Windows username\n   - Check file permissions\n   - Verify the paths exist\n\n4. **npm Global Install Issues**\n   - Try installing with admin privileges\n   - Check npm is in PATH: `npm -v`\n   - Verify global installation: `npm list -g @qpd-v/mcp-server-ragdocs`\n\nFor other issues, please check:\n- Docker logs: `docker logs $(docker ps -q --filter ancestor=qdrant/qdrant)`\n- Ollama status: `ollama list`\n- Node.js version: `node -v` (should be 16 or higher)\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "documentation",
        "document",
        "qpd",
        "stores documentation",
        "semantic search",
        "documentation vector"
      ],
      "category": "document-processing"
    },
    "qpd-v--mcp-wordcounter": {
      "owner": "qpd-v",
      "name": "mcp-wordcounter",
      "url": "https://github.com/qpd-v/mcp-wordcounter",
      "imageUrl": "/freedevtools/mcp/pfp/qpd-v.webp",
      "description": "Analyzes text documents by providing word and character counting capabilities. It processes files directly without exposing content to language models, offering statistics on total words, characters including spaces, and characters excluding spaces.",
      "stars": 10,
      "forks": 6,
      "license": "Apache License 2.0",
      "language": "JavaScript",
      "updated_at": "2025-07-28T02:45:59Z",
      "readme_content": "# MCP Word Counter\n\nA Model Context Protocol server that provides tools for analyzing text documents, including counting words and characters. This server helps LLMs perform text analysis tasks by exposing simple document statistics functionality.\n\n## Features\n\n- Count words in documents\n- Count total characters (including spaces)\n- Count characters excluding spaces\n- Process files directly without exposing content to LLMs\n\n## Installation\n\n```bash\nnpm install mcp-wordcounter\n```\n\n## Usage\n\n### As a CLI tool\n\n```bash\nnpx mcp-wordcounter\n```\n\n### In Claude Desktop\n\nAdd to your Claude Desktop configuration (`claude_desktop_config.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-wordcounter\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"mcp-wordcounter\"],\n      \"alwaysAllow\": [\"analyze_text\"]\n    }\n  }\n}\n```\n\n### Available Tools\n\n#### analyze_text\n\nCounts words and characters in a text document.\n\nParameters:\n- `filePath` (string, required): Path to the text file to analyze\n\nReturns:\n- Word count\n- Character count (including spaces)\n- Character count (excluding spaces)\n\nExample response:\n```json\n{\n  \"content\": [{\n    \"type\": \"text\",\n    \"text\": \"Analysis Results:\\n• Word count: 150\\n• Character count (including spaces): 842\\n• Character count (excluding spaces): 702\"\n  }]\n}\n```\n\n## Development\n\n```bash\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n\n# Run in watch mode during development\nnpm run watch\n\n# Test with MCP Inspector\nnpm run inspector\n```\n\n## License\n\nMIT License - see LICENSE file for details.\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "wordcounter",
        "qpd",
        "document",
        "wordcounter analyzes",
        "mcp wordcounter",
        "document processing"
      ],
      "category": "document-processing"
    },
    "quillopy--quillopy-mcp": {
      "owner": "quillopy",
      "name": "quillopy-mcp",
      "url": "https://github.com/quillopy/quillopy-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/quillopy.webp",
      "description": "Retrieve relevant package documentation for programming languages and libraries through the Quillopy API, enhancing the coding experience by providing up-to-date information directly into the user's context.",
      "stars": 119,
      "forks": 5,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-09-18T11:05:49Z",
      "readme_content": "<h3 align=\"center\">\n  <a href=\"https://quillopy.com\">🏠 Home page</a>\n  <a href=\"https://discord.gg/HuyzbYRzwu\">💬 Discord</a>\n  <a href=\"https://quillopy.com/documentation/all\">📚 Check docs</a>\n  <a href=\"https://quillopy.com/add\">➕ Add docs</a>\n</h4>\n\n# Quillopy MCP — Real Docs. Real Code. Zero Hallucination.\n\n<div align=\"center\">\n\n</div>\n\n## 🧠 Your LLM is smart. But it can’t see the latest docs.\n\n### ❌ Without Quillopy:\n\n- You get code that references functions that were deprecated two years ago\n- You spend time debugging things that were never supposed to work\n- Answers are vague, outdated, or flat-out wrong\n\n### ✅ With Quillopy:\n\nQuillopy pipes accurate documentation directly into your code assistant’s context — so it generates **real**, **working**, **up-to-date** code.\n\nNo manual uploads. No stale info. No wasted time.\n\n---\n\n### How it works:\n\n1. Ask your question in Cursor (or any assistant that supports the MCPs)\n2. Behind the scenes, Quillopy injects the right docs — automatically\n3. You get a code completion that actually runs\n\nTo explicitly activate Quillopy, just add `@quillopy` to your question — or use `@quillopy[package_name]` to specify exactly what library to pull in.\n\nNo hacks. No guessing. Just code that *works*.\n\n---\n\n### Try it with questions like:\n\n> “How to code an agent browsing the web to fetch the latest news using browser-use? @quillopy[browser-use]”\\\n> “How do I store and retrieve JSON data in Supabase? @quillopy”\\\n> “How do I secure routes with the newest NextAuth? @quillopy”\n\n---\n\n### Why devs are switching to Quillopy:\n\n✅ Zero setup — no uploads or config\\\n✅ 600+ libraries pre-indexed and updated in real time\\\n✅ Optimized for minimal context usage (perfect for LLMs)\\\n✅ Works with any library, any version, anytime\n\n\n## 🛠️ Getting Started\n\n### 1. Create an API key\n\n**Important:** You need a Quillopy API key to use this MCP server. Visit https://quillopy.com to sign up and obtain your API key (free).\n\n### 2. Install the Quillopy MCP\n\n#### Option 1: Use Smithery (Recommended)\n\nSmithery provides the easiest way to install and configure the Quillopy MCP across various AI assistant platforms.\n\n```\n# Claude\nnpx -y @smithery/cli@latest install @quillopy/quillopy-mcp --client claude\n\n# Cursor\nnpx -y @smithery/cli@latest install @quillopy/quillopy-mcp --client cursor\n\n# Windsurf\nnpx -y @smithery/cli@latest install @quillopy/quillopy-mcp --client windsurf\n```\n\nFor more information and additional integration options, visit https://smithery.ai/server/@quillopy/quillopy-mcp\n\n#### Option 2: Manual Setup\n\n##### Cursor\n\n1. Navigate to `Settings` -> `Cursor Settings` -> `MCP` -> `+ Add new global MCP server`\n2. Copy paste the following config in `~/.cursor/.mcp.json`\n   ```json\n   {\n     \"mcpServers\": {\n       \"quillopy\": {\n         \"command\": \"npx\",\n         \"args\": [\"-y\", \"@quillopy/mcp\"],\n         \"env\": {\n           \"QUILLOPY_API_KEY\": \"<your-api-key>\"\n         }\n       }\n     }\n   }\n   ```\n3. Replace `<your-api-key>` with your actual API key\n\nCheck the [Cursor MCP docs](https://docs.cursor.com/context/model-context-protocol) for more infos.\n\n##### Windsurf\nAdd this to your Windsurf MCP config file. Check the [Windsurf MCP docs](https://docs.windsurf.com/windsurf/mcp) for more infos.\n ```json\n {\n   \"mcpServers\": {\n     \"quillopy\": {\n       \"command\": \"npx\",\n       \"args\": [\"-y\", \"@quillopy/mcp\"],\n       \"env\": {\n         \"QUILLOPY_API_KEY\": \"<your-api-key>\"\n       }\n     }\n   }\n }\n ```\n\n##### Claude Desktop\n\nAdd this to your `claude_desktop_config.json`.\n\n```json\n{\n  \"mcpServers\": {\n    \"quillopy\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@quillopy/mcp\"],\n      \"env\": {\n        \"QUILLOPY_API_KEY\": \"<your-api-key>\"\n      }\n    }\n  }\n}\n```\n\n##### Continue.dev\n\n1. Open your Continue.dev configuration file in either format:\n\n   - YAML:\n     - MacOS/Linux: `~/.continue/config.yaml`\n     - Windows: `%USERPROFILE%\\.continue\\config.yaml`\n   - JSON:\n     - Same location as above, but named `config.json`\n\n2. Add the configuration using either format:\n\n   YAML format:\n\n   ```yaml\n   experimental:\n     modelContextProtocolServers:\n       - transport:\n           type: stdio\n           command: node\n           args: [\"-y\", \"@quillopy/mcp\"]\n           env: { \"QUILLOPY_API_KEY\": \"<your-api-key>\" }\n   ```\n\n   JSON format:\n\n   ```json\n   {\n     \"experimental\": {\n       \"modelContextProtocolServers\": [\n         {\n           \"transport\": {\n             \"type\": \"stdio\",\n             \"command\": \"npx\",\n             \"args\": [\"-y\", \"@quillopy/mcp\"],\n             \"env\": { \"QUILLOPY_API_KEY\": \"<your-api-key>\" }\n           }\n         }\n       ]\n     }\n   }\n   ```\n\n3. Save the file - Continue will automatically refresh to apply the new configuration. If the changes don't take effect immediately, try restarting your IDE.\n\nCheck [Continue MCP docs](https://docs.continue.dev/customize/deep-dives/mcp) for more infos.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "quillopy",
        "documentation",
        "libraries",
        "libraries quillopy",
        "quillopy api",
        "quillopy mcp"
      ],
      "category": "document-processing"
    },
    "r-huijts--opentk-mcp": {
      "owner": "r-huijts",
      "name": "opentk-mcp",
      "url": "https://github.com/r-huijts/opentk-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/r-huijts.webp",
      "description": "Provides access to Dutch parliamentary documents, debates, and member information through a standardized interface for natural language queries, facilitating research and analysis of legislative activities.",
      "stars": 15,
      "forks": 2,
      "license": "MIT License",
      "language": "HTML",
      "updated_at": "2025-09-24T07:23:36Z",
      "readme_content": "# OpenTK Model Context Protocol Server\n\n> **Important Attribution**: This MCP server is built as a wrapper around the excellent [OpenTK project](https://berthub.eu/tkconv/) created by [Bert Hubert](https://berthub.eu/). The OpenTK project provides unprecedented access to Dutch parliamentary data through a user-friendly interface. Learn more about the project in Bert's article: [Welkom bij OpenTK](https://berthub.eu/articles/posts/welkom-bij-opentk/). All credit for the underlying data access and processing goes to Bert Hubert and his contributions to open government data.\n\nA bridge between large language models (LLMs) and Dutch parliamentary data through a standardized interface. This MCP server provides access to Dutch parliamentary documents, debates, and member information from the Tweede Kamer.\n\n<a href=\"https://glama.ai/mcp/servers/@r-huijts/opentk-mcp\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@r-huijts/opentk-mcp/badge\" alt=\"OpenTK Model Context Protocol Server MCP server\" />\n</a>\n\n## Real-World Natural Language Interaction Examples\n\n## Example 1: Comparing Party Positions on AI Policies\nUser Query: \"When comparing the activities of opposition parties PvdA, GroenLinks, and Volt with government party BBB in the Dutch House of Representatives in the field of AI, what are actions they can undertake together in the short term that align with the positions and views they have demonstrated over the past year? Please use sources from OpenTK.\"\n\n## Example 2: Researching Parliamentary Discussions on Climate Policy\nUser Query: \"I'd like to analyze recent parliamentary debates on climate policy and emission reduction targets in the Netherlands. Can you help me identify key discussions and the main positions taken by different parties over the past six months?\"\n\n## Example 3: Information About a Specific MP's Voting Record\nUser Query: \"What is MP Pieter Omtzigt's voting record on healthcare reform legislation, and how does his position differ from other independent members? Has he introduced any motions on this topic?\"\n\n## Example 4: Finding Recent Housing Legislation Developments\nUser Query: \"What are the most significant parliamentary documents and debates about affordable housing legislation from the past year? I'm particularly interested in proposals addressing the rental market crisis.\"\n\n## Example 5: Finding MPs with Specific Committee Memberships\nUser Query: \"Which MPs currently serve on both the Finance Committee and the Economic Affairs Committee? What parties do they represent, and have they recently submitted any joint initiatives?\"\n\n## Example 6: Identifying Upcoming Parliamentary Activities on Digital Security\nUser Query: \"Are there any scheduled committee meetings or debates about cybersecurity and digital infrastructure planned for the next month? Which ministers will be participating and what specific topics will be addressed?\"\n\n## Project Concept\n\nThe OpenTK project is a Model Context Protocol (MCP) server that provides access to Dutch parliamentary data through a standardized interface. It serves as a bridge between large language models (LLMs) and the Dutch Parliament's information systems, allowing AI assistants to search, retrieve, and analyze parliamentary documents, debates, and member information.\n\nThe server uses the `@modelcontextprotocol/sdk` to implement the MCP specification, which enables structured communication between AI models and external data sources. By exposing parliamentary data through well-defined tools and endpoints, OpenTK makes it possible for AI assistants to:\n\n1. Search for parliamentary documents using complex queries\n2. Access information about Members of Parliament\n3. Retrieve official documents in various formats and read the full content of the documents\n4. Analyze parliamentary activities and proceedings\n5. Track legislative cases and government pledges\n\nThe project leverages Bert Hubert's tkconv service as its primary data source, which provides a more accessible API than the official Dutch Parliament APIs.\n\n## Installation\n\n### 1. Quick Start with NPM Package (Recommended)\n\nThe fastest way to get started is using the published npm package:\n\n```bash\nnpx @r-huijts/opentk-mcp\n```\n\n### 2. Using Claude Desktop with NPM Package\n\nUpdate your Claude configuration file (`~/Library/Application Support/Claude/claude_desktop_config.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"opentk\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@r-huijts/opentk-mcp\"\n      ]\n    }\n  }\n}\n```\n\n**Alternative configurations:**\n\nFor MultiServerMCPClient (Python):\n```python\nmcp_client = MultiServerMCPClient({\n    \"opentk\": {\n        \"command\": \"npx\",\n        \"args\": [\"-y\", \"@r-huijts/opentk-mcp\"],\n        \"transport\": \"stdio\",\n    }\n})\n```\n\n### 3. From Source (Development)\n\nIf you want to modify the code or contribute to development:\n\n**Clone Repository:**\n```bash\ngit clone https://github.com/r-huijts/opentk-mcp.git\ncd opentk-mcp\n```\n\n**Install Dependencies:**\n```bash\nnpm install\n```\n\n**Build the Project:**\n```bash\nnpm run build\n```\n\n**Start the Server:**\n```bash\nnpm start\n```\n\n**Configure Claude Desktop for local development:**\n\nUpdate your Claude configuration file:\n\n```json\n{\n  \"mcpServers\": {\n    \"opentk-local\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/absolute/path/to/your/opentk-mcp/dist/index.js\"\n      ]\n    }\n  }\n}\n```\n\nMake sure to replace `/absolute/path/to/your/opentk-mcp/` with the actual path to your installation.\n\n### 4. Publishing (for maintainers)\n\nTo publish a new version of the scoped package:\n\n```bash\nnpm run build\nnpm publish --access=public\n```\n\nNote: Scoped packages require the `--access=public` flag to be publicly available.\n\n## Search Functionality\n\nThe search functionality is particularly sophisticated, supporting:\n\n- Simple keyword searches: `kunstmatige intelligentie`\n- Exact phrase searches: `\"kunstmatige intelligentie\"`\n- Exclusion searches: `Hubert NOT Bruls`\n- Boolean operators: `OR`, `NEAR()`\n\nThe implementation handles various edge cases:\n- Preserves quotes in search queries\n- Uses proper content type headers\n- Implements fallback mechanisms for API errors\n- Provides meaningful error messages\n\n## Error Handling\n\nThe API service includes robust error handling:\n- Graceful handling of API errors (4xx, 5xx)\n- Fallback to simplified queries when complex ones fail\n- Detailed error messages for debugging\n- Proper logging to stderr (not stdout, which would break the stdio transport)\n\n## Configuration\n\nThe server connects to Bert Hubert's [tkconv service](https://berthub.eu/tkconv/) as its primary data source, which provides a more accessible API than the official Dutch Parliament APIs. This service, created by Bert Hubert, does the heavy lifting of collecting, organizing, and making available Dutch parliamentary data in a developer-friendly format. Our MCP server builds upon this foundation to create a standardized interface for AI assistants to interact with this valuable data.\n\n## License\n\nMIT\n\n## Conclusion\n\nThe OpenTK MCP server provides a robust and well-structured interface to Dutch parliamentary data, making it accessible to AI assistants through the Model Context Protocol. Its modular design, comprehensive API, and thorough testing ensure reliable access to parliamentary information for AI-assisted research, analysis, and information retrieval.\n\nOnce configured, Claude will be able to access Dutch parliamentary data through the OpenTK MCP server. The server exposes all the tools described in the [Usage](#usage) section above.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "parliamentary",
        "document",
        "documents",
        "dutch parliamentary",
        "parliamentary documents",
        "huijts opentk"
      ],
      "category": "document-processing"
    },
    "rajnaveen344--lsp-tools-mcp": {
      "owner": "rajnaveen344",
      "name": "lsp-tools-mcp",
      "url": "https://github.com/rajnaveen344/lsp-tools-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/rajnaveen344.webp",
      "description": "Enhances text analysis by providing regex matching capabilities to find positions of regex matches in files and managing directory access for secure interaction with system files.",
      "stars": 0,
      "forks": 1,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-03-09T09:45:17Z",
      "readme_content": "# LSP Tools MCP Server\n\nA Model Context Protocol (MCP) server providing Language Server Protocol-like functionality for text analysis.\n\n## Features\n\n- **Find Regex Position**: Find the 0-indexed line and column positions of regex pattern matches in a file\n- **List Allowed Directories**: Get a list of directories the server is allowed to access\n\n## Installation\n\n```bash\nnpm install\nnpm run build\n```\n\n## Usage\n\n```bash\n# Start the server allowing access to a specific directory\nnode dist/index.js /path/to/allowed/directory\n\n# Start the server with multiple allowed directories\nnode dist/index.js /path/to/dir1 /path/to/dir2 /path/to/dir3\n```\n\n## Development\n\n### Running Tests\n\nThe project uses Jest for testing. Run the tests with:\n\n```bash\nnpm test\n```\n\nTo run tests in watch mode during development:\n\n```bash\nnpm run test:watch\n```\n\n### Linting\n\nLint the code with ESLint:\n\n```bash\nnpm run lint\n```\n\n## Tool Documentation\n\n### find_regex_position\n\nThis tool finds the 0-indexed line and column positions of regex pattern matches in a file.\n\n**Parameters:**\n- `path`: The path to the file to search in\n- `regex`: The regular expression pattern to search for\n\n**Returns:**\n- An array of matches with the following properties:\n  - `match`: The matched text\n  - `line`: The starting line (0-indexed)\n  - `column`: The starting column (0-indexed)\n  - `endLine`: The ending line (0-indexed)\n  - `endColumn`: The ending column (0-indexed, exclusive)\n\n### list_allowed_directories\n\nThis tool lists all directories that this server is allowed to access.\n\n**Parameters:**\n- None\n\n**Returns:**\n- An array of absolute paths to allowed directories\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "regex",
        "lsp",
        "files",
        "matches files",
        "lsp tools",
        "document processing"
      ],
      "category": "document-processing"
    },
    "rajvirtual--MCP-Servers": {
      "owner": "rajvirtual",
      "name": "MCP-Servers",
      "url": "https://github.com/rajvirtual/MCP-Servers",
      "imageUrl": "/freedevtools/mcp/pfp/rajvirtual.webp",
      "description": "Access and manage Microsoft OneNote content, enabling the reading and creation of notebooks, sections, and pages directly through AI assistants. Converts HTML content to text for improved retrieval-augmented generation (RAG) processing.",
      "stars": 14,
      "forks": 5,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-08-08T13:31:04Z",
      "readme_content": "",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "onenote",
        "microsoft",
        "processing",
        "microsoft onenote",
        "onenote content",
        "document processing"
      ],
      "category": "document-processing"
    },
    "regenrek--deepwiki-mcp": {
      "owner": "regenrek",
      "name": "deepwiki-mcp",
      "url": "https://github.com/regenrek/deepwiki-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/regenrek.webp",
      "description": "Crawls Deepwiki.com documentation, converting it into Markdown format by removing unnecessary HTML elements and adjusting links for better readability. Supports fetching multiple pages and offers structured output formats for knowledge retrieval.",
      "stars": 1030,
      "forks": 60,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T22:33:01Z",
      "readme_content": "# Deepwiki MCP Server\n\n> ⚠️ **IMPORTANT NOTICE**: This server is currently not working since DeepWiki has cut off the possibility to scrape it. We recommend using the official DeepWiki MCP server at https://docs.devin.ai/work-with-devin/deepwiki-mcp for the time being.\n\nThis is an **unofficial Deepwiki MCP Server**\n\nIt takes a Deepwiki URL via MCP, crawls all relevant pages, converts them to Markdown, and returns either one document or a list by page.\n\n## Features\n\n- 🔒 **Domain Safety**: Only processes URLs from deepwiki.com\n- 🧹 **HTML Sanitization**: Strips headers, footers, navigation, scripts, and ads\n- 🔗 **Link Rewriting**: Adjusts links to work in Markdown\n- 📄 **Multiple Output Formats**: Get one document or structured pages\n- 🚀 **Performance**: Fast crawling with adjustable concurrency and depth\n- **NLP**: It's to search just for the library name\n\n## Usage\n\nPrompts you can use:\n\n```\ndeepwiki fetch how can i use gpt-image-1 with \"vercel ai\" sdk\n```\n\n```\ndeepwiki fetch how can i create new blocks in shadcn?\n```\n\n```\ndeepwiki fetch i want to understand how X works\n```\n\nFetch complete Documentation (Default)\n```\nuse deepwiki https://deepwiki.com/shadcn-ui/ui\nuse deepwiki multiple pages https://deepwiki.com/shadcn-ui/ui\n```\n\nSingle Page\n```\nuse deepwiki fetch single page https://deepwiki.com/tailwindlabs/tailwindcss/2.2-theme-system\n```\n\nGet by shortform\n```\nuse deepwiki fetch tailwindlabs/tailwindcss\n```\n\n```\ndeepwiki fetch library\n\ndeepwiki fetch url\ndeepwiki fetch <name>/<repo>\n\ndeepwiki multiple pages ...\ndeepwiki single page url ...\n```\n\n## Cursor\n\nAdd this to `.cursor/mcp.json` file.\n\n```\n{\n  \"mcpServers\": {\n    \"mcp-deepwiki\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"mcp-deepwiki@latest\"]\n    }\n  }\n}\n```\n\n\n\n### MCP Tool Integration\n\nThe package registers a tool named `deepwiki_fetch` that you can use with any MCP-compatible client:\n\n```json\n{\n  \"action\": \"deepwiki_fetch\",\n  \"params\": {\n    \"url\": \"https://deepwiki.com/user/repo\",\n    \"mode\": \"aggregate\",\n    \"maxDepth\": \"1\"\n  }\n}\n```\n\n#### Parameters\n\n- `url` (required): The starting URL of the Deepwiki repository\n- `mode` (optional): Output mode, either \"aggregate\" for a single Markdown document (default) or \"pages\" for structured page data\n- `maxDepth` (optional): Maximum depth of pages to crawl (default: 10)\n\n### Response Format\n\n#### Success Response (Aggregate Mode)\n\n```json\n{\n  \"status\": \"ok\",\n  \"data\": \"# Page Title\\n\\nPage content...\\n\\n---\\n\\n# Another Page\\n\\nMore content...\",\n  \"totalPages\": 5,\n  \"totalBytes\": 25000,\n  \"elapsedMs\": 1200\n}\n```\n\n#### Success Response (Pages Mode)\n\n```json\n{\n  \"status\": \"ok\",\n  \"data\": [\n    {\n      \"path\": \"index\",\n      \"markdown\": \"# Home Page\\n\\nWelcome to the repository.\"\n    },\n    {\n      \"path\": \"section/page1\",\n      \"markdown\": \"# First Page\\n\\nThis is the first page content.\"\n    }\n  ],\n  \"totalPages\": 2,\n  \"totalBytes\": 12000,\n  \"elapsedMs\": 800\n}\n```\n\n#### Error Response\n\n```json\n{\n  \"status\": \"error\",\n  \"code\": \"DOMAIN_NOT_ALLOWED\",\n  \"message\": \"Only deepwiki.com domains are allowed\"\n}\n```\n\n#### Partial Success Response\n\n```json\n{\n  \"status\": \"partial\",\n  \"data\": \"# Page Title\\n\\nPage content...\",\n  \"errors\": [\n    {\n      \"url\": \"https://deepwiki.com/user/repo/page2\",\n      \"reason\": \"HTTP error: 404\"\n    }\n  ],\n  \"totalPages\": 1,\n  \"totalBytes\": 5000,\n  \"elapsedMs\": 950\n}\n```\n\n### Progress Events\n\nWhen using the tool, you'll receive progress events during crawling:\n\n```\nFetched https://deepwiki.com/user/repo: 12500 bytes in 450ms (status: 200)\nFetched https://deepwiki.com/user/repo/page1: 8750 bytes in 320ms (status: 200)\nFetched https://deepwiki.com/user/repo/page2: 6200 bytes in 280ms (status: 200)\n```\n\n## Local Development - Installation\n\n### Local Usage\n\n```\n{\n  \"mcpServers\": {\n    \"mcp-deepwiki\": {\n      \"command\": \"node\",\n      \"args\": [\"./bin/cli.mjs\"]\n    }\n  }\n}\n```\n\n### From Source\n\n```bash\n# Clone the repository\ngit clone https://github.com/regenrek/deepwiki-mcp.git\ncd deepwiki-mcp\n\n# Install dependencies\nnpm install\n\n# Build the package\nnpm run build\n```\n\n#### Direct API Calls\n\nFor HTTP transport, you can make direct API calls:\n\n```bash\ncurl -X POST http://localhost:3000/mcp \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"id\": \"req-1\",\n    \"action\": \"deepwiki_fetch\",\n    \"params\": {\n      \"url\": \"https://deepwiki.com/user/repo\",\n      \"mode\": \"aggregate\"\n    }\n  }'\n```\n\n## Configuration\n\n### Environment Variables\n\n- `DEEPWIKI_MAX_CONCURRENCY`: Maximum concurrent requests (default: 5)\n- `DEEPWIKI_REQUEST_TIMEOUT`: Request timeout in milliseconds (default: 30000)\n- `DEEPWIKI_MAX_RETRIES`: Maximum retry attempts for failed requests (default: 3)\n- `DEEPWIKI_RETRY_DELAY`: Base delay for retry backoff in milliseconds (default: 250)\n\nTo configure these, create a `.env` file in the project root:\n\n```\nDEEPWIKI_MAX_CONCURRENCY=10\nDEEPWIKI_REQUEST_TIMEOUT=60000\nDEEPWIKI_MAX_RETRIES=5\nDEEPWIKI_RETRY_DELAY=500\n```\n\n## Docker Deployment (Untested)\n\nBuild and run the Docker image:\n\n```bash\n# Build the image\ndocker build -t mcp-deepwiki .\n\n# Run with stdio transport (for development)\ndocker run -it --rm mcp-deepwiki\n\n# Run with HTTP transport (for production)\ndocker run -d -p 3000:3000 mcp-deepwiki --http --port 3000\n\n# Run with environment variables\ndocker run -d -p 3000:3000 \\\n  -e DEEPWIKI_MAX_CONCURRENCY=10 \\\n  -e DEEPWIKI_REQUEST_TIMEOUT=60000 \\\n  mcp-deepwiki --http --port 3000\n```\n\n## Development\n\n```bash\n# Install dependencies\npnpm install\n\n# Run in development mode with stdio\npnpm run dev-stdio\n\n# Run tests\npnpm test\n\n# Run linter\npnpm run lint\n\n# Build the package\npnpm run build\n```\n\n## Troubleshooting\n\n### Common Issues\n\n1. **Permission Denied**: If you get EACCES errors when running the CLI, make sure to make the binary executable:\n   ```bash\n   chmod +x ./node_modules/.bin/mcp-deepwiki\n   ```\n\n2. **Connection Refused**: Make sure the port is available and not blocked by a firewall:\n   ```bash\n   # Check if port is in use\n   lsof -i :3000\n   ```\n\n3. **Timeout Errors**: For large repositories, consider increasing the timeout and concurrency:\n   ```\n   DEEPWIKI_REQUEST_TIMEOUT=60000 DEEPWIKI_MAX_CONCURRENCY=10 npx mcp-deepwiki\n   ```\n\n## Contributing\n\nWe welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for details.\n\n## License\n\nMIT\n\n## Links\n\n- X/Twitter: [@kregenrek](https://x.com/kregenrek)\n- Bluesky: [@kevinkern.dev](https://bsky.app/profile/kevinkern.dev)\n\n## Courses\n- Learn Cursor AI: [Ultimate Cursor Course](https://www.instructa.ai/en/cursor-ai)\n- Learn to build software with AI: [instructa.ai](https://www.instructa.ai)\n\n## See my other projects:\n\n* [AI Prompts](https://github.com/instructa/ai-prompts/blob/main/README.md) - Curated AI Prompts for Cursor AI, Cline, Windsurf and Github Copilot\n* [codefetch](https://github.com/regenrek/codefetch) - Turn code into Markdown for LLMs with one simple terminal command\n* [aidex](https://github.com/regenrek/aidex) A CLI tool that provides detailed information about AI language models, helping developers choose the right model for their needs.# tool-starter",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "deepwiki",
        "documentation",
        "markdown",
        "crawls deepwiki",
        "deepwiki mcp",
        "deepwiki com"
      ],
      "category": "document-processing"
    },
    "rickysullivan--gitbook-mcp": {
      "owner": "rickysullivan",
      "name": "gitbook-mcp",
      "url": "https://github.com/rickysullivan/gitbook-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/rickysullivan.webp",
      "description": "Access GitBook Organizations, Spaces, Collections, and Content through a standardized MCP interface, enabling programmatic operations for documentation workflows.",
      "stars": 11,
      "forks": 0,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-24T14:45:52Z",
      "readme_content": "# GitBook MCP Server Reference\n\nA Model Context Protocol (MCP) server that provides access to GitBook's API for AI assistants and LLM applications.\n\n## Overview\n\nThe GitBook MCP server enables programmatic access to GitBook Organizations, Spaces, Collections, and Content through a standardized MCP interface. It provides 12 tools for content operations and 6 AI-powered prompts for documentation workflows.\n\n## Quick Setup\n\n### Prerequisites\n\n- GitBook API token (obtain from https://app.gitbook.com/account/developer)\n- Your GitBook Organization ID (optional but recommended)\n\n### IDE and AI Assistant Integration\n\n#### VS Code (with GitHub Copilot)\n\nAdd to your VS Code MCP settings:\n\n```json\n{\n    \"servers\": {\n        \"gitbook-mcp\": {\n            \"type\": \"stdio\",\n            \"command\": \"npx\",\n            \"args\": [\n                \"gitbook-mcp\",\n                \"--organization-id=your_organization_id_here\"\n            ],\n            \"env\": {\n                \"GITBOOK_API_TOKEN\": \"gb_api_your_token_here\"\n            }\n        }\n    }\n}\n```\n\n#### Claude Desktop\n\nAdd to your Claude Desktop configuration (`%APPDATA%\\Claude\\claude_desktop_config.json` on Windows or `~/Library/Application Support/Claude/claude_desktop_config.json` on macOS):\n\n```json\n{\n    \"mcpServers\": {\n        \"gitbook-mcp\": {\n            \"command\": \"npx\",\n            \"args\": [\"gitbook-mcp\", \"--organization-id=your_organization_id\"],\n            \"env\": {\n                \"GITBOOK_API_TOKEN\": \"gb_api_your_token_here\"\n            }\n        }\n    }\n}\n```\n\nSee https://modelcontextprotocol.io/quickstart/user for details.\n\n#### GitHub Copilot plugin for JetBrains IDEs (IntelliJ IDEA, WebStorm, etc.):\n\nAdd to your GitHub Copilot MCP settings for JetBrains IDEs (the path may vary by product and OS, e.g., `~/.config/github-copilot/intellij/mcp.json` for IntelliJ on Linux/macOS, or the equivalent directory for your JetBrains IDE and platform):\n\n```json\n{\n    \"servers\": {\n        \"gitbook-mcp\": {\n            \"command\": \"npx\",\n            \"args\": [\n                \"gitbook-mcp\",\n                \"--organization-id=your_organization_id_here\"\n            ],\n            \"env\": {\n                \"GITBOOK_API_TOKEN\": \"gb_api_your_token_here\"\n            }\n        }\n    }\n}\n```\n\n#### JetBrains AI Assistant\n\nAdd to your JetBrains AI Assistant MCP configuration (see [official docs](https://www.jetbrains.com/help/ai-assistant/configure-an-mcp-server.html) for the exact path):\n\n### Getting Your GitBook Credentials\n\n1. **API Token**: Visit https://app.gitbook.com/account/developer to generate your API token\n2. **Organization ID**: Use the `list_organizations` tool after setup to find your organization ID\n3. **Space ID** (optional): Use the `list_spaces` tool (requires a valid organization ID and API token) to find specific space IDs\n4. **Space ID** (optional): Use the `list_spaces` tool to find specific space IDs\n\n### Configuration Options\n\nYou can configure the server using:\n\n- **CLI arguments**: `--organization-id`, `--space-id`\n- **Environment variables in MCP config**: Set via the `env` object in your MCP configuration\n- **System environment variables**: `GITBOOK_API_TOKEN`, `GITBOOK_ORGANIZATION_ID`, `GITBOOK_SPACE_ID`\n\n**Note**: `.env` files are only supported when running the server locally for development, not when using `npx gitbook-mcp`.\n\n## API Reference\n\n### Tools\n\nThe GitBook MCP server provides 12 tools organized into functional categories. Each tool includes behavioral hints:\n\n- 📖 **Read-only**: Tool only reads data and doesn't modify anything\n- 🔄 **Idempotent**: Repeated calls with same args have no additional effect with the same result\n- 🌐 **Open-world**: Tool interacts with external entities\n\n#### Organization Discovery\n\n##### List Organizations (`list_organizations`) 📖 🔄 🌐\n\nLists all accessible GitBook organizations.\n\n**Parameters:** None\n\n**Returns:**\n\n```json\n{\n    \"organizations\": [\n        {\n            \"id\": \"string\",\n            \"title\": \"string\",\n            \"urls\": {\n                \"app\": \"string\",\n                \"public\": \"string\"\n            }\n        }\n    ]\n}\n```\n\n#### Space Management\n\n##### List Spaces (`list_spaces`) 📖 🔄 🌐\n\nLists spaces, optionally filtered by organization.\n\n**Parameters:**\n\n- `organizationId` (optional): Organization ID to filter spaces\n\n**Returns:**\n\n```json\n{\n    \"spaces\": [\n        {\n            \"id\": \"string\",\n            \"title\": \"string\",\n            \"visibility\": \"string\",\n            \"urls\": {\n                \"app\": \"string\",\n                \"public\": \"string\"\n            }\n        }\n    ]\n}\n```\n\n##### Get Space Details (`get_space`) 📖 🔄 🌐\n\nRetrieves detailed information about a specific space.\n\n**Parameters:**\n\n- `spaceId` (required): The ID of the space to retrieve\n\n**Returns:**\n\n```json\n{\n    \"id\": \"string\",\n    \"title\": \"string\",\n    \"description\": \"string\",\n    \"visibility\": \"string\",\n    \"urls\": {\n        \"app\": \"string\",\n        \"public\": \"string\"\n    }\n}\n```\n\n##### Get Space Content (`get_space_content`) 📖 🔄 🌐\n\nRetrieves the content structure and pages of a space.\n\n**Parameters:**\n\n- `spaceId` (optional): The ID of the space (uses default if configured)\n\n**Returns:**\n\n```json\n{\n    \"pages\": [\n        {\n            \"id\": \"string\",\n            \"title\": \"string\",\n            \"slug\": \"string\",\n            \"path\": \"string\"\n        }\n    ]\n}\n```\n\n##### Search Content (`search_content`) 📖 🔄 🌐\n\nSearches for content within a space using full-text search.\n\n**Parameters:**\n\n- `query` (required): Search query string\n- `spaceId` (optional): The ID of the space to search (uses default if configured)\n\n**Returns:**\n\n```json\n{\n    \"results\": [\n        {\n            \"id\": \"string\",\n            \"title\": \"string\",\n            \"excerpt\": \"string\",\n            \"url\": \"string\"\n        }\n    ]\n}\n```\n\n#### Content Retrieval\n\n##### Get Page Content (`get_page_content`) 📖 🔄 🌐\n\nRetrieves the content of a specific page.\n\n**Parameters:**\n\n- `pageId` (required): The ID of the page to retrieve\n- `spaceId` (optional): The ID of the space containing the page\n- `format` (optional): Output format (`\"document\"` or `\"markdown\"`, defaults to `\"document\"`)\n- `metadata` (optional): Include revision metadata (boolean, defaults to `false`)\n- `computed` (optional): Include computed revision data (boolean, defaults to `false`)\n\n**Returns:**\n\n```json\n{\n    \"id\": \"string\",\n    \"title\": \"string\",\n    \"content\": \"string\",\n    \"format\": \"string\"\n}\n```\n\n##### Get Page by Path (`get_page_by_path`) 📖 🔄 🌐\n\nRetrieves page content using the page path.\n\n**Parameters:**\n\n- `pagePath` (required): The path of the page to retrieve\n- `spaceId` (optional): The ID of the space containing the page\n\n**Returns:**\n\n```json\n{\n    \"id\": \"string\",\n    \"title\": \"string\",\n    \"content\": \"string\",\n    \"path\": \"string\"\n}\n```\n\n#### File Management\n\n##### Get Space Files (`get_space_files`) 📖 🔄 🌐\n\nLists all files in a space.\n\n**Parameters:**\n\n- `spaceId` (optional): The ID of the space (uses default if configured)\n\n**Returns:**\n\n```json\n{\n    \"files\": [\n        {\n            \"id\": \"string\",\n            \"name\": \"string\",\n            \"downloadURL\": \"string\",\n            \"size\": \"number\"\n        }\n    ]\n}\n```\n\n##### Get File Details (`get_file`) 📖 🔄 🌐\n\nRetrieves details of a specific file.\n\n**Parameters:**\n\n- `fileId` (required): The ID of the file to retrieve\n- `spaceId` (optional): The ID of the space containing the file\n\n**Returns:**\n\n```json\n{\n    \"id\": \"string\",\n    \"name\": \"string\",\n    \"downloadURL\": \"string\",\n    \"size\": \"number\",\n    \"uploadedAt\": \"string\"\n}\n```\n\n#### Collection Management\n\n##### List Collections (`list_collections`) 📖 🔄 🌐\n\nLists all accessible collections.\n\n**Parameters:**\n\n- `organizationId` (optional): Organization ID to filter collections\n\n**Returns:**\n\n```json\n{\n    \"collections\": [\n        {\n            \"id\": \"string\",\n            \"title\": \"string\",\n            \"description\": \"string\"\n        }\n    ]\n}\n```\n\n##### Get Collection Details (`get_collection`) 📖 🔄 🌐\n\nRetrieves details of a specific collection.\n\n**Parameters:**\n\n- `collectionId` (required): The ID of the collection to retrieve\n\n**Returns:**\n\n```json\n{\n    \"id\": \"string\",\n    \"title\": \"string\",\n    \"description\": \"string\",\n    \"spaces\": \"number\"\n}\n```\n\n##### Get Collection Spaces (`get_collection_spaces`) 📖 🔄 🌐\n\nLists all spaces within a collection.\n\n**Parameters:**\n\n- `collectionId` (required): The ID of the collection\n\n**Returns:**\n\n```json\n{\n    \"spaces\": [\n        {\n            \"id\": \"string\",\n            \"title\": \"string\",\n            \"visibility\": \"string\"\n        }\n    ]\n}\n```\n\n### Prompts\n\nThe GitBook MCP server provides 6 AI-powered prompts for documentation workflows:\n\n#### Fetch Documentation (`fetch_documentation`)\n\nFetches and analyzes GitBook documentation content for specific topics.\n\n**Parameters:**\n\n- `topic` (required): The topic or subject to search for and analyze\n- `spaceId` (optional): The ID of the space to search (uses default if configured)\n- `includeStructure` (optional): Set to \"true\" to include space structure\n\n**Returns:**\nA comprehensive analysis of documentation related to the specified topic, including:\n\n- Relevant pages and sections\n- Content summaries\n- Gaps or areas needing improvement\n\n#### Analyze Content Gaps (`analyze_content_gaps`)\n\nIdentifies gaps and missing content in documentation.\n\n**Parameters:**\n\n- `spaceId` (optional): The ID of the space to analyze (uses default if configured)\n- `comparisonSource` (optional): Source to compare against (default: \"internal analysis\")\n\n**Returns:**\nA detailed gap analysis including:\n\n- Missing topics and incomplete sections\n- Coverage gaps prioritized by importance\n- Suggestions for new content areas\n\n#### Content Audit (`content_audit`)\n\nPerforms quality audits of documentation content.\n\n**Parameters:**\n\n- `spaceId` (optional): The ID of the space to audit (uses default if configured)\n- `auditCriteria` (optional): Specific criteria to audit (default: \"general quality and consistency\")\n\n**Returns:**\nA comprehensive quality assessment including:\n\n- Content quality and consistency review\n- Outdated information identification\n- Writing style and formatting recommendations\n\n#### Documentation Summary (`documentation_summary`)\n\nGenerates comprehensive summaries of GitBook spaces.\n\n**Parameters:**\n\n- `spaceId` (optional): The ID of the space to summarize (uses default if configured)\n- `summaryType` (optional): Type of summary - \"overview\", \"technical\", \"user-guide\", or \"custom\" (default: \"overview\")\n\n**Returns:**\nA structured summary including:\n\n- Space structure and content organization\n- Main topics and themes\n- Target audience and use cases\n\n#### Content Optimization (`content_optimization`)\n\nOptimizes content for SEO, readability, structure, or performance.\n\n**Parameters:**\n\n- `spaceId` (optional): The ID of the space to optimize (uses default if configured)\n- `optimizationType` (required): Type of optimization - \"SEO\", \"readability\", \"structure\", or \"performance\"\n- `targetMetrics` (optional): Specific metrics or goals to optimize for\n\n**Returns:**\nOptimization recommendations including:\n\n- Specific improvement strategies\n- Priority-ranked optimization opportunities\n- Implementation guidance\n\n## Configuration Reference\n\nThe GitBook MCP server supports multiple configuration methods with the following precedence (highest to lowest):\n\n1. **CLI Arguments** - Passed when starting the MCP server\n2. **Configuration Files** - Embedded in project configuration files\n3. **Environment Variables** - Set in `.env.local` or system environment\n\n### Environment Variables\n\n| Variable                  | Required | Type   | Description                                                               |\n| ------------------------- | -------- | ------ | ------------------------------------------------------------------------- |\n| `GITBOOK_API_TOKEN`       | Yes      | string | GitBook API token (obtain from https://app.gitbook.com/account/developer) |\n| `GITBOOK_ORGANIZATION_ID` | No       | string | Default organization ID for operations                                    |\n| `GITBOOK_SPACE_ID`        | No       | string | Default space ID for single-space projects                                |\n\n> **Note:** Environment variables can be set in `.env.local`, `.env`, or your system environment.\n\n### CLI Arguments\n\n| Argument            | Alias     | Type   | Description                  |\n| ------------------- | --------- | ------ | ---------------------------- |\n| `--organization-id` | `--org`   | string | Organization ID to work with |\n| `--space-id`        | `--space` | string | Default space for operations |\n\n**Example:**\n\n```bash\nnode dist/index.js --organization-id your-org-id --space-id your-space-id\n```\n\n### Additional Configuration Files\n\nTypically these files are provided as context to the AI assistant, which means you can store project-based configuration.\n\n1. `.github/copilot-instructions.md`\n2. `.cursorrules`\n3. `.cursor/rules/rules.md`\n4. `.cursor/rules/instructions.md`\n\ne.g.\n\n**Format:**\n\n```markdown\n## GitBook Configuration\n\nFor GitBook MCP operations, use the following configuration:\n\n- organization-id: your-org-id-here\n- space-id: your-space-id-here\n```\n\n### Default Parameter Behavior\n\nWhen `GITBOOK_ORGANIZATION_ID` or `GITBOOK_SPACE_ID` are configured:\n\n- Tools marked as \"optional\" can omit the corresponding ID parameters\n- The configured default values will be used automatically\n- Explicit parameters in tool calls override defaults\n\n## Development\n\n### Prerequisites\n\n- Node.js 20+\n- npm\n- GitBook API token (obtain from https://app.gitbook.com/account/developer)\n\n### Installation & Setup\n\n```bash\ngit clone https://github.com/rickysullivan/gitbook-mcp.git\ncd gitbook-mcp\nnpm install\nnpm run setup\n# Add your GITBOOK_API_TOKEN to .env.local (for local development only)\n```\n\n### Development\n\n```bash\nnpm run dev\n```\n\n### Debugging\n\n```bash\nDEBUG=1 npm run dev\n```\n\n### Add the MCP to VS Code for development\n\nYou will need to use `node` as the command when running locally.\nThe first arg should be the path to the compiled JavaScript output (e.g., `dist/index.js`).\n\n```json\n{\n    \"servers\": {\n        \"gitbook-mcp-dev\": {\n            \"type\": \"stdio\",\n            \"command\": \"node\",\n            \"args\": [\n                \"/my/path/to/gitbook-mcp/dist/index.js\",\n                \"--organization-id=Luj2l6y6cIUPXJwbC574\"\n            ],\n            \"env\": {\n                \"GITBOOK_API_TOKEN\": \"gb_api_UHEGTNsMg0ONPTnm0LpsJNBCCikQyOMkBTtZNDAB\"\n            }\n        }\n    }\n}\n```\n\n### Testing\n\nThere are currently no unit or integration tests; running `npm run test` only checks that the TypeScript code compiles successfully (type-check/build verification), and does not execute any actual tests.\n\n```bash\nnpm run test\n```\n\n### Error Handling\n\n#### Common Error Codes\n\n| Error Code | Description                          | Resolution                                       |\n| ---------- | ------------------------------------ | ------------------------------------------------ |\n| `401`      | Unauthorized - Invalid API token     | Verify `GITBOOK_API_TOKEN` is correct            |\n| `403`      | Forbidden - Insufficient permissions | Check space/organization access permissions      |\n| `404`      | Not Found - Resource doesn't exist   | Verify space/page/collection IDs are correct     |\n| `429`      | Rate Limited - Too many requests     | Implement request throttling                     |\n| `500`      | Internal Server Error                | Check server logs for detailed error information |\n\n### Troubleshooting\n\n**Token Issues:**\n\n- Ensure token starts with `gb_live_`\n- Verify token has not expired\n- Check token permissions in GitBook settings\n\n**ID Resolution:**\n\n- Use `list_organizations` to find valid organization IDs\n- Use `list_spaces` to find valid space IDs\n- Use `get_space_content` to find valid page IDs\n\n**Configuration Issues:**\n\n- Verify environment variables are properly set\n- Check file permissions on configuration files\n- Ensure CLI arguments are properly formatted\n\n## Contributing\n\n1. Fork the repository\n2. Create a feature branch\n3. Make your changes\n4. Submit a pull request\n\n## License\n\nMIT License - see the [LICENSE](LICENSE) file for details.\n\n## Related Documentation\n\n- [GitBook API Documentation](https://api.gitbook.com/openapi.json)\n- [Model Context Protocol Specification](https://modelcontextprotocol.io)\n- [Detailed Prompt Documentation](./PROMPTS.md)\n\n## Disclaimer\n\nThis project is independently developed and is not officially affiliated with, endorsed by, or sponsored by [GitBook](https://www.gitbook.com).\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "gitbook",
        "documentation",
        "document",
        "gitbook mcp",
        "gitbook organizations",
        "access gitbook"
      ],
      "category": "document-processing"
    },
    "rishipradeep-think41--google-drive-mcp": {
      "owner": "rishipradeep-think41",
      "name": "google-drive-mcp",
      "url": "https://github.com/rishipradeep-think41/google-drive-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/rishipradeep-think41.webp",
      "description": "Integrate Google Drive functionalities with the Model Context Protocol (MCP) to facilitate file management, content retrieval, and permission handling. Access Google's Drive resources seamlessly from LLM applications through standardized tools.",
      "stars": 2,
      "forks": 8,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-07-11T00:35:40Z",
      "readme_content": "[![smithery badge](https://smithery.ai/badge/@rishipradeep-think41/google-drive-mcp)](https://smithery.ai/server/@rishipradeep-think41/google-drive-mcp)\n\n# Google Drive MCP Server\n\nGoogle Drive MCP Server is a stateless server that integrates Google Drive functionalities with the Model Context Protocol (MCP). It provides a suite of tools and resources to interact with Google Drive, enabling operations like file management, content retrieval, and permission handling through a standardized interface.\n\n## 🚀 Features\n\n- **Root Listing:** List top-level locations like \"My Drive\" and \"Shared with me\" using `drive_roots`.\n- **Folder Browsing:** List contents of any folder with `drive_folder_children`.\n- **File Metadata:** Retrieve detailed metadata for a file using `drive_file_metadata`.\n- **File Exporting:** Retrieve raw file content using `drive_file_content` (note: no built-in format conversion).\n- **File Uploading:** Create or update files with content using `drive_upload`.\n- **Text Appending:** Append plain text to existing text files using `drive_append_text`.\n- **File Deletion & Trash:** Move files to trash or delete them permanently with `drive_delete` and `drive_file_empty_trash`.\n- **Permission Management:** Add, update, remove, or list permissions for files/folders via `drive_share`, `drive_permission_update`, `drive_permission_delete`, etc.\n- **Commenting & Replies:** Add comments, reply to them, and list/delete comments or replies using tools like `drive_comment`, `drive_file_list_comments`, and related tools.\n- **Change Tracking:** Track changes in a user's Drive using `drive_changes`.\n- **File Search:** Search for files by name or other criteria using `drive_search`.\n\n🛠️ **Installation**\n\n1.  **Clone the Repository:**\n\n    ```bash\n    git clone [https://github.com/rishipradeep-think41/google-drive-mcp.git](https://github.com/rishipradeep-think41/google-drive-mcp.git)\n    cd google-drive-mcp\n    ```\n\n2.  **Install Dependencies:**\n\n    ```bash\n    npm install\n    ```\n\n3.  **Configure Environment Variables:**\n    Create a `.env` file in the root directory and add the following:\n\n    ```env\n    CLIENT_ID=your_google_client_id\n    CLIENT_SECRET=your_google_client_secret\n    REFRESH_TOKEN=your_google_refresh_token\n    PORT=8081\n    ```\n\n    Ensure you have a valid Google OAuth2 client and refresh token with appropriate Drive API scopes.\n\n4.  **Start the Server:**\n    ```bash\n    node index.js\n    ```\n    The server will start on `http://localhost:8081`.\n\n📚 **API Overview**\n\n**Resources**\n\n- `drive_roots`: Lists files in \"My Drive\" and \"Shared with me\".\n\n## Tool Categories\n\n### Basic Navigation & Information\n\n| Tool Name                 | Description                                |\n| ------------------------- | ------------------------------------------ |\n| `drive_roots`             | List roots (My Drive, Shared with me)      |\n| `drive_changes`           | List changes in Drive                      |\n| `drive_file_metadata`     | Get metadata of a file                     |\n| `drive_folder_children`   | List contents of a folder                  |\n| `drive_search`            | Search files in Google Drive               |\n| `drive_storage_quota`     | Get storage quota information for the user |\n| `drive_storage_breakdown` | Get storage usage breakdown by file type   |\n\n### File Content Operations\n\n| Tool Name            | Description                                         |\n| -------------------- | --------------------------------------------------- |\n| `drive_file_content` | Retrieve content of a Google Drive file             |\n| `drive_create`       | Create file or folder                               |\n| `drive_upload`       | Upload or update file content                       |\n| `drive_append_text`  | Append plain text to an existing text file in Drive |\n\n### File Management\n\n| Tool Name                | Description                                        |\n| ------------------------ | -------------------------------------------------- |\n| `drive_copy`             | Copy a file or folder to a new location            |\n| `drive_move`             | Move a file or folder to a different parent folder |\n| `drive_rename`           | Rename a file or folder                            |\n| `drive_delete`           | Trash or delete a file                             |\n| `drive_restore`          | Restore a file from the trash                      |\n| `drive_file_empty_trash` | Permanently delete all trashed files               |\n| `drive_star`             | Star or unstar a file or folder                    |\n| `drive_file_lock`        | Lock or unlock a file to prevent changes           |\n| `drive_shortcut_create`  | Create a shortcut to a file or folder              |\n\n### File Version Management\n\n| Tool Name               | Description                         |\n| ----------------------- | ----------------------------------- |\n| `drive_versions_list`   | List all versions of a file         |\n| `drive_versions_delete` | Delete a specific version of a file |\n\n### Permissions & Sharing\n\n| Tool Name                     | Description                                           |\n| ----------------------------- | ----------------------------------------------------- |\n| `drive_share`                 | Manage file permissions                               |\n| `drive_permissions_list`      | List all permissions of a file or folder              |\n| `drive_permission_update`     | Update a user's permission on a file or folder        |\n| `drive_permission_delete`     | Remove a user's access from a file or folder          |\n| `drive_permission_add_domain` | Share file or folder with everyone in a domain        |\n| `drive_permission_add_anyone` | Allow anyone with the link to access a file or folder |\n\n### Comments & Collaboration\n\n| Tool Name                     | Description                   |\n| ----------------------------- | ----------------------------- |\n| `drive_comment`               | Add a comment to a file       |\n| `drive_file_list_comments`    | List all comments on a file   |\n| `drive_file_delete_comment`   | Delete a comment from a file  |\n| `drive_file_reply_to_comment` | Reply to a comment on a file  |\n| `drive_file_list_replies`     | List all replies to a comment |\n| `drive_file_delete_reply`     | Delete a reply to a comment   |\n\n### Shared Drives (Team Drives)\n\n| Tool Name                   | Description                              |\n| --------------------------- | ---------------------------------------- |\n| `drive_shared_drives_list`  | List all accessible Shared Drives        |\n| `drive_shared_drive_get`    | Get metadata for a specific Shared Drive |\n| `drive_shared_drive_create` | Create a new Shared Drive                |\n| `drive_shared_drive_delete` | Delete a Shared Drive                    |\n| `drive_shared_drive_update` | Update a Shared Drive's metadata         |\n| `drive_shared_drive_files`  | List files in a Shared Drive             |\n\n### Batch Operations\n\n| Tool Name                        | Description                                         |\n| -------------------------------- | --------------------------------------------------- |\n| `drive_batch_get_metadata`       | Get metadata for multiple files in a single request |\n| `drive_batch_update_permissions` | Update permissions for multiple files at once       |\n| `drive_batch_delete`             | Delete multiple files or folders at once            |\n| `drive_batch_copy`               | Copy multiple files to a destination folder         |\n| `drive_batch_move`               | Move multiple files to a destination folder         |\n\n🔐 **Authentication**\n\nThe server uses OAuth2 for authentication with Google Drive. Ensure that the `CLIENT_ID`, `CLIENT_SECRET`, and `REFRESH_TOKEN` are correctly set in the `.env` file. These credentials should have the necessary scopes to access and modify files in Google Drive.\n\n🧪 **Testing**\n\nYou can test the endpoints using tools like MCPInspector. Ensure the server is running at `http://localhost:${port}`.\n\n🤝 **Contributing**\n\nContributions are welcome! Please fork the repository and submit a pull request for any enhancements or bug fixes.\n\n📄 **License**\n\nThis project is licensed under the [MIT License](LICENSE).\n\n📧 **Contact**\n\nFor any questions or feedback, please open an issue on the [GitHub repository](https://github.com/rishipradeep-think41/google-drive-mcp).\n\n---\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcp",
        "document",
        "protocol",
        "google drive",
        "mcp facilitate",
        "drive mcp"
      ],
      "category": "document-processing"
    },
    "rjadhavJT--docgen-mcp": {
      "owner": "rjadhavJT",
      "name": "docgen-mcp",
      "url": "https://github.com/rjadhavJT/docgen-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/null.webp",
      "description": "Automates the creation of standardized documentation by extracting information from various source files and applying templates. Integrates with Google Drive and GitHub to enhance documentation processes with AI-generated content and management features.",
      "stars": 0,
      "forks": 0,
      "license": "Unknown",
      "language": "Unknown",
      "updated_at": "",
      "readme_content": "",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "docgen",
        "documentation",
        "document",
        "documentation extracting",
        "documentation processes",
        "enhance documentation"
      ],
      "category": "document-processing"
    },
    "rvydhya--youtube_transcriptor": {
      "owner": "rvydhya",
      "name": "youtube_transcriptor",
      "url": "https://github.com/rvydhya/youtube_transcriptor",
      "imageUrl": "/freedevtools/mcp/pfp/rvydhya.webp",
      "description": "Transcribes YouTube videos by extracting transcripts, including both manual and autogenerated captions, using the provided video URL. Supports integration with MCP clients for enhanced workflows involving video transcription.",
      "stars": 0,
      "forks": 1,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-04-23T13:38:39Z",
      "readme_content": "# YouTube Transcriptor MCP Tool\n\nThis is a Model Context Protocol (MCP) tool for transcribing YouTube videos using the `youtube-transcript-api`.\n\n## Features\n- Extracts and transcribes from YouTube videos (manual or autogenerated). Enables retrieval of transcripts from YouTube videos.\n- Exposes a single tool: `transcribe_video(video: str)`.\n\n## Usage\n\n### 1. Prerequisites\n- Python 3.12+\n- Install dependencies:\n  ```sh\n  pip install -r requirements.txt\n  ```\n\n### 2. Running the Tool\nYou can run the tool directly:\n```sh\npython youtube.py\n```\n\n### 3. Using with VS Code (Manual MCP Config)\nTo use this tool as an MCP server in VS Code, add the following to your `.vscode/settings.json` or your MCP client configuration:\n\n```json\n\"youtube_transcriptor\": {\n  \"type\": \"stdio\",\n  \"command\": \"python\",\n  \"args\": [\"PATH\\\\transcription\\\\youtube.py\"]\n}\n```\nReplace `PATH` with the absolute path to your workspace root.\n\n### 4. Using the Tool\nOnce configured, you can call the `transcribe_video` tool from your MCP client or compatible VS Code extension, passing a YouTube video URL as the argument.\n\n---\n\n**Example:**\n```python\nresult = transcribe_video(\"https://www.youtube.com/watch?v=VIDEO_ID\")\nprint(result)\n```\n\n---\n\n## License\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "youtube_transcriptor",
        "transcription",
        "transcripts",
        "rvydhya youtube_transcriptor",
        "youtube_transcriptor transcribes",
        "transcribes youtube"
      ],
      "category": "document-processing"
    },
    "ryanjoachim--mcp-rtfm": {
      "owner": "ryanjoachim",
      "name": "mcp-rtfm",
      "url": "https://github.com/ryanjoachim/mcp-rtfm",
      "imageUrl": "/freedevtools/mcp/pfp/ryanjoachim.webp",
      "description": "Facilitates the creation of manuals from existing documentation through content analysis, generates metadata, and provides intelligent search capabilities to form a functional knowledge base.",
      "stars": 33,
      "forks": 7,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-03-20T13:06:58Z",
      "readme_content": "# MCP-RTFM\n\n[![TypeScript](https://img.shields.io/badge/TypeScript-5.0-blue.svg)](https://www.typescriptlang.org/)\n[![MCP](https://img.shields.io/badge/MCP-0.1.0-green.svg)](https://github.com/modelcontextprotocol)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\n> \"RTFM!\" they say, but what if there's no FM to R? 🤔 Enter MCP-RTFM: an MCP server that helps you *create* the F*ing Manual everyone keeps telling people to read! Using advanced content analysis, metadata generation, and intelligent search capabilities, it transforms your non-existent or unreadable docs into an interconnected knowledge base that actually answers those \"basic questions\" before they're asked.\n\n> **Plot twist**: Instead of just telling people to RTFM, now you can actually give them an FM worth R-ing! Because the best response to \"read the f*ing manual\" is having a manual that's actually worth reading. 📚✨\n\n## 📚 Table of Contents\n\n- [Quick Start](#-quick-start)\n- [Features](#-features)\n- [Example Workflows](#-example-workflows)\n- [Installation](#-installation)\n- [Advanced Features](#-advanced-features)\n- [Development](#-development)\n- [Debugging](#-debugging)\n\n## 🚀 Quick Start\n\n```bash\n# Install dependencies\nnpm install\n\n# Build the server\nnpm run build\n\n# Add to your MCP settings and start using\nawait use_mcp_tool({\n  server: \"mcp-rtfm\",\n  tool: \"analyze_project_with_metadata\", // Enhanced initialization\n  args: { projectPath: \"/path/to/project\" }\n});\n\n// This will:\n// 1. Create documentation structure\n// 2. Analyze content with unified/remark\n// 3. Generate intelligent metadata\n// 4. Build search index with minisearch\n// 5. Add structured front matter\n// 6. Make your docs actually readable!\n```\n\n## ✨ Features\n\n### Documentation Management Tools\n\n- `analyze_existing_docs` - Analyze and enhance existing documentation with content analysis and metadata\n- `analyze_project_with_metadata` - Initialize documentation structure with enhanced content analysis and metadata generation\n- `analyze_project` - Basic initialization of documentation structure\n- `read_doc` - Read a documentation file (required before updating)\n- `update_doc` - Update documentation using diff-based changes\n- `get_doc_content` - Get current content of a documentation file\n- `get_project_info` - Get project structure and documentation status\n- `search_docs` - Search across documentation files with highlighted results\n- `update_metadata` - Update documentation metadata\n- `get_related_docs` - Find related documentation based on metadata and content links\n- `customize_template` - Create or update documentation templates\n\n### Default Documentation Files\n\nThe server automatically creates and manages these core documentation files:\n\n- `techStack.md` - Detailed inventory of tools, libraries, and configurations\n- `codebaseDetails.md` - Low-level explanations of code structure and logic\n- `workflowDetails.md` - Step-by-step workflows for key processes\n- `integrationGuides.md` - Instructions for external system connections\n- `errorHandling.md` - Troubleshooting strategies and practices\n- `handoff_notes.md` - Summary of key themes and next steps\n\n### Documentation Templates\n\nBuilt-in templates for different documentation types:\n\n- Standard Documentation Template\n- API Documentation Template\n- Workflow Documentation Template\n\nCustom templates can be created using the `customize_template` tool.\n\n## 📝 Example Workflows\n\n### 1. Analyzing Existing Documentation\n\n```typescript\n// Enhance existing documentation with advanced analysis\nawait use_mcp_tool({\n  server: \"mcp-rtfm\",\n  tool: \"analyze_existing_docs\",\n  args: { projectPath: \"/path/to/project\" }\n});\n\n// This will:\n// - Find all markdown files in .handoff_docs\n// - Analyze content structure with unified/remark\n// - Generate intelligent metadata\n// - Build search index\n// - Add front matter if not present\n// - Establish document relationships\n// - Preserve existing content\n\n// The results include:\n// - Enhanced metadata for all docs\n// - Search index population\n// - Content relationship mapping\n// - Git context if available\n```\n\n### 2. Enhanced Project Documentation Setup\n\n```typescript\n// Initialize documentation with advanced content analysis\nawait use_mcp_tool({\n  server: \"mcp-rtfm\",\n  tool: \"analyze_project_with_metadata\",\n  args: { projectPath: \"/path/to/project\" }\n});\n\n// Results include:\n// - Initialized documentation files\n// - Generated metadata from content analysis\n// - Established document relationships\n// - Populated search index\n// - Added structured front matter\n// - Git repository context\n\n// Get enhanced project information\nconst projectInfo = await use_mcp_tool({\n  server: \"mcp-rtfm\",\n  tool: \"get_project_info\",\n  args: { projectPath: \"/path/to/project\" }\n});\n\n// Search across documentation with intelligent results\nconst searchResults = await use_mcp_tool({\n  server: \"mcp-rtfm\",\n  tool: \"search_docs\",\n  args: {\n    projectPath: \"/path/to/project\",\n    query: \"authentication\"\n  }\n});\n\n// Results include:\n// - Weighted matches (title matches prioritized)\n// - Fuzzy search results\n// - Full content context\n// - Related document suggestions\n```\n\n### 3. Updating Documentation with Content Links\n\n```typescript\n// First read the document\nawait use_mcp_tool({\n  server: \"mcp-rtfm\",\n  tool: \"read_doc\",\n  args: {\n    projectPath: \"/path/to/project\",\n    docFile: \"techStack.md\"\n  }\n});\n\n// Update with content that links to other docs\nawait use_mcp_tool({\n  server: \"mcp-rtfm\",\n  tool: \"update_doc\",\n  args: {\n    projectPath: \"/path/to/project\",\n    docFile: \"techStack.md\",\n    searchContent: \"[Why this domain is critical to the project]\",\n    replaceContent: \"The tech stack documentation provides essential context for development. See [[workflowDetails]] for implementation steps.\",\n    continueToNext: true // Automatically move to next document\n  }\n});\n```\n\n### 4. Managing Documentation Metadata\n\n```typescript\n// Update metadata for better organization\nawait use_mcp_tool({\n  server: \"mcp-rtfm\",\n  tool: \"update_metadata\",\n  args: {\n    projectPath: \"/path/to/project\",\n    docFile: \"techStack.md\",\n    metadata: {\n      title: \"Technology Stack Overview\",\n      category: \"architecture\",\n      tags: [\"infrastructure\", \"dependencies\", \"configuration\"]\n    }\n  }\n});\n\n// Find related documentation\nconst related = await use_mcp_tool({\n  server: \"mcp-rtfm\",\n  tool: \"get_related_docs\",\n  args: {\n    projectPath: \"/path/to/project\",\n    docFile: \"techStack.md\"\n  }\n});\n```\n\n### 5. Searching Documentation with Context\n\n```typescript\n// Search with highlighted results\nconst results = await use_mcp_tool({\n  server: \"mcp-rtfm\",\n  tool: \"search_docs\",\n  args: {\n    projectPath: \"/path/to/project\",\n    query: \"authentication\"\n  }\n});\n\n// Results include:\n// - File name\n// - Line numbers\n// - Highlighted matches\n// - Context around matches\n```\n\n### 6. Creating Custom Templates\n\n```typescript\n// Create a custom template for architecture decisions\nawait use_mcp_tool({\n  server: \"mcp-rtfm\",\n  tool: \"customize_template\",\n  args: {\n    templateName: \"architecture-decision\",\n    content: `# {title}\n\n## Context\n[Background and context for the decision]\n\n## Decision\n[The architecture decision made]\n\n## Consequences\n[Impact and trade-offs of the decision]\n\n## Related Decisions\n[Links to related architecture decisions]`,\n    metadata: {\n      category: \"architecture\",\n      tags: [\"decision-record\", \"design\"]\n    }\n  }\n});\n```\n\n## 🔧 Installation\n\n### VSCode (Roo Cline)\n\nAdd to settings file at:\nAdd to settings file at:\n- Windows: `%APPDATA%\\Code\\User\\globalStorage\\rooveterinaryinc.roo-cline\\settings\\cline_mcp_settings.json`\n- MacOS: `~/Library/Application Support/Code/User/globalStorage/rooveterinaryinc.roo-cline/settings/cline_mcp_settings.json`\n- Linux: `~/.config/Code/User/globalStorage/rooveterinaryinc.roo-cline/settings/cline_mcp_settings.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-rtfm\": {\n      \"command\": \"node\",\n      \"args\": [\"<path-to-mcp-rtfm>/build/index.js\"],\n      \"disabled\": false,\n      \"alwaysAllow\": []\n    }\n  }\n}\n```\n\n### Claude Desktop\n\nAdd to config file at:\n- Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n- MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n- Linux: `~/.config/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-rtfm\": {\n      \"command\": \"node\",\n      \"args\": [\"<path-to-mcp-rtfm>/build/index.js\"],\n      \"disabled\": false,\n      \"alwaysAllow\": []\n    }\n  }\n}\n```\n\n## 🎯 Advanced Features\n\n### Content Linking\n\nUse `[[document-name]]` syntax to create links between documents. The server automatically tracks these relationships and includes them when finding related documentation.\n\n### Metadata-Driven Organization\n\nDocuments are organized using:\n\n- Categories (e.g., \"architecture\", \"api\", \"workflow\")\n- Tags for flexible grouping\n- Automatic relationship discovery based on shared metadata\n- Content link analysis\n\n### Enhanced Content Analysis\n\nThe server uses advanced libraries for better documentation management:\n\n- **unified/remark** for Markdown processing:\n  - AST-based content analysis\n  - Accurate heading structure detection\n  - Code block and link extraction\n  - Proper Markdown parsing and manipulation\n\n- **minisearch** for powerful search capabilities:\n  - Fast fuzzy searching across all documentation\n  - Field-weighted search (titles given higher priority)\n  - Full content and metadata indexing\n  - Efficient caching with TTL management\n  - Real-time search index updates\n\n### Intelligent Metadata Generation\n\n- Automatic content analysis for categorization\n- Smart tag generation based on content patterns\n- Structured front matter in documents\n- AST-based title and section detection\n- Code snippet identification and tagging\n- Context-aware result presentation\n\n### Template System\n\n- Built-in templates for common documentation types\n- Custom template support with metadata defaults\n- Template inheritance and override capabilities\n- Placeholder system for consistent formatting\n\n## 🛠️ Development\n\n```bash\n# Install dependencies\nnpm install\n\n# Build the server\nnpm run build\n\n# Development with auto-rebuild\nnpm run watch\n```\n\n## 🐛 Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. Use the [MCP Inspector](https://github.com/modelcontextprotocol/inspector):\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n\n## 📄 License\n\nMIT © [Model Context Protocol](https://github.com/modelcontextprotocol)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "documentation",
        "document",
        "rtfm",
        "rtfm facilitates",
        "document processing",
        "documentation content"
      ],
      "category": "document-processing"
    },
    "samaraxmmar--Deepseek_chat_rag": {
      "owner": "samaraxmmar",
      "name": "Deepseek_chat_rag",
      "url": "https://github.com/samaraxmmar/Deepseek_chat_rag",
      "imageUrl": "/freedevtools/mcp/pfp/samaraxmmar.webp",
      "description": "Utilizes advanced retrieval-augmented generation models to answer queries based on indexed documents extracted from various file formats. Engages users by providing relevant answers from a Chroma database that stores extracted text from PDF, DOCX, TXT, and CSV files.",
      "stars": 1,
      "forks": 0,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-06-14T12:03:25Z",
      "readme_content": "# DeepSeek RAG Chatbot 🤖\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/deepseek-ai/DeepSeek-V2/refs/heads/main/figures/logo.svg\" alt=\"DeepSeek RAG Chatbot Banner\" width=\"700\">\n</p>\n\n<p align=\"center\">\n    <b>An intelligent chatbot powered by Groq, LangChain, and ChromaDB to chat with your documents.</b>\n<br/><br/>\n    <a href=\"https://github.com/samaraxmmar/Deepseek_chat_rag/issues\"><img src=\"https://img.shields.io/github/issues/samaraxmmar/Deepseek_chat_rag?style=for-the-badge&color=brightgreen\" alt=\"Issues\"></a>\n    <a href=\"https://github.com/samaraxmmar/Deepseek_chat_rag/stargazers\"><img src=\"https://img.shields.io/github/stars/samaraxmmar/Deepseek_chat_rag?style=for-the-badge&color=f0c60f\" alt=\"Stars\"></a>\n    <a href=\"https://github.com/samaraxmmar/Deepseek_chat_rag/blob/main/LICENSE\"><img src=\"https://img.shields.io/github/license/samaraxmmar/Deepseek_chat_rag?style=for-the-badge&color=blue\" alt=\"License\"></a>\n</p>\n\n---\n\n## 🌟 Introduction\n\n**DeepSeek RAG Chatbot** is a powerful and intuitive application that allows you to have conversations with your own documents. By leveraging the speed of the **Groq LPU Inference Engine** and the versatility of **LangChain**, this tool transforms your static files (PDFs, DOCX, TXT, CSV) into an interactive knowledge base.\n\nSimply upload your documents, and the system will automatically process, index, and prepare them for your questions. The user-friendly interface, built with **Streamlit**, makes it easy for anyone to get instant, accurate answers drawn directly from the provided content.\n\n## ✨ Key Features\n\n* **Multi-Format Document Support**: Upload and process various file types, including `.pdf`, `.docx`, `.txt`, and `.csv`.\n* **High-Speed Inferencing**: Powered by **Groq**, delivering responses at exceptional speed for a fluid, real-time conversational experience.\n* **Advanced RAG Pipeline**: Utilizes **LangChain** for robust Retrieval-Augmented Generation, ensuring answers are relevant and contextually accurate.\n* **Efficient Vector Storage**: Employs **ChromaDB** to create and manage a persistent vector database of your document embeddings for fast retrieval.\n* **User-Friendly Interface**: A clean and simple web UI built with **Streamlit** that includes real-time processing feedback and chat history.\n* **Open Source & Customizable**: Fully open-source, allowing for easy customization and integration into other projects.\n\n## ⚙️ How It Works\n\nThe application follows a sophisticated Retrieval-Augmented Generation (RAG) architecture to provide answers from your documents.\n\n<p align=\"center\">\n  <img src=\"https://www.deepchecks.com/wp-content/uploads/2024/10/img-rag-architecture-model.jpg\" alt=\"RAG Architecture Diagram\" width=\"700\">\n</p>\n\n1.  **Document Loading**: You upload your documents (PDF, DOCX, etc.) through the Streamlit interface.\n2.  **Text Splitting & Embedding**: The system loads the documents, splits them into smaller, manageable chunks, and generates vector embeddings for each chunk.\n3.  **Vector Indexing**: These embeddings are stored in a **ChromaDB** vectorstore, creating a searchable index of your document's knowledge.\n4.  **User Query**: You ask a question in the chat interface.\n5.  **Context Retrieval**: The system takes your query, embeds it, and performs a similarity search in ChromaDB to retrieve the most relevant document chunks (the \"context\").\n6.  **Response Generation**: The retrieved context and your original query are passed to the **Groq**-powered language model, which generates a human-like, accurate answer based on the provided information.\n\n## 🚀 Getting Started\n\nFollow these steps to set up and run the project on your local machine.\n\n### Prerequisites\n\n* Python 3.8+\n* A Groq API Key. You can get one for free at [GroqCloud](https://console.groq.com/keys).\n\n### 1. Clone the Repository\n\n```bash\ngit clone [https://github.com/samaraxmmar/Deepseek_chat_rag.git](https://github.com/samaraxmmar/Deepseek_chat_rag.git)\ncd Deepseek_chat_rag\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "retrieval",
        "samaraxmmar",
        "documents",
        "document processing",
        "samaraxmmar deepseek_chat_rag",
        "processing samaraxmmar"
      ],
      "category": "document-processing"
    },
    "sammcj--mcp-data-extractor": {
      "owner": "sammcj",
      "name": "mcp-data-extractor",
      "url": "https://github.com/sammcj/mcp-data-extractor",
      "imageUrl": "/freedevtools/mcp/pfp/sammcj.webp",
      "description": "Extracts embedded data such as i18n translations and configurations from TypeScript and JavaScript source code, converting them into structured JSON files while preserving the hierarchical structure and template variables.",
      "stars": 8,
      "forks": 3,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-03T22:32:57Z",
      "readme_content": "# mcp-data-extractor MCP Server\n\nA Model Context Protocol server that extracts embedded data (such as i18n translations or key/value configurations) from TypeScript/JavaScript source code into structured JSON configuration files.\n\n[![smithery badge](https://smithery.ai/badge/mcp-data-extractor)](https://smithery.ai/server/mcp-data-extractor)\n\n<a href=\"https://glama.ai/mcp/servers/40c3iyazm5\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/40c3iyazm5/badge\" alt=\"MCP Data Extractor MCP server\" /></a>\n\n## Features\n\n- Data Extraction:\n  - Extracts string literals, template literals, and complex nested objects\n  - Preserves template variables (e.g., `Hello, {{name}}!`)\n  - Supports nested object structures and arrays\n  - Maintains hierarchical key structure using dot notation\n  - Handles both TypeScript and JavaScript files with JSX support\n  - Replaces source file content with \"MIGRATED TO <target absolute path>\" after successful extraction (configurable)\n\n- SVG Extraction:\n  - Extracts SVG components from React/TypeScript/JavaScript files\n  - Preserves SVG structure and attributes\n  - Removes React-specific code and props\n  - Creates individual .svg files named after their component\n  - Replaces source file content with \"MIGRATED TO <target absolute path>\" after successful extraction (configurable)\n\n## Usage\n\nAdd to your MCP Client configuration:\n\n```bash\n{\n  \"mcpServers\": {\n    \"data-extractor\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"mcp-data-extractor\"\n      ],\n      \"disabled\": false,\n      \"autoApprove\": [\n        \"extract_data\",\n        \"extract_svg\"\n      ]\n    }\n  }\n}\n```\n\n### Basic Usage\n\nThe server provides two tools:\n\n#### 1. Data Extraction\n\nUse `extract_data` to extract data (like i18n translations) from source files:\n\n```typescript\n<use_mcp_tool>\n<server_name>data-extractor</server_name>\n<tool_name>extract_data</tool_name>\n<arguments>\n{\n  \"sourcePath\": \"src/translations.ts\",\n  \"targetPath\": \"src/translations.json\"\n}\n</arguments>\n</use_mcp_tool>\n```\n\n#### 2. SVG Extraction\n\nUse `extract_svg` to extract SVG components into individual files:\n\n```typescript\n<use_mcp_tool>\n<server_name>data-extractor</server_name>\n<tool_name>extract_svg</tool_name>\n<arguments>\n{\n  \"sourcePath\": \"src/components/icons/InspectionIcon.tsx\",\n  \"targetDir\": \"src/assets/icons\"\n}\n</arguments>\n</use_mcp_tool>\n```\n\n### Source File Replacement\n\nBy default, after successful extraction, the server will replace the content of the source file with:\n- \"MIGRATED TO <target path>\" for data extraction\n- \"MIGRATED TO <target directory>\" for SVG extraction\n\nThis helps track which files have already been processed and prevents duplicate extraction. It also makes it easy for LLMs and developers to see where the extracted data now lives when they encounter the source file later.\n\nTo disable this behavior, set the `DISABLE_SOURCE_REPLACEMENT` environment variable to `true` in your MCP configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"data-extractor\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"mcp-data-extractor\"\n      ],\n      \"env\": {\n        \"DISABLE_SOURCE_REPLACEMENT\": \"true\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": [\n        \"extract_data\",\n        \"extract_svg\"\n      ]\n    }\n  }\n}\n```\n\n### Supported Patterns\n\n#### Data Extraction Patterns\n\nThe data extractor supports various patterns commonly used in TypeScript/JavaScript applications:\n\n1. Simple Object Exports:\n```typescript\nexport default {\n  welcome: \"Welcome to our app\",\n  greeting: \"Hello, {name}!\",\n  submit: \"Submit form\"\n};\n```\n\n2. Nested Objects:\n```typescript\nexport default {\n  header: {\n    title: \"Book Your Flight\",\n    subtitle: \"Find the best deals\"\n  },\n  footer: {\n    content: [\n      \"Please refer to {{privacyPolicyUrl}} for details\",\n      \"© {{year}} {{companyName}}\"\n    ]\n  }\n};\n```\n\n3. Complex Structures with Arrays:\n```typescript\nexport default {\n  faq: {\n    heading: \"Common questions\",\n    content: [\n      {\n        heading: \"What if I need to change my flight?\",\n        content: \"You can change your flight online if:\",\n        list: [\n          \"You have a flexible fare type\",\n          \"Your flight is more than 24 hours away\"\n        ]\n      }\n    ]\n  }\n};\n```\n\n4. Template Literals with Variables:\n```typescript\nexport default {\n  greeting: `Hello, {{username}}!`,\n  message: `Welcome to {{appName}}`\n};\n```\n\n### Output Formats\n\n#### Data Extraction Output\n\nThe extracted data is saved as a JSON file with dot notation for nested structures:\n\n```json\n{\n  \"welcome\": \"Welcome to our app\",\n  \"header.title\": \"Book Your Flight\",\n  \"footer.content.0\": \"Please refer to {{privacyPolicyUrl}} for details\",\n  \"footer.content.1\": \"© {{year}} {{companyName}}\",\n  \"faq.content.0.heading\": \"What if I need to change my flight?\"\n}\n```\n\n#### SVG Extraction Output\n\nSVG components are extracted into individual .svg files, with React-specific code removed. For example:\n\nInput (React component):\n```tsx\nconst InspectionIcon: React.FC<InspectionIconProps> = ({ title }) => (\n  <svg className=\"c-tab__icon\" width=\"40px\" id=\"Layer_1\" data-name=\"Layer 1\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 32 32\">\n    <title>{title}</title>\n    <path className=\"cls-1\" d=\"M18.89,12.74a3.18,3.18,0,0,1-3.24-3.11...\" />\n  </svg>\n);\n```\n\nOutput (InspectionIcon.svg):\n```svg\n<svg width=\"40px\" id=\"Layer_1\" data-name=\"Layer 1\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 32 32\">\n    <path class=\"cls-1\" d=\"M18.89,12.74a3.18,3.18,0,0,1-3.24-3.11...\" />\n</svg>\n```\n\n## Extending Supported Patterns\n\nThe extractor uses Babel to parse and traverse the AST (Abstract Syntax Tree) of your source files. You can extend the supported patterns by modifying the source code:\n\n1. **Add New Node Types**: The `extractStringValue` method in `src/index.ts` handles different types of string values. Extend it to support new node types:\n\n```typescript\nprivate extractStringValue(node: t.Node): string | null {\n  if (t.isStringLiteral(node)) {\n    return node.value;\n  } else if (t.isTemplateLiteral(node)) {\n    return node.quasis.map(quasi => quasi.value.raw).join('{{}}');\n  }\n  // Add support for new node types here\n  return null;\n}\n```\n\n2. **Custom Value Processing**: The `processValue` method handles different value types (strings, arrays, objects). Extend it to support new value types or custom processing:\n\n```typescript\nprivate processValue(value: t.Node, currentPath: string[]): void {\n  if (t.isStringLiteral(value) || t.isTemplateLiteral(value)) {\n    // Process string values\n  } else if (t.isArrayExpression(value)) {\n    // Process arrays\n  } else if (t.isObjectExpression(value)) {\n    // Process objects\n  }\n  // Add support for new value types here\n}\n```\n\n3. **Custom AST Traversal**: The server uses Babel's traverse to walk the AST. You can add new visitors to handle different node types:\n\n```typescript\ntraverse(ast, {\n  ExportDefaultDeclaration(path: NodePath<t.ExportDefaultDeclaration>) {\n    // Handle default exports\n  },\n  // Add new visitors here\n});\n```\n\n## Development\n\nInstall dependencies:\n```bash\nnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n```bash\nnpm run watch\n```\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "sammcj",
        "extractor",
        "mcp",
        "processing sammcj",
        "sammcj mcp",
        "data extractor"
      ],
      "category": "document-processing"
    },
    "sanderkooger--mcp-server-ragdocs": {
      "owner": "sanderkooger",
      "name": "mcp-server-ragdocs",
      "url": "https://github.com/sanderkooger/mcp-server-ragdocs",
      "imageUrl": "/freedevtools/mcp/pfp/sanderkooger.webp",
      "description": "Retrieve and process documentation using vector search to enhance AI responses. Enable the creation of documentation-aware AI assistants and context-aware tooling for developers.",
      "stars": 23,
      "forks": 4,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-08-22T19:11:35Z",
      "readme_content": "# MCP-server-ragdocs\n[![Node.js Package](https://github.com/sanderkooger/mcp-server-ragdocs/actions/workflows/release.yml/badge.svg)](https://github.com/sanderkooger/mcp-server-ragdocs/actions/workflows/release.yml)\n![NPM Downloads](https://img.shields.io/npm/dy/%40sanderkooger%2Fmcp-server-ragdocs)\n[![Version](https://img.shields.io/npm/v/@sanderkooger/mcp-server-ragdocs)](https://npmjs.com/package/@sanderkooger/mcp-server-ragdocs)\n[![codecov](https://codecov.io/gh/sanderkooger/mcp-server-ragdocs/branch/main/graph/badge.svg)](https://codecov.io/gh/sanderkooger/mcp-server-ragdocs)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\nAn MCP server implementation that provides tools for retrieving and processing documentation through vector search, enabling AI assistants to augment their responses with relevant documentation context.\n\n## Table of Contents\n\n- [Usage](#usage)\n- [Features](#features)\n- [Configuration](#configuration)\n- [Deployment](#deployment)\n  - [Local Development](#local-development)\n  - [Cloud Deployment](#cloud-deployment)\n- [Playwright Integration](#playwright-integration)\n- [Tools](#tools)\n- [Project Structure](#project-structure)\n- [Using Ollama Embeddings](#using-ollama-embeddings)\n- [License](#license)\n- [Development Workflow](#development-workflow)\n- [Contributing](#contributing)\n- [Forkception Acknowledgments](#forkception-acknowledgments)\n\n## Usage\n\nThe RAG Documentation tool is designed for:\n\n- Enhancing AI responses with relevant documentation\n- Building documentation-aware AI assistants\n- Creating context-aware tooling for developers\n- Implementing semantic documentation search\n- Augmenting existing knowledge bases\n\n## Features\n\n- Vector-based documentation search and retrieval\n- Support for multiple documentation sources\n- Support for local (Ollama) embeddings generation or OPENAI\n- Semantic search capabilities\n- Automated documentation processing\n- Real-time context augmentation for LLMs\n\n## Configuration\n\n```json\n{\n  \"mcpServers\": {\n    \"rag-docs\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@sanderkooger/mcp-server-ragdocs\"],\n      \"env\": {\n        \"EMBEDDINGS_PROVIDER\": \"ollama\",\n        \"QDRANT_URL\": \"your-qdrant-url\",\n        \"QDRANT_API_KEY\": \"your-qdrant-key\" # if applicable\n      }\n    }\n  }\n}\n```\n\n### Usage with Claude Desktop\n\nAdd this to your `claude_desktop_config.json`:\n\n### OpenAI Configuration\n\n```json\n{\n  \"mcpServers\": {\n    \"rag-docs-openai\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@sanderkooger/mcp-server-ragdocs\"],\n      \"env\": {\n        \"EMBEDDINGS_PROVIDER\": \"openai\",\n        \"OPENAI_API_KEY\": \"your-openai-key-here\",\n        \"QDRANT_URL\": \"your-qdrant-url\",\n        \"QDRANT_API_KEY\": \"your-qdrant-key\"\n      }\n    }\n  }\n}\n```\n\n### Ollama Configuration\n\n```json\n{\n  \"mcpServers\": {\n    \"rag-docs-ollama\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@sanderkooger/mcp-server-ragdocs\"],\n      \"env\": {\n        \"EMBEDDINGS_PROVIDER\": \"ollama\",\n        \"OLLAMA_BASE_URL\": \"http://localhost:11434\",\n        \"QDRANT_URL\": \"your-qdrant-url\",\n        \"QDRANT_API_KEY\": \"your-qdrant-key\"\n      }\n    }\n  }\n}\n```\n\n### Ollama run from this codebase\n```\n\"ragdocs-mcp\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/home/sander/code/mcp-server-ragdocs/build/index.js\"\n      ],\n      \"env\": {\n        \"QDRANT_URL\": \"http://127.0.0.1:6333\",\n        \"EMBEDDINGS_PROVIDER\": \"ollama\",\n        \"OLLAMA_URL\": \"http://localhost:11434\"\n      },\n      \"alwaysAllow\": [\n        \"run_queue\",\n        \"list_queue\",\n        \"list_sources\",\n        \"search_documentation\",\n        \"clear_queue\",\n        \"remove_documentation\",\n        \"extract_urls\"\n      ],\n      \"timeout\": 3600\n    }\n```\n\n\n\n## Environment Variables Reference\n\n| Variable                | Required For  | Default                  | remarks                       |\n|-------------------------|---------------|--------------------------|-------------------------------|\n| `EMBEDDINGS_PROVIDER`   | All           | `ollama`                 | \"openai\" or \"ollama\"          |\n| `OPENAI_API_KEY`        | OpenAI        | -                        | Obtain from OpenAI dashboard  |\n| `OLLAMA_BASE_URL`       | Ollama        | `http://localhost:11434` | Local Ollama server URL       |\n| `QDRANT_URL`            | All           | `http://localhost:6333`  | Qdrant endpoint URL           |\n| `QDRANT_API_KEY`        | Cloud Qdrant  | -                        | From Qdrant Cloud console     |\n| `PLAYWRIGHT_WS_ENDPOINT`| Playwright Remote | -                      | WebSocket endpoint for remote Playwright server (e.g., `ws://localhost:3000/`) |\n\n\n### Local Deployment\n\nThe repository includes Docker Compose configuration for local development:\n\n[Docker Compose Download](https://raw.githubusercontent.com/sanderkooger/mcp-server-ragdocs/main/docker-compose.yml)\n\n```bash\ndocker compose up -d\n```\n\nThis starts:\n\n- Qdrant vector database on port 6333\n- Ollama LLM service on port 11434\n\nAccess endpoints:\n\n- Qdrant: http://localhost:6333\n- Ollama: http://localhost:11434\n\n### Cloud Deployment\n\nFor production deployments:\n\n1. Use hosted Qdrant Cloud service\n2. Set these environment variables:\n\n```bash\nQDRANT_URL=your-cloud-cluster-url\nQDRANT_API_KEY=your-cloud-api-key\n```\n\n## Playwright Integration\n\nThis project supports running Playwright either locally or via a Docker container. This provides flexibility for environments where Playwright's dependencies might be challenging to install directly.\n\n### How it Works\n\nThe `src/api-client.ts` file automatically detects the presence of the `PLAYWRIGHT_WS_ENDPOINT` environment variable:\n\n- **If `PLAYWRIGHT_WS_ENDPOINT` is set**: The application will attempt to connect to a remote Playwright server at the specified WebSocket endpoint using `chromium.connect()`. This is ideal for using a containerized Playwright instance.\n- **If `PLAYWRIGHT_WS_ENDPOINT` is not set**: The application will launch a local Playwright browser instance using `chromium.launch()`.\n\n### Running Playwright in Docker\n\nA `playwright` service has been added to the `docker-compose.yml` file to facilitate running Playwright in a Docker container.\n\nTo start the Playwright server in Docker:\n\n```bash\ndocker-compose up playwright\n```\n\nThis command will pull the `mcr.microsoft.com/playwright:v1.53.0-noble` image and start a Playwright server accessible on port `3000` of your host machine.\n\nTo configure your application to use this containerized Playwright instance, set the following environment variable:\n\n```bash\nPLAYWRIGHT_WS_ENDPOINT=ws://localhost:3000/\n```\n\n## Tools\n\n### search_documentation\n\nSearch through stored documentation using natural language queries. Returns matching excerpts with context, ranked by relevance.\n\n**Inputs:**\n\n- `query` (string): The text to search for in the documentation. Can be a natural language query, specific terms, or code snippets.\n- `limit` (number, optional): Maximum number of results to return (1-20, default: 5). Higher limits provide more comprehensive results but may take longer to process.\n\n### list_sources\n\nList all documentation sources currently stored in the system. Returns a comprehensive list of all indexed documentation including source URLs, titles, and last update times. Use this to understand what documentation is available for searching or to verify if specific sources have been indexed.\n\n### extract_urls\n\nExtract and analyze all URLs from a given web page. This tool crawls the specified webpage, identifies all hyperlinks, and optionally adds them to the processing queue.\n\n**Inputs:**\n\n- `url` (string): The complete URL of the webpage to analyze (must include protocol, e.g., https://). The page must be publicly accessible.\n- `add_to_queue` (boolean, optional): If true, automatically add extracted URLs to the processing queue for later indexing. Use with caution on large sites to avoid excessive queuing.\n\n### remove_documentation\n\nRemove specific documentation sources from the system by their URLs. The removal is permanent and will affect future search results.\n\n**Inputs:**\n\n- `urls` (string[]): Array of URLs to remove from the database. Each URL must exactly match the URL used when the documentation was added.\n\n### list_queue\n\nList all URLs currently waiting in the documentation processing queue. Shows pending documentation sources that will be processed when run_queue is called. Use this to monitor queue status, verify URLs were added correctly, or check processing backlog.\n\n### run_queue\n\nProcess and index all URLs currently in the documentation queue. Each URL is processed sequentially, with proper error handling and retry logic. Progress updates are provided as processing occurs. Long-running operations will process until the queue is empty or an unrecoverable error occurs.\n\n### clear_queue\n\nRemove all pending URLs from the documentation processing queue. Use this to reset the queue when you want to start fresh, remove unwanted URLs, or cancel pending processing. This operation is immediate and permanent - URLs will need to be re-added if you want to process them later.\n\n## Project Structure\n\nThe package follows a modular architecture with clear separation between core components and MCP protocol handlers. See [ARCHITECTURE.md](ARCHITECTURE.md) for detailed structural documentation and design decisions.\n\n## Using Ollama Embeddings without docker\n\n1. Install Ollama:\n\n```bash\ncurl -fsSL https://ollama.com/install.sh | sh\n```\n\n2. Download the nomic-embed-text model:\n\n```bash\nollama pull nomic-embed-text\n```\n\n3. Verify installation:\n\n```bash\nollama list\n```\n\n## License\n\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.\n\n## Contributing\n\nWe welcome contributions! Please see our [CONTRIBUTING.md](CONTRIBUTING.md) for detailed guidelines, but here are the basics:\n\n1. Fork the repository\n2. Install dependencies: `npm install`\n3. Create a feature branch: `git checkout -b feat/your-feature`\n4. Commit changes with npm run commit to ensure compliance with [Conventional Commits](https://www.conventionalcommits.org)\n5. Push to your fork and open a PR\n\n## Forkception Acknowledgments\n\nThis project is based on a fork of [hannesrudolph/mcp-ragdocs](https://github.com/hannesrudolph/mcp-ragdocs), which itself was forked from the original work by [qpd-v/mcp-ragdocs](https://github.com/qpd-v/mcp-ragdocs). The original project provided the foundation for this implementation.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "documentation",
        "ai",
        "document",
        "documentation aware",
        "document processing",
        "ai assistants"
      ],
      "category": "document-processing"
    },
    "scmdr--sourcesyncai-mcp": {
      "owner": "scmdr",
      "name": "sourcesyncai-mcp",
      "url": "https://github.com/scmdr/sourcesyncai-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/scmdr.webp",
      "description": "Integrate and manage knowledge from various data sources using a standardized interface to retrieve and update documents. Perform semantic searches and manage connections to external services within a knowledge management platform.",
      "stars": 0,
      "forks": 4,
      "license": "No License",
      "language": "",
      "updated_at": "2025-03-03T15:18:06Z",
      "readme_content": "# SourceSync.ai MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@pbteja1998/sourcesyncai-mcp)](https://smithery.ai/server/@pbteja1998/sourcesyncai-mcp)\n\nA Model Context Protocol (MCP) server implementation for the [SourceSync.ai](https://sourcesync.ai) API. This server allows AI models to interact with SourceSync.ai's knowledge management platform through a standardized interface.\n\n## Features\n\n- Manage namespaces for organizing knowledge\n- Ingest content from various sources (text, URLs, websites, external services)\n- Retrieve, update, and manage documents stored in your knowledge base\n- Perform semantic and hybrid searches against your knowledge base\n- Access document content directly from parsed text URLs\n- Manage connections to external services\n- Default configuration support for seamless AI integration\n\n## Installation\n\n### Running with npx\n\n```bash\n# Install and run with your API key and tenant ID\nenv SOURCESYNC_API_KEY=your_api_key npx -y sourcesyncai-mcp\n```\n\n### Installing via Smithery\n\nTo install sourcesyncai-mcp for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@pbteja1998/sourcesyncai-mcp):\n\n```bash\nnpx -y @smithery/cli install @pbteja1998/sourcesyncai-mcp --client claude\n```\n\n### Manual Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/yourusername/sourcesyncai-mcp.git\ncd sourcesyncai-mcp\n\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n\n# Run the server\nnode dist/index.js\n```\n\n### Running on Cursor\n\nTo configure SourceSync.ai MCP in Cursor:\n\n1. Open Cursor Settings\n1. Go to `Features > MCP Servers`\n1. Click `+ Add New MCP Server`\n1. Enter the following:\n   - Name: `sourcesyncai-mcp` (or your preferred name)\n   - Type: `command`\n   - Command: `env SOURCESYNCAI_API_KEY=your-api-key npx -y sourcesyncai-mcp`\n\nAfter adding, you can use SourceSync.ai tools with Cursor's AI features by describing your knowledge management needs.\n\n### Running on Windsurf\n\nAdd this to your `./codeium/windsurf/model_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"sourcesyncai-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"soucesyncai-mcp\"],\n      \"env\": {\n        \"SOURCESYNC_API_KEY\": \"your_api_key\",\n        \"SOURCESYNC_NAMESPACE_ID\": \"your_namespace_id\",\n        \"SOURCESYNC_TENANT_ID\": \"your_tenant_id\"\n      }\n    }\n  }\n}\n```\n\n### Running on Claude Desktop\n\nTo use this MCP server with Claude Desktop:\n\n1. Locate the Claude Desktop configuration file:\n\n   - **macOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - **Windows**: `%APPDATA%\\Claude\\claude_desktop_config.json`\n   - **Linux**: `~/.config/Claude/claude_desktop_config.json`\n\n2. Edit the configuration file to add the SourceSync.ai MCP server:\n\n```json\n{\n  \"mcpServers\": {\n    \"sourcesyncai-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"sourcesyncai-mcp\"],\n      \"env\": {\n        \"SOURCESYNC_API_KEY\": \"your_api_key\",\n        \"SOURCESYNC_NAMESPACE_ID\": \"your_namespace_id\",\n        \"SOURCESYNC_TENANT_ID\": \"your_tenant_id\"\n      }\n    }\n  }\n}\n```\n\n3. Save the configuration file and restart Claude Desktop\n\n## Configuration\n\n### Environment Variables\n\n#### Required\n\n- `SOURCESYNC_API_KEY`: Your SourceSync.ai API key (required)\n\n#### Optional\n\n- `SOURCESYNC_NAMESPACE_ID`: Default namespace ID to use for operations\n- `SOURCESYNC_TENANT_ID`: Your tenant ID (optional)\n\n### Configuration Examples\n\nBasic configuration with default values:\n\n```bash\nexport SOURCESYNC_API_KEY=your_api_key\nexport SOURCESYNC_TENANT_ID=your_tenant_id\nexport SOURCESYNC_NAMESPACE_ID=your_namespace_id\n```\n\n## Available Tools\n\n### Authentication\n\n- `validate_api_key`: Validate a SourceSync.ai API key\n\n```json\n{\n  \"name\": \"validate_api_key\",\n  \"arguments\": {}\n}\n```\n\n### Namespaces\n\n- `create_namespace`: Create a new namespace\n- `list_namespaces`: List all namespaces\n- `get_namespace`: Get details of a specific namespace\n- `update_namespace`: Update a namespace\n- `delete_namespace`: Delete a namespace\n\n```json\n{\n  \"name\": \"create_namespace\",\n  \"arguments\": {\n    \"name\": \"my-namespace\",\n    \"fileStorageConfig\": {\n      \"provider\": \"S3_COMPATIBLE\",\n      \"config\": {\n        \"endpoint\": \"s3.amazonaws.com\",\n        \"accessKey\": \"your_access_key\",\n        \"secretKey\": \"your_secret_key\",\n        \"bucket\": \"your_bucket\",\n        \"region\": \"us-east-1\"\n      }\n    },\n    \"vectorStorageConfig\": {\n      \"provider\": \"PINECONE\",\n      \"config\": {\n        \"apiKey\": \"your_pinecone_api_key\",\n        \"environment\": \"your_environment\",\n        \"index\": \"your_index\"\n      }\n    },\n    \"embeddingModelConfig\": {\n      \"provider\": \"OPENAI\",\n      \"config\": {\n        \"apiKey\": \"your_openai_api_key\",\n        \"model\": \"text-embedding-3-small\"\n      }\n    },\n    \"tenantId\": \"tenant_XXX\"\n  }\n}\n```\n\n```json\n{\n  \"name\": \"list_namespaces\",\n  \"arguments\": {\n    \"tenantId\": \"tenant_XXX\"\n  }\n}\n```\n\n```json\n{\n  \"name\": \"get_namespace\",\n  \"arguments\": {\n    \"namespaceId\": \"namespace_XXX\",\n    \"tenantId\": \"tenant_XXX\"\n  }\n}\n```\n\n```json\n{\n  \"name\": \"update_namespace\",\n  \"arguments\": {\n    \"namespaceId\": \"namespace_XXX\",\n    \"tenantId\": \"tenant_XXX\",\n    \"name\": \"updated-namespace-name\"\n  }\n}\n```\n\n```json\n{\n  \"name\": \"delete_namespace\",\n  \"arguments\": {\n    \"namespaceId\": \"namespace_XXX\",\n    \"tenantId\": \"tenant_XXX\"\n  }\n}\n```\n\n### Data Ingestion\n\n- `ingest_text`: Ingest text content\n- `ingest_urls`: Ingest content from URLs\n- `ingest_sitemap`: Ingest content from a sitemap\n- `ingest_website`: Ingest content from a website\n- `ingest_notion`: Ingest content from Notion\n- `ingest_google_drive`: Ingest content from Google Drive\n- `ingest_dropbox`: Ingest content from Dropbox\n- `ingest_onedrive`: Ingest content from OneDrive\n- `ingest_box`: Ingest content from Box\n- `get_ingest_job_run_status`: Get the status of an ingestion job run\n\n```json\n{\n  \"name\": \"ingest_text\",\n  \"arguments\": {\n    \"namespaceId\": \"your_namespace_id\",\n    \"ingestConfig\": {\n      \"source\": \"TEXT\",\n      \"config\": {\n        \"name\": \"example-document\",\n        \"text\": \"This is an example document for ingestion.\",\n        \"metadata\": {\n          \"category\": \"example\",\n          \"author\": \"AI Assistant\"\n        }\n      }\n    },\n    \"tenantId\": \"tenant_XXX\"\n  }\n}\n```\n\n```json\n{\n  \"name\": \"ingest_urls\",\n  \"arguments\": {\n    \"namespaceId\": \"your_namespace_id\",\n    \"ingestConfig\": {\n      \"source\": \"URLS\",\n      \"config\": {\n        \"urls\": [\"https://example.com/page1\", \"https://example.com/page2\"],\n        \"metadata\": {\n          \"source\": \"web\",\n          \"category\": \"documentation\"\n        }\n      }\n    },\n    \"tenantId\": \"tenant_XXX\"\n  }\n}\n```\n\n```json\n{\n  \"name\": \"ingest_sitemap\",\n  \"arguments\": {\n    \"namespaceId\": \"your_namespace_id\",\n    \"ingestConfig\": {\n      \"source\": \"SITEMAP\",\n      \"config\": {\n        \"url\": \"https://example.com/sitemap.xml\",\n        \"metadata\": {\n          \"source\": \"sitemap\",\n          \"website\": \"example.com\"\n        }\n      }\n    },\n    \"tenantId\": \"tenant_XXX\"\n  }\n}\n```\n\n```json\n{\n  \"name\": \"ingest_website\",\n  \"arguments\": {\n    \"namespaceId\": \"your_namespace_id\",\n    \"ingestConfig\": {\n      \"source\": \"WEBSITE\",\n      \"config\": {\n        \"url\": \"https://example.com\",\n        \"maxDepth\": 3,\n        \"maxPages\": 100,\n        \"metadata\": {\n          \"source\": \"website\",\n          \"domain\": \"example.com\"\n        }\n      }\n    },\n    \"tenantId\": \"tenant_XXX\"\n  }\n}\n```\n\n```json\n{\n  \"name\": \"ingest_notion\",\n  \"arguments\": {\n    \"namespaceId\": \"your_namespace_id\",\n    \"ingestConfig\": {\n      \"source\": \"NOTION\",\n      \"config\": {\n        \"connectionId\": \"your_notion_connection_id\",\n        \"metadata\": {\n          \"source\": \"notion\",\n          \"workspace\": \"My Workspace\"\n        }\n      }\n    },\n    \"tenantId\": \"your_tenant_id\"\n  }\n}\n```\n\n```json\n{\n  \"name\": \"ingest_google_drive\",\n  \"arguments\": {\n    \"namespaceId\": \"your_namespace_id\",\n    \"ingestConfig\": {\n      \"source\": \"GOOGLE_DRIVE\",\n      \"config\": {\n        \"connectionId\": \"connection_XXX\",\n        \"metadata\": {\n          \"source\": \"google_drive\",\n          \"owner\": \"user@example.com\"\n        }\n      }\n    },\n    \"tenantId\": \"tenant_XXX\"\n  }\n}\n```\n\n```json\n{\n  \"name\": \"ingest_dropbox\",\n  \"arguments\": {\n    \"namespaceId\": \"your_namespace_id\",\n    \"ingestConfig\": {\n      \"source\": \"DROPBOX\",\n      \"config\": {\n        \"connectionId\": \"connection_XXX\",\n        \"metadata\": {\n          \"source\": \"dropbox\",\n          \"account\": \"user@example.com\"\n        }\n      }\n    },\n    \"tenantId\": \"tenant_XXX\"\n  }\n}\n```\n\n```json\n{\n  \"name\": \"ingest_onedrive\",\n  \"arguments\": {\n    \"namespaceId\": \"your_namespace_id\",\n    \"ingestConfig\": {\n      \"source\": \"ONEDRIVE\",\n      \"config\": {\n        \"connectionId\": \"connection_XXX\",\n        \"metadata\": {\n          \"source\": \"onedrive\",\n          \"account\": \"user@example.com\"\n        }\n      }\n    },\n    \"tenantId\": \"tenant_XXX\"\n  }\n}\n```\n\n```json\n{\n  \"name\": \"ingest_box\",\n  \"arguments\": {\n    \"namespaceId\": \"your_namespace_id\",\n    \"ingestConfig\": {\n      \"source\": \"BOX\",\n      \"config\": {\n        \"connectionId\": \"connection_XXX\",\n        \"metadata\": {\n          \"source\": \"box\",\n          \"owner\": \"user@example.com\"\n        }\n      }\n    },\n    \"tenantId\": \"tenant_XXX\"\n  }\n}\n```\n\n```json\n{\n  \"name\": \"get_ingest_job_run_status\",\n  \"arguments\": {\n    \"namespaceId\": \"your_namespace_id\",\n    \"ingestJobRunId\": \"ingest_job_run_XXX\",\n    \"tenantId\": \"tenant_XXX\"\n  }\n}\n```\n\n### Documents\n\n- `getDocuments`: Retrieve documents with optional filters\n- `updateDocuments`: Update document metadata\n- `deleteDocuments`: Delete documents\n- `resyncDocuments`: Resync documents\n- `fetchUrlContent`: Fetch text content from document URLs\n\n```json\n{\n  \"name\": \"getDocuments\",\n  \"arguments\": {\n    \"namespaceId\": \"namespace_XXX\",\n    \"tenantId\": \"tenant_XXX\",\n    \"filterConfig\": {\n      \"documentTypes\": [\"PDF\"]\n    },\n    \"includeConfig\": {\n      \"parsedTextFileUrl\": true\n    }\n  }\n}\n```\n\n```json\n{\n  \"name\": \"updateDocuments\",\n  \"arguments\": {\n    \"namespaceId\": \"namespace_XXX\",\n    \"tenantId\": \"tenant_XXX\",\n    \"documentIds\": [\"doc_XXX\", \"doc_YYY\"],\n    \"filterConfig\": {\n      \"documentIds\": [\"doc_XXX\", \"doc_YYY\"]\n    },\n    \"data\": {\n      \"metadata\": {\n        \"status\": \"reviewed\",\n        \"category\": \"technical\"\n      }\n    }\n  }\n}\n```\n\n```json\n{\n  \"name\": \"deleteDocuments\",\n  \"arguments\": {\n    \"namespaceId\": \"namespace_XXX\",\n    \"tenantId\": \"tenant_XXX\",\n    \"documentIds\": [\"doc_XXX\", \"doc_YYY\"],\n    \"filterConfig\": {\n      \"documentIds\": [\"doc_XXX\", \"doc_YYY\"]\n    }\n  }\n}\n```\n\n```json\n{\n  \"name\": \"resyncDocuments\",\n  \"arguments\": {\n    \"namespaceId\": \"namespace_XXX\",\n    \"tenantId\": \"tenant_XXX\",\n    \"documentIds\": [\"doc_XXX\", \"doc_YYY\"],\n    \"filterConfig\": {\n      \"documentIds\": [\"doc_XXX\", \"doc_YYY\"]\n    }\n  }\n}\n```\n\n```json\n{\n  \"name\": \"fetchUrlContent\",\n  \"arguments\": {\n    \"url\": \"https://api.sourcesync.ai/v1/documents/doc_XXX/content?format=text\",\n    \"apiKey\": \"your_api_key\",\n    \"tenantId\": \"tenant_XXX\"\n  }\n}\n```\n\n### Search\n\n- `semantic_search`: Perform semantic search\n- `hybrid_search`: Perform hybrid search (semantic + keyword)\n\n```json\n{\n  \"name\": \"semantic_search\",\n  \"arguments\": {\n    \"namespaceId\": \"your_namespace_id\",\n    \"query\": \"example document\",\n    \"topK\": 5,\n    \"tenantId\": \"tenant_XXX\"\n  }\n}\n```\n\n```json\n{\n  \"name\": \"hybrid_search\",\n  \"arguments\": {\n    \"namespaceId\": \"your_namespace_id\",\n    \"query\": \"example document\",\n    \"topK\": 5,\n    \"tenantId\": \"tenant_XXX\",\n    \"hybridConfig\": {\n      \"semanticWeight\": 0.7,\n      \"keywordWeight\": 0.3\n    }\n  }\n}\n```\n\n### Connections\n\n- `create_connection`: Create a new connection to an external service\n- `list_connections`: List all connections\n- `get_connection`: Get details of a specific connection\n- `update_connection`: Update a connection\n- `revoke_connection`: Revoke a connection\n\n```json\n{\n  \"name\": \"create_connection\",\n  \"arguments\": {\n    \"tenantId\": \"tenant_XXX\",\n    \"namespaceId\": \"namespace_XXX\",\n    \"name\": \"My Connection\",\n    \"connector\": \"GOOGLE_DRIVE\",\n    \"clientRedirectUrl\": \"https://your-app.com/callback\"\n  }\n}\n```\n\n```json\n{\n  \"name\": \"list_connections\",\n  \"arguments\": {\n    \"tenantId\": \"tenant_XXX\",\n    \"namespaceId\": \"namespace_XXX\"\n  }\n}\n```\n\n```json\n{\n  \"name\": \"get_connection\",\n  \"arguments\": {\n    \"tenantId\": \"tenant_XXX\",\n    \"namespaceId\": \"namespace_XXX\",\n    \"connectionId\": \"connection_XXX\"\n  }\n}\n```\n\n```json\n{\n  \"name\": \"update_connection\",\n  \"arguments\": {\n    \"tenantId\": \"tenant_XXX\",\n    \"namespaceId\": \"namespace_XXX\",\n    \"connectionId\": \"connection_XXX\",\n    \"name\": \"Updated Connection Name\",\n    \"clientRedirectUrl\": \"https://your-app.com/updated-callback\"\n  }\n}\n```\n\n```json\n{\n  \"name\": \"revoke_connection\",\n  \"arguments\": {\n    \"tenantId\": \"tenant_XXX\",\n    \"namespaceId\": \"namespace_XXX\",\n    \"connectionId\": \"connection_XXX\"\n  }\n}\n```\n\n## Example Prompts\n\nHere are some example prompts you can use with Claude or Cursor after configuring the MCP server:\n\n- \"Search my SourceSync knowledge base for information about machine learning.\"\n- \"Ingest this article into my SourceSync knowledge base: [URL]\"\n- \"Create a new namespace in SourceSync for my project documentation.\"\n- \"List all the documents in my SourceSync namespace.\"\n- \"Get the text content of document [document_id] from my SourceSync namespace.\"\n\n## Troubleshooting\n\n### Connection Issues\n\nIf you encounter issues connecting the SourceSync.ai MCP server:\n\n1. **Verify Paths**: Ensure all paths in your configuration are absolute paths, not relative.\n2. **Check Permissions**: Ensure the server file has execution permissions (`chmod +x dist/index.js`).\n3. **Enable Developer Mode**: In Claude Desktop, enable Developer Mode and check the MCP Log File.\n4. **Test the Server**: Run the server directly from the command line:\n\n   ```bash\n   node /path/to/sourcesyncai-mcp/dist/index.js\n   ```\n\n5. **Restart AI Client**: After making changes, completely restart Claude Desktop or Cursor.\n6. **Check Environment Variables**: Ensure all required environment variables are correctly set.\n\n### Debug Logging\n\nFor detailed logging, add the DEBUG environment variable:\n\n```\n\n```\n\n## Development\n\n### Project Structure\n\n- `src/index.ts`: Main entry point and server setup\n- `src/schemas.ts`: Schema definitions for all tools\n- `src/sourcesync.ts`: Client for interacting with SourceSync.ai API\n- `src/sourcesync.types.ts`: TypeScript type definitions\n\n### Building and Testing\n\n```bash\n# Build the project\nnpm run build\n\n# Run tests\nnpm test\n```\n\n## License\n\nMIT\n\n## Links\n\n- [SourceSync.ai Documentation](https://sourcesync.ai)\n- [SourceSync.ai API Reference](https://sourcesync.ai/api-reference/authentication)\n- [Model Context Protocol](https://modelcontextprotocol.io/introduction)\n\nDocument content retrieval workflow:\n\n1. First, use `getDocuments` with `includeConfig.parsedTextFileUrl: true` to get documents with their content URLs\n2. Extract the URL from the document response\n3. Use `fetchUrlContent` to retrieve the actual content:\n\n```json\n{\n  \"name\": \"fetchUrlContent\",\n  \"arguments\": {\n    \"url\": \"https://example.com\"\n  }\n}\n```\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "scmdr",
        "sourcesyncai",
        "documents",
        "scmdr sourcesyncai",
        "processing scmdr",
        "sourcesyncai mcp"
      ],
      "category": "document-processing"
    },
    "sdairs--claudekeep": {
      "owner": "sdairs",
      "name": "claudekeep",
      "url": "https://github.com/sdairs/claudekeep",
      "imageUrl": "/freedevtools/mcp/pfp/sdairs.webp",
      "description": "A server implementation that enables the saving and sharing of AI conversations from Claude Desktop, featuring both a private chat storage and a public chat display web app. This implementation utilizes the Model Context Protocol (MCP) to manage interactions with AI chat logs.",
      "stars": 10,
      "forks": 6,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-24T20:22:05Z",
      "readme_content": "Anthropic sent a trademark take down notice for claudekeep, so this little experiment is over. The code remains available in case its useful for anyone working with MCP.\n\nIf it wasn't clear enough, Claudekeep is not affiliated in any way with, nor endorsed by, Anthropic.\n\n# ClaudeKeep\n\nClaudeKeep is an experiment with Model Context Protocol (MCP) to save and share your AI conversations from Claude Desktop.\n\nIt includes:\n- an MCP server implementation that allows you to ask Claude to save your chat\n- a web app that allows you to view your private chats and see public chats\n\n## WARNING - THIS IS AN EXPERIMENT\n\nThis is an experiment. Please do not assume that it works perfectly or is secure.\n\nWhile I have done some testing, I make no guarantees that I've caught every edge case to make sure your chats are not exposed. I suggest you don't test it with sensitive chats.\n\n## How to use it?\n\n### 1. Login and get a token\n\nGo to [https://claudekeep.com](https://claudekeep.com) and hit **Login**. This will attempt to log you in via OAuth with GitHub. At the moment, this is the only OAuth provider supported.\n\nOnce logged in, in the top right you'll see a box with a JWT token, copy it.\n\n### 2. Configure Claude Desktop to use the MCP server\n\nTo use with Claude Desktop, you need to add the server config to the following file:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\nUse this config and then restart Claude Desktop (you must completely kill it CMD+Q style and then restart it):\n\n```json\n{\n  \"mcpServers\": {\n    \"claudekeep-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"claudekeep-mcp\"\n      ],\n      \"env\": {\n        \"CLAUDEKEEP_TOKEN\": \"<YOUR_TOKEN>\"\n      }\n    }\n  }\n}\n```\n\nClaude Desktop can be awkward with reading your PATH. See the [MCP readme](./apps/mcp/README.md) for more info if the MCP server doesn't work.\n\n### 3. Select the MCP and chat with Claude\n\nWhen you open Claude Desktop, there is a little paperclip icon. Hover over it and there will be a little plug icon. Click that and pick `default` under `claudekeep-mcp`. This will attach the default prompt to Claude. \n\nNow just chat with Claude as normal.\n\nEvery message you write will trigger the `store_message` tool. This will store the message locally in Claude Desktop.\n\nWhen you want to save your chat, just ask Claude. Claude will run the `save_chat` tool. By default chats are always stored as private. If you want to make your chat public straight away, let claude know when you ask it to save.\n\nFor example (but remember, it's an LLM, it's interpreting your langauge, so you can ask however you want and it will probably hopefully do the right thing):\n\nTo save a a private chat:\n```\nyou: save this chat\n```\n\nTo save a public chat:\n```\nyou: save this chat and make it public\n```\n\n## Need help?\n\nRaise an issue or contact me on [BlueSky](https://bsky.app/profile/alasdairb.com).\n\n## Refresh your token\n\nIf you accidentally expose your token, login and hit the little refresh icon next to the token. You'll see a warning, click the confirm button and it will generate a new token. The old token will be destroyed and is not recoverable.\n\n## Abuse\n\nI hope people are good and don't share dodgy chats, but it's the internet, so 🤷‍♂️ it'll probably happen. I'll do my best to catch it, but please nudge me on BlueSky if I miss something.\n\nNote that your chats are stored against your GitHub account, so while public chats are anonymous to other users, they're not anonymous on the server.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "chat",
        "conversations",
        "document",
        "ai chat",
        "ai conversations",
        "chat storage"
      ],
      "category": "document-processing"
    },
    "seanivore--Convert-Markdown-PDF-MCP": {
      "owner": "seanivore",
      "name": "Convert-Markdown-PDF-MCP",
      "url": "https://github.com/seanivore/Convert-Markdown-PDF-MCP",
      "imageUrl": "/freedevtools/mcp/pfp/seanivore.webp",
      "description": "Converts Markdown files into styled PDF documents using VS Code's markdown formatting and Python's ReportLab. Offers note storage with custom URI access and provides functionality to summarize all stored notes.",
      "stars": 12,
      "forks": 4,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-10-02T10:44:47Z",
      "readme_content": "# md-pdf-mcp (Markdown to PDF MCP Server)\n\nConvert Markdown to gorgeously styled PDFs using VS Code's markdown styling and Python's ReportLab.\n\n## Components\n\n### Resources\n\nThe server implements a simple note storage system with:\n- Custom note:// URI scheme for accessing individual notes\n- Each note resource has a name, description and text/plain mimetype\n\n### Prompts\n\nThe server provides a single prompt:\n- summarize-notes: Creates summaries of all stored notes\n  - Optional \"style\" argument to control detail level (brief/detailed)\n  - Generates prompt combining all current notes with style preference\n\n### Tools\n\nThe server implements one tool:\n- add-note: Adds a new note to the server\n  - Takes \"name\" and \"content\" as required string arguments\n  - Updates server state and notifies clients of resource changes\n\n## Configuration\n\n[TODO: Add configuration details specific to your implementation]\n\n## Quickstart\n\n### Install\n\n#### Claude Desktop\n\nOn MacOS: `~/Library/Application\\ Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n<details>\n  <summary>Development/Unpublished Servers Configuration</summary>\n  ```\n  \"mcpServers\": {\n    \"md-pdf-mcp\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/Users/path/to/your/local/md-pdf-mcp\",\n        \"run\",\n        \"md-pdf-mcp\"\n      ]\n    }\n  }\n  ```\n</details>\n\n<details>\n  <summary>Published Servers Configuration</summary>\n  ```\n  \"mcpServers\": {\n    \"md-pdf-mcp\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"md-pdf-mcp\"\n      ]\n    }\n  }\n  ```\n</details>\n\n## Development\n\n### Building and Publishing\n\nTo prepare the package for distribution:\n\n1. Sync dependencies and update lockfile:\n```bash\nuv sync\n```\n\n2. Build package distributions:\n```bash\nuv build\n```\n\nThis will create source and wheel distributions in the `dist/` directory.\n\n3. Publish to PyPI:\n```bash\nuv publish\n```\n\nNote: You'll need to set PyPI credentials via environment variables or command flags:\n- Token: `--token` or `UV_PUBLISH_TOKEN`\n- Or username/password: `--username`/`UV_PUBLISH_USERNAME` and `--password`/`UV_PUBLISH_PASSWORD`\n\n### Debugging\n\nSince MCP servers run over stdio, debugging can be challenging. For the best debugging\nexperience, we strongly recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector).\n\n\nYou can launch the MCP Inspector via [`npm`](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm) with this command:\n\n```bash\nnpx @modelcontextprotocol/inspector uv --directory /Users/seanivore/Development/md-pdf-mcp run md-pdf-mcp\n```\n\n\nUpon launching, the Inspector will display a URL that you can access in your browser to begin debugging.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "markdown",
        "document",
        "notes",
        "markdown files",
        "markdown pdf",
        "converts markdown"
      ],
      "category": "document-processing"
    },
    "seanivore--mcp-file-preview": {
      "owner": "seanivore",
      "name": "mcp-file-preview",
      "url": "https://github.com/seanivore/mcp-file-preview",
      "imageUrl": "/freedevtools/mcp/pfp/seanivore.webp",
      "description": "Enables previewing and analyzing local HTML files, including capturing full-page screenshots and examining their structural elements such as headings, paragraphs, images, and links.",
      "stars": 22,
      "forks": 9,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-10-03T22:32:04Z",
      "readme_content": "# MCP File Preview Server\n\nA Model Context Protocol (MCP) server that provides HTML file preview and analysis capabilities. This server enables capturing full-page screenshots of local HTML files and analyzing their structure.\n\n## Features\n\n- **File Preview**: Capture full-page screenshots of HTML files with proper CSS styling\n- **Content Analysis**: Analyze HTML structure (headings, paragraphs, images, links)\n- **Local File Support**: Handle local file paths and resources\n- **Screenshot Management**: Save screenshots to a dedicated directory\n\n## Installation\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/your-username/mcp-file-preview.git\ncd mcp-file-preview\n```\n\n2. Install dependencies:\n```bash\nnpm install\n```\n\n3. Build the project:\n```bash\nnpm run build\n```\n\n## Configuration\n\nAdd the server to your Claude or Cline MCP settings:\n\n### Claude Desktop App\nAdd to `~/Library/Application Support/Claude/claude_desktop_config.json`:\n```json\n{\n  \"mcpServers\": {\n    \"file-preview\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/mcp-file-preview/build/index.js\"]\n    }\n  }\n}\n```\n\n### Cline VSCode Extension\nAdd to VSCode's MCP settings:\n```json\n{\n  \"mcpServers\": {\n    \"file-preview\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/mcp-file-preview/build/index.js\"]\n    }\n  }\n}\n```\n\n## Usage\n\nThe server provides two main tools:\n\n### preview_file\nCaptures a screenshot and returns HTML content:\n```typescript\n<use_mcp_tool>\n<server_name>file-preview</server_name>\n<tool_name>preview_file</tool_name>\n<arguments>\n{\n  \"filePath\": \"/path/to/file.html\",\n  \"width\": 1024,  // optional\n  \"height\": 768   // optional\n}\n</arguments>\n</use_mcp_tool>\n```\n\nScreenshots are saved to `screenshots/` directory in the project folder.\n\n### analyze_content\nAnalyzes HTML structure:\n```typescript\n<use_mcp_tool>\n<server_name>file-preview</server_name>\n<tool_name>analyze_content</tool_name>\n<arguments>\n{\n  \"filePath\": \"/path/to/file.html\"\n}\n</arguments>\n</use_mcp_tool>\n```\n\nReturns counts of:\n- Headings\n- Paragraphs\n- Images\n- Links\n\n## Development\n\n1. Install dependencies:\n```bash\nnpm install @modelcontextprotocol/sdk puppeteer typescript @types/node @types/puppeteer\n```\n\n2. Make changes in `src/`\n3. Build:\n```bash\nnpm run build\n```\n4. Test locally:\n```bash\nnpm run dev\n```\n\n## Implementation Details\n\nThe server uses the MCP SDK's Server class with proper initialization:\n\n```typescript\nthis.server = new Server(\n  // Metadata object\n  {\n    name: 'file-preview-server',\n    version: '0.1.0'\n  },\n  // Options object with capabilities\n  {\n    capabilities: {\n      tools: {\n        preview_file: {\n          description: 'Preview local HTML file and capture screenshot',\n          inputSchema: {\n            // ... schema definition\n          }\n        }\n      }\n    }\n  }\n);\n```\n\nKey points:\n- Server constructor takes separate metadata and options objects\n- Tools are declared in capabilities.tools\n- Each tool needs a description and inputSchema\n- Screenshots are saved to a local `screenshots/` directory\n\n## Debugging\n\n1. Use the MCP Inspector:\n```bash\nnpx @modelcontextprotocol/inspector\n```\n\n2. Connect with:\n   - Transport Type: STDIO\n   - Command: node\n   - Arguments: /path/to/build/index.js\n\n3. Check Claude OS logs if tools don't appear in the dropdown\n\n## Contributing\n\nPlease read [CONTRIBUTING.md](CONTRIBUTING.md) for details on our code of conduct and the process for submitting pull requests.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "previewing",
        "preview",
        "html",
        "file preview",
        "html files",
        "previewing analyzing"
      ],
      "category": "document-processing"
    },
    "seanlee10--server-youtube-transcription": {
      "owner": "seanlee10",
      "name": "server-youtube-transcription",
      "url": "https://github.com/seanlee10/server-youtube-transcription",
      "imageUrl": "/freedevtools/mcp/pfp/seanlee10.webp",
      "description": "Transcribes audio from YouTube videos to text, providing accurate and fast text representations of video content. Integrates transcription capabilities seamlessly into applications using the MCP framework.",
      "stars": 0,
      "forks": 1,
      "license": "No License",
      "language": "",
      "updated_at": "2025-03-25T00:44:30Z",
      "readme_content": "[![smithery badge](https://smithery.ai/badge/@seanlee10/server-youtube-transcription)](https://smithery.ai/server/@seanlee10/server-youtube-transcription)\n\n# YouTube Transcription Server\n\nTranscribe YouTube videos effortlessly with this server. Leverage the power of MCP to integrate transcription capabilities into your applications. Enhance your projects by adding accurate and fast video transcriptions from YouTube content.\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "transcription",
        "seanlee10",
        "transcribes",
        "youtube transcription",
        "processing seanlee10",
        "server youtube"
      ],
      "category": "document-processing"
    },
    "sellisd--mcp-units": {
      "owner": "sellisd",
      "name": "mcp-units",
      "url": "https://github.com/sellisd/mcp-units",
      "imageUrl": "/freedevtools/mcp/pfp/sellisd.webp",
      "description": "Provides tools for converting cooking measurements between various volume, weight, and temperature units commonly used in cooking, such as milliliters to cups and grams to pounds.",
      "stars": 1,
      "forks": 1,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-10-02T17:58:24Z",
      "readme_content": "# MCP Cooking Units Converter\n\n[![smithery badge](https://smithery.ai/badge/@sellisd/mcp-units)](https://smithery.ai/server/@sellisd/mcp-units)\n\n<!-- mcp-name: io.github.sellisd/mcp-units -->\n\n**MCP Cooking Units Converter** is a Python package and MCP server for converting cooking measurements (volume, weight, temperature) between common units. It is designed for integration with MCP-compatible tools and VSCode extensions.\n\n## Installation\n\n### Installing via Smithery\n\nTo install Cooking Units Converter for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@sellisd/mcp-units):\n\n```bash\nnpx -y @smithery/cli install @sellisd/mcp-units --client claude\n```\n\n### Manual Installation\n1. Clone the repository:\n```bash\ngit clone git@github.com:sellisd/mcp-units.git\ncd mcp-units\n```\n\n2. Install:\n```bash\nuv pip install .  # For normal use\n# OR\nuv pip install -e .  # For development\n```\n\n## Usage\n\n### Available Tools\n\nThe server provides the following conversion tools:\n\n1. **Volume Conversion**\n   - Convert between: ml, l, cup, tbsp, tsp\n   - Example: 240ml → 1 cup\n\n2. **Weight Conversion**\n   - Convert between: g, kg, oz, lb\n   - Example: 454g → 1 lb\n\n3. **Temperature Conversion**\n   - Convert between: Celsius (C), Fahrenheit (F)\n   - Example: 180°C → 356°F\n\n### Running the Server\n\n```bash\nuvx --with . python -m mcp_units.server\n```\n\n## Using with VSCode Extensions\n\nThis MCP server can be integrated with VSCode extensions that support the Model Context Protocol. Here's how to set it up:\n\n1. Install an MCP-compatible VSCode extension (e.g., Roo)\n\n2. Configure the extension to use this server in `.roo/mcp.json`:\n   ```json\n   {\n     \"mcpServers\": {\n       \"units\": {\n         \"command\": \"uvx\",\n         \"args\": [\n           \"--with\",\n           \".\",\n           \"python\",\n           \"-m\",\n           \"mcp_units.server\"\n         ],\n         \"disabled\": false\n       }\n     }\n   }\n   ```\n\n## Contact\n\nFor questions, issues, or contributions, please visit the [GitHub repository](https://github.com/sellisd/mcp-units).\n\n## License\n\nThis project is licensed under the MIT License.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcp",
        "milliliters",
        "units",
        "mcp units",
        "sellisd mcp",
        "cooking milliliters"
      ],
      "category": "document-processing"
    },
    "shaunporwal--DICOM-MCP": {
      "owner": "shaunporwal",
      "name": "DICOM-MCP",
      "url": "https://github.com/shaunporwal/DICOM-MCP",
      "imageUrl": "/freedevtools/mcp/pfp/shaunporwal.webp",
      "description": "Manage and summarize DICOM images by adding notes and generating summaries to enhance workflows with medical imaging data.",
      "stars": 0,
      "forks": 1,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-04-08T14:38:32Z",
      "readme_content": "# DICOM-MCP MCP server\n\nMCP to work with DICOM images\n\n## Components\n\n### Resources\n\nThe server implements a simple note storage system with:\n- Custom note:// URI scheme for accessing individual notes\n- Each note resource has a name, description and text/plain mimetype\n\n### Prompts\n\nThe server provides a single prompt:\n- summarize-notes: Creates summaries of all stored notes\n  - Optional \"style\" argument to control detail level (brief/detailed)\n  - Generates prompt combining all current notes with style preference\n\n### Tools\n\nThe server implements one tool:\n- add-note: Adds a new note to the server\n  - Takes \"name\" and \"content\" as required string arguments\n  - Updates server state and notifies clients of resource changes\n\n## Configuration\n\n[TODO: Add configuration details specific to your implementation]\n\n## Quickstart\n\n### Install\n\n#### Claude Desktop\n\nOn MacOS: `~/Library/Application\\ Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n<details>\n  <summary>Development/Unpublished Servers Configuration</summary>\n  ```\n  \"mcpServers\": {\n    \"DICOM-MCP\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/Users/shaunporwal/Documents/GitHub/projects/DICOM-MCP\",\n        \"run\",\n        \"DICOM-MCP\"\n      ]\n    }\n  }\n  ```\n</details>\n\n<details>\n  <summary>Published Servers Configuration</summary>\n  ```\n  \"mcpServers\": {\n    \"DICOM-MCP\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"DICOM-MCP\"\n      ]\n    }\n  }\n  ```\n</details>\n\n## Development\n\n### Building and Publishing\n\nTo prepare the package for distribution:\n\n1. Sync dependencies and update lockfile:\n```bash\nuv sync\n```\n\n2. Build package distributions:\n```bash\nuv build\n```\n\nThis will create source and wheel distributions in the `dist/` directory.\n\n3. Publish to PyPI:\n```bash\nuv publish\n```\n\nNote: You'll need to set PyPI credentials via environment variables or command flags:\n- Token: `--token` or `UV_PUBLISH_TOKEN`\n- Or username/password: `--username`/`UV_PUBLISH_USERNAME` and `--password`/`UV_PUBLISH_PASSWORD`\n\n### Debugging\n\nSince MCP servers run over stdio, debugging can be challenging. For the best debugging\nexperience, we strongly recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector).\n\n\nYou can launch the MCP Inspector via [`npm`](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm) with this command:\n\n```bash\nnpx @modelcontextprotocol/inspector uv --directory /Users/shaunporwal/Documents/GitHub/projects/DICOM-MCP run dicom-mcp\n```\n\n\nUpon launching, the Inspector will display a URL that you can access in your browser to begin debugging.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "dicom",
        "imaging",
        "summarize",
        "dicom images",
        "summarize dicom",
        "dicom mcp"
      ],
      "category": "document-processing"
    },
    "shifusen329--doc-lib-mcp": {
      "owner": "shifusen329",
      "name": "doc-lib-mcp",
      "url": "https://github.com/shifusen329/doc-lib-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/shifusen329.webp",
      "description": "Manage and semantically search documentation by adding, ingesting, chunking, and querying notes across various document types. Create summaries tailored to specific detail levels and access individual notes through a custom URI scheme.",
      "stars": 0,
      "forks": 1,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-05-19T07:06:54Z",
      "readme_content": "# doc-lib-mcp MCP server\n\nA Model Context Protocol (MCP) server for document ingestion, chunking, semantic search, and note management.\n\n## Components\n\n### Resources\n\n- Implements a simple note storage system with:\n  - Custom `note://` URI scheme for accessing individual notes\n  - Each note resource has a name, description, and `text/plain` mimetype\n\n### Prompts\n\n- Provides a prompt:\n  - **summarize-notes**: Creates summaries of all stored notes\n    - Optional \"style\" argument to control detail level (brief/detailed)\n    - Generates prompt combining all current notes with style preference\n\n### Tools\n\nThe server implements a wide range of tools:\n\n- **add-note**: Add a new note to the in-memory note store\n  - Arguments: `name` (string), `content` (string)\n- **ingest-string**: Ingest and chunk a markdown or plain text string provided via message\n  - Arguments: `content` (string, required), `source` (string, optional), `tags` (list of strings, optional)\n- **ingest-markdown**: Ingest and chunk a markdown (.md) file\n  - Arguments: `path` (string)\n- **ingest-python**: Ingest and chunk a Python (.py) file\n  - Arguments: `path` (string)\n- **ingest-openapi**: Ingest and chunk an OpenAPI JSON file\n  - Arguments: `path` (string)\n- **ingest-html**: Ingest and chunk an HTML file\n  - Arguments: `path` (string)\n- **ingest-html-url**: Ingest and chunk HTML content from a URL (optionally using Playwright for dynamic content)\n  - Arguments: `url` (string), `dynamic` (boolean, optional)\n- **smart_ingestion**: Extracts all technically relevant content from a file using Gemini, then chunks it using robust markdown logic.\n  - Arguments:\n    - `path` (string, required): File path to ingest.\n    - `prompt` (string, optional): Custom prompt to use for Gemini.\n    - `tags` (list of strings, optional): Optional list of tags for classification.\n  - Uses Gemini 2.0 Flash 001 to extract only code, configuration, markdown structure, and technical definitions (no summaries or commentary).\n  - Passes the extracted content to a mistune 3.x-based chunker that preserves both code blocks and markdown/narrative content as separate chunks.\n  - Each chunk is embedded and stored for semantic search and retrieval.\n- **search-chunks**: Semantic search over ingested content\n  - Arguments:\n    - `query` (string): The semantic search query.\n    - `top_k` (integer, optional, default 3): Number of top results to return.\n    - `type` (string, optional): Filter results by chunk type (e.g., `code`, `html`, `markdown`).\n    - `tag` (string, optional): Filter results by tag in chunk metadata.\n  - Returns the most relevant chunks for a given query, optionally filtered by type and/or tag.\n- **delete-source**: Delete all chunks from a given source\n  - Arguments: `source` (string)\n- **delete-chunk-by-id**: Delete one or more chunks by id\n  - Arguments: `id` (integer, optional), `ids` (list of integers, optional)\n  - You can delete a single chunk by specifying `id`, or delete multiple chunks at once by specifying `ids`.\n- **update-chunk-type**: Update the type attribute for a chunk by id\n  - Arguments: `id` (integer, required), `type` (string, required)\n- **ingest-batch**: Ingest and chunk multiple documentation files (markdown, OpenAPI JSON, Python) in batch\n  - Arguments: `paths` (list of strings)\n- **list-sources**: List all unique sources (file paths) that have been ingested and stored in memory, with optional filtering by tag or semantic search.\n  - Arguments:\n    - `tag` (string, optional): Filter sources by tag in chunk metadata.\n    - `query` (string, optional): Semantic search query to find relevant sources.\n    - `top_k` (integer, optional, default 10): Number of top sources to return when using query.\n- **get-context**: Retrieve relevant content chunks (content only) for use as AI context, with filtering by tag, type, and semantic similarity.\n  - Arguments:\n    - `query` (string, optional): The semantic search query.\n    - `tag` (string, optional): Filter results by a specific tag in chunk metadata.\n    - `type` (string, optional): Filter results by chunk type (e.g., 'code', 'markdown').\n    - `top_k` (integer, optional, default 5): The number of top relevant chunks to retrieve.\n- **update-chunk-metadata**: Update the metadata field for a chunk by id\n  - Arguments: `id` (integer), `metadata` (object)\n- **tag-chunks-by-source**: Adds specified tags to the metadata of all chunks associated with a given source (URL or file path). Merges with existing tags.\n  - Arguments: `source` (string), `tags` (list of strings)\n- **list-notes**: List all currently stored notes and their content.\n\n#### Chunking and Code Extraction\n\n- Markdown, Python, OpenAPI, and HTML files are split into logical chunks for efficient retrieval and search.\n- The markdown chunker uses mistune 3.x's AST API and regex to robustly split content by code blocks and narrative, preserving all original formatting.\n- Both code blocks and markdown/narrative content are preserved as separate chunks.\n- The HTML chunker uses the `readability-lxml` library to extract main content first, then extracts block code snippets from `<pre>` tags as dedicated \"code\" chunks. Inline `<code>` content remains part of the narrative chunks.\n\n#### Semantic Search\n\n- The `search-chunks` tool performs vector-based semantic search over all ingested content, returning the most relevant chunks for a given query.\n- Supports optional `type` and `tag` arguments to filter results by chunk type (e.g., `code`, `html`, `markdown`) and/or by tag in chunk metadata, before semantic ranking.\n- This enables highly targeted retrieval, such as \"all code chunks tagged with 'langfuse' relevant to 'cost and usage'\".\n\n#### Metadata Management\n\n- Chunks include a `metadata` field for categorization and tagging.\n- The `update-chunk-metadata` tool allows updating metadata for any chunk by its id.\n- The `tag-chunks-by-source` tool allows adding tags to all chunks from a specific source in one operation. Tagging merges new tags with existing ones, preserving previous tags.\n\n## Configuration\n\nThe server requires the following environment variables (can be set in a .env file):\n\n### Ollama Configuration\n- OLLAMA_HOST: Hostname for Ollama API (default: localhost)\n- OLLAMA_PORT: Port for Ollama API (default: 11434)\n- RAG_AGENT: Ollama model to use for RAG responses (default: llama3)\n- OLLAMA_MODEL: Ollama model to use for embeddings (default: nomic-embed-text-v2-moe)\n\n### Database Configuration\n- HOST: PostgreSQL database host (default: localhost)\n- DB_PORT: PostgreSQL database port (default: 5432)\n- DB_NAME: PostgreSQL database name (default: doclibdb)\n- DB_USER: PostgreSQL database user (default: doclibdb_user)\n- DB_PASSWORD: PostgreSQL database password (default: doclibdb_password)\n\n### Reranker Configuration\n- RERANKER_MODEL_PATH: Path to the reranker model (default: /srv/samba/fileshare2/AI/models/bge-reranker-v2-m3)\n- RERANKER_USE_FP16: Whether to use FP16 for reranker (default: True)\n\n## Quickstart\n\n### Install\n\n#### Claude Desktop\n\nOn MacOS: `~/Library/Application\\ Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n<details>\n  <summary>Development/Unpublished Servers Configuration</summary>\n  ```\n  \"mcpServers\": {\n    \"doc-lib-mcp\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/home/administrator/python-share/doc-lib-mcp\",\n        \"run\",\n        \"doc-lib-mcp\"\n      ]\n    }\n  }\n  ```\n</details>\n\n<details>\n  <summary>Published Servers Configuration</summary>\n  ```\n  \"mcpServers\": {\n    \"doc-lib-mcp\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"doc-lib-mcp\"\n      ]\n    }\n  }\n  ```\n</details>\n\n## Development\n\n### Building and Publishing\n\nTo prepare the package for distribution:\n\n1. Sync dependencies and update lockfile:\n```bash\nuv sync\n```\n\n2. Build package distributions:\n```bash\nuv build\n```\n\nThis will create source and wheel distributions in the `dist/` directory.\n\n3. Publish to PyPI:\n```bash\nuv publish\n```\n\nNote: You'll need to set PyPI credentials via environment variables or command flags:\n- Token: `--token` or `UV_PUBLISH_TOKEN`\n- Or username/password: `--username`/`UV_PUBLISH_USERNAME` and `--password`/`UV_PUBLISH_PASSWORD`\n\n### Debugging\n\nSince MCP servers run over stdio, debugging can be challenging. For the best debugging\nexperience, we strongly recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector).\n\nYou can launch the MCP Inspector via [`npm`](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm) with this command:\n\n```bash\nnpx @modelcontextprotocol/inspector uv --directory /home/administrator/python-share/doc-lib-mcp run doc-lib-mcp\n```\n\nUpon launching, the Inspector will display a URL that you can access in your browser to begin debugging.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "documentation",
        "document",
        "shifusen329",
        "shifusen329 doc",
        "document processing",
        "search documentation"
      ],
      "category": "document-processing"
    },
    "shineforever--Youtube-Transcript-Download": {
      "owner": "shineforever",
      "name": "Youtube-Transcript-Download",
      "url": "https://github.com/shineforever/Youtube-Transcript-Download",
      "imageUrl": "/freedevtools/mcp/pfp/shineforever.webp",
      "description": "Download subtitles from popular video platforms like YouTube, Bilibili, TED, and Coursera using the AITransDub MCP service. Supports multiple subtitle languages for easier access and processing.",
      "stars": 2,
      "forks": 0,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-08-13T15:41:31Z",
      "readme_content": "# Youtube-Transcript-Download\n\n## Overview\n\nThe **Youtube-Transcript-Download** project allows users to download subtitles from various popular video platforms such as YouTube, Bilibili, TED, and Coursera. This tool is powered by the **AITransDub MCP** service, enabling you to retrieve subtitle data from these platforms for further processing or personal use.\n\n### Key Features\n- Download subtitles from YouTube, Bilibili, TED, and Coursera.\n- Use AITransDub MCP to retrieve subtitle data.\n- Supports multiple subtitle languages including English, Korean, and more.\n- Effortless integration with video platforms for easy extraction.\n\nFor even more powerful features, visit the official website at [AITransDub.com](https://AITransDub.com).\n\n## Installation\n\nTo get started, you need to clone the repository and install the dependencies:\n\n1. **Clone the repository:**\n   ```bash\n   git clone https://github.com/shineforever/Youtube-Transcript-Download.git\n   cd Youtube-Transcript-Download\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "subtitles",
        "subtitle",
        "aitransdub",
        "shineforever youtube",
        "download subtitles",
        "processing shineforever"
      ],
      "category": "document-processing"
    },
    "skrapeai--skrape-mcp": {
      "owner": "skrapeai",
      "name": "skrape-mcp",
      "url": "https://github.com/skrapeai/skrape-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/skrapeai.webp",
      "description": "Convert web pages into clean, structured Markdown suitable for large language model (LLM) consumption, streamlining the process of feeding web content into AI applications.",
      "stars": 11,
      "forks": 9,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-10-03T22:32:12Z",
      "readme_content": "# Skrape MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@skrapeai/skrape-mcp)](https://smithery.ai/server/@skrapeai/skrape-mcp)\n\nConvert webpages into clean, LLM-ready Markdown using [skrape.ai](https://skrape.ai). An MCP server that seamlessly integrates web scraping with Claude Desktop and other MCP-compatible applications.\n\n## Key Features\n\n- **Clean Output**: Removes ads, navigation, and irrelevant content\n- **JavaScript Support**: Handles dynamic content rendering\n- **LLM-Optimized**: Structured Markdown perfect for AI consumption\n- **Consistent Format**: Uniform structure regardless of source\n\n## Features\n\n### Tools\n\n- `get_markdown` - Convert any webpage to LLM-ready Markdown\n  - Takes any input URL and optional parameters\n  - Returns clean, structured Markdown optimized for LLM consumption\n  - Supports JavaScript rendering for dynamic content\n  - Optional JSON response format for advanced integrations\n\n## Installation\n\n### Installing via Smithery\n\nTo install Skrape MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@skrapeai/skrape-mcp):\n\n```bash\nnpx -y @smithery/cli install @skrapeai/skrape-mcp --client claude\n```\n\n### Manual Installation\n\n1. Get your API key from [skrape.ai](https://skrape.ai)\n\n1. Install dependencies:\n\n```bash\nnpm install\n```\n\n1. Build the server:\n\n```bash\nnpm run build\n```\n\n1. Add the server config to Claude Desktop:\n\nOn MacOS:\n\n```bash\nnano ~/Library/Application\\ Support/Claude/claude_desktop_config.json\n```\n\nOn Windows:\n\n```bash\nnotepad %APPDATA%/Claude/claude_desktop_config.json\n```\n\nAdd this configuration (replace paths and API key with your values):\n\n```json\n{\n  \"mcpServers\": {\n    \"skrape\": {\n      \"command\": \"node\",\n      \"args\": [\"path/to/skrape-mcp/build/index.js\"],\n      \"env\": {\n        \"SKRAPE_API_KEY\": \"your-key-here\"\n      }\n    }\n  }\n}\n```\n\n## Using with LLMs\n\nHere's how to use the server with Claude or other LLM models:\n\n1. First, ensure the server is properly configured in your LLM application\n2. Then, you can ask the ALLMI to fetch and process any webpage:\n\n```\nConvert this webpage to markdown: https://example.com\n\nClaude will use the MCP tool like this:\n<use_mcp_tool>\n<server_name>skrape</server_name>\n<tool_name>get_markdown</tool_name>\n<arguments>\n{\n  \"url\": \"https://example.com\",\n  \"options\": {\n    \"renderJs\": true\n  }\n}\n</arguments>\n</use_mcp_tool>\n```\n\nThe resulting Markdown will be clean, structured, and ready for LLM processing.\n\n### Advanced Options\n\nThe `get_markdown` tool accepts these parameters:\n\n- `url` (required): Any webpage URL to convert\n- `returnJson` (optional): Set to `true` to get the full JSON response instead of just markdown\n- `options` (optional): Additional scraping options\n  - `renderJs`: Whether to render JavaScript before scraping (default: true)\n\nExample with all options:\n\n```\n<use_mcp_tool>\n<server_name>skrape</server_name>\n<tool_name>get_markdown</tool_name>\n<arguments>\n{\n  \"url\": \"https://example.com\",\n  \"returnJson\": true,\n  \"options\": {\n    \"renderJs\": false\n  }\n}\n</arguments>\n</use_mcp_tool>\n```\n\n## Development\n\nFor development with auto-rebuild:\n\n```bash\nnpm run watch\n```\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector):\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n\n---\n\n<a href=\"https://glama.ai/mcp/servers/7i81qzgkzd\">\n<img width=\"190\" height=\"100\" src=\"https://glama.ai/mcp/servers/7i81qzgkzd/badge\" />\n</a>\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "markdown",
        "pages",
        "document",
        "markdown suitable",
        "structured markdown",
        "processing skrapeai"
      ],
      "category": "document-processing"
    },
    "skydeckai--mcp-server-rememberizer": {
      "owner": "skydeckai",
      "name": "mcp-server-rememberizer",
      "url": "https://github.com/skydeckai/mcp-server-rememberizer",
      "imageUrl": "/freedevtools/mcp/pfp/skydeckai.webp",
      "description": "Interact with Rememberizer's document and knowledge management API to perform document search, retrieval, and management. Supports access to both documents and Slack discussions.",
      "stars": 34,
      "forks": 7,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-09-12T12:39:35Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/skydeckai-mcp-server-rememberizer-badge.png)](https://mseep.ai/app/skydeckai-mcp-server-rememberizer)\n\n# MCP Server Rememberizer\n\n[![Verified on MseeP](https://mseep.ai/badge.svg)](https://mseep.ai/app/fe7a40fd-30c1-4767-84f9-d33bf997497e)\n\nA [Model Context Protocol](https://www.anthropic.com/news/model-context-protocol) server for interacting with Rememberizer's document and knowledge management API. This server enables Large Language Models to search, retrieve, and manage documents and integrations through Rememberizer.\n\nPlease note that `mcp-server-rememberizer` is currently in development and the functionality may be subject to change.\n\n## Components\n\n### Resources\n\nThe server provides access to two types of resources: Documents or Slack discussions\n\n### Tools\n\n1. `retrieve_semantically_similar_internal_knowledge`\n\n    - Send a block of text and retrieve cosine similar matches from your connected Rememberizer personal/team internal knowledge and memory repository\n    - Input:\n        - `match_this` (string): Up to a 400-word sentence for which you wish to find semantically similar chunks of knowledge\n        - `n_results` (integer, optional): Number of semantically similar chunks of text to return. Use 'n_results=3' for up to 5, and 'n_results=10' for more information\n        - `from_datetime_ISO8601` (string, optional): Start date in ISO 8601 format with timezone (e.g., 2023-01-01T00:00:00Z). Use this to filter results from a specific date\n        - `to_datetime_ISO8601` (string, optional): End date in ISO 8601 format with timezone (e.g., 2024-01-01T00:00:00Z). Use this to filter results until a specific date\n    - Returns: Search results as text output\n\n2. `smart_search_internal_knowledge`\n\n    - Search for documents in Rememberizer in its personal/team internal knowledge and memory repository using a simple query that returns the results of an agentic search. The search may include sources such as Slack discussions, Gmail, Dropbox documents, Google Drive documents, and uploaded files\n    - Input:\n        - `query` (string): Up to a 400-word sentence for which you wish to find semantically similar chunks of knowledge\n        - `user_context` (string, optional): The additional context for the query. You might need to summarize the conversation up to this point for better context-awared results\n        - `n_results` (integer, optional): Number of semantically similar chunks of text to return. Use 'n_results=3' for up to 5, and 'n_results=10' for more information\n        - `from_datetime_ISO8601` (string, optional): Start date in ISO 8601 format with timezone (e.g., 2023-01-01T00:00:00Z). Use this to filter results from a specific date\n        - `to_datetime_ISO8601` (string, optional): End date in ISO 8601 format with timezone (e.g., 2024-01-01T00:00:00Z). Use this to filter results until a specific date\n    - Returns: Search results as text output\n\n3. `list_internal_knowledge_systems`\n\n    - List the sources of personal/team internal knowledge. These may include Slack discussions, Gmail, Dropbox documents, Google Drive documents, and uploaded files\n    - Input: None required\n    - Returns: List of available integrations\n\n4. `rememberizer_account_information`\n\n    - Get information about your Rememberizer.ai personal/team knowledge repository account. This includes account holder name and email address\n    - Input: None required\n    - Returns: Account information details\n\n5. `list_personal_team_knowledge_documents`\n\n    - Retrieves a paginated list of all documents in your personal/team knowledge system. Sources could include Slack discussions, Gmail, Dropbox documents, Google Drive documents, and uploaded files\n    - Input:\n        - `page` (integer, optional): Page number for pagination, starts at 1 (default: 1)\n        - `page_size` (integer, optional): Number of documents per page, range 1-1000 (default: 100)\n    - Returns: List of documents\n\n6. `remember_this`\n\n    - Save a piece of text information in your Rememberizer.ai knowledge system so that it may be recalled in future through tools retrieve_semantically_similar_internal_knowledge or smart_search_internal_knowledge\n    - Input:\n        - `name` (string): Name of the information. This is used to identify the information in the future\n        - `content` (string): The information you wish to memorize\n    - Returns: Confirmation data\n\n## Installation\n\n### Manual Installation\n\n```bash\nuvx mcp-server-rememberizer\n```\n\n### Via MseeP AI Helper App\n\nIf you have MseeP AI Helper app installed, you can search for \"Rememberizer\" and install the mcp-server-rememberizer.\n\n![MseeP AI Helper](https://www.gitbook.com/cdn-cgi/image/dpr=2,width=760,onerror=redirect,format=auto/https%3A%2F%2Ffiles.gitbook.com%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FyNqpTh7Mh66N0RnO0k24%252Fuploads%252FuTpQuJffWohPRTvjmyVe%252FScreenshot%25202025-07-29%2520at%252014.43.12.png%3Falt%3Dmedia%26token%3D7f046f3b-dc69-4f09-8f8c-978097f0066e)\n\n## Configuration\n\n### Environment Variables\n\nThe following environment variables are required:\n\n-   `REMEMBERIZER_API_TOKEN`: Your Rememberizer API token\n\nYou can register an API key by creating your own [Common Knowledge in Rememberizer](https://docs.rememberizer.ai/developer/registering-and-using-api-keys).\n\n### Usage with Claude Desktop\n\nAdd this to your `claude_desktop_config.json`:\n\n```json\n\"mcpServers\": {\n  \"rememberizer\": {\n      \"command\": \"uvx\",\n      \"args\": [\"mcp-server-rememberizer\"],\n      \"env\": {\n        \"REMEMBERIZER_API_TOKEN\": \"your_rememberizer_api_token\"\n      }\n    },\n}\n```\n\n### Usage with MseeP AI Helper App\n\nAdd the env REMEMBERIZER_API_TOKEN to mcp-server-rememberizer.\n\n![MseeP AI Helper Configuration](https://www.gitbook.com/cdn-cgi/image/dpr=2,width=760,onerror=redirect,format=auto/https%3A%2F%2Ffiles.gitbook.com%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FyNqpTh7Mh66N0RnO0k24%252Fuploads%252FHxisSUT1anmCpoHhW8CJ%252FScreenshot%25202025-07-29%2520at%252014.45.42.png%3Falt%3Dmedia%26token%3D1332394a-cdbe-4e7b-9099-1dbf14e58ffb)\n\nWith support from the Rememberizer MCP server, you can now ask the following questions in your Claude Desktop app or SkyDeck AI GenStudio\n\n-   _What is my Rememberizer account?_\n\n-   _List all documents that I have there._\n\n-   _Give me a quick summary about \"...\"_\n\n-   and so on...\n\nTo learn more about Rememberizer MCP Server: https://docs.rememberizer.ai/personal-use/integrations/rememberizer-mcp-servers\n\n## License\n\nThis project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "rememberizer",
        "retrieval",
        "documents",
        "rememberizer document",
        "server rememberizer",
        "retrieval management"
      ],
      "category": "document-processing"
    },
    "slamdunkasaur--ru-heritage": {
      "owner": "slamdunkasaur",
      "name": "ru-heritage",
      "url": "https://github.com/slamdunkasaur/ru-heritage",
      "imageUrl": "/freedevtools/mcp/pfp/slamdunkasaur.webp",
      "description": "Downloads digitised books from e-heritage.ru and converts them into PDF format, facilitating easier access to digital heritage content.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "",
      "updated_at": "2025-01-20T15:00:03Z",
      "readme_content": "# ru-heritage\nDownload digitised books from e-heritage.ru and save them as PDF\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "slamdunkasaur",
        "ru",
        "heritage",
        "ru heritage",
        "heritage ru",
        "slamdunkasaur ru"
      ],
      "category": "document-processing"
    },
    "softgridinc-pte-ltd--mcp-excel-reader-server": {
      "owner": "softgridinc-pte-ltd",
      "name": "mcp-excel-reader-server",
      "url": "https://github.com/softgridinc-pte-ltd/mcp-excel-reader-server",
      "imageUrl": "/freedevtools/mcp/pfp/softgridinc-pte-ltd.webp",
      "description": "Extract data from Excel files in structured JSON format, allowing access to all sheets or specific sheets by name or index. Handles data type conversions and manages empty cells efficiently.",
      "stars": 5,
      "forks": 6,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-05-19T14:18:36Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/softgridinc-pte-ltd-mcp-excel-reader-server-badge.png)](https://mseep.ai/app/softgridinc-pte-ltd-mcp-excel-reader-server)\n\n# Excel Reader Server\n\nA Model Context Protocol (MCP) server that provides tools for reading Excel (xlsx) files.\n\n<a href=\"https://glama.ai/mcp/servers/kniyyx0gej\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/kniyyx0gej/badge\" alt=\"Excel Reader Server MCP server\" />\n</a>\n\n## Features\n\n- Read content from all sheets in an Excel file\n- Read content from a specific sheet by name\n- Read content from a specific sheet by index\n- Returns data in JSON format\n- Handles empty cells and data type conversions\n\n## Installation\n\nRequires Python 3.10 or higher.\n\n```bash\n# Using pip\npip install excel-reader-server\n\n# Using uv (recommended)\nuv pip install excel-reader-server\n```\n\n## Dependencies\n\n- mcp >= 1.2.1\n- openpyxl >= 3.1.5\n\n## Usage\n\nThe server provides three main tools:\n\n### 1. read_excel\n\nReads content from all sheets in an Excel file.\n\n```python\n{\n  \"file_path\": \"path/to/your/excel/file.xlsx\"\n}\n```\n\n### 2. read_excel_by_sheet_name\n\nReads content from a specific sheet by name. If no sheet name is provided, reads the first sheet.\n\n```python\n{\n  \"file_path\": \"path/to/your/excel/file.xlsx\",\n  \"sheet_name\": \"Sheet1\"  # optional\n}\n```\n\n### 3. read_excel_by_sheet_index\n\nReads content from a specific sheet by index. If no index is provided, reads the first sheet (index 0).\n\n```python\n{\n  \"file_path\": \"path/to/your/excel/file.xlsx\",\n  \"sheet_index\": 0  # optional\n}\n```\n\n## Response Format\n\nThe server returns data in the following JSON format:\n\n```json\n{\n  \"Sheet1\": [\n    [\"Header1\", \"Header2\", \"Header3\"],\n    [\"Value1\", \"Value2\", \"Value3\"],\n    [\"Value4\", \"Value5\", \"Value6\"]\n  ]\n}\n```\n\n- Each sheet is represented as a key in the top-level object\n- Sheet data is an array of arrays, where each inner array represents a row\n- All values are converted to strings\n- Empty cells are represented as empty strings\n\n## Error Handling\n\nThe server provides clear error messages for common issues:\n- File not found\n- Invalid sheet name\n- Index out of range\n- General Excel file reading errors\n\n## License\n\nThis project is released under the Apache 2 License. See the LICENSE file for details.\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "excel",
        "softgridinc",
        "processing",
        "excel files",
        "excel reader",
        "processing softgridinc"
      ],
      "category": "document-processing"
    },
    "soggycactus--paprika-3-mcp": {
      "owner": "soggycactus",
      "name": "paprika-3-mcp",
      "url": "https://github.com/soggycactus/paprika-3-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/soggycactus.webp",
      "description": "Exposes Paprika 3 recipes as LLM-readable resources for interaction with LLMs like Claude. Enables creation and updating of recipes within the Paprika app through specialized tools.",
      "stars": 12,
      "forks": 6,
      "license": "MIT License",
      "language": "Go",
      "updated_at": "2025-09-20T09:22:15Z",
      "readme_content": "# paprika-3-mcp\n\nA [Model Context Protocol (MCP)](https://modelcontextprotocol.io/introduction) server that exposes your **Paprika 3** recipes as LLM-readable resources — and lets an LLM like Claude create or update recipes in your Paprika app.\n\n### 🖼️ Example: Claude using the Paprika MCP server\n\n<p align=\"center\">\n  \n</p>\n\n## 🚀 Features\n\nSee anything missing? Open an issue on this repo to request a feature!\n\n#### 📄 **Resources**\n\n- Recipes ✅\n- Recipe Photos 🚧\n\n#### 🛠 **Tools**\n\n- `create_paprika_recipe`  \n  Allows Claude to save a new recipe to your Paprika app\n- `update_paprika_recipe`  \n  Allows Claude to modify an existing recipe\n\n## ⚙️ Prerequisites\n\n- ✅ A Mac, Linux, or Windows system\n- ✅ [Paprika 3](https://www.paprikaapp.com/) installed with cloud sync enabled\n- ✅ Your Paprika 3 **username and password**\n- ✅ Claude or any LLM client with **MCP tool support** enabled\n\n## 🛠 Installation\n\nYou can download a prebuilt binary from the [Releases](https://github.com/soggycactus/paprika-3-mcp/releases) page.\n\n### 🍎 macOS (via Homebrew)\n\nIf you're on macOS, the easiest way to install is with [Homebrew](https://brew.sh/):\n\n```bash\nbrew tap soggycactus/tap\nbrew install paprika-3-mcp\n```\n\n### 🐧 Linux / 🪟 Windows\n\n1. Go to the [latest release](https://github.com/soggycactus/paprika-3-mcp/releases).\n2. Download the appropriate archive for your operating system and architecture:\n   - `paprika-3-mcp_<version>_linux_amd64.zip` for Linux\n   - `paprika-3-mcp_<version>_windows_amd64.zip` for Windows\n3. Extract the zip archive:\n   - **Linux**:\n     ```bash\n     unzip paprika-3-mcp_<version>_<os>_<arch>.zip\n     ```\n   - **Windows**:\n     - Right-click the `.zip` file and select **Extract All**, or use a tool like 7-Zip.\n4. Move the binary to a directory in your system's `$PATH`:\n\n   - Linux:\n\n     ```bash\n     sudo mv paprika-3-mcp /usr/local/bin/\n     ```\n\n   - Windows:\n     - Move `paprika-3-mcp.exe` to any folder in your `PATH` (e.g., `%USERPROFILE%\\bin`)\n\n### ✅ Test the installation\n\nYou can verify the server is installed by checking:\n\n```bash\npaprika-3-mcp --version\n```\n\nYou should see:\n\n```bash\npaprika-3-mcp version v0.1.0\n```\n\n## 🤖 Setting up Claude\n\nIf you haven't setup MCP before, [first read more about how to install Claude Desktop client & configure an MCP server.](https://modelcontextprotocol.io/quickstart/user)\n\nTo add `paprika-3-mcp` to Claude, all you need to do is create another entry in the `mcpServers` section of your `claude_desktop_config.json` file:\n\n```json\n{\n  \"mcpServers\": {\n    \"paprika-3\": {\n      \"command\": \"paprika-3-mcp\",\n      \"args\": [\n        \"--username\",\n        \"<your paprika 3 username (usually email)>\",\n        \"--password\",\n        \"<your paprika 3 password>\"\n      ]\n    }\n  }\n}\n```\n\nRestart Claude and you should see the MCP server tools after clicking on the hammerhead icon:\n\n\n\n## 📄 License\n\nThis project is open source under the [MIT License](./LICENSE) © 2025 [Lucas Stephens](https://github.com/soggycactus).\n\n---\n\n#### 🗂 Miscellaneous\n\n##### 📄 Where can I see the server logs?\n\nThe MCP server writes structured logs using Go’s `slog` with rotation via `lumberjack`. Log files are automatically created based on your operating system:\n\n| Operating System | Log File Path                             |\n| ---------------- | ----------------------------------------- |\n| macOS            | `~/Library/Logs/paprika-3-mcp/server.log` |\n| Linux            | `/var/log/paprika-3-mcp/server.log`       |\n| Windows          | `%APPDATA%\\paprika-3-mcp\\server.log`      |\n| Other / Unknown  | `/tmp/paprika-3-mcp/server.log`           |\n\n> 💡 Logs are rotated automatically at 100MB, with only 5 backup files kept. Logs are also wiped after 10 days.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "paprika",
        "soggycactus",
        "recipes",
        "paprika recipes",
        "recipes paprika",
        "soggycactus paprika"
      ],
      "category": "document-processing"
    },
    "soukouki--obsidian_fetch": {
      "owner": "soukouki",
      "name": "obsidian_fetch",
      "url": "https://github.com/soukouki/obsidian_fetch",
      "imageUrl": "/freedevtools/mcp/pfp/soukouki.webp",
      "description": "Retrieve and load notes efficiently from Obsidian vaults, enabling enhanced interactions with language models by cleaning link queries and displaying backlinks to opened files. Streamlined for local GPU setups to improve note retrieval speed and efficiency.",
      "stars": 2,
      "forks": 0,
      "license": "MIT License",
      "language": "Ruby",
      "updated_at": "2025-08-19T16:26:33Z",
      "readme_content": "# ObsidianFetch\n\nMCP servers focused on fetching and presenting information from Obsidian vaults.\n\nThe existing MCP server has the following drawbacks:\n- It supports many commands, which can cause slow prompt loading when computational resources are limited.\n- When reading a note labeled \"Sample Note\", it is necessary to search for its path first before loading it, but the LLM may not always follow this procedure.\n- Some tools include unnecessary options, leading the LLM to sometimes fail to invoke them correctly.\n\nThese issues become particularly noticeable when running an LLM on a local GPU.  \nTo address this, we developed a new MCP server that simply retrieves and loads lists of notes.\n\nThe new server also provides the following additional features:\n- When the LLM attempts to retrieve link information by searching with brackets like `[[link name]]`, the server automatically removes any characters that cannot be used in links.\n- In addition to loading the note contents, it also displays backlinks—notes that link to the currently opened note.\n\t- This allows the LLM to load and understand the connections between related notes via backlinks.\n\n## Installation\n\n```bash\ngem install obsidian_fetch\n```\n\n## Usage\n\n```bash\nobsidian_fetch /path/to/your/vault\n```\n\n## Contributing\n\nBug reports and pull requests are welcome on GitHub at https://github.com/soukouki/obsidian_fetch.\n\n## License\n\nThe gem is available as open source under the terms of the [MIT License](https://opensource.org/licenses/MIT).\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "notes",
        "obsidian_fetch",
        "retrieval",
        "note retrieval",
        "notes efficiently",
        "load notes"
      ],
      "category": "document-processing"
    },
    "spacemeowx2--cargo-doc-mcp": {
      "owner": "spacemeowx2",
      "name": "cargo-doc-mcp",
      "url": "https://github.com/spacemeowx2/cargo-doc-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/spacemeowx2.webp",
      "description": "Manage and interact with Rust documentation, performing tasks such as checking, building, and searching through project documentation. Access crate documentation and symbol listings to enhance development workflows.",
      "stars": 8,
      "forks": 2,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-21T00:33:54Z",
      "readme_content": "# cargo doc MCP Server\n\nA MCP server for managing Rust documentation through cargo doc commands. This server provides tools to check, build, and search Rust documentation locally.\n\n<a href=\"https://glama.ai/mcp/servers/l4augy7aft\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/l4augy7aft/badge\" alt=\"Cargo Doc Server MCP server\" />\n</a>\n\n## Features\n\n### Tools\n\n- `get_crate_doc` - Get crate's main documentation page for understanding overall concepts and usage\n\n  - Parameters:\n    - `project_path`: Path to the Rust project (must be absolute path)\n    - `crate_name`: Name of the crate to get documentation for\n\n- `list_symbols` - List all symbols (structs, enums, traits, etc.) in a crate's documentation\n\n  - Parameters:\n    - `project_path`: Path to the Rust project (must be absolute path)\n    - `crate_name`: Name of the crate to list symbols for\n\n- `search_doc` - Search within a crate's documentation\n  - Parameters:\n    - `project_path`: Path to the Rust project (must be absolute path)\n    - `crate_name`: Name of the crate to search in\n    - `query`: Search query (keyword or symbol)\n    - `limit` (optional): Maximum number of results to return (default: 10)\n\n## Requirements\n\n- Node.js 16 or later\n- Rust and Cargo installed\n\n## Installation\n\nInstall dependencies:\n\n```bash\npnpm install\n```\n\nBuild the server:\n\n```bash\npnpm run build\n```\n\nFor development with auto-rebuild:\n\n```bash\npnpm run watch\n```\n\n## Usage\n\nAdd the following configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"docs-rs-mcp\": {\n      \"command\": \"/absolute/path/to/docs-rs-mcp/build/index.js\"\n    }\n  }\n}\n```\n\n## Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the MCP Inspector:\n\n```bash\npnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n\n## Cache System\n\nThe server maintains a cache of built documentation paths to improve performance. Cache entries expire after 24 hours to ensure documentation stays up-to-date.\n\n## License\n\nMIT",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "documentation",
        "document",
        "cargo",
        "rust documentation",
        "crate documentation",
        "cargo doc"
      ],
      "category": "document-processing"
    },
    "speakeasy-api--markdown-sidecar-mcp": {
      "owner": "speakeasy-api",
      "name": "markdown-sidecar-mcp",
      "url": "https://github.com/speakeasy-api/markdown-sidecar-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/null.webp",
      "description": "Access and serve markdown documentation for NPM packages, Go Modules, and PyPi packages from a local environment, enhancing the code generation process. Default support for Python help documentation is included for packages lacking markdown documentation.",
      "stars": 0,
      "forks": 0,
      "license": "Unknown",
      "language": "Unknown",
      "updated_at": "",
      "readme_content": "",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "documentation",
        "markdown",
        "packages",
        "markdown documentation",
        "documentation included",
        "documentation npm"
      ],
      "category": "document-processing"
    },
    "spences10--mcp-jinaai-reader": {
      "owner": "spences10",
      "name": "mcp-jinaai-reader",
      "url": "https://github.com/spences10/mcp-jinaai-reader",
      "imageUrl": "/freedevtools/mcp/pfp/spences10.webp",
      "description": "Integrates Jina.ai's Reader API for efficient web content extraction, enabling analysis and processing of documentation and web content.",
      "stars": 29,
      "forks": 4,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-10-03T22:32:10Z",
      "readme_content": "# mcp-jinaai-reader\n---\n\n## ⚠️ Notice\n\n**This repository is no longer maintained.**\n\nThe functionality of this tool is now available in [mcp-omnisearch](https://github.com/spences10/mcp-omnisearch), which combines multiple MCP tools in one unified package.\n\nPlease use [mcp-omnisearch](https://github.com/spences10/mcp-omnisearch) instead.\n\n---\n\nA Model Context Protocol (MCP) server for integrating Jina.ai's Reader\nAPI with LLMs. This server provides efficient and comprehensive web\ncontent extraction capabilities, optimized for documentation and web\ncontent analysis.\n\n<a href=\"https://glama.ai/mcp/servers/a75afsx9cx\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/a75afsx9cx/badge\" />\n</a>\n\n## Features\n\n- 📚 Advanced web content extraction through Jina.ai Reader API\n- 🚀 Fast and efficient content retrieval\n- 📄 Complete text extraction with preserved structure\n- 🔄 Clean format optimized for LLMs\n- 🌐 Support for various content types including documentation\n- 🏗️ Built on the Model Context Protocol\n\n## Configuration\n\nThis server requires configuration through your MCP client. Here are\nexamples for different environments:\n\n### Cline Configuration\n\nAdd this to your Cline MCP settings:\n\n```json\n{\n\t\"mcpServers\": {\n\t\t\"jinaai-reader\": {\n\t\t\t\"command\": \"node\",\n\t\t\t\"args\": [\"-y\", \"mcp-jinaai-reader\"],\n\t\t\t\"env\": {\n\t\t\t\t\"JINAAI_API_KEY\": \"your-jinaai-api-key\"\n\t\t\t}\n\t\t}\n\t}\n}\n```\n\n### Claude Desktop with WSL Configuration\n\nFor WSL environments, add this to your Claude Desktop configuration:\n\n```json\n{\n\t\"mcpServers\": {\n\t\t\"jinaai-reader\": {\n\t\t\t\"command\": \"wsl.exe\",\n\t\t\t\"args\": [\n\t\t\t\t\"bash\",\n\t\t\t\t\"-c\",\n\t\t\t\t\"JINAAI_API_KEY=your-jinaai-api-key npx mcp-jinaai-reader\"\n\t\t\t]\n\t\t}\n\t}\n}\n```\n\n### Environment Variables\n\nThe server requires the following environment variable:\n\n- `JINAAI_API_KEY`: Your Jina.ai API key (required)\n\n## API\n\nThe server implements a single MCP tool with configurable parameters:\n\n### read_url\n\nConvert any URL to LLM-friendly text using Jina.ai Reader.\n\nParameters:\n\n- `url` (string, required): URL to process\n- `no_cache` (boolean, optional): Bypass cache for fresh results.\n  Defaults to false\n- `format` (string, optional): Response format (\"json\" or \"stream\").\n  Defaults to \"json\"\n- `timeout` (number, optional): Maximum time in seconds to wait for\n  webpage load\n- `target_selector` (string, optional): CSS selector to focus on\n  specific elements\n- `wait_for_selector` (string, optional): CSS selector to wait for\n  specific elements\n- `remove_selector` (string, optional): CSS selector to exclude\n  specific elements\n- `with_links_summary` (boolean, optional): Gather all links at the\n  end of response\n- `with_images_summary` (boolean, optional): Gather all images at the\n  end of response\n- `with_generated_alt` (boolean, optional): Add alt text to images\n  lacking captions\n- `with_iframe` (boolean, optional): Include iframe content in\n  response\n\n## Development\n\n### Setup\n\n1. Clone the repository\n2. Install dependencies:\n\n```bash\nnpm install\n```\n\n3. Build the project:\n\n```bash\nnpm run build\n```\n\n4. Run in development mode:\n\n```bash\nnpm run dev\n```\n\n### Publishing\n\n1. Update version in package.json\n2. Build the project:\n\n```bash\nnpm run build\n```\n\n3. Publish to npm:\n\n```bash\nnpm publish\n```\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## License\n\nMIT License - see the [LICENSE](LICENSE) file for details.\n\n## Acknowledgments\n\n- Built on the\n  [Model Context Protocol](https://github.com/modelcontextprotocol)\n- Powered by [Jina.ai Reader API](https://jina.ai)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "documentation",
        "extraction",
        "reader",
        "content extraction",
        "jinaai reader",
        "document processing"
      ],
      "category": "document-processing"
    },
    "srvdneat--docs": {
      "owner": "srvdneat",
      "name": "docs",
      "url": "https://github.com/srvdneat/docs",
      "imageUrl": "/freedevtools/mcp/pfp/null.webp",
      "description": "Provides a starter kit for creating and maintaining documentation, including guide pages, navigation, customizations, and API references. Supports local previews and automatic deployment of documentation updates via integration with a GitHub app.",
      "stars": 0,
      "forks": 0,
      "license": "Unknown",
      "language": "Unknown",
      "updated_at": "",
      "readme_content": "",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "documentation",
        "srvdneat",
        "document",
        "maintaining documentation",
        "documentation including",
        "srvdneat docs"
      ],
      "category": "document-processing"
    },
    "storacha--mcp-storage-server": {
      "owner": "storacha",
      "name": "mcp-storage-server",
      "url": "https://github.com/storacha/mcp-storage-server",
      "imageUrl": "/freedevtools/mcp/pfp/storacha.webp",
      "description": "Facilitates secure storage and retrieval of files using decentralized storage via IPFS and CIDs. Enables verifiable data exchange and integration with AI frameworks, offering free storage options to users.",
      "stars": 12,
      "forks": 6,
      "license": "Apache License 2.0",
      "language": "TypeScript",
      "updated_at": "2025-08-23T20:23:53Z",
      "readme_content": "# Storacha MCP Storage Server\n\nA Model Context Protocol (MCP) server implementation for Storacha hot storage, allowing AI applications to store and retrieve files through a standardized interface. It enables trustless, decentralized data exchange using IPFS and CIDs, ensuring data sovereignty, verifiability, and seamless integration with agent frameworks & AI systems.\n\n## Free Storage Options to Start 🚀\n\nJump-start your decentralized storage journey today!\n\n- **GitHub Users**: Sign up with your GitHub account and instantly receive **100MB of free storage** — no credit card required!\n- **Email Users**: Register with your email and add a credit card to unlock **5GB of free storage space**.\n\n## Use Cases\n\n- **Document Storage & Analysis**: Securely upload and retrieve Blob documents.\n- **Long-term Structured Data Storage**: Maintain structured data storage optimized for longevity and accessibility.\n- **Data Sharing Between Agents and Systems**: Easily share data across multiple agents and diverse systems using **CIDs (Content Identifiers)**, enabling decentralized, verifiable, and efficient data exchange.\n- **Application Integration**: Seamlessly integrate Storacha storage retrieval into applications via the Model Context Protocol.\n- **AI Model Development**: Support AI models by providing reliable versioning and access to external datasets stored in Storacha.\n- **LLM Integration**: Enhance large language models (LLMs) by connecting directly with Storacha Storage for seamless data access.\n- **Web Application Backups**: Reliably store backup copies of web applications for disaster recovery.\n- **Machine Learning Datasets**: Efficiently manage and access large datasets used in machine learning workflows.\n\n## Quick Installation Guide\n\nGet started with the Storacha MCP Storage Server in just a few simple steps.\n\n1. **Clone the Repository**\n\n   ```bash\n   git clone https://github.com/storacha/mcp-storage-server.git && cd mcp-storage-server\n   ```\n\n2. **Install Dependencies**\n\n   ```bash\n   pnpm install\n   ```\n\n3. **Generate Keys & Delegation**\n\n   - **Install the CLI**\n     ```bash\n     npm install -g @web3-storage/w3cli\n     ```\n   - **Login to Storacha**\n     ```bash\n     w3 login\n     ```\n     _Output:_\n     ```\n     ? How do you want to login?\n       Via Email\n     ❯ Via GitHub\n     ```\n     _Select **Via GitHub** and authenticate with your GitHub account._\n   - **Create a Space**\n     ```bash\n     w3 space create <your_space_name>\n     ```\n     _Replace `<your_space_name>` with a name for your new Space_. :warning: _Make sure you save the recovery key, so you can access your space from another device if needed._\n   - **Create a Private Key**\n\n     ```bash\n     w3 key create\n     ```\n\n     _Output:_\n\n     ```txt\n     AgentId: did:key:z6MkhMZRW2aoJ6BQwkpMSJu68Jgqkz1FTpr1p69cpnN43YWG\n     PrivateKey: LMgCYLkvOc8Sm0mOL4cWFLxsWP0ZPEYrLxcQqsV93/s5RLje0BKx05muAse1Hkvh+sxUW38OcHtpiN1zxfpTJ4ht4jxV0=\n     ```\n\n   - **Set the Agent ID & Create Delegation**\n     ```bash\n     w3 delegation create <agent_id> \\\n      --can 'store/add' \\\n      --can 'filecoin/offer' \\\n      --can 'upload/add' \\\n      --can 'space/blob/add' \\\n      --can 'space/index/add' --base64\n     ```\n     _Replace <agent_id> with the AgentId from the previous step. It grants the Agent the permission to store files into the recently created space_.\n\n4. **Configure the MCP Client**\n\n   Next, configure your MCP client (such as Cursor) to use this server. Most MCP clients store the configuration as JSON in the following format:\n\n   ```jsonc\n   {\n     \"mcpServers\": {\n       \"storacha-storage-server\": {\n         \"command\": \"node\",\n         \"args\": [\"./dist/index.js\"],\n         \"env\": {\n           // The server supports `stdio`, `sse`, and `rest` modes, the default is `stdio`.\n           \"MCP_TRANSPORT_MODE\": \"stdio\",\n           // The Storacha Agent private key that is authorized to store data into the Space.\n           \"PRIVATE_KEY\": \"<agent_private_key>\",\n           // The base64 encoded delegation that proves the Agent is allowed to store data. If not set, MUST be provided for each upload request.\n           \"DELEGATION\": \"<base64_delegation>\",\n         },\n         \"shell\": true,\n         \"cwd\": \"./\",\n       },\n     },\n   }\n   ```\n\n   _Replace `<agent_private_key>` with the PrivateKey you created in step 3. Then, replace the `<base64_delegation>` with the delegation you created in step 3._\n\n   ### REST Mode and Cloud Hosting\n\n   The Storacha MCP Storage Server supports REST transport mode, which is compatible with MCP.so cloud hosting. To use REST mode:\n\n   ```jsonc\n   {\n     \"mcpServers\": {\n       \"storacha-storage-server-rest\": {\n         \"url\": \"http://localhost:3001/rest\",\n       },\n     },\n   }\n   ```\n\n   For more information on deploying to MCP.so cloud, see the [integrations.md](https://github.com/storacha/mcp-storage-server/blob/main/docs/integrations.md#mcpso-cloud-hosting) guide.\n\n   _:warning: There are several ways to configure MCP clients, please read the [integrations.md](https://github.com/storacha/mcp-storage-server/blob/main/docs/integrations.md) guide for more information._\n\n## Tools\n\nThe Storacha MCP Storage Server provides the following tools for AI systems to interact with a decentralized storage network.\n\n### Storage Operations\n\n#### upload\n\nUpload a file to the Storacha Network. The file must be provided as a base64 encoded string with a filename that includes the extension for MIME type detection.\n\n```typescript\ninterface UploadParams {\n  // Base64 encoded file content\n  file: string;\n  // Filename with extension for MIME type detection\n  name: string;\n  // Optional: Whether to publish to Filecoin (default: false)\n  publishToFilecoin?: boolean;\n  // Optional: Custom delegation proof\n  delegation?: string;\n  // Optional: Custom gateway URL\n  gatewayUrl?: string;\n}\n```\n\n#### retrieve\n\nRetrieve a file from the Storacha Network. Supported filepath formats: `CID/filename`, `/ipfs/CID/filename`, or `ipfs://CID/filename`.\n\n```typescript\ninterface RetrieveParams {\n  // Path in format: CID/filename, /ipfs/CID/filename, or ipfs://CID/filename\n  filepath: string;\n  // Optional: Whether to use multiformat base64 encoding\n  useMultiformatBase64?: boolean;\n}\n```\n\n#### identity\n\nReturns the `DIDKey` of the Storacha Agent loaded from the private key storage configuration.\n\n```typescript\ninterface IdentityParams {\n  // No parameters required\n}\n```\n\nSee the [integrations.md](https://github.com/storacha/mcp-storage-server/blob/main/docs/integrations.md) guide for detailed code examples and different integration patterns (SDK, Docker, etc).\n\n## License\n\nMIT or Apache 2 License\n\n## Support\n\nFor support, please visit [Storacha Support](https://storacha.network) or open an issue in this repository.\n\n## Certifications\n- [MCP Review](https://mcpreview.com/mcp-servers/storacha/mcp-storage-server)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ipfs",
        "storage",
        "files",
        "decentralized storage",
        "mcp storage",
        "storage server"
      ],
      "category": "document-processing"
    },
    "swairshah--zotero-mcp-server": {
      "owner": "swairshah",
      "name": "zotero-mcp-server",
      "url": "https://github.com/swairshah/zotero-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/swairshah.webp",
      "description": "Access and manage your Zotero library programmatically, enabling the search of papers, management of notes, and the ability to request summaries through MCP clients. Facilitates seamless integration into research workflows with existing tools.",
      "stars": 20,
      "forks": 2,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-08-23T05:46:16Z",
      "readme_content": "# Zotero MCP Server\n\nA MCP (Model Context Protocol) server to let your MCP clients (e.g. Anthropic Claude App, Goose, possibly vscode Cline too) interact with your local Zotero repository. This server enables programmatic access to your Zotero library, allowing you to search papers, manage notes, and more.\n\n**Note**: If you don't want to set up API keys, see the [SQLite database server option](#alternative-direct-sqlite-database-access) below.\n\n## Setup\n\n1. Install dependencies:\n```bash\npip install -e .\n```\n\n2. Create a `.env` file in the root directory with your Zotero credentials:\n```bash\nZOTERO_API_KEY=your_api_key_here\nZOTERO_USER_ID=your_user_id_here\n```\n\nYou can get your Zotero API key and user ID from [Zotero's settings page](https://www.zotero.org/settings/keys).\n\n## Integration with Anthropic Desktop App\n\nTo integrate with the Anthropic Desktop app, add the following configuration to `~/Library/Application Support/Claude/claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"zotero-mcp-server\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/Users/swairshah/work/research/zotero-mcp\",\n        \"run\",\n        \"python\",\n        \"-m\",\n        \"zotero_mcp.server\"\n      ]\n    }\n  }\n}\n```\nIf this gives an error like\n``` \n{\"method\":\"initialize\",\"params\":{\"protocolVersion\":\"2024-11-05\",\"capabilities\":{},\"clientInfo\":{\"name\":\"claude-ai\",\"version\":\"0.1.0\"}},\"jsonrpc\":\"2.0\",\"id\":0}\n  error: unexpected argument '--directory' found\n```\nThen use the following config, make sure to do `uv venv`; `source .venv/bin/activate`; `uv pip install \".[dev]\"` to make sure the server can be run with all dependencies. \n\n```json\n{\n   \"mcpServers\": {\n      \"zotero-mcp-server\": {\n        \"command\": \"bash\",\n        \"args\": [\n          \"-c\",\n          \"cd /Users/shahswai/personal/zotero-mcp-server && source .venv/bin/activate && python -m zotero_mcp.server\"\n        ]\n      }\n    }\n  }\n```\n\n## Alternative: Direct SQLite Database Access\n\nIf you prefer to bypass the Zotero API entirely and work directly with the SQLite database, use `zotero_mcp/db_server.py`. This approach gives you full control over your Zotero data without API limitations. Note that you'll need to close Zotero completely before using this method since SQLite locks the database when Zotero is running.\n\nClaude MCP config for the SQLite version:\n```json\n{\n  \"mcpServers\": {\n    \"zotero-mcp-server\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/Users/swair/work/code/zotero-mcp-server\",\n        \"run\",\n        \"python\",\n        \"-m\",\n        \"zotero_mcp.db_server\"\n      ]\n    }\n  }\n}\n```\n\n## Example Usage\n\n\n\nThe server allows you to:\n- Search papers by tags\n- Get paper details and attached notes\n- Add notes to papers\n- Request paper summaries",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "zotero",
        "workflows",
        "document",
        "zotero library",
        "manage zotero",
        "document processing"
      ],
      "category": "document-processing"
    },
    "sylphxltd--pdf-reader-mcp": {
      "owner": "sylphxltd",
      "name": "pdf-reader-mcp",
      "url": "https://github.com/sylphxltd/pdf-reader-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/sylphxltd.webp",
      "description": "Enables secure reading and extraction of text, metadata, and page counts from PDF files. Processes multiple PDFs from local paths or URLs with structured JSON output for easy parsing.",
      "stars": 262,
      "forks": 34,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T07:07:54Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/sylphxltd-pdf-reader-mcp-badge.png)](https://mseep.ai/app/sylphxltd-pdf-reader-mcp)\n\n# PDF Reader MCP Server (@sylphlab/pdf-reader-mcp)\n\n<!-- Status Badges Area -->\n\n[![CI/CD Pipeline](https://github.com/sylphlab/pdf-reader-mcp/actions/workflows/ci.yml/badge.svg)](https://github.com/sylphlab/pdf-reader-mcp/actions/workflows/ci.yml)\n[![codecov](https://codecov.io/gh/sylphlab/pdf-reader-mcp/graph/badge.svg?token=VYRQFB40UN)](https://codecov.io/gh/sylphlab/pdf-reader-mcp)\n[![npm version](https://badge.fury.io/js/%40sylphlab%2Fpdf-reader-mcp.svg)](https://badge.fury.io/js/%40sylphlab%2Fpdf-reader-mcp)\n[![Docker Pulls](https://img.shields.io/docker/pulls/sylphlab/pdf-reader-mcp.svg)](https://hub.docker.com/r/sylphlab/pdf-reader-mcp)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\n<!-- End Status Badges Area -->\n\nEmpower your AI agents (like Cline) with the ability to securely read and extract information (text, metadata, page count) from PDF files within your project context using a single, flexible tool.\n\n<a href=\"https://glama.ai/mcp/servers/@sylphlab/pdf-reader-mcp\">\n  \n</a>\n\n## Installation\n\n### Using npm (Recommended)\n\nInstall as a dependency in your MCP host environment or project:\n\n```bash\npnpm add @sylphlab/pdf-reader-mcp # Or npm install / yarn add\n```\n\nConfigure your MCP host (e.g., `mcp_settings.json`) to use `npx`:\n\n```json\n{\n  \"mcpServers\": {\n    \"pdf-reader-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\"@sylphlab/pdf-reader-mcp\"],\n      \"name\": \"PDF Reader (npx)\"\n    }\n  }\n}\n```\n\n_(Ensure the host sets the correct `cwd` for the target project)_\n\n### Using Docker\n\nPull the image:\n\n```bash\ndocker pull sylphlab/pdf-reader-mcp:latest\n```\n\nConfigure your MCP host to run the container, mounting your project directory to `/app`:\n\n```json\n{\n  \"mcpServers\": {\n    \"pdf-reader-mcp\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-v\",\n        \"/path/to/your/project:/app\", // Or use \"$PWD:/app\", \"%CD%:/app\", etc.\n        \"sylphlab/pdf-reader-mcp:latest\"\n      ],\n      \"name\": \"PDF Reader (Docker)\"\n    }\n  }\n}\n```\n\n### Local Build (For Development)\n\n1. Clone: `git clone https://github.com/sylphlab/pdf-reader-mcp.git`\n2. Install: `cd pdf-reader-mcp && pnpm install`\n3. Build: `pnpm run build`\n4. Configure MCP Host:\n   ```json\n   {\n     \"mcpServers\": {\n       \"pdf-reader-mcp\": {\n         \"command\": \"node\",\n         \"args\": [\"/path/to/cloned/repo/pdf-reader-mcp/build/index.js\"],\n         \"name\": \"PDF Reader (Local Build)\"\n       }\n     }\n   }\n   ```\n   _(Ensure the host sets the correct `cwd` for the target project)_\n\n## Quick Start\n\nAssuming the server is running and configured in your MCP host:\n\n**MCP Request (Get metadata and page 2 text from a local PDF):**\n\n```json\n{\n  \"tool_name\": \"read_pdf\",\n  \"arguments\": {\n    \"sources\": [\n      {\n        \"path\": \"./documents/my_report.pdf\",\n        \"pages\": [2]\n      }\n    ],\n    \"include_metadata\": true,\n    \"include_page_count\": false, // Default is true, explicitly false here\n    \"include_full_text\": false // Ignored because 'pages' is specified\n  }\n}\n```\n\n**Expected Response Snippet:**\n\n```json\n{\n  \"results\": [\n    {\n      \"source\": \"./documents/my_report.pdf\",\n      \"success\": true,\n      \"data\": {\n        \"page_texts\": [\n          { \"page\": 2, \"text\": \"Text content from page 2...\" }\n        ],\n        \"info\": { ... },\n        \"metadata\": { ... }\n        // num_pages not included as requested\n      }\n    }\n  ]\n}\n```\n\n## Why Choose This Project?\n\n- **🛡️ Secure:** Confines file access strictly to the project root directory.\n- **🌐 Flexible:** Handles both local relative paths and public URLs.\n- **🧩 Consolidated:** A single `read_pdf` tool serves multiple extraction needs (full text, specific pages, metadata, page count).\n- **⚙️ Structured Output:** Returns data in a predictable JSON format, easy for agents to parse.\n- **🚀 Easy Integration:** Designed for seamless use within MCP environments via `npx` or Docker.\n- **✅ Robust:** Uses `pdfjs-dist` for reliable parsing and Zod for input validation.\n\n## Performance Advantages\n\nInitial benchmarks using Vitest on a sample PDF show efficient handling of various operations:\n\n| Scenario                         | Operations per Second (hz) | Relative Speed |\n| :------------------------------- | :------------------------- | :------------- |\n| Handle Non-Existent File         | ~12,933                    | Fastest        |\n| Get Full Text                    | ~5,575                     |                |\n| Get Specific Page (Page 1)       | ~5,329                     |                |\n| Get Specific Pages (Pages 1 & 2) | ~5,242                     |                |\n| Get Metadata & Page Count        | ~4,912                     | Slowest        |\n\n_(Higher hz indicates better performance. Results may vary based on PDF complexity and environment.)_\n\nSee the [Performance Documentation](./docs/performance/index.md) for more details and future plans.\n\n## Features\n\n- Read full text content from PDF files.\n- Read text content from specific pages or page ranges.\n- Read PDF metadata (author, title, creation date, etc.).\n- Get the total page count of a PDF.\n- Process multiple PDF sources (local paths or URLs) in a single request.\n- Securely operates within the defined project root.\n- Provides structured JSON output via MCP.\n- Available via npm and Docker Hub.\n\n## Design Philosophy\n\nThe server prioritizes security through context confinement, efficiency via structured data transfer, and simplicity for easy integration into AI agent workflows. It aims for minimal dependencies, relying on the robust `pdfjs-dist` library.\n\nSee the full [Design Philosophy](./docs/design/index.md) documentation.\n\n## Comparison with Other Solutions\n\nCompared to direct file access (often infeasible) or generic filesystem tools, this server offers PDF-specific parsing capabilities. Unlike external CLI tools (e.g., `pdftotext`), it provides a secure, integrated MCP interface with structured output, enhancing reliability and ease of use for AI agents.\n\nSee the full [Comparison](./docs/comparison/index.md) documentation.\n\n## Future Plans (Roadmap)\n\n- **Documentation:**\n  - Finalize all documentation sections (Guide, API, Design, Comparison).\n  - Resolve TypeDoc issue and generate API documentation.\n  - Add more examples and advanced usage patterns.\n  - Implement PWA support and mobile optimization for the docs site.\n  - Add share buttons and growth metrics to the docs site.\n- **Benchmarking:**\n  - Conduct comprehensive benchmarks with diverse PDF files (size, complexity).\n  - Measure memory usage.\n  - Compare URL vs. local file performance.\n- **Core Functionality:**\n  - Explore potential optimizations for very large PDF files.\n  - Investigate options for extracting images or annotations (longer term).\n- **Testing:**\n  - Increase test coverage towards 100% where practical.\n  - Add runtime tests once feasible.\n\n## Documentation\n\nFor detailed usage, API reference, and guides, please visit the **[Full Documentation Website](https://sylphlab.github.io/pdf-reader-mcp/)** (Link to be updated upon deployment).\n\n## Community & Support\n\n- **Found a bug or have a feature request?** Please open an issue on [GitHub Issues](https://github.com/sylphlab/pdf-reader-mcp/issues).\n- **Want to contribute?** We welcome contributions! Please see [CONTRIBUTING.md](./CONTRIBUTING.md).\n- **Star & Watch:** If you find this project useful, please consider starring ⭐ and watching 👀 the repository on [GitHub](https://github.com/sylphlab/pdf-reader-mcp) to show your support and stay updated!\n\n## License\n\nThis project is licensed under the [MIT License](./LICENSE).",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "pdfs",
        "pdf",
        "sylphxltd",
        "pdf reader",
        "sylphxltd pdf",
        "reader mcp"
      ],
      "category": "document-processing"
    },
    "takashiishida--arxiv-latex-mcp": {
      "owner": "takashiishida",
      "name": "arxiv-latex-mcp",
      "url": "https://github.com/takashiishida/arxiv-latex-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/takashiishida.webp",
      "description": "Fetches and processes LaTeX sources of arXiv papers, enabling AI models to accurately interpret mathematical content and equations without the limitations of PDF files.",
      "stars": 66,
      "forks": 7,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-04T06:58:54Z",
      "readme_content": "# arxiv-latex MCP Server\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![GitHub Release](https://img.shields.io/github/v/release/takashiishida/arxiv-latex-mcp)](https://github.com/takashiishida/arxiv-latex-mcp/releases)\n\n\nAn MCP server that enables [Claude Desktop](https://claude.ai/download), [Cursor](https://www.cursor.com/), or other MCP clients to directly access and process arXiv papers by fetching the LaTeX source. It uses [arxiv-to-prompt](https://github.com/takashiishida/arxiv-to-prompt) under the hood to handle downloading and processing the LaTeX.\n\nWhy use the LaTeX source instead of uploading PDFs? Many PDF chat applications often struggle with mathematical content and equation-heavy papers. By utilizing the original LaTeX source code from arXiv papers, the LLM can accurately understand and handle equations and notations. This approach is particularly valuable for fields like computer science, mathematics, and engineering where precise interpretation of mathematical expressions is crucial.\n\n## Installation\n\nIf you are using Claude Desktop and MacOS, you can utilize Desktop Extensions by double-clicking on the .dxt file to install.\nDownload the .dxt file from [here](https://github.com/takashiishida/arxiv-latex-mcp/releases/).\n\nOtherwise, you can manually add the following configuration to your config file:\n```json\n{\n  \"mcpServers\": {\n      \"arxiv-latex-mcp\": {\n          \"command\": \"uv\",\n          \"args\": [\n              \"--directory\",\n              \"/ABSOLUTE/PATH/TO/arxiv-latex-mcp\",\n              \"run\",\n              \"server/main.py\"\n          ]\n      }\n  }\n}\n```\n\nYou may need to replace the `command` field with the full path of `uv`: check this by running `which uv` (MacOS/Linux) or `where uv` (Windows).\n\nRestart the application after saving the above.\n\nFor Claude Desktop, click on the hammer icon, and you should see `get_paper_prompt` in the list of \"Available MCP tools\".\n\n## Example\nTry asking questions about a paper from arXiv, e.g., \"Explain the first theorem in 2202.00395\"\n\n<div align=\"center\">\n  \n</div>",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "latex",
        "ai",
        "arxiv",
        "arxiv latex",
        "arxiv papers",
        "latex sources"
      ],
      "category": "document-processing"
    },
    "takuya0206--obsidian-mcp": {
      "owner": "takuya0206",
      "name": "obsidian-mcp",
      "url": "https://github.com/takuya0206/obsidian-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/takuya0206.webp",
      "description": "Interact with an Obsidian vault to read, write, and manipulate notes using a standardized interface, facilitating enhanced productivity and organization.",
      "stars": 2,
      "forks": 1,
      "license": "ISC License",
      "language": "TypeScript",
      "updated_at": "2025-04-09T09:26:56Z",
      "readme_content": "# Obsidian MCP (Model Context Protocol)\n\nObsidian MCP is a tool that allows you to interact with your Obsidian vault using the Model Context Protocol. This enables AI assistants to read, write, and manipulate notes in your Obsidian vault through a standardized interface.\n\n\n## Prerequisites\n\n- Node.js 18 or higher\n- Obsidian with [Local REST API plugin](https://github.com/coddingtonbear/obsidian-local-rest-api) installed and configured\n- API key generated from the Local REST API plugin\n\n## Setting MCP Server (e.g. Claude Desktop App)\n\n1. Clone this repository\n2. Install dependencies:\n   ```\n   npm install\n   ```\n3. Build the project:\n   ```\n   npm run build\n   ```\n\n4. Configure Claude Desktop App to use this MCP server:\n   ```\n   {\n      \"mcpServers\": {\n        \"Obsidian\": {\n          \"command\": \"node\",\n          \"args\": [\"/Users/<Your Own Path>/obsisian-mcp/build/index.js\"],\n          \"env\": {\n            \"apiKey\": \"<Your API Token>\",\n            \"port\": \"27123\",\n            \"host\": \"127.0.0.1\"\n          }\n        }\n      }\n    }\n   ```\n## Development\nCreate `.env` and configure \"apiKey\", \"port\", and \"host\" as mentioned above.\n\n\n### Available Tools\n\nThe following tools are implemented:\n\n1. **readNote** - Read the contents of a specific note\n   ```\n   {\n     \"path\": \"path/to/note.md\"\n   }\n   ```\n\n2. **readActiveNote** - Read the contents of the current active note\n   ```\n   {}\n   ```\n\n3. **listNotes** - Recursively lists files and folders in the entire Vault or under a specified folder\n   ```\n   {\n     \"path\": \"optional/folder/path\"\n   }\n   ```\n\n4. **patchNote** - Inserts content into an existing note relative to a heading, block reference, or frontmatter field\n   ```\n   {\n     \"path\": \"path/to/note.md\",\n     \"operation\": \"append|prepend|replace\",\n     \"targetType\": \"heading|block|frontmatter\",\n     \"target\": \"target_identifier\",\n     \"content\": \"content to insert\"\n   }\n   ```\n\n5. **searchWithJsonLogic** - Search Obsidian notes using JsonLogic format queries\n   ```\n   {\n     \"query\": {\n       // JsonLogic query object\n     }\n   }\n   ```\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "obsidian",
        "document",
        "vault",
        "obsidian mcp",
        "obsidian vault",
        "interact obsidian"
      ],
      "category": "document-processing"
    },
    "tatn--mcp-server-diff-python": {
      "owner": "tatn",
      "name": "mcp-server-diff-python",
      "url": "https://github.com/tatn/mcp-server-diff-python",
      "imageUrl": "/freedevtools/mcp/pfp/tatn.webp",
      "description": "Obtain text differences between two strings using Python's `difflib`, providing output in Unified diff format suitable for text comparison and version control.",
      "stars": 7,
      "forks": 6,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-06-02T12:48:21Z",
      "readme_content": "# mcp-server-diff-python\n\nAn MCP server for obtaining text differences between two strings.\nThis server leverages Python's standard library `difflib` to efficiently generate and provide differences between two texts in Unified diff format, making it ideal for text comparison and version control purposes.\n\n<a href=\"https://glama.ai/mcp/servers/qbwsx2g4vd\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/qbwsx2g4vd/badge\" alt=\"Server Diff Python MCP server\" /></a>\n\n## Features\n\n### Tools\n\nThe server provides a single tool:\n\n- **get-unified-diff**: Get differences between two texts in Unified diff format\n  - Arguments:\n    - `string_a`: Source text for comparison (required)\n    - `string_b`: Target text to compare against (required)\n  - Return value: A string containing the differences in Unified diff format\n\n## Usage\n\n### Claude Desktop\n\nUsing with Claude Desktop\nTo use with Claude Desktop, add the server config:\n\nOn MacOS:  `~/Library/Application\\ Support/Claude/claude_desktop_config.json`  \nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n\"mcpServers\": {\n  \"mcp-server-diff-python\": {\n    \"command\": \"uvx\",\n    \"args\": [\n      \"mcp-server-diff-python\"\n    ]\n  }\n}\n```\n\nor Add the following configuration:\n\n```bash\ngit clone https://github.com/tatn/mcp-server-diff-python.git\ncd mcp-server-diff-python\nuv sync\nuv build\n```\n\n```json\n\"mcpServers\": {\n  \"mcp-server-diff-python\": {\n    \"command\": \"uv\",\n    \"args\": [\n      \"--directory\",\n      \"path\\\\to\\\\mcp-server-diff-python\",\n      \"run\",\n      \"mcp-server-diff-python\"\n    ]\n  }\n}\n```\n\n## Development\n### Debugging\n\nYou can start the MCP Inspector using [npx](https://docs.npmjs.com/cli/v11/commands/npx)with the following commands:\n\n```bash\nnpx @modelcontextprotocol/inspector uvx mcp-server-diff-python\n```\n\n```bash\nnpx @modelcontextprotocol/inspector uv --directory path\\to\\mcp-server-diff-python run mcp-server-diff-python\n```\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "difflib",
        "diff",
        "python",
        "diff python",
        "python difflib",
        "diff format"
      ],
      "category": "document-processing"
    },
    "tatn--mcp-server-fetch-typescript": {
      "owner": "tatn",
      "name": "mcp-server-fetch-typescript",
      "url": "https://github.com/tatn/mcp-server-fetch-typescript",
      "imageUrl": "/freedevtools/mcp/pfp/tatn.webp",
      "description": "Retrieves and converts web content using various formats and rendering methods, suitable for both data extraction and web scraping tasks. It allows access to text-based resources and provides raw text content from specified URLs without additional processing.",
      "stars": 3,
      "forks": 6,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-19T14:03:40Z",
      "readme_content": "# mcp-server-fetch-typescript MCP Server\n\nA Model Context Protocol server that provides web content fetching and conversion capabilities. This server implements a comprehensive web content retrieval system with support for various formats and rendering methods, making it ideal for tasks ranging from simple data extraction to sophisticated web scraping.\n\n<a href=\"https://glama.ai/mcp/servers/iyfpvfkgyx\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/iyfpvfkgyx/badge\" alt=\"Server Fetch TypeScript MCP server\" /></a>\n\n## Features\n\n### Tools\n\n- `get_raw_text` - Retrieve raw text content directly from URLs\n  - Takes `url` as a required parameter pointing to text-based resources\n  - Returns unprocessed text content without browser rendering\n  - Ideal for JSON, XML, CSV, TSV, or plain text files\n  - Best used when fast, direct access to source content is needed\n\n- `get_rendered_html` - Fetch fully rendered HTML content\n  - Takes `url` as a required parameter\n  - Returns complete HTML content after JavaScript execution\n  - Uses Playwright for headless browser rendering\n  - Essential for modern web applications and SPAs\n\n- `get_markdown` - Convert web content to Markdown format\n  - Takes `url` as a required parameter\n  - Returns well-formatted Markdown preserving structural elements\n  - Supports tables and definition lists\n  - Recommended for content archiving and documentation\n\n- `get_markdown_summary` - Extract and convert main content\n  - Takes `url` as a required parameter\n  - Returns clean Markdown focusing on main content\n  - Automatically removes navigation, headers, footers\n  - Perfect for article and blog post extraction\n\n## Installation\n\n### As a Global Package\n\n```bash\nnpm install -g mcp-server-fetch-typescript\n```\n\n### As a Project Dependency\n\n```bash\nnpm install mcp-server-fetch-typescript\n```\n\n## Usage\n\n### Using with Claude Desktop\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`  \nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n\"mcpServers\": {\n  \"mcp-server-fetch-typescript\": {\n    \"command\": \"npx\",\n    \"args\": [\n      \"-y\",\n      \"mcp-server-fetch-typescript\"\n    ]\n  }\n}\n```\n\nor Add the following configuration:\n\n```bash\ngit clone https://github.com/tatn/mcp-server-fetch-typescript.git\ncd mcp-server-fetch-typescript\nnpm install\nnpm run build\n```\n\n```json\n\"mcpServers\": {\n  \"mcp-server-fetch-typescript\": {\n    \"command\": \"node\",\n    \"args\": [\n      \"/path/to/mcp-server-fetch-typescript/build/index.js\"\n    ]\n  }\n}\n```\n\n### Debugging\n\nTo debug the MCP server:\n\n```bash\nnpx @modelcontextprotocol/inspector npx -y mcp-server-fetch-typescript\n```\n\n```bash\nnpx @modelcontextprotocol/inspector node /path/to/mcp-server-fetch-typescript/build/index.js\n```\n\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "typescript",
        "fetch",
        "scraping",
        "extraction web",
        "fetch typescript",
        "typescript retrieves"
      ],
      "category": "document-processing"
    },
    "taweili--mcp-rss-md": {
      "owner": "taweili",
      "name": "mcp-rss-md",
      "url": "https://github.com/taweili/mcp-rss-md",
      "imageUrl": "/freedevtools/mcp/pfp/taweili.webp",
      "description": "Generates Markdown content from RSS feeds, transforming raw RSS data into well-structured Markdown documents for easy sharing and publishing.",
      "stars": 0,
      "forks": 1,
      "license": "Other",
      "language": "TypeScript",
      "updated_at": "2025-03-20T18:28:46Z",
      "readme_content": "# RSS to Markdown MCP Server\n\nAn MCP (Model Context Protocol) server that provides tools for converting RSS feeds into Markdown format.\n\n## Installation\n\n1. Clone this repository\n2. Run `npm install` to install dependencies\n3. Add the server to your MCP configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"rss-to-md\": {\n      \"command\": \"node\",\n      \"args\": [\"rss-to-md-server.js\"]\n    }\n  }\n}\n```\n\n## MCP Tools\n\nThis server provides the following MCP tools:\n\n- `convert_rss`: Converts an RSS feed to Markdown format\n  - Parameters:\n    - `url`: The URL of the RSS feed to convert\n    - `outputPath`: (Optional) Path to save the Markdown output\n\n## Usage\n\n### As an MCP Server\n\nOnce configured, you can use the MCP tools through any MCP client.\n\n### Standalone\n\nYou can also run the server directly:\n\n```bash\nnode rss-to-md-server.js\n```\n\n## License\n\nThis project is licensed under the GPL-3.0 License - see the [LICENSE](LICENSE) file for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "markdown",
        "rss",
        "feeds",
        "rss md",
        "markdown documents",
        "raw rss"
      ],
      "category": "document-processing"
    },
    "taxihabbel--parsemypdf": {
      "owner": "taxihabbel",
      "name": "parsemypdf",
      "url": "https://github.com/taxihabbel/parsemypdf",
      "imageUrl": "/freedevtools/mcp/pfp/taxihabbel.webp",
      "description": "Extract and analyze complex PDF documents using various tools to maintain document structure and efficiently extract tables, images, and mixed content. Specialized processors are available tailored to the complexity and content type of the PDFs.",
      "stars": 1,
      "forks": 0,
      "license": "MIT License",
      "language": "",
      "updated_at": "2025-08-13T22:52:33Z",
      "readme_content": "<div align=\"center\">\n<h1><a href=\"https://www.instagram.com/genieincodebottle/\"><img width=\"200\" src=\"https://github.com/genieincodebottle/generative-ai/blob/main/images/logo_genie_new.png\">&nbsp;</a></h1>\n</div>\n<div align=\"center\">\n    <a target=\"_blank\" href=\"https://www.youtube.com/@genieincodebottle\"><img src=\"https://img.shields.io/badge/YouTube-@genieincodebottle-blue\"></a>&nbsp;\n    <a target=\"_blank\" href=\"https://www.linkedin.com/in/rajesh-srivastava\"><img src=\"https://img.shields.io/badge/style--5eba00.svg?label=LinkedIn&logo=linkedin&style=social\"></a>&nbsp;\n    <a target=\"_blank\" href=\"https://www.instagram.com/genieincodebottle/\"><img src=\"https://img.shields.io/badge/@genieincodebottle-C13584?style=flat-square&labelColor=C13584&logo=instagram&logoColor=white&link=https://www.instagram.com/eduardopiresbr/\"></a>&nbsp;\n    <a target=\"_blank\" href=\"https://github.com/genieincodebottle/generative-ai/blob/main/GenAI_Roadmap.md\"><img src=\"https://img.shields.io/badge/style--5eba00.svg?label=GenAI Roadmap&logo=github&style=social\"></a>\n</div>\n\n#  \n\n# 📑 Complex PDF Parsing\n\nA comprehensive example codes for extracting content from PDFs\n\nAlso, check -> [Pdf Parsing Guide](https://github.com/genieincodebottle/parse-my-pdf/blob/main/pdf-parsing-guide.pdf)\n\n## 📌 Core Features\n\n### 📤 Content Extraction\n- Multiple extraction methods with different tools/libraries:\n  - Cloud-based: Claude 3.5 Sonnet, GPT-4 Vision, Unstructured.io\n  - Local: Llama 3.2 11B, Docling, PDFium\n  - Specialized: Camelot (tables), PDFMiner (text), PDFPlumber (mixed), PyPdf etc\n- Maintains document structure and formatting\n- Handles complex PDFs with mixed content including extracting image data\n\n\n## 📦 Implementation Options\n\n### 1. ☁️ Cloud-Based Methods\n- **Claude & Llama**: Excellent  for complex PDFs with mixed content\n- **GPT-4 Vision**: Excellent for visual content analysis\n- **Unstructured.io**: Advanced content partitioning and classification\n\n### 2. 🖥️ Local Methods\n- **Llama 3.2 11B Vision**: Image-based PDF processing\n- **Docling**: Excellent  for complex PDFs with mixed content\n- **PDFium**: High-fidelity processing using Chrome's PDF engine\n- **Camelot**: Specialized table extraction\n- **PDFMiner/PDFPlumber**: Basic text and layout extraction\n\n## 🔗 Dependencies\n\n### 📚 Core Libraries\n```bash\nlangchain_ollama\nlangchain_huggingface\nlangchain_community\nFAISS\npython-dotenv\n```\n\n### ⚙️ Implementation-Specific\n```bash\nanthropic        # Claude\nopenai           # GPT-4 Vision\ncamelot-py      # Table extraction\ndocling         # Text processing\npdf2image       # PDF conversion\npypdfium2       # PDFium processing\nboto3           # AWS Textract\n```\n\n## 🛠️ Setup\n\n1. Environment Variables\n```bash\nANTHROPIC_API_KEY=your_key_here    # For Claude\nOPENAI_API_KEY=your_key_here       # For OpenAI\nUNSTRUCTURED_API_KEY=your_key_here # For Unstructured.io\n```\n\n2. Install Dependencies\n```bash\npip install -r requirements.txt\n```\n\n3. Install Ollama & Models (for local processing)\n```bash\n# Install Ollama\ncurl https://ollama.ai/install.sh | sh\n\n# Pull required models\nollama pull llama3.1\nollama pull x/llama3.2-vision:11b\n```\n\n## 📈 Usage\n\n1. Place PDF files in `input/` directory\n\n## 📄 Example Complex Pdf placed in Input folder\n- **sample-1.pdf**: Standard tables\n- **sample-2.pdf**: Image-based simple tables\n- **sample-3.pdf**: Image-based complex tables\n- **sample-4.pdf**: Mixed content (text, tables, images)\n\n## 📝 Notes\n- System resources needed for local LLM operations\n- API keys required for cloud based implementations\n- Consider PDF complexity when choosing implementation\n- Ghostscript required for Camelot\n- Different processors suit different use cases\n  - Cloud: Complex documents, mixed content\n  - Local: Simple text, basic tables\n  - Specialized: Specific content types (tables, forms)",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "parsemypdf",
        "pdfs",
        "pdf",
        "parsemypdf extract",
        "taxihabbel parsemypdf",
        "pdf documents"
      ],
      "category": "document-processing"
    },
    "thirdstrandstudio--mcp-xpath": {
      "owner": "thirdstrandstudio",
      "name": "mcp-xpath",
      "url": "https://github.com/thirdstrandstudio/mcp-xpath",
      "imageUrl": "/freedevtools/mcp/pfp/thirdstrandstudio.webp",
      "description": "Execute XPath queries on XML and HTML content, fetching and querying data from URLs or local files. Return structured results to enhance applications with powerful XML data manipulation capabilities.",
      "stars": 0,
      "forks": 4,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-08-04T16:44:53Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/thirdstrandstudio-mcp-xpath-badge.png)](https://mseep.ai/app/thirdstrandstudio-mcp-xpath)\n\n# XPath MCP Server\n\n[![Third Strand Studio](https://img.shields.io/badge/Third%20Strand%20Studio-Visit%20Us-blue)](https://tss.topiray.com)\n\nMCP Server for executing XPath queries on XML content.\n\n<a href=\"https://glama.ai/mcp/servers/@thirdstrandstudio/mcp-xpath\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@thirdstrandstudio/mcp-xpath/badge\" alt=\"mcp-xpath MCP server\" />\n</a>\n\n![image](https://github.com/user-attachments/assets/369045f3-1cdb-4204-9c62-0f5f32636262)\n\n[![smithery badge](https://smithery.ai/badge/@thirdstrandstudio/mcp-xpath)](https://smithery.ai/server/@thirdstrandstudio/mcp-xpath)\n\n## Tools\n\n1. `xpath`\n   - Query XML content using XPath expressions\n   - Inputs:\n     - `xml` (string): The XML content to query\n     - `query` (string): The XPath query to execute\n     - `mimeType` (optional, string): The MIME type (e.g. text/xml, application/xml, text/html, application/xhtml+xml)\n   - Returns: The result of the XPath query as a string\n\n2. `xpathwithurl`\n   - Fetch content from a URL and query it using XPath expressions\n   - Inputs:\n     - `url` (string): The URL to fetch XML/HTML content from\n     - `query` (string): The XPath query to execute\n     - `mimeType` (optional, string): The MIME type (e.g. text/xml, application/xml, text/html, application/xhtml+xml)\n   - Returns: The result of the XPath query as a string\n\n## Installation\n\n### Installing via Smithery\n\nTo install mcp-xpath for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@thirdstrandstudio/mcp-xpath):\n\n```bash\nnpx -y @smithery/cli install @thirdstrandstudio/mcp-xpath --client claude\n```\n\n```bash\n# Install dependencies\nnpm install\n\n# Build the package\nnpm run build\n```\n\n## Setup\n\n### Usage with Claude Desktop\n\nAdd the following to your `claude_desktop_config.json`:\n\n#### npx\n\n```json\n{\n  \"mcpServers\": {\n    \"xpath\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"@thirdstrandstudio/mcp-xpath\"\n      ]\n    }\n  }\n}\n```\n\n#### Direct Node.js\n\n```json\n{\n  \"mcpServers\": {\n    \"xpath\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/path/to/mcp-xpath/dist/index.js\"\n      ]\n    }\n  }\n}\n```\n\nReplace `/path/to/mcp-xpath` with the actual path to your repository.\n\n\n## Examples\n\n### Query XML content\n\n```javascript\n// Select all <item> elements from XML\nconst result = await callTool(\"xpath\", {\n  xml: \"<root><item>value1</item><item>value2</item></root>\",\n  query: \"//item/text()\",\n  mimeType: \"text/xml\"\n});\n```\n\n### Query HTML content\n\n```javascript\n// Get all links from HTML\nconst result = await callTool(\"xpath\", {\n  xml: \"<html><body><a href='link1.html'>Link 1</a><a href='link2.html'>Link 2</a></body></html>\",\n  query: \"//a/@href\",\n  mimeType: \"text/html\"\n});\n```\n\n### Query URL content\n\n```javascript\n// Get all links from a webpage\nconst result = await callTool(\"xpathwithurl\", {\n  url: \"https://example.com\",\n  query: \"//a/@href\",\n  mimeType: \"text/html\"\n});\n```\n\n## Development\n\n```bash\n# Install dependencies\nnpm install\n\n# Start the server in development mode\nnpm start\n```\n\n## License\n\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "xpath",
        "xml",
        "thirdstrandstudio",
        "mcp xpath",
        "xpath queries",
        "execute xpath"
      ],
      "category": "document-processing"
    },
    "tizee--mcp-server-ietf": {
      "owner": "tizee",
      "name": "mcp-server-ietf",
      "url": "https://github.com/tizee/mcp-server-ietf",
      "imageUrl": "/freedevtools/mcp/pfp/tizee.webp",
      "description": "Access and retrieve IETF RFC documents, enabling search by keywords and management of document pagination. Provides standardized access to essential specifications for Large Language Models.",
      "stars": 8,
      "forks": 3,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-27T16:37:54Z",
      "readme_content": "# MCP-Server-IETF\n\nA Model Context Protocol server for fetching IETF documents (RFCs) for Large Language Models.\n\n## Overview\n\nThis project implements a [Model Context Protocol (MCP)](https://modelcontextprotocol.github.io/) server that provides access to IETF RFC documents. It enables Large Language Models to access RFC specifications through a standardized interface.\n\nKey features:\n- Download and cache RFC index and documents\n- Search RFCs by keyword in titles\n- Access RFC documents with pagination support\n- Extract metadata like page numbers from documents\n\n## Installation\n\n### Requirements\n- Python 3.11 or higher\n- Dependencies as listed in `pyproject.toml`\n\n### Install from source\n\n```bash\n# Clone the repository\ngit clone https://github.com/tizee/mcp-server-ietf\ncd mcp-server-ietf\n\n# Install with pip\npip install -e .\n```\n\n## Usage\n\n### Starting the server\n\n```bash\n# Start the server\nmcp-server-ietf\n```\n\nOr use it with the MCP inspector:\n\n```bash\nnpx @modelcontextprotocol/inspector uv run mcp-server-ietf\n```\n\n### Available Tools\n\nWhen connected to the server, the following tools are available:\n\n#### `list_docs_number`\nGet the total number of RFC documents available in the index.\n\n#### `get_doc`\nGet an RFC document by its number with pagination support.\n\nParameters:\n- `number`: The RFC number (e.g., \"1234\")\n- `start_line`: The line number to start from (default: 1)\n- `max_lines`: Maximum number of lines to return (default: 200)\n\n#### `search_rfc_by_keyword`\nSearch for RFC documents by keyword in their titles.\n\nParameters:\n- `keyword`: The search term to look for in RFC titles\n\n## Development\n\n### Setup Development Environment\n\n```bash\n# Install development dependencies\nuv install -e .[dev]\n```\n\nRun inspector with Makefile:\n\n```\nmake dev\n```\n\n### Running Tests\n\n```bash\n# Run tests\nuv run pytest\n```\n\nOr using the Makefile:\n\n```bash\nmake test\n```\n\n### Cache Location\n\nBy default, the server caches RFC documents and the index at `~/.cache/ietf-doc-server`.\n\n### Environment Variables\n\n- `LOG_LEVEL`: Set the logging level (default: \"DEBUG\")\n\n## License\n\nMIT License - See `LICENSE` file for details.\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "rfc",
        "document",
        "documents",
        "rfc documents",
        "ietf rfc",
        "document processing"
      ],
      "category": "document-processing"
    },
    "tizee--mcp-unix-manual": {
      "owner": "tizee",
      "name": "mcp-unix-manual",
      "url": "https://github.com/tizee/mcp-unix-manual",
      "imageUrl": "/freedevtools/mcp/pfp/tizee.webp",
      "description": "Retrieve Unix command documentation, including help pages and version information. List common commands and check command availability within conversations.",
      "stars": 1,
      "forks": 6,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-04-05T23:34:38Z",
      "readme_content": "# Unix Manual Server (MCP)\n\nAn MCP server that provides Unix command documentation directly within Claude conversations.\n\n## Features\n\n- **Get command documentation**: Retrieve help pages, man pages, and usage information for Unix commands\n- **List common commands**: Discover available commands on your system, categorized by function\n- **Check command existence**: Verify if a specific command is available and get its version information\n\n## Installation\n\n### Prerequisites\n\n- Python 3.13+\n- [Claude Desktop](https://claude.ai/download) or any MCP-compatible client\n\n### Setup\n\n1. Clone this repository\n2. Install the package:\n\n```bash\npip install -e .\n# or\nuv install -e .\n```\n\n3. Install the server in Claude Desktop:\n\n```bash\nmcp install unix_manual_server.py\n# uv\nuv run mcp install unix_manual_server.py\n```\n\n## Usage\n\nOnce installed, you can use the server's tools directly in Claude:\n\n### Get command documentation\n\n```\nI need help with the grep command. Can you show me the documentation?\n```\n\n### List common commands\n\n```\nWhat Unix commands are available on my system?\n```\n\n### Check if a command exists\n\n```\nIs the awk command available on my system?\n```\n\n## Development\n\nTo test the server locally without installing it in Claude:\n\n```bash\nmcp dev unix_manual_server.py\n```\n\n## Security\n\nThe server takes precautions to prevent command injection by:\n- Validating command names against a regex pattern\n- Executing commands directly without using shell\n- Setting timeouts on all command executions\n- Only checking for documentation, never executing arbitrary commands\n\n## Logging\n\nLogs are saved to `unix-manual-server.log` in the same directory as the script, useful for debugging.\n\n- use `@modelcontextprotocol/inspector` with `npx` under the hood.\n\n```zsh\nuv run mcp dev unix_manual_server.py\n```\n\n```\nnpx @modelcontextprotocol/inspector uv run unix_manual_server.py\n```\n\n## License\n\nMIT\n\n---\n\n*Created with the MCP Python SDK. For more information about MCP, visit [modelcontextprotocol.io](https://modelcontextprotocol.io).*\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "commands",
        "unix",
        "documentation",
        "command documentation",
        "unix manual",
        "mcp unix"
      ],
      "category": "document-processing"
    },
    "trafflux--pdf-reader-mcp": {
      "owner": "trafflux",
      "name": "pdf-reader-mcp",
      "url": "https://github.com/trafflux/pdf-reader-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/trafflux.webp",
      "description": "Extracts text from both local and online PDF files with robust error handling and standardized output. Supports various PDF formats and includes features for auto-detection of encoding and volume mounting.",
      "stars": 31,
      "forks": 8,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-10-02T09:42:50Z",
      "readme_content": "# PDF Reader MCP Server\n\nA Model Context Protocol (MCP) server that provides tools for reading and extracting text from PDF files, supporting both local files and URLs.\n\n## Author\n\nPhilip Van de Walker  \nEmail: philip.vandewalker@gmail.com  \nGitHub: https://github.com/trafflux\n\n## Features\n\n- Read text content from local PDF files\n- Read text content from PDF URLs\n- Error handling for corrupt or invalid PDFs\n- Volume mounting for accessing local PDFs\n- Auto-detection of PDF encoding\n- Standardized JSON output format\n\n## Installation\n\n1. Clone the repository:\n\n```bash\ngit clone https://github.com/trafflux/pdf-reader-mcp.git\ncd pdf-reader-mcp\n```\n\n2. Build the Docker image:\n\n```bash\ndocker build -t mcp/pdf-reader .\n```\n\n## Usage\n\n### Running the Server\n\nTo run the server with access to local PDF files:\n\n```bash\ndocker run -i --rm -v /path/to/pdfs:/pdfs mcp/pdf-reader\n```\n\nReplace `/path/to/pdfs` with the actual path to your PDF files directory.\n\nIf not using local PDF files:\n\n```bash\ndocker run -i --rm mcp/pdf-reader\n```\n\n### MCP Configuration\n\nAdd to your MCP settings configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"pdf-reader\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-v\",\n        \"/path/to/pdfs:/pdfs\",\n        \"mcp/pdf-reader\"\n      ],\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\nWithout local file PDF files:\n\n```json\n{\n  \"mcpServers\": {\n    \"pdf-reader\": {\n      \"command\": \"docker\",\n      \"args\": [\"run\", \"-i\", \"--rm\", \"mcp/pdf-reader\"],\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\n### Available Tools\n\n1. `read_local_pdf`\n\n   - Purpose: Read text content from a local PDF file\n   - Input:\n     ```json\n     {\n       \"path\": \"/pdfs/document.pdf\"\n     }\n     ```\n   - Output:\n     ```json\n     {\n       \"success\": true,\n       \"data\": {\n         \"text\": \"Extracted content...\"\n       }\n     }\n     ```\n\n2. `read_pdf_url`\n   - Purpose: Read text content from a PDF URL\n   - Input:\n     ```json\n     {\n       \"url\": \"https://example.com/document.pdf\"\n     }\n     ```\n   - Output:\n     ```json\n     {\n       \"success\": true,\n       \"data\": {\n         \"text\": \"Extracted content...\"\n       }\n     }\n     ```\n\n## Error Handling\n\nThe server handles various error cases with clear error messages:\n\n- Invalid or corrupt PDF files\n- Missing files\n- Failed URL requests\n- Permission issues\n- Network connectivity problems\n\nError responses follow the format:\n\n```json\n{\n  \"success\": false,\n  \"error\": \"Detailed error message\"\n}\n```\n\n## Dependencies\n\n- Python 3.11+\n- PyPDF2: PDF parsing and text extraction\n- requests: HTTP client for fetching PDFs from URLs\n- MCP SDK: Model Context Protocol implementation\n\n## Project Structure\n\n```\n.\n├── Dockerfile          # Container configuration\n├── README.md          # This documentation\n├── requirements.txt   # Python dependencies\n└── src/\n    ├── __init__.py    # Package initialization\n    └── server.py      # Main server implementation\n```\n\n## License\n\nCopyright 2025 Philip Van de Walker\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## Contact\n\nFor questions, issues, or contributions, please contact Philip Van de Walker:\n\n- Email: philip.vandewalker@gmail.com\n- GitHub: https://github.com/trafflux\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "pdf",
        "trafflux",
        "formats",
        "trafflux pdf",
        "pdf reader",
        "pdf formats"
      ],
      "category": "document-processing"
    },
    "truaxki--mcp-Pdf2png": {
      "owner": "truaxki",
      "name": "mcp-Pdf2png",
      "url": "https://github.com/truaxki/mcp-Pdf2png",
      "imageUrl": "/freedevtools/mcp/pfp/truaxki.webp",
      "description": "Convert PDF documents into high-quality PNG images seamlessly, transforming each page of a PDF into a PNG file using a simple MCP tool call. Enhance document processing with efficient image generation from PDFs.",
      "stars": 6,
      "forks": 4,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-08-13T02:42:13Z",
      "readme_content": "# PDF to PNG MCP Server\n\nA Model Context Protocol (MCP) server that provides PDF to PNG conversion capabilities. This server allows you to convert PDF documents into PNG images with a simple MCP tool call.\n\n## Prerequisites\n\nThis server requires the Model Context Protocol (MCP). If you're new to MCP, start by installing the SDK:\n```bash\nuv pip install mcp\n```\n\nAdditional requirements:\n- Python 3.10 or higher\n- [uv](https://github.com/astral-sh/uv) package manager\n- poppler (required for pdf2image)\n\n### Installing Poppler\n\n- **Windows**: Download and install from [poppler-windows](https://github.com/oschwartz10612/poppler-windows/releases/)\n- **macOS**: `brew install poppler`\n- **Linux**: `sudo apt-get install poppler-utils`\n\n## Installation\n\n1. Clone this repository:\n   ```bash\n   git clone https://github.com/truaxki/mcp-Pdf2png.git\n   cd mcp-Pdf2png\n   ```\n\n2. Create and activate a virtual environment:\n   ```bash\n   uv venv\n   # Windows\n   .venv\\Scripts\\activate\n   # Unix/macOS\n   source .venv/bin/activate\n   ```\n\n3. Install the package:\n   ```bash\n   uv pip install -e .\n   ```\n\n## Usage\n\n### 1. Configure MCP Client\n\nAdd the server configuration to your `claude_desktop_config.json`. The file is typically located in:\n- Windows: `%APPDATA%\\Claude Desktop\\config\\claude_desktop_config.json`\n- macOS/Linux: `~/.config/Claude Desktop/config/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"pdf2png\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/absolute/path/to/mcp-Pdf2png\",\n        \"run\",\n        \"pdf2png\"\n      ]\n    }\n  }\n}\n```\n\nNote: Replace `/absolute/path/to/mcp-Pdf2png` with the actual path where you cloned the repository.\n\n### 2. Using the Server\n\nThe server provides a single tool `pdf2png` with these parameters:\n- `read_file_path`: Absolute path to the input PDF file\n- `write_folder_path`: Absolute path to the directory where PNG files should be saved\n\nOutput:\n- Each PDF page is converted to a PNG image\n- Files are named `page_1.png`, `page_2.png`, etc.\n- Returns a success message with the conversion count\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "pdf2png",
        "pdfs",
        "png",
        "mcp pdf2png",
        "pdf png",
        "pdf2png convert"
      ],
      "category": "document-processing"
    },
    "tuki0918--eagle-mcp-server": {
      "owner": "tuki0918",
      "name": "eagle-mcp-server",
      "url": "https://github.com/tuki0918/eagle-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/tuki0918.webp",
      "description": "Integrates with the Eagle app to manage and interact with digital assets through a standardized MCP interface, enabling operations such as folder and item management, metadata retrieval, and media handling.",
      "stars": 3,
      "forks": 1,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-22T11:24:54Z",
      "readme_content": "# Eagle MCP Server (Unofficial)\n\n> [!NOTE]\n> [Official MCP support is planned for Eagle v5 (public beta in Q1 2026)](https://eagle.cool/blog/post/eagle5-teaser)\n\n\n\nA Model Context Protocol (MCP) server for Eagle.\n\n<details>\n\n<summary>Supported file formats:</summary>\n\n- `JPG` / `JPEG`\n- `PNG`\n- `PDF`\n- `SVG`\n- `MP4`\n- `MP3`\n- `FBX`\n- `OBJ`\n- `EPS`\n- `TIF` / `TIFF`\n- `WebP`\n- `BMP`\n- `ICO`\n- `RAW`\n- etc\n\n</details>\n\n- Eagle: https://eagle.cool/<br />\n- Eagle API docs: https://api.eagle.cool/<br />\n\n## Requirements\n\n- Python 3.13\n- [uv](https://docs.astral.sh/uv/)\n\n## Prerequisites\n\nInstall the required dependencies:\n\n```bash\nuv sync\n```\n\n## Usage\n\n1. Launch the [Eagle](https://eagle.cool/) app.\n2. Launch this MCP server by running the following command:\n\n```bash\nuv run main.py\n```\n\n\n## Connecting to the MCP Server using Streamable HTTP\n\nExample config (Cursor editor recommended):\n\n```\n{\n  \"mcpServers\": {\n    \"eagle-mcp-server\": {\n      \"url\": \"http://localhost:8000/mcp\"\n    }\n  }\n}\n```\n\n## Tools\n\n| Supported | Eagle API endpoint | Operation ID | Enabled (default) | Category |\n|:----:|:---------------------------|:-------------------------|:----:|:------------|\n| ✅ | -               | `connect`                |  | MCP         |\n| ✅ | /api/application/info      | `get_application_info`   | ⚫︎ | Application |\n| ✅ | /api/folder/create         | `create_folder`          | ⚫︎ | Folder      |\n| ✅ | /api/folder/rename         | `rename_folder`          |  | Folder      |\n| ✅ | /api/folder/update         | `update_folder`          | ⚫︎ | Folder      |\n| ✅ | /api/folder/list           | `get_folder_list`        | ⚫︎ | Folder      |\n| ✅ | /api/folder/listRecent     | `get_folder_list_recent` |  | Folder      |\n| ✅ | /api/item/addFromURL       | `add_item_from_url`      |  | Item        |\n| ✅ | /api/item/addFromURLs      | `add_items_from_urls`    |  | Item        |\n| ✅ | /api/item/addFromPath      | `add_item_from_path`     | ⚫︎ | Item        |\n| ✅ | /api/item/addFromPaths     | `add_items_from_paths`   |  | Item        |\n| ✅ | /api/item/addBookmark      | `add_bookmark`           |  | Item        |\n| ✅ | /api/item/info             | `get_item_info`          | ⚫︎ | Item        |\n| ✅ | -           | `get_item_source`        | ⚫︎ | Item        |\n| ✅ | /api/item/thumbnail        | `get_item_thumbnail`     |  | Item        |\n| ✅ | /api/item/list             | `get_item_list`          | ⚫︎ | Item        |\n| ✅ | /api/item/moveToTrash      | `move_item_to_trash`     | ⚫︎ | Item        |\n| ✅ | /api/item/refreshPalette   | `refresh_item_palette`   |  | Item        |\n| ✅ | /api/item/refreshThumbnail | `refresh_item_thumbnail` |  | Item        |\n| ✅ | /api/item/update           | `update_item`            | ⚫︎ | Item        |\n| ✅ | /api/library/info          | `get_library_info`       | ⚫︎ | Library     |\n| ✅ | /api/library/history       | `get_library_history`    |  | Library     |\n| ✅ | /api/library/switch        | `switch_library`         |  | Library     |\n| ✅ | /api/library/icon          | `get_library_icon`       |  | Library     |\n\nMCP Server API docs: \n- https://tuki0918.github.io/eagle-mcp-server/\n- http://localhost:8000/redoc\n\n## Enabling Disabled Tools\n\nSome tools are disabled by default (shown as empty cells in the \"Enabled (default)\" column above). To enable these disabled tools:\n\n1. Locate the tool definition in the source code\n2. Remove the `tags=[\"Disabled\"]` line from the tool configuration\n3. Restart the MCP server\n\nThis will make the previously disabled tools available for use.\n\n## Use Cases\n\n### 1) Same Host (Recommended)\n\n```mermaid\nflowchart LR\n\n    subgraph 192.168.1.100\n        direction LR\n        \n        subgraph FileSystem [File System]\n        end\n        subgraph EagleApp [Eagle App<br/>localhost:41595]\n        end\n        subgraph MCPServer [MCP Server<br/>localhost:8000]\n        end\n        subgraph MCPClient [MCP Client]\n        end\n    end\n\n    EagleApp ==> MCPServer e1@==> MCPClient\n    MCPClient e2@==> MCPServer ==> EagleApp\n    EagleApp ==> FileSystem\n    FileSystem ==> EagleApp\n\n    e1@{ animate: true }\n    e2@{ animate: true }\n```\n\n> [!TIP]\n> You have direct access to the filesystem.\n\n### 2) Other Host (MCP Client) + Same Host (MCP Server, Eagle App)\n\n```mermaid\nflowchart LR\n  \n    subgraph 192.168.1.100\n        subgraph FileSystem [File System]\n        end\n        subgraph EagleApp [Eagle App<br/>localhost:41595]\n        end\n        subgraph MCPServer [MCP Server<br/>localhost:8000]\n        end\n    end\n\n    subgraph 192.168.1.xxx\n        subgraph MCPClient [MCP Client]\n        end\n    end\n\n    EagleApp ==> MCPServer e1@==> MCPClient\n    MCPClient e2@==> MCPServer ==> EagleApp\n    EagleApp ==> FileSystem\n    FileSystem ==> EagleApp\n\n    e1@{ animate: true }\n    e2@{ animate: true }\n```\n\n> [!WARNING]\n> You don't have access to the filesystem.\n\n### 3) Other Host\n\n```mermaid\nflowchart LR\n\n    subgraph 192.168.1.100\n        subgraph FileSystem [File System]\n        end\n        subgraph EagleApp [Eagle App<br/>localhost:41595]\n        end\n    end\n\n    subgraph 192.168.1.101\n        subgraph MCPServer [MCP Server<br/>localhost:8000]\n        end\n    end\n\n    subgraph 192.168.1.xxx\n        subgraph MCPClient [MCP Client]\n        end\n    end\n\n    EagleApp ==> MCPServer e1@==> MCPClient\n    MCPClient e2@==> MCPServer ==> EagleApp\n    EagleApp ==> FileSystem\n    FileSystem ==> EagleApp\n\n    e1@{ animate: true }\n    e2@{ animate: true }\n```\n\n> [!WARNING]\n> You don't have access to the filesystem.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "eagle",
        "mcp",
        "processing",
        "eagle mcp",
        "eagle app",
        "integrates eagle"
      ],
      "category": "document-processing"
    },
    "tumf--mcp-text-editor": {
      "owner": "tumf",
      "name": "mcp-text-editor",
      "url": "https://github.com/tumf/mcp-text-editor",
      "imageUrl": "/freedevtools/mcp/pfp/tumf.webp",
      "description": "Provides line-oriented text file editing capabilities through a standardized API, optimized for efficient interaction with large language models, enabling partial file access to minimize token usage.",
      "stars": 161,
      "forks": 21,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-04T01:16:39Z",
      "readme_content": "# MCP Text Editor Server\n\n[![codecov](https://codecov.io/gh/tumf/mcp-text-editor/branch/main/graph/badge.svg?token=52D51U0ZUR)](https://codecov.io/gh/tumf/mcp-text-editor)\n[![smithery badge](https://smithery.ai/badge/mcp-text-editor)](https://smithery.ai/server/mcp-text-editor)\n[![Glama MCP Server](https://glama.ai/mcp/servers/k44dnvso10/badge)](https://glama.ai/mcp/servers/k44dnvso10)\n\nA Model Context Protocol (MCP) server that provides line-oriented text file editing capabilities through a standardized API. Optimized for LLM tools with efficient partial file access to minimize token usage.\n\n## Quick Start for Claude.app Users\n\nTo use this editor with Claude.app, add the following configuration to your prompt:\n\n```shell\ncode ~/Library/Application\\ Support/Claude/claude_desktop_config.json\n```\n\n```json\n{\n  \"mcpServers\": {\n    \"text-editor\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"mcp-text-editor\"\n      ]\n    }\n  }\n}\n```\n\n## Overview\n\nMCP Text Editor Server is designed to facilitate safe and efficient line-based text file operations in a client-server architecture. It implements the Model Context Protocol, ensuring reliable file editing with robust conflict detection and resolution. The line-oriented approach makes it ideal for applications requiring synchronized file access, such as collaborative editing tools, automated text processing systems, or any scenario where multiple processes need to modify text files safely. The partial file access capability is particularly valuable for LLM-based tools, as it helps reduce token consumption by loading only the necessary portions of files.\n\n### Key Benefits\n\n- Line-based editing operations\n- Token-efficient partial file access with line-range specifications\n- Optimized for LLM tool integration\n- Safe concurrent editing with hash-based validation\n- Atomic multi-file operations\n- Robust error handling with custom error types\n- Comprehensive encoding support (utf-8, shift_jis, latin1, etc.)\n\n## Features\n\n- Line-oriented text file editing and reading\n- Smart partial file access to minimize token usage in LLM applications\n- Get text file contents with line range specification\n- Read multiple ranges from multiple files in a single operation\n- Line-based patch application with correct handling of line number shifts\n- Edit text file contents with conflict detection\n- Flexible character encoding support (utf-8, shift_jis, latin1, etc.)\n- Support for multiple file operations\n- Proper handling of concurrent edits with hash-based validation\n- Memory-efficient processing of large files\n\n## Requirements\n\n- Python 3.11 or higher\n- POSIX-compliant operating system (Linux, macOS, etc.) or Windows\n- Sufficient disk space for text file operations\n- File system permissions for read/write operations\n\n1. Install Python 3.11+\n\n```bash\npyenv install 3.11.6\npyenv local 3.11.6\n```\n\n2. Install uv (recommended) or pip\n\n```bash\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n```\n\n3. Create virtual environment and install dependencies\n\n```bash\nuv venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\nuv pip install -e \".[dev]\"\n```\n\n## Requirements\n\n- Python 3.13+\n- POSIX-compliant operating system (Linux, macOS, etc.) or Windows\n- File system permissions for read/write operations\n\n## Installation\n\n### Run via uvx\n\n```bash\nuvx mcp-text-editor\n```\n\n### Installing via Smithery\n\nTo install Text Editor Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/mcp-text-editor):\n\n```bash\nnpx -y @smithery/cli install mcp-text-editor --client claude\n```\n\n### Manual Installation\n\n1. Install Python 3.13+\n\n```bash\npyenv install 3.13.0\npyenv local 3.13.0\n```\n\n2. Install uv (recommended) or pip\n\n```bash\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n```\n\n3. Create virtual environment and install dependencies\n\n```bash\nuv venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\nuv pip install -e \".[dev]\"\n```\n\n## Usage\n\nStart the server:\n\n```bash\npython -m mcp_text_editor\n```\n\n### MCP Tools\n\nThe server provides several tools for text file manipulation:\n\n#### get_text_file_contents\n\nGet the contents of one or more text files with line range specification.\n\n**Single Range Request:**\n\n```json\n{\n  \"file_path\": \"path/to/file.txt\",\n  \"line_start\": 1,\n  \"line_end\": 10,\n  \"encoding\": \"utf-8\"  // Optional, defaults to utf-8\n}\n```\n\n**Multiple Ranges Request:**\n\n```json\n{\n  \"files\": [\n    {\n      \"file_path\": \"file1.txt\",\n      \"ranges\": [\n        {\"start\": 1, \"end\": 10},\n        {\"start\": 20, \"end\": 30}\n      ],\n      \"encoding\": \"shift_jis\"  // Optional, defaults to utf-8\n    },\n    {\n      \"file_path\": \"file2.txt\",\n      \"ranges\": [\n        {\"start\": 5, \"end\": 15}\n      ]\n    }\n  ]\n}\n```\n\nParameters:\n- `file_path`: Path to the text file\n- `line_start`/`start`: Line number to start from (1-based)\n- `line_end`/`end`: Line number to end at (inclusive, null for end of file)\n- `encoding`: File encoding (default: \"utf-8\"). Specify the encoding of the text file (e.g., \"shift_jis\", \"latin1\")\n\n**Single Range Response:**\n\n```json\n{\n  \"contents\": \"File contents\",\n  \"line_start\": 1,\n  \"line_end\": 10,\n  \"hash\": \"sha256-hash-of-contents\",\n  \"file_lines\": 50,\n  \"file_size\": 1024\n}\n```\n\n**Multiple Ranges Response:**\n\n```json\n{\n  \"file1.txt\": [\n    {\n      \"content\": \"Lines 1-10 content\",\n      \"start\": 1,\n      \"end\": 10,\n      \"hash\": \"sha256-hash-1\",\n      \"total_lines\": 50,\n      \"content_size\": 512\n    },\n    {\n      \"content\": \"Lines 20-30 content\",\n      \"start\": 20,\n      \"end\": 30,\n      \"hash\": \"sha256-hash-2\",\n      \"total_lines\": 50,\n      \"content_size\": 512\n    }\n  ],\n  \"file2.txt\": [\n    {\n      \"content\": \"Lines 5-15 content\",\n      \"start\": 5,\n      \"end\": 15,\n      \"hash\": \"sha256-hash-3\",\n      \"total_lines\": 30,\n      \"content_size\": 256\n    }\n  ]\n}\n```\n\n#### patch_text_file_contents\n\nApply patches to text files with robust error handling and conflict detection. Supports editing multiple files in a single operation.\n\n**Request Format:**\n\n```json\n{\n  \"files\": [\n    {\n      \"file_path\": \"file1.txt\",\n      \"hash\": \"sha256-hash-from-get-contents\",\n      \"encoding\": \"utf-8\",  // Optional, defaults to utf-8\n      \"patches\": [\n        {\n          \"start\": 5,\n          \"end\": 8,\n          \"range_hash\": \"sha256-hash-of-content-being-replaced\",\n          \"contents\": \"New content for lines 5-8\\n\"\n        },\n        {\n          \"start\": 15,\n          \"end\": null,  // null means end of file\n          \"range_hash\": \"sha256-hash-of-content-being-replaced\",\n          \"contents\": \"Content to append\\n\"\n        }\n      ]\n    }\n  ]\n}\n```\n\nImportant Notes:\n1. Always get the current hash and range_hash using get_text_file_contents before editing\n2. Patches are applied from bottom to top to handle line number shifts correctly\n3. Patches must not overlap within the same file\n4. Line numbers are 1-based\n5. `end: null` can be used to append content to the end of file\n6. File encoding must match the encoding used in get_text_file_contents\n\n**Success Response:**\n\n```json\n{\n  \"file1.txt\": {\n    \"result\": \"ok\",\n    \"hash\": \"sha256-hash-of-new-contents\"\n  }\n}\n```\n\n**Error Response with Hints:**\n\n```json\n{\n  \"file1.txt\": {\n    \"result\": \"error\",\n    \"reason\": \"Content hash mismatch\",\n    \"suggestion\": \"get\",  // Suggests using get_text_file_contents\n    \"hint\": \"Please run get_text_file_contents first to get current content and hashes\"\n  }\n}\n```\n\n    \"result\": \"error\",\n    \"reason\": \"Content hash mismatch - file was modified\",\n    \"hash\": \"current-hash\",\n    \"content\": \"Current file content\"\n\n  }\n}\n\n```\n\n### Common Usage Pattern\n\n1. Get current content and hash:\n\n```python\ncontents = await get_text_file_contents({\n    \"files\": [\n        {\n            \"file_path\": \"file.txt\",\n            \"ranges\": [{\"start\": 1, \"end\": null}]  # Read entire file\n        }\n    ]\n})\n```\n\n2. Edit file content:\n\n```python\nresult = await edit_text_file_contents({\n    \"files\": [\n        {\n            \"path\": \"file.txt\",\n            \"hash\": contents[\"file.txt\"][0][\"hash\"],\n            \"encoding\": \"utf-8\",  # Optional, defaults to \"utf-8\"\n            \"patches\": [\n                {\n                    \"line_start\": 5,\n                    \"line_end\": 8,\n                    \"contents\": \"New content\\n\"\n                }\n            ]\n        }\n    ]\n})\n```\n\n3. Handle conflicts:\n\n```python\nif result[\"file.txt\"][\"result\"] == \"error\":\n    if \"hash mismatch\" in result[\"file.txt\"][\"reason\"]:\n        # File was modified by another process\n        # Get new content and retry\n        pass\n```\n\n### Error Handling\n\nThe server handles various error cases:\n- File not found\n- Permission errors\n- Hash mismatches (concurrent edit detection)\n- Invalid patch ranges\n- Overlapping patches\n- Encoding errors (when file cannot be decoded with specified encoding)\n- Line number out of bounds\n\n## Security Considerations\n\n- File Path Validation: The server validates all file paths to prevent directory traversal attacks\n- Access Control: Proper file system permissions should be set to restrict access to authorized directories\n- Hash Validation: All file modifications are validated using SHA-256 hashes to prevent race conditions\n- Input Sanitization: All user inputs are properly sanitized and validated\n- Error Handling: Sensitive information is not exposed in error messages\n\n## Troubleshooting\n\n### Common Issues\n\n1. Permission Denied\n   - Check file and directory permissions\n   - Ensure the server process has necessary read/write access\n\n2. Hash Mismatch and Range Hash Errors\n   - The file was modified by another process\n   - Content being replaced has changed\n   - Run get_text_file_contents to get fresh hashes\n\n3. Encoding Issues\n   - Verify file encoding matches the specified encoding\n   - Use utf-8 for new files\n   - Check for BOM markers in files\n\n4. Connection Issues\n   - Verify the server is running and accessible\n   - Check network configuration and firewall settings\n\n5. Performance Issues\n   - Consider using smaller line ranges for large files\n   - Monitor system resources (memory, disk space)\n   - Use appropriate encoding for file type\n\n## Development\n\n### Setup\n\n1. Clone the repository\n2. Create and activate a Python virtual environment\n3. Install development dependencies: `uv pip install -e \".[dev]\"`\n4. Run tests: `make all`\n\n### Code Quality Tools\n\n- Ruff for linting\n- Black for code formatting\n- isort for import sorting\n- mypy for type checking\n- pytest-cov for test coverage\n\n### Testing\n\nTests are located in the `tests` directory and can be run with pytest:\n\n```bash\n# Run all tests\npytest\n\n# Run tests with coverage report\npytest --cov=mcp_text_editor --cov-report=term-missing\n\n# Run specific test file\npytest tests/test_text_editor.py -v\n```\n\nCurrent test coverage: 90%\n\n### Project Structure\n\n```\nmcp-text-editor/\n├── mcp_text_editor/\n│   ├── __init__.py\n│   ├── __main__.py      # Entry point\n│   ├── models.py        # Data models\n│   ├── server.py        # MCP Server implementation\n│   ├── service.py       # Core service logic\n│   └── text_editor.py   # Text editor functionality\n├── tests/               # Test files\n└── pyproject.toml       # Project configuration\n```\n\n## License\n\nMIT\n\n## Contributing\n\n1. Fork the repository\n2. Create a feature branch\n3. Make your changes\n4. Run tests and code quality checks\n5. Submit a pull request\n\n### Type Hints\n\nThis project uses Python type hints throughout the codebase. Please ensure any contributions maintain this.\n\n### Error Handling\n\nAll error cases should be handled appropriately and return meaningful error messages. The server should never crash due to invalid input or file operations.\n\n### Testing\n\nNew features should include appropriate tests. Try to maintain or improve the current test coverage.\n\n### Code Style\n\nAll code should be formatted with Black and pass Ruff linting. Import sorting should be handled by isort.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "editor",
        "editing",
        "tumf",
        "file editing",
        "text editor",
        "editor provides"
      ],
      "category": "document-processing"
    },
    "tuncer-byte--memory-bank-MCP": {
      "owner": "tuncer-byte",
      "name": "memory-bank-MCP",
      "url": "https://github.com/tuncer-byte/memory-bank-MCP",
      "imageUrl": "/freedevtools/mcp/pfp/tuncer-byte.webp",
      "description": "Create and manage structured project documentation with AI assistance, generating interconnected Markdown files that capture project knowledge from goals to progress. It supports context-aware querying for efficient searching and exporting of project information.",
      "stars": 100,
      "forks": 17,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-09-27T09:34:41Z",
      "readme_content": "# Memory Bank MCP\n\n<div align=\"center\">\n  <img src=\"https://github.com/tuncer-byte/byte/blob/main/media/icons/icon-white.png\" height=\"128\">\n  <h1>Memory Bank MCP</h1>\n  <p>\n    <b>Structured project knowledge management for LLMs via Model Context Protocol (MCP)</b>\n  </p>\n</div>\n\n<a href=\"https://glama.ai/mcp/servers/@tuncer-byte/memory-bank-MCP\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@tuncer-byte/memory-bank-MCP/badge\" alt=\"Memory Bank MCP server\" />\n</a>\n\n---\n\n> **Note:** This is not a traditional Node.js application. Memory Bank MCP is an **MCP server**—a component in the [Model Context Protocol](https://modelcontextprotocol.io/introduction) ecosystem. It exposes project knowledge to LLM-powered agents and tools using a standardized protocol, enabling seamless integration with AI clients (e.g., Claude Desktop, IDEs, or custom LLM agents).\n\n---\n\n## What is Model Context Protocol (MCP)?\n\nMCP is an open protocol that standardizes how applications provide context to LLMs. Think of MCP like a USB-C port for AI: it provides a universal way to connect AI models to data sources and tools, both locally and remotely. MCP enables:\n\n- **Plug-and-play integrations** between LLMs, data, and tools\n- **Switching between LLM providers** with minimal friction\n- **Secure, modular architecture** for building AI workflows\n\nLearn more: [MCP Introduction](https://modelcontextprotocol.io/introduction)\n\n## About Memory Bank MCP\n\nMemory Bank MCP is an **MCP server** that helps teams create, manage, and access structured project documentation. It generates and maintains interconnected Markdown documents capturing all aspects of project knowledge, from high-level goals to technical details and daily progress. It is designed to be accessed by MCP-compatible clients and LLM agents.\n\n## Features\n\n- **AI-Generated Documentation**: Uses Gemini API to generate and update project documentation\n- **Structured Knowledge System**: Maintains six core document types in a hierarchical structure\n- **MCP Server**: Implements the Model Context Protocol for integration with LLM agents and tools\n- **Customizable Storage**: Choose where your Memory Bank directory is created\n- **Document Templates**: Pre-defined templates for project brief, product context, system patterns, etc.\n- **AI-Assisted Updates**: Update documents manually or regenerate them with AI\n- **Advanced Querying**: Search across all documents with context-aware relevance ranking\n\n## Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/tuncer-byte/memory-bank-mcp.git\ncd memory-bank-mcp\n\n# Install dependencies\nnpm install\n\n# (Optional) Create .env file with your Gemini API key\necho \"GEMINI_API_KEY=your_api_key_here\" > .env\n```\n\n## Usage\n\n> **Note:** Memory Bank MCP is intended to be run as an MCP server, not as a standalone app. You typically launch it as part of an MCP workflow, and connect to it from an MCP-compatible client (such as Claude Desktop or your own LLM agent).\n\n### Development Mode\n\n```bash\nnpm run dev\n```\n\n### Production Mode\n\n```bash\nnpm run build\nnpm run start\n```\n\n### MCP Integration\n\nTo connect Memory Bank MCP to your MCP client, add the following to your `mcp.json` configuration:\n\n```json\n{\n  \"memoryBank\": {\n    \"command\": \"node\",\n    \"args\": [\"/path/to/memory-bank-mcp/dist/index.js\"],\n    \"env\": {\n      \"GEMINI_API_KEY\": \"your_gemini_api_key_here\"\n    }\n  }\n}\n```\n\nReplace `/path/to/memory-bank-mcp/dist/index.js` with the absolute path to your built file, and add your Gemini API key if needed.\n\n---\n\n## MCP Tools Exposed by Memory Bank\n\nMemory Bank MCP provides the following tools via the Model Context Protocol:\n\n### `initialize_memory_bank`\n\nCreates a new Memory Bank structure with all document templates.\n\n**Parameters:**\n- `goal` (string): Project goal description (min 10 characters)\n- `geminiApiKey` (string, optional): Gemini API key for document generation\n- `location` (string, optional): Absolute path where memory-bank folder will be created\n\n**Example:**\n```javascript\nawait callTool({\n  name: \"initialize_memory_bank\",\n  arguments: {\n    goal: \"Building a self-documenting AI-powered software development assistant\",\n    location: \"/Users/username/Documents/projects/ai-assistant\"\n  }\n});\n```\n\n### `update_document`\n\nUpdates a specific document in the Memory Bank.\n\n**Parameters:**\n- `documentType` (enum): One of: `projectbrief`, `productContext`, `systemPatterns`, `techContext`, `activeContext`, `progress`\n- `content` (string, optional): New content for the document\n- `regenerate` (boolean, default: false): Whether to regenerate the document using AI\n\n**Example:**\n```javascript\nawait callTool({\n  name: \"update_document\",\n  arguments: {\n    documentType: \"projectbrief\",\n    content: \"# Project Brief\\n\\n## Purpose\\nTo develop an advanced and user-friendly AI...\"\n  }\n});\n```\n\n### `query_memory_bank`\n\nSearches across all documents with context-aware relevance ranking.\n\n**Parameters:**\n- `query` (string): Search query (min 5 characters)\n\n**Example:**\n```javascript\nawait callTool({\n  name: \"query_memory_bank\",\n  arguments: {\n    query: \"system architecture components\"\n  }\n});\n```\n\n### `export_memory_bank`\n\nExports all Memory Bank documents.\n\n**Parameters:**\n- `format` (enum, default: \"folder\"): Export format, either \"json\" or \"folder\"\n- `outputPath` (string, optional): Custom output path for the export\n\n**Example:**\n```javascript\nawait callTool({\n  name: \"export_memory_bank\",\n  arguments: {\n    format: \"json\",\n    outputPath: \"/Users/username/Documents/exports\"\n  }\n});\n```\n\n## Document Types\n\nMemory Bank organizes project knowledge into six core document types:\n\n1. **Project Brief** (`projectbrief.md`): Core document defining project objectives, scope, and vision\n2. **Product Context** (`productContext.md`): Documents product functionality from a user perspective\n3. **System Patterns** (`systemPatterns.md`): Establishes system architecture and component relationships\n4. **Tech Context** (`techContext.md`): Specifies technology stack and implementation details\n5. **Active Context** (`activeContext.md`): Tracks current tasks, open issues, and development focus\n6. **Progress** (`progress.md`): Documents completed work, milestones, and project history\n\n## License\n\nMIT",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "documentation",
        "document",
        "markdown",
        "documentation ai",
        "project documentation",
        "document processing"
      ],
      "category": "document-processing"
    },
    "u3588064--AutoGuarantee": {
      "owner": "u3588064",
      "name": "AutoGuarantee",
      "url": "https://github.com/u3588064/AutoGuarantee",
      "imageUrl": "/freedevtools/mcp/pfp/u3588064.webp",
      "description": "自动提取保函文本中的要素和条款，提供法律和金融专业人士分析所需的信息。输出结果为 JSON 格式，支持提取担保人的 SWIFT 标识代码、开立日期和保函种类等要素。",
      "stars": 2,
      "forks": 0,
      "license": "MIT License",
      "language": "",
      "updated_at": "2025-02-28T14:20:52Z",
      "readme_content": "# 保函业务自动化项目\n\n## 项目概述\n\n本项目旨在从保函文本中抽取要素、切分条款、提示要点、录制系统，以便于法律和金融专业人士进行分析和处理。项目使用自然语言处理技术，从保函文本中提取特定要素，并以JSON格式输出结果。\n\n## 项目结构\n\n```\n保函要素抽取项目/\n│\n├── data/\n│   ├── sample_guarantee.txt       # 示例保函文本\n│   └── ...                       # 其他保函文本\n│\n├── src/\n│   ├── extractor.py              # 要素抽取脚本\n│   ├── clause_splitter.py        # 条款分割脚本\n│   ├── key_points.py             # 要点提示脚本\n│   ├── format.py                 # 格式处理脚本\n│   └── ...                       # 其他源代码文件\n│\n├── tests/\n│   ├── test_extractor.py         # 要素抽取单元测试\n│   ├── test_clause_splitter.py   # 条款分割单元测试\n│   └── ...                       # 其他测试文件\n│\n├── README.md                     # 项目说明文档\n├── requirements.txt               # 项目依赖\n└── ...                           # 其他配置文件\n```\n\n## 要素列表\n\n项目目前支持抽取以下要素：\n\n1. 担保人的SWIFT标识代码\n2. 开立日期\n3. 保函种类\n4. 保函编号\n5. 担保人的名称\n6. 保函开立地址\n7. 申请人的名称\n8. 申请人的地址\n9. 受益人的名称\n10. 受益人的地址\n11. 基础合同名称\n12. 基础合同编号\n13. 基础合同货物描述\n14. 保函的金额\n15. 保函的币种\n\n## 条款分割\n\n项目支持按以下类别切分条款：\n\n1. 需提交的支持索赔的单据\n2. 需提交单据的语言\n3. 交单形式\n4. 交单地点\n5. 生效条款\n6. 失效条款\n7. 费用的承担方\n8. 担保人的承诺\n9. 索赔的提交要求\n10. 索赔的时间和地点要求\n11. 适用规则\n12. 适用法律\n13. 司法管辖地\n\n\n## 使用方法\n\n#在线版体验\n\n完成度80%，域名申请中\n\n#本地部署\n\n1. 克隆项目仓库：\n    ```bash\n    git clone https://github.com/u3588064/AutoGuarantee.git\n    cd 保函要素抽取项目\n    ```\n\n2. 安装项目依赖：\n    ```bash\n    pip install -r requirements.txt\n    ```\n\n3. 运行要素抽取脚本：\n    ```bash\n    python src/extractor.py data/sample_guarantee.txt\n    ```\n\n4. 查看输出结果：\n    脚本会在终端输出抽取的要素，以JSON格式展示。\n\n## 示例\n输入文本：\n```\nPerformance Guarantee\n\nIssue date: December 7, 2023\nNo.: XX1234567\n\nTo:Machine Shopping Department (hereinafter called 'the Beneficiary')\nAdd:Q.X.TOY 101 HUAYUAN, Korea\n\n…… (SEE Full Text in the repository)\n\nThis performance guarantee shall be valid from its issuance and remian valid until August 35, 2025 (expiry date). Any demand in respect of this guarantee should reach us at our counter not later than the close of our Business hours on the above expiry date.\n\nThis performance guarantee is only personnel to you and is not assignable or transferable.\n\nThis guaranttee is subject to the Uniform Rules for Demand Guarantees, ICC Publication No.758.\n\n```\n\n要素抽取结果：\n```json\n{\n  \"担保人的SWIFT标识代码\": \"\",\n  \"开立日期\": \"December 7, 2023\",\n  \"保函种类\": [\"Performance Guarantee\",\"Advance Payment Guarantee\"],\n  \"保函编号\": \"XX1234567\",\n  \"担保人的名称\": \"Bank of China Ltd, ABC Branch\",\n  \"保函开立地址\": \"No.1 N Road, Xi Province, P. R. China\",\n  \"申请人的名称\": \"GUANGDONG GX GROUP MACHINE CO., LTD\",\n  \"申请人的地址\": \"NO.18 E ROAD, CHINA\",\n  \"受益人的名称\": \"Machine Shopping Department\",\n  \"受益人的地址\": \"Q.X.TOY 101 HUAYUAN, Korea\",\n  \"基础合同名称\": \"Supply Contract\",\n  \"基础合同编号\": \"AK/123/2023/09\",\n  \"基础合同货物描述\": \"Supply of Toy bags\",\n  \"保函的金额\": 1,123.00,\n  \"保函的币种\": \"USD\"\n}\n{\n \"保函种类\": [\"Performance Guarantee\",\"Advance Payment Guarantee\"]\n}\n```\n\n条款切分结果：\n```\n{\n  \"需提交的支持索赔的单据\": null,\n  \"需提交单据的语言\": null,\n  \"交单形式\": \"any such demand in original should be presented to us through your Banker confirmation that the signatures thereon are authentic and legally binding upon you.\",\n  \"交单地点\": \"our counter\",\n  \"生效条款\": \"This performance guarantee shall be valid from its issuance\",\n  \"失效条款\": \"This performance guarantee shall ... remain valid until August 35, 2025 (expiry date).\",\n  \"费用的承担方\": null,\n  \"担保人的承诺\": \"we undertake to pay you unconditionally and independently, upon our receipt of your first written demand in original paper form declaring the seller fails to perform its obligations under the Contract and specifying in which respect the seller is in failure.\",\n  \"索赔的提交要求\": \"your first written demand in original paper form declaring the seller fails to perform its obligations under the Contract and specifying in which respect the seller is in failure.\",\n  \"索赔的时间和地点要求\": \"Any demand in respect of this guarantee should reach us at our counter not later than the close of our Business hours on the above expiry date.\",\n  \"适用规则\": \"This guaranttee is subject to the Uniform Rules for Demand Guarantees, ICC Publication No.758.\",\n  \"适用法律\": null,\n  \"司法管辖地\": null\n}\n```\n\n## 贡献\n\n欢迎对本项目进行贡献。如果您有任何建议或发现任何问题，请提交Issue或Pull Request。\n\n## 许可证\n\n本项目采用MIT许可证，详见LICENSE文件。\n\n## 联系方式\n\n如果您有任何问题或需要进一步的信息，请联系项目维护者：[u3588064@connect.hku.hk](mailto:u3588064@connect.hku.hk)。",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "自动提取保函文本中的要素和条款",
        "document",
        "autoguarantee",
        "autoguarantee 自动提取保函文本中的要素和条款",
        "输出结果为 json",
        "document processing"
      ],
      "category": "document-processing"
    },
    "u3588064--Entity-Resolution": {
      "owner": "u3588064",
      "name": "Entity-Resolution",
      "url": "https://github.com/u3588064/Entity-Resolution",
      "imageUrl": "/freedevtools/mcp/pfp/u3588064.webp",
      "description": "Compares two sets of data to determine if they originate from the same entity using text normalization and semantic analysis. It evaluates both exact and semantic equality of values, ensuring accurate data validation.",
      "stars": 1,
      "forks": 1,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-05-03T13:53:49Z",
      "readme_content": "# EntityIdentification\nIdentify whether two sets of data are from the same entity. 识别两组数据是否来自同一主体\n\nThis is a MCP (Model Context Protocol) server. 这是一个支持MCP协议的服务器。\n\n\n# Data Comparison Tool\n\nThis tool provides a comprehensive way to compare two sets of data, evaluating both exact and semantic equality of their values. It leverages text normalization and a language model to determine if the data originates from the same entity.\n\n## Features\n\n- **Text Normalization**: Converts text to lowercase, removes punctuation, and normalizes whitespace.\n- **Value Comparison**: Compares values directly and semantically (ignoring order for lists).\n- **JSON Traversal**: Iterates through each key in the JSON objects and compares corresponding values.\n- **Language Model Integration**: Uses a generative language model to assess semantic similarity and provide a final judgment on whether the data comes from the same entity.\n\n## Installation\n\nTo use this tool, ensure you have the necessary dependencies installed. You can install them using pip:\n\n```bash\npip install genai\n```\n\n## Usage\n\n### Functions\n\n1. **normalize_text(text)**:\n   - Normalizes the input text by converting it to lowercase, removing punctuation, and normalizing whitespace.\n\n2. **compare_values(val1, val2)**:\n   - Compares two values both exactly and semantically.\n   - If the values are lists, it ignores the order of elements for semantic comparison.\n\n3. **compare_json(json1, json2)**:\n   - Compares two JSON objects key by key.\n   - Uses `compare_values` to evaluate each key's values.\n   - Integrates a language model to assess semantic similarity and provides a final judgment.\n\n### Example\n\n```python\nimport json\nimport genai\nimport re\n\n# Define your JSON objects\njson1 = {\n    \"name\": \"John Doe\",\n    \"address\": \"123 Main St, Anytown, USA\",\n    \"hobbies\": [\"reading\", \"hiking\", \"coding\"]\n}\n\njson2 = {\n    \"name\": \"john doe\",\n    \"address\": \"123 Main Street, Anytown, USA\",\n    \"hobbies\": [\"coding\", \"hiking\", \"reading\"]\n}\n\n# Compare the JSON objects\ncomparison_results = compare_json(json1, json2)\n\n# Generate final matching result\nmodel1 = genai.GenerativeModel(\"gemini-2.0-flash-thinking-exp\")\nresult_matching = model1.generate_content(\"综合这些信息，你认为可以判断两个数据来自同一主体吗？\"+json.dumps(comparison_results, ensure_ascii=False, indent=4))\nprint(result_matching.text)\n```\n\n## Contributing\n\nContributions are welcome! Please open an issue or submit a pull request.\n\n## License\n\nThis project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.\n## Contact\n\nIf you have any questions or suggestions, please contact me:\n- Email: u3588064@connect.hku.hk\n- GitHub: [u3588064@connect.hku.hk](mailto:u3588064@connect.hku.hk)。\n\nWechat",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "entity",
        "semantic",
        "normalization",
        "entity resolution",
        "normalization semantic",
        "document processing"
      ],
      "category": "document-processing"
    },
    "ucalyptus--prem-mcp-server": {
      "owner": "ucalyptus",
      "name": "prem-mcp-server",
      "url": "https://github.com/ucalyptus/prem-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/ucalyptus.webp",
      "description": "Integrates with Prem AI's features for chat interactions and document management, supporting Retrieval-Augmented Generation with document repositories and real-time streaming responses.",
      "stars": 0,
      "forks": 2,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-03-26T02:24:56Z",
      "readme_content": "# Prem MCP Server\n[![smithery badge](https://smithery.ai/badge/@ucalyptus/prem-mcp-server)](https://smithery.ai/server/@ucalyptus/prem-mcp-server)\n\nA Model Context Protocol (MCP) server implementation for [Prem AI](https://premai.io/), enabling seamless integration with Claude and other MCP-compatible clients. This server provides access to Prem AI's powerful features through the MCP interface.\n\n## Features\n\n- 🤖 **Chat Completions**: Interact with Prem AI's language models\n- 📚 **RAG Support**: Retrieval-Augmented Generation with document repository integration\n- 📝 **Document Management**: Upload and manage documents in repositories\n- 🎭 **Template System**: Use predefined prompt templates for specialized outputs\n- ⚡ **Streaming Responses**: Real-time streaming of model outputs\n- 🛡️ **Error Handling**: Robust error handling and logging\n\n## Prerequisites\n\n- Node.js (v16 or higher)\n- A Prem AI account with API key\n- A Prem project ID\n\n## Installation\n\n### Installing via Smithery\n\nTo install prem-mcp-server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@ucalyptus/prem-mcp-server):\n\n```bash\nnpx -y @smithery/cli install @ucalyptus/prem-mcp-server --client claude\n```\n\n### Installing Manually\n```bash\n# Using npm\nnpm install prem-mcp-server\n\n# Using yarn\nyarn add prem-mcp-server\n\n# Using pnpm\npnpm add prem-mcp-server\n```\n\n## Configuration\n\n### 1. Environment Variables\nCreate a `.env` file in your project root:\n```env\nPREM_API_KEY=your_api_key_here\nPREM_PROJECT_ID=your_project_id_here\n```\n\n### 2. Cursor Configuration\nTo use the Prem MCP server with Cursor, add the following to your `~/.cursor/mcp.json`:\n```json\n{\n  \"mcpServers\": {\n    \"PremAI\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/your/prem-mcp/build/index.js\", \"--stdio\"],\n      \"env\": {\n        \"PREM_API_KEY\": \"your_api_key_here\",\n        \"PREM_PROJECT_ID\": \"your_project_id_here\"\n      }\n    }\n  }\n}\n```\nReplace `/path/to/your/prem-mcp` with the actual path to your project directory.\n\n### 3. Claude Desktop Configuration\nFor Claude Desktop users, add the following to your `claude_desktop_config.json`:\n```json\n{\n  \"mcpServers\": {\n    \"PremAI\": {\n      \"command\": \"npx\",\n      \"args\": [\"prem-mcp-server\", \"--stdio\"],\n      \"env\": {\n        \"PREM_API_KEY\": \"your_api_key_here\",\n        \"PREM_PROJECT_ID\": \"your_project_id_here\"\n      }\n    }\n  }\n}\n```\n\n## Usage\n\n### Starting the Server\n\n```bash\nnpx prem-mcp-server\n```\n\n### Example Prompts\n\n1. **Basic Chat**\n```\nLet's have a conversation about artificial intelligence.\n```\n\n2. **RAG with Documents**\n```\nBased on the documents in repository XYZ, what are the key points about [topic]?\n```\n\n3. **Using Templates**\n```\nUse template ABC to generate [specific type of content].\n```\n\n### Document Upload\n\nThe server supports uploading documents to Prem AI repositories for RAG operations. Supported formats:\n- `.txt`\n- `.pdf`\n- `.docx`\n\n## API Reference\n\n### Chat Completion Parameters\n\n- `query`: The input text\n- `system_prompt`: Custom system prompt\n- `model`: Model identifier\n- `temperature`: Response randomness (0-1)\n- `max_tokens`: Maximum response length\n- `repository_ids`: Array of repository IDs for RAG\n- `similarity_threshold`: Threshold for document similarity\n- `limit`: Maximum number of document chunks\n\n### Template Parameters\n\n- `template_id`: ID of the prompt template\n- `params`: Template-specific parameters\n- `temperature`: Response randomness (0-1)\n- `max_tokens`: Maximum response length\n\n## Development\n\n```bash\n# Clone the repository\ngit clone https://github.com/yourusername/prem-mcp-server.git\n\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n\n# Run tests\nnpm test\n```\n\n## Troubleshooting\n\n### Common Issues\n\n1. **Server Not Found**\n   - Verify the server path in `claude_desktop_config.json`\n   - Check if the server is running\n\n2. **API Key Invalid**\n   - Ensure your Prem AI API key is valid\n   - Check if the API key has the required permissions\n\n3. **Document Upload Failed**\n   - Verify file format is supported\n   - Check file permissions\n   - Ensure repository ID is correct\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## License\n\nMIT License - see the [LICENSE](LICENSE) file for details.\n\n## Acknowledgments\n\n- [Prem AI](https://prem.ai/) for their powerful AI platform\n- [Model Context Protocol](https://github.com/anthropics/anthropic-tools/tree/main/model-context-protocol) for the protocol specification\n- [Anthropic](https://www.anthropic.com/) for Claude and the MCP ecosystem\n\n## Support\n\nFor issues and feature requests, please use the GitHub Issues page.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "document",
        "chat",
        "ai",
        "features chat",
        "document processing",
        "document management"
      ],
      "category": "document-processing"
    },
    "umuthopeyildirim--markai": {
      "owner": "umuthopeyildirim",
      "name": "markai",
      "url": "https://github.com/umuthopeyildirim/markai",
      "imageUrl": "/freedevtools/mcp/pfp/umuthopeyildirim.webp",
      "description": "MarkAI is a platform that enables users to ask questions and receive answers derived from their documents, providing efficient data access. It supports various file formats and offers both public and private collaboration options.",
      "stars": 22,
      "forks": 1,
      "license": "Apache License 2.0",
      "language": "TypeScript",
      "updated_at": "2025-03-27T03:57:16Z",
      "readme_content": "# MarkAI - Another RAG template\n\n![License](https://img.shields.io/github/license/umuthopeyildirim/markai)\n\nMarkAI is a AI-platform that guides you on your employees to be more efficient. It is a platform that you can ask questions to your AI and get answers from your documents. We designed it to be serverless and scalable. It is a platform that you can use for your company or personal use.\n\n## Key Features 🎯\n\n-   **Fast and Efficient**: Designed with speed and efficiency at its core. MarkAI ensures rapid access to your data.\n-   **Secure**: Your data, your control. Always.\n-   **File Compatibility**: Text, Markdown, HTML\n-   **Open Source**: Freedom is beautiful, and so is MarkAI. Open source and free to use.\n-   **Public/Private**: Invite your team to collaborate, or keep your data private.\n\n\n\n## Setup 🛠\n\nJust follow the instructions on the [setup.md](docs/setup.md).\n\n## Used Technologies\n\n-   [Clerk](https://clerk.com) for authentication\n-   [Supabase](https://supabase.com) for database and vector search\n-   [LangChain](https://www.langchain.com/) for Agents and Embeddings\n-   [Cloudflare](https://cloudflare.com) (Optional) for custom domain and AI Gateway(Monitoring)\n-   [Vercel](https://vercel.com) for deployment, CI/CD and serverless functions\n-   [OpenAI](https://openai.com) for AI API calls\n-   [TailwindCSS](https://tailwindcss.com) for styling\n-   [Next.js](https://nextjs.org) for frontend\n-   [NextUI](https://nextui.org) for UI components\n\n## Contributing\n\nIf you encounter a bug or have a feature request, please open an issue. If you want to contribute code, fork this repository and make a pull request.\n\n## Contributors ✨\n\nThanks go to these wonderful people:\n\n<a href=\"https://github.com/umuthopeyildirim/markai/graphs/contributors\">\n<img src=\"https://contrib.rocks/image?repo=umuthopeyildirim/markai\" />\n</a>\n\n## Stars History 📈\n\n<a href=\"https://star-history.com/#umuthopeyildirim/markai&Timeline\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=umuthopeyildirim/markai&type=Timeline&theme=dark\" />\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=umuthopeyildirim/markai&type=Timeline\" />\n    <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=umuthopeyildirim/markai&type=Timeline\" />\n  </picture>\n</a>",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "markai",
        "document",
        "documents",
        "markai platform",
        "markai markai",
        "umuthopeyildirim markai"
      ],
      "category": "document-processing"
    },
    "upstash--context7": {
      "owner": "upstash",
      "name": "context7",
      "url": "https://github.com/upstash/context7",
      "imageUrl": "/freedevtools/mcp/pfp/upstash.webp",
      "description": "Fetches up-to-date, version-specific documentation and code examples directly from source libraries to enhance prompts. Integrates real-time documentation into AI coding workflows for improved code accuracy and productivity.",
      "stars": 32501,
      "forks": 1611,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-10-04T09:57:24Z",
      "readme_content": "# Context7 MCP - Up-to-date Code Docs For Any Prompt\n\n[![Website](https://img.shields.io/badge/Website-context7.com-blue)](https://context7.com) [![smithery badge](https://smithery.ai/badge/@upstash/context7-mcp)](https://smithery.ai/server/@upstash/context7-mcp) [![NPM Version](https://img.shields.io/npm/v/%40upstash%2Fcontext7-mcp?color=red)](https://www.npmjs.com/package/@upstash/context7-mcp) [![MIT licensed](https://img.shields.io/npm/l/%40upstash%2Fcontext7-mcp)](./LICENSE)\n\n[![Install MCP Server](https://cursor.com/deeplink/mcp-install-dark.svg)](https://cursor.com/en/install-mcp?name=context7&config=eyJ1cmwiOiJodHRwczovL21jcC5jb250ZXh0Ny5jb20vbWNwIn0%3D) [<img alt=\"Install in VS Code (npx)\" src=\"https://img.shields.io/badge/Install%20in%20VS%20Code-0098FF?style=for-the-badge&logo=visualstudiocode&logoColor=white\">](https://insiders.vscode.dev/redirect?url=vscode%3Amcp%2Finstall%3F%7B%22name%22%3A%22context7%22%2C%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22%40upstash%2Fcontext7-mcp%40latest%22%5D%7D)\n\n[![繁體中文](https://img.shields.io/badge/docs-繁體中文-yellow)](./docs/README.zh-TW.md) [![简体中文](https://img.shields.io/badge/docs-简体中文-yellow)](./docs/README.zh-CN.md) [![日本語](https://img.shields.io/badge/docs-日本語-b7003a)](./docs/README.ja.md) [![한국어 문서](https://img.shields.io/badge/docs-한국어-green)](./docs/README.ko.md) [![Documentación en Español](https://img.shields.io/badge/docs-Español-orange)](./docs/README.es.md) [![Documentation en Français](https://img.shields.io/badge/docs-Français-blue)](./docs/README.fr.md) [![Documentação em Português (Brasil)](<https://img.shields.io/badge/docs-Português%20(Brasil)-purple>)](./docs/README.pt-BR.md) [![Documentazione in italiano](https://img.shields.io/badge/docs-Italian-red)](./docs/README.it.md) [![Dokumentasi Bahasa Indonesia](https://img.shields.io/badge/docs-Bahasa%20Indonesia-pink)](./docs/README.id-ID.md) [![Dokumentation auf Deutsch](https://img.shields.io/badge/docs-Deutsch-darkgreen)](./docs/README.de.md) [![Документация на русском языке](https://img.shields.io/badge/docs-Русский-darkblue)](./docs/README.ru.md) [![Українська документація](https://img.shields.io/badge/docs-Українська-lightblue)](./docs/README.uk.md) [![Türkçe Doküman](https://img.shields.io/badge/docs-Türkçe-blue)](./docs/README.tr.md) [![Arabic Documentation](https://img.shields.io/badge/docs-Arabic-white)](./docs/README.ar.md) [![Tiếng Việt](https://img.shields.io/badge/docs-Tiếng%20Việt-red)](./docs/README.vi.md)\n\n## ❌ Without Context7\n\nLLMs rely on outdated or generic information about the libraries you use. You get:\n\n- ❌ Code examples are outdated and based on year-old training data\n- ❌ Hallucinated APIs that don't even exist\n- ❌ Generic answers for old package versions\n\n## ✅ With Context7\n\nContext7 MCP pulls up-to-date, version-specific documentation and code examples straight from the source — and places them directly into your prompt.\n\nAdd `use context7` to your prompt in Cursor:\n\n```txt\nCreate a Next.js middleware that checks for a valid JWT in cookies and redirects unauthenticated users to `/login`. use context7\n```\n\n```txt\nConfigure a Cloudflare Worker script to cache JSON API responses for five minutes. use context7\n```\n\nContext7 fetches up-to-date code examples and documentation right into your LLM's context.\n\n- 1️⃣ Write your prompt naturally\n- 2️⃣ Tell the LLM to `use context7`\n- 3️⃣ Get working code answers\n\nNo tab-switching, no hallucinated APIs that don't exist, no outdated code generation.\n\n## 📚 Adding Projects\n\nCheck out our [project addition guide](./docs/adding-projects.md) to learn how to add (or update) your favorite libraries to Context7.\n\n## 🛠️ Installation\n\n### Requirements\n\n- Node.js >= v18.0.0\n- Cursor, Claude Code, VSCode, Windsurf or another MCP Client\n- Context7 API Key (Optional) for higher rate limits and private repositories (Get yours by creating an account at [context7.com/dashboard](https://context7.com/dashboard))\n\n> [!WARNING]\n> **SSE Protocol Deprecation Notice**\n>\n> The Server-Sent Events (SSE) transport protocol is deprecated and its endpoint will be removed in upcoming releases. Please use HTTP or stdio transport methods instead.\n\n<details>\n<summary><b>Installing via Smithery</b></summary>\n\nTo install Context7 MCP Server for any client automatically via [Smithery](https://smithery.ai/server/@upstash/context7-mcp):\n\n```bash\nnpx -y @smithery/cli@latest install @upstash/context7-mcp --client <CLIENT_NAME> --key <YOUR_SMITHERY_KEY>\n```\n\nYou can find your Smithery key in the [Smithery.ai webpage](https://smithery.ai/server/@upstash/context7-mcp).\n\n</details>\n\n<details>\n<summary><b>Install in Cursor</b></summary>\n\nGo to: `Settings` -> `Cursor Settings` -> `MCP` -> `Add new global MCP server`\n\nPasting the following configuration into your Cursor `~/.cursor/mcp.json` file is the recommended approach. You may also install in a specific project by creating `.cursor/mcp.json` in your project folder. See [Cursor MCP docs](https://docs.cursor.com/context/model-context-protocol) for more info.\n\n> Since Cursor 1.0, you can click the install button below for instant one-click installation.\n\n#### Cursor Remote Server Connection\n\n[![Install MCP Server](https://cursor.com/deeplink/mcp-install-dark.svg)](https://cursor.com/en/install-mcp?name=context7&config=eyJ1cmwiOiJodHRwczovL21jcC5jb250ZXh0Ny5jb20vbWNwIn0%3D)\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"url\": \"https://mcp.context7.com/mcp\",\n      \"headers\": {\n        \"CONTEXT7_API_KEY\": \"YOUR_API_KEY\"\n      }\n    }\n  }\n}\n```\n\n#### Cursor Local Server Connection\n\n[![Install MCP Server](https://cursor.com/deeplink/mcp-install-dark.svg)](https://cursor.com/en/install-mcp?name=context7&config=eyJjb21tYW5kIjoibnB4IC15IEB1cHN0YXNoL2NvbnRleHQ3LW1jcCJ9)\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@upstash/context7-mcp\", \"--api-key\", \"YOUR_API_KEY\"]\n    }\n  }\n}\n```\n\n</details>\n\n<details>\n<summary><b>Install in Claude Code</b></summary>\n\nRun this command. See [Claude Code MCP docs](https://docs.anthropic.com/en/docs/claude-code/mcp) for more info.\n\n#### Claude Code Remote Server Connection\n\n```sh\nclaude mcp add --transport http context7 https://mcp.context7.com/mcp --header \"CONTEXT7_API_KEY: YOUR_API_KEY\"\n```\n\n#### Claude Code Local Server Connection\n\n```sh\nclaude mcp add context7 -- npx -y @upstash/context7-mcp --api-key YOUR_API_KEY\n```\n\n</details>\n\n<details>\n<summary><b>Install in Amp</b></summary>\n\nRun this command in your terminal. See [Amp MCP docs](https://ampcode.com/manual#mcp) for more info.\n\n#### Without API Key (Basic Usage)\n\n```sh\namp mcp add context7 https://mcp.context7.com/mcp\n```\n\n#### With API Key (Higher Rate Limits & Private Repos)\n\n```sh\namp mcp add context7 --header \"CONTEXT7_API_KEY=YOUR_API_KEY\" https://mcp.context7.com/mcp\n```\n\n</details>\n\n<details>\n<summary><b>Install in Windsurf</b></summary>\n\nAdd this to your Windsurf MCP config file. See [Windsurf MCP docs](https://docs.windsurf.com/windsurf/cascade/mcp) for more info.\n\n#### Windsurf Remote Server Connection\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"serverUrl\": \"https://mcp.context7.com/mcp\",\n      \"headers\": {\n        \"CONTEXT7_API_KEY\": \"YOUR_API_KEY\"\n      }\n    }\n  }\n}\n```\n\n#### Windsurf Local Server Connection\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@upstash/context7-mcp\", \"--api-key\", \"YOUR_API_KEY\"]\n    }\n  }\n}\n```\n\n</details>\n\n<details>\n<summary><b>Install in VS Code</b></summary>\n\n[<img alt=\"Install in VS Code (npx)\" src=\"https://img.shields.io/badge/VS_Code-VS_Code?style=flat-square&label=Install%20Context7%20MCP&color=0098FF\">](https://insiders.vscode.dev/redirect?url=vscode%3Amcp%2Finstall%3F%7B%22name%22%3A%22context7%22%2C%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22%40upstash%2Fcontext7-mcp%40latest%22%5D%7D)\n[<img alt=\"Install in VS Code Insiders (npx)\" src=\"https://img.shields.io/badge/VS_Code_Insiders-VS_Code_Insiders?style=flat-square&label=Install%20Context7%20MCP&color=24bfa5\">](https://insiders.vscode.dev/redirect?url=vscode-insiders%3Amcp%2Finstall%3F%7B%22name%22%3A%22context7%22%2C%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22%40upstash%2Fcontext7-mcp%40latest%22%5D%7D)\n\nAdd this to your VS Code MCP config file. See [VS Code MCP docs](https://code.visualstudio.com/docs/copilot/chat/mcp-servers) for more info.\n\n#### VS Code Remote Server Connection\n\n```json\n\"mcp\": {\n  \"servers\": {\n    \"context7\": {\n      \"type\": \"http\",\n      \"url\": \"https://mcp.context7.com/mcp\",\n      \"headers\": {\n        \"CONTEXT7_API_KEY\": \"YOUR_API_KEY\"\n      }\n    }\n  }\n}\n```\n\n#### VS Code Local Server Connection\n\n```json\n\"mcp\": {\n  \"servers\": {\n    \"context7\": {\n      \"type\": \"stdio\",\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@upstash/context7-mcp\", \"--api-key\", \"YOUR_API_KEY\"]\n    }\n  }\n}\n```\n\n</details>\n\n<details>\n<summary>\n<b>Install in Cline</b>\n</summary>\n\nYou can easily install Context7 through the [Cline MCP Server Marketplace](https://cline.bot/mcp-marketplace) by following these instructions:\n\n1. Open **Cline**.\n2. Click the hamburger menu icon (☰) to enter the **MCP Servers** section.\n3. Use the search bar within the **Marketplace** tab to find _Context7_.\n4. Click the **Install** button.\n\nOr you can directly edit MCP servers configuration:\n\n1. Open **Cline**.\n2. Click the hamburger menu icon (☰) to enter the **MCP Servers** section.\n3. Choose **Remote Servers** tab.\n4. Click the **Edit Configuration** button.\n5. Add context7 to `mcpServers`:\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"url\": \"https://mcp.context7.com/mcp\",\n      \"type\": \"streamableHttp\",\n      \"headers\": {\n        \"Authorization\": \"Bearer YOUR_API_KEY\"\n      }\n    }\n  }\n}\n```\n\n</details>\n\n<details>\n<summary><b>Install in Zed</b></summary>\n\nIt can be installed via [Zed Extensions](https://zed.dev/extensions?query=Context7) or you can add this to your Zed `settings.json`. See [Zed Context Server docs](https://zed.dev/docs/assistant/context-servers) for more info.\n\n```json\n{\n  \"context_servers\": {\n    \"Context7\": {\n      \"source\": \"custom\",\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@upstash/context7-mcp\", \"--api-key\", \"YOUR_API_KEY\"]\n    }\n  }\n}\n```\n\n</details>\n\n<details>\n<summary><b>Install in Augment Code</b></summary>\n\nTo configure Context7 MCP in Augment Code, you can use either the graphical interface or manual configuration.\n\n### **A. Using the Augment Code UI**\n\n1. Click the hamburger menu.\n2. Select **Settings**.\n3. Navigate to the **Tools** section.\n4. Click the **+ Add MCP** button.\n5. Enter the following command:\n\n   ```\n   npx -y @upstash/context7-mcp@latest\n   ```\n\n6. Name the MCP: **Context7**.\n7. Click the **Add** button.\n\nOnce the MCP server is added, you can start using Context7's up-to-date code documentation features directly within Augment Code.\n\n---\n\n### **B. Manual Configuration**\n\n1. Press Cmd/Ctrl Shift P or go to the hamburger menu in the Augment panel\n2. Select Edit Settings\n3. Under Advanced, click Edit in settings.json\n4. Add the server configuration to the `mcpServers` array in the `augment.advanced` object\n\n```json\n\"augment.advanced\": {\n  \"mcpServers\": [\n    {\n      \"name\": \"context7\",\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@upstash/context7-mcp\", \"--api-key\", \"YOUR_API_KEY\"]\n    }\n  ]\n}\n```\n\nOnce the MCP server is added, restart your editor. If you receive any errors, check the syntax to make sure closing brackets or commas are not missing.\n\n</details>\n\n<details>\n<summary><b>Install in Roo Code</b></summary>\n\nAdd this to your Roo Code MCP configuration file. See [Roo Code MCP docs](https://docs.roocode.com/features/mcp/using-mcp-in-roo) for more info.\n\n#### Roo Code Remote Server Connection\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"type\": \"streamable-http\",\n      \"url\": \"https://mcp.context7.com/mcp\",\n      \"headers\": {\n        \"CONTEXT7_API_KEY\": \"YOUR_API_KEY\"\n      }\n    }\n  }\n}\n```\n\n#### Roo Code Local Server Connection\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@upstash/context7-mcp\", \"--api-key\", \"YOUR_API_KEY\"]\n    }\n  }\n}\n```\n\n</details>\n\n<details>\n<summary><b>Install in Gemini CLI</b></summary>\n\nSee [Gemini CLI Configuration](https://google-gemini.github.io/gemini-cli/docs/tools/mcp-server.html) for details.\n\n1.  Open the Gemini CLI settings file. The location is `~/.gemini/settings.json` (where `~` is your home directory).\n2.  Add the following to the `mcpServers` object in your `settings.json` file:\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"httpUrl\": \"https://mcp.context7.com/mcp\",\n      \"headers\": {\n        \"CONTEXT7_API_KEY\": \"YOUR_API_KEY\",\n        \"Accept\": \"application/json, text/event-stream\"\n      }\n    }\n  }\n}\n```\n\nOr, for a local server:\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@upstash/context7-mcp\", \"--api-key\", \"YOUR_API_KEY\"]\n    }\n  }\n}\n```\n\nIf the `mcpServers` object does not exist, create it.\n\n</details>\n\n<details>\n<summary><b>Install in Claude Desktop</b></summary>\n\n#### Remote Server Connection\n\nOpen Claude Desktop and navigate to Settings > Connectors > Add Custom Connector. Enter the name as `Context7` and the remote MCP server URL as `https://mcp.context7.com/mcp`.\n\n#### Local Server Connection\n\nOpen Claude Desktop developer settings and edit your `claude_desktop_config.json` file to add the following configuration. See [Claude Desktop MCP docs](https://modelcontextprotocol.io/quickstart/user) for more info.\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@upstash/context7-mcp\", \"--api-key\", \"YOUR_API_KEY\"]\n    }\n  }\n}\n```\n\n</details>\n\n<details>\n<summary><b>Install in Opencode</b></summary>\n\nAdd this to your Opencode configuration file. See [Opencode MCP docs](https://opencode.ai/docs/mcp-servers) for more info.\n\n#### Opencode Remote Server Connection\n\n```json\n\"mcp\": {\n  \"context7\": {\n    \"type\": \"remote\",\n    \"url\": \"https://mcp.context7.com/mcp\",\n    \"headers\": {\n      \"CONTEXT7_API_KEY\": \"YOUR_API_KEY\"\n    },\n    \"enabled\": true\n  }\n}\n```\n\n#### Opencode Local Server Connection\n\n```json\n{\n  \"mcp\": {\n    \"context7\": {\n      \"type\": \"local\",\n      \"command\": [\"npx\", \"-y\", \"@upstash/context7-mcp\", \"--api-key\", \"YOUR_API_KEY\"],\n      \"enabled\": true\n    }\n  }\n}\n```\n\n</details>\n\n<details>\n<summary><b>Install in OpenAI Codex</b></summary>\n\nSee [OpenAI Codex](https://github.com/openai/codex) for more information.\n\nAdd the following configuration to your OpenAI Codex MCP server settings:\n\n```toml\n[mcp_servers.context7]\nargs = [\"-y\", \"@upstash/context7-mcp\", \"--api-key\", \"YOUR_API_KEY\"]\ncommand = \"npx\"\n```\n\n⚠️ Windows Notes\n\nOn Windows, some users may encounter request timed out errors with the default configuration.\nIn that case, explicitly configure the MCP server with the full path to Node.js and the installed package:\n\n```toml\n[mcp_servers.context7]\ncommand = \"C:\\\\Program Files\\\\nodejs\\\\node.exe\"\nargs = [\n  \"C:\\\\Users\\\\yourname\\\\AppData\\\\Roaming\\\\npm\\\\node_modules\\\\@upstash\\\\context7-mcp\\\\dist\\\\index.js\",\n  \"--transport\",\n  \"stdio\",\n  \"--api-key\",\n  \"YOUR_API_KEY\"\n]\n```\n\nAlternatively, you can use the following configuration:\n\n```toml\n[mcp_servers.context7]\ncommand = \"cmd\"\nargs = [\n    \"/c\",\n    \"npx\",\n    \"-y\",\n    \"@upstash/context7-mcp\",\n    \"--api-key\",\n    \"YOUR_API_KEY\"\n]\nenv = { SystemRoot=\"C:\\\\Windows\" }\nstartup_timeout_ms = 20_000\n```\n\nThis ensures Codex CLI works reliably on Windows.\n\n⚠️ MacOS Notes\n\nOn MacOS, some users may encounter the same request timed out errors like Windows,\nit also can be solved tith the full path to Node.js and the installed package:\n\n```toml\n[mcp_servers.context7]\ncommand = \"/Users/yourname/.nvm/versions/node/v22.14.0/bin/node\"  # Node.js full path\nargs = [\"/Users/yourname/.nvm/versions/node/v22.14.0/lib/node_modules/@upstash/context7-mcp/dist/index.js\",  \n  \"--transport\",\n  \"stdio\",\n  \"--api-key\",\n  \"YOUR_API_KEY\"\n]\n```\nThis ensures Codex CLI works reliably on MacOS.\n\n</details>\n\n<details>\n\n<summary><b>Install in JetBrains AI Assistant</b></summary>\n\nSee [JetBrains AI Assistant Documentation](https://www.jetbrains.com/help/ai-assistant/configure-an-mcp-server.html) for more details.\n\n1. In JetBrains IDEs, go to `Settings` -> `Tools` -> `AI Assistant` -> `Model Context Protocol (MCP)`\n2. Click `+ Add`.\n3. Click on `Command` in the top-left corner of the dialog and select the As JSON option from the list\n4. Add this configuration and click `OK`\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@upstash/context7-mcp\", \"--api-key\", \"YOUR_API_KEY\"]\n    }\n  }\n}\n```\n\n5. Click `Apply` to save changes.\n6. The same way context7 could be added for JetBrains Junie in `Settings` -> `Tools` -> `Junie` -> `MCP Settings`\n\n</details>\n\n<details>\n  \n<summary><b>Install in Kiro</b></summary>\n\nSee [Kiro Model Context Protocol Documentation](https://kiro.dev/docs/mcp/configuration/) for details.\n\n1. Navigate `Kiro` > `MCP Servers`\n2. Add a new MCP server by clicking the `+ Add` button.\n3. Paste the configuration given below:\n\n```json\n{\n  \"mcpServers\": {\n    \"Context7\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@upstash/context7-mcp\", \"--api-key\", \"YOUR_API_KEY\"],\n      \"env\": {},\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\n4. Click `Save` to apply the changes.\n\n</details>\n\n<details>\n<summary><b>Install in Trae</b></summary>\n\nUse the Add manually feature and fill in the JSON configuration information for that MCP server.\nFor more details, visit the [Trae documentation](https://docs.trae.ai/ide/model-context-protocol?_lang=en).\n\n#### Trae Remote Server Connection\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"url\": \"https://mcp.context7.com/mcp\"\n    }\n  }\n}\n```\n\n#### Trae Local Server Connection\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@upstash/context7-mcp\", \"--api-key\", \"YOUR_API_KEY\"]\n    }\n  }\n}\n```\n\n</details>\n\n<details>\n<summary><b>Using Bun or Deno</b></summary>\n\nUse these alternatives to run the local Context7 MCP server with other runtimes. These examples work for any client that supports launching a local MCP server via command + args.\n\n#### Bun\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"command\": \"bunx\",\n      \"args\": [\"-y\", \"@upstash/context7-mcp\", \"--api-key\", \"YOUR_API_KEY\"]\n    }\n  }\n}\n```\n\n#### Deno\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"command\": \"deno\",\n      \"args\": [\n        \"run\",\n        \"--allow-env=NO_DEPRECATION,TRACE_DEPRECATION\",\n        \"--allow-net\",\n        \"npm:@upstash/context7-mcp\"\n      ]\n    }\n  }\n}\n```\n\n</details>\n\n<details>\n<summary><b>Using Docker</b></summary>\n\nIf you prefer to run the MCP server in a Docker container:\n\n1. **Build the Docker Image:**\n\n   First, create a `Dockerfile` in the project root (or anywhere you prefer):\n\n   <details>\n   <summary>Click to see Dockerfile content</summary>\n\n   ```Dockerfile\n   FROM node:18-alpine\n\n   WORKDIR /app\n\n   # Install the latest version globally\n   RUN npm install -g @upstash/context7-mcp\n\n   # Expose default port if needed (optional, depends on MCP client interaction)\n   # EXPOSE 3000\n\n   # Default command to run the server\n   CMD [\"context7-mcp\"]\n   ```\n\n   </details>\n\n   Then, build the image using a tag (e.g., `context7-mcp`). **Make sure Docker Desktop (or the Docker daemon) is running.** Run the following command in the same directory where you saved the `Dockerfile`:\n\n   ```bash\n   docker build -t context7-mcp .\n   ```\n\n2. **Configure Your MCP Client:**\n\n   Update your MCP client's configuration to use the Docker command.\n\n   _Example for a cline_mcp_settings.json:_\n\n   ```json\n   {\n     \"mcpServers\": {\n       \"Сontext7\": {\n         \"autoApprove\": [],\n         \"disabled\": false,\n         \"timeout\": 60,\n         \"command\": \"docker\",\n         \"args\": [\"run\", \"-i\", \"--rm\", \"context7-mcp\"],\n         \"transportType\": \"stdio\"\n       }\n     }\n   }\n   ```\n\n   _Note: This is an example configuration. Please refer to the specific examples for your MCP client (like Cursor, VS Code, etc.) earlier in this README to adapt the structure (e.g., `mcpServers` vs `servers`). Also, ensure the image name in `args` matches the tag used during the `docker build` command._\n\n</details>\n\n<details>\n<summary><b>Install Using the Desktop Extension</b></summary>\n\nInstall the [context7.mcpb](mcpb/context7.mcpb) file under the mcpb folder and add it to your client. For more information, please check out [MCP bundles docs](https://github.com/anthropics/mcpb#mcp-bundles-mcpb).\n\n</details>\n\n<details>\n<summary><b>Install in Windows</b></summary>\n\nThe configuration on Windows is slightly different compared to Linux or macOS (_`Cline` is used in the example_). The same principle applies to other editors; refer to the configuration of `command` and `args`.\n\n```json\n{\n  \"mcpServers\": {\n    \"github.com/upstash/context7-mcp\": {\n      \"command\": \"cmd\",\n      \"args\": [\"/c\", \"npx\", \"-y\", \"@upstash/context7-mcp\", \"--api-key\", \"YOUR_API_KEY\"],\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\n</details>\n\n<details>\n<summary><b>Install in Amazon Q Developer CLI</b></summary>\n\nAdd this to your Amazon Q Developer CLI configuration file. See [Amazon Q Developer CLI docs](https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-mcp-configuration.html) for more details.\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@upstash/context7-mcp\", \"--api-key\", \"YOUR_API_KEY\"]\n    }\n  }\n}\n```\n\n</details>\n\n<details>\n<summary><b>Install in Warp</b></summary>\n\nSee [Warp Model Context Protocol Documentation](https://docs.warp.dev/knowledge-and-collaboration/mcp#adding-an-mcp-server) for details.\n\n1. Navigate `Settings` > `AI` > `Manage MCP servers`.\n2. Add a new MCP server by clicking the `+ Add` button.\n3. Paste the configuration given below:\n\n```json\n{\n  \"Context7\": {\n    \"command\": \"npx\",\n    \"args\": [\"-y\", \"@upstash/context7-mcp\", \"--api-key\", \"YOUR_API_KEY\"],\n    \"env\": {},\n    \"working_directory\": null,\n    \"start_on_launch\": true\n  }\n}\n```\n\n4. Click `Save` to apply the changes.\n\n</details>\n\n<details>\n\n<summary><b>Install in Copilot Coding Agent</b></summary>\n\n## Using Context7 with Copilot Coding Agent\n\nAdd the following configuration to the `mcp` section of your Copilot Coding Agent configuration file Repository->Settings->Copilot->Coding agent->MCP configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"type\": \"http\",\n      \"url\": \"https://mcp.context7.com/mcp\",\n      \"headers\": {\n        \"CONTEXT7_API_KEY\": \"YOUR_API_KEY\"\n      },\n      \"tools\": [\"get-library-docs\", \"resolve-library-id\"]\n    }\n  }\n}\n```\n\nFor more information, see the [official GitHub documentation](https://docs.github.com/en/enterprise-cloud@latest/copilot/how-tos/agents/copilot-coding-agent/extending-copilot-coding-agent-with-mcp).\n\n</details>\n\n<details>\n<summary><b>Install in LM Studio</b></summary>\n\nSee [LM Studio MCP Support](https://lmstudio.ai/blog/lmstudio-v0.3.17) for more information.\n\n#### One-click install:\n\n[![Add MCP Server context7 to LM Studio](https://files.lmstudio.ai/deeplink/mcp-install-light.svg)](https://lmstudio.ai/install-mcp?name=context7&config=eyJjb21tYW5kIjoibnB4IiwiYXJncyI6WyIteSIsIkB1cHN0YXNoL2NvbnRleHQ3LW1jcCJdfQ%3D%3D)\n\n#### Manual set-up:\n\n1. Navigate to `Program` (right side) > `Install` > `Edit mcp.json`.\n2. Paste the configuration given below:\n\n```json\n{\n  \"mcpServers\": {\n    \"Context7\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@upstash/context7-mcp\", \"--api-key\", \"YOUR_API_KEY\"]\n    }\n  }\n}\n```\n\n3. Click `Save` to apply the changes.\n4. Toggle the MCP server on/off from the right hand side, under `Program`, or by clicking the plug icon at the bottom of the chat box.\n\n</details>\n\n<details>\n<summary><b>Install in Visual Studio 2022</b></summary>\n\nYou can configure Context7 MCP in Visual Studio 2022 by following the [Visual Studio MCP Servers documentation](https://learn.microsoft.com/visualstudio/ide/mcp-servers?view=vs-2022).\n\nAdd this to your Visual Studio MCP config file (see the [Visual Studio docs](https://learn.microsoft.com/visualstudio/ide/mcp-servers?view=vs-2022) for details):\n\n```json\n{\n  \"inputs\": [],\n  \"servers\": {\n    \"context7\": {\n      \"type\": \"http\",\n      \"url\": \"https://mcp.context7.com/mcp\",\n      \"headers\": {\n        \"CONTEXT7_API_KEY\": \"YOUR_API_KEY\"\n      }\n    }\n  }\n}\n```\n\nOr, for a local server:\n\n```json\n{\n  \"mcp\": {\n    \"servers\": {\n      \"context7\": {\n        \"type\": \"stdio\",\n        \"command\": \"npx\",\n        \"args\": [\"-y\", \"@upstash/context7-mcp\", \"--api-key\", \"YOUR_API_KEY\"]\n      }\n    }\n  }\n}\n```\n\nFor more information and troubleshooting, refer to the [Visual Studio MCP Servers documentation](https://learn.microsoft.com/visualstudio/ide/mcp-servers?view=vs-2022).\n\n</details>\n\n<details>\n<summary><b>Install in Crush</b></summary>\n\nAdd this to your Crush configuration file. See [Crush MCP docs](https://github.com/charmbracelet/crush#mcps) for more info.\n\n#### Crush Remote Server Connection (HTTP)\n\n```json\n{\n  \"$schema\": \"https://charm.land/crush.json\",\n  \"mcp\": {\n    \"context7\": {\n      \"type\": \"http\",\n      \"url\": \"https://mcp.context7.com/mcp\",\n      \"headers\": {\n        \"CONTEXT7_API_KEY\": \"YOUR_API_KEY\"\n      }\n    }\n  }\n}\n```\n\n#### Crush Local Server Connection\n\n```json\n{\n  \"$schema\": \"https://charm.land/crush.json\",\n  \"mcp\": {\n    \"context7\": {\n      \"type\": \"stdio\",\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@upstash/context7-mcp\", \"--api-key\", \"YOUR_API_KEY\"]\n    }\n  }\n}\n```\n\n</details>\n\n<details>\n<summary><b>Install in BoltAI</b></summary>\n\nOpen the \"Settings\" page of the app, navigate to \"Plugins,\" and enter the following JSON:\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@upstash/context7-mcp\", \"--api-key\", \"YOUR_API_KEY\"]\n    }\n  }\n}\n```\n\nOnce saved, enter in the chat `get-library-docs` followed by your Context7 documentation ID (e.g., `get-library-docs /nuxt/ui`). More information is available on [BoltAI's Documentation site](https://docs.boltai.com/docs/plugins/mcp-servers). For BoltAI on iOS, [see this guide](https://docs.boltai.com/docs/boltai-mobile/mcp-servers).\n\n</details>\n\n<details>\n<summary><b>Install in Rovo Dev CLI</b></summary>\n\nEdit your Rovo Dev CLI MCP config by running the command below -\n\n```bash\nacli rovodev mcp\n```\n\nExample config -\n\n#### Remote Server Connection\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"url\": \"https://mcp.context7.com/mcp\"\n    }\n  }\n}\n```\n\n#### Local Server Connection\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@upstash/context7-mcp\", \"--api-key\", \"YOUR_API_KEY\"]\n    }\n  }\n}\n```\n\n</details>\n\n<details>\n<summary><b>Install in Zencoder</b></summary>\n\nTo configure Context7 MCP in Zencoder, follow these steps:\n\n1. Go to the Zencoder menu (...)\n2. From the dropdown menu, select Agent tools\n3. Click on the Add custom MCP\n4. Add the name and server configuration from below, and make sure to hit the Install button\n\n```json\n{\n  \"command\": \"npx\",\n  \"args\": [\"-y\", \"@upstash/context7-mcp\", \"--api-key\", \"YOUR_API_KEY\"]\n}\n```\n\nOnce the MCP server is added, you can easily continue using it.\n\n</details>\n\n<details>\n<summary><b>Install in Qodo Gen</b></summary>\n\nSee [Qodo Gen docs](https://docs.qodo.ai/qodo-documentation/qodo-gen/qodo-gen-chat/agentic-mode/agentic-tools-mcps) for more details.\n\n1. Open Qodo Gen chat panel in VSCode or IntelliJ.\n2. Click Connect more tools.\n3. Click + Add new MCP.\n4. Add the following configuration:\n\n#### Qodo Gen Local Server Connection\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@upstash/context7-mcp\", \"--api-key\", \"YOUR_API_KEY\"]\n    }\n  }\n}\n```\n\n#### Qodo Gen Remote Server Connection\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"url\": \"https://mcp.context7.com/mcp\"\n    }\n  }\n}\n```\n\n</details>\n\n<details>\n<summary><b>Install in Perplexity Desktop</b></summary>\n\nSee [Local and Remote MCPs for Perplexity](https://www.perplexity.ai/help-center/en/articles/11502712-local-and-remote-mcps-for-perplexity) for more information.\n\n1. Navigate `Perplexity` > `Settings`\n2. Select `Connectors`.\n3. Click `Add Connector`.\n4. Select `Advanced`.\n5. Enter Server Name: `Context7`\n6. Paste the following JSON in the text area:\n\n```json\n{\n  \"args\": [\"-y\", \"@upstash/context7-mcp\", \"--api-key\", \"YOUR_API_KEY\"],\n  \"command\": \"npx\",\n  \"env\": {}\n}\n```\n\n7. Click `Save`.\n</details>\n\n## 🔨 Available Tools\n\nContext7 MCP provides the following tools that LLMs can use:\n\n- `resolve-library-id`: Resolves a general library name into a Context7-compatible library ID.\n  - `libraryName` (required): The name of the library to search for\n\n- `get-library-docs`: Fetches documentation for a library using a Context7-compatible library ID.\n  - `context7CompatibleLibraryID` (required): Exact Context7-compatible library ID (e.g., `/mongodb/docs`, `/vercel/next.js`)\n  - `topic` (optional): Focus the docs on a specific topic (e.g., \"routing\", \"hooks\")\n  - `tokens` (optional, default 5000): Max number of tokens to return. Values less than 1000 are automatically increased to 1000.\n\n## 🛟 Tips\n\n### Add a Rule\n\nIf you don’t want to add `use context7` to every prompt, you can define a simple rule in your MCP client's rule section:\n\n- For Windsurf, in `.windsurfrules` file\n- For Cursor, from `Cursor Settings > Rules` section\n- For Claude Code, in `CLAUDE.md` file\n\nOr the equivalent in your MCP client to auto-invoke Context7 on any code question.\n\n#### Example Rule\n\n```txt\nAlways use context7 when I need code generation, setup or configuration steps, or\nlibrary/API documentation. This means you should automatically use the Context7 MCP\ntools to resolve library id and get library docs without me having to explicitly ask.\n```\n\nFrom then on, you’ll get Context7’s docs in any related conversation without typing anything extra. You can alter the rule to match your use cases.\n\n### Use Library Id\n\nIf you already know exactly which library you want to use, add its Context7 ID to your prompt. That way, Context7 MCP server can skip the library-matching step and directly continue with retrieving docs.\n\n```txt\nImplement basic authentication with Supabase. use library /supabase/supabase for API and docs.\n```\n\nThe slash syntax tells the MCP tool exactly which library to load docs for.\n\n### HTTPS Proxy\n\nIf you are behind an HTTP proxy, Context7 uses the standard `https_proxy` / `HTTPS_PROXY` environment variables.\n\n## 💻 Development\n\nClone the project and install dependencies:\n\n```bash\nbun i\n```\n\nBuild:\n\n```bash\nbun run build\n```\n\nRun the server:\n\n```bash\nbun run dist/index.js\n```\n\n### CLI Arguments\n\n`context7-mcp` accepts the following CLI flags:\n\n- `--transport <stdio|http>` – Transport to use (`stdio` by default). Note that HTTP transport automatically provides both HTTP and SSE endpoints.\n- `--port <number>` – Port to listen on when using `http` transport (default `3000`).\n- `--api-key <key>` – API key for authentication. You can get your API key by creating an account at [context7.com/dashboard](https://context7.com/dashboard).\n\nExample with HTTP transport and port 8080:\n\n```bash\nbun run dist/index.js --transport http --port 8080\n```\n\nAnother example with stdio transport:\n\n```bash\nbun run dist/index.js --transport stdio --api-key YOUR_API_KEY\n```\n\n<details>\n<summary><b>Local Configuration Example</b></summary>\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"command\": \"npx\",\n      \"args\": [\"tsx\", \"/path/to/folder/context7/src/index.ts\", \"--api-key\", \"YOUR_API_KEY\"]\n    }\n  }\n}\n```\n\n</details>\n\n<details>\n<summary><b>Testing with MCP Inspector</b></summary>\n\n```bash\nnpx -y @modelcontextprotocol/inspector npx @upstash/context7-mcp\n```\n\n</details>\n\n## 🚨 Troubleshooting\n\n<details>\n<summary><b>Module Not Found Errors</b></summary>\n\nIf you encounter `ERR_MODULE_NOT_FOUND`, try using `bunx` instead of `npx`:\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"command\": \"bunx\",\n      \"args\": [\"-y\", \"@upstash/context7-mcp\"]\n    }\n  }\n}\n```\n\nThis often resolves module resolution issues in environments where `npx` doesn't properly install or resolve packages.\n\n</details>\n\n<details>\n<summary><b>ESM Resolution Issues</b></summary>\n\nFor errors like `Error: Cannot find module 'uriTemplate.js'`, try the `--experimental-vm-modules` flag:\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"--node-options=--experimental-vm-modules\", \"@upstash/context7-mcp@1.0.6\"]\n    }\n  }\n}\n```\n\n</details>\n\n<details>\n<summary><b>TLS/Certificate Issues</b></summary>\n\nUse the `--experimental-fetch` flag to bypass TLS-related problems:\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"--node-options=--experimental-fetch\", \"@upstash/context7-mcp\"]\n    }\n  }\n}\n```\n\n</details>\n\n<details>\n<summary><b>General MCP Client Errors</b></summary>\n\n1. Try adding `@latest` to the package name\n2. Use `bunx` as an alternative to `npx`\n3. Consider using `deno` as another alternative\n4. Ensure you're using Node.js v18 or higher for native fetch support\n\n</details>\n\n## ⚠️ Disclaimer\n\nContext7 projects are community-contributed and while we strive to maintain high quality, we cannot guarantee the accuracy, completeness, or security of all library documentation. Projects listed in Context7 are developed and maintained by their respective owners, not by Context7. If you encounter any suspicious, inappropriate, or potentially harmful content, please use the \"Report\" button on the project page to notify us immediately. We take all reports seriously and will review flagged content promptly to maintain the integrity and safety of our platform. By using Context7, you acknowledge that you do so at your own discretion and risk.\n\n## 🤝 Connect with Us\n\nStay updated and join our community:\n\n- 📢 Follow us on [X](https://x.com/context7ai) for the latest news and updates\n- 🌐 Visit our [Website](https://context7.com)\n- 💬 Join our [Discord Community](https://upstash.com/discord)\n\n## 📺 Context7 In Media\n\n- [Better Stack: \"Free Tool Makes Cursor 10x Smarter\"](https://youtu.be/52FC3qObp9E)\n- [Cole Medin: \"This is Hands Down the BEST MCP Server for AI Coding Assistants\"](https://www.youtube.com/watch?v=G7gK8H6u7Rs)\n- [Income Stream Surfers: \"Context7 + SequentialThinking MCPs: Is This AGI?\"](https://www.youtube.com/watch?v=-ggvzyLpK6o)\n- [Julian Goldie SEO: \"Context7: New MCP AI Agent Update\"](https://www.youtube.com/watch?v=CTZm6fBYisc)\n- [JeredBlu: \"Context 7 MCP: Get Documentation Instantly + VS Code Setup\"](https://www.youtube.com/watch?v=-ls0D-rtET4)\n- [Income Stream Surfers: \"Context7: The New MCP Server That Will CHANGE AI Coding\"](https://www.youtube.com/watch?v=PS-2Azb-C3M)\n- [AICodeKing: \"Context7 + Cline & RooCode: This MCP Server Makes CLINE 100X MORE EFFECTIVE!\"](https://www.youtube.com/watch?v=qZfENAPMnyo)\n- [Sean Kochel: \"5 MCP Servers For Vibe Coding Glory (Just Plug-In & Go)\"](https://www.youtube.com/watch?v=LqTQi8qexJM)\n\n## ⭐ Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=upstash/context7&type=Date)](https://www.star-history.com/#upstash/context7&Date)\n\n## 📄 License\n\nMIT",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "upstash",
        "documentation",
        "context7",
        "upstash context7",
        "documentation ai",
        "processing upstash"
      ],
      "category": "document-processing"
    },
    "vgnshiyer--apple-books-mcp": {
      "owner": "vgnshiyer",
      "name": "apple-books-mcp",
      "url": "https://github.com/vgnshiyer/apple-books-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/vgnshiyer.webp",
      "description": "Manage and explore your Apple Books library, summarize highlights, and receive book recommendations by harnessing Claude's capabilities.",
      "stars": 32,
      "forks": 5,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-09-25T20:39:59Z",
      "readme_content": "# Apple Books MCP\n\nModel Context Protocol (MCP) server for Apple Books.\n\n![](https://badge.mcpx.dev?type=server 'MCP Server')\n[![PyPI](https://img.shields.io/pypi/v/apple-books-mcp.svg)](https://pypi.org/project/apple-books-mcp/)\n[![License: Apache 2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n[![](https://img.shields.io/badge/Follow-vgnshiyer-0A66C2?logo=linkedin)](https://www.linkedin.com/comm/mynetwork/discovery-see-all?usecase=PEOPLE_FOLLOWS&followMember=vgnshiyer)\n[![Buy Me A Coffee](https://img.shields.io/badge/Buy%20Me%20A%20Coffee-Donate-yellow.svg?logo=buymeacoffee)](https://www.buymeacoffee.com/vgnshiyer)\n\n## At a glance\n\n* Ask Claude to summarize your recent highlights\n* Ask Claude to organize books in your library by genre\n* Ask Claude to recommend similar books based on your reading history\n* Ask Claude to compare notes from different books read on the same subject\n\nhttps://github.com/user-attachments/assets/77a5a29b-bfd7-4275-a4af-8d6c51a4527e\n\nAnd much more!\n\n## Available Tools\n\n| Tool | Description | Parameters |\n|----------|-------------|------------|\n| list_collections() | List all collections | None |\n| get_collection_books(collection_id) | Get all books in a collection | collection_id: str |\n| describe_collection(collection_id) | Get details of a collection | collection_id: str |\n| list_all_books() | List all books | None |\n| get_book_annotations(book_id) | Get all annotations for a book | book_id: str |\n| describe_book(book_id) | Get details of a particular book | book_id: str |\n| list_all_annotations() | List all annotations | None |\n| get_highlights_by_color(color) | Get all highlights by color | color: str |\n| search_highlighted_text(text) | Search for highlights by highlighted text | text: str |\n| search_notes(note) | Search for notes | note: str |\n| full_text_search(text) | Search for annotations containing the given text | text: str |\n| recent_annotations() | Get 10 most recent annotations | None |\n| describe_annotation(annotation_id) | Get details of an annotation | annotation_id: str |\n\n## Installation\n\n### Using uv (recommended)\n\n[uvx](https://docs.astral.sh/uv/guides/tools/) can be used to directly run apple-books-mcp (without installing it).\n\n```bash\nbrew install uv  # for macos\nuvx apple-books-mcp\n```\n\n### Using pip\n\n```bash\npip install apple-books-mcp\n```\n\nAfter installing, you can run the server using:\n\n```bash\npython -m apple_books_mcp\n```\n\n## Configuration\n\n### Claude Desktop Setup\n\n#### Using uvx (recommended)\n\n```json\n{\n    \"mcpServers\": {\n        \"apple-books-mcp\": {\n            \"command\": \"uvx\",\n            \"args\": [ \"apple-books-mcp@latest\" ]\n        }\n    }\n}\n```\n\n#### Using python\n\n```json\n{\n    \"mcpServers\": {\n        \"apple-books-mcp\": {\n            \"command\": \"python\",\n            \"args\": [\"-m\", \"apple_books_mcp\"]\n        }\n    }\n}\n```\n\n## Upcoming Features\n\n- [ ] add docker support\n- [ ] add resources support\n- [ ] edit collections support\n- [ ] edit highlights support\n\n## Contribution\n\nThank you for considering contributing to this project!\n\n### Development\n\nIf you cloned this repository, you can test it using Claude Desktop with below configuration:\n\nUse `uv venv` to create a virtual environment and install the dependencies.\n\n```bash\nuv venv\nuv sync\n```\n\n#### Debugging\n\n**With Claude Desktop**\n\n```json\n{\n    \"mcpServers\": {\n        \"apple-books-mcp\": {\n            \"command\": \"uv\",\n            \"args\": [\n                \"--directory\",\n                \"/path/to/apple-books-mcp/\",\n                \"run\",\n                \"apple_books_mcp\",\n                \"-v\"\n            ]\n        }\n    }\n}\n```\n\n**With inspector**\n\n```bash\nnpx @modelcontextprotocol/inspector uvx apple-books-mcp\n```\n\n### Opening Issues\nIf you encounter a bug, have a feature request, or want to discuss something related to the project, please open an issue on the GitHub repository. When opening an issue, please provide:\n\n**Bug Reports**: Describe the issue in detail. Include steps to reproduce the bug if possible, along with any error messages or screenshots.\n\n**Feature Requests**: Clearly explain the new feature you'd like to see added to the project. Provide context on why this feature would be beneficial.\n\n**General Discussions**: Feel free to start discussions on broader topics related to the project.\n\n### Contributing\n\n1️⃣ Fork the GitHub repository https://github.com/vgnshiyer/apple-books-mcp \\\n2️⃣ Create a new branch for your changes (git checkout -b feature/my-new-feature). \\\n3️⃣ Make your changes and test them thoroughly. \\\n4️⃣ Push your changes and open a Pull Request to `main`.\n\n*Please provide a clear title and description of your changes.*\n\n## License\n\nApple Books MCP is licensed under the Apache 2.0 license. See the LICENSE file for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "books",
        "mcp",
        "library",
        "apple books",
        "books mcp",
        "vgnshiyer apple"
      ],
      "category": "document-processing"
    },
    "visheshd--docmcp": {
      "owner": "visheshd",
      "name": "docmcp",
      "url": "https://github.com/visheshd/docmcp",
      "imageUrl": "/freedevtools/mcp/pfp/visheshd.webp",
      "description": "Index and query technical documentation using AI-powered semantic search. It crawls, processes, and embeds documentation for efficient retrieval through AI IDEs with built-in MCP tools for seamless integration.",
      "stars": 6,
      "forks": 1,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-08-24T08:17:50Z",
      "readme_content": "# DocMCP: Index the latest doc for LLMs on PostgreSQL using pgvector and expose to AI IDEs\n\nA system for crawling, processing, and querying documentation with AI-powered embedding generation and semantic search capabilities.\n\n## Features\n\n- **Documentation Crawling**: Automatically crawl documentation sites with customizable depth and rate limiting\n- **Content Processing**: Convert HTML to clean Markdown with metadata extraction\n- **Vector Embeddings**: Generate embeddings using AWS Bedrock for semantic searching\n- **Job Management**: Track and manage document processing jobs with detailed progress reporting\n- **MCP Integration**: Built-in MCP tools for AI agent integration\n\n## Roadmap\n- SPA support: currently the crawler doesn't support SPAs\n- Caching: crawled urls are directly added to the DB\n\n## Getting Started (Development Setup)\n\n### Prerequisites\n\n- Docker ([Install Guide](https://docs.docker.com/engine/install/))\n- Docker Compose ([Install Guide](https://docs.docker.com/compose/install/))\n- Node.js 16+\n- Git\n- AWS Account with Bedrock access\n- AWS CLI configured with appropriate credentials\n\n### Quick Start Steps\n\n1.  **Clone the Repository:**\n    ```bash\n    git clone https://github.com/visheshd/docmcp.git\n    cd docmcp\n    ```\n\n2.  **Configure Environment:**\n    *   Copy the example environment file:\n        ```bash\n        cp .env.example .env\n        ```\n    *   **Edit the `.env` file:**\n        *   Set `DATABASE_URL` to `postgresql://postgres:postgres@localhost:5433/docmcp`\n        *   **Configure AWS Bedrock:**\n            *   Set `AWS_REGION` to your AWS region (e.g., `us-east-1`)\n            *   Set `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY` with your AWS credentials\n            *   Or ensure your AWS CLI is configured with appropriate credentials\n        *   Adjust other settings like `LOG_LEVEL` if needed\n\n3.  **Start the Development Environment:**\n    ```bash\n    # Make the script executable\n    chmod +x dev-start.sh\n    \n    # Start the development environment\n    ./dev-start.sh\n    ```\n    This script will:\n    * Start PostgreSQL with pgvector in a Docker container\n    * Install project dependencies\n    * Run database migrations\n    * Import seed data automatically\n    * The database will be accessible on port 5433\n\n4.  **Add Documentation:**\n    Use the `add-docs` script to crawl and process documentation:\n    ```bash\n    # Basic usage\n    npm run add-docs -- --url https://example.com/docs --max-depth 3\n\n    # With additional options\n    npm run add-docs -- \\\n      --url https://example.com/docs \\\n      --max-depth 3 \\\n      --tags react,frontend \\\n      --package react \\\n      --version 18.0.0 \\\n      --wait\n    ```\n\n    Available options:\n    - `--url`: Documentation URL to crawl (required)\n    - `--max-depth`: Maximum crawl depth (default: 3)\n    - `--tags`: Comma-separated tags for categorization\n    - `--package`: Package name this documentation is for\n    - `--version`: Package version (defaults to \"latest\")\n    - `--wait`: Wait for processing to complete\n    - `--verbose`: Enable detailed logging\n    - See `npm run add-docs -- --help` for all options\n\n5.  **Query Documentation:**\n    Once documentation is added, you can query it using the MCP tools. See the \"Querying Documentation\" section below.\n\n6.  **Stop the Development Environment:**\n    ```bash\n    docker-compose -f docker-compose.dev.yml down\n    ```\n\nThis setup provides a lightweight development environment with just the required PostgreSQL database and pre-loaded seed data. For production deployments or if you prefer a fully containerized setup, see the \"Production Docker Setup\" section below.\n\n## Cursor Setup\n\nTo use DocMCP with Cursor IDE, you'll need to configure the MCP transport. Add the following configuration to your Cursor settings:\n\n```json\n{\n    \"docmcp-local-stdio\": {\n      \"transport\": \"stdio\",\n      \"command\": \"node\",\n      \"args\": [\n        \"<DOCMCP_DIR>/dist/stdio-server.js\"\n      ],\n      \"clientInfo\": {\n        \"name\": \"cursor-client\",\n        \"version\": \"1.0.0\"\n      }\n    }\n}\n```\n\nReplace `<DOCMCP_DIR>` with the absolute path to your DocMCP installation directory.\n\nFor example, if DocMCP is installed in `/home/user/projects/docmcp`, your configuration would be:\n```json\n\"args\": [\"/home/user/projects/docmcp/dist/stdio-server.js\"]\n```\n\nAfter adding this configuration, restart Cursor for the changes to take effect.\n\n## Architecture\n\nThe system consists of several core services:\n\n- **CrawlerService**: Handles documentation site crawling with robots.txt support\n- **DocumentProcessorService**: Processes documents (HTML→Markdown, chunking, embedding)\n- **JobService**: Manages asynchronous processing jobs with detailed status tracking\n- **ChunkService**: Stores and retrieves document chunks with vector search capabilities\n- **MCP Tools**: Agent-friendly interface for adding and querying documentation\n\n### Document Processing Pipeline\n\nThe DocMCP system processes documentation through the following pipeline:\n\n1. **Documentation Input**\n   - User provides a URL through the `add_documentation` MCP tool\n   - System creates a Job record with \"pending\" status\n   - Job is assigned tags for categorization and future filtering\n\n2. **Web Crawling** (CrawlerService)\n   - Crawler respects robots.txt restrictions\n   - Follows links up to specified maximum depth\n   - Captures HTML content and metadata\n   - Creates Document records linked to the parent Job\n\n3. **Document Processing** (DocumentProcessorService)\n   - Cleans HTML and converts to structured Markdown\n   - Extracts metadata (package info, version, document type)\n   - Establishes parent-child relationships between documents\n   - Updates Job progress as processing continues\n\n4. **Chunking & Embedding** (ChunkService)\n   - Splits documents into semantic chunks for better retrieval\n   - Generates vector embeddings using AWS Bedrock\n   - Stores embeddings in PostgreSQL with pgvector extension\n   - Preserves chunk metadata and document references\n\n5. **Job Finalization** (JobService)\n   - Updates Job status to \"completed\"\n   - Calculates and stores document statistics\n   - Makes documents available for querying\n\n6. **Querying & Retrieval**\n   - User sends query through `query_documentation` MCP tool\n   - System converts query to vector embedding\n   - Performs similarity search to find relevant chunks\n   - Returns formatted results with source information\n   - Supports filtering by tags, status, and metadata\n\nThis pipeline enables efficient storage, processing, and retrieval of documentation with semantic understanding capabilities. All steps are tracked through the job system, allowing detailed progress monitoring and error handling.\n\n## Project Structure\n\n```\ndocmcp/\n├── prisma/                  # Database schema and migrations\n│   └── schema.prisma        # Prisma model definitions and database configuration\n├── src/\n│   ├── config/              # Application configuration\n│   │   └── database.ts      # Database connection setup\n│   ├── generated/           # Generated code (Prisma client)\n│   ├── services/            # Core service modules\n│   │   ├── crawler.service.ts     # Website crawling functionality\n│   │   ├── document.service.ts    # Document management\n│   │   ├── document-processor.service.ts # Document processing and transformation\n│   │   ├── job.service.ts         # Async job management\n│   │   ├── chunk.service.ts       # Document chunking and vector operations\n│   │   └── mcp-tools/       # MCP integration tools\n│   │       ├── add-documentation.tool.ts    # Tool for adding new documentation\n│   │       ├── get-job-status.tool.ts       # Tool for checking job status\n│   │       ├── list-documentation.tool.ts   # Tool for listing available documentation\n│   │       ├── query-documentation.tool.ts  # Tool for querying documentation\n│   │       ├── sample.tool.ts               # Example tool implementation\n│   │       └── index.ts                     # Tool registry and exports\n│   ├── types/               # TypeScript type definitions\n│   │   └── mcp.ts           # MCP tool interface definitions\n│   ├── utils/               # Utility functions\n│   │   ├── logger.ts        # Logging utilities\n│   │   └── prisma-filters.ts # Reusable Prisma filtering patterns\n│   └── __tests__/           # Test files\n│       └── utils/           # Test utilities\n│           └── testDb.ts    # Test database setup and teardown\n├── .env                     # Environment variables\n└── package.json             # Project dependencies and scripts\n```\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "docmcp",
        "documentation",
        "search",
        "docmcp index",
        "semantic search",
        "visheshd docmcp"
      ],
      "category": "document-processing"
    },
    "vivekVells--mcp-pandoc": {
      "owner": "vivekVells",
      "name": "mcp-pandoc",
      "url": "https://github.com/vivekVells/mcp-pandoc",
      "imageUrl": "/freedevtools/mcp/pfp/vivekVells.webp",
      "description": "Facilitates document format conversion using pandoc, enabling transformation between various document types while maintaining formatting and structure.",
      "stars": 420,
      "forks": 54,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-03T14:01:54Z",
      "readme_content": "[![Downloads](https://img.shields.io/pypi/dm/mcp-pandoc.svg)](https://pypi.python.org/pypi/mcp-pandoc)\n[![CI](https://github.com/vivekVells/mcp-pandoc/actions/workflows/ci.yml/badge.svg)](https://github.com/vivekVells/mcp-pandoc/actions/workflows/ci.yml)\n<br />\n\n![image](https://github.com/user-attachments/assets/10f18317-58e7-430e-9aec-b706b60fe2c6)\n\n<!-- [![Downloads](https://static.pepy.tech/badge/mcp-pandoc/month)](https://pepy.tech/project/mcp-pandoc) -->\n<!-- ![PyPI - Downloads](https://img.shields.io/pypi/dm/mcp-pandoc?style=social) -->\n\n<!--\n[![Downloads](https://img.shields.io/pypi/dm/mcp-pandoc.svg)](https://pypi.python.org/pypi/mcp-pandoc)\n[![CI](https://github.com/vivekVells/mcp-pandoc/actions/workflows/ci.yml/badge.svg)](https://github.com/vivekVells/mcp-pandoc/actions/workflows/ci.yml)\n<a href=\"https://smithery.ai/server/mcp-pandoc\"><img alt=\"Smithery Badge\" src=\"https://smithery.ai/badge/mcp-pandoc\"></a> <a href=\"https://glama.ai/mcp/servers/xyzzgaj9bk\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/xyzzgaj9bk/badge\" /></a> \n-->\n[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/vivekvells-mcp-pandoc-badge.png)](https://mseep.ai/app/vivekvells-mcp-pandoc)\n<a href=\"https://glama.ai/mcp/servers/xyzzgaj9bk\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/xyzzgaj9bk/badge\" />\n\n# mcp-pandoc: A Document Conversion MCP Server\n\n> Officially included in the [Model Context Protocol servers](https://github.com/modelcontextprotocol/servers/blob/main/README.md) open-source project. 🎉\n\n## Overview\n\nA Model Context Protocol server for document format conversion using [pandoc](https://pandoc.org/index.html). This server provides tools to transform content between different document formats while preserving formatting and structure.\n\nPlease note that mcp-pandoc is currently in early development. PDF support is under development, and the functionality and available tools are subject to change and expansion as we continue to improve the server.\n\nCredit: This project uses the [Pandoc Python package](https://pypi.org/project/pandoc/) for document conversion, forming the foundation for this project.\n\n## 📋 Quick Reference\n\n**New to mcp-pandoc?** Check out **[📖 CHEATSHEET.md](CHEATSHEET.md)** for\n\n- ⚡ Copy-paste examples for all formats\n- 🔄 Bidirectional conversion matrix\n- 🎯 Common workflows and pro tips\n- 🌟 Reference document styling guide\n\n_Perfect for quick lookups and getting started fast!_\n\n## Demo\n\n[![mcp-pandoc - v1: Seamless Document Format Conversion for Claude using MCP server](https://img.youtube.com/vi/vN3VOb0rygM/maxresdefault.jpg)](https://youtu.be/vN3VOb0rygM)\n\n> 🎥 [Watch on YouTube](https://youtu.be/vN3VOb0rygM)\n\n<details>\n<summary>Screenshots</summary>\n\n<img width=\"2407\" alt=\"Screenshot 2024-12-26 at 3 33 54 PM\" src=\"https://github.com/user-attachments/assets/ce3f5396-252a-4bba-84aa-65b2a06b859e\" />\n<img width=\"2052\" alt=\"Screenshot 2024-12-26 at 3 38 24 PM\" src=\"https://github.com/user-attachments/assets/8c525ad1-b184-41ca-b068-7dd34b60b85d\" />\n<img width=\"1498\" alt=\"Screenshot 2024-12-26 at 3 40 51 PM\" src=\"https://github.com/user-attachments/assets/a1e0682d-fe44-40b6-9988-bf805627beeb\" />\n<img width=\"760\" alt=\"Screenshot 2024-12-26 at 3 41 20 PM\" src=\"https://github.com/user-attachments/assets/1d7f5998-6d7f-48fa-adcf-fc37d0521213\" />\n<img width=\"1493\" alt=\"Screenshot 2024-12-26 at 3 50 27 PM\" src=\"https://github.com/user-attachments/assets/97992c5d-8efc-40af-a4c3-94c51c392534\" />\n</details>\n\nMore to come...\n\n## Tools\n\n1. `convert-contents`\n   - Transforms content between supported formats\n   - Inputs:\n     - `contents` (string): Source content to convert (required if input_file not provided)\n     - `input_file` (string): Complete path to input file (required if contents not provided)\n     - `input_format` (string): Source format of the content (defaults to markdown)\n     - `output_format` (string): Target format (defaults to markdown)\n     - `output_file` (string): Complete path for output file (required for pdf, docx, rst, latex, epub formats)\n     - `reference_doc` (string): Path to a reference document to use for styling (supported for docx output format)\n     - `defaults_file` (string): Path to a Pandoc defaults file (YAML) containing conversion options\n     - `filters` (array): List of Pandoc filter paths to apply during conversion\n   - Supported input/output formats:\n     - markdown\n     - html\n     - pdf\n     - docx\n     - rst\n     - latex\n     - epub\n     - txt\n     - ipynb\n     - odt\n   - Note: For advanced formats (pdf, docx, rst, latex, epub), an output_file path is required\n\n### 🔧 Advanced Features\n\n#### Defaults Files (YAML Configuration)\n\nUse defaults files to create reusable conversion templates with consistent formatting:\n\n```yaml\n# academic-paper.yaml\nfrom: markdown\nto: pdf\nnumber-sections: true\ntoc: true\nmetadata:\n  title: \"Academic Paper\"\n  author: \"Research Team\"\n```\n\nExample usage: `\"Convert paper.md to PDF using defaults academic-paper.yaml and save as paper.pdf\"`\n\n#### Pandoc Filters\n\nApply custom filters for enhanced processing:\n\nExample usage: `\"Convert docs.md to HTML with filters ['/path/to/mermaid-filter.py'] and save as docs.html\"`\n\n> 💡 **For comprehensive examples and workflows**, see **[CHEATSHEET.md](CHEATSHEET.md)**\n\n## 📊 Supported Formats & Conversions\n\n### Bidirectional Conversion Matrix\n\n| From\\To      | MD  | HTML | TXT | DOCX | PDF | RST | LaTeX | EPUB | IPYNB | ODT |\n| ------------ | --- | ---- | --- | ---- | --- | --- | ----- | ---- | ----- | --- |\n| **Markdown** | ✅  | ✅   | ✅  | ✅   | ✅  | ✅  | ✅    | ✅   | ✅    | ✅  |\n| **HTML**     | ✅  | ✅   | ✅  | ✅   | ✅  | ✅  | ✅    | ✅   | ✅    | ✅  |\n| **TXT**      | ✅  | ✅   | ✅  | ✅   | ✅  | ✅  | ✅    | ✅   | ✅    | ✅  |\n| **DOCX**     | ✅  | ✅   | ✅  | ✅   | ✅  | ✅  | ✅    | ✅   | ✅    | ✅  |\n| **RST**      | ✅  | ✅   | ✅  | ✅   | ✅  | ✅  | ✅    | ✅   | ✅    | ✅  |\n| **LaTeX**    | ✅  | ✅   | ✅  | ✅   | ✅  | ✅  | ✅    | ✅   | ✅    | ✅  |\n| **EPUB**     | ✅  | ✅   | ✅  | ✅   | ✅  | ✅  | ✅    | ✅   | ✅    | ✅  |\n| **IPYNB**    | ✅  | ✅   | ✅  | ✅   | ✅  | ✅  | ✅    | ✅   | ✅    | ✅  |\n| **ODT**      | ✅  | ✅   | ✅  | ✅   | ✅  | ✅  | ✅    | ✅   | ✅    | ✅  |\n\n### A Note on PDF Support\n\nThis tool uses `pandoc` for conversions, which allows for generating PDF files from the formats listed above. However, converting _from_ a PDF to other formats is not supported. Therefore, PDF should be considered an **output-only** format.\n\n### Format Categories\n\n| Category     | Formats                     | Requirements                    |\n| ------------ | --------------------------- | ------------------------------- |\n| **Basic**    | MD, HTML, TXT, IPYNB, ODT   | None                            |\n| **Advanced** | DOCX, PDF, RST, LaTeX, EPUB | Must specify `output_file` path |\n| **Styled**   | DOCX with reference doc     | Custom template support ⭐      |\n\n### Requirements by Format\n\n- **PDF (.pdf)** - requires TeX Live installation\n- **DOCX (.docx)** - supports custom styling via reference documents\n- **All others** - no additional requirements\n\nNote: For advanced formats:\n\n1. Complete file paths with filename and extension are required\n2. **PDF conversion requires TeX Live installation** (see Critical Requirements section -> For macOS: `brew install texlive`)\n3. When no output path is specified:\n   - Basic formats: Displays converted content in the chat\n   - Advanced formats: May save in system temp directory (/tmp/ on Unix systems)\n\n## Usage & configuration\n\n**NOTE: Ensure to complete installing required packages mentioned below under \"Critical Requirements\".**\n\nTo use the published one\n\n```bash\n{\n  \"mcpServers\": {\n    \"mcp-pandoc\": {\n      \"command\": \"uvx\",\n      \"args\": [\"mcp-pandoc\"]\n    }\n  }\n}\n```\n\n**💡 Quick Start**: See **[CHEATSHEET.md](CHEATSHEET.md)** for copy-paste examples and common workflows.\n\n### ⚠️ Important Notes\n\n#### Critical Requirements\n\n1. **Pandoc Installation**\n\n- **Required**: Install `pandoc` - the core document conversion engine\n- Installation:\n\n  ```bash\n  # macOS\n  brew install pandoc\n\n  # Ubuntu/Debian\n  sudo apt-get install pandoc\n\n  # Windows\n  # Download installer from: https://pandoc.org/installing.html\n  ```\n\n- **Verify**: `pandoc --version`\n\n2. **UV package installation**\n\n- **Required**: Install `uv` package (includes `uvx` command)\n- Installation:\n\n  ```bash\n  # macOS\n  brew install uv\n\n  # Windows/Linux\n  pip install uv\n  ```\n\n- **Verify**: `uvx --version`\n\n3. **PDF Conversion Prerequisites:** Only needed if you need to convert & save pdf\n\n- TeX Live must be installed before attempting PDF conversion\n- Installation commands:\n\n  ```bash\n  # Ubuntu/Debian\n  sudo apt-get install texlive-xetex\n\n  # macOS\n  brew install texlive\n\n  # Windows\n  # Install MiKTeX or TeX Live from:\n  # https://miktex.org/ or https://tug.org/texlive/\n  ```\n\n4. **File Path Requirements**\n\n- When saving or converting files, you MUST provide complete file paths including filename and extension\n- The tool does not automatically generate filenames or extensions\n\n#### Examples\n\n✅ Correct Usage:\n\n```bash\n# Converting content to PDF\n\"Convert this text to PDF and save as /path/to/document.pdf\"\n\n# Converting between file formats\n\"Convert /path/to/input.md to PDF and save as /path/to/output.pdf\"\n\n# Converting to DOCX with a reference document template\n\"Convert input.md to DOCX using template.docx as reference and save as output.docx\"\n\n# Step-by-step reference document workflow\n\"First create a reference document: pandoc -o custom-reference.docx --print-default-data-file reference.docx\" or if you already have one, use that\n\"Then convert with custom styling: Convert this text to DOCX using /path/to/custom-reference.docx as reference and save as /path/to/styled-output.docx\"\n```\n\n❌ Incorrect Usage:\n\n```bash\n# Missing filename and extension\n\"Save this as PDF in /documents/\"\n\n# Missing complete path\n\"Convert this to PDF\"\n\n# Missing extension\n\"Save as /documents/story\"\n```\n\n#### Common Issues and Solutions\n\n1. **PDF Conversion Fails**\n\n   - Error: \"xelatex not found\"\n   - Solution: Install TeX Live first (see installation commands above)\n\n2. **File Conversion Fails**\n\n   - Error: \"Invalid file path\"\n   - Solution: Provide complete path including filename and extension\n   - Example: `/path/to/document.pdf` instead of just `/path/to/`\n\n3. **Format Conversion Fails**\n\n   - Error: \"Unsupported format\"\n   - Solution: Use only supported formats:\n     - Basic: txt, html, markdown\n     - Advanced: pdf, docx, rst, latex, epub\n\n4. **Reference Document Issues**\n   - Error: \"Reference document not found\"\n   - Solution: Ensure the reference document path exists and is accessible\n   - Note: Reference documents only work with DOCX output format\n   - How to create: `pandoc -o reference.docx --print-default-data-file reference.docx`\n\n## Quickstart\n\n<!-- Uncomment after smithery fix\n### Install\n\n#### Option 1: Installing manually via claude_desktop_config.json config file\n-->\n\n### Installing manually via claude_desktop_config.json config file\n\n- On MacOS: `open ~/Library/Application\\ Support/Claude/claude_desktop_config.json`\n- On Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\na) Only for local development & contribution to this repo\n\n<details>\n  <summary>Development/Unpublished Servers Configuration</summary>\n\nℹ️ Replace <DIRECTORY> with your locally cloned project path\n\n```bash\n\"mcpServers\": {\n  \"mcp-pandoc\": {\n    \"command\": \"uv\",\n    \"args\": [\n      \"--directory\",\n      \"<DIRECTORY>/mcp-pandoc\",\n      \"run\",\n      \"mcp-pandoc\"\n    ]\n  }\n}\n```\n\n</details>\n\nb) Published Servers Configuration - Consumers should use this config\n\n```bash\n\"mcpServers\": {\n  \"mcp-pandoc\": {\n    \"command\": \"uvx\",\n    \"args\": [\n      \"mcp-pandoc\"\n    ]\n  }\n}\n```\n\n<!-- Uncomment after smithery cli fix\n#### Option 2: To install Published Servers Configuration automatically via Smithery\n\nRun the following bash command to install **published** [mcp-pandoc pypi](https://pypi.org/project/mcp-pandoc) for Claude Desktop automatically via [Smithery](https://smithery.ai/server/mcp-pandoc):\n\n```bash\nnpx -y @smithery/cli install mcp-pandoc --client claude\n```\n-->\n\n- If you face any issue, use the \"Published Servers Configuration\" above directly instead of this cli.\n\n**Note**: To use locally configured mcp-pandoc, follow \"Development/Unpublished Servers Configuration\" step above.\n\n## Development\n\n### Testing\n\nTo run the comprehensive test suite and validate all supported bidirectional conversions, use the following command:\n\n```bash\nuv run pytest tests/test_conversions.py\n```\n\nThis ensures backward compatibility and verifies the tool's core functionality.\n\n### Building and Publishing\n\nTo prepare the package for distribution:\n\n1. Sync dependencies and update lockfile:\n\n```bash\nuv sync\n```\n\n2. Build package distributions:\n\n```bash\nuv build\n```\n\nThis will create source and wheel distributions in the `dist/` directory.\n\n3. Publish to PyPI:\n\n```bash\nuv publish\n```\n\nNote: You'll need to set PyPI credentials via environment variables or command flags:\n\n- Token: `--token` or `UV_PUBLISH_TOKEN`\n- Or username/password: `--username`/`UV_PUBLISH_USERNAME` and `--password`/`UV_PUBLISH_PASSWORD`\n\n### Debugging\n\nSince MCP servers run over stdio, debugging can be challenging. For the best debugging\nexperience, we strongly recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector).\n\nYou can launch the MCP Inspector via [`npm`](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm) with this command:\n\n```bash\nnpx @modelcontextprotocol/inspector uv --directory /Users/vivekvells/Desktop/code/ai/mcp-pandoc run mcp-pandoc\n```\n\nUpon launching, the Inspector will display a URL that you can access in your browser to begin debugging.\n\n---\n\n## Contributing\n\nWe welcome contributions to enhance mcp-pandoc! Here's how you can get involved:\n\n1. **Report Issues**: Found a bug or have a feature request? Open an issue on our [GitHub Issues](https://github.com/vivekVells/mcp-pandoc/issues) page.\n2. **Submit Pull Requests**: Improve the codebase or add features by creating a pull request.\n\n---\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "pandoc",
        "format",
        "document",
        "pandoc facilitates",
        "using pandoc",
        "pandoc enabling"
      ],
      "category": "document-processing"
    },
    "w-jeon--mcp-framework": {
      "owner": "w-jeon",
      "name": "mcp-framework",
      "url": "https://github.com/w-jeon/mcp-framework",
      "imageUrl": "/freedevtools/mcp/pfp/w-jeon.webp",
      "description": "This framework enables the creation of custom tools for interaction with large language models, facilitating web content retrieval and various file handling capabilities. It automates the processing of PDF, Word, and Excel documents for enhanced productivity.",
      "stars": 3,
      "forks": 0,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-06-12T10:49:14Z",
      "readme_content": "# MCP开发框架\n[![smithery badge](https://smithery.ai/badge/@aigo666/mcp-framework)](https://smithery.ai/server/@aigo666/mcp-framework)\n\n一个强大的MCP（Model Context Protocol）开发框架，用于创建与大语言模型交互的自定义工具。该框架提供了一套完整的工具集，可以轻松地扩展Cursor IDE的功能，实现网页内容获取、文件处理（PDF、Word、Excel）等高级功能。\n\n## 主要功能\n\n本框架提供了以下核心功能：\n\n### 1. 综合文件处理\n\n使用`file`工具可以自动识别文件类型并选择合适的处理方式，支持PDF、Word和Excel文件。\n\n- **用法**: `file /path/to/document`\n- **支持格式**: \n  - PDF文件 (.pdf)\n  - Word文档 (.doc, .docx)\n  - Excel文件 (.xls, .xlsx, .xlsm)\n- **参数**: `file_path` - 文件的本地路径\n- **返回**: 根据文件类型返回相应的处理结果\n\n### 2. PDF文档处理\n\n使用`pdf`工具可以处理PDF文档，支持两种处理模式：\n\n- **用法**: `pdf /path/to/document.pdf [mode]`\n- **参数**: \n  - `file_path` - PDF文件的本地路径\n  - `mode` - 处理模式（可选）：\n    - `quick` - 快速预览模式，仅提取文本内容\n    - `full` - 完整解析模式，提取文本和图片内容（默认）\n- **返回**: \n  - 快速预览模式：文档的文本内容\n  - 完整解析模式：文档的文本内容和图片\n- **特点**: \n  - 使用PyMuPDF提供高质量的文本提取和图像处理\n  - 自动处理大型文件\n  - 支持图片提取和保存\n\n### 3. Word文档解析\n\n使用`word`工具可以解析Word文档，提取文本、表格和图片信息。\n\n- **用法**: `word /path/to/document.docx`\n- **功能**: 解析Word文档并提取文本内容、表格和图片信息\n- **参数**: `file_path` - Word文档的本地路径\n- **返回**: 文档的文本内容、表格和图片信息\n- **特点**: 使用python-docx库提供高质量的文本和表格提取\n\n### 4. Excel文件处理\n\n使用`excel`工具可以解析Excel文件，提供完整的表格数据和结构信息。\n\n- **用法**: `excel /path/to/spreadsheet.xlsx`\n- **功能**: 解析Excel文件的所有工作表\n- **参数**: `file_path` - Excel文件的本地路径\n- **返回**: \n  - 文件基本信息（文件名、工作表数量）\n  - 每个工作表的详细信息：\n    - 行数和列数\n    - 列名列表\n    - 完整的表格数据\n- **特点**: \n  - 使用pandas和openpyxl提供高质量的表格数据处理\n  - 支持多工作表处理\n  - 自动处理数据类型转换\n\n### 5. 网页内容获取\n\n使用`url`工具可以获取任何网页的内容。\n\n- **用法**: `url https://example.com`\n- **参数**: `url` - 要获取内容的网站URL\n- **返回**: 网页的文本内容\n- **特点**: \n  - 完整的HTTP错误处理\n  - 超时管理\n  - 自动编码处理\n\n## 技术特点\n\n本框架采用了多种技术来优化文件处理性能：\n\n1. **智能文件类型识别**\n   - 自动根据文件扩展名选择合适的处理工具\n   - 提供统一的文件处理接口\n\n2. **高效的文档处理**\n   - PDF处理：支持快速预览和完整解析两种模式\n   - Word处理：精确提取文本、表格和图片\n   - Excel处理：高效处理大型表格数据\n\n3. **内存优化**\n   - 使用临时文件管理大型文件\n   - 自动清理临时资源\n   - 分块处理大型文档\n\n4. **错误处理**\n   - 完整的异常捕获和处理\n   - 详细的错误信息反馈\n   - 优雅的失败处理机制\n\n## 文档处理技术细节\n\n### PDF处理\n\n1. **多层次处理策略**:\n   - 首先尝试使用PyMuPDF（fitz）提取内容（速度快、准确度高）\n   - 如果失败，回退到PymuPDF4llm（专为大语言模型优化）\n   - 最后尝试PyPDF2作为最终备用方案\n\n2. **性能优化**:\n   - 限制处理的最大页数（完整模式: 30页，快速模式: 50页）\n   - 图片处理优化（DPI调整、大小限制）\n   - 多线程处理加速\n\n3. **错误处理**:\n   - 详细的错误信息和提示\n   - 备用处理方法，确保服务稳定性\n   - 超时保护机制（5分钟超时设置）\n\n### Word文档处理\n\n1. **文档结构解析**:\n   - 提取文档属性（标题、作者、创建时间等）\n   - 段落内容提取，保留原始格式\n   - 表格转换为Markdown格式\n\n2. **图片信息**:\n   - 提供文档中图片的数量信息\n   - 图片引用关系识别\n\n## 项目结构\n\n本框架采用模块化设计，便于扩展和维护：\n\n```\nmcp_tool/\n├── tools/\n│   ├── __init__.py        # 定义工具基类和注册器\n│   ├── loader.py          # 工具加载器，自动加载所有工具\n│   ├── file_tool.py       # 综合文件处理工具\n│   ├── pdf_tool.py        # PDF解析工具\n│   ├── word_tool.py       # Word文档解析工具\n│   ├── excel_tool.py      # Excel文件处理工具\n│   └── url_tool.py        # URL工具实现\n├── __init__.py\n├── __main__.py\n└── server.py              # MCP服务器实现\n```\n\n## 开发指南\n\n### 如何开发新工具\n\n1. 在`tools`目录下创建一个新的Python文件，如`your_tool.py`\n2. 导入必要的依赖和基类\n3. 创建一个继承自`BaseTool`的工具类\n4. 使用`@ToolRegistry.register`装饰器注册工具\n5. 实现工具的`execute`方法\n\n### 工具模板示例\n\n```python\nimport mcp.types as types\nfrom . import BaseTool, ToolRegistry\n\n@ToolRegistry.register\nclass YourTool(BaseTool):\n    \"\"\"您的工具描述\"\"\"\n    name = \"your_tool_name\"  # 工具的唯一标识符\n    description = \"您的工具描述\"  # 工具的描述信息，将显示给用户\n    input_schema = {\n        \"type\": \"object\",\n        \"required\": [\"param1\"],  # 必需的参数\n        \"properties\": {\n            \"param1\": {\n                \"type\": \"string\",\n                \"description\": \"参数1的描述\",\n            },\n            \"param2\": {\n                \"type\": \"integer\",\n                \"description\": \"参数2的描述（可选）\",\n            }\n        },\n    }\n  \n    async def execute(self, arguments: dict) -> list[types.TextContent | types.ImageContent | types.EmbeddedResource]:\n        \"\"\"执行工具逻辑\"\"\"\n        # 参数验证\n        if \"param1\" not in arguments:\n            return [types.TextContent(\n                type=\"text\",\n                text=\"Error: Missing required argument 'param1'\"\n            )]\n          \n        # 获取参数\n        param1 = arguments[\"param1\"]\n        param2 = arguments.get(\"param2\", 0)  # 获取可选参数，提供默认值\n      \n        # 执行工具逻辑\n        result = f\"处理参数: {param1}, {param2}\"\n      \n        # 返回结果\n        return [types.TextContent(\n            type=\"text\",\n            text=result\n        )]\n```\n\n## 部署指南\n\n### Docker部署（推荐）\n\n1. 初始设置：\n```bash\n# 克隆仓库\ngit clone https://github.com/your-username/mcp-framework.git\ncd mcp-framework\n\n# 创建环境文件\ncp .env.example .env\n```\n\n2. 使用Docker Compose：\n```bash\n# 构建并启动\ndocker compose up --build -d\n\n# 查看日志\ndocker compose logs -f\n\n# 管理容器\ndocker compose ps\ndocker compose pause\ndocker compose unpause\ndocker compose down\n```\n\n3. 访问服务：\n- SSE端点: http://localhost:8000/sse\n\n4. Cursor IDE配置：\n- 设置 → 功能 → 添加MCP服务器\n- 类型: \"sse\"\n- URL: `http://localhost:8000/sse`\n\n### 传统Python部署\n\n1. 安装系统依赖：\n```bash\n# Ubuntu/Debian\nsudo apt-get update\nsudo apt-get install -y poppler-utils tesseract-ocr tesseract-ocr-chi-sim\n\n# macOS\nbrew install poppler tesseract tesseract-lang\n\n# Windows\n# 1. 下载并安装Tesseract: https://github.com/UB-Mannheim/tesseract/wiki\n# 2. 将Tesseract添加到系统PATH\n```\n\n2. 安装Python依赖：\n```bash\n# 创建虚拟环境\npython -m venv venv\nsource venv/bin/activate  # Linux/Mac\n# 或\n.\\venv\\Scripts\\activate  # Windows\n\n# 安装依赖\npip install -r requirements.txt\n```\n\n3. 启动服务：\n```bash\npython -m mcp_tool\n```\n\n## 配置\n\n### 环境变量\n\n在`.env`文件中配置：\n\n- `MCP_SERVER_PORT`: 服务器端口（默认: 8000）\n- `MCP_SERVER_HOST`: 绑定地址（默认: 0.0.0.0）\n- `DEBUG`: 调试模式（默认: false）\n- `MCP_USER_AGENT`: 自定义User-Agent\n\n## 依赖项\n\n主要依赖：\n- `mcp`: Model Context Protocol实现\n- `PyMuPDF`: PDF文档处理\n- `python-docx`: Word文档处理\n- `pandas`和`openpyxl`: Excel文件处理\n- `httpx`: 异步HTTP客户端\n- `anyio`: 异步I/O支持\n- `click`: 命令行接口\n\n## 贡献指南\n\n1. Fork仓库\n2. 创建功能分支 (`git checkout -b feature/amazing-feature`)\n3. 提交更改 (`git commit -m 'Add some amazing feature'`)\n4. 推送到分支 (`git push origin feature/amazing-feature`)\n5. 打开Pull Request\n\n## 许可证\n\n本项目采用MIT许可证 - 详情请参阅[LICENSE](LICENSE)文件。\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "framework",
        "document",
        "processing",
        "document processing",
        "mcp framework",
        "framework framework"
      ],
      "category": "document-processing"
    },
    "weloyun--dify": {
      "owner": "weloyun",
      "name": "dify",
      "url": "https://github.com/weloyun/dify",
      "imageUrl": "/freedevtools/mcp/pfp/weloyun.webp",
      "description": "Dify allows users to build and test AI workflows on a visual canvas, facilitating the integration of tools and data sources for enhanced AI interactions. It supports both cloud hosting and self-hosting options for flexible usage.",
      "stars": 0,
      "forks": 1,
      "license": "Other",
      "language": "TypeScript",
      "updated_at": "2025-03-01T04:26:29Z",
      "readme_content": "![cover-v5-optimized](https://github.com/langgenius/dify/assets/13230914/f9e19af5-61ba-4119-b926-d10c4c06ebab)\n\n<p align=\"center\">\n  📌 <a href=\"https://dify.ai/blog/introducing-dify-workflow-file-upload-a-demo-on-ai-podcast\">Introducing Dify Workflow File Upload: Recreate Google NotebookLM Podcast</a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://cloud.dify.ai\">Dify Cloud</a> ·\n  <a href=\"https://docs.dify.ai/getting-started/install-self-hosted\">Self-hosting</a> ·\n  <a href=\"https://docs.dify.ai\">Documentation</a> ·\n  <a href=\"https://udify.app/chat/22L1zSxg6yW1cWQg\">Enterprise inquiry</a>\n</p>\n\n<p align=\"center\">\n    <a href=\"https://dify.ai\" target=\"_blank\">\n        <img alt=\"Static Badge\" src=\"https://img.shields.io/badge/Product-F04438\"></a>\n    <a href=\"https://dify.ai/pricing\" target=\"_blank\">\n        <img alt=\"Static Badge\" src=\"https://img.shields.io/badge/free-pricing?logo=free&color=%20%23155EEF&label=pricing&labelColor=%20%23528bff\"></a>\n    <a href=\"https://discord.gg/FngNHpbcY7\" target=\"_blank\">\n        <img src=\"https://img.shields.io/discord/1082486657678311454?logo=discord&labelColor=%20%235462eb&logoColor=%20%23f5f5f5&color=%20%235462eb\"\n            alt=\"chat on Discord\"></a>\n    <a href=\"https://reddit.com/r/difyai\" target=\"_blank\">  \n        <img src=\"https://img.shields.io/reddit/subreddit-subscribers/difyai?style=plastic&logo=reddit&label=r%2Fdifyai&labelColor=white\"\n            alt=\"join Reddit\"></a>\n    <a href=\"https://twitter.com/intent/follow?screen_name=dify_ai\" target=\"_blank\">\n        <img src=\"https://img.shields.io/twitter/follow/dify_ai?logo=X&color=%20%23f5f5f5\"\n            alt=\"follow on X(Twitter)\"></a>\n    <a href=\"https://www.linkedin.com/company/langgenius/\" target=\"_blank\">\n        <img src=\"https://custom-icon-badges.demolab.com/badge/LinkedIn-0A66C2?logo=linkedin-white&logoColor=fff\"\n            alt=\"follow on LinkedIn\"></a>\n    <a href=\"https://hub.docker.com/u/langgenius\" target=\"_blank\">\n        <img alt=\"Docker Pulls\" src=\"https://img.shields.io/docker/pulls/langgenius/dify-web?labelColor=%20%23FDB062&color=%20%23f79009\"></a>\n    <a href=\"https://github.com/langgenius/dify/graphs/commit-activity\" target=\"_blank\">\n        <img alt=\"Commits last month\" src=\"https://img.shields.io/github/commit-activity/m/langgenius/dify?labelColor=%20%2332b583&color=%20%2312b76a\"></a>\n    <a href=\"https://github.com/langgenius/dify/\" target=\"_blank\">\n        <img alt=\"Issues closed\" src=\"https://img.shields.io/github/issues-search?query=repo%3Alanggenius%2Fdify%20is%3Aclosed&label=issues%20closed&labelColor=%20%237d89b0&color=%20%235d6b98\"></a>\n    <a href=\"https://github.com/langgenius/dify/discussions/\" target=\"_blank\">\n        <img alt=\"Discussion posts\" src=\"https://img.shields.io/github/discussions/langgenius/dify?labelColor=%20%239b8afb&color=%20%237a5af8\"></a>\n</p>\n\n<p align=\"center\">\n  <a href=\"./README.md\"><img alt=\"README in English\" src=\"https://img.shields.io/badge/English-d9d9d9\"></a>\n  <a href=\"./README_CN.md\"><img alt=\"简体中文版自述文件\" src=\"https://img.shields.io/badge/简体中文-d9d9d9\"></a>\n  <a href=\"./README_JA.md\"><img alt=\"日本語のREADME\" src=\"https://img.shields.io/badge/日本語-d9d9d9\"></a>\n  <a href=\"./README_ES.md\"><img alt=\"README en Español\" src=\"https://img.shields.io/badge/Español-d9d9d9\"></a>\n  <a href=\"./README_FR.md\"><img alt=\"README en Français\" src=\"https://img.shields.io/badge/Français-d9d9d9\"></a>\n  <a href=\"./README_KL.md\"><img alt=\"README tlhIngan Hol\" src=\"https://img.shields.io/badge/Klingon-d9d9d9\"></a>\n  <a href=\"./README_KR.md\"><img alt=\"README in Korean\" src=\"https://img.shields.io/badge/한국어-d9d9d9\"></a>\n  <a href=\"./README_AR.md\"><img alt=\"README بالعربية\" src=\"https://img.shields.io/badge/العربية-d9d9d9\"></a>\n  <a href=\"./README_TR.md\"><img alt=\"Türkçe README\" src=\"https://img.shields.io/badge/Türkçe-d9d9d9\"></a>\n  <a href=\"./README_VI.md\"><img alt=\"README Tiếng Việt\" src=\"https://img.shields.io/badge/Ti%E1%BA%BFng%20Vi%E1%BB%87t-d9d9d9\"></a>\n  <a href=\"./README_DE.md\"><img alt=\"README in Deutsch\" src=\"https://img.shields.io/badge/German-d9d9d9\"></a>\n</p>\n\n\nDify is an open-source LLM app development platform. Its intuitive interface combines agentic AI workflow, RAG pipeline, agent capabilities, model management, observability features and more, letting you quickly go from prototype to production. \n\n## Quick start\n> Before installing Dify, make sure your machine meets the following minimum system requirements:\n> \n>- CPU >= 2 Core\n>- RAM >= 4 GiB\n\n</br>\n\nThe easiest way to start the Dify server is through [docker compose](docker/docker-compose.yaml). Before running Dify with the following commands, make sure that [Docker](https://docs.docker.com/get-docker/) and [Docker Compose](https://docs.docker.com/compose/install/) are installed on your machine:\n\n```bash\ncd dify\ncd docker\ncp .env.example .env\ndocker compose up -d\n```\n\nAfter running, you can access the Dify dashboard in your browser at [http://localhost/install](http://localhost/install) and start the initialization process.\n\n#### Seeking help\nPlease refer to our [FAQ](https://docs.dify.ai/getting-started/install-self-hosted/faqs) if you encounter problems setting up Dify. Reach out to [the community and us](#community--contact) if you are still having issues.\n\n> If you'd like to contribute to Dify or do additional development, refer to our [guide to deploying from source code](https://docs.dify.ai/getting-started/install-self-hosted/local-source-code)\n\n## Key features\n**1. Workflow**: \n  Build and test powerful AI workflows on a visual canvas, leveraging all the following features and beyond.\n\n\n  https://github.com/langgenius/dify/assets/13230914/356df23e-1604-483d-80a6-9517ece318aa\n\n\n\n**2. Comprehensive model support**: \n  Seamless integration with hundreds of proprietary / open-source LLMs from dozens of inference providers and self-hosted solutions, covering GPT, Mistral, Llama3, and any OpenAI API-compatible models. A full list of supported model providers can be found [here](https://docs.dify.ai/getting-started/readme/model-providers).\n\n![providers-v5](https://github.com/langgenius/dify/assets/13230914/5a17bdbe-097a-4100-8363-40255b70f6e3)\n\n\n**3. Prompt IDE**: \n  Intuitive interface for crafting prompts, comparing model performance, and adding additional features such as text-to-speech to a chat-based app. \n\n**4. RAG Pipeline**: \n  Extensive RAG capabilities that cover everything from document ingestion to retrieval, with out-of-box support for text extraction from PDFs, PPTs, and other common document formats.\n\n**5. Agent capabilities**: \n  You can define agents based on LLM Function Calling or ReAct, and add pre-built or custom tools for the agent. Dify provides 50+ built-in tools for AI agents, such as Google Search, DALL·E, Stable Diffusion and WolframAlpha.\n\n**6. LLMOps**: \n  Monitor and analyze application logs and performance over time. You could continuously improve prompts, datasets, and models based on production data and annotations.\n\n**7. Backend-as-a-Service**: \n  All of Dify's offerings come with corresponding APIs, so you could effortlessly integrate Dify into your own business logic.\n\n## Feature Comparison\n<table style=\"width: 100%;\">\n  <tr>\n    <th align=\"center\">Feature</th>\n    <th align=\"center\">Dify.AI</th>\n    <th align=\"center\">LangChain</th>\n    <th align=\"center\">Flowise</th>\n    <th align=\"center\">OpenAI Assistants API</th>\n  </tr>\n  <tr>\n    <td align=\"center\">Programming Approach</td>\n    <td align=\"center\">API + App-oriented</td>\n    <td align=\"center\">Python Code</td>\n    <td align=\"center\">App-oriented</td>\n    <td align=\"center\">API-oriented</td>\n  </tr>\n  <tr>\n    <td align=\"center\">Supported LLMs</td>\n    <td align=\"center\">Rich Variety</td>\n    <td align=\"center\">Rich Variety</td>\n    <td align=\"center\">Rich Variety</td>\n    <td align=\"center\">OpenAI-only</td>\n  </tr>\n  <tr>\n    <td align=\"center\">RAG Engine</td>\n    <td align=\"center\">✅</td>\n    <td align=\"center\">✅</td>\n    <td align=\"center\">✅</td>\n    <td align=\"center\">✅</td>\n  </tr>\n  <tr>\n    <td align=\"center\">Agent</td>\n    <td align=\"center\">✅</td>\n    <td align=\"center\">✅</td>\n    <td align=\"center\">❌</td>\n    <td align=\"center\">✅</td>\n  </tr>\n  <tr>\n    <td align=\"center\">Workflow</td>\n    <td align=\"center\">✅</td>\n    <td align=\"center\">❌</td>\n    <td align=\"center\">✅</td>\n    <td align=\"center\">❌</td>\n  </tr>\n  <tr>\n    <td align=\"center\">Observability</td>\n    <td align=\"center\">✅</td>\n    <td align=\"center\">✅</td>\n    <td align=\"center\">❌</td>\n    <td align=\"center\">❌</td>\n  </tr>\n  <tr>\n    <td align=\"center\">Enterprise Feature (SSO/Access control)</td>\n    <td align=\"center\">✅</td>\n    <td align=\"center\">❌</td>\n    <td align=\"center\">❌</td>\n    <td align=\"center\">❌</td>\n  </tr>\n  <tr>\n    <td align=\"center\">Local Deployment</td>\n    <td align=\"center\">✅</td>\n    <td align=\"center\">✅</td>\n    <td align=\"center\">✅</td>\n    <td align=\"center\">❌</td>\n  </tr>\n</table>\n\n## Using Dify\n\n- **Cloud </br>**\nWe host a [Dify Cloud](https://dify.ai) service for anyone to try with zero setup. It provides all the capabilities of the self-deployed version, and includes 200 free GPT-4 calls in the sandbox plan.\n\n- **Self-hosting Dify Community Edition</br>**\nQuickly get Dify running in your environment with this [starter guide](#quick-start).\nUse our [documentation](https://docs.dify.ai) for further references and more in-depth instructions.\n\n- **Dify for enterprise / organizations</br>**\nWe provide additional enterprise-centric features. [Log your questions for us through this chatbot](https://udify.app/chat/22L1zSxg6yW1cWQg) or [send us an email](mailto:business@dify.ai?subject=[GitHub]Business%20License%20Inquiry) to discuss enterprise needs. </br>\n  > For startups and small businesses using AWS, check out [Dify Premium on AWS Marketplace](https://aws.amazon.com/marketplace/pp/prodview-t22mebxzwjhu6) and deploy it to your own AWS VPC with one-click. It's an affordable AMI offering with the option to create apps with custom logo and branding.\n\n\n## Staying ahead\n\nStar Dify on GitHub and be instantly notified of new releases.\n\n![star-us](https://github.com/langgenius/dify/assets/13230914/b823edc1-6388-4e25-ad45-2f6b187adbb4)\n\n\n## Advanced Setup\n\nIf you need to customize the configuration, please refer to the comments in our [.env.example](docker/.env.example) file and update the corresponding values in your `.env` file. Additionally, you might need to make adjustments to the `docker-compose.yaml` file itself, such as changing image versions, port mappings, or volume mounts, based on your specific deployment environment and requirements. After making any changes, please re-run `docker-compose up -d`. You can find the full list of available environment variables [here](https://docs.dify.ai/getting-started/install-self-hosted/environments).\n\nIf you'd like to configure a highly-available setup, there are community-contributed [Helm Charts](https://helm.sh/) and YAML files which allow Dify to be deployed on Kubernetes.\n\n- [Helm Chart by @LeoQuote](https://github.com/douban/charts/tree/master/charts/dify)\n- [Helm Chart by @BorisPolonsky](https://github.com/BorisPolonsky/dify-helm)\n- [YAML file by @Winson-030](https://github.com/Winson-030/dify-kubernetes)\n\n#### Using Terraform for Deployment\n\nDeploy Dify to Cloud Platform with a single click using [terraform](https://www.terraform.io/)\n\n##### Azure Global\n- [Azure Terraform by @nikawang](https://github.com/nikawang/dify-azure-terraform)\n\n##### Google Cloud\n- [Google Cloud Terraform by @sotazum](https://github.com/DeNA/dify-google-cloud-terraform)\n\n#### Using AWS CDK for Deployment\n\nDeploy Dify to AWS with [CDK](https://aws.amazon.com/cdk/)\n\n##### AWS \n- [AWS CDK by @KevinZhao](https://github.com/aws-samples/solution-for-deploying-dify-on-aws)\n\n## Contributing\n\nFor those who'd like to contribute code, see our [Contribution Guide](https://github.com/langgenius/dify/blob/main/CONTRIBUTING.md). \nAt the same time, please consider supporting Dify by sharing it on social media and at events and conferences.\n\n\n> We are looking for contributors to help with translating Dify to languages other than Mandarin or English. If you are interested in helping, please see the [i18n README](https://github.com/langgenius/dify/blob/main/web/i18n/README.md) for more information, and leave us a comment in the `global-users` channel of our [Discord Community Server](https://discord.gg/8Tpq4AcN9c).\n\n## Community & contact\n\n* [Github Discussion](https://github.com/langgenius/dify/discussions). Best for: sharing feedback and asking questions.\n* [GitHub Issues](https://github.com/langgenius/dify/issues). Best for: bugs you encounter using Dify.AI, and feature proposals. See our [Contribution Guide](https://github.com/langgenius/dify/blob/main/CONTRIBUTING.md).\n* [Discord](https://discord.gg/FngNHpbcY7). Best for: sharing your applications and hanging out with the community.\n* [X(Twitter)](https://twitter.com/dify_ai). Best for: sharing your applications and hanging out with the community.\n\n**Contributors**\n\n<a href=\"https://github.com/langgenius/dify/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=langgenius/dify\" />\n</a>\n\n## Star history\n\n[![Star History Chart](https://api.star-history.com/svg?repos=langgenius/dify&type=Date)](https://star-history.com/#langgenius/dify&Date)\n\n\n## Security disclosure\n\nTo protect your privacy, please avoid posting security issues on GitHub. Instead, send your questions to security@dify.ai and we will provide you with a more detailed answer.\n\n## License\n\nThis repository is available under the [Dify Open Source License](LICENSE), which is essentially Apache 2.0 with a few additional restrictions.\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "dify",
        "cloud",
        "weloyun",
        "weloyun dify",
        "dify allows",
        "dify dify"
      ],
      "category": "document-processing"
    },
    "whiteking64--macos-ocr-mcp": {
      "owner": "whiteking64",
      "name": "macos-ocr-mcp",
      "url": "https://github.com/whiteking64/macos-ocr-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/whiteking64.webp",
      "description": "Perform Optical Character Recognition (OCR) on images with the help of macOS's Vision framework, extracting recognized text segments, confidence scores, and bounding box coordinates. Suitable for applications that require text extraction from image files.",
      "stars": 1,
      "forks": 1,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-06-07T18:16:13Z",
      "readme_content": "# macOS OCR MCP Tool\n\nThis project provides a MetaCall Protocol (MCP) tool to perform Optical Character Recognition (OCR) on images using macOS's built-in Vision framework. It exposes an `ocr_image` tool that takes an image file path and returns the recognized text along with confidence scores and bounding boxes.\n\n## Project Setup\n\n### Dependencies\nThis project relies on Python 3.13+ and the following main dependencies:\n- `ocrmac`: For accessing macOS OCR capabilities. See [ocrmac](https://github.com/straussmaximilian/ocrmac).\n- `Pillow`: For image manipulation.\n- `mcp[cli]>=1.7.1`: For the MetaCall Protocol server and client.\n\n### Installation\nIt is recommended to use a virtual environment.\n\n1.  **Create and activate a virtual environment:**\n    ```bash\n    python -m venv .venv\n    source .venv/bin/activate\n    ```\n\n2.  **Install dependencies using `uv`:**\n    ```bash\n    uv sync\n    ```\n\n## Running the MCP Server\n\nTo start the MCP server, run `main.py`:\n```bash\nuv run main.py\n```\nThis will start the MCP server, making the `ocr_image` tool available.\n\n## Available MCP Tools\n\n### `ocr_image`\n-   **Description:** Conducts OCR on the provided image file using macOS's built-in capabilities. Returns recognized text segments, their confidence scores, and bounding box coordinates.\n-   **Input:** `file_path: str` - The absolute or relative path to the image file.\n-   **Output (Example Success):**\n    ```json\n    {\n      \"filename\": \"path/to/your/image.png\",\n      \"annotations\": [\n        {\n          \"text\": \"Hello World\",\n          \"confidence\": 0.95,\n          \"bounding_box\": [0.1, 0.1, 0.5, 0.05] \n        },\n        // ... more annotations\n      ]\n    }\n    ```\n-   **Output (Example Error):**\n    ```json\n    {\n      \"error\": \"OCR functionality is only available on macOS.\"\n    }\n    ```\n    or\n    ```json\n    {\n      \"error\": \"File not found: path/to/nonexistent/image.png\"\n    }\n    ```\n\n**Note:** This tool will only function correctly on a macOS system due to its reliance on the Vision framework.\n\n## Testing with MCP Inspector\n\nYou can use the [MCP Inspector](https://github.com/modelcontextprotocol/inspector) to connect to the running MCP server and test the tool.\n\n## Cursor MCP Configuration\n\nTo configure this MCP server in Cursor, you can add the following to your MCP JSON configuration file (e.g., `~/.cursor/mcp.json` or project-specific `.cursor/mcp.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"ocrmac\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/path/to/macos-ocr-mcp\",\n        \"run\",\n        \"main.py\"\n      ]\n    }\n  }\n}\n```\n\nThis configuration tells Cursor how to start your MCP server. You can then call the `ocrmac.ocr_image` tool from within Cursor.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ocr",
        "macos",
        "recognition",
        "macos ocr",
        "ocr mcp",
        "ocr images"
      ],
      "category": "document-processing"
    },
    "wizd--airylark-mcp-server": {
      "owner": "wizd",
      "name": "airylark-mcp-server",
      "url": "https://github.com/wizd/airylark-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/wizd.webp",
      "description": "Provides high-accuracy translation services through a structured three-stage workflow, ensuring consistency and quality across multiple languages. Supports various professional fields such as technical documentation, academia, law, medicine, and finance.",
      "stars": 22,
      "forks": 3,
      "license": "Other",
      "language": "TypeScript",
      "updated_at": "2025-09-25T15:35:30Z",
      "readme_content": "# AiryLark MCP 专业翻译服务器\n\n[![License: Custom](https://img.shields.io/badge/License-Custom%20(Apache%202.0%20with%20restrictions)-blue.svg)](../LICENSE)\n\n这是AiryLark项目的ModelContextProtocol(MCP)服务器模块，提供专业级高精度翻译服务接口。MCP是一种标准协议，允许智能助手与外部服务进行结构化交互，使复杂翻译能力可直接被Claude等大型AI模型调用。\n\n## 专业翻译优势\n\n- **三阶段翻译流程**：分析规划、分段翻译、全文审校，确保专业领域文档的翻译质量\n- **领域术语识别**：自动识别专业文本领域，提取关键术语并确保术语一致性\n- **质量评估系统**：提供全面翻译质量评估，包括准确性、流畅性、术语使用和风格一致性\n- **多语言支持**：支持中文、英文、日语、韩语、法语、德语等多种语言互译\n- **风格与格式保持**：根据文本类型自动调整翻译风格，保持原文的专业性和表达方式\n\n## 适用场景\n\n- **技术文档翻译**：软件文档、API文档、技术规范等专业内容翻译\n- **学术论文翻译**：确保学术术语准确，保持学术文体风格\n- **法律文件翻译**：保证法律术语准确性和表述精确性\n- **医疗资料翻译**：专业医学术语翻译和医疗文献本地化\n- **金融报告翻译**：准确翻译金融术语和复杂财务概念\n\n## 安装\n\n1. 确保已安装Node.js (v18+)和npm\n\n2. 安装依赖:\n\n```bash\ncd mcp-server\nnpm install\n```\n\n3. 配置环境变量:\n\n创建`.env`文件或设置以下环境变量:\n\n```\n# 翻译API配置\nTRANSLATION_API_KEY=your_api_key\nTRANSLATION_MODEL=your_model_name\nTRANSLATION_BASE_URL=your_api_base_url\n\n# 服务器配置\nPORT=3031  # MCP服务器端口，可选，默认3031\n```\n\n## 使用方法\n\n### 开发环境\n\n启动开发服务器:\n\n```bash\nnpm run dev\n```\n\n### 生产环境\n\n构建并启动服务器:\n\n```bash\nnpm run build\nnpm start\n```\n\n## MCP工具接口\n\n服务器提供以下MCP标准工具:\n\n### 1. 翻译工具 (translate_text)\n\n专业级文本翻译，自动适应不同领域和文体风格。\n\n**参数:**\n- `text`: 需要翻译的源文本\n- `target_language`: 目标语言代码 (如'zh'、'en'、'ja'等)\n- `source_language`: (可选)源语言代码\n- `high_quality`: (可选)是否启用高精度翻译流程，默认为true\n\n**使用场景:**\n- 设置`high_quality=true`用于专业文档、学术论文等对精度要求高的场景\n- 设置`high_quality=false`用于非正式内容或需要快速翻译的场景\n\n### 2. 翻译质量评估工具 (evaluate_translation)\n\n对翻译结果进行全面质量评估，提供详细反馈。\n\n**参数:**\n- `original_text`: 原始文本\n- `translated_text`: 翻译后的文本\n- `detailed_feedback`: (可选)是否提供详细反馈，默认为false\n\n**评估指标:**\n- 准确性：译文是否准确传达原文意思\n- 流畅性：译文是否符合目标语言表达习惯\n- 术语使用：专业术语翻译的准确性和一致性\n- 风格一致性：译文是否保持原文风格\n\n### 资源接口\n\n- **supported_languages**: 支持的语言列表\n  - URI: `languages://list`\n\n## 与AI助手集成\n\n本服务器设计为与支持MCP协议的AI助手无缝集成，使AI能够提供专业级翻译服务:\n\n```typescript\nimport { Client } from \"@modelcontextprotocol/sdk/client/index.js\";\nimport { SSEClientTransport } from \"@modelcontextprotocol/sdk/client/sse.js\";\n\n// 连接到MCP服务器\nconst transport = new SSEClientTransport(\"http://localhost:3031\");\nconst client = new Client(\n  { name: \"assistant-client\", version: \"1.0.0\" },\n  { capabilities: { tools: {} } }\n);\nawait client.connect(transport);\n\n// 调用专业翻译工具\nconst result = await client.callTool({\n  name: \"translate_text\",\n  arguments: {\n    text: \"The mitochondrion is the powerhouse of the cell.\",\n    target_language: \"zh\",\n    high_quality: true\n  }\n});\n\nconsole.log(result.content[0].text);\n```\n\n## Claude Chat与Cursor等MCP客户端配置\n\n在支持MCP协议的AI助手应用中，可通过以下方式配置与AiryLark翻译服务器的连接：\n\n### Cursor配置\n\n在Cursor设置或配置文件中添加以下MCP服务器配置：\n\n```json\n{\n  \"mcpServers\": {\n    \"airylark-translation\": {\n      \"url\": \"https://airylark-mcp.vcorp.ai/sse\"\n    }\n  }\n}\n```\n\n### Claude Chat配置\n\n在Claude Chat中，可以通过以下步骤开启MCP服务器连接：\n\n1. 进入设置页面\n2. 找到\"开发者设置\"或\"外部工具\"选项\n3. 添加新的MCP服务器，填写名称与URL\n4. 服务器URL填写 `https://airylark-mcp.vcorp.ai/sse`\n\n配置完成后，AI助手便可以使用\"translate_text\"和\"evaluate_translation\"工具，轻松处理各类专业文档翻译需求。\n\n## 服务器配置与运行\n\nAiryLark MCP服务器支持多种部署和运行方式，以下是常用配置方法：\n\n### Docker部署\n\n使用官方发布的Docker镜像是最简单的部署方式：\n\n```bash\n# 拉取官方镜像\ndocker pull wizdy/airylark-mcp-server\n\n# 运行容器\ndocker run -p 3031:3031 --env-file .env -d wizdy/airylark-mcp-server\n```\n\n### Docker Compose部署\n\n使用项目提供的docker-compose.yml文件，配合官方镜像可以更方便地管理服务：\n\n```yaml\n# docker-compose.yml 示例\nservices:\n  mcp-server:\n    image: wizdy/airylark-mcp-server\n    ports:\n      - \"${MCP_PORT}:${MCP_PORT}\"\n    environment:\n      - NODE_ENV=production\n      - PORT=${MCP_PORT}\n      - TRANSLATION_API_KEY=${TRANSLATION_API_KEY}\n      - TRANSLATION_MODEL=${TRANSLATION_MODEL}\n      - TRANSLATION_BASE_URL=${TRANSLATION_BASE_URL}\n    restart: always\n```\n\n运行服务：\n\n```bash\n# 设置环境变量或创建.env文件\nexport MCP_PORT=3031\nexport TRANSLATION_API_KEY=your_api_key\nexport TRANSLATION_MODEL=your_model_name\nexport TRANSLATION_BASE_URL=your_api_base_url\n\n# 启动服务\ndocker-compose up -d\n```\n\n### 服务器配置示例\n\n您也可以使用类似以下的配置方式来定义和启动MCP服务器：\n\n```json\n{\n  \"mcpServers\": {\n    \"airylark-translation\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-e\",\n        \"TRANSLATION_API_KEY\",\n        \"-e\",\n        \"TRANSLATION_MODEL\",\n        \"-e\",\n        \"TRANSLATION_BASE_URL\",\n        \"wizdy/airylark-mcp-server\"\n      ],\n      \"env\": {\n        \"TRANSLATION_API_KEY\": \"<YOUR_API_KEY>\",\n        \"TRANSLATION_MODEL\": \"<YOUR_MODEL>\",\n        \"TRANSLATION_BASE_URL\": \"<YOUR_API_URL>\"\n      }\n    }\n  }\n}\n```\n\n这种配置方式适用于需要在应用内直接管理MCP服务器生命周期的场景。\n\n## 许可证\n\n本项目使用与AiryLark主项目相同的定制许可证，详见[LICENSE](LICENSE)文件。",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "wizd",
        "document",
        "documentation",
        "translation services",
        "processing wizd",
        "document processing"
      ],
      "category": "document-processing"
    },
    "wolfyy970--docs-fetch-mcp": {
      "owner": "wolfyy970",
      "name": "docs-fetch-mcp",
      "url": "https://github.com/wolfyy970/docs-fetch-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/wolfyy970.webp",
      "description": "Fetch and explore web content autonomously by navigating through documentation and web pages to extract relevant information. It supports recursive exploration and filters navigation links for content-rich pages.",
      "stars": 7,
      "forks": 4,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-07-30T22:42:56Z",
      "readme_content": "# Docs Fetch MCP Server\n\nA Model Context Protocol (MCP) server for fetching web content with recursive exploration capabilities. This server enables LLMs to autonomously explore web pages and documentation to learn about specific topics.\n\n## Overview\n\nThe Docs Fetch MCP Server provides a simple but powerful way for LLMs to retrieve and explore web content. It enables:\n\n- Fetching clean, readable content from any web page\n- Recursive exploration of linked pages up to a specified depth\n- Same-domain link traversal to gather comprehensive information\n- Smart filtering of navigation links to focus on content-rich pages\n\nThis tool is particularly useful when users want an LLM to learn about a specific topic by exploring documentation or web content.\n\n## Features\n\n- **Content Extraction**: Cleanly extracts the main content from web pages, removing distractions like navigation, ads, and irrelevant elements\n- **Link Analysis**: Identifies and extracts links from the page, assessing their relevance\n- **Recursive Exploration**: Follows links to related content within the same domain, up to a specified depth\n- **Parallel Processing**: Efficiently crawls content with concurrent requests and proper error handling\n- **Robust Error Handling**: Gracefully handles network issues, timeouts, and malformed pages\n- **Dual-Strategy Approach**: Uses fast axios requests first with puppeteer as a fallback for more complex pages\n- **Timeout Prevention**: Implements global timeout handling to ensure reliable operation within MCP time limits\n- **Partial Results**: Returns available content even when some pages fail to load completely\n\n## Usage\n\nThe server exposes a single MCP tool:\n\n### `fetch_doc_content`\n\nFetches web page content with the ability to explore linked pages up to a specified depth.\n\n**Parameters:**\n- `url` (string, required): URL of the web page to fetch\n- `depth` (number, optional, default: 1): Maximum depth of directory/link exploration (1-5)\n\n**Returns:**\n```json\n{\n  \"rootUrl\": \"https://example.com/docs\",\n  \"explorationDepth\": 2,\n  \"pagesExplored\": 5,\n  \"content\": [\n    {\n      \"url\": \"https://example.com/docs\",\n      \"title\": \"Documentation\",\n      \"content\": \"Main page content...\",\n      \"links\": [\n        {\n          \"url\": \"https://example.com/docs/topic1\",\n          \"text\": \"Topic 1\"\n        },\n        ...\n      ]\n    },\n    ...\n  ]\n}\n```\n\n## Installation\n\n1. Clone this repository:\n```bash\ngit clone https://github.com/wolfyy970/docs-fetch-mcp.git\ncd docs-fetch-mcp\n```\n\n2. Install dependencies:\n```bash\nnpm install\n```\n\n3. Build the project:\n```bash\nnpm run build\n```\n\n4. Configure your MCP settings in your Claude Client:\n```json\n{\n  \"mcpServers\": {\n    \"docs-fetch\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/path/to/docs-fetch-mcp/build/index.js\"\n      ],\n      \"env\": {\n        \"MCP_TRANSPORT\": \"pipe\"\n      }\n    }\n  }\n}\n```\n\n## Dependencies\n\n- `@modelcontextprotocol/sdk`: MCP server SDK\n- `puppeteer`: Headless browser for web page interaction\n- `axios`: HTTP client for making requests\n\n## Development\n\nTo run the server in development mode:\n\n```bash\nnpm run dev\n```\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "document",
        "documentation",
        "pages",
        "docs fetch",
        "documentation web",
        "document processing"
      ],
      "category": "document-processing"
    },
    "wong2--mcp-jina-reader": {
      "owner": "wong2",
      "name": "mcp-jina-reader",
      "url": "https://github.com/wong2/mcp-jina-reader",
      "imageUrl": "/freedevtools/mcp/pfp/wong2.webp",
      "description": "Fetches the content of a remote URL and converts it into Markdown format using Jina Reader.",
      "stars": 45,
      "forks": 10,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-09-15T11:38:55Z",
      "readme_content": "# Jina Reader MCP Server\n\nFetch the content of a remote URL as Markdown with Jina Reader\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "markdown",
        "jina",
        "reader",
        "jina reader",
        "mcp jina",
        "markdown format"
      ],
      "category": "document-processing"
    },
    "wonnyboi--mcp-server": {
      "owner": "wonnyboi",
      "name": "mcp-server",
      "url": "https://github.com/wonnyboi/mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/wonnyboi.webp",
      "description": "Automates the collection of project information from GitHub for students, assisting in resume writing, interview question generation, and portfolio management. Provides tools for project-based self-introduction and interview practice to streamline career preparation.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-05-09T07:36:39Z",
      "readme_content": "# MCP (My Career Portfolio) Server\n\nSSAFY 학생들을 위한 프로젝트 포트폴리오 및 면접 준비 도우미 서버입니다.\n\n## 주요 기능\n\n1. 프로젝트 정보 수집\n\n   - GitHub 저장소 연동\n   - 프로젝트 정보 자동 수집\n   - 역할별 상세 정보 수집\n\n2. 자기소개서 작성 지원\n\n   - 프로젝트 기반 자기소개서 작성\n   - 자기소개서 수정 및 관리\n\n3. 면접 준비\n\n   - 프로젝트 기반 면접 질문 생성\n   - 면접 답변 연습\n   - 면접 피드백\n\n4. 포트폴리오 작성\n   - 프로젝트 기반 포트폴리오 작성\n   - 포트폴리오 수정 및 관리\n\n## 설치 방법\n\n1. 저장소 클론\n\n```bash\ngit clone https://github.com/wonnyboi/mcp-server.git\ncd mcp-server\n```\n\n2. 가상환경 생성 및 활성화\n\n```bash\npython -m venv venv\nsource venv/bin/activate  # Linux/Mac\nvenv\\Scripts\\activate     # Windows\n```\n\n3. 의존성 설치\n\n```bash\npip install -r requirements.txt\n```\n\n4. GitHub 토큰 설정\n\n   - GitHub.com → Settings → Developer settings → Personal access tokens → Tokens (classic)\n   - 'Generate new token' 클릭\n   - Note: 'MCP Portfolio Access' 입력\n   - Expiration: 'No expiration' 선택\n   - Select scopes: 'repo' 체크\n   - 'Generate token' 클릭\n   - 생성된 토큰을 복사\n   - 프로젝트 루트 디렉토리에 '.env' 파일 생성\n   - 다음 내용을 입력:\n     ```\n     GITHUB_TOKEN=your_github_token_here\n     ```\n\n5. 서버 실행\n\n```bash\npython project_portfolio_server.py\n```\n\n## 사용 방법\n\n1. 프로젝트 추가\n\n   - GitHub 저장소 URL 입력\n   - 프로젝트 유형 선택\n   - 역할 선택\n   - 상세 정보 입력\n\n2. 자기소개서 작성\n\n   - 프로젝트 기반 자기소개서 작성\n   - 수정 및 관리\n\n3. 면접 준비\n\n   - 프로젝트 기반 면접 질문 생성\n   - 답변 연습\n   - 피드백 수집\n\n4. 포트폴리오 작성\n   - 프로젝트 기반 포트폴리오 작성\n   - 수정 및 관리\n\n## 프로젝트 구조\n\n```\nmcp-server/\n├── project_data/           # 프로젝트 데이터 저장\n├── project_portfolio_server.py  # 메인 서버 파일\n├── requirements.txt        # 의존성 목록\n├── .env                   # 환경 변수 (GitHub 토큰)\n└── README.md             # 프로젝트 설명\n```\n\n## 기여 방법\n\n1. Fork the Project\n2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)\n3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)\n4. Push to the Branch (`git push origin feature/AmazingFeature`)\n5. Open a Pull Request\n\n## 라이선스\n\n이 프로젝트는 MIT 라이선스 하에 배포됩니다. 자세한 내용은 [LICENSE](LICENSE) 파일을 참조하세요.\n\n## 연락처\n\n프로젝트 관리자 - [@wonnyboi](https://github.com/wonnyboi)\n\n프로젝트 링크: [https://github.com/wonnyboi/mcp-server](https://github.com/wonnyboi/mcp-server)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "github",
        "mcp",
        "resume",
        "wonnyboi mcp",
        "github students",
        "mcp server"
      ],
      "category": "document-processing"
    },
    "worldnine--scrapbox-cosense-mcp": {
      "owner": "worldnine",
      "name": "scrapbox-cosense-mcp",
      "url": "https://github.com/worldnine/scrapbox-cosense-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/worldnine.webp",
      "description": "Access and interact with Scrapbox project pages, facilitating content retrieval, page listing, and full-text searching across project content.",
      "stars": 31,
      "forks": 8,
      "license": "MIT License",
      "language": "HTML",
      "updated_at": "2025-09-01T23:47:39Z",
      "readme_content": "# scrapbox-cosense-mcp\n\n[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/worldnine-scrapbox-cosense-mcp-badge.png)](https://mseep.ai/app/worldnine-scrapbox-cosense-mcp)\n\n<a href=\"https://glama.ai/mcp/servers/8huixkwpe2\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/8huixkwpe2/badge\" alt=\"Scrapbox Cosense Server MCP server\" /></a>\n\n\n[English](#english) | [日本語](#日本語)\n\n## English\n\nMCP server for [cosense/scrapbox](https://cosen.se).\n\n### Features\n\n- `get_page`\n  - Get page content from cosense/Scrapbox\n    - Input: Page title, optional project name\n    - Output: Page content, metadata, links, and editor information\n- `list_pages`\n  - Browse and list pages with flexible sorting and pagination\n    - Purpose: Discover pages by recency, popularity, or alphabetically\n    - Input: Sorting options, pagination, optional project name\n    - Output: Page metadata and first 5 lines of content\n    - Max: 1000 pages per request\n    - Sorting: updated, created, accessed, linked, views, title\n- `search_pages`\n  - Search for content within pages using keywords or phrases\n    - Purpose: Find pages containing specific keywords or phrases\n    - Input: Search query, optional project name\n    - Output: Matching pages with highlighted search terms and content snippets\n    - Max: 100 results (API limitation)\n    - Supports: basic search, AND search, exclude search, exact phrases\n- `create_page`\n  - Create a new page in the project with WebSocket API\n    - Input: Page title, optional markdown body text, optional project name, optional createActually flag\n    - Output: Creates the page immediately and returns success confirmation with URL\n    - Note: Markdown content is converted to Scrapbox format\n    - Feature: Automatically converts numbered lists to bullet lists (configurable)\n    - Authentication: Requires COSENSE_SID for actual page creation\n- `get_page_url`\n  - Generate URL for a page in the project\n    - Input: Page title, optional project name\n    - Output: Direct URL to the specified page\n- `insert_lines`\n  - Insert text after a specified line in a page\n    - Input: Page title, target line text, text to insert, optional project name\n    - Output: Success message with insertion details\n    - Behavior: If target line not found, text is appended to the end of the page\n\n### Installation\n\n```bash\ngit clone https://github.com/worldnine/scrapbox-cosense-mcp.git\ncd scrapbox-cosense-mcp\nnpm install\nnpm run build\n```\n\n### Basic Setup\n\nTo use with Claude Desktop, add the server configuration as follows:\n\nFor MacOS: `~/Library/Application\\ Support/Claude/claude_desktop_config.json`\nFor Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n**Single Project Configuration:**\n```json\n{\n  \"mcpServers\": {\n    \"scrapbox-cosense-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\"github:worldnine/scrapbox-cosense-mcp\"],\n      \"env\": {\n        \"COSENSE_PROJECT_NAME\": \"your_project_name\",\n        \"COSENSE_SID\": \"your_sid\", // Required for private projects\n        \"COSENSE_PAGE_LIMIT\": \"25\", // Optional (default: 100)\n        \"COSENSE_SORT_METHOD\": \"created\", // Optional (default: \"updated\")\n        \"SERVICE_LABEL\": \"scrapbox(cosense)\" // Optional (default: \"cosense(scrapbox)\")\n      }\n    }\n  }\n}\n```\n\n### Usage Examples\n\nOnce configured, you can use the tools in Claude:\n\n```\n# Get a specific page\nPlease get the content of page \"Meeting Notes\" using get_page.\n\n# List recent pages  \nPlease list the 10 most recently updated pages using list_pages.\n\n# Search for content\nPlease search for pages containing \"JavaScript tutorial\" using search_pages.\n\n# Create a new page\nPlease create a new page titled \"Today's Learning\" using create_page.\n\n# Get page URL\nPlease get the URL for page \"Project Plan\" using get_page_url.\n```\n\n### Environment Variables\n\nThis server uses the following environment variables:\n\n#### Required Environment Variables\n\n- `COSENSE_PROJECT_NAME`: Project name\n- `COSENSE_SID`: Session ID for Scrapbox/Cosense authentication (required for private projects) - [See how to get this cookie](#how-to-get-cosense_sid-cookie)\n\n#### Optional Environment Variables\n\n- `API_DOMAIN`: API domain (default: \"scrapbox.io\")\n- `SERVICE_LABEL`: Service identifier (default: \"cosense (scrapbox)\")\n- `COSENSE_PAGE_LIMIT`: Initial page fetch limit (1-1000, default: 100)\n- `COSENSE_SORT_METHOD`: Initial page fetch order (updated/created/accessed/linked/views/title, default: updated)\n- `COSENSE_TOOL_SUFFIX`: Tool name suffix for multiple server instances (e.g., \"main\" creates \"get_page_main\")\n- `COSENSE_CONVERT_NUMBERED_LISTS`: Convert numbered lists to bullet lists in Markdown (true/false, default: false)\n\n#### Environment Variable Behavior\n\n- **COSENSE_PROJECT_NAME**: Required environment variable. Server will exit with an error if not set.\n- **COSENSE_SID**: Required for accessing private projects. If not set, only public projects are accessible. [See detailed instructions](#how-to-get-cosense_sid-cookie) for obtaining this cookie.\n- **API_DOMAIN**:\n  - Uses \"scrapbox.io\" if not set\n  - While unverified with domains other than \"scrapbox.io\" in the author's environment, this option exists in case some environments require \"cosen.se\"\n- **COSENSE_PAGE_LIMIT**:\n  - Uses 100 if not set\n  - Uses 100 if value is invalid (non-numeric or out of range)\n  - Valid range: 1-1000\n- **COSENSE_SORT_METHOD**:\n  - Uses 'updated' if not set\n  - Uses 'updated' if value is invalid\n  - Does not affect list_pages tool behavior (only used for initial resource fetch)\n\n### How to Get COSENSE_SID Cookie\n\nFor accessing private Scrapbox projects, you need to obtain the `connect.sid` cookie from your browser. Follow these steps:\n\n1. **Navigate to your Scrapbox project**\n   - Open your browser and go to `https://scrapbox.io/YOUR_PROJECT_NAME`\n   - Replace `YOUR_PROJECT_NAME` with your actual project name\n\n2. **Log in to Scrapbox**\n   - Make sure you're logged in to your Scrapbox account\n   - Verify you can access your private project\n\n3. **Open Developer Tools**\n   - **Windows/Linux**: Press `F12` or `Ctrl+Shift+I`\n   - **macOS**: Press `Cmd+Option+I`\n   - **Alternative**: Right-click on the page and select \"Inspect\" or \"Inspect Element\"\n\n4. **Navigate to Cookies**\n   - In the Developer Tools, look for the **\"Application\"** tab (Chrome/Edge) or **\"Storage\"** tab (Firefox)\n   - In the left sidebar, expand **\"Cookies\"**\n   - Click on `https://scrapbox.io`\n\n5. **Find and copy the connect.sid cookie**\n   - Look for a cookie named `connect.sid`\n   - Click on it to see its value\n   - **Important**: The browser displays the URL-encoded value, but you need to use the **decoded** value\n   - Browser shows: `s%3Axxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx.xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx`\n   - You should use: `s:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx.xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx` (note the `:` after `s`)\n\n6. **Set the environment variable**\n   - Use the **decoded** value (with `:` instead of `%3A`) as your `COSENSE_SID` environment variable\n   - **Correct format**: `COSENSE_SID=s:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx.xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx`\n   - **Incorrect format**: `COSENSE_SID=s%3Axxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx.xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx`\n\n**Important Notes:**\n- Keep your `connect.sid` cookie value secure and never share it publicly\n- The cookie may expire after some time; you'll need to obtain a new one if authentication fails\n- This cookie provides access to your private projects, so treat it like a password\n\n### Multiple Project Support (Advanced)\n\n#### Method 1: Single Server with Optional Parameters\n\nAll tools support an optional `projectName` parameter to target different projects from a single server:\n\n- **Default behavior**: Uses `COSENSE_PROJECT_NAME` environment variable when no project is specified\n- **Multi-project usage**: Specify `projectName` parameter to access different projects  \n- **Backward compatibility**: Existing configurations work unchanged\n\n**Usage Examples:**\n\n```\n# Get page from default project\nPlease get the content of page \"Meeting Notes\" using get_page.\n\n# Get page from specific project  \nPlease get the content of page \"Design Guidelines\" from project \"help-ja\" using get_page.\n\n# Search in different project\nPlease search for pages containing \"API documentation\" in project \"developer-docs\" using search_pages.\n\n# Create page in specific project\nPlease create a new page titled \"Weekly Report\" in project \"team-updates\" using create_page.\n```\n\n**Important Limitations:**\n\nThis approach works best with public projects or projects that share the same authentication. For multiple private projects with different access credentials, use Method 2 below.\n\n#### Method 2: Multiple MCP Server Instances (Recommended for Private Projects)\n\nFor best user experience with multiple private projects, run separate MCP server instances for each project:\n\n```json\n{\n  \"mcpServers\": {\n    \"main-scrapbox\": {\n      \"command\": \"npx\",\n      \"args\": [\"github:worldnine/scrapbox-cosense-mcp\"],\n      \"env\": {\n        \"COSENSE_PROJECT_NAME\": \"main-project\",        // Actual project name for API calls\n        \"COSENSE_SID\": \"s:main_sid_here...\",           // Session ID for this project\n        \"COSENSE_TOOL_SUFFIX\": \"main\",                 // Creates tools like get_page_main\n        \"SERVICE_LABEL\": \"Main Scrapbox\"               // Human-readable label in tool descriptions\n      }\n    },\n    \"team-cosense\": {\n      \"command\": \"npx\",\n      \"args\": [\"github:worldnine/scrapbox-cosense-mcp\"],\n      \"env\": {\n        \"COSENSE_PROJECT_NAME\": \"team-workspace\",      // Actual project name for API calls\n        \"COSENSE_SID\": \"s:team_sid_here...\",           // Session ID for this project\n        \"COSENSE_TOOL_SUFFIX\": \"team\",                 // Creates tools like get_page_team\n        \"SERVICE_LABEL\": \"Team Cosense\"                // Human-readable label in tool descriptions\n      }\n    }\n  }\n}\n```\n\n**Key Configuration Points:**\n- **COSENSE_PROJECT_NAME**: The actual project name used in API calls (e.g., `scrapbox.io/main-project`)\n- **SERVICE_LABEL**: Display name shown in tool descriptions (e.g., \"Create page on Main Scrapbox\")\n- **COSENSE_TOOL_SUFFIX**: Creates unique tool names like `get_page_main` and `get_page_team`\n- **Different service names**: Using \"Scrapbox\" and \"Cosense\" helps distinguish between projects\n\nThis creates tools like `get_page_main`, `list_pages_main`, `get_page_team`, `list_pages_team`, allowing LLMs to automatically select the appropriate project.\n\n### Development\n\nInstall dependencies:\n\n```bash\nnpm install\n```\n\nBuild the server:\n\n```bash\nnpm run build\n```\n\nAuto-rebuild during development:\n\n```bash\nnpm run watch\n```\n\nRun tests:\n\n```bash\nnpm test\n```\n\nRun linting:\n\n```bash\nnpm run lint\n```\n\n### Quality Management\n\nThis project includes automated quality checks to ensure code reliability:\n\n- **ESLint**: TypeScript-aware linting with console.log warnings\n- **GitHub Actions**: Automated CI/CD pipeline for pull requests\n- **Branch Protection**: Main branch requires PR and passing checks\n- **Test Suite**: 142+ tests covering all functionality\n\n#### Contributing Guidelines\n\n1. Create a feature branch from main\n2. Make your changes with appropriate tests\n3. Run `npm run lint` and `npm test` locally\n4. Create a pull request\n5. CI will automatically run quality checks\n6. Merge only after all checks pass\n\nThe quality management system prevents debug logs and broken code from reaching production.\n\n### Debugging\n\nSince MCP servers communicate via stdio, debugging can be challenging. This server includes comprehensive debug logging to help troubleshoot issues.\n\n#### Debug Logs\n\nThe server outputs detailed debug information to help identify configuration and API issues:\n\n- **Server Configuration**: Project name, tool suffix, SID presence, limits\n- **Tool Generation**: List of generated tools with their names\n- **Tool Calls**: Requested vs normalized tool names, arguments\n- **API Requests**: URLs, project names, authentication status\n- **API Errors**: Detailed error information with context\n\n#### Using MCP Inspector\n\nUsing [MCP Inspector](https://github.com/modelcontextprotocol/inspector) is recommended for interactive debugging:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector provides a URL to access debugging tools in the browser.\n\n#### Troubleshooting Multiple Servers\n\nWhen running multiple server instances, check the debug logs for:\n\n1. **Tool Name Conflicts**: Ensure `COSENSE_TOOL_SUFFIX` is set differently for each server\n2. **API Access**: Verify SID authentication works for each project\n3. **Project Names**: Confirm project names are correctly configured\n\n## 日本語\n\n[cosense/scrapbox](https://cosen.se) 用のMCPサーバーです。\n\n## 機能\n\n- `get_page`\n  - cosense/Scrapboxからページコンテンツを取得\n    - 入力: ページタイトル、オプションのプロジェクト名\n    - 出力: ページコンテンツ、メタデータ、リンク、編集者の情報\n- `list_pages`\n  - 柔軟なソートとページネーションによるページ一覧の閲覧\n    - 用途: 最新性、人気度、アルファベット順でページを発見\n    - 入力: ソートオプション、ページネーション、オプションのプロジェクト名\n    - 出力: ページのメタデータと冒頭5行の内容\n    - 最大: 1リクエスト当たり1000件\n    - ソート: updated, created, accessed, linked, views, title\n- `search_pages`\n  - キーワードやフレーズを使用したページ内コンテンツの検索\n    - 用途: 特定のキーワードやフレーズを含むページを発見\n    - 入力: 検索クエリ、オプションのプロジェクト名\n    - 出力: マッチしたページとハイライトされた検索語句、コンテンツスニペット\n    - 最大: 100件（API制限）\n    - サポート: 基本検索、AND検索、除外検索、完全一致フレーズ\n- `create_page`\n  - WebSocket APIを使ってプロジェクトに新しいページを作成\n    - 入力: ページタイトル、オプションのマークダウン本文テキスト、オプションのプロジェクト名、オプションのcreateActuallyフラグ\n    - 出力: ページを即座に作成し、成功確認とURLを返す\n    - 注意: マークダウンコンテンツはScrapbox形式に変換されます\n    - 機能: 数字付きリストを自動的に箇条書きに変換（設定可能）\n    - 認証: 実際のページ作成にはCOSENSE_SIDが必要\n- `get_page_url`\n  - プロジェクト内のページのURLを生成\n    - 入力: ページタイトル、オプションのプロジェクト名\n    - 出力: 指定されたページへの直接URL\n- `insert_lines`\n  - ページの指定した行の後にテキストを挿入\n    - 入力: ページタイトル、対象行のテキスト、挿入するテキスト、オプションのプロジェクト名\n    - 出力: 挿入の詳細を含む成功メッセージ\n    - 動作: 対象行が見つからない場合は、ページの末尾にテキストが追加されます\n\n## インストール方法\n\n```bash\ngit clone https://github.com/worldnine/scrapbox-cosense-mcp.git\ncd scrapbox-cosense-mcp\nnpm install\nnpm run build\n```\n\n## 基本設定\n\nClaude Desktopで使用するには、以下のようにサーバー設定を追加してください:\n\nMacOSの場合: `~/Library/Application\\ Support/Claude/claude_desktop_config.json`\nWindowsの場合: `%APPDATA%/Claude/claude_desktop_config.json`\n\n**単一プロジェクト設定:**\n```json\n{\n  \"mcpServers\": {\n    \"scrapbox-cosense-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\"github:worldnine/scrapbox-cosense-mcp\"],\n      \"env\": {\n        \"COSENSE_PROJECT_NAME\": \"your_project_name\",\n        \"COSENSE_SID\": \"your_sid\", // プライベートプロジェクトの場合は必須\n        \"COSENSE_PAGE_LIMIT\": \"25\", // オプション（デフォルト: 100）\n        \"COSENSE_SORT_METHOD\": \"created\", // オプション（デフォルト: \"updated\"）\n        \"SERVICE_LABEL\": \"scrapbox(cosense)\" // オプション（デフォルト: \"cosense(scrapbox)\"）\n      }\n    }\n  }\n}\n```\n\n## 使用例\n\n設定完了後、Claudeで以下のようにツールを使用できます：\n\n```\n# 特定のページを取得\nget_page を使用してページ「会議メモ」の内容を取得してください。\n\n# 最近のページ一覧\nlist_pages を使用して最近更新された10件のページを一覧表示してください。\n\n# コンテンツ検索\nsearch_pages を使用して「JavaScript チュートリアル」を含むページを検索してください。\n\n# 新しいページを作成\ncreate_page を使用して「今日の学び」というタイトルでページを作成してください。\n\n# ページURLを取得\nget_page_url を使用してページ「プロジェクト計画」のURLを取得してください。\n```\n\n## 環境変数\n\nこのサーバーは以下の環境変数を使用します：\n\n### 必須の環境変数\n\n- `COSENSE_PROJECT_NAME`: プロジェクト名\n- `COSENSE_SID`: Scrapbox/Cosenseの認証用セッションID（プライベートプロジェクトの場合は必須） - [Cookieの取得方法](#cosense_sid-cookieの取得方法)\n\n### オプションの環境変数\n\n- `API_DOMAIN`: APIドメイン（デフォルト: \"scrapbox.io\"）\n- `SERVICE_LABEL`: サービスの識別名（デフォルト: \"cosense (scrapbox)\"）\n- `COSENSE_PAGE_LIMIT`: 初期取得時のページ数（1-1000、デフォルト: 100）\n- `COSENSE_SORT_METHOD`: 初期取得時の取得ページ順（updated/created/accessed/linked/views/title、デフォルト: updated）\n- `COSENSE_TOOL_SUFFIX`: 複数サーバーインスタンス用のツール名サフィックス（例：\"main\"で\"get_page_main\"が作成されます）\n\n### 環境変数の挙動について\n\n- **COSENSE_PROJECT_NAME**: 必須の環境変数です。未設定の場合、サーバーは起動時にエラーで終了します。\n- **COSENSE_SID**: プライベートプロジェクトへのアクセスに必要です。未設定の場合、パブリックプロジェクトのみアクセス可能です。[詳細な取得手順](#cosense_sid-cookieの取得方法)をご確認ください。\n- **API_DOMAIN**:\n  - 未設定時は\"scrapbox.io\"を使用\n  - 作者の環境では\"scrapbox.io\"以外の値は未検証ですが、\"cosen.se\"でないと動作しない環境が存在する可能性があるため念のためのオプションです。\n- **COSENSE_PAGE_LIMIT**:\n  - 未設定時は100を使用\n  - 無効な値（数値以外や範囲外）の場合は100を使用\n  - 有効範囲: 1-1000\n- **COSENSE_SORT_METHOD**:\n  - 未設定時は'updated'を使用\n  - 無効な値の場合は'updated'を使用\n  - list_pagesツールの動作には影響しません（初期リソース取得時のみ使用）\n\n### COSENSE_SID Cookieの取得方法\n\nプライベートなScrapboxプロジェクトにアクセスするには、ブラウザから `connect.sid` Cookieを取得する必要があります。以下の手順に従ってください：\n\n1. **Scrapboxプロジェクトにアクセス**\n   - ブラウザで `https://scrapbox.io/あなたのプロジェクト名` を開きます\n   - `あなたのプロジェクト名` を実際のプロジェクト名に置き換えてください\n\n2. **Scrapboxにログイン**\n   - Scrapboxアカウントにログインしていることを確認してください\n   - プライベートプロジェクトにアクセスできることを確認してください\n\n3. **開発者ツールを開く**\n   - **Windows/Linux**: `F12` キーまたは `Ctrl+Shift+I` を押します\n   - **macOS**: `Cmd+Option+I` を押します\n   - **別の方法**: ページ上で右クリックして「検証」または「要素を調査」を選択\n\n4. **Cookieを確認**\n   - 開発者ツールで **「Application」** タブ（Chrome/Edge）または **「ストレージ」** タブ（Firefox）を探します\n   - 左側のサイドバーで **「Cookies」** を展開します\n   - `https://scrapbox.io` をクリックします\n\n5. **connect.sid Cookieを見つけてコピー**\n   - `connect.sid` という名前のCookieを探します\n   - それをクリックして値を確認します\n   - **重要**: ブラウザはURLエンコードされた値を表示しますが、実際には**デコードされた値**を使用する必要があります\n   - ブラウザ表示: `s%3Axxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx.xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx`\n   - 使用すべき値: `s:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx.xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx`（`s`の後は`:`です）\n\n6. **環境変数に設定**\n   - **デコードされた値**（`%3A`の代わりに`:`）を `COSENSE_SID` 環境変数として使用します\n   - **正しい形式**: `COSENSE_SID=s:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx.xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx`\n   - **間違った形式**: `COSENSE_SID=s%3Axxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx.xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx`\n\n**重要な注意事項:**\n- `connect.sid` Cookieの値は機密情報のため、安全に管理し、公開しないでください\n- Cookieは時間が経つと期限切れになる場合があります。認証エラーが発生した場合は新しいCookieを取得してください\n- このCookieはプライベートプロジェクトへのアクセス権を提供するため、パスワードと同様に扱ってください\n\n## 複数プロジェクト対応（高度な機能）\n\n### 方法1: オプショナルパラメータを使用した単一サーバー\n\nすべてのツールで、単一サーバーから異なるプロジェクトを対象とするオプションの`projectName`パラメータをサポートしています：\n\n- **デフォルト動作**: プロジェクトが指定されていない場合は`COSENSE_PROJECT_NAME`環境変数を使用\n- **複数プロジェクト使用**: `projectName`パラメータを指定して異なるプロジェクトにアクセス\n- **後方互換性**: 既存の設定は変更なしで動作\n\n**使用例:**\n\n```\n# デフォルトプロジェクトからページを取得\nget_page を使用してページ「会議メモ」の内容を取得してください。\n\n# 特定のプロジェクトからページを取得  \nget_page を使用して、プロジェクト名「help-ja」からページ「使い方」の内容を取得してください。\n\n# 異なるプロジェクトでページを検索\nsearch_pages を使用して、プロジェクト名「developer-docs」で「API ドキュメント」を含むページを検索してください。\n\n# 特定のプロジェクトにページを作成\ncreate_page を使用して、プロジェクト名「team-updates」に「週次レポート」というタイトルでページを作成してください。\n```\n\n**重要な制限事項:**\n\nこの方法は、パブリックプロジェクトや同じ認証情報を共有するプロジェクトで最も効果的です。異なるアクセス認証情報を持つ複数のプライベートプロジェクトには、以下の方法2をご利用ください。\n\n### 方法2: 複数MCPサーバーインスタンス（プライベートプロジェクト推奨）\n\n複数のプライベートプロジェクトで最良のユーザー体験を得るには、プロジェクトごとに別々のMCPサーバーインスタンスを実行します：\n\n```json\n{\n  \"mcpServers\": {\n    \"main-scrapbox\": {\n      \"command\": \"npx\",\n      \"args\": [\"github:worldnine/scrapbox-cosense-mcp\"],\n      \"env\": {\n        \"COSENSE_PROJECT_NAME\": \"main-project\",        // API呼び出しで使用される実際のプロジェクト名\n        \"COSENSE_SID\": \"s:main_sid_here...\",           // このプロジェクト用のセッションID\n        \"COSENSE_TOOL_SUFFIX\": \"main\",                 // get_page_main のようなツール名を作成\n        \"SERVICE_LABEL\": \"Main Scrapbox\"               // ツール説明で表示される人間向けの名前\n      }\n    },\n    \"team-cosense\": {\n      \"command\": \"npx\",\n      \"args\": [\"github:worldnine/scrapbox-cosense-mcp\"],\n      \"env\": {\n        \"COSENSE_PROJECT_NAME\": \"team-workspace\",      // API呼び出しで使用される実際のプロジェクト名\n        \"COSENSE_SID\": \"s:team_sid_here...\",           // このプロジェクト用のセッションID\n        \"COSENSE_TOOL_SUFFIX\": \"team\",                 // get_page_team のようなツール名を作成\n        \"SERVICE_LABEL\": \"Team Cosense\"                // ツール説明で表示される人間向けの名前\n      }\n    }\n  }\n}\n```\n\n**設定のポイント:**\n- **COSENSE_PROJECT_NAME**: API呼び出しで使用される実際のプロジェクト名（例: `scrapbox.io/main-project`）\n- **SERVICE_LABEL**: ツール説明で表示される名前（例: 「Main Scrapboxでページを作成」）\n- **COSENSE_TOOL_SUFFIX**: `get_page_main` や `get_page_team` のような固有のツール名を作成\n- **サービス名の使い分け**: 「Scrapbox」と「Cosense」を使い分けることでプロジェクトを区別\n\nこれにより `get_page_main`、`list_pages_main`、`get_page_team`、`list_pages_team` のようなツールが作成され、LLMが自動的に適切なプロジェクトを選択できるようになります。\n\n## 開発方法\n\n依存関係のインストール:\n\n```bash\nnpm install\n```\n\nサーバーのビルド:\n\n```bash\nnpm run build\n```\n\n開発時の自動リビルド:\n\n```bash\nnpm run watch\n```\n\nテストの実行:\n\n```bash\nnpm test\n```\n\nリンティングの実行:\n\n```bash\nnpm run lint\n```\n\n### 品質管理\n\nこのプロジェクトでは、コードの信頼性を確保するための自動品質チェックが導入されています：\n\n- **ESLint**: TypeScript対応のリンティング、console.log使用時の警告\n- **GitHub Actions**: プルリクエスト用の自動CI/CDパイプライン\n- **ブランチ保護**: mainブランチへはPRとチェック通過が必須\n- **テストスイート**: 142+のテストで全機能をカバー\n\n#### 貢献ガイドライン\n\n1. mainから機能ブランチを作成\n2. 適切なテストと共に変更を実装\n3. ローカルで `npm run lint` と `npm test` を実行\n4. プルリクエストを作成\n5. CIが自動的に品質チェックを実行\n6. 全チェック通過後にマージ\n\nこの品質管理システムにより、デバッグログや壊れたコードの本番環境への混入を防げます。\n\n### デバッグ方法\n\nMCPサーバーはstdioを介して通信を行うため、デバッグが難しい場合があります。[MCP Inspector](https://github.com/modelcontextprotocol/inspector)の使用を推奨します。以下のコマンドで実行できます：\n\n```bash\nnpm run inspector\n```\n\nInspectorはブラウザでデバッグツールにアクセスするためのURLを提供します。\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "scrapbox",
        "retrieval",
        "pages",
        "scrapbox project",
        "scrapbox cosense",
        "interact scrapbox"
      ],
      "category": "document-processing"
    },
    "worldnine--textwell-mcp": {
      "owner": "worldnine",
      "name": "textwell-mcp",
      "url": "https://github.com/worldnine/textwell-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/worldnine.webp",
      "description": "A specialized MCP server for writing text to the Textwell application on macOS, offering modes for replacing, inserting, or appending text. It facilitates text manipulation directly within the Textwell environment.",
      "stars": 0,
      "forks": 2,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-01-17T13:30:15Z",
      "readme_content": "# Textwell Write Tool (MCP Server)\n\nA specialized MCP server designed exclusively for writing text to the Textwell application on macOS.\n\n## Overview\n\nThis tool provides a straightforward way to write text to Textwell. \n\n## Features\n\nThe server provides a single tool: `write-text`\n\n### Write Text Tool\n\nWrites text to Textwell using specified modes:\n\n- **Replace Mode** (default)\n  - Replaces the entire content with new text\n  - Use case: Complete content replacement\n\n- **Insert Mode**\n  - Inserts text at the current cursor position\n  - Use case: Adding content within existing text\n\n- **Add Mode**\n  - Appends text to the end of current content\n  - Use case: Adding new content while preserving existing text\n\n## Limitations\n\n- Write-only operations (no read capabilities)\n\n## Development Setup\n\n### Prerequisites\n\n- Node.js v22.12.0 (managed by Volta)\n- npm v10.9.0 (managed by Volta)\n- macOS (for Textwell integration)\n\n### Installation\n\n1. Clone the repository\n```bash\ngit clone [repository-url]\ncd textwell-mcp\n```\n\n2. Install dependencies\n```bash\nnpm install\n```\n\n3. Build the server\n```bash\nnpm run build\n```\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "textwell",
        "mcp",
        "text",
        "textwell mcp",
        "textwell application",
        "text textwell"
      ],
      "category": "document-processing"
    },
    "wowyuarm--file-converter-mcp": {
      "owner": "wowyuarm",
      "name": "file-converter-mcp",
      "url": "https://github.com/wowyuarm/file-converter-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/wowyuarm.webp",
      "description": "Convert various document and image formats such as DOCX to PDF, PDF to DOCX, and multiple image formats (JPG, PNG, WebP, etc.). Provides reliable and flexible file handling to meet diverse conversion needs.",
      "stars": 19,
      "forks": 11,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-24T18:57:24Z",
      "readme_content": "# File Converter MCP Server\n\n[简体中文](README_CN.md) | English\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)\n\nThis MCP server provides multiple file conversion tools for converting various document and image formats. This project is built using the [Model Context Protocol (MCP)](https://modelcontextprotocol.io) and is designed to serve AI agents that need file conversion capabilities.\n\n## Features\n\n  - **DOCX to PDF**: Convert Microsoft Word documents to PDF\n  - **PDF to DOCX**: Convert PDF documents to Microsoft Word format\n  - **Image Format Conversion**: Convert between various image formats (JPG, PNG, WebP, etc.)\n  - **Excel to CSV**: Convert Excel spreadsheets to CSV format\n  - **HTML to PDF**: Convert HTML files to PDF format\n  - **Markdown to PDF**: Convert Markdown documents to PDF with proper styling\n  - **Generic Conversion**: A versatile tool that attempts to handle various format conversions\n\n## Technologies\n\n- Python 3.10+\n- [Model Context Protocol (MCP) Python SDK](https://pypi.org/project/mcp/)\n- Various conversion libraries:\n  - [docx2pdf](https://pypi.org/project/docx2pdf/) - for DOCX to PDF conversion\n  - [pdf2docx](https://pypi.org/project/pdf2docx/) - for PDF to DOCX conversion\n  - [Pillow](https://pypi.org/project/Pillow/) - for image format conversions\n  - [pandas](https://pypi.org/project/pandas/) - for Excel to CSV conversion\n  - [pdfkit](https://pypi.org/project/pdfkit/) - for HTML to PDF conversion\n  - [markdown](https://pypi.org/project/markdown/) - for Markdown to HTML conversion\n\n## Installation\n\n1. **Clone the Repository**\n\n   ```bash\n   git clone https://github.com/wowyuarm/file-converter-mcp.git\n   cd file-converter-mcp\n   ```\n\n2. **Create a Virtual Environment (optional but recommended)**\n\n   ```bash\n   python -m venv venv\n   source venv/bin/activate      # On Unix-based systems\n   venv\\Scripts\\activate         # On Windows\n   ```\n\n3. **Install Dependencies**\n\n   Install the required packages using pip:\n\n   ```bash\n   pip install mcp docx2pdf pdf2docx pillow pandas pdfkit markdown\n   ```\n\n   Alternatively, if you are using [uv](https://docs.astral.sh/uv/):\n\n   ```bash\n   uv add \"mcp[cli]\" docx2pdf pdf2docx pillow pandas pdfkit markdown\n   ```\n\n   Note: Some conversion libraries may have additional system dependencies. Please check their documentation for details.\n\n## Usage\n\n### Running the Server in Development Mode\n\nTo test the server, run:\n\n```bash\nmcp dev file_converter_server.py\n```\n\n### Installing for Claude Desktop\n\nOptionally, you can install the server on Claude Desktop with:\n\n```bash\nmcp install file_converter_server.py --name \"File Converter\"\n```\n\n### API / Tools\n\nThe MCP server exposes the following tools:\n\n#### Path-Based Tools (Also Support Content Input)\n\n##### docx2pdf\nCommand: `docx2pdf`\n- **Input Option 1**: Path to a .docx file\n  ```\n  input_file: path/to/document.docx\n  ```\n- **Input Option 2**: Base64 encoded content of the DOCX file\n  ```\n  file_content_base64: [base64 encoded string]\n  ```\n- **Output**: Base64 encoded string of the converted PDF file\n\n##### pdf2docx\nCommand: `pdf2docx`\n- **Input Option 1**: Path to a PDF file\n  ```\n  input_file: path/to/document.pdf\n  ```\n- **Input Option 2**: Base64 encoded content of the PDF file\n  ```\n  file_content_base64: [base64 encoded string]\n  ```\n- **Output**: Base64 encoded string of the converted DOCX file\n\n##### convert_image\nCommand: `convert_image`\n- **Input Option 1**: \n  ```\n  input_file: path/to/image.png\n  output_format: jpg\n  ```\n- **Input Option 2**:\n  ```\n  file_content_base64: [base64 encoded string]\n  input_format: png\n  output_format: jpg\n  ```\n- **Output**: Base64 encoded string of the converted image\n\n##### excel2csv\nCommand: `excel2csv`\n- **Input**: Path to an Excel file (.xls or .xlsx)\n- **Output**: Base64 encoded string of the converted CSV file\n\n##### html2pdf\nCommand: `html2pdf`\n- **Input**: Path to an HTML or Markdown file (.html, .md, .markdown)\n- **Output**: Base64 encoded string of the converted PDF file\n\n##### convert_file (Generic Converter)\nCommand: `convert_file`\n- **Input Option 1**: \n  ```\n  input_file: path/to/file.docx\n  input_format: docx\n  output_format: pdf\n  ```\n- **Input Option 2**:\n  ```\n  file_content_base64: [base64 encoded string]\n  input_format: docx\n  output_format: pdf\n  ```\n- **Output**: Base64 encoded string of the converted file\n\n#### Content-Based Tools (Legacy)\n\nThese are maintained for backward compatibility. All main tools now support content-based input directly.\n\n##### convert_content (Generic Content Converter)\nCommand: `convert_content`\n- **Input**:\n  - Base64 encoded content of the input file\n  - Source format (e.g., \"docx\", \"pdf\", \"md\")\n  - Target format (e.g., \"pdf\", \"docx\")\n- **Output**: Base64 encoded string of the converted file\n\n##### docx2pdf_content\nCommand: `docx2pdf_content`\n- **Input**: Base64 encoded content of the DOCX file\n- **Output**: Base64 encoded string of the converted PDF file\n\n##### pdf2docx_content\nCommand: `pdf2docx_content`\n- **Input**: Base64 encoded content of the PDF file\n- **Output**: Base64 encoded string of the converted DOCX file\n\n##### markdown2pdf_content\nCommand: `markdown2pdf_content`\n- **Input**: Base64 encoded content of the Markdown file\n- **Output**: Base64 encoded string of the converted PDF file\n\n## File Handling\n\nThe server includes robust file path handling that:\n- Uses a multi-stage search strategy to find files\n- Searches for uploaded files in common locations (temp directories, current directory)\n- Tries multiple filename variations (case-insensitive, with/without extensions)\n- Provides detailed logs to help troubleshoot file location issues\n- Works seamlessly with files uploaded via Claude chat interface\n- Supports relative and absolute file paths\n- Automatically detects file formats when possible\n\n### Dual-Mode Input\n\nAll conversion tools now support two methods of input:\n\n1. **Path-Based Conversion** (traditional approach)\n   ```\n   @File Converter\n   docx2pdf\n   input_file: file.docx\n   ```\n\n2. **Content-Based Conversion** (works even when path lookup fails)\n   ```\n   @File Converter\n   docx2pdf\n   file_content_base64: [base64 encoded string]\n   ```\n\nThis dual-mode approach provides maximum flexibility and reliability:\n- When in doubt, use content-based input for guaranteed processing\n- All intermediate files are created with unique names in temporary directories\n- Temporary files are automatically cleaned up after processing\n\n### Handling Claude-Specific File Uploads\n\nWhen using with Claude, if a file upload fails to be found:\n\n1. Try using the original filename with a preceding path:\n   ```\n   @File Converter\n   docx2pdf\n   input_file: /tmp/file.docx\n   ```\n\n2. If that fails, obtain the file content directly from Claude:\n   ```\n   @File Converter\n   docx2pdf\n   file_content_base64: [base64 content obtained from Claude]\n   ```\n\n## Error Handling\n\n- Each tool validates file existence using multiple search strategies\n- Detailed error messages are returned in a structured JSON format: `{\"success\": false, \"error\": \"error message\"}`\n- Successful conversions return: `{\"success\": true, \"data\": \"base64 encoded file content\"}`\n- The server includes comprehensive logging for troubleshooting\n- The server gracefully handles exceptions and returns informative error messages\n\n## Contributing\n\nContributions are welcome! If you'd like to contribute, please follow the guidelines in [CONTRIBUTING.md](CONTRIBUTING.md) (中文版: [贡献指南](CONTRIBUTING.md), English: [Contributing Guidelines](CONTRIBUTING_EN.md)).\n\n## License\n\nThis project is licensed under the MIT License – see the [LICENSE](LICENSE) file for details.\n\n## GitHub Repository\n\nVisit the GitHub repository at: https://github.com/wowyuarm/file-converter-mcp\n\n## MCP Server Configuration\n\nThis project can be used as a Model Context Protocol (MCP) server, providing file conversion tools to AI agents.\n\n### Quick Start\n\n1. **Install dependencies:**\n   ```bash\n   python -m pip install -e .\n   ```\n\n2. **Start the MCP server:**\n   ```bash\n   python start_mcp_server.py\n   ```\n\n3. **Configure your MCP client** (e.g., Claude Desktop, Cursor) with the following configuration:\n\n   **Recommended configuration** (`cursor-mcp.config.json`):\n   ```json\n   {\n     \"mcpServers\": {\n       \"file-converter\": {\n         \"command\": \"python\",\n         \"args\": [\"file_converter_server.py\"],\n         \"cwd\": \".\"\n       }\n     }\n   }\n   ```\n\n   **Alternative configuration** (`mcp.config.json`):\n   ```json\n   {\n     \"mcpServers\": {\n       \"file-converter\": {\n         \"command\": \"python\",\n         \"args\": [\"file_converter_server.py\"],\n         \"cwd\": \".\"\n       }\n     }\n   }\n   ```\n\n### Important Notes\n\n- **stdio mode is recommended** - This is the most reliable way to connect MCP servers\n- **Use `cursor-mcp.config.json`** for the simplest configuration\n- **Make sure the server is running** before connecting from Cursor\n\n### Available Tools\n\nThe MCP server provides the following tools:\n\n- **`docx2pdf`**: Convert Word documents to PDF\n- **`pdf2docx`**: Convert PDF to Word documents  \n- **`convert_image`**: Convert between image formats (PNG, JPG, WEBP, etc.)\n- **`excel2csv`**: Convert Excel files to CSV\n- **`html2pdf`**: Convert HTML/Markdown to PDF\n- **`convert_file`**: Generic file conversion between supported formats\n- **`convert_content`**: Convert files from base64 content\n\n### Usage Examples\n\nOnce configured, you can use the tools in your AI agent:\n\n```\nConvert this Word document to PDF: [upload file]\nConvert this image from PNG to JPG: [upload file]\nConvert this Excel file to CSV: [upload file]\n``` ",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "docx",
        "formats",
        "document",
        "formats docx",
        "file converter",
        "image formats"
      ],
      "category": "document-processing"
    },
    "wushouzhuan1--finance_news_analysis": {
      "owner": "wushouzhuan1",
      "name": "finance_news_analysis",
      "url": "https://github.com/wushouzhuan1/finance_news_analysis",
      "imageUrl": "/freedevtools/mcp/pfp/wushouzhuan1.webp",
      "description": "Scrapes financial data, performs NLP algorithm analysis, and facilitates quantitative strategy backtesting. Integrates various components for automated financial data processing and insights extraction.",
      "stars": 2,
      "forks": 0,
      "license": "No License",
      "language": "C++",
      "updated_at": "2025-04-14T18:10:33Z",
      "readme_content": "## 项目简介\n本项目致力于完成金融相关的数据抓取、NLP算法分析、量化策略、回测框架等的系统搭建工作，系统包括如下几个主要的部分；  \n![image](https://ooo.0o0.ooo/2017/06/11/593d32cbf3f37.png)  \n代码和tutorial仍在完善中，将于近期更新  \n\n## 项目结构\n.  \n├── algorithm(算法模型框架)  \n├── analyze(具体策略)   \n├── crawler(scrapy爬虫)  \n│   └── crawler  \n│       └── spiders(爬虫具体抓取代码)  \n├── database(数据库操作)  \n├── preprocess(数据预处理)  \n│   └── pre_data(预处理存放目录)  \n├── strategy(回测接口)  \n├── tonglian(通联数据获取接口)  \n├── tools(通联数据获取接口)  \n├── utils(通用处理类)  \n└── data(存放数据的目录)\n\n## Python库依赖\n中文分词: [jieba](https://github.com/fxsjy/jieba)  \n爬虫: [scrapy](http://scrapy.org/)  \nMysql连接: [MySQLdb](http://mysql-python.sourceforge.net/MySQLdb.html)  \nORM工具: [sqlalchemy](http://www.sqlalchemy.org/)  \nAC自动机: [esmre](https://github.com/wharris/esmre)  \n布隆过滤器: [pybloom](https://github.com/jaybaird/python-bloomfilter)  \n机器学习: [scikit-learn](http://scikit-learn.org/)  \n文本主题模型: [gensim](https://github.com/piskvorky/gensim)  \n快速生成Python扩展模块: [Cython](http://cython.org/)\n\n## 注意事项\n1. 修改PYTHONPATH  \n把项目所在目录添加到PYTHONPATH中。  \n建议方法：  \n通过PYTHONPATH 中的任何 .pth 文件来添加pythonpath。  \n比如添加/home/aa这个路径到pythonpath里，可以这样做：  \n    1) 新建一个文件，名字随便，但后缀名须是.pth，比如aa.pth；  \n\t2) 文件内容直接输入\"/home/aa\"(没有引号)，如果有多个路径可以多行输入，但每行保证只有一个路径；  \n\t3) 然后文件保存到sys.path列表中的任一文件夹下，一般来说我们保存到/usr/local/lib/python*/dist-packages，需要特别指出的是在不同版本中dist-packages可能被改成site-packages，最后重启python就可以了。  ",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "finance_news_analysis",
        "nlp",
        "data",
        "finance_news_analysis scrapes",
        "wushouzhuan1 finance_news_analysis",
        "insights extraction"
      ],
      "category": "document-processing"
    },
    "wysh3--perplexity-mcp-zerver": {
      "owner": "wysh3",
      "name": "perplexity-mcp-zerver",
      "url": "https://github.com/wysh3/perplexity-mcp-zerver",
      "imageUrl": "/freedevtools/mcp/pfp/wysh3.webp",
      "description": "Integrate AI research capabilities by performing web searches, retrieving documentation, and analyzing code through interaction with the Perplexity website. It provides persistent chat history and does not require an API key, relying on browser automation.",
      "stars": 59,
      "forks": 15,
      "license": "GNU General Public License v3.0",
      "language": "TypeScript",
      "updated_at": "2025-09-29T08:26:10Z",
      "readme_content": "# Perplexity MCP Zerver\n\nA minimalist research server implementing the Model Context Protocol (MCP) to deliver AI-powered research capabilities through Perplexity's web interface.\n\n[![MCP Compatible](https://img.shields.io/badge/MCP-Compatible-333)]()\n[![TypeScript Codebase](https://img.shields.io/badge/TypeScript-Codebase-333)]()\n[![Tests Passing](https://img.shields.io/badge/Tests-Passing-333)]()\n[![Bun Runtime](https://img.shields.io/badge/Runtime-Bun-333)]()\n\n## Research Capabilities\n\n- **Intelligent Web Research**: Search and summarize content without API limits\n- **Persistent Conversations**: Maintain context with local SQLite chat storage\n- **Content Extraction**: Clean article extraction with GitHub repository parsing\n- **Developer Tooling**: Documentation retrieval, API discovery, code analysis\n- **Keyless Operation**: Browser automation replaces API key requirements\n\n---\n\n## Available Tools\n\n### Search (`search`)\nPerform research queries with configurable depth  \n*Returns raw text results*\n\n### Get Documentation (`get_documentation`)\nRetrieve technical documentation with examples  \n*Returns structured documentation*\n\n### Find APIs (`find_apis`)\nDiscover relevant APIs for development needs  \n*Returns API listings and descriptions*\n\n### Check Deprecated Code (`check_deprecated_code`)\nAnalyze code snippets for outdated patterns  \n*Returns analysis report*\n\n### Extract URL Content (`extract_url_content`)\nParse web content with automatic GitHub handling  \n*Returns structured content metadata*\n\n### Chat (`chat_perplexity`)\nPersistent conversations with context history  \n*Returns conversation state in JSON format*\n\n---\n\n## Getting Started\n\n### Prerequisites\n- Bun runtime\n- Node.js 18+ (for TypeScript compilation)\n\n### Installation\n```bash\ngit clone https://github.com/wysh3/perplexity-mcp-zerver.git\ncd perplexity-mcp-zerver\nbun install\nbun run build\n```\n\n### Configuration\nAdd to your MCP configuration file:\n```json\n{\n  \"mcpServers\": {\n    \"perplexity-server\": {\n      \"command\": \"bun\",\n      \"args\": [\"/absolute/path/to/build/main.js\"],\n      \"timeout\": 300\n    }\n  }\n}\n```\n\n### Usage\nInitiate commands through your MCP client:\n- \"Use perplexity to research quantum computing advancements\"\n- \"Ask perplexity-server for React 18 documentation\"\n- \"Begin conversation with perplexity about neural networks\"\n\n---\n\n## Technical Comparison\n\n| Feature              | This Implementation | Traditional APIs |\n|----------------------|---------------------|------------------|\n| Authentication       | None required       | API keys         |\n| Cost                 | Free                | Usage-based      |\n| Data Privacy         | Local processing    | Remote servers   |\n| GitHub Integration   | Native support      | Limited          |\n| History Persistence  | SQLite storage      | Session-based    |\n\n---\n\n## Troubleshooting\n\n**Server Connection Issues**\n1. Verify absolute path in configuration\n2. Confirm Node.js installation with `node -v`\n3. Ensure build completed successfully\n\n**Content Extraction**\n- GitHub paths must use full repository URLs\n- Adjust link recursion depth in source configuration\n\n---\n\n## Origins & License\n \nbased on - [DaInfernalCoder/perplexity-researcher-mcp](https://github.com/DaInfernalCoder/perplexity-researcher-mcp)  \nrefactored from - [sm-moshi/docshunter](https://github.com/sm-moshi/docshunter)  \n\nLicensed under **GNU GPL v3.0** - [View License](LICENSE)\n\n---\n\n> This project interfaces with Perplexity via browser automation. Use responsibly and ethically. Stability depends on Perplexity's website consistency. Educational use only.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "documentation",
        "automation",
        "ai",
        "wysh3 perplexity",
        "perplexity website",
        "ai research"
      ],
      "category": "document-processing"
    },
    "xiandan-erizo--ops-mcp": {
      "owner": "xiandan-erizo",
      "name": "ops-mcp",
      "url": "https://github.com/xiandan-erizo/ops-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/xiandan-erizo.webp",
      "description": "Search and retrieve Confluence documents, accessing full page content and associated metadata for efficient document management. Supports full-text search and retrieval of document details including title, space, and version information.",
      "stars": 1,
      "forks": 0,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-05-14T10:53:12Z",
      "readme_content": "# Confluence MCP Server\n\n基于 Model Context Protocol (MCP) 的 Confluence 文档访问服务，提供文档搜索和内容获取功能。\n\n## 功能特性\n\n- **文档搜索**\n  - 支持标题和全文搜索\n  - 限制返回结果数量\n  - 返回匹配内容片段和文档基本信息\n\n- **文档内容获取**\n  - 获取完整的页面内容\n  - 包含元数据（标题、空间信息、版本等）\n  - 创建和修改信息\n  - 页面标签\n\n## 快速开始\n\n### 环境配置\n\n创建 `.env` 文件配置 Confluence 访问信息：\n\n```bash\nCONFLUENCE_URL=\"your-confluence-url\"\nCONFLUENCE_USERNAME=\"your-username\"\nCONFLUENCE_PASSWORD=\"your-password\"\n# 或者使用 Token 认证\nCONFLUENCE_TOKEN=\"your-api-token\"\n```\n\n### 安装依赖\n\n```bash\n# 安装项目依赖\nuv pip install -e .\n\n# 或者直接安装依赖包\nuv pip install \"mcp[cli]>=1.5.0\" \"atlassian-python-api>=3.41.4\" \"typer>=0.9.0\"\n```\n\n### 运行服务\n\n```bash\n# 使用 uvx\n/Users/hose/.local/bin/uvx --directory /Users/hose/code/ops/ops-mcp mcp main.py\n\n# 或者使用 uv run\nuv run --with mcp mcp run main.py\n```\n\n## MCP 接口说明\n\n### Tools (工具)\n\n1. search_confluence\n   ```python\n   # 搜索 Confluence 内容\n   Input:\n   - query: str       # 搜索关键词\n   - limit: int = 10  # 返回结果数量限制\n   \n   Output:\n   {\n     \"success\": true,\n     \"query\": \"搜索词\",\n     \"total\": 5,\n     \"results\": [\n       {\n         \"id\": \"12345\",\n         \"title\": \"页面标题\",\n         \"type\": \"page\",\n         \"url\": \"页面URL\",\n         \"excerpt\": \"匹配内容片段\"\n       }\n     ]\n   }\n   ```\n\n2. get_confluence_page\n   ```python\n   # 获取页面详细信息\n   Input:\n   - page_id: str  # 页面ID\n   \n   Output:\n   {\n     \"success\": true,\n     \"page\": {\n       \"id\": \"12345\",\n       \"title\": \"页面标题\",\n       \"space\": {\n         \"key\": \"SPACE\",\n         \"name\": \"空间名称\"\n       },\n       \"version\": 1,\n       \"content\": \"页面内容\",\n       \"url\": \"页面URL\",\n       \"created\": {\n         \"date\": \"创建时间\",\n         \"by\": \"创建者\"\n       },\n       \"modified\": {\n         \"date\": \"修改时间\",\n         \"by\": \"修改者\"\n       },\n       \"labels\": [\"标签1\", \"标签2\"]\n     }\n   }\n   ```\n\n### Resources (资源)\n\n1. confluence://pages/{page_id}\n   - 通过页面ID直接获取页面内容和元数据\n   - 返回 JSON 格式数据\n\n2. confluence://search/{query}\n   - 通过关键词直接搜索内容\n   - 返回 JSON 格式的搜索结果\n\n## 错误处理\n\n所有接口在出错时返回统一格式：\n\n```json\n{\n  \"success\": false,\n  \"error\": \"错误信息描述\"\n}\n```\n\n## 使用示例\n\n1. 搜索文档\n```python\nresult = await mcp.use_tool(\"search_confluence\", {\n    \"query\": \"Python\",\n    \"limit\": 5\n})\n```\n\n2. 获取页面内容\n```python\npage = await mcp.use_tool(\"get_confluence_page\", {\n    \"page_id\": \"12345\"\n})\n```\n\n3. 使用资源URI\n```python\ncontent = await mcp.access_resource(\"confluence://pages/12345\")\nsearch_results = await mcp.access_resource(\"confluence://search/Python\")\n```\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "documents",
        "document",
        "confluence",
        "retrieval document",
        "document processing",
        "confluence documents"
      ],
      "category": "document-processing"
    },
    "xraywu--mcp-pdf-extraction-server": {
      "owner": "xraywu",
      "name": "mcp-pdf-extraction-server",
      "url": "https://github.com/xraywu/mcp-pdf-extraction-server",
      "imageUrl": "/freedevtools/mcp/pfp/xraywu.webp",
      "description": "Extracts text from PDF files using advanced reading and OCR capabilities. Supports content retrieval from specified pages or entire documents for seamless integration into applications.",
      "stars": 18,
      "forks": 9,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-09-14T15:12:13Z",
      "readme_content": "# PDF Extraction MCP Server (Claude Code Fork)\n\nMCP server to extract contents from PDF files, with fixes for Claude Code CLI installation.\n\nThis fork includes critical fixes for installing and running the server with Claude Code (the CLI version).\n\n## What's Different in This Fork\n\n1. **Added `__main__.py`** - Enables the package to be run as a module with `python -m pdf_extraction`\n2. **Claude Code specific instructions** - Clear installation steps that work with Claude Code CLI\n3. **Tested installation process** - Verified working with `claude mcp add` command\n\n## Components\n\n### Tools\n\nThe server implements one tool:\n- **extract-pdf-contents**: Extract contents from a local PDF file\n  - Takes `pdf_path` as a required string argument (local file path)\n  - Takes `pages` as an optional string argument (comma-separated page numbers, supports negative indexing like `-1` for last page)\n  - Supports both PDF text extraction and OCR for scanned documents\n\n## Installation for Claude Code CLI\n\n### Prerequisites\n\n- Python 3.11 or higher\n- pip or conda\n- Claude Code CLI installed (`claude` command)\n\n### Step 1: Clone and Install\n\n```bash\n# Clone this fork\ngit clone https://github.com/lh/mcp-pdf-extraction-server.git\ncd mcp-pdf-extraction-server\n\n# Install in development mode\npip install -e .\n```\n\n### Step 2: Find the Installed Command\n\n```bash\n# Check where pdf-extraction was installed\nwhich pdf-extraction\n# Example output: /opt/homebrew/Caskroom/miniconda/base/bin/pdf-extraction\n```\n\n### Step 3: Add to Claude Code\n\n```bash\n# Add the server using the full path from above\nclaude mcp add pdf-extraction /opt/homebrew/Caskroom/miniconda/base/bin/pdf-extraction\n\n# Verify it was added\nclaude mcp list\n```\n\n### Step 4: Use in Claude\n\n```bash\n# Start a new Claude session\nclaude\n\n# In Claude, type:\n/mcp\n\n# You should see:\n# MCP Server Status\n# • pdf-extraction: connected\n```\n\n## Usage Example\n\nOnce connected, you can ask Claude to extract PDF contents:\n\n```\n\"Can you extract the content from the PDF at /path/to/document.pdf?\"\n\n\"Extract pages 1-3 and the last page from /path/to/document.pdf\"\n```\n\n## Troubleshooting\n\n### Server Not Connecting\n\n1. Make sure you started a NEW Claude session after adding the server\n2. Verify the command path is correct: `ls -la $(which pdf-extraction)`\n3. Test the command directly (it should hang waiting for input): `pdf-extraction`\n\n### Module Not Found Errors\n\nIf you get Python import errors:\n1. Make sure you're using the same Python environment where you installed the package\n2. Try using the full Python path: `claude mcp add pdf-extraction /path/to/python -m pdf_extraction`\n\n### Installation Issues\n\nIf `pip install -e .` fails:\n1. Make sure you have Python 3.11+: `python --version`\n2. Try creating a fresh virtual environment:\n   ```bash\n   python -m venv venv\n   source venv/bin/activate  # On Windows: venv\\Scripts\\activate\n   pip install -e .\n   ```\n\n## For Claude Desktop Users\n\nThis fork is specifically for Claude Code CLI. If you're using Claude Desktop (the GUI app), please refer to the [original repository](https://github.com/xraywu/mcp-pdf-extraction-server) for installation instructions.\n\n## Dependencies\n\n- mcp>=1.2.0\n- pypdf2>=3.0.1\n- pytesseract>=0.3.10 (for OCR support)\n- Pillow>=10.0.0\n- pydantic>=2.10.1,<3.0.0\n- pymupdf>=1.24.0\n\n## Contributing\n\nContributions are welcome! The main change in this fork is the addition of `__main__.py` to make the package runnable as a module.\n\n## License\n\nSame as the original repository.\n\n## Credits\n\nOriginal server by [@xraywu](https://github.com/xraywu)\nClaude Code fixes by [@lh](https://github.com/lh)",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ocr",
        "pdf",
        "document",
        "pdf extraction",
        "document processing",
        "processing xraywu"
      ],
      "category": "document-processing"
    },
    "yellowgg2--mcp-bookstack": {
      "owner": "yellowgg2",
      "name": "mcp-bookstack",
      "url": "https://github.com/yellowgg2/mcp-bookstack",
      "imageUrl": "/freedevtools/mcp/pfp/yellowgg2.webp",
      "description": "Search and retrieve structured data from BookStack pages with customizable queries, pagination, and HTML-to-text conversion for enhanced reading. It includes robust error handling and validation for seamless content access.",
      "stars": 9,
      "forks": 5,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-09-22T00:34:46Z",
      "readme_content": "# BookStack MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@yellowgg2/mcp-bookstack)](https://smithery.ai/server/@yellowgg2/mcp-bookstack)\n\nA Model Context Protocol (MCP) server that provides tools for searching pages from BookStack. This server interacts with the BookStack API and provides structured data for pages with clean HTML-to-text conversion.\n\n## Features\n\n- Search pages from BookStack with customizable queries\n- Get structured data including titles, URLs, and content\n- Configurable pagination (page number and count)\n- HTML-to-text conversion for clean content reading\n- Clean error handling and validation\n\n## Installation\n\n### Installing via Smithery\n\nTo install mcp-bookstack for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@yellowgg2/mcp-bookstack):\n\n```bash\nnpx -y @smithery/cli install @yellowgg2/mcp-bookstack --client claude\n```\n\n### Installing Manually\n1. Clone the repository:\n\n```bash\ngit clone https://github.com/yellowgg2/mcp-bookstack.git\ncd mcp-bookstack\n```\n\n2. Install dependencies:\n\n```bash\nnpm install\n```\n\n3. Configure your environment:\n\nCreate a `.env` file with your BookStack API credentials or provide them in the MCP settings configuration file:\n\n```\nBOOKSTACK_API_TOKEN=your_token\nBOOKSTACK_API_URL=your_bookstack_url\nBOOKSTACK_API_KEY=your_api_key\n```\n\n4. Build the server:\n\n```bash\nnpm run build\n```\n\n5. Add to your MCP settings configuration file (location depends on your system):\n\nFor VSCode Claude extension:\n\n```json\n{\n  \"mcpServers\": {\n    \"bookstack\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/mcp-bookstack/build/app.js\"],\n      \"env\": {\n        \"BOOKSTACK_API_URL\": \"your_bookstack_url\",\n        \"BOOKSTACK_API_TOKEN\": \"your_token\",\n        \"BOOKSTACK_API_KEY\": \"your_api_key\"\n      }\n    }\n  }\n}\n```\n\n## Usage\n\nThe server provides a tool called `search_pages` that can be used to search pages from BookStack.\n\n### Tool: search_pages\n\nParameters:\n\n- `query` (string): Query to search for pages\n  - Default: \"\" (empty string)\n- `page` (number): Page number to return\n  - Range: 1-10\n  - Default: 1\n- `count` (number): Number of pages to return\n  - Range: 1-30\n  - Default: 10\n\nExample usage:\n\n```typescript\nuse_mcp_tool with:\nserver_name: \"bookstack\"\ntool_name: \"search_pages\"\narguments: {\n  \"query\": \"knowledge base\",\n  \"page\": 1,\n  \"count\": 5\n}\n```\n\nSample output:\n\n```\n# Page Title\n\nPage content in plain text format...\n\nSource: https://your-bookstack-url/page-url\n```\n\n## Integrating with Claude\n\nTo use this MCP server with Claude, you'll need to:\n\n1. Have the Claude desktop app or VSCode Claude extension installed\n2. Configure the MCP server in your settings\n3. Use Claude's natural language interface to interact with BookStack\n\n### Configuration\n\nFor the Claude desktop app, VSCode Claude extension, and Cursor, add the server configuration to:\n\n```json\n// ~/Library/Application Support/Claude/claude_desktop_config.json (macOS)\n// %APPDATA%\\Claude\\claude_desktop_config.json (Windows)\n{\n  \"mcpServers\": {\n    \"bookstack\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/mcp-bookstack/build/app.js\"],\n      \"env\": {\n        \"BOOKSTACK_API_URL\": \"your_bookstack_url\",\n        \"BOOKSTACK_API_TOKEN\": \"your_token\",\n        \"BOOKSTACK_API_KEY\": \"your_api_key\"\n      }\n    }\n  }\n}\n```\n\n### Example Interactions\n\nOnce configured, you can interact with Claude using natural language to search BookStack pages. Examples:\n\n- \"Search for documentation about API usage in our BookStack knowledge base\"\n- \"Find information about deployment in our internal docs\"\n- \"Look up security guidelines in BookStack\"\n\nClaude will automatically use the appropriate parameters to search for the pages you want.\n\n## Page Response Structure\n\nEach page response includes:\n\n- Title of the page\n- Full content of the page (converted from HTML to plain text)\n- Source URL to the original page\n\nThe HTML-to-text conversion handles:\n\n- HTML entity decoding\n- Line breaks and paragraph formatting\n- List items with bullet points\n- Removal of HTML tags\n- Whitespace normalization\n\n## Development\n\nThe server is built using:\n\n- TypeScript\n- Model Context Protocol SDK\n- Axios for API requests\n- Zod for data validation\n- dotenv for environment configuration\n\nTo modify the server:\n\n1. Make changes to `src/app.ts`\n2. Rebuild:\n\n```bash\nnpm run build\n```\n\n## Error Handling\n\nThe server includes robust error handling for:\n\n- API connection failures\n- Authentication issues\n- Invalid parameter values\n- Data parsing errors\n\nErrors are returned with appropriate error codes and descriptive messages.\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## License\n\nMIT License - feel free to use this in your own projects.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "bookstack",
        "pages",
        "reading",
        "bookstack search",
        "bookstack pages",
        "data bookstack"
      ],
      "category": "document-processing"
    },
    "yosider--cosense-mcp-server": {
      "owner": "yosider",
      "name": "cosense-mcp-server",
      "url": "https://github.com/yosider/cosense-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/yosider.webp",
      "description": "Access and interact with the Cosense knowledge sharing platform by retrieving, listing, and searching for pages, as well as inserting text into existing pages.",
      "stars": 8,
      "forks": 8,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-09-07T02:00:58Z",
      "readme_content": "# Cosense MCP Server\n\nA MCP server for [Cosense](https://cosen.se).\n\n## Tools\n\nThe following tools are available for interacting with Cosense pages:\n\n- `get_page`: Retrieves a page with the specified title\n- `list_pages`: Lists available pages in the resources\n- `search_pages`: Searches for pages containing the specified query string\n- `insert_lines`: Inserts text after a specified line in a page\n\n## MCP Client Configuration\n\nThe following environment variables are required:\n\n- `COSENSE_PROJECT_NAME`: Project name\n- `COSENSE_SID`: Session ID for authentication\n  - Required for writing to pages and reading private pages\n  - Handle with care as it contains sensitive information\n  - For more details, see [scrapboxlab/connect.sid](https://scrapbox.io/scrapboxlab/connect.sid)\n- `NODE_ENV`: Execution environment (`development` or `production`)\n  - Controls logging behavior\n  - In `development` mode, debug logs are displayed\n  - In `production` mode, debug logs are suppressed\n\n### Run from npm registry\n\n#### JSR registry configuration\n\nThis package depends on [@cosense/std](https://jsr.io/@cosense/std) and [@cosense/types](https://jsr.io/@cosense/types) which are hosted on JSR. Before using npx, you need to configure the JSR registry globally:\n\nFor Linux/macOS:\n\n```bash\necho \"@jsr:registry=https://npm.jsr.io\" >> ~/.npmrc\n```\n\nFor Windows (PowerShell):\n\n```powershell\necho \"@jsr:registry=https://npm.jsr.io\" >> $env:USERPROFILE\\.npmrc\n```\n\nOr if you prefer not to modify global settings, run from source instead (see the section below)\n\n#### Client json configuration\n\nAfter configuring JSR registry, configure your MCP client:\n\n```json\n{\n  \"mcpServers\": {\n    \"cosense-mcp-server\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@yosider/cosense-mcp-server\"],\n      \"env\": {\n        \"COSENSE_PROJECT_NAME\": \"your_project_name\",\n        \"COSENSE_SID\": \"your_sid\"\n      }\n    }\n  }\n}\n```\n\n### Run from source\n\n#### Clone and build\n\n```bash\ngit clone https://github.com/yosider/cosense-mcp-server.git\ncd cosense-mcp-server\nnpm install\nnpm run build\n```\n\n#### Client json configuration\n\n```json\n{\n  \"mcpServers\": {\n    \"cosense-mcp-server\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"/path/to/cosense-mcp-server\"],\n      \"env\": {\n        \"COSENSE_PROJECT_NAME\": \"your_project_name\",\n        \"COSENSE_SID\": \"your_sid\"\n      }\n    }\n  }\n}\n```\n\nFor development debugging, add `\"NODE_ENV\": \"development\"` to the `env` section. Note that setting environment variables in a `.env` file won't work due to execution timing - use the MCP client configuration instead.\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspect\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n\n## Acknowledgments\n\nThis project is forked from [funwarioisii/cosense-mcp-server](https://github.com/funwarioisii/cosense-mcp-server).\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "cosense",
        "pages",
        "processing",
        "cosense knowledge",
        "interact cosense",
        "cosense mcp"
      ],
      "category": "document-processing"
    },
    "yzfly--mcp-excel-server": {
      "owner": "yzfly",
      "name": "mcp-excel-server",
      "url": "https://github.com/yzfly/mcp-excel-server",
      "imageUrl": "/freedevtools/mcp/pfp/yzfly.webp",
      "description": "Manage and analyze Excel files, including reading, writing, and visualizing data. Perform statistical analysis and data quality assessments to enhance data manipulation and insights.",
      "stars": 72,
      "forks": 14,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-09-30T14:55:08Z",
      "readme_content": "# Excel MCP Server\n\nAn MCP server that provides comprehensive Excel file management and data analysis capabilities.\n\n## Features\n\n- **Excel File Operations**\n  - Read multiple Excel formats (XLSX, XLS, CSV, TSV, JSON)\n  - Write and update Excel files\n  - Get file information and sheet names\n\n- **Data Analysis**\n  - Summary statistics and descriptive analysis\n  - Data quality assessment\n  - Pivot tables\n  - Filtering and querying data\n\n- **Visualization**\n  - Generate charts and plots from Excel data\n  - Create data previews\n  - Export visualizations as images\n\n## Installation\n\n1. Create a new Python environment (recommended):\n\n```bash\n# Using uv (recommended)\nuv init excel-mcp-server\ncd excel-mcp-server\nuv venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n\n# Or using pip\npython -m venv .venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n```\n\n2. Install dependencies:\n\n```bash\n# Using uv\nuv pip install -e .\n```\n\n## Integration with Claude Desktop\n\n1. Install [Claude Desktop](https://claude.ai/download)\n2. Open Settings and go to the Developer tab\n3. Edit `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"mcp-excel-server\"\n      ],\n      \"env\": {\n        \"PYTHONPATH\": \"/path/to/your/python\"\n      }\n  }\n}\n```\n\n## Available Tools\n\n### File Reading\n- `read_excel`: Read Excel files\n- `get_excel_info`: Get file details\n- `get_sheet_names`: List worksheet names\n\n### Data Analysis\n- `analyze_excel`: Perform statistical analysis\n- `filter_excel`: Filter data by conditions\n- `pivot_table`: Create pivot tables\n- `data_summary`: Generate comprehensive data summary\n\n### Data Visualization\n- `export_chart`: Generate charts\n  - Supports line charts, bar charts, scatter plots, histograms\n\n### File Operations\n- `write_excel`: Write new Excel files\n- `update_excel`: Update existing Excel files\n\n## Available Resources\n\n- `excel://{file_path}`: Get file content\n- `excel://{file_path}/info`: Get file structure information\n- `excel://{file_path}/preview`: Generate data preview image\n\n## Prompt Templates\n\n- `analyze_excel_data`: Guided template for Excel data analysis\n- `create_chart`: Help create data visualizations\n- `data_cleaning`: Assist with data cleaning\n\n## Usage Examples\n\n- \"Analyze my sales_data.xlsx file\"\n- \"Create a bar chart for product_sales.csv\"\n- \"Filter employees over 30 in employees.xlsx\"\n- \"Generate a pivot table of department sales\"\n\n## Security Considerations\n\n- Read files only from specified paths\n- Limit file size\n- Prevent accidental file overwriting\n- Strictly control data transformation operations\n\n## Dependencies\n\n- pandas\n- numpy\n- matplotlib\n- seaborn\n\n## License\n\nMIT License",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "excel",
        "yzfly",
        "processing",
        "excel server",
        "processing yzfly",
        "mcp excel"
      ],
      "category": "document-processing"
    },
    "zanetworker--mcp-docling": {
      "owner": "zanetworker",
      "name": "mcp-docling",
      "url": "https://github.com/zanetworker/mcp-docling",
      "imageUrl": "/freedevtools/mcp/pfp/zanetworker.webp",
      "description": "Convert documents to markdown, extract tables, and process multiple files efficiently for enhanced document processing capabilities.",
      "stars": 18,
      "forks": 8,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-25T02:42:51Z",
      "readme_content": "# MCP Docling Server\n\nAn MCP server that provides document processing capabilities using the Docling library.\n\n## Installation\n\nYou can install the package using pip:\n\n```bash\npip install -e .\n```\n\n## Usage\n\nStart the server using either stdio (default) or SSE transport:\n\n```bash\n# Using stdio transport (default)\nmcp-server-lls\n\n# Using SSE transport on custom port\nmcp-server-lls --transport sse --port 8000\n```\n\nIf you're using uv, you can run the server directly without installing:\n\n```bash\n# Using stdio transport (default)\nuv run mcp-server-lls\n\n# Using SSE transport on custom port\nuv run mcp-server-lls --transport sse --port 8000\n```\n\n## Available Tools\n\nThe server exposes the following tools:\n\n1. **convert_document**: Convert a document from a URL or local path to markdown format\n   - `source`: URL or local file path to the document (required)\n   - `enable_ocr`: Whether to enable OCR for scanned documents (optional, default: false)\n   - `ocr_language`: List of language codes for OCR, e.g. [\"en\", \"fr\"] (optional)\n\n2. **convert_document_with_images**: Convert a document and extract embedded images\n   - `source`: URL or local file path to the document (required)\n   - `enable_ocr`: Whether to enable OCR for scanned documents (optional, default: false)\n   - `ocr_language`: List of language codes for OCR (optional)\n\n3. **extract_tables**: Extract tables from a document as structured data\n   - `source`: URL or local file path to the document (required)\n\n4. **convert_batch**: Process multiple documents in batch mode\n   - `sources`: List of URLs or file paths to documents (required)\n   - `enable_ocr`: Whether to enable OCR for scanned documents (optional, default: false)\n   - `ocr_language`: List of language codes for OCR (optional)\n\n5. **qna_from_document**: Create a Q&A document from a URL or local path to YAML format\n   - `source`: URL or local file path to the document (required)\n   - `no_of_qnas`: Number of expected Q&As (optional, default: 5)\n   - **Note**: This tool requires IBM Watson X credentials to be set as environment variables:\n     - `WATSONX_PROJECT_ID`: Your Watson X project ID\n     - `WATSONX_APIKEY`: Your IBM Cloud API key\n     - `WATSONX_URL`: The Watson X API URL (default: https://us-south.ml.cloud.ibm.com)\n\n6. **get_system_info**: Get information about system configuration and acceleration status\n\n## Example with Llama Stack\n\n\nhttps://github.com/user-attachments/assets/8ad34e50-cbf7-4ec8-aedd-71c42a5de0a1\n\n\nYou can use this server with [Llama Stack](https://github.com/meta-llama/llama-stack) to provide document processing capabilities to your LLM applications. Make sure you have a running Llama Stack server, then configure your `INFERENCE_MODEL`\n\n```python\nfrom llama_stack_client.lib.agents.agent import Agent\nfrom llama_stack_client.lib.agents.event_logger import EventLogger\nfrom llama_stack_client.types.agent_create_params import AgentConfig\nfrom llama_stack_client.types.shared_params.url import URL\nfrom llama_stack_client import LlamaStackClient\nimport os\n\n# Set your model ID\nmodel_id = os.environ[\"INFERENCE_MODEL\"]\nclient = LlamaStackClient(\n    base_url=f\"http://localhost:{os.environ.get('LLAMA_STACK_PORT', '8080')}\"\n)\n\n# Register MCP tools\nclient.toolgroups.register(\n    toolgroup_id=\"mcp::docling\",\n    provider_id=\"model-context-protocol\",\n    mcp_endpoint=URL(uri=\"http://0.0.0.0:8000/sse\"))\n\n# Define an agent with MCP toolgroup\nagent_config = AgentConfig(\n    model=model_id,\n    instructions=\"\"\"You are a helpful assistant with access to tools to manipulate documents.\nAlways use the appropriate tool when asked to process documents.\"\"\",\n    toolgroups=[\"mcp::docling\"],\n    tool_choice=\"auto\",\n    max_tool_calls=3,\n)\n\n# Create the agent\nagent = Agent(client, agent_config)\n\n# Create a session\nsession_id = agent.create_session(\"test-session\")\n\ndef _summary_and_qna(source: str):\n    # Define the prompt\n    run_turn(f\"Please convert the document at {source} to markdown and summarize its content.\")\n    run_turn(f\"Please generate a Q&A document with 3 items for source at {source} and display it in YAML format.\")\n\ndef _run_turn(prompt):\n    # Create a turn\n    response = agent.create_turn(\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": prompt,\n            }\n        ],\n        session_id=session_id,\n    )\n\n    # Log the response\n    for log in EventLogger().log(response):\n        log.print()\n\n_summary_and_qna('https://arxiv.org/pdf/2004.07606')\n```\n\n## Caching\n\nThe server caches processed documents in `~/.cache/mcp-docling/` to improve performance for repeated requests.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "docling",
        "document",
        "markdown",
        "document processing",
        "docling convert",
        "convert documents"
      ],
      "category": "document-processing"
    },
    "zcaceres--markdownify-mcp": {
      "owner": "zcaceres",
      "name": "markdownify-mcp",
      "url": "https://github.com/zcaceres/markdownify-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/zcaceres.webp",
      "description": "Converts various file types and web content into Markdown format, supporting multiple input types such as PDFs, images, and audio files.",
      "stars": 2168,
      "forks": 178,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T16:23:43Z",
      "readme_content": "# Markdownify MCP Server\n\n> Help! I need someone with a Windows computer to help me add support for Markdownify-MCP on Windows. PRs exist but I cannot test them. Post [here](https://github.com/zcaceres/markdownify-mcp/issues/18) if interested.\n\n\n\nMarkdownify is a Model Context Protocol (MCP) server that converts various file types and web content to Markdown format. It provides a set of tools to transform PDFs, images, audio files, web pages, and more into easily readable and shareable Markdown text.\n\n<a href=\"https://glama.ai/mcp/servers/bn5q4b0ett\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/bn5q4b0ett/badge\" alt=\"Markdownify Server MCP server\" /></a>\n\n## Features\n\n- Convert multiple file types to Markdown:\n  - PDF\n  - Images\n  - Audio (with transcription)\n  - DOCX\n  - XLSX\n  - PPTX\n- Convert web content to Markdown:\n  - YouTube video transcripts\n  - Bing search results\n  - General web pages\n- Retrieve existing Markdown files\n\n## Getting Started\n\n1. Clone this repository\n2. Install dependencies:\n   ```\n   pnpm install\n   ```\n\nNote: this will also install `uv` and related Python depdencies.\n\n3. Build the project:\n   ```\n   pnpm run build\n   ```\n4. Start the server:\n   ```\n   pnpm start\n   ```\n\n## Development\n\n- Use `pnpm run dev` to start the TypeScript compiler in watch mode\n- Modify `src/server.ts` to customize server behavior\n- Add or modify tools in `src/tools.ts`\n\n## Usage with Desktop App\n\nTo integrate this server with a desktop app, add the following to your app's server configuration:\n\n```js\n{\n  \"mcpServers\": {\n    \"markdownify\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"{ABSOLUTE PATH TO FILE HERE}/dist/index.js\"\n      ],\n      \"env\": {\n        // By default, the server will use the default install location of `uv`\n        \"UV_PATH\": \"/path/to/uv\"\n      }\n    }\n  }\n}\n```\n\n## Available Tools\n\n- `youtube-to-markdown`: Convert YouTube videos to Markdown\n- `pdf-to-markdown`: Convert PDF files to Markdown\n- `bing-search-to-markdown`: Convert Bing search results to Markdown\n- `webpage-to-markdown`: Convert web pages to Markdown\n- `image-to-markdown`: Convert images to Markdown with metadata\n- `audio-to-markdown`: Convert audio files to Markdown with transcription\n- `docx-to-markdown`: Convert DOCX files to Markdown\n- `xlsx-to-markdown`: Convert XLSX files to Markdown\n- `pptx-to-markdown`: Convert PPTX files to Markdown\n- `get-markdown-file`: Retrieve an existing Markdown file. File extension must end with: *.md, *.markdown.\n  \n  OPTIONAL: set `MD_SHARE_DIR` env var to restrict the directory from which files can be retrieved, e.g. `MD_SHARE_DIR=[SOME_PATH] pnpm run start` \n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "markdownify",
        "markdown",
        "mcp",
        "markdownify mcp",
        "zcaceres markdownify",
        "content markdown"
      ],
      "category": "document-processing"
    },
    "zcardb--front-code-sum": {
      "owner": "zcardb",
      "name": "front-code-sum",
      "url": "https://github.com/zcardb/front-code-sum",
      "imageUrl": "/freedevtools/mcp/pfp/zcardb.webp",
      "description": "Summarize front-end learning materials and showcase small demo projects. Provides concise notes and practical examples for better understanding of front-end technologies.",
      "stars": 2,
      "forks": 0,
      "license": "No License",
      "language": "HTML",
      "updated_at": "2021-04-28T03:06:08Z",
      "readme_content": "# front-code-sum\n自己学习前端的一些小总结和小demo\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "zcardb",
        "document",
        "code",
        "processing zcardb",
        "zcardb code",
        "document processing"
      ],
      "category": "document-processing"
    },
    "zentala--zntl-mcp-server": {
      "owner": "zentala",
      "name": "zntl-mcp-server",
      "url": "https://github.com/zentala/zntl-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/null.webp",
      "description": "Provides AI-powered transcription and analysis functionalities via a standardized Model Context Protocol interface, enabling efficient data searching, summarizing, and retrieval. Integrates with the Transcripter project to facilitate interaction with transcription and analysis data.",
      "stars": 0,
      "forks": 0,
      "license": "Unknown",
      "language": "Unknown",
      "updated_at": "",
      "readme_content": "",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "transcripter",
        "transcription",
        "zntl",
        "transcription analysis",
        "transcripter project",
        "integrates transcripter"
      ],
      "category": "document-processing"
    },
    "zereight--confluence-mcp": {
      "owner": "zereight",
      "name": "confluence-mcp",
      "url": "https://github.com/zereight/confluence-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/zereight.webp",
      "description": "Integrate with the Confluence API to access and manipulate Confluence data. Execute CQL queries and retrieve page content seamlessly.",
      "stars": 21,
      "forks": 5,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-10-02T00:53:32Z",
      "readme_content": "# Better Confluence Communication Server\n\n## Overview\n\nThis server implements the Model Context Protocol (MCP) for Confluence integration.\n**This version addresses and fixes bugs found in the existing Confluence server, providing a more stable and reliable experience.**\nIt provides functionalities to execute CQL queries and retrieve page content from Confluence.\n\nThis server follows the MCP client-server architecture:\n\n- Acts as an MCP server providing Confluence functionalities\n- Connects to Confluence as a data source\n- Communicates with MCP clients through a standardized protocol\n\n# How to use\n\n[![smithery badge](https://smithery.ai/badge/@zereight/confluence-mcp)](https://smithery.ai/server/@zereight/confluence-mcp)\n\n<a href=\"https://glama.ai/mcp/servers/p7fnmpaukj\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/p7fnmpaukj/badge\" alt=\"confluence-mcp MCP server\" /></a>\n\n## Using with Claude App, Cline, Roo Code\n\nWhen using with the Claude App, you need to set up your API key and URLs directly.\n\n```json\n{\n  \"mcpServers\": {\n    \"Confluence communication server\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@zereight/mcp-confluence\"],\n      \"env\": {\n        \"CONFLUENCE_URL\": \"https://XXXXXXXX.atlassian.net\",\n        \"JIRA_URL\": \"https://XXXXXXXX.atlassian.net\",\n        \"CONFLUENCE_API_MAIL\": \"Your email\",\n        \"CONFLUENCE_API_KEY\": \"KEY_FROM: https://id.atlassian.com/manage-profile/security/api-tokens\",\n        \"CONFLUENCE_IS_CLOUD\": \"true\" // Set to \"false\" for Server/Data Center\n      }\n    }\n  }\n}\n```\n\n## Using with Cursor\n\n### Installing via Smithery\n\nTo install Confluence communication server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@zereight/confluence-mcp):\n\n```bash\nnpx -y @smithery/cli install @zereight/confluence-mcp --client claude\n```\n\nWhen using with Cursor, you can set up environment variables and run the server as follows:\n\n```bash\nenv CONFLUENCE_API_MAIL=your@email.com CONFLUENCE_API_KEY=your-key CONFLUENCE_URL=your-confluence-url JIRA_URL=your-jira-url npx -y @zereight/mcp-confluence\n```\n\n- `CONFLUENCE_API_MAIL`: Your email address for the Confluence API.\n- `CONFLUENCE_API_KEY`: Your Confluence API key.\n- `CONFLUENCE_URL`: Your Confluence URL.\n- `JIRA_URL`: Your JIRA URL.\n- `CONFLUENCE_IS_CLOUD`: Determines Confluence version (Cloud or Server)\n  - Default: true (Cloud version)\n  - Set to 'false' explicitly for Server/Data Center version\n  - Affects API endpoint paths:\n    - Cloud: `/wiki/rest/api`\n    - Server: `/rest/api`\n\n### Confluence Tools\n\n- **execute_cql_search**: Executes a CQL query on Confluence to search pages.\n\n  - Description: Executes a CQL query on the Confluence instance to search for pages.\n  - Input Schema:\n    ```json\n    {\n      \"type\": \"object\",\n      \"properties\": {\n        \"cql\": {\n          \"type\": \"string\",\n          \"description\": \"CQL query string\"\n        },\n        \"limit\": {\n          \"type\": \"integer\",\n          \"description\": \"Number of results to return\",\n          \"default\": 10\n        }\n      },\n      \"required\": [\"cql\"]\n    }\n    ```\n\n- **get_page_content**: Retrieves the content of a specific Confluence page.\n\n  - Description: Gets the content of a Confluence page using the page ID.\n  - Input Schema:\n    ```json\n    {\n      \"type\": \"object\",\n      \"properties\": {\n        \"pageId\": {\n          \"type\": \"string\",\n          \"description\": \"Confluence Page ID\"\n        }\n      },\n      \"required\": [\"pageId\"]\n    }\n    ```\n\n- **create_page**: Creates a new Confluence page.\n\n  - Description: Creates a new page in the specified Confluence space.\n  - Input Schema:\n    ```json\n    {\n      \"type\": \"object\",\n      \"properties\": {\n        \"spaceKey\": {\n          \"type\": \"string\",\n          \"description\": \"Space key where the page will be created\"\n        },\n        \"title\": {\n          \"type\": \"string\",\n          \"description\": \"Page title\"\n        },\n        \"content\": {\n          \"type\": \"string\",\n          \"description\": \"Page content in storage format\"\n        },\n        \"parentId\": {\n          \"type\": \"string\",\n          \"description\": \"Parent page ID (optional)\"\n        }\n      },\n      \"required\": [\"spaceKey\", \"title\", \"content\"]\n    }\n    ```\n\n- **update_page**: Updates an existing Confluence page.\n  - Description: Updates the content of an existing Confluence page.\n  - Input Schema:\n    ```json\n    {\n      \"type\": \"object\",\n      \"properties\": {\n        \"pageId\": {\n          \"type\": \"string\",\n          \"description\": \"ID of the page to update\"\n        },\n        \"content\": {\n          \"type\": \"string\",\n          \"description\": \"New page content in storage format\"\n        },\n        \"title\": {\n          \"type\": \"string\",\n          \"description\": \"New page title (optional)\"\n        }\n      },\n      \"required\": [\"pageId\", \"content\"]\n    }\n    ```\n\n### Jira Tools\n\n- **execute_jql_search**: Executes a JQL query on Jira to search issues.\n\n  - Description: Executes a JQL query on the Jira instance to search for issues.\n  - Input Schema:\n    ```json\n    {\n      \"type\": \"object\",\n      \"properties\": {\n        \"jql\": {\n          \"type\": \"string\",\n          \"description\": \"JQL query string\"\n        },\n        \"limit\": {\n          \"type\": \"integer\",\n          \"description\": \"Number of results to return\",\n          \"default\": 10\n        }\n      },\n      \"required\": [\"jql\"]\n    }\n    ```\n\n- **create_jira_issue**: Creates a new Jira issue.\n\n  - Description: Creates a new issue in the specified Jira project.\n  - Input Schema:\n    ```json\n    {\n      \"type\": \"object\",\n      \"properties\": {\n        \"project\": {\n          \"type\": \"string\",\n          \"description\": \"Project key\"\n        },\n        \"summary\": {\n          \"type\": \"string\",\n          \"description\": \"Issue summary\"\n        },\n        \"description\": {\n          \"type\": \"string\",\n          \"description\": \"Issue description\"\n        },\n        \"issuetype\": {\n          \"type\": \"string\",\n          \"description\": \"Issue type name\"\n        },\n        \"assignee\": {\n          \"type\": \"string\",\n          \"description\": \"Assignee account ID\"\n        },\n        \"priority\": {\n          \"type\": \"string\",\n          \"description\": \"Priority ID\"\n        }\n      },\n      \"required\": [\"project\", \"summary\", \"issuetype\"]\n    }\n    ```\n\n- **update_jira_issue**: Updates an existing Jira issue.\n\n  - Description: Updates fields of an existing Jira issue.\n  - Input Schema:\n    ```json\n    {\n      \"type\": \"object\",\n      \"properties\": {\n        \"issueKey\": {\n          \"type\": \"string\",\n          \"description\": \"Issue key (e.g., PROJ-123)\"\n        },\n        \"summary\": {\n          \"type\": \"string\",\n          \"description\": \"New issue summary\"\n        },\n        \"description\": {\n          \"type\": \"string\",\n          \"description\": \"New issue description\"\n        },\n        \"assignee\": {\n          \"type\": \"string\",\n          \"description\": \"New assignee account ID\"\n        },\n        \"priority\": {\n          \"type\": \"string\",\n          \"description\": \"New priority ID\"\n        }\n      },\n      \"required\": [\"issueKey\"]\n    }\n    ```\n\n- **transition_jira_issue**: Changes the status of a Jira issue.\n\n  - Description: Changes the status of a Jira issue using transition ID.\n  - Input Schema:\n    ```json\n    {\n      \"type\": \"object\",\n      \"properties\": {\n        \"issueKey\": {\n          \"type\": \"string\",\n          \"description\": \"Issue key (e.g. PROJ-123)\"\n        },\n        \"transitionId\": {\n          \"type\": \"string\",\n          \"description\": \"Transition ID to change the issue status\"\n        }\n      },\n      \"required\": [\"issueKey\", \"transitionId\"]\n    }\n    ```\n\n- **get_board_sprints**: Get all sprints from a Jira board.\n\n  - Description: Retrieves all sprints from a specified Jira board.\n  - Input Schema:\n    ```json\n    {\n      \"type\": \"object\",\n      \"properties\": {\n        \"boardId\": {\n          \"type\": \"string\",\n          \"description\": \"Jira board ID\"\n        },\n        \"state\": {\n          \"type\": \"string\",\n          \"description\": \"Filter sprints by state (active, future, closed)\",\n          \"enum\": [\"active\", \"future\", \"closed\"]\n        }\n      },\n      \"required\": [\"boardId\"]\n    }\n    ```\n\n- **get_sprint_issues**: Get all issues from a sprint.\n\n  - Description: Retrieves all issues from a specified sprint.\n  - Input Schema:\n    ```json\n    {\n      \"type\": \"object\",\n      \"properties\": {\n        \"sprintId\": {\n          \"type\": \"string\",\n          \"description\": \"Sprint ID\"\n        },\n        \"fields\": {\n          \"type\": \"array\",\n          \"items\": {\n            \"type\": \"string\"\n          },\n          \"description\": \"List of fields to return for each issue\"\n        }\n      },\n      \"required\": [\"sprintId\"]\n    }\n    ```\n\n- **get_current_sprint**: Get current active sprint from a board with its issues.\n\n  - Description: Retrieves the current active sprint and its issues from a specified board.\n  - Input Schema:\n    ```json\n    {\n      \"type\": \"object\",\n      \"properties\": {\n        \"boardId\": {\n          \"type\": \"string\",\n          \"description\": \"Jira board ID\"\n        },\n        \"includeIssues\": {\n          \"type\": \"boolean\",\n          \"description\": \"Whether to include sprint issues in the response\",\n          \"default\": true\n        }\n      },\n      \"required\": [\"boardId\"]\n    }\n    ```\n\n- **get_epic_issues**: Get all issues belonging to an epic.\n\n  - Description: Retrieves all issues that belong to a specified epic.\n  - Input Schema:\n    ```json\n    {\n      \"type\": \"object\",\n      \"properties\": {\n        \"epicKey\": {\n          \"type\": \"string\",\n          \"description\": \"Epic issue key (e.g. CONNECT-1234)\"\n        },\n        \"fields\": {\n          \"type\": \"array\",\n          \"items\": {\n            \"type\": \"string\"\n          },\n          \"description\": \"List of fields to return for each issue\"\n        }\n      },\n      \"required\": [\"epicKey\"]\n    }\n    ```\n\n- **get_user_issues**: Get all issues assigned to or reported by a specific user in a board.\n\n  - Description: Retrieves all issues associated with a specific user in a board.\n  - Input Schema:\n    ```json\n    {\n      \"type\": \"object\",\n      \"properties\": {\n        \"boardId\": {\n          \"type\": \"string\",\n          \"description\": \"Jira board ID\"\n        },\n        \"username\": {\n          \"type\": \"string\",\n          \"description\": \"Username to search issues for\"\n        },\n        \"type\": {\n          \"type\": \"string\",\n          \"description\": \"Type of user association with issues\",\n          \"enum\": [\"assignee\", \"reporter\"],\n          \"default\": \"assignee\"\n        },\n        \"status\": {\n          \"type\": \"string\",\n          \"description\": \"Filter by issue status\",\n          \"enum\": [\"open\", \"in_progress\", \"done\", \"all\"],\n          \"default\": \"all\"\n        }\n      },\n      \"required\": [\"boardId\", \"username\"]\n    }\n    ```\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "confluence",
        "cql",
        "zereight",
        "confluence data",
        "confluence api",
        "zereight confluence"
      ],
      "category": "document-processing"
    },
    "zeyangxu--local-rag": {
      "owner": "zeyangxu",
      "name": "local-rag",
      "url": "https://github.com/zeyangxu/local-rag",
      "imageUrl": "/freedevtools/mcp/pfp/zeyangxu.webp",
      "description": "Access and query information from large PDF files using a powerful retrieval-augmented generation (RAG) system that integrates with Claude. Utilize advanced document processing and vector storage to enhance data retrieval capabilities.",
      "stars": 1,
      "forks": 0,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-08-02T02:13:20Z",
      "readme_content": "# PDF RAG System with MCP Server\n\nThis project implements a Retrieval-Augmented Generation (RAG) system with an MCP server that allows Claude to access and query information from large PDF files. It uses Chroma as the vector database.\n\n## Prerequisites\n\n- Node.js (v14 or higher)\n- npm (v6 or higher)\n- Python 3.9+ with ChromaDB installed\n- OpenAI API key (for embeddings)\n\n## Setup\n\n1. Clone the repository\n2. Install dependencies:\n   ```\n   npm install\n   ```\n3. Install Python dependencies:\n   ```\n   python3 -m pip install chromadb\n   ```\n4. Configure environment variables by editing the `.env` file:\n   ```\n   OPENAI_API_KEY=your_openai_api_key\n   PORT=3000  # Port for the MCP server\n   ```\n\n## Usage\n\n### 1. Add PDF Files\n\nPlace your PDF files in the `data/pdfs` directory:\n\n```\ndata/\n  pdfs/\n    your-file1.pdf\n    your-file2.pdf\n```\n\n### 2. Start the Chroma Server\n\nStart the Chroma database server:\n\n```\n./start-chroma.sh\n```\n\nOr manually:\n\n```\npython3 -m chromadb.cli.cli run --path ./data/chroma_db\n```\n\nThis will start a Chroma server at http://localhost:8000.\n\n### 3. Ingest PDFs\n\nIn a new terminal, process the PDFs and create the vector store:\n\n```\nnpm run ingest\n```\n\nThis will:\n- Extract text from the PDFs\n- Split the text into chunks\n- Create embeddings\n- Store the vectors in a Chroma database\n\n### 4. Start the MCP Server\n\nIn another terminal, start the server:\n\n```\nnpm run dev\n```\n\nThe MCP server will be available at: http://localhost:3000/api/mcp/query\n\n### 5. Query the MCP Server\n\nYou can query the system using Claude or a REST client:\n\n```\nPOST http://localhost:3000/api/mcp/query\nContent-Type: application/json\n\n{\n  \"query\": \"What does the document say about...\",\n  \"topK\": 5  # Optional, number of results to return\n}\n```\n\n## Claude Integration\n\nTo use this with Claude via MCP:\n\n1. Configure Claude to use the MCP endpoint\n2. Ensure Claude has access to this server\n3. Now Claude can query the content of your PDFs through the RAG system\n\n## Project Structure\n\n- `src/`\n  - `index.ts` - Main server file\n  - `ingest.ts` - Script for processing PDFs\n  - `services/`\n    - `documentProcessor.ts` - PDF processing and Chroma database operations\n    - `mcpService.ts` - MCP service for Claude\n  - `routes/`\n    - `mcpRoutes.ts` - API routes for MCP\n  - `utils/`\n    - `env.ts` - Environment variable utilities\n- `data/`\n  - `pdfs/` - Directory for PDF files\n  - `chroma_db/` - Directory for Chroma vector database\n- `start-chroma.sh` - Script to start the Chroma server\n\n## License\n\nMIT ",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "retrieval",
        "rag",
        "document",
        "document processing",
        "data retrieval",
        "retrieval capabilities"
      ],
      "category": "document-processing"
    },
    "zhiwei5576--excel-mcp-server": {
      "owner": "zhiwei5576",
      "name": "excel-mcp-server",
      "url": "https://github.com/zhiwei5576/excel-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/zhiwei5576.webp",
      "description": "Read, write, and analyze Excel files while seamlessly managing data through various functionalities, including accessing multiple worksheets and exporting structure information.",
      "stars": 41,
      "forks": 7,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-06T02:32:45Z",
      "readme_content": "# Excel MCP Server\n[![npm](https://img.shields.io/npm/v/@zhiweixu/excel-mcp-server)](https://www.npmjs.com/package/@zhiweixu/excel-mcp-server)\n[![smithery badge](https://smithery.ai/badge/@zhiwei5576/excel-mcp-server)](https://smithery.ai/server/@zhiwei5576/excel-mcp-server)\n[简体中文](./README_CN.md) | English\n\nExcel file processing server based on Model Context Protocol (MCP), providing functionalities for reading, writing, and analyzing Excel files.\n\n## Features\n\n- 📖 Read Excel Files\n\n  - Get worksheet list\n  - Read specific worksheet data\n  - Read all worksheets data\n\n- ✍️ Write Excel Files\n\n  - Create new Excel files\n  - Write to specific worksheet\n  - Support multiple worksheets\n\n- 🔍 Analyze Excel Structure\n\n  - Analyze worksheet structure\n  - Export structure to new file\n\n- 💾 Cache Management\n\n  - Automatic file content caching\n  - Scheduled cache cleanup\n  - Manual cache clearing\n\n- 📝 Log Management\n  - Automatic operation logging\n  - Periodic log cleanup\n\n## Installation\n\n### Installing via Smithery\n\nTo install excel-mcp-server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@zhiwei5576/excel-mcp-server):\n\n```bash\nnpx -y @smithery/cli install @zhiwei5576/excel-mcp-server --client claude\n```\n\n### Installing Manually\nInstalling via NPM\nexcel-mcp-server can be automatically installed by adding the following configuration to the MCP servers configuration.\n\nWindows Platform:\n\n```bash\n{\n  \"mcpServers\": {\n    \"excel\": {\n        \"command\": \"cmd\",\n        \"args\": [\"/c\", \"npx\", \"--yes\", \"@zhiweixu/excel-mcp-server\"],\n        \"env\": {\n            \"LOG_PATH\": \"[set an accessible absolute path]\",\n            \"CACHE_MAX_AGE\": \"1\",\n            \"CACHE_CLEANUP_INTERVAL\": \"4\",\n            \"LOG_RETENTION_DAYS\": \"7\",\n            \"LOG_CLEANUP_INTERVAL\": \"24\"\n        }\n    }\n}\n```\n\nOther Platforms:\n\n```bash\n{\n  \"mcpServers\": {\n    \"excel\": {\n        \"command\": \"npx\",\n        \"args\": [\"--yes\", \"@zhiweixu/excel-mcp-server\"],\n        \"env\": {\n            \"LOG_PATH\": \"[set an accessible absolute path]\",\n            \"CACHE_MAX_AGE\": \"1\",\n            \"CACHE_CLEANUP_INTERVAL\": \"4\",\n            \"LOG_RETENTION_DAYS\": \"7\",\n            \"LOG_CLEANUP_INTERVAL\": \"24\"\n        }\n    }\n}\n```\nNote: LOG_PATH is optional. If not set, logs will be stored in the 'logs' folder under the application root directory.other arguments are optional.\n\n## API Tools\n\n### Structure Tools\n\n1. analyzeExcelStructure\n   - Function: Get Excel file structure including sheet list and column headers in JSON format\n   - Parameters:\n     - fileAbsolutePath: Absolute path of the Excel file\n     - headerRows: Number of header rows (default: 1)\n\n2. exportExcelStructure\n   - Function: Export Excel file structure (sheets and headers) to a new Excel template file\n   - Parameters:\n     - sourceFilePath: Source Excel file path\n     - targetFilePath: Target Excel file path\n     - headerRows: Number of header rows (default: 1)\n\n### Read Tools\n\n1. readSheetNames\n   - Function: Get all sheet names from the Excel file\n   - Parameters:\n     - fileAbsolutePath: Absolute path of the Excel file\n\n2. readDataBySheetName\n   - Function: Get data from a specific sheet in the Excel file\n   - Parameters:\n     - fileAbsolutePath: Absolute path of the Excel file\n     - sheetName: Name of the sheet to read\n     - headerRow: Header row number (default: 1)\n     - dataStartRow: Data start row number (default: 2)\n\n3. readSheetData\n   - Function: Get data from all sheets in the Excel file\n   - Parameters:\n     - fileAbsolutePath: Absolute path of the Excel file\n     - headerRow: Header row number (default: 1)\n     - dataStartRow: Data start row number (default: 2)\n\n### Write Tools\n\n1. writeDataBySheetName\n   - Function: Write data to a specific sheet in the Excel file (overwrites if sheet exists)\n   - Parameters:\n     - fileAbsolutePath: Absolute path of the Excel file\n     - sheetName: Name of the sheet to write\n     - data: Array of data to write\n\n2. writeSheetData\n   - Function: Create a new Excel file with provided data\n   - Parameters:\n     - fileAbsolutePath: Absolute path for the new Excel file\n     - data: Object containing multiple sheet data\n\n### Cache Tools\n\n1. clearFileCache\n   - Function: Clear cached data for the specified Excel file\n   - Parameters:\n     - fileAbsolutePath: Absolute path of the Excel file to clear from cache\n\n## Configuration\n\n### Environment Variables\n\n- `LOG_PATH`: Log files storage path\n  - Optional\n  - Default: 'logs' folder under application root directory\n\n- `CACHE_MAX_AGE`: Cache expiration time (hours)\n  - Optional\n  - Default: 1\n\n- `CACHE_CLEANUP_INTERVAL`: Cache cleanup interval (hours)\n  - Optional\n  - Default: 4\n\n- `LOG_RETENTION_DAYS`: Log retention days\n  - Optional\n  - Default: 7\n\n- `LOG_CLEANUP_INTERVAL`: Log cleanup interval (hours)\n  - Optional\n  - Default: 24\n\n### Default Configuration\n\n- Cache Configuration\n  - Cache expiration time: 1 hour\n  - Cache cleanup interval: 4 hours\n\n- Log Configuration\n  - Log retention days: 7 days\n  - Cleanup interval: 24 hours\n\n## Dependencies\n\n- @modelcontextprotocol/sdk: ^1.7.0\n- xlsx: ^0.18.5\n- typescript: ^5.8.2\n\n## Development Dependencies\n\n- @types/node: ^22.13.10\n- nodemon: ^3.1.9\n- ts-node: ^10.9.2\n\n## License\n\nThis project is licensed under the MIT License. This means you are free to:\n\n- Use the software for commercial or non-commercial purposes\n- Modify the source code\n- Distribute original or modified code\n  Requirements:\n\n- Retain the original copyright notice\n- No liability can be claimed against the authors for software use\n  For detailed license information,please see the [LICENSE](./LICENSE) file.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "excel",
        "worksheets",
        "exporting",
        "zhiwei5576 excel",
        "excel files",
        "document processing"
      ],
      "category": "document-processing"
    },
    "zhuangmanhong--PDFMathTranslate": {
      "owner": "zhuangmanhong",
      "name": "PDFMathTranslate",
      "url": "https://github.com/zhuangmanhong/PDFMathTranslate",
      "imageUrl": "/freedevtools/mcp/pfp/zhuangmanhong.webp",
      "description": "Translate PDF scientific papers while maintaining the integrity of formulas, charts, and annotations. Supports multiple languages and various translation services through a command-line interface, interactive GUI, or Docker deployment.",
      "stars": 0,
      "forks": 0,
      "license": "GNU Affero General Public License v3.0",
      "language": "",
      "updated_at": "2025-03-17T15:52:34Z",
      "readme_content": "<div align=\"center\">\n\nEnglish | [简体中文](docs/README_zh-CN.md) | [繁體中文](docs/README_zh-TW.md) | [日本語](docs/README_ja-JP.md) | [한국어](docs/README_ko-KR.md)\n\n\n\n<h2 id=\"title\">PDFMathTranslate</h2>\n\n<p>\n  <!-- PyPI -->\n  <a href=\"https://pypi.org/project/pdf2zh/\">\n    <img src=\"https://img.shields.io/pypi/v/pdf2zh\"></a>\n  <a href=\"https://pepy.tech/projects/pdf2zh\">\n    <img src=\"https://static.pepy.tech/badge/pdf2zh\"></a>\n  <a href=\"https://hub.docker.com/repository/docker/byaidu/pdf2zh\">\n    <img src=\"https://img.shields.io/docker/pulls/byaidu/pdf2zh\"></a>\n  <a href=\"https://gitcode.com/Byaidu/PDFMathTranslate/overview\">\n    <img src=\"https://gitcode.com/Byaidu/PDFMathTranslate/star/badge.svg\"></a>\n  <a href=\"https://huggingface.co/spaces/reycn/PDFMathTranslate-Docker\">\n    <img src=\"https://img.shields.io/badge/%F0%9F%A4%97-Online%20Demo-FF9E0D\"></a>\n  <a href=\"https://www.modelscope.cn/studios/AI-ModelScope/PDFMathTranslate\">\n    <img src=\"https://img.shields.io/badge/ModelScope-Demo-blue\"></a>\n  <a href=\"https://github.com/Byaidu/PDFMathTranslate/pulls\">\n    <img src=\"https://img.shields.io/badge/contributions-welcome-green\"></a>\n  <a href=\"https://t.me/+Z9_SgnxmsmA5NzBl\">\n    <img src=\"https://img.shields.io/badge/Telegram-2CA5E0?style=flat-squeare&logo=telegram&logoColor=white\"></a>\n  <!-- License -->\n  <a href=\"./LICENSE\">\n    <img src=\"https://img.shields.io/github/license/Byaidu/PDFMathTranslate\"></a>\n</p>\n\n<a href=\"https://trendshift.io/repositories/12424\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/12424\" alt=\"Byaidu%2FPDFMathTranslate | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n\n</div>\n\nPDF scientific paper translation and bilingual comparison.\n\n- 📊 Preserve formulas, charts, table of contents, and annotations _([preview](#preview))_.\n- 🌐 Support [multiple languages](#language), and diverse [translation services](#services).\n- 🤖 Provides [commandline tool](#usage), [interactive user interface](#gui), and [Docker](#docker)\n\nFeel free to provide feedback in [GitHub Issues](https://github.com/Byaidu/PDFMathTranslate/issues) or [Telegram Group](https://t.me/+Z9_SgnxmsmA5NzBl).\n\nFor details on how to contribute, please consult the [Contribution Guide](https://github.com/Byaidu/PDFMathTranslate/wiki/Contribution-Guide---%E8%B4%A1%E7%8C%AE%E6%8C%87%E5%8D%97).\n\n<h2 id=\"updates\">Updates</h2>\n\n- [Mar. 3, 2025] Experimental support for the new backend [BabelDOC](https://github.com/funstory-ai/BabelDOC) WebUI added as an experimental option (by [@awwaawwa](https://github.com/awwaawwa))\n- [Feb. 22 2025] Better release CI and well-packaged windows-amd64 exe (by [@awwaawwa](https://github.com/awwaawwa))\n- [Dec. 24 2024] The translator now supports local models on [Xinference](https://github.com/xorbitsai/inference) _(by [@imClumsyPanda](https://github.com/imClumsyPanda))_\n- [Dec. 19 2024] Non-PDF/A documents are now supported using `-cp` _(by [@reycn](https://github.com/reycn))_\n- [Dec. 13 2024] Additional support for backend by _(by [@YadominJinta](https://github.com/YadominJinta))_\n- [Dec. 10 2024] The translator now supports OpenAI models on Azure _(by [@yidasanqian](https://github.com/yidasanqian))_\n\n<h2 id=\"preview\">Preview</h2>\n\n<div align=\"center\">\n\n</div>\n\n<h2 id=\"demo\">Online Service 🌟</h2>\n\nYou can try our application out using either of the following demos:\n\n- [Public free service](https://pdf2zh.com/) online without installation _(recommended)_.\n- [Immersive Translate - BabelDOC](https://app.immersivetranslate.com/babel-doc/) 1000 free pages per month. _(recommended)_\n- [Demo hosted on HuggingFace](https://huggingface.co/spaces/reycn/PDFMathTranslate-Docker)\n- [Demo hosted on ModelScope](https://www.modelscope.cn/studios/AI-ModelScope/PDFMathTranslate) without installation.\n\nNote that the computing resources of the demo are limited, so please avoid abusing them.\n\n<h2 id=\"install\">Installation and Usage</h2>\n\n### Methods\n\nFor different use cases, we provide distinct methods to use our program:\n\n<details open>\n  <summary>1. UV install</summary>\n\n1. Python installed (3.10 <= version <= 3.12)\n2. Install our package:\n\n   ```bash\n   pip install uv\n   uv tool install --python 3.12 pdf2zh\n   ```\n\n3. Execute translation, files generated in [current working directory](https://chatgpt.com/share/6745ed36-9acc-800e-8a90-59204bd13444):\n\n   ```bash\n   pdf2zh document.pdf\n   ```\n\n</details>\n\n<details>\n  <summary>2. Windows exe</summary>\n\n1. Download pdf2zh-version-win64.zip from [release page](https://github.com/Byaidu/PDFMathTranslate/releases)\n\n2. Unzip and double-click `pdf2zh.exe` to run.\n\n</details>\n\n<details>\n  <summary>3. Graphic user interface</summary>\n1. Python installed (3.10 <= version <= 3.12)\n2. Install our package:\n\n```bash\npip install pdf2zh\n```\n\n3. Start using in browser:\n\n   ```bash\n   pdf2zh -i\n   ```\n\n4. If your browswer has not been started automatically, goto\n\n   ```bash\n   http://localhost:7860/\n   ```\n\n   \n\nSee [documentation for GUI](./docs/README_GUI.md) for more details.\n\n</details>\n\n<details>\n  <summary>4. Docker</summary>\n\n1. Pull and run:\n\n   ```bash\n   docker pull byaidu/pdf2zh\n   docker run -d -p 7860:7860 byaidu/pdf2zh\n   ```\n\n2. Open in browser:\n\n   ```\n   http://localhost:7860/\n   ```\n\nFor docker deployment on cloud service:\n\n<div>\n<a href=\"https://www.heroku.com/deploy?template=https://github.com/Byaidu/PDFMathTranslate\">\n  <img src=\"https://www.herokucdn.com/deploy/button.svg\" alt=\"Deploy\" height=\"26\"></a>\n<a href=\"https://render.com/deploy\">\n  <img src=\"https://render.com/images/deploy-to-render-button.svg\" alt=\"Deploy to Koyeb\" height=\"26\"></a>\n<a href=\"https://zeabur.com/templates/5FQIGX?referralCode=reycn\">\n  <img src=\"https://zeabur.com/button.svg\" alt=\"Deploy on Zeabur\" height=\"26\"></a>\n<a href=\"https://app.koyeb.com/deploy?type=git&builder=buildpack&repository=github.com/Byaidu/PDFMathTranslate&branch=main&name=pdf-math-translate\">\n  <img src=\"https://www.koyeb.com/static/images/deploy/button.svg\" alt=\"Deploy to Koyeb\" height=\"26\"></a>\n</div>\n\n</details>\n\n<details>\n  <summary>5. Zotero Plugin</summary>\n\n\nSee [Zotero PDF2zh](https://github.com/guaguastandup/zotero-pdf2zh) for more details.\n\n</details>\n\n<details>\n  <summary>6. Commandline</summary>\n\n1. Python installed (3.10 <= version <= 3.12)\n2. Install our package:\n\n   ```bash\n   pip install pdf2zh\n   ```\n\n3. Execute translation, files generated in [current working directory](https://chatgpt.com/share/6745ed36-9acc-800e-8a90-59204bd13444):\n\n   ```bash\n   pdf2zh document.pdf\n   ```\n\n</details>\n\n> [!TIP]\n>\n> - If you're using Windows and cannot open the file after downloading, please install [vc_redist.x64.exe](https://aka.ms/vs/17/release/vc_redist.x64.exe) and try again.\n>\n> - If you cannot access Docker Hub, please try the image on [GitHub Container Registry](https://github.com/Byaidu/PDFMathTranslate/pkgs/container/pdfmathtranslate).\n> ```bash\n> docker pull ghcr.io/byaidu/pdfmathtranslate\n> docker run -d -p 7860:7860 ghcr.io/byaidu/pdfmathtranslate\n> ```\n\n### Unable to install?\n\nThe present program needs an AI model(`wybxc/DocLayout-YOLO-DocStructBench-onnx`) before working and some users are not able to download due to network issues. If you have a problem with downloading this model, we provide a workaround using the following environment variable:\n\n```shell\nset HF_ENDPOINT=https://hf-mirror.com\n```\n\nFor PowerShell user:\n\n```shell\n$env:HF_ENDPOINT = https://hf-mirror.com\n```\n\nIf the solution does not work to you / you encountered other issues, please refer to [frequently asked questions](https://github.com/Byaidu/PDFMathTranslate/wiki#-faq--%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98).\n\n<h2 id=\"usage\">Advanced Options</h2>\n\nExecute the translation command in the command line to generate the translated document `example-mono.pdf` and the bilingual document `example-dual.pdf` in the current working directory. Use Google as the default translation service. More support translation services can find [HERE](https://github.com/Byaidu/PDFMathTranslate/blob/main/docs/ADVANCED.md#services).\n\n\n\nIn the following table, we list all advanced options for reference:\n\n| Option         | Function                                                                                                      | Example                                        |\n| -------------- | ------------------------------------------------------------------------------------------------------------- | ---------------------------------------------- |\n| files          | Local files                                                                                                   | `pdf2zh ~/local.pdf`                           |\n| links          | Online files                                                                                                  | `pdf2zh http://arxiv.org/paper.pdf`            |\n| `-i`           | [Enter GUI](#gui)                                                                                             | `pdf2zh -i`                                    |\n| `-p`           | [Partial document translation](https://github.com/Byaidu/PDFMathTranslate/blob/main/docs/ADVANCED.md#partial) | `pdf2zh example.pdf -p 1`                      |\n| `-li`          | [Source language](https://github.com/Byaidu/PDFMathTranslate/blob/main/docs/ADVANCED.md#languages)            | `pdf2zh example.pdf -li en`                    |\n| `-lo`          | [Target language](https://github.com/Byaidu/PDFMathTranslate/blob/main/docs/ADVANCED.md#languages)            | `pdf2zh example.pdf -lo zh`                    |\n| `-s`           | [Translation service](https://github.com/Byaidu/PDFMathTranslate/blob/main/docs/ADVANCED.md#services)         | `pdf2zh example.pdf -s deepl`                  |\n| `-t`           | [Multi-threads](https://github.com/Byaidu/PDFMathTranslate/blob/main/docs/ADVANCED.md#threads)                | `pdf2zh example.pdf -t 1`                      |\n| `-o`           | Output dir                                                                                                    | `pdf2zh example.pdf -o output`                 |\n| `-f`, `-c`     | [Exceptions](https://github.com/Byaidu/PDFMathTranslate/blob/main/docs/ADVANCED.md#exceptions)                | `pdf2zh example.pdf -f \"(MS.*)\"`               |\n| `-cp`          | Compatibility Mode                                                                                            | `pdf2zh example.pdf --compatible`              |\n| `--skip-subset-fonts` | [Skip font subset](https://github.com/Byaidu/PDFMathTranslate/blob/main/docs/ADVANCED.md#font-subset)  | `pdf2zh example.pdf --skip-subset-fonts`       |\n| `--ignore-cache` | [Ignore translate cache](https://github.com/Byaidu/PDFMathTranslate/blob/main/docs/ADVANCED.md#cache)       | `pdf2zh example.pdf --ignore-cache`            |\n| `--share`      | Public link                                                                                                   | `pdf2zh -i --share`                            |\n| `--authorized` | [Authorization](https://github.com/Byaidu/PDFMathTranslate/blob/main/docs/ADVANCED.md#auth)                   | `pdf2zh -i --authorized users.txt [auth.html]` |\n| `--prompt`     | [Custom Prompt](https://github.com/Byaidu/PDFMathTranslate/blob/main/docs/ADVANCED.md#prompt)                 | `pdf2zh --prompt [prompt.txt]`                 |\n| `--onnx`       | [Use Custom DocLayout-YOLO ONNX model]                                                                        | `pdf2zh --onnx [onnx/model/path]`              |\n| `--serverport` | [Use Custom WebUI port]                                                                                       | `pdf2zh --serverport 7860`                     |\n| `--dir`        | [batch translate]                                                                                             | `pdf2zh --dir /path/to/translate/`             |\n| `--config`     | [configuration file](https://github.com/Byaidu/PDFMathTranslate/blob/main/docs/ADVANCED.md#cofig)             | `pdf2zh --config /path/to/config/config.json`  |\n| `--serverport` | [custom gradio server port]                                                                                   | `pdf2zh --serverport 7860`                     |\n|`--babeldoc`| Use Experimental backend [BabelDOC](https://funstory-ai.github.io/BabelDOC/) to translate |`pdf2zh --babeldoc` -s openai example.pdf|\n\nFor detailed explanations, please refer to our document about [Advanced Usage](./docs/ADVANCED.md) for a full list of each option.\n\n<h2 id=\"downstream\">Secondary Development (APIs)</h2>\n\nThe current pdf2zh API is temporarily deprecated. The API will be provided again after [pdf2zh 2.0](https://github.com/Byaidu/PDFMathTranslate/issues/586) is released. For users who need programmatic access, please use the `babeldoc.high_level.async_translate` function of [BabelDOC](https://github.com/funstory-ai/BabelDOC).\n\nThis API being temporarily deprecated means: the relevant code will not be removed for now, but no technical support will be provided, and no bug fixes will be made.\n<!-- For downstream applications, please refer to our document about [API Details](./docs/APIS.md) for futher information about:\n\n- [Python API](./docs/APIS.md#api-python), how to use the program in other Python programs\n- [HTTP API](./docs/APIS.md#api-http), how to communicate with a server with the program installed -->\n\n<h2 id=\"todo\">TODOs</h2>\n\n- [ ] Parse layout with DocLayNet based models, [PaddleX](https://github.com/PaddlePaddle/PaddleX/blob/17cc27ac3842e7880ca4aad92358d3ef8555429a/paddlex/repo_apis/PaddleDetection_api/object_det/official_categories.py#L81), [PaperMage](https://github.com/allenai/papermage/blob/9cd4bb48cbedab45d0f7a455711438f1632abebe/README.md?plain=1#L102), [SAM2](https://github.com/facebookresearch/sam2)\n\n- [ ] Fix page rotation, table of contents, format of lists\n\n- [ ] Fix pixel formula in old papers\n\n- [ ] Async retry except KeyboardInterrupt\n\n- [ ] Knuth–Plass algorithm for western languages\n\n- [ ] Support non-PDF/A files\n\n- [ ] Plugins of [Zotero](https://github.com/zotero/zotero) and [Obsidian](https://github.com/obsidianmd/obsidian-releases)\n\n<h2 id=\"acknowledgement\">Acknowledgements</h2>\n\n- [Immersive Translation](https://immersivetranslate.com) sponsors monthly Pro membership redemption codes for active contributors to this project, see details at: [CONTRIBUTOR_REWARD.md](https://github.com/funstory-ai/BabelDOC/blob/main/docs/CONTRIBUTOR_REWARD.md)\n\n- New backend: [BabelDOC](https://github.com/funstory-ai/BabelDOC)\n\n- Document merging: [PyMuPDF](https://github.com/pymupdf/PyMuPDF)\n\n- Document parsing: [Pdfminer.six](https://github.com/pdfminer/pdfminer.six)\n\n- Document extraction: [MinerU](https://github.com/opendatalab/MinerU)\n\n- Document Preview: [Gradio PDF](https://github.com/freddyaboulton/gradio-pdf)\n\n- Multi-threaded translation: [MathTranslate](https://github.com/SUSYUSTC/MathTranslate)\n\n- Layout parsing: [DocLayout-YOLO](https://github.com/opendatalab/DocLayout-YOLO)\n\n- Document standard: [PDF Explained](https://zxyle.github.io/PDF-Explained/), [PDF Cheat Sheets](https://pdfa.org/resource/pdf-cheat-sheets/)\n\n- Multilingual Font: [Go Noto Universal](https://github.com/satbyy/go-noto-universal)\n\n<h2 id=\"contrib\">Contributors</h2>\n\n<a href=\"https://github.com/Byaidu/PDFMathTranslate/graphs/contributors\">\n  <img src=\"https://opencollective.com/PDFMathTranslate/contributors.svg?width=890&button=false\" />\n</a>\n\n![Alt](https://repobeats.axiom.co/api/embed/dfa7583da5332a11468d686fbd29b92320a6a869.svg \"Repobeats analytics image\")\n\n<h2 id=\"star_hist\">Star History</h2>\n\n<a href=\"https://star-history.com/#Byaidu/PDFMathTranslate&Date\">\n <picture>\n   <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=Byaidu/PDFMathTranslate&type=Date&theme=dark\" />\n   <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=Byaidu/PDFMathTranslate&type=Date\" />\n   <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=Byaidu/PDFMathTranslate&type=Date\"/>\n </picture>\n</a>",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "pdfmathtranslate",
        "zhuangmanhong",
        "pdf",
        "zhuangmanhong pdfmathtranslate",
        "processing zhuangmanhong",
        "translate pdf"
      ],
      "category": "document-processing"
    },
    "zhushengxiao--jianshu": {
      "owner": "zhushengxiao",
      "name": "jianshu",
      "url": "https://github.com/zhushengxiao/jianshu",
      "imageUrl": "/freedevtools/mcp/pfp/zhushengxiao.webp",
      "description": "Manage and organize writing projects with a user-friendly interface, providing features tailored specifically for writers to enhance their workflow.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2020-06-12T16:04:49Z",
      "readme_content": "This project was bootstrapped with [Create React App](https://github.com/facebook/create-react-app).\n\n## Available Scripts\n\nIn the project directory, you can run:\n\n### `yarn start`\n\nRuns the app in the development mode.<br />\nOpen [http://localhost:3000](http://localhost:3000) to view it in the browser.\n\nThe page will reload if you make edits.<br />\nYou will also see any lint errors in the console.\n\n### `yarn test`\n\nLaunches the test runner in the interactive watch mode.<br />\nSee the section about [running tests](https://facebook.github.io/create-react-app/docs/running-tests) for more information.\n\n### `yarn build`\n\nBuilds the app for production to the `build` folder.<br />\nIt correctly bundles React in production mode and optimizes the build for the best performance.\n\nThe build is minified and the filenames include the hashes.<br />\nYour app is ready to be deployed!\n\nSee the section about [deployment](https://facebook.github.io/create-react-app/docs/deployment) for more information.\n\n### `yarn eject`\n\n**Note: this is a one-way operation. Once you `eject`, you can’t go back!**\n\nIf you aren’t satisfied with the build tool and configuration choices, you can `eject` at any time. This command will remove the single build dependency from your project.\n\nInstead, it will copy all the configuration files and the transitive dependencies (webpack, Babel, ESLint, etc) right into your project so you have full control over them. All of the commands except `eject` will still work, but they will point to the copied scripts so you can tweak them. At this point you’re on your own.\n\nYou don’t have to ever use `eject`. The curated feature set is suitable for small and middle deployments, and you shouldn’t feel obligated to use this feature. However we understand that this tool wouldn’t be useful if you couldn’t customize it when you are ready for it.\n\n## Learn More\n\nYou can learn more in the [Create React App documentation](https://facebook.github.io/create-react-app/docs/getting-started).\n\nTo learn React, check out the [React documentation](https://reactjs.org/).\n\n### Code Splitting\n\nThis section has moved here: https://facebook.github.io/create-react-app/docs/code-splitting\n\n### Analyzing the Bundle Size\n\nThis section has moved here: https://facebook.github.io/create-react-app/docs/analyzing-the-bundle-size\n\n### Making a Progressive Web App\n\nThis section has moved here: https://facebook.github.io/create-react-app/docs/making-a-progressive-web-app\n\n### Advanced Configuration\n\nThis section has moved here: https://facebook.github.io/create-react-app/docs/advanced-configuration\n\n### Deployment\n\nThis section has moved here: https://facebook.github.io/create-react-app/docs/deployment\n\n### `yarn build` fails to minify\n\nThis section has moved here: https://facebook.github.io/create-react-app/docs/troubleshooting#npm-run-build-fails-to-minify\n#\u0000 \u0000j\u0000i\u0000a\u0000n\u0000s\u0000h\u0000u\u0000\r\u0000\n\u0000",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "writing",
        "writers",
        "zhushengxiao",
        "organize writing",
        "processing zhushengxiao",
        "document processing"
      ],
      "category": "document-processing"
    },
    "zm1990s--panw": {
      "owner": "zm1990s",
      "name": "panw",
      "url": "https://github.com/zm1990s/panw",
      "imageUrl": "/freedevtools/mcp/pfp/zm1990s.webp",
      "description": "Integrates Palo Alto Networks AI security capabilities into clients compatible with the Model Context Protocol, enabling real-time content risk analysis and interaction with large language models. Supports various input types for dynamic content detection and compliance during AI interactions.",
      "stars": 1,
      "forks": 0,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-06-27T04:29:37Z",
      "readme_content": "",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "document",
        "security",
        "ai",
        "ai security",
        "compliance ai",
        "content detection"
      ],
      "category": "document-processing"
    },
    "zoharbabin--kaltura-mcp": {
      "owner": "zoharbabin",
      "name": "kaltura-mcp",
      "url": "https://github.com/zoharbabin/kaltura-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/zoharbabin.webp",
      "description": "Integrates Kaltura's media management for uploading, retrieving, and managing media with standardized API interactions. Supports operations like metadata retrieval, media search, category management, and user permissions management.",
      "stars": 3,
      "forks": 2,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-07-15T11:53:49Z",
      "readme_content": "# Kaltura MCP Server\n\nA Model Context Protocol (MCP) server that provides secure, read-only tools for managing Kaltura API operations. This server enables AI assistants to search, discover, and analyze Kaltura media content safely.\n\n## Features\n\n- **Media Discovery**: Search and browse media entries with advanced filtering\n- **Content Analysis**: Access captions, transcripts, and attachment content\n- **Category Management**: Browse and explore content categories  \n- **Analytics**: Retrieve viewing analytics and performance metrics\n- **Secure Access**: Read-only operations with comprehensive input validation\n- **Session Management**: Automatic session handling with configurable expiry\n\n## Installation\n\n1. Clone this repository:\n```bash\ngit clone https://github.com/zoharbabin/kaltura-mcp.git\ncd kaltura-mcp\n```\n\n2. Install dependencies:\n```bash\npip install -e .\n```\n\n## Usage Modes\n\nThis server supports two deployment modes:\n\n### 🔧 Local MCP Server (Stdio Mode)\n**Best for:** Personal use, direct Claude Desktop integration, development\n\n### 🌐 Remote MCP Server (HTTP/SSE Mode)  \n**Best for:** Hosted services, multiple users, production deployments\n\n---\n\n## Local MCP Server Setup (Claude Desktop)\n\n### Step 1: Install Package\n\n```bash\npip install kaltura-mcp\n```\n\n### Step 2: Setup Environment Configuration\n\n**🔒 Secure Method (Recommended)**: Use the interactive setup script:\n\n```bash\n# Navigate to your project directory\ncd /path/to/kaltura-mcp\n\n# Run the interactive setup\npython setup_env.py\n```\n\nThe script will guide you through:\n1. Choosing between stdio (local) or remote mode\n2. Securely entering your Kaltura credentials\n3. Generating a `.env` file with proper permissions (600)\n4. Providing the exact Claude Desktop configuration\n\n**📋 Manual Method**: Copy and edit the example file:\n\n```bash\n# Copy the example file\ncp .env.example .env\n\n# Edit with your credentials\n# - For stdio mode: Only fill in KALTURA_* variables\n# - For remote mode: Fill in JWT_SECRET_KEY, OAUTH_*, and SERVER_* variables\nnano .env\n\n# Set secure permissions\nchmod 600 .env\n```\n\n### Step 3: Get Your Kaltura Credentials\n\nYou'll need these credentials from your Kaltura account:\n\n- **Service URL**: Your Kaltura server URL (usually `https://cdnapisec.kaltura.com`)\n- **Partner ID**: Your numeric partner ID (found in KMC → Settings → Integration Settings)\n- **Admin Secret**: Your API admin secret key (found in KMC → Settings → Integration Settings)  \n- **User ID**: Your Kaltura user ID (usually your email or `admin`)\n\n### Step 4: Configure Claude Desktop\n\nOpen your Claude Desktop configuration file:\n\n**macOS**: `~/Library/Application\\ Support/Claude/claude_desktop_config.json`\n**Windows**: `%APPDATA%\\Claude\\claude_desktop_config.json`\n\n**🔒 Secure Configuration (credentials in .env file)**:\n\n```json\n{\n  \"mcpServers\": {\n    \"kaltura\": {\n      \"command\": \"/full/path/to/kaltura-mcp\"\n    }\n  }\n}\n```\n\n**Important Notes**: \n- Replace `/full/path/to/kaltura-mcp` with the actual path to your kaltura-mcp command (find it with `which kaltura-mcp`)\n- The `.env` file is automatically loaded from the project directory by the server\n- The `setup_env.py` script will automatically detect and provide the correct command path\n\n### Step 5: Restart Claude Desktop\n\nAfter saving the configuration file, restart Claude Desktop completely for the changes to take effect.\n\n### Step 6: Test the Integration\n\nIn Claude Desktop, try asking:\n- \"Search for recent Kaltura videos\"\n- \"List my Kaltura categories\"\n- \"Find videos about [topic] in my Kaltura account\"\n\n### Troubleshooting Local Setup\n\n**Issue**: `kaltura-mcp` command not found\n- **Solution**: Make sure you installed with `pip install kaltura-mcp` and the command is in your PATH\n\n**Issue**: \"Error: Missing required environment variables\"\n- **Solution**: \n  1. Check that `.env` file exists in your project directory\n  2. Verify file permissions: `ls -la .env` (should show `-rw-------`)\n  3. Ensure all required Kaltura credentials are set in `.env` file\n\n**Issue**: \"Invalid credentials\" or \"Authentication failed\"\n- **Solution**: \n  1. Verify your credentials in Kaltura KMC → Settings → Integration Settings\n  2. Check `.env` file for typos or extra spaces\n  3. Run `python setup_env.py` to recreate the configuration\n\n**Issue**: Claude Desktop doesn't show the MCP server\n- **Solution**: \n  1. Check the config file syntax with a JSON validator\n  2. Verify the command path is correct (use `which kaltura-mcp`)\n  3. Restart Claude Desktop completely\n  4. Check Claude Desktop logs for error messages\n\n**Issue**: \".env file not found\" error\n- **Solution**:\n  1. Run `python setup_env.py` from your project directory\n  2. Ensure the `.env` file exists in the same directory as the server code\n  3. Check file permissions: `ls -la .env` (should show `-rw-------`)\n\n**✅ Security Benefits:** \n- ✅ **Secure file permissions** (600 - owner only)\n- ✅ **Git-ignored by default** (won't be committed)\n- ✅ **Local to project directory** (easy to manage)\n- ✅ **Standard .env pattern** (familiar to developers)\n- ✅ **No credentials in config files** (improved security)\n\n---\n\n## Remote MCP Server Setup\n\n### Configuration\n\nFor remote/hosted deployment, additional environment variables are required:\n\n```bash\ncp .env.example .env\n# Configure remote server settings\n```\n\n**Required environment variables:**\n- `JWT_SECRET_KEY`: Strong secret key for JWT token signing (⚠️ **CRITICAL FOR SECURITY**)\n- `OAUTH_REDIRECT_URI`: OAuth callback URL (e.g., `https://your-domain.com/oauth/callback`)\n- `SERVER_HOST`: Server bind address (default: `0.0.0.0`)\n- `SERVER_PORT`: Server port (default: `8000`)\n\n**Optional environment variables:**\n- `SERVER_RELOAD`: Enable auto-reload in development (default: `false`)\n- `OAUTH_CLIENT_ID`: Custom OAuth client ID\n- `OAUTH_CLIENT_SECRET`: Custom OAuth client secret\n\n### Running Remote Server\n\n```bash\n# Using the installed command\nkaltura-mcp-remote\n\n# Or using Python module\npython -m kaltura_mcp.remote_server\n```\n\nThe remote server provides:\n- **HTTP/SSE transport** for MCP protocol\n- **JWT-based authentication** for secure credential management\n- **Web-based authorization** flow for user-friendly setup\n- **Multi-tenant support** for hosting as a service\n\n### Available Tools\n\n1. **get_media_entry** - Get detailed information about a specific media entry\n   - Parameters: entry_id (required)\n\n2. **list_categories** - List and search content categories\n   - Parameters: search_text, limit\n\n3. **Analytics Tools** - Comprehensive analytics suite with purpose-driven functions:\n   - **get_analytics** - General analytics data for reporting and analysis\n   - **get_analytics_timeseries** - Time-series data optimized for charts\n   - **get_video_retention** - Detailed viewer retention analysis throughout videos\n   - **get_realtime_metrics** - Live analytics updated every ~30 seconds\n   - **get_quality_metrics** - Quality of Experience (QoE) and streaming performance\n   - **get_geographic_breakdown** - Location-based analytics at various granularities\n   - **list_analytics_capabilities** - Discover all available analytics functions\n   - See [Analytics Guide](docs/KALTURA_ANALYTICS_GUIDE.md) for detailed usage\n\n4. **get_download_url** - Get direct download URL for media files\n   - Parameters: entry_id (required), flavor_id\n\n5. **get_thumbnail_url** - Get video thumbnail/preview image URL with custom dimensions\n   - Parameters: entry_id (required), width, height, second\n\n6. **search_entries** - Search and discover media entries with intelligent sorting and filtering\n   - Parameters: query (required), search_type, match_type, specific_field, boolean_operator, include_highlights, custom_metadata, date_range, max_results, sort_field, sort_order\n\n7. **list_caption_assets** - List available captions and subtitles for a media entry\n   - Parameters: entry_id (required)\n\n8. **get_caption_content** - Get caption/subtitle content and download URL\n   - Parameters: caption_asset_id (required)\n\n9. **list_attachment_assets** - List attachment assets for a media entry\n   - Parameters: entry_id (required)\n\n10. **get_attachment_content** - Get attachment content details and download content as base64\n    - Parameters: attachment_asset_id (required)\n\n### Prompts\n\nThe server provides intelligent prompts to guide users through complex workflows:\n\n1. **analytics_wizard** - Interactive guide for creating comprehensive analytics reports\n   ```\n   Arguments:\n   - analysis_goal: What to analyze (e.g., \"video performance\", \"viewer engagement\", \"geographic reach\")\n   - time_period: Time range (e.g., \"today\", \"yesterday\", \"last_week\", \"last_month\")\n   ```\n\n2. **content_discovery** - Natural language search assistant for finding media\n   ```\n   Arguments:\n   - search_intent: What you're looking for in natural language\n   - include_details: Whether to fetch captions/attachments (yes/no)\n   ```\n\n3. **accessibility_audit** - Content accessibility compliance checker\n   ```\n   Arguments:\n   - audit_scope: What to audit (\"all\", \"recent\", \"category:name\", or entry_id)\n   ```\n\n4. **retention_analysis** - Create comprehensive retention analysis report\n   ```\n   Arguments:\n   - entry_id: Video to analyze (e.g., \"1_3atosphg\") [required]\n   - time_period: Months of data to analyze (default: \"12\")\n   - output_format: \"interactive\" (HTML) or \"markdown\" (default: \"interactive\")\n   ```\n\n### Resources\n\nThe server exposes frequently-used data as cached resources:\n\n1. **kaltura://analytics/capabilities** - Complete analytics documentation\n   - All 60+ report types with descriptions\n   - Available metrics and dimensions\n   - Best practices for different use cases\n   - Cached for 30 minutes\n\n2. **kaltura://categories/tree** - Category hierarchy with entry counts\n   - Complete category tree structure\n   - Entry counts per category\n   - Parent-child relationships\n   - Cached for 30 minutes\n\n3. **kaltura://media/recent/{count}** - Recent media entries\n   - Replace {count} with number of entries (e.g., kaltura://media/recent/20)\n   - Maximum 100 entries\n   - Includes basic metadata\n   - Cached for 5 minutes\n\n---\n\n## Remote MCP Server (Advanced)\n\n### User Authorization Flow\n\n1. **Server Deployment**: Deploy the remote server to your hosting environment\n2. **User Authorization**: Users visit `https://your-server.com/oauth/authorize` \n3. **Credential Entry**: Users securely enter their Kaltura credentials via web form\n4. **Token Generation**: Server generates a JWT token with encrypted credentials\n5. **Client Configuration**: Users add the server URL and token to their MCP client\n\n### Step-by-Step Remote Setup\n\n#### 1. Generate Secure JWT Secret\n\n```bash\n# Generate a strong secret key\npython -c \"import secrets; print(secrets.token_urlsafe(32))\"\n```\n\n#### 2. Configure Environment\n\n```bash\n# Set in your .env file or environment\nJWT_SECRET_KEY=your-generated-secret-key-here\nOAUTH_REDIRECT_URI=https://your-domain.com/oauth/callback\nSERVER_HOST=0.0.0.0\nSERVER_PORT=8000\n```\n\n#### 3. Deploy Server\n\n**Option A: Direct Python**\n```bash\nkaltura-mcp-remote\n```\n\n**Option B: Docker**\n```bash\ndocker-compose up -d\n```\n\n**Option C: Production with Gunicorn (Optional)**\n```bash\n# Install gunicorn separately if needed for production\npip install gunicorn\ngunicorn -w 4 -k uvicorn.workers.UvicornWorker kaltura_mcp.remote_server:app\n```\n\n#### 4. User Onboarding\n\nSend users to: `https://your-server.com/oauth/authorize?response_type=code&client_id=kaltura-mcp&redirect_uri=https://your-server.com/oauth/callback&state=user123`\n\n#### 5. Client Configuration\n\n**For Claude Desktop (Remote Mode):**\n\nThe easiest way to use the remote server with Claude Desktop is via the proxy client:\n\n```json\n{\n  \"mcpServers\": {\n    \"kaltura-remote\": {\n      \"command\": \"kaltura-mcp-proxy\",\n      \"env\": {\n        \"KALTURA_REMOTE_SERVER_URL\": \"https://your-server.com/mcp/messages\",\n        \"KALTURA_REMOTE_ACCESS_TOKEN\": \"your-jwt-token-from-authorization-flow\"\n      }\n    }\n  }\n}\n```\n\nThe proxy client (`kaltura-mcp-proxy`) acts as a local stdio MCP server that forwards requests to your remote server. This provides the best compatibility with Claude Desktop.\n\n**For Custom MCP Clients:**\n```javascript\n// HTTP transport with authentication\nconst transport = new HTTPTransport({\n  baseUrl: \"https://your-server.com/mcp/messages\",\n  headers: {\n    \"Authorization\": \"Bearer user-jwt-token-here\"\n  }\n});\n```\n\n### Analytics Documentation\n\nThe MCP server provides a comprehensive analytics suite with purpose-driven functions optimized for different use cases:\n\n**Purpose-Built Analytics Functions:**\n- **get_analytics**: Comprehensive reporting data in table format for detailed analysis\n- **get_analytics_timeseries**: Time-series data optimized for charts and visualizations\n- **get_video_retention**: Detailed viewer retention curves showing exactly where viewers drop off\n- **get_realtime_metrics**: Live analytics updated every ~30 seconds for monitoring\n- **get_quality_metrics**: Quality of Experience (QoE) metrics for streaming performance\n- **get_geographic_breakdown**: Location-based analytics at country, region, or city level\n\n**Analytics Capabilities:**\n- 60+ report types covering content, users, geography, platforms, and more\n- Raw data access for custom analysis and visualization\n- Intelligent insights including drop-off points and engagement patterns\n- Support for filtering by date ranges, categories, users, and dimensions\n\nFor comprehensive documentation, see:\n- [Analytics Guide](docs/KALTURA_ANALYTICS_GUIDE.md) - Complete reference for all analytics functions\n- [Analytics Examples](examples/analytics_examples.py) - Code examples and visualizations\n\n### Security Considerations\n\n#### Production Deployment\n- **Use HTTPS**: Always deploy with TLS/SSL certificates\n- **Secure JWT Secret**: Use a cryptographically strong secret key (32+ bytes)\n- **Environment Security**: Never commit secrets to version control\n- **Network Security**: Use firewalls and VPN access where appropriate\n- **Regular Updates**: Keep dependencies updated for security patches\n\n#### JWT Token Security\n- **Token Expiration**: Tokens expire after 24 hours by default\n- **Credential Encryption**: Kaltura credentials are encrypted within JWT payload\n- **Scope Limitation**: Tokens are limited to read-only Kaltura operations\n- **Revocation**: Restart server to invalidate all existing tokens\n\n#### Infrastructure\n```bash\n# Example nginx configuration for production\nserver {\n    listen 443 ssl;\n    server_name your-kaltura-mcp.com;\n    \n    ssl_certificate /path/to/cert.pem;\n    ssl_certificate_key /path/to/key.pem;\n    \n    location / {\n        proxy_pass http://localhost:8000;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n    }\n}\n```\n\n### Docker Deployment\n\n**docker-compose.yml for production:**\n```yaml\nversion: '3.8'\nservices:\n  kaltura-mcp:\n    build: .\n    ports:\n      - \"8000:8000\"\n    environment:\n      - JWT_SECRET_KEY=${JWT_SECRET_KEY}\n      - OAUTH_REDIRECT_URI=https://your-domain.com/oauth/callback\n      - SERVER_HOST=0.0.0.0\n      - SERVER_PORT=8000\n    restart: unless-stopped\n    volumes:\n      - ./logs:/app/logs\n    labels:\n      - \"traefik.enable=true\"\n      - \"traefik.http.routers.kaltura-mcp.rule=Host(\\`your-domain.com\\`)\"\n      - \"traefik.http.routers.kaltura-mcp.tls=true\"\n```\n\n### Monitoring & Logging\n\nThe remote server provides built-in logging and can be monitored via:\n- **Health Check**: `GET /` returns server status\n- **Metrics**: Access logs via Docker volumes or server logs\n- **Error Tracking**: Configure external error tracking services\n\n### Important Security Notes\n\n#### Local Mode Security (Recommended)\n- ✅ **Direct Configuration** - Credentials configured directly in Claude Desktop\n- ✅ **MCP Standard Compliance** - Client passes credentials to server via environment variables\n- ✅ **Process Isolation** - MCP server runs in isolated process with limited scope\n- ✅ **No network exposure** - Direct API communication with Kaltura\n- ✅ **Local credential storage** - Credentials never leave your machine\n- ✅ **Secure transmission** - Credentials passed securely to MCP server process\n\n#### Remote Mode Security  \n- ✅ **Credential encryption** - Kaltura credentials encrypted in JWT tokens\n- ✅ **Token expiration** - Automatic 24-hour token expiry\n- ✅ **TLS encryption** - HTTPS required for production\n- ⚠️ **Server trust** - You must trust the remote server operator\n- ⚠️ **Credential transmission** - Credentials are sent to remote server (encrypted)\n\n#### Production Checklist\n- [ ] Use HTTPS with valid certificates\n- [ ] Generate strong JWT secret key (32+ bytes)\n- [ ] Configure secure environment variables\n- [ ] Set up proper logging and monitoring\n- [ ] Implement rate limiting (nginx/cloudflare)\n- [ ] Regular security updates\n- [ ] Backup and disaster recovery plan\n\n### Deployment Architectures\n\n#### Personal Use (Recommended)\n```\nClaude Desktop ←→ Local MCP Server ←→ Kaltura API\n```\n\n#### Small Team\n```\nClaude Desktop ←→ Proxy Client ←→ Remote MCP Server ←→ Kaltura API\n```\n\n#### Enterprise\n```\nMultiple Clients ←→ Load Balancer ←→ Multiple MCP Servers ←→ Kaltura API\n                                          ↓\n                                    Redis/Database\n```\n\n## Documentation\n\n- [Analytics Guide](docs/KALTURA_ANALYTICS_GUIDE.md) - Comprehensive guide to analytics features\n- [Prompts and Resources](docs/PROMPTS_AND_RESOURCES.md) - Detailed documentation of MCP prompts and resources\n- [API Documentation](https://developer.kaltura.com/) - Official Kaltura API documentation\n\n## Development\n\n### Running Tests\n\n```bash\npytest\n```\n\n### Code Formatting\n\n```bash\nblack src/\nruff check src/\n```\n\n## License\n\nMIT",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "kaltura",
        "uploading",
        "processing",
        "kaltura media",
        "kaltura mcp",
        "media management"
      ],
      "category": "document-processing"
    },
    "zongmin-yu--sqlite-literature-management-fastmcp-mcp-server": {
      "owner": "zongmin-yu",
      "name": "sqlite-literature-management-fastmcp-mcp-server",
      "url": "https://github.com/zongmin-yu/sqlite-literature-management-fastmcp-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/zongmin-yu.webp",
      "description": "Manages various types of sources such as papers, books, and webpages while integrating them with knowledge graphs. Tracks relationships between sources and entities, supports multiple identifiers, and maintains structured note-taking and status tracking.",
      "stars": 14,
      "forks": 3,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-29T04:17:43Z",
      "readme_content": "# Universal Source Management System\n\nA flexible system for managing various types of sources (papers, books, webpages, etc.) and integrating them with knowledge graphs.\n\n## Features\n\n### Core Features\n\n- Universal source identification with internal UUID system\n- Support for multiple source types (papers, webpages, books, videos, blogs)\n- Multiple identifier support per source (arxiv, DOI, semantic scholar, ISBN, URL)\n- Structured note-taking with titles and content\n- Status tracking (unread, reading, completed, archived)\n\n### Entity Integration\n\n- Link sources to knowledge graph entities\n- Track relationships between sources and entities\n- Flexible relation types (discusses, introduces, extends, etc.)\n- Integration with memory graph\n\n## Prerequisites\n\nThis system integrates with the [MCP Memory Server](https://github.com/modelcontextprotocol/servers/tree/main/src/memory) for persistent knowledge graph storage.\n\n## Quick Start\n\n1. Create a new SQLite database with our schema:\n\n```bash\n# Create a new database\nsqlite3 sources.db < create_sources_db.sql\n```\n\n2. Install the source management server:\n\n```bash\n# Install for Claude Desktop with your database path\nfastmcp install source-manager-server.py --name \"Source Manager\" -e SQLITE_DB_PATH=/path/to/sources.db\n```\n\n## Schema\n\n### Core Tables\n\n```sql\n-- Sources table\nCREATE TABLE sources (\n    id UUID PRIMARY KEY,\n    title TEXT NOT NULL,\n    type TEXT CHECK(type IN ('paper', 'webpage', 'book', 'video', 'blog')) NOT NULL,\n    identifiers JSONB NOT NULL,\n    status TEXT CHECK(status IN ('unread', 'reading', 'completed', 'archived')) DEFAULT 'unread'\n);\n\n-- Source notes\nCREATE TABLE source_notes (\n    source_id UUID REFERENCES sources(id),\n    note_title TEXT NOT NULL,\n    content TEXT NOT NULL,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    PRIMARY KEY (source_id, note_title)\n);\n\n-- Entity links\nCREATE TABLE source_entity_links (\n    source_id UUID REFERENCES sources(id),\n    entity_name TEXT,\n    relation_type TEXT CHECK(relation_type IN ('discusses', 'introduces', 'extends', 'evaluates', 'applies', 'critiques')),\n    notes TEXT,\n    PRIMARY KEY (source_id, entity_name)\n);\n```\n\n## Usage Examples\n\n### 1. Managing Sources\n\nAdd a paper with multiple identifiers:\n\n```python\nadd_source(\n    title=\"Attention Is All You Need\",\n    type=\"paper\",\n    identifier_type=\"arxiv\",\n    identifier_value=\"1706.03762\",\n    initial_note={\n        \"title\": \"Initial thoughts\",\n        \"content\": \"Groundbreaking paper introducing transformers...\"\n    }\n)\n\n# Add another identifier to the same paper\nadd_identifier(\n    title=\"Attention Is All You Need\",\n    type=\"paper\",\n    current_identifier_type=\"arxiv\",\n    current_identifier_value=\"1706.03762\",\n    new_identifier_type=\"semantic_scholar\",\n    new_identifier_value=\"204e3073870fae3d05bcbc2f6a8e263d9b72e776\"\n)\n```\n\nAdd a webpage:\n\n```python\nadd_source(\n    title=\"Understanding Transformers\",\n    type=\"webpage\",\n    identifier_type=\"url\",\n    identifier_value=\"https://example.com/transformers\",\n)\n```\n\n### 2. Note Taking\n\nAdd notes to a source:\n\n```python\nadd_note(\n    title=\"Attention Is All You Need\",\n    type=\"paper\",\n    identifier_type=\"arxiv\",\n    identifier_value=\"1706.03762\",\n    note_title=\"Implementation details\",\n    note_content=\"The paper describes the architecture...\"\n)\n```\n\n### 3. Entity Linking\n\nLink source to entities:\n\n```python\nlink_to_entity(\n    title=\"Attention Is All You Need\",\n    type=\"paper\",\n    identifier_type=\"arxiv\",\n    identifier_value=\"1706.03762\",\n    entity_name=\"transformer\",\n    relation_type=\"introduces\",\n    notes=\"First paper to introduce the transformer architecture\"\n)\n```\n\nQuery sources by entity:\n\n```python\nget_entity_sources(\n    entity_name=\"transformer\",\n    type_filter=\"paper\",\n    relation_filter=\"discusses\"\n)\n```\n\n## Best Practices\n\n1. Source Management\n\n   - Use consistent titles across references\n   - Provide as many identifiers as available\n   - Keep notes structured with clear titles\n   - Use appropriate source types\n\n2. Entity Linking\n   - Be specific with relation types\n   - Add contextual notes to relationships\n   - Verify entity names against memory graph\n   - Keep entity relationships focused\n\n## Technical Details\n\n1. Source Identification\n\n   - Internal UUID system for consistent referencing\n   - Multiple external identifiers per source\n   - Flexible identifier types (arxiv, doi, url, etc.)\n   - Title and type based fuzzy matching\n\n2. Data Organization\n   - Structured notes with titles\n   - Clear source type categorization\n   - Entity relationship tracking\n   - Status management\n\n## Contributing\n\n1. Fork the repository\n2. Create a feature branch\n3. Add tests for new features\n4. Submit a pull request\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "fastmcp",
        "sqlite",
        "document",
        "document processing",
        "management fastmcp",
        "sources entities"
      ],
      "category": "document-processing"
    },
    "zw459123678--tuniao-server": {
      "owner": "zw459123678",
      "name": "tuniao-server",
      "url": "https://github.com/zw459123678/tuniao-server",
      "imageUrl": "/freedevtools/mcp/pfp/zw459123678.webp",
      "description": "Provides access to TuNiao UI components documentation and listings via the Model Context Protocol. Features include retrieving component information and detailed documentation for specific components.",
      "stars": 0,
      "forks": 1,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-04-18T15:47:34Z",
      "readme_content": "# Tuniao UI MCP Server\n\nA Model Context Protocol (MCP) server that provides access to TuNiao UI components documentation and listings.\n\n## Features\n\n- Component information from [Tuniao UI](https://vue2.tuniaokj.com/)\n- MCP protocol compatible\n- Easy integration with AI models\n- Markdown formatted output with clickable links\n- Comprehensive component documentation\n\n## Available Tools\n\n- `get_component_list`\n  - Gets a list of available TuNiao UI components\n  \n- `get_component_doc`\n  - Gets detailed documentation for a specific TuNiao UI component\n\n## Installation\n\n### NPX\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-server-tuniao\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@zw459123678/tuniao-server\"\n      ]\n    }\n  }\n}\n```\n\n### Docker \n（ Docker image not uploaded to Docker Hub, need to build it yourself. ）\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-server-tuniao\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"zw459123678/tuniao-server\"\n      ]\n    }\n  }\n}\n```\n\n## Development\n\n```bash\n# Install dependencies\nnpm install\n\n# Watch mode\nnpm run watch\n\n# Build\nnpm run build\n\n# Test components\nnpm run test:comp\n```\n\nDocker build:\n\n```bash\ndocker build -t zw459123678/tuniao-server:latest -f Dockerfile .\n```\n\n## License\n\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "tuniao",
        "documentation",
        "document",
        "tuniao ui",
        "tuniao server",
        "access tuniao"
      ],
      "category": "document-processing"
    }
  }
}